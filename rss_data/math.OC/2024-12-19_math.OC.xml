<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Scalable Method for Optimal Path Planning on Manifolds via a Hopf-Lax Type Formula</title>
      <link>https://arxiv.org/abs/2412.13346</link>
      <description>arXiv:2412.13346v1 Announce Type: new 
Abstract: We consider the problem of optimal path planning on a manifold which is the image of a smooth function. Optimal path-planning is of crucial importance for motion planning, image processing, and statistical data analysis. In this work, we consider a particle lying on the graph of a smooth function that seeks to navigate from some initial point to another point on the manifold in minimal time. We model the problem using optimal control theory, the dynamic programming principle, and a Hamilton-Jacobi-Bellman equation. We then design a novel primal dual hybrid gradient inspired algorithm that resolves the solution efficiently based on a generalized Hopf-Lax type formula. We present examples which demonstrate the effectiveness and efficiency of the algorithm. Finally, we demonstrate that, because the algorithm does not rely on grid-based numerical methods for partial differential equations, it scales well for high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13346v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Huynh, Christian Parkinson</dc:creator>
    </item>
    <item>
      <title>A polynomial approximation scheme for nonlinear model reduction by moment matching</title>
      <link>https://arxiv.org/abs/2412.13371</link>
      <description>arXiv:2412.13371v1 Announce Type: new 
Abstract: We propose a procedure for the numerical approximation of invariance equations arising in the moment matching technique associated with reduced-order modeling of high-dimensional dynamical systems. The Galerkin residual method is employed to find an approximate solution to the invariance equation using a Newton iteration on the coefficients of a monomial basis expansion of the solution. These solutions to the invariance equations can then be used to construct reduced-order models. We assess the ability of the method to solve the invariance PDE system as well as to achieve moment matching and recover a system's steady-state behaviour for linear and nonlinear signal generators with system dynamics up to $n=1000$ dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13371v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Doebeli, Alessandro Astolfi, Dante Kalise, Alessio Moreschini, Giordano Scarciotti, Joel Simard</dc:creator>
    </item>
    <item>
      <title>Sum-of-Squares Programming for Ma-Trudinger-Wang Regularity of Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2412.13372</link>
      <description>arXiv:2412.13372v1 Announce Type: new 
Abstract: For a given ground cost, approximating the Monge optimal transport map that pushes forward a given probability measure onto another has become a staple in several modern machine learning algorithms. The fourth-order Ma-Trudinger-Wang (MTW) tensor associated with this ground cost function provides a notion of curvature in optimal transport. The non-negativity of this tensor plays a crucial role for establishing continuity for the Monge optimal transport map. It is, however, generally difficult to analytically verify this condition for any given ground cost. To expand the class of cost functions for which MTW non-negativity can be verified, we propose a provably correct computational approach which provides certificates of non-negativity for the MTW tensor using Sum-of-Squares (SOS) programming. We further show that our SOS technique can also be used to compute an inner approximation of the region where MTW non-negativity holds. We apply our proposed SOS programming method to several practical ground cost functions to approximate the regions of regularity of their corresponding optimal transport maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13372v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sachin Shivakumar, Georgiy A. Bondar, Gabriel Khan, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>QP Based Constrained Optimization for Reliable PINN Training</title>
      <link>https://arxiv.org/abs/2412.13403</link>
      <description>arXiv:2412.13403v1 Announce Type: new 
Abstract: Physics-Informed Neural Networks (PINNs) have emerged as a powerful tool for integrating physics-based constraints and data to address forward and inverse problems in machine learning. Despite their potential, the implementation of PINNs are hampered by several challenges, including issues related to convergence, stability, and the design of neural networks and loss functions. In this paper, we introduce a novel training scheme that addresses these challenges by framing the training process as a constrained optimization problem. Utilizing a quadratic program (QP)-based gradient descent law, our approach simplifies the design of loss functions and guarantees convergences to optimal neural network parameters. This methodology enables dynamic balancing, over the course of training, between data-based loss and a partial differential equation (PDE) residual loss, ensuring an acceptable level of accuracy while prioritizing the minimization of PDE-based loss. We demonstrate the formulation of the constrained PINNs approach with noisy data, in the context of solving Laplace's equation in a capacitor with complex geometry. This work not only advances the capabilities of PINNs but also provides a framework for their training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13403v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alan Williams, Christopher Leon, Alexander Scheinker</dc:creator>
    </item>
    <item>
      <title>Learning complexity of gradient descent and conjugate gradient algorithms</title>
      <link>https://arxiv.org/abs/2412.13473</link>
      <description>arXiv:2412.13473v1 Announce Type: new 
Abstract: Gradient Descent (GD) and Conjugate Gradient (CG) methods are among the most effective iterative algorithms for solving unconstrained optimization problems, particularly in machine learning and statistical modeling, where they are employed to minimize cost functions. In these algorithms, tunable parameters, such as step sizes or conjugate parameters, play a crucial role in determining key performance metrics, like runtime and solution quality. In this work, we introduce a framework that models algorithm selection as a statistical learning problem, and thus learning complexity can be estimated by the pseudo-dimension of the algorithm group. We first propose a new cost measure for unconstrained optimization algorithms, inspired by the concept of primal-dual integral in mixed-integer linear programming. Based on the new cost measure, we derive an improved upper bound for the pseudo-dimension of gradient descent algorithm group by discretizing the set of step size configurations. Moreover, we generalize our findings from gradient descent algorithm to the conjugate gradient algorithm group for the first time, and prove the existence a learning algorithm capable of probabilistically identifying the optimal algorithm with a sufficiently large sample size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13473v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianqi Jiao, Jia Liu, Zhiping Chen</dc:creator>
    </item>
    <item>
      <title>Lyapunov Analysis For Monotonically Forward-Backward Accelerated Algorithms</title>
      <link>https://arxiv.org/abs/2412.13527</link>
      <description>arXiv:2412.13527v1 Announce Type: new 
Abstract: In the realm of gradient-based optimization, Nesterov's accelerated gradient method (NAG) is a landmark advancement, achieving an accelerated convergence rate that outperforms the vanilla gradient descent method for convex function. However, for strongly convex functions, whether NAG converges linearly remains an open question, as noted in the comprehensive review by Chambolle and Pock [2016]. This issue, aside from the critical step size, was addressed by Li et al. [2024a] using a high-resolution differential equation framework. Furthermore, Beck [2017, Section 10.7.4] introduced a monotonically convergent variant of NAG, referred to as M-NAG. Despite these developments, the Lyapunov analysis presented in [Li et al., 2024a] cannot be directly extended to M-NAG. In this paper, we propose a modification to the iterative relation by introducing a gradient term, leading to a new gradient-based iterative relation. This adjustment allows for the construction of a novel Lyapunov function that excludes kinetic energy. The linear convergence derived from this Lyapunov function is independent of both the parameters of the strongly convex functions and the step size, yielding a more general and robust result. Notably, we observe that the gradient iterative relation derived from M-NAG is equivalent to that from NAG when the position-velocity relation is applied. However, the Lyapunov analysis does not rely on the position-velocity relation, allowing us to extend the linear convergence to M-NAG. Finally, by utilizing two proximal inequalities, which serve as the proximal counterparts of strongly convex inequalities, we extend the linear convergence to both the fast iterative shrinkage-thresholding algorithm (FISTA) and its monotonic counterpart (M-FISTA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13527v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mingwei Fu, Bin Shi</dc:creator>
    </item>
    <item>
      <title>Stabilization of strictly pre-dissipative nonlinear receding horizon control by terminal costs</title>
      <link>https://arxiv.org/abs/2412.13538</link>
      <description>arXiv:2412.13538v1 Announce Type: new 
Abstract: It is known that receding horizon control with a strictly pre-dissipative optimal control problem yields a practically asymptotically stable closed loop when suitable state constraints are imposed. In this note we show that alternatively suitably bounded terminal costs can be used for stabilizing the closed loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13538v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Gr\"une, Mario Zanon</dc:creator>
    </item>
    <item>
      <title>GPU-based Graver Basis Extraction for Nonlinear Integer Optimization</title>
      <link>https://arxiv.org/abs/2412.13576</link>
      <description>arXiv:2412.13576v1 Announce Type: new 
Abstract: Nonlinear integer programs involve optimizing nonlinear objectives with variables restricted to integer values, and have widespread applications in areas such as resource allocation and portfolio selection. One approach to solving these problems is the augmentation procedure, which iteratively refines a feasible solution by identifying augmenting steps from the Graver Basis--a set of test directions. While this method guarantees termination in polynomially many steps, computing the Graver Basis exactly is known to be $\mathcal{NP}$-hard. To address this computational challenge, we propose Multi-start Augmentation via Parallel Extraction (MAPLE), a GPU-based heuristic designed to efficiently approximate the Graver Basis. MAPLE extracts test directions by optimizing non-convex continuous problems, leveraging first-order methods to enable parallelizable implementation. The resulting set of directions is then used in multiple augmentations, each seeking to improve the solution's optimality. The proposed approach has three notable characteristics: (i) independence from general-purpose solvers, while ensuring guaranteed feasibility of solutions; (ii) high computational efficiency, achieved through GPU-based parallelization; (iii) flexibility in handling instances with shared constraint matrices but varying objectives and right-hand sides. Empirical evaluations on QPLIB benchmark instances demonstrate that MAPLE delivers performance comparable to state-of-the-art solvers in terms of solution quality, while achieving significant gains in computational efficiency. These results highlight MAPLE's potential as an effective heuristic for solving nonlinear integer programs in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13576v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenbo Liu, Akang Wang, Wenguo Yang</dc:creator>
    </item>
    <item>
      <title>Disease Progression Modelling and Stratification for detecting sub-trajectories in the natural history of pathologies: application to Parkinson's Disease trajectory modelling</title>
      <link>https://arxiv.org/abs/2412.13608</link>
      <description>arXiv:2412.13608v1 Announce Type: new 
Abstract: Modelling the progression of Degenerative Diseases (DD) is essential for detection, prevention, and treatment, yet it remains challenging due to the heterogeneity in disease trajectories among individuals. Factors such as demographics, genetic conditions, and lifestyle contribute to diverse phenotypical manifestations, necessitating patient stratification based on these variations. Recent methods like Subtype and Stage Inference (SuStaIn) have advanced unsupervised stratification of disease trajectories, but they face potential limitations in robustness, interpretability, and temporal granularity. To address these challenges, we introduce Disease Progression Modelling and Stratification (DP-MoSt), a novel probabilistic method that optimises clusters of continuous trajectories over a long-term disease time-axis while estimating the confidence of trajectory sub-types for each biomarker. We validate DP-MoSt using both synthetic and real-world data from the Parkinson's Progression Markers Initiative (PPMI). Our results demonstrate that DP-MoSt effectively identifies both sub-trajectories and subpopulations, and is a promising alternative to current state-of-the-art models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13608v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Viani (CRISAM), Boris A Gutman (IIT), Emile d'Angremont (Amsterdam UMC), Marco Lorenzi (CRISAM)</dc:creator>
    </item>
    <item>
      <title>Speeding up Stochastic Proximal Optimization in the High Hessian Dissimilarity Setting</title>
      <link>https://arxiv.org/abs/2412.13619</link>
      <description>arXiv:2412.13619v1 Announce Type: new 
Abstract: Stochastic proximal point methods have recently garnered renewed attention within the optimization community, primarily due to their desirable theoretical properties. Notably, these methods exhibit a convergence rate that is independent of the Lipschitz smoothness constants of the loss function, a feature often missing in the loss functions of modern ML applications. In this paper, we revisit the analysis of the Loopless Stochastic Variance Reduced Proximal Point Method (L-SVRP). Building on existing work, we establish a theoretical improvement in the convergence rate in scenarios characterized by high Hessian dissimilarity among the functions. Our concise analysis, which does not require smoothness assumptions, demonstrates a significant improvement in communication complexity compared to standard stochastic gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13619v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elnur Gasanov, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>A novel necessary and sufficient condition for the stability of $2\times 2$ first-order linear hyperbolic systems</title>
      <link>https://arxiv.org/abs/2412.13929</link>
      <description>arXiv:2412.13929v1 Announce Type: new 
Abstract: In this paper, we establish a necessary and sufficient stability condition for a class of two coupled first-order linear hyperbolic partial differential equations. Through a backstepping transform, the problem is reformulated as a stability problem for an integral difference equation, that is, a difference equation with distributed delay. Building upon a St\'ep\'an--Hassard argument variation theorem originally designed for time-delay systems of retarded type, we then introduce a theorem that counts the number of unstable roots of our integral difference equation. This leads to the expected necessary and sufficient stability criterion for the system of first-order linear hyperbolic partial differential equations. Finally, we validate our theoretical findings through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13929v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isma\"ila Balogoun (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France), Guilherme Mazanti (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France, F\'ed\'eration de Math\'ematiques de CentraleSup\'elec, Gif-sur-Yvette, France), Jean Auriol (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France), Islam Boussaada (Universit\'e Paris-Saclay, CNRS, CentraleSup\'elec, Inria, Laboratoire des Signaux et Syst\`emes, Gif-sur-Yvette, France, IPSA Paris, Ivry-sur-Seine, France)</dc:creator>
    </item>
    <item>
      <title>Surrogate-Based Optimization Techniques for Process Systems Engineering</title>
      <link>https://arxiv.org/abs/2412.13948</link>
      <description>arXiv:2412.13948v1 Announce Type: new 
Abstract: Optimization plays an important role in chemical engineering, impacting cost-effectiveness, resource utilization, product quality, and process sustainability metrics. This chapter broadly focuses on data-driven optimization, particularly, on model-based derivative-free techniques, also known as surrogate-based optimization. The chapter introduces readers to the theory and practical considerations of various algorithms, complemented by a performance assessment across multiple dimensions, test functions, and two chemical engineering case studies: a stochastic high-dimensional reactor control study and a low-dimensional constrained stochastic reactor optimization study. This assessment sheds light on each algorithm's performance and suitability for diverse applications. Additionally, each algorithm is accompanied by background information, mathematical foundations, and algorithm descriptions. Among the discussed algorithms are Bayesian Optimization (BO), including state-of-the-art TuRBO, Constrained Optimization by Linear Approximation (COBYLA), the Ensemble Tree Model Optimization Tool (ENTMOOT) which uses decision trees as surrogates, Stable Noisy Optimization by Branch and Fit (SNOBFIT), methods that use radial basis functions such as DYCORS and SRBFStrategy, Constrained Optimization by Quadratic Approximations (COBYQA), as well as a few others recognized for their effectiveness in surrogate-based optimization. By combining theory with practice, this chapter equips readers with the knowledge to integrate surrogate-based optimization techniques into chemical engineering. The overarching aim is to highlight the advantages of surrogate-based optimization, introduce state-of-the-art algorithms, and provide guidance for successful implementation within process systems engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13948v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Mathias Neufang, Emma Pajak, Damien van de Berg, Ye Seol Lee, Ehecatl Antonio del Rio Chanona</dc:creator>
    </item>
    <item>
      <title>Variance-based loss function for improved regularization</title>
      <link>https://arxiv.org/abs/2412.13993</link>
      <description>arXiv:2412.13993v1 Announce Type: new 
Abstract: In deep learning, the mean of a chosen error metric, such as squared or absolute error, is commonly used as a loss function. While effective in reducing the average error, this approach often fails to address localized outliers, leading to significant inaccuracies in regions with sharp gradients or discontinuities. This issue is particularly evident in physics-informed neural networks (PINNs), where such localized errors are expected and affect the overall solution. To overcome this limitation, we propose a novel loss function that combines the mean and the standard deviation of the chosen error metric. By minimizing this combined loss function, the method ensures a more uniform error distribution and reduces the impact of localized high-error regions. The proposed loss function was tested on three problems: Burger's equation, 2D linear elastic solid mechanics, and 2D steady Navier-Stokes, demonstrating improved solution quality and lower maximum errors compared to the standard mean-based loss, using the same number of iterations and weight initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13993v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John M. Hanna, Irene E. Vignon-Clemental</dc:creator>
    </item>
    <item>
      <title>Operator Splitting for Convex Constrained Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2412.14002</link>
      <description>arXiv:2412.14002v1 Announce Type: new 
Abstract: We consider finite Markov decision processes (MDPs) with convex constraints and known dynamics. In principle, this problem is amenable to off-the-shelf convex optimization solvers, but typically this approach suffers from poor scalability. In this work, we develop a first-order algorithm, based on the Douglas-Rachford splitting, that allows us to decompose the dynamics and constraints. Thanks to this decoupling, we can incorporate a wide variety of convex constraints. Our scheme consists of simple and easy-to-implement updates that alternate between solving a regularized MDP and a projection. The inherent presence of regularized updates ensures last-iterate convergence, numerical stability, and, contrary to existing approaches, does not require us to regularize the problem explicitly. If the constraints are not attainable, we exploit salient properties of the Douglas-Rachord algorithm to detect infeasibility and compute a policy that minimally violates the constraints. We demonstrate the performance of our algorithm on two benchmark problems and show that it compares favorably to competing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14002v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis D. Grontas, Anastasios Tsiamis, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Fast FISTA Algorithm With New Backtracking Technique For Multiobjective Optimization</title>
      <link>https://arxiv.org/abs/2412.14007</link>
      <description>arXiv:2412.14007v1 Announce Type: new 
Abstract: This paper proposes a new backtracking strategy based on the FISTA accelerated algorithm for multiobjective optimization problems. The strategy addresses the limitation of existing algorithms that struggle to handle situations where the Lipschitz constant $L(f)$ of the objective function's gradient is still being determined. It mitigates the petite iteration step sizes caused by a significant value of $L(f)$. Furthermore, the proposed strategy effectively avoids the limitation in convergence proofs arising from the non-negativity of the auxiliary sequence $W_k(z):= \min_{i =1,\dotsb,m} [F_i(x_k) - F_i(z)]$, thus providing a theoretical guarantee for its performance. We demonstrate that, under relatively mild assumptions, the algorithm achieves the convergence rate of $O(1/k^2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14007v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengzhi Huang, Jian Chen, Liping Tang</dc:creator>
    </item>
    <item>
      <title>Gauss-Newton Dynamics for Neural Networks: A Riemannian Optimization Perspective</title>
      <link>https://arxiv.org/abs/2412.14031</link>
      <description>arXiv:2412.14031v1 Announce Type: new 
Abstract: We analyze the convergence of Gauss-Newton dynamics for training neural networks with smooth activation functions. In the underparameterized regime, the Gauss-Newton gradient flow induces a Riemannian gradient flow on a low-dimensional, smooth, embedded submanifold of the Euclidean output space. Using tools from Riemannian optimization, we prove \emph{last-iterate} convergence of the Riemannian gradient flow to the optimal in-class predictor at an \emph{exponential rate} that is independent of the conditioning of the Gram matrix, \emph{without} requiring explicit regularization. We further characterize the critical impacts of the neural network scaling factor and the initialization on the convergence behavior. In the overparameterized regime, we show that the Levenberg-Marquardt dynamics with an appropriately chosen damping factor yields robustness to ill-conditioned kernels, analogous to the underparameterized regime. These findings demonstrate the potential of Gauss-Newton methods for efficiently optimizing neural networks, particularly in ill-conditioned problems where kernel and Gram matrices have small singular values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14031v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Causal Invariance Learning via Efficient Optimization of a Nonconvex Objective</title>
      <link>https://arxiv.org/abs/2412.11850</link>
      <description>arXiv:2412.11850v2 Announce Type: cross 
Abstract: Data from multiple environments offer valuable opportunities to uncover causal relationships among variables. Leveraging the assumption that the causal outcome model remains invariant across heterogeneous environments, state-of-the-art methods attempt to identify causal outcome models by learning invariant prediction models and rely on exhaustive searches over all (exponentially many) covariate subsets. These approaches present two major challenges: 1) determining the conditions under which the invariant prediction model aligns with the causal outcome model, and 2) devising computationally efficient causal discovery algorithms that scale polynomially, instead of exponentially, with the number of covariates. To address both challenges, we focus on the additive intervention regime and propose nearly necessary and sufficient conditions for ensuring that the invariant prediction model matches the causal outcome model. Exploiting the essentially necessary identifiability conditions, we introduce Negative Weight Distributionally Robust Optimization (NegDRO), a nonconvex continuous minimax optimization whose global optimizer recovers the causal outcome model. Unlike standard group DRO problems that maximize over the simplex, NegDRO allows negative weights on environment losses, which break the convexity. Despite its nonconvexity, we demonstrate that a standard gradient method converges to the causal outcome model, and we establish the convergence rate with respect to the sample size and the number of iterations. Our algorithm avoids exhaustive search, making it scalable especially when the number of covariates is large. The numerical results further validate the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11850v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenyu Wang, Yifan Hu, Peter B\"uhlmann, Zijian Guo</dc:creator>
    </item>
    <item>
      <title>Stochastic modeling of cyclic cancer treatments under common noise</title>
      <link>https://arxiv.org/abs/2412.13201</link>
      <description>arXiv:2412.13201v1 Announce Type: cross 
Abstract: Path integral control is an effective method in cancer drug treatment, providing a structured approach to handle the complexities and unpredictability of tumor behavior. Utilizing mathematical principles from physics, this technique optimizes drug delivery in environments influenced by randomness. It takes into account the intricate interactions between cancer cells, healthy tissues, and the immune system, as well as factors such as patient-specific characteristics and tumor diversity. Path integral control offers tailored solutions to these issues, enabling the design of drug dosing regimens that enhance therapeutic effectiveness while minimizing side effects. Its flexibility makes it a valuable tool in creating personalized, precision-driven therapies, ultimately improving patient outcomes in cancer treatment. In this paper we give a review about the current status of path integral control in cancer research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13201v1</guid>
      <category>q-bio.TO</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Sonith</dc:creator>
    </item>
    <item>
      <title>On stochastic control problems with higher-order moments</title>
      <link>https://arxiv.org/abs/2412.13521</link>
      <description>arXiv:2412.13521v1 Announce Type: cross 
Abstract: In this paper, we focus on a class of time-inconsistent stochastic control problems, where the objective function includes the mean and several higher-order central moments of the terminal value of state. To tackle the time-inconsistency, we seek both the closed-loop and the open-loop Nash equilibrium controls as time-consistent solutions. We establish a partial differential equation (PDE) system for deriving a closed-loop Nash equilibrium control, which does not include the equilibrium value function and is different from the extended Hamilton-Jacobi-Bellman (HJB) equations as in Bj\"ork et al. (Finance Stoch. 21: 331-360, 2017). We show that our PDE system is equivalent to the extended HJB equations that seems difficult to be solved for our higher-order moment problems. In deriving an open-loop Nash equilibrium control, due to the non-separable higher-order moments in the objective function, we make some moment estimates in addition to the standard perturbation argument for developing a maximum principle. Then, the problem is reduced to solving a flow of forward-backward stochastic differential equations. In particular, we investigate linear controlled dynamics and some objective functions affine in the mean. The closed-loop and the open-loop Nash equilibrium controls are identical, which are independent of the state value, random path and the preference on the odd-order central moments. By sending the highest order of central moments to infinity, we obtain the time-consistent solutions to some control problems whose objective functions include some penalty functions for deviation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13521v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yike Wang, Jinzhen Liu, Alain Bensoussan, Ka-Fai Cedric Yiu, Jiaqin Wei</dc:creator>
    </item>
    <item>
      <title>The networked input-output economic problem</title>
      <link>https://arxiv.org/abs/2412.13564</link>
      <description>arXiv:2412.13564v1 Announce Type: cross 
Abstract: In this paper, we formulate an input-output economic model with multiple interactive economic systems. The model captures the multi-dimensional nature of the economic sectors or industries in each economic system, the interdependencies among industries within an economic system and across different economic systems, and the influence of demand. To determine the equilibrium price structure of the model, a matrix-weighted updating algorithm is proposed. We prove that the equilibrium price structure can be globally asymptotically achieved given that certain joint conditions on the matrix-weighted graph and the input-output matrices are satisfied. The theoretical results are then supported by numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13564v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Hoang Trinh, Nhat-Minh Le-Phan, Hyo-Sung Ahn</dc:creator>
    </item>
    <item>
      <title>New variational arguments regarding the Blaschke-Lebesgue theorem</title>
      <link>https://arxiv.org/abs/2412.13808</link>
      <description>arXiv:2412.13808v1 Announce Type: cross 
Abstract: The sensitivity of the areas of Reuleaux polygons and disk polygons is computed with respect to vertex perturbations. Computations are completed for both constrained and Lagrangian formulations and they imply that the only critical Reuleaux polygons for the area functional are the regular ones. As a consequence, new variational proofs for the Blaschke-Lebesgue and Firey-Sallee theorems are found.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13808v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beniamin Bogosel</dc:creator>
    </item>
    <item>
      <title>A convexity-like structure for polar decomposition with an application to distributed computing</title>
      <link>https://arxiv.org/abs/2412.13990</link>
      <description>arXiv:2412.13990v1 Announce Type: cross 
Abstract: We make a full landscape analysis of the (generally non-convex) orthogonal Procrustes problem. This problem is equivalent with computing the polar factor of a square matrix. We reveal a convexity-like structure, which explains the already established tractability of the problem and show that gradient descent in the orthogonal group computes the polar factor of a square matrix with linear convergence rate if the matrix is invertible and with an algebraic one if the matrix is singular. These results are similar to the ones of Alimisis and Vandereycken (2024) for the symmetric eigenvalue problem. We present an instance of a distributed Procrustes problem, which is hard to deal by standard techniques from numerical linear algebra. Our theory though can provide a solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13990v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Foivos Alimisis, Bart Vandereycken</dc:creator>
    </item>
    <item>
      <title>Neural Combinatorial Optimization for Stochastic Flexible Job Shop Scheduling Problems</title>
      <link>https://arxiv.org/abs/2412.14052</link>
      <description>arXiv:2412.14052v1 Announce Type: cross 
Abstract: Neural combinatorial optimization (NCO) has gained significant attention due to the potential of deep learning to efficiently solve combinatorial optimization problems. NCO has been widely applied to job shop scheduling problems (JSPs) with the current focus predominantly on deterministic problems. In this paper, we propose a novel attention-based scenario processing module (SPM) to extend NCO methods for solving stochastic JSPs. Our approach explicitly incorporates stochastic information by an attention mechanism that captures the embedding of sampled scenarios (i.e., an approximation of stochasticity). Fed with the embedding, the base neural network is intervened by the attended scenarios, which accordingly learns an effective policy under stochasticity. We also propose a training paradigm that works harmoniously with either the expected makespan or Value-at-Risk objective. Results demonstrate that our approach outperforms existing learning and non-learning methods for the flexible JSP problem with stochastic processing times on a variety of instances. In addition, our approach holds significant generalizability to varied numbers of scenarios and disparate distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14052v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor G. Smit, Yaoxin Wu, Pavel Troubil, Yingqian Zhang, Wim P. M. Nuijten</dc:creator>
    </item>
    <item>
      <title>Event-based Photometric Bundle Adjustment</title>
      <link>https://arxiv.org/abs/2412.14111</link>
      <description>arXiv:2412.14111v1 Announce Type: cross 
Abstract: We tackle the problem of bundle adjustment (i.e., simultaneous refinement of camera poses and scene map) for a purely rotating event camera. Starting from first principles, we formulate the problem as a classical non-linear least squares optimization. The photometric error is defined using the event generation model directly in the camera rotations and the semi-dense scene brightness that triggers the events. We leverage the sparsity of event data to design a tractable Levenberg-Marquardt solver that handles the very large number of variables involved. To the best of our knowledge, our method, which we call Event-based Photometric Bundle Adjustment (EPBA), is the first event-only photometric bundle adjustment method that works on the brightness map directly and exploits the space-time characteristics of event data, without having to convert events into image-like representations. Comprehensive experiments on both synthetic and real-world datasets demonstrate EPBA's effectiveness in decreasing the photometric error (by up to 90%), yielding results of unparalleled quality. The refined maps reveal details that were hidden using prior state-of-the-art rotation-only estimation methods. The experiments on modern high-resolution event cameras show the applicability of EPBA to panoramic imaging in various scenarios (without map initialization, at multiple resolutions, and in combination with other methods, such as IMU dead reckoning or previous event-based rotation estimation methods). We make the source code publicly available. https://github.com/tub-rip/epba</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14111v1</guid>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuang Guo, Guillermo Gallego</dc:creator>
    </item>
    <item>
      <title>(Corrected Version) Push-LSVRG-UP: Distributed Stochastic Optimization over Unbalanced Directed Networks with Uncoordinated Triggered Probabilities</title>
      <link>https://arxiv.org/abs/2305.09181</link>
      <description>arXiv:2305.09181v5 Announce Type: replace 
Abstract: Distributed stochastic optimization, arising in the crossing and integration of traditional stochastic optimization, distributed computing and storage, and network science, has advantages of high efficiency and a low per-iteration computational complexity in resolving large-scale optimization problems. This paper concentrates on resolving a large-scale convex finite-sum optimization problem in a multi-agent system over unbalanced directed networks. To tackle this problem in an efficient way, a distributed consensus optimization algorithm, adopting the push-sum technique and a distributed loopless stochastic variance-reduced gradient (LSVRG) method with uncoordinated triggered probabilities, is developed and named Push-LSVRG-UP. Each agent under this algorithmic framework performs only local computation and communicates only with its neighbors without leaking their private information. The convergence analysis of Push-LSVRG-UP is relied on analyzing the contraction relationships between four error terms associated with the multi-agent system. Theoretical results provide an explicit feasible range of the constant step-size, a linear convergence rate, and an iteration complexity of Push-LSVRG-UP when achieving the globally optimal solution. It is shown that Push-LSVRG-UP achieves the superior characteristics of accelerated linear convergence, fewer storage costs, and a lower per-iteration computational complexity than most existing works. Meanwhile, the introduction of an uncoordinated probabilistic triggered mechanism allows Push-LSVRG-UP to facilitate the independence and flexibility of agents in computing local batch gradients. In simulations, the practicability and improved performance of Push-LSVRG-UP are manifested via resolving two distributed learning problems based on real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09181v5</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TNSE.2022.3225229</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Network Science and Engineering, VOL. 10, NO. 2, 2023, PP. 934-950</arxiv:journal_reference>
      <dc:creator>Jinhui Hu, Guo Chen, Huaqing Li, Zixiang Shen, Weidong Zhang</dc:creator>
    </item>
    <item>
      <title>Metric Entropy-Free Sample Complexity Bounds for Sample Average Approximation in Convex Stochastic Programming</title>
      <link>https://arxiv.org/abs/2401.00664</link>
      <description>arXiv:2401.00664v5 Announce Type: replace 
Abstract: This paper studies sample average approximation (SAA) in solving convex or strongly convex stochastic programming (SP) problems. Under some common regularity conditions, we show -- perhaps for the first time -- that SAA's sample complexity can be completely free from any quantification of metric entropy (such as the logarithm of the covering number), leading to a significantly more efficient rate with dimensionality $d$ than most existing results. From the newly established complexity bounds, an important revelation is that SAA and the canonical stochastic mirror descent (SMD) method, two mainstream solution approaches to SP, entail almost identical rates of sample efficiency, lifting a theoretical discrepancy of SAA from SMD by the order of $O(d)$. Furthermore, this paper explores non-Lipschitzian scenarios where SAA maintains provable efficacy but the corresponding results for SMD remain mostly unexplored, indicating the potential of SAA's better applicability in some irregular settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00664v5</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongcheng Liu, Jindong Tong</dc:creator>
    </item>
    <item>
      <title>Stochastic linear quadratic optimal control problems with regime-switching jumps in infinite horizon</title>
      <link>https://arxiv.org/abs/2403.00288</link>
      <description>arXiv:2403.00288v3 Announce Type: replace 
Abstract: This paper investigates a stochastic linear-quadratic (SLQ, for short) control problem regulated by a time-invariant Markov chain in infinite horizon. Under the $L^2$-stability framework, we study a class of linear backward stochastic differential equations (BSDE, for short) in infinite horizon and discuss the open-loop and closed-loop solvabilities of the SLQ problem. The open-loop solvability is characterized by the solvability of a system of coupled forward-backward stochastic differential equations (FBSDEs, for short) in infinite horizon and the convexity of the cost functional, and the closed-loop solvability is shown to be equivalent to the open-loop solvability, which in turn is equivalent to the existence of a static stabilizing solution to the associated constrained coupled algebra Riccati equations (CAREs, for short). Under the uniform convexity assumption, we obtain the unique solvability of associated CAREs and construct the corresponding closed-loop optimal strategy. Finally, we also solve a class of discounted SLQ problems and give two concrete examples to illustrate the results developed in the earlier sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00288v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu, Xun Li, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>The link between $1$-norm approximation and effective Positivstellensatze for the hypercube</title>
      <link>https://arxiv.org/abs/2404.04190</link>
      <description>arXiv:2404.04190v2 Announce Type: replace 
Abstract: The Schm\"udgen's Positivstellensatz gives a certificate to verify positivity of a strictly positive polynomial $f$ on a compact, basic, semi-algebraic set $\mathbf{K} \subset \mathbb{R}^n$. A Positivstellensatz of this type is called effective if one may bound the degrees of the polynomials appearing in the certificate in terms of properties of $f$. If $\mathbf{K} = [-1,1]^n$ and $0 &lt; f_\min := \min_{x \in \mathbf{K}} f(x)$, then the degrees of the polynomials appearing in the certificate may be bounded by $O\left(\sqrt{\frac{f_\max - f_\min}{f_\min}}\right)$, where $f_\max := \max_{x \in \mathbf{K}} f(x)$, as was recently shown by Laurent and Slot [Optimization Letters 17:515-530, 2023]. The big-O notation suppresses dependence on $n$ and the degree $d$ of $f$. In this paper we show a similar result, but with a better dependence on $n$ and $d$. In particular, our bounds depend on the $1$-norm of the coefficients of $f$, that may readily be calculated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04190v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Etienne de Klerk, Juan Vera Lizcano</dc:creator>
    </item>
    <item>
      <title>Distributed Model Predictive Control for Piecewise Affine Systems Based on Switching ADMM</title>
      <link>https://arxiv.org/abs/2404.16712</link>
      <description>arXiv:2404.16712v3 Announce Type: replace 
Abstract: This paper presents a novel approach for distributed model predictive control (MPC) for piecewise affine (PWA) systems. Existing approaches rely on solving mixed-integer optimization problems, requiring significant computation power or time. We propose a distributed MPC scheme that requires solving only convex optimization problems. The key contribution is a novel method, based on the alternating direction method of multipliers, for solving the non-convex optimal control problem that arises due to the PWA dynamics. We present a distributed MPC scheme, leveraging this method, that explicitly accounts for the coupling between subsystems by reaching agreement on the values of coupled states. Stability and recursive feasibility are shown under additional assumptions on the underlying system. Two numerical examples are provided, in which the proposed controller is shown to significantly improve the CPU time and closed-loop performance over existing state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16712v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Mallick, Azita Dabiri, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>Duality-based single-level reformulations of bilevel optimization problems</title>
      <link>https://arxiv.org/abs/2405.07672</link>
      <description>arXiv:2405.07672v2 Announce Type: replace 
Abstract: Usually, bilevel optimization problems need to be transformed into single-level ones in order to derive optimality conditions and solution algorithms. Among the available approaches, the replacement of the lower-level problem by means of duality relations became popular quite recently. We revisit three realizations of this idea which are based on the lower-level Lagrange, Wolfe, and Mond--Weir dual problem. The resulting single-level surrogate problems are equivalent to the original bilevel optimization problem from the viewpoint of global minimizers under mild assumptions. However, all these reformulations suffer from the appearance of so-called implicit variables, i.e., surrogate variables which do not enter the objective function but appear in the feasible set for modeling purposes. Treating implicit variables as explicit ones has been shown to be problematic when locally optimal solutions, stationary points, and applicable constraint qualifications are compared to the original problem. Indeed, we illustrate that the same difficulties have to be faced when using these duality-based reformulations. Furthermore, we show that the Mangasarian-Fromovitz constraint qualification is likely to be violated at each feasible point of these reformulations, contrasting assertions in some recently published papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07672v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stephan Dempe, Patrick Mehlitz</dc:creator>
    </item>
    <item>
      <title>Least multivariate Chebyshev polynomials on diagonally determined domains</title>
      <link>https://arxiv.org/abs/2405.19219</link>
      <description>arXiv:2405.19219v2 Announce Type: replace 
Abstract: We consider a new multivariate generalization of the classical monic (univariate) Chebyshev polynomial that minimizes the uniform norm on the interval $[-1,1]$. Let $\Pi^*_n$ be the subset of polynomials of degree at most $n$ in $d$ variables, whose homogeneous part of degree $n$ has coefficients summing up to $1$. The problem is determining a polynomial in $\Pi^*_n$ with the smallest uniform norm on a domain $\Omega$, which we call a least Chebyshev polynomial (associated with $\Omega$). Our main result solves the problem for $\Omega$ belonging to a non-trivial class of domains that we call diagonally-determined, and establishes the remarkable result that a least Chebyshev polynomial can be given via the classical, univariate, Chebyshev polynomial. In particular, the solution can be independent of the dimension. Diagonally-determined domains include centered balls in $\mathbb{R}^d$ in any norm, but can be non-convex and highly irregular. We also introduce a computational procedure, based on semidefinite programming hierarchies, to detect if a given semi-algebraic set is diagonally-determined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19219v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mareike Dressler, Simon Foucart, Mioara Joldes, Etienne de Klerk, Jean-Bernard Lasserre, Yuan Xu</dc:creator>
    </item>
    <item>
      <title>Local SGD for Near-Quadratic Problems: Improving Convergence under Unconstrained Noise Conditions</title>
      <link>https://arxiv.org/abs/2409.10478</link>
      <description>arXiv:2409.10478v2 Announce Type: replace 
Abstract: Distributed optimization plays an important role in modern large-scale machine learning and data processing systems by optimizing the utilization of computational resources. One of the classical and popular approaches is Local Stochastic Gradient Descent (Local SGD), characterized by multiple local updates before averaging, which is particularly useful in distributed environments to reduce communication bottlenecks and improve scalability. A typical feature of this method is the dependence on the frequency of communications. But in the case of a quadratic target function with homogeneous data distribution over all devices, the influence of frequency of communications vanishes. As a natural consequence, subsequent studies include the assumption of a Lipschitz Hessian, as this indicates the similarity of the optimized function to a quadratic one to some extent. However, in order to extend the completeness of the Local SGD theory and unlock its potential, in this paper we abandon the Lipschitz Hessian assumption by introducing a new concept of $\textit{approximate quadraticity}$. This assumption gives a new perspective on problems that have near quadratic properties. In addition, existing theoretical analyses of Local SGD often assume bounded variance. We, in turn, consider the unbounded noise condition, which allows us to broaden the class of studied problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10478v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4213/rm10207</arxiv:DOI>
      <dc:creator>Andrey Sadchikov, Savelii Chezhegov, Aleksandr Beznosikov, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>Lipschitz-free Projected Subgradient Method with Time-varying Step-size</title>
      <link>https://arxiv.org/abs/2410.22336</link>
      <description>arXiv:2410.22336v2 Announce Type: replace 
Abstract: We introduce a novel family of time-varying step-sizes for the classical projected subgradient method, offering optimal ergodic convergence. Importantly, this approach does not depend on the Lipschitz assumption of the objective function, thereby broadening the convergence result of projected subgradient method to non-Lipschitz case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22336v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yong Xia, Yanhao Zhang, Zhihan Zhu</dc:creator>
    </item>
    <item>
      <title>Analytical Pursuit-Evasion Game Strategy in Arbitrary Keplerian Reference Orbits</title>
      <link>https://arxiv.org/abs/2411.15912</link>
      <description>arXiv:2411.15912v2 Announce Type: replace 
Abstract: This paper develops an analytical strategy for solving the linear quadratic pursuit-evasion game in arbitrary Keplerian reference orbits. The motion of the pursuer and evader is described using the controlled Tschauner-Hempel equations, and the optimal game strategies of the pursuer and evader are presented by the solution of the differential Riccati equation.The analytical solution of the differential Riccati equation is presented for elliptic, parabolic, and hyperbolic reference orbits, thereby enabling an analytical pursuit-evasion game strategy. Then, the procedure to solve the pursuit-evasion game using this analytical strategy is proposed. Simulations of pursuit-evasion game in elliptic, parabolic, and hyperbolic reference orbits validate the effectiveness of the developed analytical strategy. Results indicates that the analytical strategy saves the CPU time by more than 99.8$\%$ compared to the numerical one, highlighting the efficiency of the developed strategy. The developed analytical strategy is also applicable to pursuit-evasion game scenarios considering orbital disturbances. Compared to the conventional strategy, which succeed in only two out of six test scenarios, the developed strategy achieves success in all six cases, particularly demonstrating its effectiveness in high-eccentricity cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15912v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuyue Fu, Shengping Gong, Peng Shi</dc:creator>
    </item>
    <item>
      <title>Improved conditional gradient method for the generalized cone order optimization problem on the local sphere</title>
      <link>https://arxiv.org/abs/2412.12899</link>
      <description>arXiv:2412.12899v2 Announce Type: replace 
Abstract: In this paper, a generalized optimization problem on the local sphere is established by the cone order relation on the tangent space, and solved by an improved conditional gradient method (for short, ICGM). The auxiliary subproblems are constructed by the directed distance function on the tangent space, the iteration step size is updated by the Armijo rule, and the convergence of the ICGM is proved without the convexity of the objective function. Under the assumption of convexity, the clusters of the sequence generated by the ICGM are proved to be the spherical weakly Pareto solutions (also known as weakly efficient solutions) of this problem .</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12899v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li-wen Zhou, Min Tang, Ya-ling Yi, Yao-Jia Zhang</dc:creator>
    </item>
    <item>
      <title>Learning Dynamic Mechanisms in Unknown Environments: A Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2202.12797</link>
      <description>arXiv:2202.12797v3 Announce Type: replace-cross 
Abstract: Dynamic mechanism design studies how mechanism designers should allocate resources among agents in a time-varying environment. We consider the problem where the agents interact with the mechanism designer according to an unknown Markov Decision Process (MDP), where agent rewards and the mechanism designer's state evolve according to an episodic MDP with unknown reward functions and transition kernels. We focus on the online setting with linear function approximation and propose novel learning algorithms to recover the dynamic Vickrey-Clarke-Grove (VCG) mechanism over multiple rounds of interaction. A key contribution of our approach is incorporating reward-free online Reinforcement Learning (RL) to aid exploration over a rich policy space to estimate prices in the dynamic VCG mechanism. We show that the regret of our proposed method is upper bounded by $\tilde{\mathcal{O}}(T^{2/3})$ and further devise a lower bound to show that our algorithm is efficient, incurring the same $\Omega(T^{2 / 3})$ regret as the lower bound, where $T$ is the total number of rounds. Our work establishes the regret guarantee for online RL in solving dynamic mechanism design problems without prior knowledge of the underlying model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.12797v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Qiu, Boxiang Lyu, Qinglin Meng, Zhaoran Wang, Zhuoran Yang, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Regularity and Optimal Control of Non Local Cahn Hilliard Brinkman system with Singular Potential</title>
      <link>https://arxiv.org/abs/2311.05008</link>
      <description>arXiv:2311.05008v2 Announce Type: replace-cross 
Abstract: The evolution of two incompressible, immiscible, isothermal fluids in a bounded domain and a porous media is described by the coupled Cahn-Hilliard-Brinkman (CHB) system. The CHB system consists of the Cahn-Hilliard equation describing the dynamics of the relative concentration of fluids and the Brinkman equation for velocity. This work addresses the optimal control problem for a two-dimensional nonlocal CHB system with a singular-type potential. The existence and regularity results are obtained by approximating the singular potential by a sequence of regular potentials and introducing a sequence of mobility terms to resolve the blow-up due to the singularity of the potential. Further, we prove the existence of a strong solution under higher regularity assumptions on the initial data and the uniqueness of the solution using the weak-strong uniqueness technique. By considering the external forcing term in the velocity equation as a control, we prove the existence of an optimal control for a tracking type cost functional. The differentiability properties of the control-to-state operator are studied to establish the first-order necessary optimality conditions. Moreover, the optimal control is characterised in terms of the adjoint variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05008v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheetal Dharmatti, Greeshma K</dc:creator>
    </item>
    <item>
      <title>A Guide to Stochastic Optimisation for Large-Scale Inverse Problems</title>
      <link>https://arxiv.org/abs/2406.06342</link>
      <description>arXiv:2406.06342v3 Announce Type: replace-cross 
Abstract: Stochastic optimisation algorithms are the de facto standard for machine learning with large amounts of data. Handling only a subset of available data in each optimisation step dramatically reduces the per-iteration computational costs, while still ensuring significant progress towards the solution. Driven by the need to solve large-scale optimisation problems as efficiently as possible, the last decade has witnessed an explosion of research in this area. Leveraging the parallels between machine learning and inverse problems has allowed harnessing the power of this research wave for solving inverse problems. In this survey, we provide a comprehensive account of the state-of-the-art in stochastic optimisation from the viewpoint of variational regularisation for inverse problems where the solution is modelled as minimising an objective function. We present algorithms with diverse modalities of problem randomisation and discuss the roles of variance reduction, acceleration, higher-order methods, and other algorithmic modifications, and compare theoretical results with practical behaviour. We focus on the potential and the challenges for stochastic optimisation that are unique to variational regularisation for inverse imaging problems and are not commonly encountered in machine learning. We conclude the survey with illustrative examples from imaging on linear inverse problems to examine the advantages and disadvantages that this new generation of algorithms bring to the field of inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06342v3</guid>
      <category>math.NA</category>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias J. Ehrhardt, Zeljko Kereta, Jingwei Liang, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Semi-on-Demand Off-Peak Transit Services with Shared Autonomous Vehicles -- Service Planning, Simulation, and Analysis in Munich, Germany</title>
      <link>https://arxiv.org/abs/2408.10547</link>
      <description>arXiv:2408.10547v2 Announce Type: replace-cross 
Abstract: This study investigates the implementation of semi-on-demand (SoD) hybrid-route services using Shared Autonomous Vehicles (SAVs) on existing transit lines. SoD services combine the cost efficiency of fixed-route buses with the flexibility of on-demand services. SAVs first serve all scheduled fixed-route stops, then drop off and pick up passengers in the pre-determined flexible-route portion, and return to the fixed route. This study addresses four key questions: optimal fleet and vehicle sizes for peak-hour fixed-route services with SAVs and during transition (from drivers to autonomous vehicles), optimal off-peak SoD service planning, and suitable use cases. The methodology combines analytical modeling for service planning with agent-based simulation for operational analysis. We examine ten bus routes in Munich, Germany, considering full SAV and transition scenarios with varying proportions of drivers. Our findings demonstrate that the lower operating costs of SAVs improve service quality through increased frequency and smaller vehicles, even in transition scenarios. The reduced headway lowers waiting time and also favors more flexible-route operation in SoD services. The optimal SoD settings range from fully flexible to hybrid routes, where higher occupancy from the terminus favors shorter flexible routes. During the transition phase, limited fleet size and higher headways constrain the benefits of flexible-route operations. The simulation results corroborate the SoD benefits of door-to-door convenience, attracting more passengers without excessive detours and operator costs at moderate flexible-route lengths, and validate the analytical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10547v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Roman Engelhardt, Florian Dandl, Vasileios Volakakis, Hani S. Mahmassani, Klaus Bogenberger</dc:creator>
    </item>
    <item>
      <title>Optimal Rates for Robust Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2412.11003</link>
      <description>arXiv:2412.11003v2 Announce Type: replace-cross 
Abstract: Machine learning algorithms in high-dimensional settings are highly susceptible to the influence of even a small fraction of structured outliers, making robust optimization techniques essential. In particular, within the $\epsilon$-contamination model, where an adversary can inspect and replace up to an $\epsilon$-fraction of the samples, a fundamental open problem is determining the optimal rates for robust stochastic convex optimization (SCO) under such contamination. We develop novel algorithms that achieve minimax-optimal excess risk (up to logarithmic factors) under the $\epsilon$-contamination model. Our approach improves over existing algorithms, which are not only suboptimal but also require stringent assumptions, including Lipschitz continuity and smoothness of individual sample functions. By contrast, our optimal algorithms do not require these restrictive assumptions, and can handle nonsmooth but Lipschitz population loss functions. We complement our algorithmic developments with a tight lower bound for robust SCO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11003v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changyu Gao, Andrew Lowy, Xingyu Zhou, Stephen J. Wright</dc:creator>
    </item>
  </channel>
</rss>
