<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 01:57:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Constrained Bayesian Optimization under Bivariate Gaussian Process with Application to Cure Process Optimization</title>
      <link>https://arxiv.org/abs/2506.00174</link>
      <description>arXiv:2506.00174v1 Announce Type: new 
Abstract: Bayesian Optimization, leveraging Gaussian process models, has proven to be a powerful tool for minimizing expensive-to-evaluate objective functions by efficiently exploring the search space. Extensions such as constrained Bayesian Optimization have further enhanced Bayesian Optimization's utility in practical scenarios by focusing the search within feasible regions defined by a black-box constraint function. However, constrained Bayesian Optimization in is developed based on the independence Gaussian processes assumption between objective and constraint functions, which may not hold in real-world applications. To address this issue, we use the bivariate Gaussian process model to characterize the dependence between the objective and constraint functions and developed the constrained expected improvement acquisition function under this model assumption. We show case the performance of the proposed approach with an application to cure process optimization in Manufacturing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00174v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yezhuo Li, Qiong Zhang, Madhura Limaye, Gang Li</dc:creator>
    </item>
    <item>
      <title>A Semiparametric Stochastic Volatility Model with Dependent Errors</title>
      <link>https://arxiv.org/abs/2506.01094</link>
      <description>arXiv:2506.01094v1 Announce Type: new 
Abstract: This paper proposes a semiparametric stochastic volatility (SV) model that relaxes the restrictive Gaussian assumption in both the return and volatility error terms, allowing them to follow flexible, nonparametric distributions with potential dependence. By integrating this framework into a Bayesian Markov Chain Monte Carlo (MCMC) approach, the model effectively captures the heavy tails, skewness, and other complex features often observed in financial return data. Simulation studies under correlated Gaussian and Student's t error settings demonstrate that the proposed method achieves lower bias and variance when estimating model parameters and volatility compared to traditional Gaussian-based and popular Bayesian implementations. We conduct an empirical application to the real world financial data, which further underscores the model's practical advantages: it provides volatility estimates that respond more accurately to large fluctuations, reflecting real-world market behavior. These findings suggest that the introduced semiparametric SV framework offers a more robust and adaptable tool for financial econometrics, particularly in scenarios characterized by non-Gaussian and dependent return dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01094v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Feng, Ashis Gangopadhyay</dc:creator>
    </item>
    <item>
      <title>Riemannian Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2506.00226</link>
      <description>arXiv:2506.00226v1 Announce Type: cross 
Abstract: This paper proposes an innovative extension of Principal Component Analysis (PCA) that transcends the traditional assumption of data lying in Euclidean space, enabling its application to data on Riemannian manifolds. The primary challenge addressed is the lack of vector space operations on such manifolds. Fletcher et al., in their work {\em Principal Geodesic Analysis for the Study of Nonlinear Statistics of Shape}, proposed Principal Geodesic Analysis (PGA) as a geometric approach to analyze data on Riemannian manifolds, particularly effective for structured datasets like medical images, where the manifold's intrinsic structure is apparent. However, PGA's applicability is limited when dealing with general datasets that lack an implicit local distance notion. In this work, we introduce a generalized framework, termed {\em Riemannian Principal Component Analysis (R-PCA)}, to extend PGA for any data endowed with a local distance structure. Specifically, we adapt the PCA methodology to Riemannian manifolds by equipping data tables with local metrics, enabling the incorporation of manifold geometry. This framework provides a unified approach for dimensionality reduction and statistical analysis directly on manifolds, opening new possibilities for datasets with region-specific or part-specific distance notions, ensuring respect for their intrinsic geometric properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00226v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Oldemar Rodr\'iguez</dc:creator>
    </item>
    <item>
      <title>Building nonstationary extreme value model using L-moments</title>
      <link>https://arxiv.org/abs/2506.00977</link>
      <description>arXiv:2506.00977v1 Announce Type: cross 
Abstract: The maximum likelihood estimation for a time-dependent nonstationary (NS) extreme value model is often too sensitive to influential observations, such as large values toward the end of a sample. Thus, alternative methods using L-moments have been developed in NS models to address this problem while retaining the advantages of the stationary L-moment method. However, one method using L-moments displays inferior performance compared to stationary estimation when the data exhibit a positive trend in variance. To address this problem, we propose a new algorithm for efficiently estimating the NS parameters. The proposed method combines L-moments and robust regression, using standardized residuals. A simulation study demonstrates that the proposed method overcomes the mentioned problem. The comparison is conducted using conventional and redefined return level estimates. An application to peak streamflow data in Trehafod in the UK illustrates the usefulness of the proposed method. Additionally, we extend the proposed method to a NS extreme value model in which physical covariates are employed as predictors. Furthermore, we consider a model selection criterion based on the cross-validated generalized L-moment distance as an alternative to the likelihood-based criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00977v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s42952-025-00325-3</arxiv:DOI>
      <arxiv:journal_reference>Journal of the Korean Statistical Society, 2025</arxiv:journal_reference>
      <dc:creator>Yire Shin, Yonggwan Shin, Jeong-Soo Park</dc:creator>
    </item>
    <item>
      <title>Learning to optimize convex risk measures: The cases of utility-based shortfall risk and optimized certainty equivalent risk</title>
      <link>https://arxiv.org/abs/2506.01101</link>
      <description>arXiv:2506.01101v1 Announce Type: cross 
Abstract: We consider the problems of estimation and optimization of two popular convex risk measures: utility-based shortfall risk (UBSR) and Optimized Certainty Equivalent (OCE) risk. We extend these risk measures to cover possibly unbounded random variables. We cover prominent risk measures like the entropic risk, expectile risk, monotone mean-variance risk, Value-at-Risk, and Conditional Value-at-Risk as few special cases of either the UBSR or the OCE risk. In the context of estimation, we derive non-asymptotic bounds on the mean absolute error (MAE) and mean-squared error (MSE) of the classical sample average approximation (SAA) estimators of both, the UBSR and the OCE. Next, in the context of optimization, we derive expressions for the UBSR gradient and the OCE gradient under a smooth parameterization. Utilizing these expressions, we propose gradient estimators for both, the UBSR and the OCE. We use the SAA estimator of UBSR in both these gradient estimators, and derive non-asymptotic bounds on MAE and MSE for the proposed gradient estimation schemes. We incorporate the aforementioned gradient estimators into a stochastic gradient (SG) algorithm for optimization. Finally, we derive non-asymptotic bounds that quantify the rate of convergence of our SG algorithm for the optimization of the UBSR and the OCE risk measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01101v1</guid>
      <category>cs.CE</category>
      <category>q-fin.MF</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumedh Gupte, Prashanth L. A., Sanjay P. Bhat</dc:creator>
    </item>
    <item>
      <title>Large Bayesian VARs for Binary and Censored Variables</title>
      <link>https://arxiv.org/abs/2506.01422</link>
      <description>arXiv:2506.01422v1 Announce Type: cross 
Abstract: We extend the standard VAR to jointly model the dynamics of binary, censored and continuous variables, and develop an efficient estimation approach that scales well to high-dimensional settings. In an out-of-sample forecasting exercise, we show that the proposed VARs forecast recessions and short-term interest rates well. We demonstrate the utility of the proposed framework using a wide rage of empirical applications, including conditional forecasting and a structural analysis that examines the dynamic effects of a financial shock on recession probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01422v1</guid>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua C. C. Chan, Michael Pfarrhofer</dc:creator>
    </item>
    <item>
      <title>Simulating Complex Crossectional and Longitudinal Data using the simDAG R Package</title>
      <link>https://arxiv.org/abs/2506.01498</link>
      <description>arXiv:2506.01498v1 Announce Type: cross 
Abstract: Generating artificial data is a crucial step when performing Monte-Carlo simulation studies. Depending on the planned study, complex data generation processes (DGP) containing multiple, possibly time-varying, variables with various forms of dependencies and data types may be required. Simulating data from such DGP may therefore become a difficult and time-consuming endeavor. The simDAG R package offers a standardized approach to generate data from simple and complex DGP based on the definition of structural equations in directed acyclic graphs using arbitrary functions or regression models. The package offers a clear syntax with an enhanced formula interface and directly supports generating binary, categorical, count and time-to-event data with arbitrary dependencies, possibly non-linear relationships and interactions. It additionally includes a framework to conduct discrete-time based simulations which allows the generation of longitudinal data on a semi-continuous time-scale. This approach may be used to generate time-to-event data with both recurrent or competing events and possibly multiple time-varying covariates, which may themselves have arbitrary data types. In this article we demonstrate the vast amount of features included in simDAG by replicating the DGP of multiple real Monte-Carlo simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01498v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Denz, Nina Timmesfeld</dc:creator>
    </item>
    <item>
      <title>Machine-Learned Sampling of Conditioned Path Measures</title>
      <link>https://arxiv.org/abs/2506.01904</link>
      <description>arXiv:2506.01904v1 Announce Type: cross 
Abstract: We propose algorithms for sampling from posterior path measures $P(C([0, T], \mathbb{R}^d))$ under a general prior process. This leverages ideas from (1) controlled equilibrium dynamics, which gradually transport between two path measures, and (2) optimization in $\infty$-dimensional probability space endowed with a Wasserstein metric, which can be used to evolve a density curve under the specified likelihood. The resulting algorithms are theoretically grounded and can be integrated seamlessly with neural networks for learning the target trajectory ensembles, without access to data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01904v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qijia Jiang, Reuben Cohn-Gordon</dc:creator>
    </item>
    <item>
      <title>A Randomized Exchange Algorithm for Optimal Design of Multi-Response Experiments</title>
      <link>https://arxiv.org/abs/2407.16283</link>
      <description>arXiv:2407.16283v2 Announce Type: replace 
Abstract: Despite the increasing prevalence of vector observations, computation of optimal experimental design for multi-response models has received limited attention. To address this problem within the framework of approximate designs, we introduce mREX, an algorithm that generalizes the randomized exchange algorithm REX (J Am Stat Assoc 115:529, 2020), originally specialized for single-response models. The mREX algorithm incorporates several improvements: a novel method for computing efficient sparse initial designs, an extension to all differentiable Kiefer's optimality criteria, and an efficient method for performing optimal exchanges of weights. For the most commonly used D-optimality criterion, we propose a technique for optimal weight exchanges based on the characteristic matrix polynomial. The mREX algorithm is applicable to linear, nonlinear, and generalized linear models, and scales well to large problems. It typically converges to optimal designs faster than available alternative methods, although it does not require advanced mathematical programming solvers. We demonstrate the usefulness of mREX to bivariate dose-response Emax models for clinical trials, both without and with the inclusion of covariates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16283v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'al Somogyi, Samuel Rosa, Radoslav Harman</dc:creator>
    </item>
    <item>
      <title>Particle Gibbs without the Gibbs bit</title>
      <link>https://arxiv.org/abs/2505.04611</link>
      <description>arXiv:2505.04611v4 Announce Type: replace 
Abstract: Exact parameter and trajectory inference in state-space models is typically achieved by one of two methods: particle marginal Metropolis-Hastings (PMMH) or particle Gibbs (PGibbs). PMMH is a pseudo-marginal algorithm which jointly proposes a new trajectory and parameter, and accepts or rejects both at once. PGibbs instead alternates between sampling from the trajectory, using an algorithm known as conditional sequential Monte Carlo (CSMC) and the parameter in a Hastings-within-Gibbs fashion. While particle independent Metropolis Hastings (PIMH), the parameter-free version of PMMH, is known to be statistically worse than CSMC, PGibbs can induce a slow mixing if the parameter and the state trajectory are very correlated. This has made PMMH the method of choice for many practitioners, despite theory and experiments favouring CSMC over PIMH for the parameter-free problem. In this article, we describe a formulation of PGibbs which bypasses the Gibbs step, essentially marginalizing over the trajectory distribution in a fashion similar to PMMH. This is achieved by considering the implementation of a CSMC algortihm for the state-space model integrated over the joint distribution of the current parameter and the parameter proposal. We illustrate the benefits of method on a simple example known to be challenging for PMMH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04611v4</guid>
      <category>stat.CO</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrien Corenflos</dc:creator>
    </item>
    <item>
      <title>Bayesian Geostatistics Using Predictive Stacking</title>
      <link>https://arxiv.org/abs/2304.12414</link>
      <description>arXiv:2304.12414v3 Announce Type: replace-cross 
Abstract: We develop Bayesian predictive stacking for geostatistical models, where the primary inferential objective is to provide inference on the latent spatial random field and conduct spatial predictions at arbitrary locations. We exploit analytically tractable posterior distributions for regression coefficients of predictors and the realizations of the spatial process conditional upon process parameters. We subsequently combine such inference by stacking these models across the range of values of the hyper-parameters. We devise stacking of means and posterior densities in a manner that is computationally efficient without resorting to iterative algorithms such as Markov chain Monte Carlo (MCMC) and can exploit the benefits of parallel computations. We offer novel theoretical insights into the resulting inference within an infill asymptotic paradigm and through empirical results showing that stacked inference is comparable to full sampling-based Bayesian inference at a significantly lower computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12414v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Zhang, Wenpin Tang, Sudipto Banerjee</dc:creator>
    </item>
    <item>
      <title>Gradient-Free Score-Based Sampling Methods with Ensembles</title>
      <link>https://arxiv.org/abs/2401.17539</link>
      <description>arXiv:2401.17539v2 Announce Type: replace-cross 
Abstract: Recent developments in generative modeling have utilized score-based methods coupled with stochastic differential equations to sample from complex probability distributions. However, these and other performant sampling methods generally require gradients of the target probability distribution, which can be unavailable or computationally prohibitive in many scientific and engineering applications. Here, we introduce ensembles within score-based sampling methods to develop gradient-free approximate sampling techniques that leverage the collective dynamics of particle ensembles to compute approximate reverse diffusion drifts. We introduce the underlying methodology, emphasizing its relationship with generative diffusion models and the previously introduced F\"ollmer sampler. We demonstrate the efficacy of the ensemble strategies through various examples, ranging from low- to medium-dimensionality sampling problems, including multi-modal and highly non-Gaussian probability distributions, and provide comparisons to traditional methods like the No-U-Turn Sampler. Additionally, we showcase these strategies in the context of a high-dimensional Bayesian inversion problem within the geophysical sciences. Our findings highlight the potential of ensemble strategies for modeling complex probability distributions in situations where gradients are unavailable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17539v2</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apm.2025.116224</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematical Modelling (2025), 147,</arxiv:journal_reference>
      <dc:creator>Bryan Riel, Tobias Bischoff</dc:creator>
    </item>
    <item>
      <title>Bayesian Inference for Spatial-Temporal Non-Gaussian Data Using Predictive Stacking</title>
      <link>https://arxiv.org/abs/2406.04655</link>
      <description>arXiv:2406.04655v3 Announce Type: replace-cross 
Abstract: Analysing non-Gaussian spatial-temporal data requires introducing spatial dependence in generalised linear models through the link function of an exponential family distribution. Unlike in Gaussian likelihoods, inference is considerably encumbered by the inability to analytically integrate out the random effects and reduce the dimension of the parameter space. Iterative estimation algorithms struggle to converge due to the presence of weakly identified parameters. We devise Bayesian inference using predictive stacking that assimilates inference from analytically tractable conditional posterior distributions. We achieve this by expanding upon the Diaconis-Ylvisaker family of conjugate priors and exploiting generalised conjugate multivariate (GCM) distribution theory for exponential families, which enables exact sampling from analytically available posterior distributions conditional upon some process parameters. Subsequently, we assimilate inference over a range of values of these parameters using Bayesian predictive stacking. We evaluate inferential performance on simulated data, compare with full Bayesian inference using Markov chain Monte Carlo (MCMC) and apply our method to analyse spatially-temporally referenced avian count data from the North American Breeding Bird Survey database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04655v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soumyakanti Pan, Lu Zhang, Jonathan R. Bradley, Sudipto Banerjee</dc:creator>
    </item>
    <item>
      <title>Approximations to worst-case data dropping: unmasking failure modes</title>
      <link>https://arxiv.org/abs/2408.09008</link>
      <description>arXiv:2408.09008v5 Announce Type: replace-cross 
Abstract: A data analyst might worry about generalization if dropping a very small fraction of data points from a study could change its substantive conclusions. Checking this non-robustness directly poses a combinatorial optimization problem and is intractable even for simple models and moderate data sizes. Recently various authors have proposed a diverse set of approximations to detect this non-robustness. In the present work, we show that, even in a setting as simple as ordinary least squares (OLS) linear regression, many of these approximations can fail to detect (true) non-robustness in realistic data arrangements. We focus on OLS in the present work due its widespread use and since some approximations work only for OLS. Across our synthetic and real-world data sets, we find that a simple recursive greedy algorithm is the sole algorithm that does not fail any of our tests and also that it can be orders of magnitude faster to run than some competitors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09008v5</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jenny Y. Huang, David R. Burt, Yunyi Shen, Tin D. Nguyen, Tamara Broderick</dc:creator>
    </item>
    <item>
      <title>Understanding the Statistical Accuracy-Communication Trade-off in Personalized Federated Learning with Minimax Guarantees</title>
      <link>https://arxiv.org/abs/2410.08934</link>
      <description>arXiv:2410.08934v4 Announce Type: replace-cross 
Abstract: Personalized federated learning (PFL) offers a flexible framework for aggregating information across distributed clients with heterogeneous data. This work considers a personalized federated learning setting that simultaneously learns global and local models. While purely local training has no communication cost, collaborative learning among the clients can leverage shared knowledge to improve statistical accuracy, presenting an accuracy-communication trade-off in personalized federated learning. However, the theoretical analysis of how personalization quantitatively influences sample and algorithmic efficiency and their inherent trade-off is largely unexplored. This paper makes a contribution towards filling this gap, by providing a quantitative characterization of the personalization degree on the tradeoff. The results further offers theoretical insights for choosing the personalization degree. As a side contribution, we establish the minimax optimality in terms of statistical accuracy for a widely studied PFL formulation. The theoretical result is validated on both synthetic and real-world datasets and its generalizability is verified in a non-convex setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08934v4</guid>
      <category>stat.ML</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Yu, Zelin He, Ying Sun, Lingzhou Xue, Runze Li</dc:creator>
    </item>
    <item>
      <title>Tuning Sequential Monte Carlo Samplers via Greedy Incremental Divergence Minimization</title>
      <link>https://arxiv.org/abs/2503.15704</link>
      <description>arXiv:2503.15704v3 Announce Type: replace-cross 
Abstract: The performance of sequential Monte Carlo (SMC) samplers heavily depends on the tuning of the Markov kernels used in the path proposal. For SMC samplers with unadjusted Markov kernels, standard tuning objectives, such as the Metropolis-Hastings acceptance rate or the expected-squared jump distance, are no longer applicable. While stochastic gradient-based end-to-end optimization has been explored for tuning SMC samplers, they often incur excessive training costs, even for tuning just the kernel step sizes. In this work, we propose a general adaptation framework for tuning the Markov kernels in SMC samplers by minimizing the incremental Kullback-Leibler (KL) divergence between the proposal and target paths. For step size tuning, we provide a gradient- and tuning-free algorithm that is generally applicable for kernels such as Langevin Monte Carlo (LMC). We further demonstrate the utility of our approach by providing a tailored scheme for tuning kinetic LMC used in SMC samplers. Our implementations are able to obtain a full schedule of tuned parameters at the cost of a few vanilla SMC runs, which is a fraction of gradient-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15704v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyurae Kim, Zuheng Xu, Jacob R. Gardner, Trevor Campbell</dc:creator>
    </item>
  </channel>
</rss>
