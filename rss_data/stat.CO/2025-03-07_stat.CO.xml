<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Mar 2025 05:01:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Weighted Fisher divergence for high-dimensional Gaussian variational inference</title>
      <link>https://arxiv.org/abs/2503.04246</link>
      <description>arXiv:2503.04246v1 Announce Type: new 
Abstract: Bayesian inference has many advantages for complex models. However, standard Monte Carlo methods for summarizing the posterior can be computationally demanding, and it is attractive to consider optimization-based variational approximations. Our work considers Gaussian approximations with sparse precision matrices which are tractable to optimize in high-dimensional problems. Although the optimal Gaussian approximation is usually defined as the one closest to the target posterior in Kullback-Leibler divergence, it is useful to consider other divergences when the Gaussian assumption is crude, in order to capture important features of the posterior for a given application. Our work studies the weighted Fisher divergence, which focuses on gradient differences between the target posterior and its approximation, with the Fisher and score-based divergences being special cases. We make three main contributions. First, we compare approximations for weighted Fisher divergences under mean-field assumptions for both Gaussian and non-Gaussian targets with Kullback-Leibler approximations. Second, we go beyond mean-field and consider approximations with sparse precision matrices reflecting posterior conditional independence structure for hierarchical models. Using stochastic gradient descent to enforce sparsity, we develop two approaches to minimize the weighted Fisher divergence, based on the reparametrization trick and a batch approximation of the objective. Finally, we examine the performance of our methods for examples involving logistic regression, generalized linear mixed models and stochastic volatility models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04246v1</guid>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aoxiang Chen, David J. Nott, Linda S. L. Tan</dc:creator>
    </item>
    <item>
      <title>Guided smoothing and control for diffusion processes</title>
      <link>https://arxiv.org/abs/2503.04326</link>
      <description>arXiv:2503.04326v1 Announce Type: cross 
Abstract: The smoothing distribution is the conditional distribution of the diffusion process in the space of trajectories given noisy observations made continuously in time. It is generally difficult to sample from this distribution. We use the theory of enlargement of filtrations to show that the conditional process has an additional drift term derived from the backward filtering distribution that is moving or guiding the process towards the observations. This term is intractable, but its effect can be equally introduced by replacing it with a heuristic, where importance weights correct for the discrepancy. From this Markov Chain Monte Carlo and sequential Monte Carlo algorithms are derived to sample from the smoothing distribution. The choice of the guiding heuristic is discussed from an optimal control perspective and evaluated. The results are tested numerically on a stochastic differential equation for reaction-diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04326v1</guid>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oskar Eklund, Annika Lang, Moritz Schauer</dc:creator>
    </item>
    <item>
      <title>Penetrance Estimation in Family-based Studies with the penetrance R package</title>
      <link>https://arxiv.org/abs/2411.18816</link>
      <description>arXiv:2411.18816v2 Announce Type: replace 
Abstract: Reliable methods for penetrance (age-specific risk among those who carry a genetic variant) estimation are critical to improving clinical decision making and risk assessment for hereditary syndromes. We introduce penetrance, an open-source R package, to estimate age-specific penetrance using family-history pedigree data. The package employs a Bayesian estimation approach, allowing for the incorporation of prior knowledge through the specification of priors for the parameters of the carrier distribution. It also includes options to impute missing ages during the estimation process, addressing incomplete age information which is not uncommon in pedigree datasets. Our software provides a flexible and user-friendly tool for researchers to estimate penetrance in complex family-based studies, facilitating improved genetic risk assessment in hereditary syndromes. The penetrance R package is freely available on CRAN, with accompanying documentation and examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18816v2</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Kubista, Danielle Braun, Giovanni Parmigiani</dc:creator>
    </item>
    <item>
      <title>Scalable Estimation of Multinomial Response Models with Random Consideration Sets</title>
      <link>https://arxiv.org/abs/2308.12470</link>
      <description>arXiv:2308.12470v4 Announce Type: replace-cross 
Abstract: A common assumption in the fitting of unordered multinomial response models for $J$ mutually exclusive categories is that the responses arise from the same set of $J$ categories across subjects. However, when responses measure a choice made by the subject, it is more appropriate to condition the distribution of multinomial responses on a subject-specific consideration set, drawn from the power set of $\{1,2,\ldots,J\}$. This leads to a mixture of multinomial response models governed by a probability distribution over the $J^{\ast} = 2^J -1$ consideration sets. We introduce a novel method for estimating such generalized multinomial response models based on the fundamental result that any mass distribution over $J^{\ast}$ consideration sets can be represented as a mixture of products of $J$ component-specific inclusion-exclusion probabilities. Moreover, under time-invariant consideration sets, the conditional posterior distribution of consideration sets is sparse. These features enable a scalable MCMC algorithm for sampling the posterior distribution of parameters, random effects, and consideration sets. Under regularity conditions, the posterior distributions of the marginal response probabilities and the model parameters satisfy consistency. The methodology is demonstrated in a longitudinal data set on weekly cereal purchases that cover $J = 101$ brands, a dimension substantially beyond the reach of existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12470v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Chib, Kenichi Shimizu</dc:creator>
    </item>
    <item>
      <title>Canonical normalizing flows for manifold learning</title>
      <link>https://arxiv.org/abs/2310.12743</link>
      <description>arXiv:2310.12743v3 Announce Type: replace-cross 
Abstract: Manifold learning flows are a class of generative modelling techniques that assume a low-dimensional manifold description of the data. The embedding of such a manifold into the high-dimensional space of the data is achieved via learnable invertible transformations. Therefore, once the manifold is properly aligned via a reconstruction loss, the probability density is tractable on the manifold and maximum likelihood can be used to optimize the network parameters. Naturally, the lower-dimensional representation of the data requires an injective-mapping. Recent approaches were able to enforce that the density aligns with the modelled manifold, while efficiently calculating the density volume-change term when embedding to the higher-dimensional space. However, unless the injective-mapping is analytically predefined, the learned manifold is not necessarily an efficient representation of the data. Namely, the latent dimensions of such models frequently learn an entangled intrinsic basis, with degenerate information being stored in each dimension. Alternatively, if a locally orthogonal and/or sparse basis is to be learned, here coined canonical intrinsic basis, it can serve in learning a more compact latent space representation. Toward this end, we propose a canonical manifold learning flow method, where a novel optimization objective enforces the transformation matrix to have few prominent and non-degenerate basis functions. We demonstrate that by minimizing the off-diagonal manifold metric elements $\ell_1$-norm, we can achieve such a basis, which is simultaneously sparse and/or orthogonal. Canonical manifold flow yields a more efficient use of the latent space, automatically generating fewer prominent and distinct dimensions to represent data, and a better approximation of target distributions than other manifold flow methods in most experiments we conducted, resulting in lower FID scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12743v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.DG</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyriakos Flouris, Ender Konukoglu</dc:creator>
    </item>
    <item>
      <title>Semiparametric Growth-Curve Modeling in Hierarchical, Longitudinal Studies</title>
      <link>https://arxiv.org/abs/2503.03550</link>
      <description>arXiv:2503.03550v2 Announce Type: replace-cross 
Abstract: Modeling of growth (or decay) curves arises in many fields such as microbiology, epidemiology, marketing, and econometrics. Parametric forms like Logistic and Gompertz are often used for modeling such monotonic patterns. While useful for compact description, the real-life growth curves rarely follow these parametric forms perfectly. Therefore, the curve estimation methods that strike a balance between prior information in the parametric form and fidelity with the observed data are preferred. In hierarchical, longitudinal studies the interest lies in comparing the growth curves of different groups while accounting for the differences between the within-group subjects. This article describes a flexible state space modeling framework that enables semiparametric growth curve modeling for the data generated from hierarchical, longitudinal studies. The methodology, a type of functional mixed effects modeling, is illustrated with a real-life example of bacterial growth in different settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03550v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rajesh Selukar</dc:creator>
    </item>
  </channel>
</rss>
