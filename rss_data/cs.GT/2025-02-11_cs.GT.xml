<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 11 Feb 2025 05:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Adaptable Budget Planner for Enhancing Budget-Constrained Auto-Bidding in Online Advertising</title>
      <link>https://arxiv.org/abs/2502.05187</link>
      <description>arXiv:2502.05187v1 Announce Type: new 
Abstract: In online advertising, advertisers commonly utilize auto-bidding services to bid for impression opportunities. A typical objective of the auto-bidder is to optimize the advertiser's cumulative value of winning impressions within specified budget constraints. However, such a problem is challenging due to the complex bidding environment faced by diverse advertisers. To address this challenge, we introduce ABPlanner, a few-shot adaptable budget planner designed to improve budget-constrained auto-bidding. ABPlanner is based on a hierarchical bidding framework that decomposes the bidding process into shorter, manageable stages. Within this framework, ABPlanner allocates the budget across all stages, allowing a low-level auto-bidder to bids based on the budget allocation plan. The adaptability of ABPlanner is achieved through a sequential decision-making approach, inspired by in-context reinforcement learning. For each advertiser, ABPlanner adjusts the budget allocation plan episode by episode, using data from previous episodes as prompt for current decisions. This enables ABPlanner to quickly adapt to different advertisers with few-shot data, providing a sample-efficient solution. Extensive simulation experiments and real-world A/B testing validate the effectiveness of ABPlanner, demonstrating its capability to enhance the cumulative value achieved by auto-bidders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05187v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijian Duan, Yusen Huo, Tianyu Wang, Zhilin Zhang, Yeshu Li, Chuan Yu, Jian Xu, Bo Zheng, Xiaotie Deng</dc:creator>
    </item>
    <item>
      <title>Optimizing Wealth by a Game within Cellular Automata</title>
      <link>https://arxiv.org/abs/2502.05246</link>
      <description>arXiv:2502.05246v1 Announce Type: new 
Abstract: The objective is to find a Cellular Automata (CA) rule that can evolve 2D patterns that are optimal with respect to a global fitness function. The global fitness is defined as the sum of local computed utilities. A utility or value function computes a score depending on the states in the local neighborhood. First the method is explained that was followed to find such a CA rule. Then this method is applied to find a rule that maximizes social wealth. Here wealth is defined as the sum of the payoffs that all players (agents, cells) receive in a prisoner's dilemma game, and then shared equally among them. The problem is solved in four steps: (0) Defining the utility function, (1) Finding optimal master patterns with a Genetic Algorithm, (2) Extracting templates (local neighborhood configurations), (3) Inserting the templates in a general CA rule. The constructed CA rule finds optimal and near-optimal patterns for even and odd grid sizes. Optimal patterns of odd size contain exactly one singularity, a 2 x 2 block of cooperators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05246v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rolf Hoffmann, Franciszek Seredy\'nski, Dominique D\'es\'erable</dc:creator>
    </item>
    <item>
      <title>Two-Player Zero-Sum Differential Games with One-Sided Information</title>
      <link>https://arxiv.org/abs/2502.05314</link>
      <description>arXiv:2502.05314v1 Announce Type: new 
Abstract: Unlike Poker where the action space $\mathcal{A}$ is discrete, differential games in the physical world often have continuous action spaces not amenable to discrete abstraction, rendering no-regret algorithms with $\mathcal{O}(|\mathcal{A}|)$ complexity not scalable. To address this challenge within the scope of two-player zero-sum (2p0s) games with one-sided information, we show that (1) a computational complexity independent of $|\mathcal{A}|$ can be achieved by exploiting the convexification property of incomplete-information games and the Isaacs' condition that commonly holds for dynamical systems, and that (2) the computation of the two equilibrium strategies can be decoupled under one-sidedness of information. Leveraging these insights, we develop an algorithm that successfully approximates the optimal strategy in a homing game. Code available in https://github.com/ghimiremukesh/cams/tree/workshop</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05314v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mukesh Ghimire, Zhe Xu, Yi Ren</dc:creator>
    </item>
    <item>
      <title>Finding equilibria: simpler for pessimists, simplest for optimists</title>
      <link>https://arxiv.org/abs/2502.05316</link>
      <description>arXiv:2502.05316v1 Announce Type: new 
Abstract: We consider simple stochastic games with terminal-node rewards and multiple players, who have differing perceptions of risk. Specifically, we study risk-sensitive equilibria (RSEs), where no player can improve their perceived reward -- based on their risk parameter -- by deviating from their strategy. We start with the entropic risk (ER) measure, which is widely studied in finance. ER characterises the players on a quantitative spectrum, with positive risk parameters representing optimists and negative parameters representing pessimists. Building on known results for Nash equilibira, we show that RSEs exist under ER for all games with non-negative terminal rewards. However, using similar techniques, we also show that the corresponding constrained existence problem -- to determine whether an RSE exists under ER with the payoffs in given intervals -- is undecidable.
  To address this, we introduce a new, qualitative risk measure -- called extreme risk (XR) -- which coincides with the limit cases of positively infinite and negatively infinite ER parameters. Under XR, every player is an extremist: an extreme optimist perceives their reward as the maximum payoff that can be achieved with positive probability, while an extreme pessimist expects the minimum payoff achievable with positive probability. Our first main result proves the existence of RSEs also under XR for non-negative terminal rewards. Our second main result shows that under XR the constrained existence problem is not only decidable, but NP-complete. Moreover, when all players are extreme optimists, the problem becomes PTIME-complete. Our algorithmic results apply to all rewards, positive or negative, establishing the first decidable fragment for equilibria in simple stochastic games with terminal objectives without restrictions on strategy types or number of players.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05316v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eonard Brice, Thomas Henzinger, K. S. Thejaswini</dc:creator>
    </item>
    <item>
      <title>Online Bidding Algorithms with Strict Return on Spend (ROS) Constraint</title>
      <link>https://arxiv.org/abs/2502.05599</link>
      <description>arXiv:2502.05599v1 Announce Type: new 
Abstract: Auto-bidding problem under a strict return-on-spend constraint (ROSC) is considered, where an algorithm has to make decisions about how much to bid for an ad slot depending on the revealed value, and the hidden allocation and payment function that describes the probability of winning the ad-slot depending on its bid. The objective of an algorithm is to maximize the expected utility (product of ad value and probability of winning the ad slot) summed across all time slots subject to the total expected payment being less than the total expected utility, called the ROSC. A (surprising) impossibility result is derived that shows that no online algorithm can achieve a sub-linear regret even when the value, allocation and payment function are drawn i.i.d. from an unknown distribution. The problem is non-trivial even when the revealed value remains constant across time slots, and an algorithm with regret guarantee that is optimal up to logarithmic factor is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05599v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rahul Vaze, Abhishek Sinha</dc:creator>
    </item>
    <item>
      <title>Open Data in the Digital Economy: An Evolutionary Game Theory Perspective</title>
      <link>https://arxiv.org/abs/2502.05604</link>
      <description>arXiv:2502.05604v1 Announce Type: new 
Abstract: Open data, as an essential element in the sustainable development of the digital economy, is highly valued by many relevant sectors in the implementation process. However, most studies suppose that there are only data providers and users in the open data process and ignore the existence of data regulators. In order to establish long-term green supply relationships between multi-stakeholders, we hereby introduce data regulators and propose an evolutionary game model to observe the cooperation tendency of multi-stakeholders (data providers, users, and regulators). The newly proposed game model enables us to intensively study the trading behavior which can be realized as strategies and payoff functions of the data providers, users, and regulators. Besides, a replicator dynamic system is built to study evolutionary stable strategies of multi-stakeholders. In simulations, we investigate the evolution of the cooperation ratio as time progresses under different parameters, which is proved to be in agreement with our theoretical analysis. Furthermore, we explore the influence of the cost of data users to acquire data, the value of open data, the reward (penalty) from the regulators, and the data mining capability of data users to group strategies and uncover some regular patterns. Some meaningful results are also obtained through simulations, which can guide stakeholders to make better decisions in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05604v1</guid>
      <category>cs.GT</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TCSS.2023.3324087</arxiv:DOI>
      <dc:creator>Qin Li, Bin Pi, Minyu Feng, J\"urgen Kurths</dc:creator>
    </item>
    <item>
      <title>Fairness Driven Slot Allocation Problem in Billboard Advertisement</title>
      <link>https://arxiv.org/abs/2502.05851</link>
      <description>arXiv:2502.05851v1 Announce Type: new 
Abstract: In billboard advertisement, a number of digital billboards are owned by an influence provider, and several commercial houses (which we call advertisers) approach the influence provider for a specific number of views of their advertisement content on a payment basis. Though the billboard slot allocation problem has been studied in the literature, this problem still needs to be addressed from a fairness point of view. In this paper, we introduce the Fair Billboard Slot Allocation Problem, where the objective is to allocate a given set of billboard slots among a group of advertisers based on their demands fairly and efficiently. As fairness criteria, we consider the maximin fair share, which ensures that each advertiser will receive a subset of slots that maximizes the minimum share for all the advertisers. We have proposed a solution approach that generates an allocation and provides an approximate maximum fair share. The proposed methodology has been analyzed to understand its time and space requirements and a performance guarantee. It has been implemented with real-world trajectory and billboard datasets, and the results have been reported. The results show that the proposed approach leads to a balanced allocation by satisfying the maximin fairness criteria. At the same time, it maximizes the utility of advertisers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05851v1</guid>
      <category>cs.GT</category>
      <category>cs.DB</category>
      <category>cs.MA</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Suman Banerjee, Shweta Jain, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>Strategic Queues with Priority Classes</title>
      <link>https://arxiv.org/abs/2502.05906</link>
      <description>arXiv:2502.05906v1 Announce Type: new 
Abstract: We consider a strategic M/M/1 queueing model under a first-come-first-served regime, where customers are split into two classes and class $A$ has priority over class $B$. Customers can decide whether to join the queue or balk, and, in case they have joined the queue, whether and when to renege. We study the equilibrium strategies and compare the equilibrium outcome and the social optimum in the two cases where the social optimum is or is not constrained by priority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05906v1</guid>
      <category>cs.GT</category>
      <category>math.PR</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maurizio D'Andrea, Marco Scarsini</dc:creator>
    </item>
    <item>
      <title>Verifying Proportionality in Temporal Voting</title>
      <link>https://arxiv.org/abs/2502.05949</link>
      <description>arXiv:2502.05949v1 Announce Type: new 
Abstract: We study a model of temporal voting where there is a fixed time horizon, and at each round the voters report their preferences over the available candidates and a single candidate is selected. Prior work has adapted popular notions of justified representation as well as voting rules that provide strong representation guarantees from the multiwinner election setting to this model. In our work, we focus on the complexity of verifying whether a given outcome offers proportional representation. We show that in the temporal setting verification is strictly harder than in multiwinner voting, but identify natural special cases that enable efficient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05949v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edith Elkind, Svetlana Obraztsova, Jannik Peters, Nicholas Teh</dc:creator>
    </item>
    <item>
      <title>Perpetual Demand Lending Pools</title>
      <link>https://arxiv.org/abs/2502.06028</link>
      <description>arXiv:2502.06028v1 Announce Type: new 
Abstract: Decentralized perpetuals protocols have collectively reached billions of dollars of daily trading volume, yet are still not serious competitors on the basis of trading volume with centralized venues such as Binance. One of the main reasons for this is the high cost of capital for market makers and sophisticated traders in decentralized settings. Recently, numerous decentralized finance protocols have been used to improve borrowing costs for perpetual futures traders. We formalize this class of mechanisms utilized by protocols such as Jupiter, Hyperliquid, and GMX, which we term~\emph{Perpetual Demand Lending Pools} (PDLPs). We then formalize a general target weight mechanism that generalizes what GMX and Jupiter are using in practice. We explicitly describe pool arbitrage and expected payoffs for arbitrageurs and liquidity providers within these mechanisms. Using this framework, we show that under general conditions, PDLPs are easy to delta hedge, partially explaining the proliferation of live hedged PDLP strategies. Our results suggest directions to improve capital efficiency in PDLPs via dynamic parametrization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06028v1</guid>
      <category>cs.GT</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarun Chitra, Theo Diamandis, Nathan Sheng, Luke Sterle, Kamil Yusubov</dc:creator>
    </item>
    <item>
      <title>A Fair and Optimal Approach to Sequential Health Rationing</title>
      <link>https://arxiv.org/abs/2502.06082</link>
      <description>arXiv:2502.06082v1 Announce Type: new 
Abstract: The COVID-19 pandemic underscored the urgent need for fair and effective allocation of scarce resources, from hospital beds to vaccine distribution. In this paper, we study a healthcare rationing problem where identical units of a resource are divided into different categories, and agents are assigned based on priority rankings. % We first introduce a simple and efficient algorithm that satisfies four fundamental axioms critical to practical applications: eligible compliance, non-wastefulness, respect for priorities, and maximum cardinality. This new algorithm is not only conceptually simpler but also computationally faster than the Reverse Rejecting rules proposed in recent work. % We then extend our analysis to a more general sequential setting, where categories can be processed both sequentially and simultaneously. For this broader framework, we introduce a novel algorithm that preserves the four fundamental axioms while achieving additional desirable properties that existing rules fail to satisfy. Furthermore, we prove that when a strict precedence order over categories is imposed, this rule is the unique mechanism that satisfies these properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06082v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhaohong Sun</dc:creator>
    </item>
    <item>
      <title>Liquid Welfare and Revenue Monotonicity in Adaptive Clinching Auctions</title>
      <link>https://arxiv.org/abs/2502.06278</link>
      <description>arXiv:2502.06278v1 Announce Type: new 
Abstract: This study explores the monotonicity of adaptive clinching auctions -- a key mechanism in budget-constrained auctions -- with respect to fluctuations in the number of bidders. Specifically, we investigate how the addition of new bidders affect efficiency and revenue. In a symmetric setting, where all bidders have equal budgets, we show that while the allocated goods and payments for many bidders decrease, overall both liquid welfare and revenue weakly increase. Our analysis also extends to scenarios where bidders arrive online during the auction. In contrast, for asymmetric budgets, we provide counterexamples showing that these monotonicity properties no longer hold. These findings contribute to a better theoretical understanding of budget-constrained auctions and offer insights into the behavior of adaptive clinching auctions in social networks, where new bidders emerge through information diffusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06278v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryosuke Sato</dc:creator>
    </item>
    <item>
      <title>Utilitarian Distortion with Predictions</title>
      <link>https://arxiv.org/abs/2502.06489</link>
      <description>arXiv:2502.06489v1 Announce Type: new 
Abstract: We study the utilitarian distortion of social choice mechanisms under the recently proposed learning-augmented framework where some (possibly unreliable) predicted information about the preferences of the agents is given as input. In particular, we consider two fundamental social choice problems: single-winner voting and one-sided matching. In these settings, the ordinal preferences of the agents over the alternatives (either candidates or items) is known, and some prediction about their underlying cardinal values is also provided. The goal is to leverage the prediction to achieve improved distortion guarantees when it is accurate, while simultaneously still achieving reasonable worst-case bounds when it is not. This leads to the notions of consistency and robustness, and the quest to achieve the best possible tradeoffs between the two. We show tight tradeoffs between the consistency and robustness of ordinal mechanisms for single-winner voting and one-sided matching, for different levels of information provided by as prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06489v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aris Filos-Ratsikas, Georgios Kalantzis, Alexandros A. Voudouris</dc:creator>
    </item>
    <item>
      <title>Fractional Claims Trades and Donations in Financial Networks</title>
      <link>https://arxiv.org/abs/2502.06515</link>
      <description>arXiv:2502.06515v1 Announce Type: new 
Abstract: Exploring measures to improve financial networks and mitigate systemic risks is an ongoing challenge. We study claims trading, a notion defined in Chapter 11 of the U.S. Bankruptcy Code. For a bank $v$ in distress and a trading partner $w$, the latter is taking over some claims of $v$ and in return giving liquidity to $v$. The idea is to rescue $v$ (or mitigate contagion effects from $v$'s insolvency). We focus on the impact of trading claims fractionally, when $v$ and $w$ can agree to trade only part of a claim. In addition, we study donations, in which $w$ only provides liquidity to $v$. They can be seen as special claims trades.
  When trading a single claim or making a single donation in networks without default cost, we show that it is impossible to strictly improve the assets of both banks $v$ and $w$. Since the goal is to rescue $v$ in distress, we study creditor-positive trades, in which $v$ improves and $w$ remains indifferent. We show that an optimal creditor-positive trade that maximizes the assets of $v$ can be computed in polynomial time. It also yields a (weak) Pareto-improvement for all banks in the entire network. In networks with default cost, we obtain a trade in polynomial time that weakly Pareto-improves all assets over the ones resulting from the optimal creditor-positive trade. We generalize these results to trading multiple claims for which $v$ is the creditor.
  Instead, when trading claims with a common debtor $u$, we obtain NP-hardness results for computing trades in networks with default cost that maximize the assets of the creditors and Pareto-improve the assets in the network. Similar results apply when $w$ donates to multiple banks in networks with default costs. For networks without default cost, we give an efficient algorithm to compute optimal donations to multiple banks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06515v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Hoefer, Lars Huth, Lisa Wilhelmi</dc:creator>
    </item>
    <item>
      <title>Network Creation Games with 2-Neighborhood Maximization</title>
      <link>https://arxiv.org/abs/2502.06561</link>
      <description>arXiv:2502.06561v1 Announce Type: new 
Abstract: Network creation games are well-established for investigating the decentralized formation of communication networks, like the Internet or social networks. In these games, selfish agents that correspond to network nodes strategically create costly edges to maximize their centrality in the formed network. We depart from this by focusing on the simpler objective of maximizing the 2-neighborhood. This seems natural for social networks, as an agent's connection benefit is typically provided by her neighbors and their neighbors but not by strangers further away.
  For this natural model, we study the existence, the structure and the quality both of Nash equilibria (NE) and greedy equilibria (GE). We give structural results on the existence of degree-2 paths and cycles, and we provide tight constant bounds on the diameter. In contrast to most previous network creation game research, our bounds on the diameter are independent of edge cost $\alpha$ and the number of agents $n$. Also, bounding the diameter does not imply bounding the price of anarchy, which calls for other methods. Using them, we obtain non-trivial bounds on the price of anarchy, including a $\Omega(\log(\frac{n}{\alpha}))$ lower bound for NE, and a tight linear bound for GE for low $\alpha$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06561v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Merlin de la Haye, Pascal Lenzner, Daniel Schmand, Nicole Schr\"oder</dc:creator>
    </item>
    <item>
      <title>Incentivizing Desirable Effort Profiles in Strategic Classification: The Role of Causality and Uncertainty</title>
      <link>https://arxiv.org/abs/2502.06749</link>
      <description>arXiv:2502.06749v1 Announce Type: new 
Abstract: We study strategic classification in binary decision-making settings where agents can modify their features in order to improve their classification outcomes. Importantly, our work considers the causal structure across different features, acknowledging that effort in a given feature may affect other features. The main goal of our work is to understand \emph{when and how much agent effort is invested towards desirable features}, and how this is influenced by the deployed classifier, the causal structure of the agent's features, their ability to modify them, and the information available to the agent about the classifier and the feature causal graph.
  In the complete information case, when agents know the classifier and the causal structure of the problem, we derive conditions ensuring that rational agents focus on features favored by the principal. We show that designing classifiers to induce desirable behavior is generally non-convex, though tractable in special cases. We also extend our analysis to settings where agents have incomplete information about the classifier or the causal graph. While optimal effort selection is again a non-convex problem under general uncertainty, we highlight special cases of partial uncertainty where this selection problem becomes tractable. Our results indicate that uncertainty drives agents to favor features with higher expected importance and lower variance, potentially misaligning with principal preferences. Finally, numerical experiments based on a cardiovascular disease risk study illustrate how to incentivize desirable modifications under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06749v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valia Efthymiou, Chara Podimata, Diptangshu Sen, Juba Ziani</dc:creator>
    </item>
    <item>
      <title>Instant Runoff Voting and the Reinforcement Paradox</title>
      <link>https://arxiv.org/abs/2502.05185</link>
      <description>arXiv:2502.05185v1 Announce Type: cross 
Abstract: We analyze the susceptibility of instant runoff voting (IRV) to a lesser-studied paradox known as a reinforcement paradox, which occurs when candidate X wins under IRV in two distinct elections but X loses in the combined election formed by merging the ballots from the two elections. For three-candidate IRV elections we provide necessary and sufficient conditions under which there exists a partition of the ballot set into two sets of ballots such that a given losing candidate wins each of the sub-elections. Using these conditions, we use Monte Carlo simulations to estimate the frequency with which such partitions exist under various models of voter behavior. We also analyze the frequency with which the paradox in a large dataset of real-world ranked-choice elections to provide empirical probabilities. Our general finding is that IRV is highly susceptible to this paradox in three-candidate elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05185v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David McCune, Jennifer Wilson</dc:creator>
    </item>
    <item>
      <title>Riemannian Manifold Learning for Stackelberg Games with Neural Flow Representations</title>
      <link>https://arxiv.org/abs/2502.05498</link>
      <description>arXiv:2502.05498v1 Announce Type: cross 
Abstract: We present a novel framework for online learning in Stackelberg general-sum games, where two agents, the leader and follower, engage in sequential turn-based interactions. At the core of this approach is a learned diffeomorphism that maps the joint action space to a smooth Riemannian manifold, referred to as the Stackelberg manifold. This mapping, facilitated by neural normalizing flows, ensures the formation of tractable isoplanar subspaces, enabling efficient techniques for online learning. By assuming linearity between the agents' reward functions on the Stackelberg manifold, our construct allows the application of standard bandit algorithms. We then provide a rigorous theoretical basis for regret minimization on convex manifolds and establish finite-time bounds on simple regret for learning Stackelberg equilibria. This integration of manifold learning into game theory uncovers a previously unrecognized potential for neural normalizing flows as an effective tool for multi-agent learning. We present empirical results demonstrating the effectiveness of our approach compared to standard baselines, with applications spanning domains such as cybersecurity and economic supply chain optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05498v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Larkin Liu, Kashif Rasul, Yutong Chao, Jalal Etesami</dc:creator>
    </item>
    <item>
      <title>Barriers and Pathways to Human-AI Alignment: A Game-Theoretic Approach</title>
      <link>https://arxiv.org/abs/2502.05934</link>
      <description>arXiv:2502.05934v1 Announce Type: cross 
Abstract: Under what conditions can capable AI agents efficiently align their actions with human preferences? More specifically, when they are proficient enough to collaborate with us, how long does coordination take, and when is it computationally feasible? These foundational questions of AI alignment help define what makes an AI agent ``sufficiently safe'' and valuable to humans. Since such generally capable systems do not yet exist, a theoretical analysis is needed to establish when guarantees hold -- and what they even are.
  We introduce a game-theoretic framework that generalizes prior alignment approaches with fewer assumptions, allowing us to analyze the computational complexity of alignment across $M$ objectives and $N$ agents, providing both upper and lower bounds. Unlike previous work, which often assumes common priors, idealized communication, or implicit tractability, our framework formally characterizes the difficulty of alignment under minimal assumptions.
  Our main result shows that even when agents are fully rational and computationally \emph{unbounded}, alignment can be achieved with high probability in time \emph{linear} in the task space size. Therefore, in real-world settings, where task spaces are often \emph{exponential} in input length, this remains impractical. More strikingly, our lower bound demonstrates that alignment is \emph{impossible} to speed up when scaling to exponentially many tasks or agents, highlighting a fundamental computational barrier to scalable alignment.
  Relaxing these idealized assumptions, we study \emph{computationally bounded} agents with noisy messages (representing obfuscated intent), showing that while alignment can still succeed with high probability, it incurs additional \emph{exponential} slowdowns in the task space size, number of agents, and number of tasks.
  We conclude by identifying conditions that make alignment more feasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05934v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aran Nayebi</dc:creator>
    </item>
    <item>
      <title>How Humans Help LLMs: Assessing and Incentivizing Human Preference Annotators</title>
      <link>https://arxiv.org/abs/2502.06387</link>
      <description>arXiv:2502.06387v1 Announce Type: cross 
Abstract: Human-annotated preference data play an important role in aligning large language models (LLMs). In this paper, we investigate the questions of assessing the performance of human annotators and incentivizing them to provide high-quality annotations. The quality assessment of language/text annotation faces two challenges: (i) the intrinsic heterogeneity among annotators, which prevents the classic methods that assume the underlying existence of a true label; and (ii) the unclear relationship between the annotation quality and the performance of downstream tasks, which excludes the possibility of inferring the annotators' behavior based on the model performance trained from the annotation data. Then we formulate a principal-agent model to characterize the behaviors of and the interactions between the company and the human annotators. The model rationalizes a practical mechanism of a bonus scheme to incentivize annotators which benefits both parties and it underscores the importance of the joint presence of an assessment system and a proper contract scheme. From a technical perspective, our analysis extends the existing literature on the principal-agent model by considering a continuous action space for the agent. We show the gap between the first-best and the second-best solutions (under the continuous action space) is of $\Theta(1/\sqrt{n \log n})$ for the binary contracts and $\Theta(1/n)$ for the linear contracts, where $n$ is the number of samples used for performance assessment; this contrasts with the known result of $\exp(-\Theta(n))$ for the binary contracts when the action space is discrete. Throughout the paper, we use real preference annotation data to accompany our discussions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06387v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shang Liu, Hanzhao Wang, Zhongyao Ma, Xiaocheng Li</dc:creator>
    </item>
    <item>
      <title>A Quadratic Lower Bound for Stable Roommates Solvability</title>
      <link>https://arxiv.org/abs/2502.06464</link>
      <description>arXiv:2502.06464v1 Announce Type: cross 
Abstract: In their seminal work on the Stable Marriage Problem (SM), Gale and Shapley introduced a generalization of SM referred to as the Stable Roommates Problem (SR). An instance of SR consists of a set of $2n$ agents, and each agent has preferences in the form of a ranked list of all other agents. The goal is to find a one-to-one matching between the agents that is stable in the sense that no pair of agents have a mutual incentive to deviate from the matching. Unlike the (bipartite) stable marriage problem, in SR, stable matchings need not exist. Irving devised an algorithm that finds a stable matching or reports that none exists in $O(n^2)$ time. In their influential 1989 text, Gusfield and Irving posed the question of whether $\Omega(n^2)$ time is required for SR solvability -- the task of determining if an SR instance admits a stable matching.
  In this paper we provide an affirmative answer to Gusfield and Irving's question. We show that any (randomized) algorithm that determines SR solvability requires $\Omega(n^2)$ adaptive Boolean queries to the agents' preferences (in expectation). Our argument follows from a reduction from the communication complexity of the set disjointness function. The query lower bound implies quadratic time lower bounds for Turing machines, and memory access lower bounds for random access machines. Thus, we establish that Irving's algorithm is optimal (up to a logarithmic factor) in a very strong sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06464v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Will Rosenbaum</dc:creator>
    </item>
    <item>
      <title>On the Impact of the Utility in Semivalue-based Data Valuation</title>
      <link>https://arxiv.org/abs/2502.06574</link>
      <description>arXiv:2502.06574v1 Announce Type: cross 
Abstract: Semivalue-based data valuation in machine learning (ML) quantifies the contribution of individual data points to a downstream ML task by leveraging principles from cooperative game theory and the notion of utility. While this framework has been used in practice for assessing data quality, our experiments reveal inconsistent valuation outcomes across different utilities, albeit all related to ML performance. Beyond raising concerns about the reliability of data valuation, this inconsistency is challenging to interpret, as it stems from the complex interaction of the utility with data points and semivalue weights, which has barely been studied in prior work. In this paper, we take a first step toward clarifying the utility impact on semivalue-based data valuation. Specifically, we provide geometric interpretations of this impact for a broad family of classification utilities, which includes the accuracy and the arithmetic mean. We introduce the notion of spatial signatures: given a semivalue, data points can be embedded into a two-dimensional space, and utility functions map to the dual of this space. This geometric perspective separates the influence of the dataset and semivalue from that of the utility, providing a theoretical explanation for the experimentally observed sensitivity of valuation outcomes to the utility choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06574v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>M\'elissa Tamine, Benjamin Heymann, Patrick Loiseau, Maxime Vono</dc:creator>
    </item>
    <item>
      <title>Institutional Preferences in the Laboratory</title>
      <link>https://arxiv.org/abs/2502.06748</link>
      <description>arXiv:2502.06748v1 Announce Type: cross 
Abstract: Getting a group to adopt cooperative norms is an enduring challenge. But in real-world settings, individuals don't just passively accept static environments, they act both within and upon the social systems that structure their interactions. Should we expect the dynamism of player-driven changes to the "rules of the game" to hinder cooperation -- because of the substantial added complexity -- or help it, as prosocial agents tweak their environment toward non-zero-sum games? We introduce a laboratory setting to test whether groups can guide themselves to cooperative outcomes by manipulating the environmental parameters that shape their emergent cooperation process. We test for cooperation in a set of economic games that impose different social dilemmas. These games vary independently in the institutional features of stability, efficiency, and fairness. By offering agency over behavior along with second-order agency over the rules of the game, we understand emergent cooperation in naturalistic settings in which the rules of the game are themselves dynamic and subject to choice. The literature on transfer learning in games suggests that interactions between features are important and might aid or hinder the transfer of cooperative learning to new settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06748v1</guid>
      <category>cs.SI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiankun Zhong, Nori Jacoby, Ofer Tchernichovski, Seth Frey</dc:creator>
    </item>
    <item>
      <title>Bounds on the revenue gap of linear posted pricing for selling a divisible item</title>
      <link>https://arxiv.org/abs/2007.08246</link>
      <description>arXiv:2007.08246v3 Announce Type: replace 
Abstract: Selling a perfectly divisible item to potential buyers is a fundamental task with apparent applications to pricing communication bandwidth and cloud computing services. Surprisingly, despite the rich literature on single-item auctions, revenue maximization when selling a divisible item is a much less understood objective. We introduce a Bayesian setting, in which the potential buyers have concave valuation functions (defined for each possible item fraction) that are randomly chosen according to known probability distributions. Extending the sequential posted pricing paradigm, we focus on mechanisms that use linear pricing, charging a fixed price for the whole item and proportional prices for fractions of it. Our goal is to understand the power of such mechanisms by bounding the gap between the expected revenue that can be achieved by the best among these mechanisms and the maximum expected revenue that can be achieved by any mechanism assuming mild restrictions on the behavior of the buyers. Under regularity assumptions for the probability distributions, we show that this revenue gap depends only logarithmically on a natural parameter characterizing the valuation functions and the number of agents. Our results follow by bounding the objective value of a mathematical program that maximizes the ex-ante relaxation of optimal revenue under linear pricing revenue constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.08246v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Caragiannis, Zhile Jiang, Apostolis Kerentzis</dc:creator>
    </item>
    <item>
      <title>Learning in Zero-Sum Markov Games: Relaxing Strong Reachability and Mixing Time Assumptions</title>
      <link>https://arxiv.org/abs/2312.08008</link>
      <description>arXiv:2312.08008v3 Announce Type: replace 
Abstract: We address payoff-based decentralized learning in infinite-horizon zero-sum Markov games. In this setting, each player makes decisions based solely on received rewards, without observing the opponent's strategy or actions nor sharing information. Prior works established finite-time convergence to an approximate Nash equilibrium under strong reachability and mixing time assumptions. We propose a convergent algorithm that significantly relaxes these assumptions, requiring only the existence of a single policy (not necessarily known) with bounded reachability and mixing time. Our key technical novelty is introducing Tsallis entropy regularization to smooth the best-response policy updates. By suitably tuning this regularization, we ensure sufficient exploration, thus bypassing previous stringent assumptions on the MDP. By establishing novel properties of the value and policy updates induced by the Tsallis entropy regularizer, we prove finite-time convergence to an approximate Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.08008v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Reda Ouhamma, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>A Partially Defined Game with Payments</title>
      <link>https://arxiv.org/abs/2405.07591</link>
      <description>arXiv:2405.07591v2 Announce Type: replace 
Abstract: The present study explores an original problem that can be resolved by employing the notion of a PDG, yet cannot by using a restricted game. The following situation is considered: First, it is assumed that the worth of the grand and singleton coalitions are known. It takes some amount of costs to obtain worth of larger coalitions. If it is performed, then the worth of the grand coalition is decreased by the value of a cost function. The problem of a partially defined game with payments is finding the solution of partially defined games at each point and the best exiting rule of examinations of coalitional worth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07591v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Satoshi Masuya</dc:creator>
    </item>
    <item>
      <title>Conformalized Strategy-Proof Auctions</title>
      <link>https://arxiv.org/abs/2405.12016</link>
      <description>arXiv:2405.12016v4 Announce Type: replace 
Abstract: Auctions are key for maximizing sellers' revenue and ensuring truthful bidding among buyers. Recently, an approach known as differentiable economics based on machine learning (ML) has shown promise in learning powerful auction mechanisms for multiple items and participants. However, this approach has no guarantee of strategy-proofness at test time. Strategy-proofness is crucial as it ensures that buyers are incentivized to bid their true valuations, leading to optimal and fair auction outcomes without the risk of manipulation. In this work, we propose a formulation of statistical strategy-proofness auction mechanism, ensuring that the probability of regret exceeding a predefined threshold is strictly controlled. Building upon conformal prediction techniques, we develop an auction acceptance rule that leverages regret predictions to guarantee that the data-driven auction mechanism meets the statistical strategy-proofness requirement with high probability. Our approach represents a practical middle-ground between two extremes: forcing zero-regret at the cost of significant revenue loss, and naively using ML to construct auctions with the hope of attaining low regret at test time. Numerical experiments demonstrate the necessity of the proposed method, the validity of our theoretical result, and its applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12016v4</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roy Maor Lotan, Inbal Talgam-Cohen, Yaniv Romano</dc:creator>
    </item>
    <item>
      <title>Adapting Beyond the Depth Limit: Counter Strategies in Large Imperfect Information Games</title>
      <link>https://arxiv.org/abs/2501.10464</link>
      <description>arXiv:2501.10464v3 Announce Type: replace 
Abstract: We study the problem of adapting to a known sub-rational opponent during online play while remaining robust to rational opponents. We focus on large imperfect-information (zero-sum) games, which makes it impossible to inspect the whole game tree at once and necessitates the use of depth-limited search. However, all existing methods assume rational play beyond the depth-limit, which only allows them to adapt a very limited portion of the opponent's behaviour. We propose an algorithm Adapting Beyond Depth-limit (ABD) that uses a strategy-portfolio approach - which we refer to as matrix-valued states - for depth-limited search. This allows the algorithm to fully utilise all information about the opponent model, making it the first robust-adaptation method to be able to do so in large imperfect-information games. As an additional benefit, the use of matrix-valued states makes the algorithm simpler than traditional methods based on optimal value functions. Our experimental results in poker and battleship show that ABD yields more than a twofold increase in utility when facing opponents who make mistakes beyond the depth limit and also delivers significant improvements in utility and safety against randomly generated opponents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10464v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Milec, Vojt\v{e}ch Kova\v{r}\'ik, Viliam Lis\'y</dc:creator>
    </item>
    <item>
      <title>Can Reinforcement Learning Solve Asymmetric Combinatorial-Continuous Zero-Sum Games?</title>
      <link>https://arxiv.org/abs/2502.01252</link>
      <description>arXiv:2502.01252v2 Announce Type: replace 
Abstract: There have been extensive studies on learning in zero-sum games, focusing on the analysis of the existence and algorithmic convergence of Nash equilibrium (NE). Existing studies mainly focus on symmetric games where the strategy spaces of the players are of the same type and size. For the few studies that do consider asymmetric games, they are mostly restricted to matrix games. In this paper, we define and study a new practical class of asymmetric games called two-player Asymmetric Combinatorial-Continuous zEro-Sum (ACCES) games, featuring a combinatorial action space for one player and an infinite compact space for the other. Such ACCES games have broad implications in the real world, particularly in combinatorial optimization problems (COPs) where one player optimizes a solution in a combinatorial space, and the opponent plays against it in an infinite (continuous) compact space (e.g., a nature player deciding epistemic parameters of the environmental model). Our first key contribution is to prove the existence of NE for two-player ACCES games, using the idea of essentially finite game approximation. Building on the theoretical insights and double oracle (DO)-based solutions to complex zero-sum games, our second contribution is to design the novel algorithm, Combinatorial Continuous DO (CCDO), to solve ACCES games, and prove the convergence of the proposed algorithm. Considering the NP-hardness of most COPs and recent advancements in reinforcement learning (RL)-based solutions to COPs, our third contribution is to propose a practical algorithm to solve NE in the real world, CCDORL (based on CCDO), and provide the novel convergence analysis in the ACCES game. Experimental results across diverse instances of COPs demonstrate the empirical effectiveness of our algorithms. The code of this work is available at https://github.com/wmd3i/CCDO-RL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01252v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Published in ICLR 2025</arxiv:journal_reference>
      <dc:creator>Yuheng Li, Panpan Wang, Haipeng Chen</dc:creator>
    </item>
    <item>
      <title>Near-Feasible Solutions to Complex Stable Matching Problems</title>
      <link>https://arxiv.org/abs/2502.02503</link>
      <description>arXiv:2502.02503v2 Announce Type: replace 
Abstract: In this paper, we demonstrate that in many NP-complete variants of the stable matching problem, such as the Stable Hypergraph Matching problem, the Stable Multicommodity Flow problem, and the College Admission problem with common quotas, a near-feasible stable solution - that is, a solution which is stable, but may slightly violate some capacities - always exists. Our results provide strong theoretical guarantees that even under complex constraints, stability can be restored with minimal capacity modifications.
  To achieve this, we present an iterative rounding algorithm that starts from a stable fractional solution and systematically adjusts capacities to ensure the existence of an integral stable solution. This approach leverages Scarf's algorithm to compute an initial fractional stable solution, which serves as the foundation for our rounding process. Notably, in the case of the Stable Fixtures problem, where a stable fractional matching can be computed efficiently, our method runs in polynomial time.
  These findings have significant practical implications for market design, college admissions, and other real-world allocation problems, where small adjustments to institutional constraints can guarantee stable and implementable outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02503v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gergely Cs\'aji</dc:creator>
    </item>
    <item>
      <title>Coordination Mechanisms with Rank-Based Utilities</title>
      <link>https://arxiv.org/abs/2502.03113</link>
      <description>arXiv:2502.03113v2 Announce Type: replace 
Abstract: In classical job-scheduling games, each job behaves as a selfish player, choosing a machine to minimize its own completion time. To reduce the equilibria inefficiency, coordination mechanisms are employed, allowing each machine to follow its own scheduling policy. In this paper we study the effects of incorporating rank-based utilities within coordination mechanisms across environments with either identical or unrelated machines.
  With rank-based utilities, players aim to perform well relative to their competitors, rather than solely minimizing their completion time. We first demonstrate that even in basic setups, such as two identical machines with unit-length jobs, a pure Nash equilibrium (NE) assignment may not exist. This observation motivates our inquiry into the complexity of determining whether a given game instance admits a NE. We prove that this problem is NP-complete, even in highly restricted cases. In contrast, we identify specific classes of games where a NE is guaranteed to exist, or where the decision problem can be resolved in polynomial time.
  Additionally, we examine how competition impacts the efficiency of Nash equilibria, or sink equilibria if a NE does not exist. We derive tight bounds on the price of anarchy, and show that competition may either enhance or degrade overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03113v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilad Lavie, Tami Tamir</dc:creator>
    </item>
    <item>
      <title>Incentivizing Honesty among Competitors in Collaborative Learning and Optimization</title>
      <link>https://arxiv.org/abs/2305.16272</link>
      <description>arXiv:2305.16272v4 Announce Type: replace-cross 
Abstract: Collaborative learning techniques have the potential to enable training machine learning models that are superior to models trained on a single entity's data. However, in many cases, potential participants in such collaborative schemes are competitors on a downstream task, such as firms that each aim to attract customers by providing the best recommendations. This can incentivize dishonest updates that damage other participants' models, potentially undermining the benefits of collaboration. In this work, we formulate a game that models such interactions and study two learning tasks within this framework: single-round mean estimation and multi-round SGD on strongly-convex objectives. For a natural class of player actions, we show that rational clients are incentivized to strongly manipulate their updates, preventing learning. We then propose mechanisms that incentivize honest communication and ensure learning quality comparable to full cooperation. Lastly, we empirically demonstrate the effectiveness of our incentive scheme on a standard non-convex federated learning benchmark. Our work shows that explicitly modeling the incentives and actions of dishonest clients, rather than assuming them malicious, can enable strong robustness guarantees for collaborative learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.16272v4</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian E. Dorner, Nikola Konstantinov, Georgi Pashaliev, Martin Vechev</dc:creator>
    </item>
    <item>
      <title>Incentive Allocation in Vertical Federated Learning Based on Bankruptcy Problem</title>
      <link>https://arxiv.org/abs/2307.03515</link>
      <description>arXiv:2307.03515v3 Announce Type: replace-cross 
Abstract: Vertical federated learning (VFL) is a promising approach for collaboratively training machine learning models using private data partitioned vertically across different parties. Ideally in a VFL setting, the active party (party possessing features of samples with labels) benefits by improving its machine learning model through collaboration with some passive parties (parties possessing additional features of the same samples without labels) in a privacy preserving manner. However, motivating passive parties to participate in VFL can be challenging. In this paper, we focus on the problem of allocating incentives to the passive parties by the active party based on their contributions to the VFL process. We address this by formulating the incentive allocation problem as a bankruptcy game, a concept from cooperative game theory. Using the Talmudic division rule, which leads to the Nucleolus as its solution, we ensure a fair distribution of incentives. We evaluate our proposed method on synthetic and real-world datasets and show that it ensures fairness and stability in incentive allocation among passive parties who contribute their data to the federated model. Additionally, we compare our method to the existing solution of calculating Shapley values and show that our approach provides a more efficient solution with fewer computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03515v3</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Afsana Khan, Marijn ten Thij, Frank Thuijsman, Anna Wilbik</dc:creator>
    </item>
    <item>
      <title>Independent RL for Cooperative-Competitive Agents: A Mean-Field Perspective</title>
      <link>https://arxiv.org/abs/2403.11345</link>
      <description>arXiv:2403.11345v2 Announce Type: replace-cross 
Abstract: We address in this paper Reinforcement Learning (RL) among agents that are grouped into teams such that there is cooperation within each team but general-sum (non-zero sum) competition across different teams. To develop an RL method that provably achieves a Nash equilibrium, we focus on a linear-quadratic structure. Moreover, to tackle the non-stationarity induced by multi-agent interactions in the finite population setting, we consider the case where the number of agents within each team is infinite, i.e., the mean-field setting. This results in a General-Sum LQ Mean-Field Type Game (GS-MFTG). We characterize the Nash equilibrium (NE) of the GS-MFTG, under a standard invertibility condition. This MFTG NE is then shown to be $O(1/M)$-NE for the finite population game where $M$ is a lower bound on the number of agents in each team. These structural results motivate an algorithm called Multi-player Receding-horizon Natural Policy Gradient (MRNPG), where each team minimizes its cumulative cost \emph{independently} in a receding-horizon manner. Despite the non-convexity of the problem, we establish that the resulting algorithm converges to a global NE through a novel problem decomposition into sub-problems using backward recursive discrete-time Hamilton-Jacobi-Isaacs (HJI) equations, in which \emph{independent natural policy gradient} is shown to exhibit linear convergence under time-independent diagonal dominance. Numerical studies included corroborate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11345v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 11 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Aneeq uz Zaman, Alec Koppel, Mathieu Lauri\`ere, Tamer Ba\c{s}ar</dc:creator>
    </item>
  </channel>
</rss>
