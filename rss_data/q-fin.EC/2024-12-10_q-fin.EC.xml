<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Dec 2024 02:57:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Measuring Consumer Sensitivity to Audio Advertising: A Long-Run Field Experiment on Pandora Internet Radio</title>
      <link>https://arxiv.org/abs/2412.05516</link>
      <description>arXiv:2412.05516v1 Announce Type: new 
Abstract: A randomized experiment with almost 35 million Pandora listeners enables us to measure the sensitivity of consumers to advertising, an important topic of study in the era of ad-supported digital content provision. The experiment randomized listeners into nine treatment groups, each of which received a different level of audio advertising interrupting their music listening, with the highest treatment group receiving more than twice as many ads as the lowest treatment group. By maintaining consistent treatment assignment for 21 months, we measure long-run demand effects and find ad-load sensitivity three times greater than what we would have obtained from a month-long experiment. We show the negative impact on the number of hours listened, days listened, and probability of listening at all in the final month. Using an experimental design that separately varies the number of commercial interruptions per hour and the number of ads per commercial interruption, we find that listeners primarily respond to the total number of ads per hour, with a slight preference for more frequent but shorter ad breaks. Lastly, we find that increased ad load led to an increase in the number of paid ad-free subscriptions to Pandora. Importantly, we show that observational methods often lead to biased or even directionally incorrect estimates of these effects, highlighting the value of experimental data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05516v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ali Goli, Jason Huang, David Reiley, Nickolai M. Riabov</dc:creator>
    </item>
    <item>
      <title>India's residential space cooling transition: A carbon perspective from 2000 onward</title>
      <link>https://arxiv.org/abs/2412.06360</link>
      <description>arXiv:2412.06360v1 Announce Type: new 
Abstract: As an emerging emitter poised for significant growth in space cooling demand, India requires comprehensive insights into historical emission trends and decarbonization performance to shape future low-carbon cooling strategies. By integrating a bottom-up demand resource energy analysis model and a top-down decomposition method, this study is the first to conduct a state-level analysis of carbon emission trends and the corresponding decarbonization efforts for residential space cooling in urban and rural India from 2000 to 2022. The results indicate that (1) the carbon intensity of residential space cooling in India increased by 292.4% from 2000 to 2022, reaching 513.8 kilograms of carbon dioxide per household. The net state domestic product per capita, representing income, emerged as the primary positive contributor. (2) The increase in carbon emissions from space cooling can be primarily attributed to the use of fans. While fan-based space cooling has nearly saturated Indian urban households, it is anticipated to persist as the primary cooling method in rural households for decades. (3) States with higher decarbonization potential are concentrated in two categories: those with high household income and substantial cooling appliance ownership and those with pronounced unmet cooling demand but low household income and hot climates. Furthermore, it is believed that promoting energy-efficient building designs can be prioritized to achieve affordable space cooling. Overall, this study serves as an effective foundation for formulating and promoting India's future cooling action plan, addressing the country's rising residential cooling demands and striving toward its net-zero goal by 2070.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06360v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ran Yan, Nan Zhou, Minda Ma, Chao Mao</dc:creator>
    </item>
    <item>
      <title>Leveraging Large Language Models to Democratize Access to Costly Financial Datasets for Academic Research</title>
      <link>https://arxiv.org/abs/2412.02065</link>
      <description>arXiv:2412.02065v1 Announce Type: cross 
Abstract: Unequal access to costly datasets essential for empirical research has long hindered researchers from disadvantaged institutions, limiting their ability to contribute to their fields and advance their careers. Recent breakthroughs in Large Language Models (LLMs) have the potential to democratize data access by automating data collection from unstructured sources. We develop and evaluate a novel methodology using GPT-4o-mini within a Retrieval-Augmented Generation (RAG) framework to collect data from corporate disclosures. Our approach achieves human-level accuracy in collecting CEO pay ratios from approximately 10,000 proxy statements and Critical Audit Matters (CAMs) from more than 12,000 10-K filings, with LLM processing times of 9 and 40 minutes respectively, each at a cost under $10. This stands in stark contrast to the hundreds of hours needed for manual collection or the thousands of dollars required for commercial database subscriptions. To foster a more inclusive research community by empowering researchers with limited resources to explore new avenues of inquiry, we share our methodology and the resulting datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02065v1</guid>
      <category>q-fin.GN</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Julian Junyan Wang, Victor Xiaoqi Wang</dc:creator>
    </item>
    <item>
      <title>A Scoping Review of ChatGPT Research in Accounting and Finance</title>
      <link>https://arxiv.org/abs/2412.05731</link>
      <description>arXiv:2412.05731v1 Announce Type: cross 
Abstract: This paper provides a review of recent publications and working papers on ChatGPT and related Large Language Models (LLMs) in accounting and finance. The aim is to understand the current state of research in these two areas and identify potential research opportunities for future inquiry. We identify three common themes from these earlier studies. The first theme focuses on applications of ChatGPT and LLMs in various fields of accounting and finance. The second theme utilizes ChatGPT and LLMs as a new research tool by leveraging their capabilities such as classification, summarization, and text generation. The third theme investigates implications of LLM adoption for accounting and finance professionals, as well as for various organizations and sectors. While these earlier studies provide valuable insights, they leave many important questions unanswered or partially addressed. We propose venues for further exploration and provide technical guidance for researchers seeking to employ ChatGPT and related LLMs as a tool for their research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05731v1</guid>
      <category>q-fin.GN</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.accinf.2024.100715</arxiv:DOI>
      <arxiv:journal_reference>Intl. J. Account. Inf. Syst. 55 (2024): 100715</arxiv:journal_reference>
      <dc:creator>Mengming Michael Dong, Theophanis C. Stratopoulos, Victor Xiaoqi Wang</dc:creator>
    </item>
    <item>
      <title>Unveiling True Talent: The Soccer Factor Model for Skill Evaluation</title>
      <link>https://arxiv.org/abs/2412.05911</link>
      <description>arXiv:2412.05911v1 Announce Type: cross 
Abstract: Evaluating a soccer player's performance can be challenging due to the high costs and small margins involved in recruitment decisions. Raw observational statistics further complicate an accurate individual skill assessment as they do not abstract from the potentially confounding factor of team strength. We introduce the Soccer Factor Model (SFM), which corrects this bias by isolating a player's true skill from the team's influence. We compile a novel data set, web-scraped from publicly available data sources. Our empirical application draws on information of 144 players, playing a total of over 33,000 matches, in seasons 2000/01 through 2023/24. Not only does the SFM allow for a structural interpretation of a player's skill, but also stands out against more reduced-form benchmarks in terms of forecast accuracy. Moreover, we propose Skill- and Performance Above Replacement as metrics for fair cross-player comparisons. These, for example, allow us to settle the discussion about the GOAT of soccer in the first quarter of the twenty-first century.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05911v1</guid>
      <category>stat.AP</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Andorra, Maximilian G\"obel</dc:creator>
    </item>
    <item>
      <title>Unified Merger List in the Container Shipping Industry from 1966 to 2022: A Structural Estimation of M&amp;A Matching</title>
      <link>https://arxiv.org/abs/2310.09938</link>
      <description>arXiv:2310.09938v3 Announce Type: replace 
Abstract: We construct a novel unified merger list in the global container shipping industry between 1966 (the beginning of the industry) and 2022. Combining the list with proprietary data, we construct a structural matching model to describe the historical transition of the importance of a firm's age, size, and geographical proximity on merger decisions. We find that, as a positive factor, a firm's size is more important than a firm's age by 9.858 times as a merger incentive between 1991 and 2005. However, between 2006 and 2022, as a negative factor, a firm's size is more important than a firm's age by 2.013 times, that is, a firm's size works as a disincentive. We also find that the distance between buyer and seller firms works as a disincentive for the whole period, but the importance has dwindled to economic insignificance in recent years. In counterfactual simulations, we observe that the prohibition of mergers between firms in the same country would affect the merger configuration of not only the firms involved in prohibited mergers but also those involved in permitted mergers. Finally, we present interview-based evidence of the consistency between our merger lists, estimations, and counterfactual simulations with the industry experts' historical experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09938v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suguru Otani, Takuma Matsuda</dc:creator>
    </item>
    <item>
      <title>A Global Minimum Tax for Large Firms Only: Implications for Tax Competition</title>
      <link>https://arxiv.org/abs/2404.14302</link>
      <description>arXiv:2404.14302v3 Announce Type: replace 
Abstract: The Global Minimum Tax (GMT) is applied only to firms above a certain size threshold, permitting countries to set differential tax rates for small and large firms. We analyze tax competition among multiple tax havens and a non-haven country for heterogeneous multinationals to evaluate the effects of this partial coverage of GMT. Upon the introduction of a moderately low GMT rate, the havens commit to the single uniform GMT rate for all multinationals. However, gradual increases in the GMT rate induce the havens, and subsequently the non-haven, to adopt discriminatory, lower tax rates for small multinationals. Our calibration exercise shows that the implementation of a 15% GMT rate results in a regime where only the havens adopt split tax rates. Upon GMT introduction, welfare and tax revenues fall in the tax havens but rise in the non-haven, yielding a positive net gain worldwide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14302v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Andreas Haufler, Hayato Kato</dc:creator>
    </item>
    <item>
      <title>Scaling Laws for Economic Productivity: Experimental Evidence in LLM-Assisted Translation</title>
      <link>https://arxiv.org/abs/2409.02391</link>
      <description>arXiv:2409.02391v2 Announce Type: replace 
Abstract: This paper derives "scaling laws"--empirical relationships between the training compute of Large Language Models (LLMs) and their performance--for economic outcomes. In a preregistered online experiment, 300 professional translators completed 1,800 tasks using one of 13 LLMs (or a control). A tenfold increase in model compute improved task completion speed by 12.3%, grades by 0.18 standard deviations, and earnings per minute by 16.1%. Gains were four times larger for lower-skilled workers. These findings suggest continued model scaling could boost U.S. productivity by at least 6.9% over the next decade.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02391v2</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Merali</dc:creator>
    </item>
    <item>
      <title>Blockchain-Based Ad Auctions and Bayesian Persuasion: An Analysis of Advertiser Behavior</title>
      <link>https://arxiv.org/abs/2410.07392</link>
      <description>arXiv:2410.07392v2 Announce Type: replace 
Abstract: This paper explores how ad platforms can utilize Bayesian persuasion within blockchain-based auction systems to strategically influence advertiser behavior despite increased transparency. By integrating game-theoretic models with machine learning techniques and the principles of blockchain technology, we analyze the role of strategic information disclosure in ad auctions. Our findings demonstrate that even in environments with inherent transparency, ad platforms can design signals to affect advertisers' beliefs and bidding strategies. A detailed case study illustrates how machine learning can predict advertiser responses to different signals, leading to optimized signaling strategies that increase expected revenue. The study contributes to the literature by extending Bayesian persuasion models to transparent systems and providing practical insights for auction design in the digital advertising industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07392v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xinyu Li</dc:creator>
    </item>
    <item>
      <title>Trade Wars with Trade Deficits</title>
      <link>https://arxiv.org/abs/2411.15092</link>
      <description>arXiv:2411.15092v2 Announce Type: replace 
Abstract: Trade imbalances significantly alter the welfare implications of tariffs. Using an illustrative model, we show that trade deficits enhance a country's ability to alter its terms of trade, and thereby benefit from tariffs. Greater trade deficits imply higher optimal, or welfare maximizing, tariffs. We compute optimal unilateral and Nash equilibrium tariffs between the United States and China $\unicode{x2014}$ the countries with the largest bilateral trade imbalance $\unicode{x2014}$ using a multi-region, multi-sector applied general equilibrium model with service sectors and input-output linkages, a computationally complex task. Free trade benefits both countries compared to a trade war. Relative to existing tariff rates, however, the United States gains from a trade war with China $\unicode{x2014}$ a result that hinges on their bilateral trade imbalance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15092v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pau Pujolas, Jack Rossbach</dc:creator>
    </item>
    <item>
      <title>As Generative Models Improve, We must Adapt Our Prompts</title>
      <link>https://arxiv.org/abs/2407.14333</link>
      <description>arXiv:2407.14333v3 Announce Type: replace-cross 
Abstract: The recent surge in generative AI has led to new models being introduced almost every month. In light of this rapid progression, we pose and address a central question: to what extent must prompts evolve as the capabilities of generative AI models advance? To answer this question, we conducted an online experiment with N = 1,893 participants where each participant was incentivized to write prompts to reproduce a target image as closely as possible in 10 consecutive tries. Each participant was randomly and blindly assigned to use one of three text-to-image diffusion models: DALL-E 2, its more advanced successor, DALL-E 3, or a version of DALL-E 3 with automatic prompt revision. In total, we collected and analyzed over 18,000 prompts and over 300,000 images. We find that task performance was higher for participants using DALL-E 3 than for those using DALL-E 2. This performance gap corresponds to a noticeable difference in the similarity of participants' images to their target images, and was caused in equal measure by: (1) the increased technical capabilities of DALL-E 3, and (2) endogenous changes in participants' prompting in response to these increased capabilities. Furthermore, while participants assigned to DALL-E 3 with prompt revision still outperformed those assigned to DALL-E 2, automatic prompt revision reduced the benefits of using DALL-E 3 by 58\%. Our results suggest that for generative AI to realize its full impact on the global economy, people, firms, and institutions will need to update their prompts in response to new models. Not doing so could leave more than half of the potential benefits of these AI systems untapped.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14333v3</guid>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 10 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eaman Jahani, Benjamin S. Manning, Joe Zhang, Hong-Yi TuYe, Mohammed Alsobay, Christos Nicolaides, Siddharth Suri, David Holtz</dc:creator>
    </item>
  </channel>
</rss>
