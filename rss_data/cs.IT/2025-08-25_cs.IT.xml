<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 02:20:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Straggler-Resilient Federated Learning over A Hybrid Conventional and Pinching Antenna Network</title>
      <link>https://arxiv.org/abs/2508.15821</link>
      <description>arXiv:2508.15821v1 Announce Type: new 
Abstract: Leveraging pinching antennas in wireless network enabled federated learning (FL) can effectively mitigate the common "straggler" issue in FL by dynamically establishing strong line-of-sight (LoS) links on demand. This letter proposes a hybrid conventional and pinching antenna network (HCPAN) to significantly improve communication efficiency in the non-orthogonal multiple access (NOMA)-enabled FL system. Within this framework, a fuzzy logic-based client classification scheme is first proposed to effectively balance clients' data contributions and communication conditions. Given this classification, we formulate a total time minimization problem to jointly optimize pinching antenna placement and resource allocation. Due to the complexity of variable coupling and non-convexity, a deep reinforcement learning (DRL)-based algorithm is developed to effectively address this problem. Simulation results validate the superiority of the proposed scheme in enhancing FL performance via the optimized deployment of pinching antenna.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15821v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bibo Wu, Fang Fang, Ming Zeng, Xianbin Wang</dc:creator>
    </item>
    <item>
      <title>Tri-Hybrid Beamforming for Radiation-Center Reconfigurable Antenna Array: Spectral Efficiency and Energy Efficiency</title>
      <link>https://arxiv.org/abs/2508.15924</link>
      <description>arXiv:2508.15924v1 Announce Type: new 
Abstract: In this paper, we propose a tri-hybrid beamforming (THBF) architecture based on the radiation-center (RC) reconfigurable antenna array (RCRAA), including the digital beamforming, analog beamforming, and electromagnetic (EM) beamforming, where the EM beamformer design is modeled as RC selection. Aiming at spectral efficiency (SE) maximization subject to the hardware and power consumption constraints, we propose a tri-loop alternating optimization (TLAO) scheme for the THBF design, where the digital and analog beamformers are optimized based on the penalty dual decomposition in the inner and middle loops, and the RC selection is determined through the coordinate descent method in the outer loop. Aiming at energy-efficiency (EE) maximization, we develop a dual quadratic transform-based fractional programming (DQTFP) scheme, where the TLAO scheme is readily used for the THBF design. To reduce the computational complexity, we propose the Lagrange dual transform-based fractional programming (LDTFP) scheme, where each iteration has a closed-form solution. Simulation results demonstrate the great potential of the RCRAA in improving both SE and EE. Compared to the DQTFP scheme, the LDTFP scheme significantly reduces the computational complexity with only minor performance loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15924v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinchen Li, Chenhao Qi, Shiwen Mao, Octavia A. Dobre</dc:creator>
    </item>
    <item>
      <title>Multi-User SLNR-Based Precoding With Gold Nanoparticles in Vehicular VLC Systems</title>
      <link>https://arxiv.org/abs/2508.16075</link>
      <description>arXiv:2508.16075v1 Announce Type: new 
Abstract: Visible spectrum is an emerging frontier in wireless communications for enhancing connectivity and safety in vehicular environments. The vehicular visible light communication (VVLC) system is a key feature in leveraging existing infrastructures, but it still has several critical challenges. Especially, VVLC channels are highly correlated due to the small gap between light emitting diodes (LEDs) in each headlight, making it difficult to increase data rates by spatial multiplexing. In this paper, we exploit recently synthesized gold nanoparticles (GNPs) to reduce the correlation between LEDs, i.e., the chiroptical properties of GNPs for differential absorption depending on the azimuth angle of incident light are used to mitigate the LED correlation. In addition, we adopt a signal-to-leakage-plus-noise ratio (SLNR)-based precoder to support multiple users. The ratio of RGB light sources in each LED also needs to be optimized to maximize the sum SLNR satisfying a white light constraint for illumination since the GNPs can vary the color of transmitted light by the differential absorption across wavelength. The nonconvex optimization problems for precoders and RGB ratios can be solved by the generalized Rayleigh quotient with the approximated shot noise and successive convex approximation (SCA). The simulation results show that the SLNR-based precoder with the optimized RGB ratios significantly improves the sum rate in a multi-user vehicular environment and the secrecy rate in a wiretapping scenario. The proposed SLNR-based precoding verifies that the decorrelation between LEDs and the RGB ratio optimization are essential to enhance the VVLC performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16075v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geonho Han, Hyuckjin Choi, Hyesang Cho, Jeong Hyeon Han, Ki Tae Nam, Junil Choi</dc:creator>
    </item>
    <item>
      <title>Implicit and Explicit Formulas of the Joint RDF for a Tuple of Multivariate Gaussian Sources with Individual Square-Error Distortions</title>
      <link>https://arxiv.org/abs/2508.16301</link>
      <description>arXiv:2508.16301v1 Announce Type: new 
Abstract: This paper analyzes the joint Rate Distortion Function (RDF) of correlated multivariate Gaussian sources with individual square-error distortions. Leveraging Hotelling's canonical variable form, presented is a closed-form characterization of the joint RDF, that involves {a system of nonlinear equations. Furthermore, for the special case of symmetric distortions (i.e., equal distortions), the joint RDF is explicitly expressed in terms of} two water-filling variables. The results greatly improve our understanding and advance the development of closed-form solutions of the joint RDF for multivariate Gaussian sources with individual square-error distortions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16301v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evagoras Stylianou, Charalambos D. Charalambous, Themistoklis Charalambous</dc:creator>
    </item>
    <item>
      <title>Agentic AI Empowered Multi-UAV Trajectory Optimization in Low-Altitude Economy Networks</title>
      <link>https://arxiv.org/abs/2508.16379</link>
      <description>arXiv:2508.16379v1 Announce Type: new 
Abstract: This paper proposes a novel Agentic Retrieval-augmented generation with Mamba-Attention Integrated Transformer (ARMAIT) framework for multi-Unmanned Aerial Vehicle (UAV) trajectory optimization. The framework is built upon Large Language Models (LLMs), incorporating Retrieval-Augmented Generation (RAG) empowered by Agentic AI and integrated with a UAV-specific knowledge base. Through the Agentic RAG, the LLM autonomously interprets high-level task requirements and identifies the key components necessary for trajectory optimization, including model inputs and outputs, network architecture, reward functions, and task constraints. To support efficient modeling across different system scales, we introduce the Mamba-Attention Integrated Transformer (MAIT), a hybrid neural architecture that combines the long-range dependency modeling capability of attention mechanisms with the efficient temporal dynamic representation of Mamba. Furthermore, a Trajectory-Group Relative Policy Optimization (T-GRPO) method is proposed to achieve unified policy gradient optimization in both discrete and continuous trajectory spaces for MAIT training. Extensive experimental results validate the feasibility and effectiveness of the proposed ARMAIT framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16379v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feibo Jiang, Li Dong, Xitao Pan, Kezhi Wang, Cunhua Pan</dc:creator>
    </item>
    <item>
      <title>Enhanced Successive Cancellation List Decoder for Long Polar Codes Targeting 6G Air Interface</title>
      <link>https://arxiv.org/abs/2508.16498</link>
      <description>arXiv:2508.16498v1 Announce Type: new 
Abstract: The 6th generation communication standard's air interface requires innovation in channel coding to fulfill anticipated energy and area cost reduction requirements. In this paper, we propose algorithmic techniques to enable the implementation of long polar codes (e.g., length 8K bits) in next-generation communications standards by addressing key challenges in memory usage and computational complexity presented by successive decoding list (SCL) polar decoding. Perturbation-enhanced (PE) successive cancelation list (SCL) decoders with a list size of $L$ reach the decoding performance of the SCL decoder with a list size of $2L$. The proposed bias-enhanced (BE) SCL decoders, which simplifies the PE SCL decoder based on insights gained by an ablation study, returns similar decoding performance to PE SCL decoders. Also, proposed BE generalized partitioned SCL (GPSCL) decoders with a list size of $8$ have a $67\%$ reduction in the memory usage and similar decoding performance compared to SCL decoders with a list size of $16$. Furthermore, input-distribution-aware (IDA) decoding is applied to BE GPSCL decoders. Up to $5.4\times$ reduction in the computational complexity is achieved compared to SCL decoders with a list size of $16$. The degraded decoding performance is at most $0.05\text{ dB}$ compared to BE GPSCL decoders without IDA decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16498v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajie Li, Sihui Shen, Warren J. Gross</dc:creator>
    </item>
    <item>
      <title>Exploiting Information Redundancy in Attention Maps for Extreme Quantization of Vision Transformers</title>
      <link>https://arxiv.org/abs/2508.16311</link>
      <description>arXiv:2508.16311v1 Announce Type: cross 
Abstract: Transformer models rely on Multi-Head Self-Attention (MHSA) mechanisms, where each attention head contributes to the final representation. However, their computational complexity and high memory demands due to MHSA hinders their deployment at the edge. In this work, we analyze and exploit information redundancy in attention maps to accelerate model inference. By quantifying the information captured by each attention head using Shannon entropy, our analysis reveals that attention heads with lower entropy, i.e., exhibiting more deterministic behavior, tend to contribute less information, motivating targeted compression strategies. Relying on these insights, we propose Entropy Attention Maps (EAM), a model that freezes the weights of low-entropy attention maps and quantizes these values to low precision to avoid redundant re-computation. Empirical validation on ImageNet-1k shows that EAM achieves similar or higher accuracy at $\leq$20\% sparsity in attention maps and competitive performance beyond this level for the DeiT and Swin Transformer models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16311v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lucas Maisonnave, Karim Haroun, Tom Pegeot</dc:creator>
    </item>
    <item>
      <title>ML-PWS: Estimating the Mutual Information Between Experimental Time Series Using Neural Networks</title>
      <link>https://arxiv.org/abs/2508.16509</link>
      <description>arXiv:2508.16509v1 Announce Type: cross 
Abstract: The ability to quantify information transmission is crucial for the analysis and design of natural and engineered systems. The information transmission rate is the fundamental measure for systems with time-varying signals, yet computing it is extremely challenging. In particular, the rate cannot be obtained directly from experimental time-series data without approximations, because of the high dimensionality of the signal trajectory space. Path Weight Sampling (PWS) is a computational technique that makes it possible to obtain the information rate exactly for any stochastic system. However, it requires a mathematical model of the system of interest, be it described by a master equation or a set of differential equations. Here, we present a technique that employs Machine Learning (ML) to develop a generative model from experimental time-series data, which is then combined with PWS to obtain the information rate. We demonstrate the accuracy of this technique, called ML-PWS, by comparing its results on synthetic time-series data generated from a non-linear model against ground-truth results obtained by applying PWS directly to the same model. We illustrate the utility of ML-PWS by applying it to neuronal time-series data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16509v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Reinhardt, Ga\v{s}per Tka\v{c}ik, Pieter Rein ten Wolde</dc:creator>
    </item>
    <item>
      <title>Optimal Hamiltonian for a quantum state with finite entropy</title>
      <link>https://arxiv.org/abs/2508.16575</link>
      <description>arXiv:2508.16575v1 Announce Type: cross 
Abstract: We consider the following task: how for a given quantum state $\rho$ to find a grounded Hamiltonian $H$ such that $\mathrm{Tr}H\rho\leq E_0&lt;+\infty$ in such a way that the von Neumann entropy of the Gibbs state $\gamma_H(E)$ corresponding to a given energy $E&gt;0$ be as small as possible.
  We show that for any mixed state $\rho$ with finite entropy and any $E&gt;0$ there is a unique solution $H(\rho,E_0,E)$ of the above problem which we call optimal Hamiltonian for this state. Explicit expressions for $H(\rho,E_0,E)$ and $S(\gamma_H(E))$ with $H=H(\rho,E_0,E)$ are obtained. Several examples are considered.
  A brief overview of possible applications is given (with the intention to give a detailed description in a separate article).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16575v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. E. Shirokov</dc:creator>
    </item>
    <item>
      <title>Computation and Communication Co-scheduling for Multi-Task Remote Inference</title>
      <link>https://arxiv.org/abs/2501.04231</link>
      <description>arXiv:2501.04231v2 Announce Type: replace 
Abstract: In multi-task remote inference systems, an intelligent receiver (e.g., command center) performs multiple inference tasks (e.g., target detection) using data features received from several remote sources (e.g., edge devices). Key challenges to facilitating timely inference in these systems arise from (i) limited computational power of the sources to produce features from their inputs, and (ii) limited communication resources of the channels to carry simultaneous feature transmissions to the receiver. We develop a novel computation and communication co-scheduling methodology which determines feature generation and transmission scheduling to minimize inference errors subject to these resource constraints. Specifically, we formulate the co-scheduling problem as a weakly-coupled Markov decision process with Age of Information (AoI)-based timeliness gauging the inference errors. To overcome its PSPACE-hard complexity, we analyze a Lagrangian relaxation of the problem, which yields gain indices assessing the improvement in inference error for each potential feature generation-transmission scheduling action. Based on this, we develop a reoptimized maximum gain first (MGF) policy. We show that this policy is asymptotically optimal for the original problem as the number of inference tasks and the available communication and computation resources increase, provided the ratio among them remains fixed. Experiments demonstrate that reoptimized MGF obtains significant improvements over baseline policies for varying numbers of tasks, channels, and sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04231v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Kamran Chowdhury Shisher, Adam Piaseczny, Yin Sun, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>Design and Analysis of a Concatenated Code for Intersymbol Interference Wiretap Channels</title>
      <link>https://arxiv.org/abs/2501.07561</link>
      <description>arXiv:2501.07561v3 Announce Type: replace 
Abstract: We propose a two-stage concatenated coding scheme for reliable and information-theoretically secure communication over intersymbol interference wiretap channels. Motivated by the theoretical coding strategies that achieve the secrecy capacity, our scheme integrates low-density parity-check (LDPC) codes in the outer stage, forming a nested structure of wiretap codes, with trellis codes in the inner stage to improve achievable secure rates. The trellis code is specifically designed to transform the uniformly distributed codewords produced by the LDPC code stage into a Markov process, achieving tight lower bounds on the secrecy capacity. We further estimate the information leakage rate of the proposed coding scheme using an upper bound. To meet the weak secrecy criterion, we optimize degree distributions of the irregular LDPC codes at the outer stage, essentially driving the estimated upper bound on the information leakage rate to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.07561v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aria Nouri, Reza Asvadi, Jun Chen</dc:creator>
    </item>
    <item>
      <title>Information-Theoretic Decentralized Secure Aggregation with Collusion Resilience</title>
      <link>https://arxiv.org/abs/2508.00596</link>
      <description>arXiv:2508.00596v2 Announce Type: replace 
Abstract: In decentralized federated learning (FL), multiple clients collaboratively learn a shared machine learning (ML) model by leveraging their privately held datasets distributed across the network, through interactive exchange of the intermediate model updates. To ensure data security, cryptographic techniques are commonly employed to protect model updates during aggregation. Despite growing interest in secure aggregation, existing works predominantly focus on protocol design and computational guarantees, with limited understanding of the fundamental information-theoretic limits of such systems. Moreover, optimal bounds on communication and key usage remain unknown in decentralized settings, where no central aggregator is available. Motivated by these gaps, we study the problem of decentralized secure aggregation (DSA) from an information-theoretic perspective. Specifically, we consider a network of $K$ fully-connected users, each holding a private input -- an abstraction of local training data -- who aim to securely compute the sum of all inputs. The security constraint requires that no user learns anything beyond the input sum, even when colluding with up to $T$ other users. We characterize the optimal rate region, which specifies the minimum achievable communication and secret key rates for DSA. In particular, we show that to securely compute one symbol of the desired input sum, each user must (i) transmit at least one symbol to others, (ii) hold at least one symbol of secret key, and (iii) all users must collectively hold no fewer than $K - 1$ independent key symbols. Our results establish the fundamental performance limits of DSA, providing insights for the design of provably secure and communication-efficient protocols in distributed learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00596v2</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhang, Zhou Li, Shuangyang Li, Kai Wan, Derrick Wing Kwan Ng, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Optimum 1-Step Majority-Logic Decoding of Binary Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2508.08736</link>
      <description>arXiv:2508.08736v2 Announce Type: replace 
Abstract: The classical majority-logic decoder proposed by Reed for Reed-Muller codes RM(r, m) of order r and length 2^m, unfolds in r+1 sequential steps, decoding message symbols from highest to lowest degree. Several follow-up decoding algorithms reduced the number of steps, but for a limited set of parameters, or at the expense of reduced performance, or relying on the existence of some combinatorial structures. We show that any one-step majority-logic decoder-that is, a decoder performing all majority votes in one step simultaneously without sequential processing-can correct at most d_min/4 errors for all values of r and m, where d_min denotes the code's minimum distance. We then introduce a new hard-decision decoder that completes the decoding in a single step and attains this error-correction limit. It applies to all r and m, and can be viewed as a parallel realization of Reed's original algorithm, decoding all message symbols simultaneously. Remarkably, we also prove that the decoder is optimum in the erasure setting: it recovers the message from any erasure pattern of up to d_min-1 symbols-the theoretical limit. To our knowledge, this is the first 1-step decoder for RM codes that achieves both optimal erasure correction and the maximum one-step error correction capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08736v2</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Ly, Emina Soljanin</dc:creator>
    </item>
    <item>
      <title>Bayesian Multi-wavelength Imaging of the LMC SN1987A with SRG/eROSITA</title>
      <link>https://arxiv.org/abs/2410.14599</link>
      <description>arXiv:2410.14599v2 Announce Type: replace-cross 
Abstract: The eROSITA Early Data Release (EDR) and eROSITA All-Sky Survey (eRASS1) data have already revealed a remarkable number of undiscovered X-ray sources. Using Bayesian inference and generative modeling techniques for X-ray imaging, we aim to increase the sensitivity and scientific value of these observations by denoising, deconvolving, and decomposing the X-ray sky. Leveraging information field theory, we can exploit the spatial and spectral correlation structures of the different physical components of the sky with non-parametric priors to enhance the image reconstruction. By incorporating instrumental effects into the forward model, we develop a comprehensive Bayesian imaging algorithm for eROSITA pointing observations. Finally, we apply the developed algorithm to EDR data of the Large Magellanic Cloud (LMC) SN1987A, fusing data sets from observations made by five different telescope modules. The final result is a denoised, deconvolved, and decomposed view of the LMC, which enables the analysis of its fine-scale structures, the identification of point sources in this region, and enhanced calibration for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14599v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.16918521</arxiv:DOI>
      <dc:creator>Vincent Eberle, Matteo Guardiani, Margret Westerkamp, Philipp Frank, Michael Freyberg, Mara Salvato, Torsten En{\ss}lin</dc:creator>
    </item>
    <item>
      <title>Fundamental Limits of Matrix Sensing: Exact Asymptotics, Universality, and Applications</title>
      <link>https://arxiv.org/abs/2503.14121</link>
      <description>arXiv:2503.14121v2 Announce Type: replace-cross 
Abstract: In the matrix sensing problem, one wishes to reconstruct a matrix from (possibly noisy) observations of its linear projections along given directions. We consider this model in the high-dimensional limit: while previous works on this model primarily focused on the recovery of low-rank matrices, we consider in this work more general classes of structured signal matrices with potentially large rank, e.g. a product of two matrices of sizes proportional to the dimension. We provide rigorous asymptotic equations characterizing the Bayes-optimal learning performance from a number of samples which is proportional to the number of entries in the matrix. Our proof is composed of three key ingredients: $(i)$ we prove universality properties to handle structured sensing matrices, related to the ''Gaussian equivalence'' phenomenon in statistical learning, $(ii)$ we provide a sharp characterization of Bayes-optimal learning in generalized linear models with Gaussian data and structured matrix priors, generalizing previously studied settings, and $(iii)$ we leverage previous works on the problem of matrix denoising. The generality of our results allow for a variety of applications: notably, we mathematically establish predictions obtained via non-rigorous methods from statistical physics in [ETB+24] regarding Bilinear Sequence Regression, a benchmark model for learning from sequences of tokens, and in [MTM+24] on Bayes-optimal learning in neural networks with quadratic activation function, and width proportional to the dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14121v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhou Xu, Antoine Maillard, Lenka Zdeborov\'a, Florent Krzakala</dc:creator>
    </item>
    <item>
      <title>VIBE: Video-to-Text Information Bottleneck Evaluation for TL;DR</title>
      <link>https://arxiv.org/abs/2505.17423</link>
      <description>arXiv:2505.17423v2 Announce Type: replace-cross 
Abstract: Many decision-making tasks, where both accuracy and efficiency matter, still require human supervision. For example, tasks like traffic officers reviewing hour-long dashcam footage or researchers screening conference videos can benefit from concise summaries that reduce cognitive load and save time. Yet current vision-language models (VLMs) often produce verbose, redundant outputs that hinder task performance. Existing video caption evaluation depends on costly human annotations and overlooks the summaries' utility in downstream tasks. We address these gaps with Video-to-text Information Bottleneck Evaluation (VIBE), an annotation-free method that scores VLM outputs using two metrics: grounding (how well the summary aligns with visual content) and utility (how informative it is for the task). VIBE selects from randomly sampled VLM outputs by ranking them according to the two scores to support effective human decision-making. Human studies on LearningPaper24, SUTD-TrafficQA, and LongVideoBench show that summaries selected by VIBE consistently improve performance-boosting task accuracy by up to 61.23% and reducing response time by 75.77% compared to naive VLM summaries or raw video.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17423v2</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenghui Chen, Po-han Li, Sandeep Chinchali, Ufuk Topcu</dc:creator>
    </item>
  </channel>
</rss>
