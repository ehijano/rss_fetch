<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2024 04:00:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Global Solution Algorithm for AC Optimal Power Flow through Linear Constrained Quadratic Programming</title>
      <link>https://arxiv.org/abs/2406.11899</link>
      <description>arXiv:2406.11899v1 Announce Type: new 
Abstract: We formulate the Alternating Current Optimal Power Flow Problem (ACOPF) as a Linear Constrained Quadratic Program (LCQP) with many negative eigenvalues ($r$) and linear constraints, making it NP-hard. We propose two algorithms, Feasible Successive Linear Programming (FSLP) and Feasible Branch-and-Bound (FBB), for a global optimal solution. These use optimization strategies like bounded successive linear programming, convex relaxation, initialization, and branch-and-bound to find a globally optimal solution within a predefined $\epsilon$-tolerance. The complexity of FSLP and FBB is $\mathcal{O}\left(N \prod_{i=1}^r\left\lceil\frac{\sqrt{r}(t_u^i-t_l^i)}{2 \sqrt{\epsilon}}\right\rceil\right)$, where $N$ is the complexity of solving subproblems at each FBB node. Variables $t_l$ and $t_u$ are the lower and upper bounds of $t$, respectively, and $-|t|^2$ is the negative quadratic component in the ACOPF objective function. We use penalized semidefinite modeling, convex relaxation, and line search to design a globally feasible branch-and-bound algorithm for the LCQP form of ACOPF, finding an optimal solution within $\epsilon$-tolerance. Initial results show FSLP and FBB can find global optimal solutions for large-scale ACOPF instances, even with large $r$, and outperform other methods in most PG-lib tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11899v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Barati</dc:creator>
    </item>
    <item>
      <title>Practical Applications of Unidimensional Optimization Using Octave</title>
      <link>https://arxiv.org/abs/2406.11910</link>
      <description>arXiv:2406.11910v1 Announce Type: new 
Abstract: This paper suggests integrating one-dimensional optimization methods to tackle diverse problems, emphasizing their significance in resolving practical issues and applying mathematical principles to real-world contexts. It focuses on employing the Octave programming language, backed by specific examples, to simplify the practical application of mathematical concepts and improve problem-solving abilities. The research aims to assess the effect on students' comprehension of one-dimensional optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11910v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erick Clapton de Lima Silva, Francisco M\'arcio Barboza</dc:creator>
    </item>
    <item>
      <title>Convergence rates of S.O.S hierarchies for polynomial semidefinite programs</title>
      <link>https://arxiv.org/abs/2406.12013</link>
      <description>arXiv:2406.12013v1 Announce Type: new 
Abstract: We introduce a S.O.S hierarchy of lower bounds for a polynomial optimization problem whose constraint is expressed as a matrix polynomial semidefinite condition. Our approach involves utilizing a penalty function framework to directly address the matrix-based constraint, making it applicable to both discrete and continuous polynomial optimization problems. We investigate the convergence rates of these bounds in both problem types. The proposed method yields a variation of Putinar's theorem tailored for positive polynomials within a compact semidefinite set, defined by a matrix polynomial semidefinite constraint. More specifically, we derive novel insights into the convergence rates and degree of additional terms in the representation within this modified version of Putinar's theorem, based on the Jackson's theorem and a version of {\L}ojasiewicz inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12013v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hoang Anh Tran, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Block Matrix and Tensor Randomized Kaczmarz Methods for Linear Feasibility Problems</title>
      <link>https://arxiv.org/abs/2406.12021</link>
      <description>arXiv:2406.12021v1 Announce Type: new 
Abstract: The randomized Kaczmarz methods are a popular and effective family of iterative methods for solving large-scale linear systems of equations, which have also been applied to linear feasibility problems. In this work, we propose a new block variant of the randomized Kaczmarz method, B-MRK, for solving linear feasibility problems defined by matrices. We show that B-MRK converges linearly in expectation to the feasible region.Furthermore, we extend the method to solve tensor linear feasibility problems defined under the tensor t-product. A tensor randomized Kaczmarz (TRK) method, TRK-L, is proposed for solving linear feasibility problems that involve mixed equality and inequality constraints. Additionally, we introduce another TRK method, TRK-LB, specifically tailored for cases where the feasible region is defined by linear equality constraints coupled with bound constraints on the variables. We show that both of the TRK methods converge linearly in expectation to the feasible region. Moreover, the effectiveness of our methods is demonstrated through numerical experiments on various Gaussian random data and applications in image deblurring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12021v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minxin Zhang, Jamie Haddock, Deanna Needell</dc:creator>
    </item>
    <item>
      <title>Patient Assignment and Prioritization for Multi-Stage Care with Reentrance</title>
      <link>https://arxiv.org/abs/2406.12135</link>
      <description>arXiv:2406.12135v1 Announce Type: new 
Abstract: In this paper, we study a queueing model that incorporates patient reentrance to reflect patients' recurring requests for nurse care and their rest periods between these requests. Within this framework, we address two levels of decision-making: the priority discipline decision for each nurse and the nurse-patient assignment problem. We introduce the shortest-first and longest-first rules in the priority discipline decision problem and show the condition under which each policy excels through theoretical analysis and comprehensive simulations. For the nurse-patient assignment problem, we propose two heuristic policies. We show that the policy maximizing the immediate decrease in holding costs outperforms the alternative policy, which considers the long-term aggregate holding cost. Additionally, both proposed policies significantly surpass the benchmark policy, which does not utilize queue length information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12135v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Liu, Mengshi Lu, Pengyi Shi</dc:creator>
    </item>
    <item>
      <title>Expected Bipartite Matching Distance in A $D$-dimensional $L^p$ Space: Approximate Closed-form Formulas and Applications to Mobility Services</title>
      <link>https://arxiv.org/abs/2406.12174</link>
      <description>arXiv:2406.12174v1 Announce Type: new 
Abstract: Although many well-known algorithms can solve the bipartite matching problem instance efficiently, it remains an open question how one could estimate the expected optimal matching distance for arbitrary numbers of randomly distributed vertices in a $D$-dimensional $L^p$ space (referred to as a random bipartite matching problem, or RBMP). This paper proposes an analytical model with closed-form formulas (without statistical curve-fitting) that estimate both the probability distribution and expectation of the optimal matching distance of RBMP. Simpler asymptotic approximations of the formulas are also developed for some special cases. A series of Monte-Carlo simulation experiments are conducted to verify the accuracy of the proposed formulas under varying conditions. These proposed distance estimates could be key for strategic performance evaluation and resource planning in a wide variety of application contexts. To illustrate their usefulness, we focus on mobility service systems where matches must be made between customers and service vehicles that are randomly distributed over time and space. We show how the proposed distance formulas provide a theoretical foundation for the empirically assumed Cobb-Douglas matching function for taxi systems, and reveal conditions under which the matching function can be suitable. Our formulas can also be easily incorporated into optimization models to select taxi operation strategies (e.g., whether newly arriving customers shall be instantly matched or pooled into a batch for matching). Agent-based simulations are conducted to verify the predicted performance of the demand pooling strategy for two types of e-hailing taxi systems. The results not only demonstrate the accuracy of the proposed model estimates under various service conditions, but also offer valuable managerial insights for service operators to optimize their strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12174v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shiyu Shen, Yuhui Zhai, Yanfeng Ouyang</dc:creator>
    </item>
    <item>
      <title>Stability of Data-Dependent Ridge-Regularization for Inverse Problems</title>
      <link>https://arxiv.org/abs/2406.12289</link>
      <description>arXiv:2406.12289v1 Announce Type: new 
Abstract: Theoretical guarantees for the robust solution of inverse problems have important implications for applications. To achieve both guarantees and high reconstruction quality, we propose to learn a pixel-based ridge regularizer with a data-dependent and spatially-varying regularization strength. For this architecture, we establish the existence of solutions to the associated variational problem and the stability of its solution operator. Further, we prove that the reconstruction forms a maximum-a-posteriori approach. Simulations for biomedical imaging and material sciences demonstrate that the approach yields high-quality reconstructions even if only a small instance-specific training set is available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12289v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Neumayer, Fabian Altekr\"uger</dc:creator>
    </item>
    <item>
      <title>Effective Generation of Feasible Solutions for Integer Programming via Guided Diffusion</title>
      <link>https://arxiv.org/abs/2406.12349</link>
      <description>arXiv:2406.12349v1 Announce Type: new 
Abstract: Feasible solutions are crucial for Integer Programming (IP) since they can substantially speed up the solving process. In many applications, similar IP instances often exhibit similar structures and shared solution distributions, which can be potentially modeled by deep learning methods. Unfortunately, existing deep-learning-based algorithms, such as Neural Diving and Predict-and-search framework, are limited to generating only partial feasible solutions, and they must rely on solvers like SCIP and Gurobi to complete the solutions for a given IP problem. In this paper, we propose a novel framework that generates complete feasible solutions end-to-end. Our framework leverages contrastive learning to characterize the relationship between IP instances and solutions, and learns latent embeddings for both IP instances and their solutions. Further, the framework employs diffusion models to learn the distribution of solution embeddings conditioned on IP representations, with a dedicated guided sampling strategy that accounts for both constraints and objectives. We empirically evaluate our framework on four typical datasets of IP problems, and show that it effectively generates complete feasible solutions with a high probability (&gt; 89.7 \%) without the reliance of Solvers and the quality of solutions is comparable to the best heuristic solutions from Gurobi. Furthermore, by integrating our method's sampled partial solutions with the CompleteSol heuristic from SCIP, the resulting feasible solutions outperform those from state-of-the-art methods across all datasets, exhibiting a 3.7 to 33.7\% improvement in the gap to optimal values, and maintaining a feasible ratio of over 99.7\% for all datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12349v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Zeng, Jiaqi Wang, Avirup Das, Junying He, Kunpeng Han, Haoyuan Hu, Mingfei Sun</dc:creator>
    </item>
    <item>
      <title>Affordable mixed-integer Lagrangian methods: optimality conditions and convergence analysis</title>
      <link>https://arxiv.org/abs/2406.12436</link>
      <description>arXiv:2406.12436v1 Announce Type: new 
Abstract: Necessary optimality conditions in Lagrangian form and the augmented Lagrangian framework are extended to mixed-integer nonlinear optimization, without any convexity assumptions. Building upon a recently developed notion of local optimality for problems with polyhedral and integrality constraints, a characterization of local minimizers and critical points is given for problems including also nonlinear constraints. This approach lays the foundations for developing affordable sequential minimization algorithms with convergence guarantees to critical points from arbitrary initializations. A primal-dual perspective, a local saddle point property, and the dual relationships with the proximal point algorithm are also advanced in the presence of integer variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12436v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto De Marchi</dc:creator>
    </item>
    <item>
      <title>First-Order Methods for Linearly Constrained Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2406.12771</link>
      <description>arXiv:2406.12771v1 Announce Type: new 
Abstract: Algorithms for bilevel optimization often encounter Hessian computations, which are prohibitive in high dimensions. While recent works offer first-order methods for unconstrained bilevel problems, the constrained setting remains relatively underexplored. We present first-order linearly constrained optimization methods with finite-time hypergradient stationarity guarantees. For linear equality constraints, we attain $\epsilon$-stationarity in $\widetilde{O}(\epsilon^{-2})$ gradient oracle calls, which is nearly-optimal. For linear inequality constraints, we attain $(\delta,\epsilon)$-Goldstein stationarity in $\widetilde{O}(d{\delta^{-1} \epsilon^{-3}})$ gradient oracle calls, where $d$ is the upper-level dimension. Finally, we obtain for the linear inequality setting dimension-free rates of $\widetilde{O}({\delta^{-1} \epsilon^{-4}})$ oracle complexity under the additional assumption of oracle access to the optimal dual variable. Along the way, we develop new nonsmooth nonconvex optimization methods with inexact oracles. We verify these guarantees with preliminary numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12771v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Kornowski, Swati Padmanabhan, Kai Wang, Zhe Zhang, Suvrit Sra</dc:creator>
    </item>
    <item>
      <title>A Benchmark for Maximum Cut: Towards Standardization of the Evaluation of Learned Heuristics for Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2406.11897</link>
      <description>arXiv:2406.11897v1 Announce Type: cross 
Abstract: Recently, there has been much work on the design of general heuristics for graph-based, combinatorial optimization problems via the incorporation of Graph Neural Networks (GNNs) to learn distribution-specific solution structures.However, there is a lack of consistency in the evaluation of these heuristics, in terms of the baselines and instances chosen, which makes it difficult to assess the relative performance of the algorithms. In this paper, we propose an open-source benchmark suite MaxCut-Bench dedicated to the NP-hard Maximum Cut problem in both its weighted and unweighted variants, based on a careful selection of instances curated from diverse graph datasets. The suite offers a unified interface to various heuristics, both traditional and machine learning-based. Next, we use the benchmark in an attempt to systematically corroborate or reproduce the results of several, popular learning-based approaches, including S2V-DQN [31], ECO-DQN [4], among others, in terms of three dimensions: objective value, generalization, and scalability. Our empirical results show that several of the learned heuristics fail to outperform a naive greedy algorithm, and that only one of them consistently outperforms Tabu Search, a simple, general heuristic based upon local search. Furthermore, we find that the performance of ECO-DQN remains the same or is improved if the GNN is replaced by a simple linear regression on a subset of the features that are related to Tabu Search. Code, data, and pretrained models are available at: \url{https://github.com/ankurnath/MaxCut-Bench}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11897v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ankur Nath, Alan Kuhnle</dc:creator>
    </item>
    <item>
      <title>Optimal withdrawals in a general diffusion model with control rates subject to a state-dependent upper bound</title>
      <link>https://arxiv.org/abs/2406.12067</link>
      <description>arXiv:2406.12067v1 Announce Type: cross 
Abstract: We consider a classical stochastic control problem in which a diffusion process is controlled by a withdrawal process up to a termination time. The objective is to maximize the expected discounted value of the withdrawals until the first-passage time below level zero. In this work, we are considering absolutely continuous control strategies in a general diffusion model. Our main contribution is a solution to the control problem under study, which is achieved by using a probabilistic guess-and-verify approach. We prove that the optimal strategy belongs to the family of bang-bang strategies, i.e. strategies in which, above an optimal barrier level, we withdraw at the highest-allowed rate, while no withdrawals are made below this barrier. Some nontrivial examples are studied numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12067v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H\'el\`ene Gu\'erin, Dante Mata, Jean-Fran\c{c}ois Renaud, Alexandre Roch</dc:creator>
    </item>
    <item>
      <title>$L^p$ asymptotic stability of 1D damped wave equation with nonlinear distributed damping</title>
      <link>https://arxiv.org/abs/2406.12085</link>
      <description>arXiv:2406.12085v1 Announce Type: cross 
Abstract: In this paper, we study the one-dimensional wave equation with localized nonlinear damping and Dirichlet boundary conditions, in the $L^p$ framework, with $p\in [1,\infty)$.
  We start by addressing the well-posedness problem. We prove the existence and the uniqueness of weak and strong solutions for $p\in [1,\infty)$, under suitable assumptions on the damping function.
  Then we study the asymptotic behaviour of the associated energy when $p \in (1,\infty)$, and we provide decay estimates that appear to be almost optimal as compared to a similar problem with boundary damping.
  Our study is motivated by earlier works, in particular, \cite{Haraux2009, Chitour-Marx-Prieur-2020}. Our proofs combine arguments from \cite{KMJC2022} (wave equation in the $L^p$ framework with a linear damping) with a technique of weighted energy estimates (\cite{PM-COCV}) and new integral inequalities when $p&gt;2$, and with convex analysis tools when $p\in (1,2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12085v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yacine Chitour, Meryem Kafnemer, Patrick Martinez, Benmiloud Mebkhout</dc:creator>
    </item>
    <item>
      <title>An Optimal Transport Approach for Network Regression</title>
      <link>https://arxiv.org/abs/2406.12204</link>
      <description>arXiv:2406.12204v1 Announce Type: cross 
Abstract: We study the problem of network regression, where one is interested in how the topology of a network changes as a function of Euclidean covariates. We build upon recent developments in generalized regression models on metric spaces based on Fr\'echet means and propose a network regression method using the Wasserstein metric. We show that when representing graphs as multivariate Gaussian distributions, the network regression problem requires the computation of a Riemannian center of mass (i.e., Fr\'echet means). Fr\'echet means with non-negative weights translates into a barycenter problem and can be efficiently computed using fixed point iterations. Although the convergence guarantees of fixed-point iterations for the computation of Wasserstein affine averages remain an open problem, we provide evidence of convergence in a large number of synthetic and real-data scenarios. Extensive numerical results show that the proposed approach improves existing procedures by accurately accounting for graph size, topology, and sparsity in synthetic experiments. Additionally, real-world experiments using the proposed approach result in higher Coefficient of Determination ($R^{2}$) values and lower mean squared prediction error (MSPE), cementing improved prediction capabilities in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12204v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex G. Zalles, Kai M. Hung, Ann E. Finneran, Lydia Beaudrot, C\'esar A. Uribe</dc:creator>
    </item>
    <item>
      <title>Discrete Variable Topology Optimization Using Multi-Cut Formulation and Adaptive Trust Regions</title>
      <link>https://arxiv.org/abs/2406.12215</link>
      <description>arXiv:2406.12215v1 Announce Type: cross 
Abstract: We present a new framework for solving general topology optimization (TO) problems that find an optimal material distribution within a design space to maximize the performance of a structure while satisfying design constraints. These problems involve state variables that nonlinearly depend on the design variables, with objective functions that can be convex or non-convex, and may include multiple candidate materials. The framework is designed to greatly enhance computational efficiency, primarily by diminishing optimization iteration counts and thereby reducing the solving of associated state-equilibrium partial differential equations (PDEs). It maintains binary design variables and addresses the large-scale mixed integer nonlinear programming (MINLP) problem that arises from discretizing the design space and PDEs. The core of this framework is the integration of the generalized Benders' decomposition and adaptive trust regions. The trust-region radius adapts based on a merit function. To mitigate ill-conditioning due to extreme parameter values, we further introduce a parameter relaxation scheme where two parameters are relaxed in stages at different paces. Numerical tests validate the framework's superior performance, including minimum compliance and compliant mechanism problems in single-material and multi-material designs. We compare our results with those of other methods and demonstrate significant reductions in optimization iterations by about one order of magnitude, while maintaining comparable optimal objective function values. As the design variables and constraints increase, the framework maintains consistent solution quality and efficiency, underscoring its good scalability. We anticipate this framework will be especially advantageous for TO applications involving substantial design variables and constraints and requiring significant computational resources for PDE solving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12215v1</guid>
      <category>math.NA</category>
      <category>cs.GR</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zisheng Ye, Wenxiao Pan</dc:creator>
    </item>
    <item>
      <title>Robust dividend policy: Equivalence of Epstein-Zin and Maenhout preferences</title>
      <link>https://arxiv.org/abs/2406.12305</link>
      <description>arXiv:2406.12305v1 Announce Type: cross 
Abstract: In a continuous-time economy, this study formulates the Epstein-Zin (EZ) preference for the discounted dividend (or cash payouts) of stockholders as an EZ singular control utility. We show that such a problem is well-defined and equivalent to the robust dividend policy set by the firm's executive in the sense of Maenhout's ambiguity-averse preference. While the firm's executive announces the expected future earnings in financial reports, they also signal the firm's confidence in the expected earnings through dividend or cash payouts. The robust dividend policy can then be characterized by a Hamilton-Jacobi-Bellman (HJB) variational inequality (VI). By constructing a novel shooting method for the HJB-VI, we theoretically prove that the robust dividend policy is a threshold strategy on the firm's surplus process. Therefore, dividend-caring investors can choose firms that match their preferences by examining stock's dividend policies and financial statements, whereas executives can make use of dividend to signal their confidence, in the form of ambiguity aversion, on realizing the earnings implied by their financial statements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12305v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.GN</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kexin Chen, Kyunghyun Park, Hoi Ying Wong</dc:creator>
    </item>
    <item>
      <title>On the Convergence of T\^atonnement for Linear Fisher Markets</title>
      <link>https://arxiv.org/abs/2406.12526</link>
      <description>arXiv:2406.12526v1 Announce Type: cross 
Abstract: T\^atonnement is a simple, intuitive market process where prices are iteratively adjusted based on the difference between demand and supply. Many variants under different market assumptions have been studied and shown to converge to a market equilibrium, in some cases at a fast rate. However, the classical case of linear Fisher markets have long eluded the analyses, and it remains unclear whether t\^atonnement converges in this case. We show that, for a sufficiently small step size, the prices given by the t\^atonnement process are guaranteed to converge to equilibrium prices, up to a small approximation radius that depends on the stepsize. To achieve this, we consider the dual Eisenberg-Gale convex program in the price space, view t\^atonnement as subgradient descent on this convex program, and utilize novel last-iterate convergence results for subgradient descent under error bound conditions. In doing so, we show that the convex program satisfies a particular error bound condition, the quadratic growth condition, and that the price sequence generated by t\^atonnement is bounded above and away from zero. We also show that a similar convergence result holds for t\^atonnement in quasi-linear Fisher markets. Numerical experiments are conducted to demonstrate that the theoretical linear convergence aligns with empirical observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12526v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianlong Nan, Yuan Gao, Christian Kroer</dc:creator>
    </item>
    <item>
      <title>Mitigating Information Asymmetry in Two-Stage Contracts with Non-Myopic Agents</title>
      <link>https://arxiv.org/abs/2406.12648</link>
      <description>arXiv:2406.12648v1 Announce Type: cross 
Abstract: We consider a Stackelberg game in which a principal (she) establishes a two-stage contract with a non-myopic agent (he) whose type is unknown. The contract takes the form of an incentive function mapping the agent's first-stage action to his second-stage incentive. While the first-stage action reveals the agent's type under truthful play, a non-myopic agent could benefit from portraying a false type in the first stage to obtain a larger incentive in the second stage. The challenge is thus for the principal to design the incentive function so as to induce truthful play. We show that this is only possible with a constant, non-reactive incentive functions when the type space is continuous, whereas it can be achieved with reactive functions for discrete types. Additionally, we show that introducing an adjustment mechanism that penalizes inconsistent behavior across both stages allows the principal to design more flexible incentive functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12648v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Munther A. Dahleh, Thibaut Horel, M. Umar B. Niazi</dc:creator>
    </item>
    <item>
      <title>Ensuring Both Positivity and Stability Using Sector-Bounded Nonlinearity for Systems with Neural Network Controllers</title>
      <link>https://arxiv.org/abs/2406.12744</link>
      <description>arXiv:2406.12744v1 Announce Type: cross 
Abstract: This paper introduces a novel method for the stability analysis of positive feedback systems with a class of fully connected feedforward neural networks (FFNN) controllers. By establishing sector bounds for fully connected FFNNs without biases, we present a stability theorem that demonstrates the global exponential stability of linear systems under fully connected FFNN control. Utilizing principles from positive Lur'e systems and the positive Aizerman conjecture, our approach effectively addresses the challenge of ensuring stability in highly nonlinear systems. The crux of our method lies in maintaining sector bounds that preserve the positivity and Hurwitz property of the overall Lur'e system. We showcase the practical applicability of our methodology through its implementation in a linear system managed by a FFNN trained on output feedback controller data, highlighting its potential for enhancing stability in dynamic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12744v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hamidreza Montazeri Hedesh, Milad Siami</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Mirror Flow on Separable Data</title>
      <link>https://arxiv.org/abs/2406.12763</link>
      <description>arXiv:2406.12763v1 Announce Type: cross 
Abstract: We examine the continuous-time counterpart of mirror descent, namely mirror flow, on classification problems which are linearly separable. Such problems are minimised `at infinity' and have many possible solutions; we study which solution is preferred by the algorithm depending on the mirror potential. For exponential tailed losses and under mild assumptions on the potential, we show that the iterates converge in direction towards a $\phi_\infty$-maximum margin classifier. The function $\phi_\infty$ is the $\textit{horizon function}$ of the mirror potential and characterises its shape `at infinity'. When the potential is separable, a simple formula allows to compute this function. We analyse several examples of potentials and provide numerical experiments highlighting our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12763v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Pesme, Radu-Alexandru Dragomir, Nicolas Flammarion</dc:creator>
    </item>
    <item>
      <title>Towards Exact Gradient-based Training on Analog In-memory Computing</title>
      <link>https://arxiv.org/abs/2406.12774</link>
      <description>arXiv:2406.12774v1 Announce Type: cross 
Abstract: Given the high economic and environmental costs of using large vision or language models, analog in-memory accelerators present a promising solution for energy-efficient AI. While inference on analog accelerators has been studied recently, the training perspective is underexplored. Recent studies have shown that the "workhorse" of digital AI training - stochastic gradient descent (SGD) algorithm converges inexactly when applied to model training on non-ideal devices. This paper puts forth a theoretical foundation for gradient-based training on analog devices. We begin by characterizing the non-convergent issue of SGD, which is caused by the asymmetric updates on the analog devices. We then provide a lower bound of the asymptotic error to show that there is a fundamental performance limit of SGD-based analog training rather than an artifact of our analysis. To address this issue, we study a heuristic analog algorithm called Tiki-Taka that has recently exhibited superior empirical performance compared to SGD and rigorously show its ability to exactly converge to a critical point and hence eliminates the asymptotic error. The simulations verify the correctness of the analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12774v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Tayfun Gokmen, Malte J. Rasch, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Evaluating the design space of diffusion-based generative models</title>
      <link>https://arxiv.org/abs/2406.12839</link>
      <description>arXiv:2406.12839v1 Announce Type: cross 
Abstract: Most existing theoretical investigations of the accuracy of diffusion models, albeit significant, assume the score function has been approximated to a certain accuracy, and then use this a priori bound to control the error of generation. This article instead provides a first quantitative understanding of the whole generation process, i.e., both training and sampling. More precisely, it conducts a non-asymptotic convergence analysis of denoising score matching under gradient descent. In addition, a refined sampling error analysis for variance exploding models is also provided. The combination of these two results yields a full error analysis, which elucidates (again, but this time theoretically) how to design the training and sampling processes for effective generation. For instance, our theory implies a preference toward noise distribution and loss weighting that qualitatively agree with the ones used in [Karras et al. 2022]. It also provides some perspectives on why the time and variance schedule used in [Karras et al. 2022] could be better tuned than the pioneering version in [Song et al. 2020].</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12839v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqing Wang, Ye He, Molei Tao</dc:creator>
    </item>
    <item>
      <title>ROOT-SGD: Sharp Nonasymptotics and Near-Optimal Asymptotics in a Single Algorithm</title>
      <link>https://arxiv.org/abs/2008.12690</link>
      <description>arXiv:2008.12690v3 Announce Type: replace 
Abstract: We study the problem of solving strongly convex and smooth unconstrained optimization problems using stochastic first-order algorithms. We devise a novel algorithm, referred to as \emph{Recursive One-Over-T SGD} (\textsf{ROOT-SGD}), based on an easily implementable, recursive averaging of past stochastic gradients. We prove that it simultaneously achieves state-of-the-art performance in both a finite-sample, nonasymptotic sense and an asymptotic sense. On the nonasymptotic side, we prove risk bounds on the last iterate of \textsf{ROOT-SGD} with leading-order terms that match the optimal statistical risk with a unity pre-factor, along with a higher-order term that scales at the sharp rate of $O(n^{-3/2})$ under the Lipschitz condition on the Hessian matrix. On the asymptotic side, we show that when a mild, one-point Hessian continuity condition is imposed, the rescaled last iterate of (multi-epoch) \textsf{ROOT-SGD} converges asymptotically to a Gaussian limit with the Cram\'{e}r-Rao optimal asymptotic covariance, for a broad range of step-size choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.12690v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Junchi Li</dc:creator>
    </item>
    <item>
      <title>On universal classes of Lyapunov functions for linear switched systems</title>
      <link>https://arxiv.org/abs/2208.09179</link>
      <description>arXiv:2208.09179v2 Announce Type: replace 
Abstract: In this paper we discuss the notion of universality for classes of candidate common Lyapunov functions of linear switched systems. On the one hand, we prove that a family of absolutely homogeneous functions is universal as soon as it approximates arbitrarily well every convex absolutely homogeneous function for the $C^0$ topology of the unit sphere. On the other hand, we prove several obstructions for a class to be universal, showing, in particular, that families of piecewise-polynomial continuous functions whose construction involves at most $l$ polynomials of degree at most $m$ (for given positive integers $l,m$) cannot be universal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.09179v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.automatica.2023.111155</arxiv:DOI>
      <arxiv:journal_reference>Automatica, 2023, 155, pp.111155</arxiv:journal_reference>
      <dc:creator>Paolo Mason (L2S), Yacine Chitour (L2S), Mario Sigalotti (CaGE, LJLL)</dc:creator>
    </item>
    <item>
      <title>Interior Point Methods in Optimal Control</title>
      <link>https://arxiv.org/abs/2309.01425</link>
      <description>arXiv:2309.01425v2 Announce Type: replace 
Abstract: This paper deals with Interior Point Methods (IPMs) for Optimal Control Problems (OCPs) with pure state and mixed constraints. This paper establishes a complete proof of convergence of IPMs for a general class of OCPs. Convergence results are proved for primal variables, namely state and control variables, and for dual variables, namely, the adjoint state, and the constraints multipliers. In addition, the presented convergence result does not rely on a strong convexity assumption. Finally, this paper provides two IPM-based solving algorithms: a primal solving algorithm and a primal-dual solving algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01425v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Malisani (IFPEN)</dc:creator>
    </item>
    <item>
      <title>Accelerating optimization over the space of probability measures</title>
      <link>https://arxiv.org/abs/2310.04006</link>
      <description>arXiv:2310.04006v3 Announce Type: replace 
Abstract: The acceleration of gradient-based optimization methods is a subject of significant practical and theoretical importance, particularly within machine learning applications. While much attention has been directed towards optimizing within Euclidean space, the need to optimize over spaces of probability measures in machine learning motivates exploration of accelerated gradient methods in this context too. To this end, we introduce a Hamiltonian-flow approach analogous to momentum-based approaches in Euclidean space. We demonstrate that, in the continuous-time setting, algorithms based on this approach can achieve convergence rates of arbitrarily high order. We complement our findings with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04006v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shi Chen, Qin Li, Oliver Tse, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Piecewise SOS-Convex Moment Optimization and Applications via Exact Semi-Definite Programs</title>
      <link>https://arxiv.org/abs/2402.07064</link>
      <description>arXiv:2402.07064v5 Announce Type: replace 
Abstract: This paper presents exact Semi-Definite Program (SDP) reformulations for infinite-dimensional moment optimization problems involving a new class of piecewise Sum-of-Squares (SOS)-convex functions and projected spectrahedral support sets. These reformulations show that solving a single SDP finds the optimal value and an optimal probability measure of the original moment problem. This is done by establishing an SOS representation for the non-negativity of a piecewise SOS-convex function over a projected spectrahedron. Finally, as an application and a proof-of-concept illustration, the paper also presents numerical results for the Newsvendor and revenue maximization problems with higher-order moments by solving their equivalent SDP reformulations. These reformulations promise a flexible and efficient approach to solving these models. The main novelty of the present work in relation to the recent research lies in finding the solution to moment problems, for the first time, with piecewise SOS-convex functions from their numerically tractable exact SDP reformulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07064v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Queenie Yingkun Huang, Vaithilingam Jeyakumar, Guoyin Li</dc:creator>
    </item>
    <item>
      <title>Generalized pair-wise logit dynamic and its connection to a mean field game: theoretical and computational investigations focusing on resource management</title>
      <link>https://arxiv.org/abs/2403.01657</link>
      <description>arXiv:2403.01657v2 Announce Type: replace 
Abstract: Logit dynamics are evolution equations that describe transitions to equilibria of actions among many players. We formulate a pair-wise logit dynamic in a continuous action space with a generalized exponential function, which we call a generalized pair-wise logit dynamic, depicted by a new evolution equation nonlocal in space. We prove the well-posedness and approximability of the generalized pair-wise logit dynamic to show that it is computationally implementable. We also show that this dynamic has an explicit connection to a mean field game of a controlled pure-jump process, with which the two different mathematical models can be understood in a unified way. Particularly, we show that the generalized pair-wise logit dynamic is derived as a myopic version of the corresponding mean field game, and that the conditions to guarantee the existence of unique solutions are different from each other. The key in this procedure is to find the objective function to be optimized in the mean field game based on the logit function. The monotonicity of the utility is unnecessary for the generalized pair-wise logit dynamic but crucial for the mean field game. Finally, we present applications of the two approaches to fisheries management problems with collected data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01657v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s13235-024-00569-4</arxiv:DOI>
      <arxiv:journal_reference>Dynamic Games and Applications, 2024</arxiv:journal_reference>
      <dc:creator>Hidekazu Yoshioka, Motoh Tsujimura</dc:creator>
    </item>
    <item>
      <title>Extending Identifiability Results from Continuous to Discrete-Space Systems</title>
      <link>https://arxiv.org/abs/2403.05736</link>
      <description>arXiv:2403.05736v2 Announce Type: replace 
Abstract: Researchers develop models to explain the unknowns.
  These models typically involve parameters that capture tangible quantities, the estimation of which is desired.
  Parameter identifiability investigates the recoverability of the unknown parameters given the error-free outputs, inputs, and the developed equations of the model.
  Different notions of and methods to test identifiability exist for dynamical systems defined in the continuous space.
  Yet little attention was paid to the identifiability of discrete space systems, where variables and parameters are defined in a discrete space.
  We develop the identifiability framework for discrete space systems and highlight that this is not an immediate extension of the continuous space framework.
  Unlike the continuous case, local identifiability concepts are sensitive to how a ``neighborhood'' is defined.
  Moreover, results on algebraic identifiability that proved useful in the continuous space are less so in their discrete form as the notion of differentiability disappears.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05736v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anuththara Sarathchandra, Azadeh Aghaeeyan, Pouria Ramazi</dc:creator>
    </item>
    <item>
      <title>A Unified Non-Strict Finsler Lemma</title>
      <link>https://arxiv.org/abs/2403.10306</link>
      <description>arXiv:2403.10306v2 Announce Type: replace 
Abstract: In this paper, we present a unified general non-strict Finsler lemma. This result is general in the sense that it does not impose any restrictions on the involved matrices and, thereby, it encompasses all existing non-strict versions of Finsler's lemma that do impose such restrictions. To further illustrate its usefulness, we showcase applications of the non-strict Finsler's lemma in deriving a structured solution to a special case of the non-strict projection lemma, and we use the unified non-strict Finsler's lemma to prove a more general version of the matrix Finsler's lemma.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10306v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>10.1109/LCSYS.2024.3415473</arxiv:journal_reference>
      <dc:creator>T. J. Meijer, K. J. A. Scheres, S. van den Eijnden, T. Holicki, C. W. Scherer, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>A new dual spectral projected gradient method for log-determinant semidefinite programming with hidden clustering structures</title>
      <link>https://arxiv.org/abs/2403.18284</link>
      <description>arXiv:2403.18284v3 Announce Type: replace 
Abstract: In this paper, we propose a new efficient method for a sparse Gaussian graphical model with hidden clustering structures by extending a dual spectral projected gradient (DSPG) method proposed by Nakagaki et al.~(2020). We establish the global convergence of the proposed method to an optimal solution, and we show that the projection onto the feasible region can be solved with a low computational complexity by the use of the pool-adjacent-violators algorithm. Numerical experiments on synthesis data and real data demonstrate the efficiency of the proposed method. The proposed method takes 0.91 seconds to achieve a similar solution to the direct application of the DSPG method which takes 4361 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18284v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Namchaisiri, Tianxiang Liu, Makoto Yamashita</dc:creator>
    </item>
    <item>
      <title>Fast Adaptive Meta-Heuristic for Large-Scale Facility Location Problem</title>
      <link>https://arxiv.org/abs/2406.07382</link>
      <description>arXiv:2406.07382v2 Announce Type: replace 
Abstract: Facility location problems have been a major research area of interest in the last several decades. In particular, uncapacitated location problems (ULP) have enormous applications. Variations of ULP often appear, especially as large-scale subproblems in more complex combinatorial optimization problems. Although many researchers have studied different versions of ULP (e.g., uncapacitated facility location problem (UCFLP) and p-Median problem), most of these authors have considered small to moderately sized problems. In this paper, we address the ULP and provide a fast adaptive meta-heuristic for large-scale problems. The approach is based on critical event memory tabu search. For the diversification component of the algorithm, we have chosen a procedure based on a sequencing problem commonly used for traveling salesman-type problems. The efficacy of this approach is evaluated across a diverse range of benchmark problems sourced from the Internet, with a comprehensive comparison against four prominent algorithms in the literature. The proposed adaptive critical event tabu search (ACETS) demonstrates remarkable effectiveness for large-scale problems. The algorithm successfully solved all problems optimally within a short computing time. Notably, ACETS discovered three best new solutions for benchmark problems, specifically for Asymmetric 500A-1, Asymmetric 750A-1, and Symmetric 750B-4, underscoring its innovative and robust nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07382v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahram Alidaee, Haibo Wang</dc:creator>
    </item>
    <item>
      <title>City-LEO: Toward Transparent City Management Using LLM with End-to-End Optimization</title>
      <link>https://arxiv.org/abs/2406.10958</link>
      <description>arXiv:2406.10958v2 Announce Type: replace 
Abstract: Existing operations research (OR) models and tools play indispensable roles in smart-city operations, yet their practical implementation is limited by the complexity of modeling and deficiencies in optimization proficiency. To generate more relevant and accurate solutions to users' requirements, we propose a large language model (LLM)-based agent ("City-LEO") that enhances the efficiency and transparency of city management through conversational interactions. Specifically, to accommodate diverse users' requirements and enhance computational tractability, City-LEO leverages LLM's logical reasoning capabilities on prior knowledge to scope down large-scale optimization problems efficiently. In the human-like decision process, City-LEO also incorporates End-to-end (E2E) model to synergize the prediction and optimization. The E2E framework be conducive to coping with environmental uncertainties and involving more query-relevant features, and then facilitates transparent and interpretable decision-making process. In case study, we employ City-LEO in the operations management of e-bike sharing (EBS) system. The numerical results demonstrate that City-LEO has superior performance when benchmarks against the full-scale optimization problem. With less computational time, City-LEO generates more satisfactory and relevant solutions to the users' requirements, and achieves lower global suboptimality without significantly compromising accuracy. In a broader sense, our proposed agent offers promise to develop LLM-embedded OR tools for smart-city operations management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10958v2</guid>
      <category>math.OC</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zihao Jiao, Mengyi Sha, Haoyu Zhang, Xinyu Jiang, Wei Qi</dc:creator>
    </item>
    <item>
      <title>Stay or Switch: Competitive Online Algorithms for Energy Plan Selection in Energy Markets with Retail Choice</title>
      <link>https://arxiv.org/abs/1905.07145</link>
      <description>arXiv:1905.07145v3 Announce Type: replace-cross 
Abstract: Energy markets with retail choice enable customers to switch energy plans among competitive retail suppliers. Despite the promising benefits of more affordable prices and better savings to customers, there appears subsided participation in energy retail markets from residential customers. One major reason is the complex online decision-making process for selecting the best energy plan from a multitude of options that hinders average consumers. In this paper, we shed light on the online energy plan selection problem by providing effective competitive online algorithms. We first formulate the online energy plan selection problem as a metrical task system problem with temporally dependent switching costs. For the case of constant cancellation fee, we present a 3-competitive deterministic online algorithm and a 2-competitive randomized online algorithm for solving the energy plan selection problem. We show that the two competitive ratios are the best possible among deterministic and randomized online algorithms, respectively. We further extend our online algorithms to the case where the cancellation fee is linearly proportional to the residual contract duration. Through empirical evaluations using real-world household and energy plan data, we show that our deterministic online algorithm can produce on average 14.6% cost saving, as compared to 16.2% by the offline optimal algorithm, while our randomized online algorithm can further improve cost saving by up to 0.5%.</description>
      <guid isPermaLink="false">oai:arXiv.org:1905.07145v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Zhai, Sid Chi-Kin Chau, Minghua Chen</dc:creator>
    </item>
    <item>
      <title>Efficient algorithms for implementing incremental proximal-point methods</title>
      <link>https://arxiv.org/abs/2205.01457</link>
      <description>arXiv:2205.01457v2 Announce Type: replace-cross 
Abstract: Model training algorithms which observe a small portion of the training set in each computational step are ubiquitous in practical machine learning, and include both stochastic and online optimization methods. In the vast majority of cases, such algorithms typically observe the training samples via the gradients of the cost functions the samples incur. Thus, these methods exploit are the slope of the cost functions via their first-order approximations. To address limitations of gradient-based methods, such as sensitivity to step-size choice in the stochastic setting, or inability to use small function variability in the online setting, several streams of research attempt to exploit more information about the cost functions than just their gradients via the well-known proximal operators. However, implementing such methods in practice poses a challenge, since each iteration step boils down to computing the proximal operator, which may not be easy. In this work we devise a novel algorithmic framework, which exploits convex duality theory to achieve both algorithmic efficiency and software modularity of proximal operator implementations, in order to make experimentation with incremental proximal optimization algorithms accessible to a larger audience of researchers and practitioners, by reducing the gap between their theoretical description in research papers and their use in practice. We provide a reference Python implementation for the framework developed in this paper as an open source library at on https://github.com/alexshtf/inc_prox_pt/releases/tag/prox_pt_paper, along with examples which demonstrate our implementation on a variety of problems, and reproduce the numerical experiments in this paper. The pure Python reference implementation is not necessarily the most efficient, but is a basis for creating efficient implementations by combining Python with a native backend.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.01457v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Shtoff</dc:creator>
    </item>
    <item>
      <title>Integrated Planning in Hospitals: A Review</title>
      <link>https://arxiv.org/abs/2307.05258</link>
      <description>arXiv:2307.05258v2 Announce Type: replace-cross 
Abstract: Efficient planning of scarce resources in hospitals is a challenging task for which a large variety of Operations Research and Management Science approaches have been developed since the 1950s. While efficient planning of single resources such as operating rooms, beds, or specific types of staff can already lead to enormous efficiency gains, integrated planning of several resources has been shown to hold even greater potential, and a large number of integrated planning approaches have been presented in the literature over the past decades. This paper provides the first literature review that focuses specifically on the Operations Research and Management Science literature related to integrated planning of different resources in hospitals. We collect the relevant literature and analyze it regarding different aspects such as uncertainty modeling and the use of real-life data. Several cross comparisons reveal interesting insights concerning, e.g., relations between the modeling and solution methods used and the practical implementation of the approaches developed. Moreover, we provide a high-level taxonomy for classifying different resource-focused integration approaches and point out gaps in the literature as well as promising directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05258v2</guid>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Rachuba, Melanie Reuter-Oppermann, Clemens Thielen</dc:creator>
    </item>
    <item>
      <title>Gap-Free Clustering: Sensitivity and Robustness of SDP</title>
      <link>https://arxiv.org/abs/2308.15642</link>
      <description>arXiv:2308.15642v2 Announce Type: replace-cross 
Abstract: We study graph clustering in the Stochastic Block Model (SBM) in the presence of both large clusters and small, unrecoverable clusters. Previous convex relaxation approaches achieving exact recovery do not allow any small clusters of size $o(\sqrt{n})$, or require a size gap between the smallest recovered cluster and the largest non-recovered cluster. We provide an algorithm based on semidefinite programming (SDP) which removes these requirements and provably recovers large clusters regardless of the remaining cluster sizes. Mid-sized clusters pose unique challenges to the analysis, since their proximity to the recovery threshold makes them highly sensitive to small noise perturbations and precludes a closed-form candidate solution. We develop novel techniques, including a leave-one-out-style argument which controls the correlation between SDP solutions and noise vectors even when the removal of one row of noise can drastically change the SDP solution. We also develop improved eigenvalue perturbation bounds of potential independent interest. Our results are robust to certain semirandom settings that are challenging for alternative algorithms. Using our gap-free clustering procedure, we obtain efficient algorithms for the problem of clustering with a faulty oracle with superior query complexities, notably achieving $o(n^2)$ sample complexity even in the presence of a large number of small clusters. Our gap-free clustering procedure also leads to improved algorithms for recursive clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15642v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>High-Performance Hybrid Algorithm for Minimum Sum-of-Squares Clustering of Infinitely Tall Data</title>
      <link>https://arxiv.org/abs/2311.04517</link>
      <description>arXiv:2311.04517v4 Announce Type: replace-cross 
Abstract: This paper introduces a novel formulation of the clustering problem, namely the Minimum Sum-of-Squares Clustering of Infinitely Tall Data (MSSC-ITD), and presents HPClust, an innovative set of hybrid parallel approaches for its effective solution. By utilizing modern high-performance computing techniques, HPClust enhances key clustering metrics: effectiveness, computational efficiency, and scalability. In contrast to vanilla data parallelism, which only accelerates processing time through the MapReduce framework, our approach unlocks superior performance by leveraging the multi-strategy competitive-cooperative parallelism and intricate properties of the objective function landscape. Unlike other available algorithms that struggle to scale, our algorithm is inherently parallel in nature, improving solution quality through increased scalability and parallelism, and outperforming even advanced algorithms designed for small and medium-sized datasets. Our evaluation of HPClust, featuring four parallel strategies, demonstrates its superiority over traditional and cutting-edge methods by offering better performance in the key metrics. These results also show that parallel processing not only enhances the clustering efficiency, but the accuracy as well. Additionally, we explore the balance between computational efficiency and clustering quality, providing insights into optimal parallel strategies based on dataset specifics and resource availability. This research advances our understanding of parallelism in clustering algorithms, demonstrating that a judicious hybridization of advanced parallel approaches yields optimal results for MSSC-ITD. Experiments on synthetic data further confirm HPClust's exceptional scalability and robustness to noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04517v4</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ravil Mussabayev, Rustam Mussabayev</dc:creator>
    </item>
    <item>
      <title>Completeness in the Polynomial Hierarchy for many natural Problems in Bilevel and Robust Optimization</title>
      <link>https://arxiv.org/abs/2311.10540</link>
      <description>arXiv:2311.10540v2 Announce Type: replace-cross 
Abstract: Because $\Sigma^p_2$- and $\Sigma^p_3$-hardness proofs are usually tedious and difficult, not so many complete problems for these classes are known. This is especially true in the areas of min-max regret robust optimization, network interdiction, most vital vertex problems, blocker problems, and two-stage adjustable robust optimization problems. Even though these areas are well-researched for over two decades and one would naturally expect many (if not most) of the problems occurring in these areas to be complete for the above classes, almost no completeness results exist in the literature. We address this lack of knowledge by introducing over 70 new $\Sigma^p_2$-complete and $\Sigma^p_3$-complete problems. We achieve this result by proving a new meta-theorem, which shows $\Sigma^p_2$- and $\Sigma^p_3$-completeness simultaneously for a huge class of problems. The majority of all earlier publications on $\Sigma^p_2$- and $\Sigma^p_3$-completeness in said areas are special cases of our meta-theorem. Our precise result is the following: We introduce a large list of problems for which the meta-theorem is applicable (including clique, vertex cover, knapsack, TSP, facility location and many more). For every problem on this list, we show: The interdiction/minimum cost blocker/most vital nodes problem (with element costs) is $\Sigma^p_2$-complete. The min-max-regret problem with interval uncertainty is $\Sigma^p_2$-complete. The two-stage adjustable robust optimization problem with discrete budgeted uncertainty is $\Sigma^p_3$-complete. In summary, our work reveals the interesting insight that a large amount of NP-complete problems have the property that their min-max versions are 'automatically' $\Sigma^p_2$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10540v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christoph Gr\"une, Lasse Wulf</dc:creator>
    </item>
    <item>
      <title>BiLO: Bilevel Local Operator Learning for PDE inverse problems</title>
      <link>https://arxiv.org/abs/2404.17789</link>
      <description>arXiv:2404.17789v2 Announce Type: replace-cross 
Abstract: We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17789v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Zirui Zhang, Xiaohui Xie, John Lowengrub</dc:creator>
    </item>
    <item>
      <title>Sampling Theorem and interpolation formula for non-vanishing signals</title>
      <link>https://arxiv.org/abs/2405.10007</link>
      <description>arXiv:2405.10007v5 Announce Type: replace-cross 
Abstract: The paper establishes an analog Whittaker-Shannon-Kotelnikov sampling theorem with fast decreasing coefficient, as well as a new modification of the corresponding interpolation formula applicable for general type non-vanishing bounded continuous signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10007v5</guid>
      <category>cs.IT</category>
      <category>math.FA</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Dokuchaev</dc:creator>
    </item>
    <item>
      <title>Challenges with Differentiable Quantum Dynamics</title>
      <link>https://arxiv.org/abs/2406.06361</link>
      <description>arXiv:2406.06361v2 Announce Type: replace-cross 
Abstract: Differentiable quantum dynamics require automatic differentiation of a complex-valued initial value problem, which numerically integrates a system of ordinary differential equations from a specified initial condition, as well as the eigendecomposition of a matrix. We explored several automatic differentiation frameworks for these tasks, finding that no framework natively supports our application requirements. We therefore demonstrate a need for broader support of complex-valued, differentiable numerical integration in scientific computing libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06361v2</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sri Hari Krishna Narayanan, Michael Perlin, Robert Lewis-Swan, Jeffrey Larson, Matt Menickelly, Jan H\"uckelheim, Paul Hovland</dc:creator>
    </item>
    <item>
      <title>Finite-difference least square methods for solving Hamilton-Jacobi equations using neural networks</title>
      <link>https://arxiv.org/abs/2406.10758</link>
      <description>arXiv:2406.10758v2 Announce Type: replace-cross 
Abstract: We present a simple algorithm to approximate the viscosity solution of Hamilton-Jacobi~(HJ) equations by means of an artificial deep neural network. The algorithm uses a stochastic gradient descent-based algorithm to minimize the least square principle defined by a monotone, consistent numerical scheme. We analyze the least square principle's critical points and derive conditions that guarantee that any critical point approximates the sought viscosity solution. The use of a deep artificial neural network on a finite difference scheme lifts the restriction of conventional finite difference methods that rely on computing functions on a fixed grid. This feature makes it possible to solve HJ equations posed in higher dimensions where conventional methods are infeasible. We demonstrate the efficacy of our algorithm through numerical studies on various canonical HJ equations across different dimensions, showcasing its potential and versatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10758v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Esteve-Yag\"ue, Richard Tsai, Alex Massucco</dc:creator>
    </item>
  </channel>
</rss>
