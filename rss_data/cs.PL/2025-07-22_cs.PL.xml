<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 22 Jul 2025 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>NPUEval: Optimizing NPU Kernels with LLMs and Open Source Compilers</title>
      <link>https://arxiv.org/abs/2507.14403</link>
      <description>arXiv:2507.14403v1 Announce Type: new 
Abstract: Neural processing units (NPUs) are gaining prominence in power-sensitive devices like client devices, with AI PCs being defined by their inclusion of these specialized processors. Running AI workloads efficiently on these devices requires libraries of optimized kernels. Creating efficient kernels demands expertise in domain-specific C++ with vector intrinsics and in-depth knowledge of the target architecture. Unlike GPU programming, which has had years to mature, NPU programming is new, with smaller and more fragmented developer communities across hardware platforms. This fragmentation poses a challenge when utilizing LLMs to assist in writing NPU kernels, as domain-specific optimized code examples are underrepresented in LLM pre-training data.
  In this paper we introduce NPUEval -- a benchmark for writing and evaluating NPU kernels, consisting of 102 common operators for machine learning workloads. We evaluate LLM generated code on actual hardware based on both functional correctness and vectorization efficiency using open source compiler tools targeting the AMD NPU. We evaluate a range of state-of-the-art LLMs with a mix of proprietary and open-weight models. Latest reasoning models like DeepSeek R1, show promising results achieving out-of-the-box 50%+ vectorization on select kernels. However, the average score across the entire dataset remains roughly 10% even with compiler feedback and vectorized kernel examples -- showing that this is a challenging dataset even for frontier models. The dataset and evaluation code will be released with a permissive open source license, providing an essential benchmark for advancing research in code generation and NPU kernel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14403v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarunas Kalade, Graham Schelle</dc:creator>
    </item>
    <item>
      <title>Timetide: A programming model for logically synchronous distributed systems</title>
      <link>https://arxiv.org/abs/2507.14471</link>
      <description>arXiv:2507.14471v1 Announce Type: new 
Abstract: Massive strides in deterministic models have been made using synchronous languages. They are mainly focused on centralised applications, as the traditional approach is to compile away the concurrency. Time triggered languages such as Giotto and Lingua Franca are suitable for distribution albeit that they rely on expensive physical clock synchronisation, which is both expensive and may suffer from scalability. Hence, deterministic programming of distributed systems remains challenging. We address the challenges of deterministic distribution by developing a novel multiclock semantics of synchronous programs. The developed semantics is amenable to seamless distribution. Moreover, our programming model, Timetide, alleviates the need for physical clock synchronisation by building on the recently proposed logical synchrony model for distributed systems. We discuss the important aspects of distributing computation, such as network communication delays, and explore the formal verification of Timetide programs. To the best of our knowledge, Timetide is the first multiclock synchronous language that is both amenable to distribution and formal verification without the need for physical clock synchronisation or clock gating.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14471v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Logan Kenwright, Partha Roop, Nathan Allen, C\u{a}lin Ca\c{s}caval, Avinash Malik</dc:creator>
    </item>
    <item>
      <title>Hear Your Code Fail, Voice-Assisted Debugging for Python</title>
      <link>https://arxiv.org/abs/2507.15007</link>
      <description>arXiv:2507.15007v1 Announce Type: new 
Abstract: This research introduces an innovative voice-assisted debugging plugin for Python that transforms silent runtime errors into actionable audible diagnostics. By implementing a global exception hook architecture with pyttsx3 text-to-speech conversion and Tkinter-based GUI visualization, the solution delivers multimodal error feedback through parallel auditory and visual channels. Empirical evaluation demonstrates 37% reduced cognitive load (p&lt;0.01, n=50) compared to traditional stack-trace debugging, while enabling 78% faster error identification through vocalized exception classification and contextualization. The system achieves sub-1.2 second voice latency with under 18% CPU overhead during exception handling, vocalizing error types and consequences while displaying interactive tracebacks with documentation deep links. Criteria validate compatibility across Python 3.7+ environments on Windows, macOS, and Linux platforms. Needing only two lines of integration code, the plugin significantly boosts availability for aesthetically impaired designers and supports multitasking workflows through hands-free error medical diagnosis. Educational applications show particular promise, with pilot studies indicating 45% faster debugging skill acquisition among novice programmers. Future development will incorporate GPT-based repair suggestions and real-time multilingual translation to further advance auditory debugging paradigms. The solution represents a fundamental shift toward human-centric error diagnostics, bridging critical gaps in programming accessibility while establishing new standards for cognitive efficiency in software development workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15007v1</guid>
      <category>cs.PL</category>
      <category>cs.CL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sayed Mahbub Hasan Amiri, Md. Mainul Islam, Mohammad Shakhawat Hossen, Sayed Majhab Hasan Amiri, Mohammad Shawkat Ali Mamun, Sk. Humaun Kabir, Naznin Akter</dc:creator>
    </item>
    <item>
      <title>Invariant Generation for Floating-Point Programs via Constraint Solving</title>
      <link>https://arxiv.org/abs/2507.15017</link>
      <description>arXiv:2507.15017v1 Announce Type: new 
Abstract: In numeric-intensive computations, it is well known that the execution of floating-point programs is imprecise as floating point arithmetics (e.g., addition, subtraction, multiplication, division, etc.) incurs rounding errors. Albeit the rounding error is small for every single floating-point operation, the aggregation of such error in multiple operations may be dramatic and cause catastrophic program failures. Therefore, to ensure the correctness of floating-point programs, the effect of floating point error needs to be carefully taken into account. In this work, we consider the invariant generation for floating point programs, whose aim is to generate tight invariants under the perturbation of floating point errors. Our main contribution is a theoretical framework on how to apply constraint solving methods to address the invariant generation problem. In our framework, we propose a novel combination between the first-order differential characterization by FPTaylor (TOPLAS 2018) and constraint solving methods, aiming to reduce the computational burden of constraint solving. Moreover, we devise two polynomial invariant generation algorithms to instantiate the framework. The first algorithm is applicable to a wide range of floating-point operations but requires an initial (coarse) invariant as external input, while the second does not require an initial invariant but is limited to polynomial programs. Furthermore, we show how conditional branches, a difficult issue in floating-point analysis, can be handled in our framework. Experimental results show that our algorithms outperform SOTA approaches in both the time efficiency and the precision of the generated invariants over a variety of benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15017v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xuran Cai, Liqian Chen, Hongfei Fu</dc:creator>
    </item>
    <item>
      <title>A Few Fit Most: Improving Performance Portability of SGEMM on GPUs using Multi-Versioning</title>
      <link>https://arxiv.org/abs/2507.15277</link>
      <description>arXiv:2507.15277v1 Announce Type: new 
Abstract: Hand-optimizing linear algebra kernels for different GPU devices and applications is complex and labor-intensive. Instead, many developers use automatic performance tuning (autotuning) to achieve high performance on a variety of devices. However, autotuning "overfits", and must be redone if any part of the environment changes, such as if the device or input characteristics change.
  In most non-trivial cases, a single compute kernel cannot maintain near-optimal performance across all environments. Changing the kernel to specialize it to the current execution environment is possible, but on GPUs, runtime tuning and compilation can be expensive.
  In this work, we use multi-versioning -- producing several variants of the same code -- as a way to generate performance portable code. We describe a framework called portability tuning that can automatically generate multi-versioned code whose performance is portable, requiring no retuning.
  We evaluate our framework on a dataset of execution times for GEMM kernels from the CLBlast linear algebra library. We find our portability tuning techniques outperform CLBlast's default kernels -- often approaching within 10% of the theoretical maximum performance -- despite CLBlast using autotuning techniques. Further, we find that our generated programs generalize well to new and unseen devices, matching the performance of autotuning without ever portability tuning for those devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15277v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Hochgraf (Rochester Institute of Technology), Sreepathi Pai (University of Rochester)</dc:creator>
    </item>
    <item>
      <title>Bayesian Separation Logic</title>
      <link>https://arxiv.org/abs/2507.15530</link>
      <description>arXiv:2507.15530v1 Announce Type: new 
Abstract: Bayesian probabilistic programming languages (BPPLs) let users denote statistical models as code while the interpreter infers the posterior distribution. The semantics of BPPLs are usually mathematically complex and unable to reason about desirable properties such as expected values and independence of random variables. To reason about these properties in a non-Bayesian setting, probabilistic separation logics such as PSL and Lilac interpret separating conjunction as probabilistic independence of random variables. However, no existing separation logic can handle Bayesian updating, which is the key distinguishing feature of BPPLs.
  To close this gap, we introduce Bayesian separation logic (BaSL), a probabilistic separation logic that gives semantics to BPPL. We prove an internal version of Bayes' theorem using a result in measure theory known as the Rokhlin-Simmons disintegration theorem. Consequently, BaSL can model probabilistic programming concepts such as Bayesian updating, unnormalised distribution, conditional distribution, soft constraint, conjugate prior and improper prior while maintaining modularity via the frame rule. The model of BaSL is based on a novel instantiation of Kripke resource monoid via $\sigma$-finite measure spaces over the Hilbert cube, and the semantics of Hoare triple is compatible with an existing denotational semantics of BPPL based on the category of $s$-finite kernels. Using BaSL, we then prove properties of statistical models such as the expected value of Bayesian coin flip, correlation of random variables in the collider Bayesian network, and the posterior distributions of the burglar alarm model, a parameter estimation algorithm, and the Gaussian mixture model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15530v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shing Hin Ho, Nicolas Wu, Azalea Raad</dc:creator>
    </item>
    <item>
      <title>Formal Analysis of Networked PLC Controllers Interacting with Physical Environments</title>
      <link>https://arxiv.org/abs/2507.15596</link>
      <description>arXiv:2507.15596v1 Announce Type: new 
Abstract: Programmable Logic Controllers (PLCs) are widely used in industrial automation to control physical systems. As PLC applications become increasingly complex, ensuring their correctness is crucial. Existing formal verification techniques focus on individual PLC programs in isolation, often neglecting interactions with physical environments and network communication between controllers. This limitation poses significant challenges in analyzing real-world industrial systems, where continuous dynamics and communication delays play a critical role. In this paper, we present a unified formal framework that integrates discrete PLC semantics, networked communication, and continuous physical behaviors. To mitigate state explosion, we apply partial order reduction, significantly reducing the number of explored states while maintaining correctness. Our framework enables precise analysis of PLC-driven systems with continuous dynamics and networked communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15596v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaeseo Lee, Kyungmin Bae</dc:creator>
    </item>
    <item>
      <title>Closure Conversion, Flat Environments, and the Complexity of Abstract Machines</title>
      <link>https://arxiv.org/abs/2507.15843</link>
      <description>arXiv:2507.15843v1 Announce Type: new 
Abstract: Closure conversion is a program transformation at work in compilers for functional languages to turn inner functions into global ones, by building closures pairing the transformed functions with the environment of their free variables. Abstract machines rely on similar and yet different concepts of closures and environments.
  In this paper, we study the relationship between the two approaches. We adopt a very simple {\lambda}-calculus with tuples as source language and study abstract machines for both the source language and the target of closure conversion. Moreover, we focus on the simple case of flat closures/environments, that is, with no sharing of environments. We provide three contributions.
  Firstly, a new simple proof technique for the correctness of closure conversion, inspired by abstract machines.
  Secondly, we show how the closure invariants of the target language allow us to design a new way of handling environments in abstract machines, not suffering the shortcomings of other styles.
  Thirdly, we study the machines from the point of view of time complexity, adapting analyses by Accattoli and co-authors. We show that closure conversion decreases various dynamic costs while increasing the size of the initial code. Despite these changes, the overall complexity of the machines before and after closure conversion turns out to be the same.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15843v1</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beniamino Accattoli (Inria &amp; LIX, \'Ecole Polytechnique), Dan Ghica (Huawei Central Software Institute, University of Birmingham), Giulio Guerrieri (University of Sussex), Cl\'audio Belo Louren\c{c}o (Huawei Central Software Institute), Claudio Sacerdoti Coen (Universit\`a di Bologna)</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of Large Language Models in Writing Alloy Formulas</title>
      <link>https://arxiv.org/abs/2502.15441</link>
      <description>arXiv:2502.15441v1 Announce Type: cross 
Abstract: Declarative specifications have a vital role to play in developing safe and dependable software systems. Writing specifications correctly, however, remains particularly challenging. This paper presents a controlled experiment on using large language models (LLMs) to write declarative formulas in the well-known language Alloy. Our use of LLMs is three-fold. One, we employ LLMs to write complete Alloy formulas from given natural language descriptions (in English). Two, we employ LLMs to create alternative but equivalent formulas in Alloy with respect to given Alloy formulas. Three, we employ LLMs to complete sketches of Alloy formulas and populate the holes in the sketches by synthesizing Alloy expressions and operators so that the completed formulas accurately represent the desired properties (that are given in natural language). We conduct the experimental evaluation using 11 well-studied subject specifications and employ two popular LLMs, namely ChatGPT and DeepSeek. The experimental results show that the LLMs generally perform well in synthesizing complete Alloy formulas from input properties given in natural language or in Alloy, and are able to enumerate multiple unique solutions. Moreover, the LLMs are also successful at completing given sketches of Alloy formulas with respect to natural language descriptions of desired properties (without requiring test cases). We believe LLMs offer a very exciting advance in our ability to write specifications, and can help make specifications take a pivotal role in software development and enhance our ability to build robust software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15441v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Hong, Shan Jiang, Yulei Fu, Sarfraz Khurshid</dc:creator>
    </item>
    <item>
      <title>Quantum Programming in Polylogarithmic Time</title>
      <link>https://arxiv.org/abs/2507.15415</link>
      <description>arXiv:2507.15415v1 Announce Type: cross 
Abstract: Polylogarithmic time delineates a relevant notion of feasibility on several classical computational models such as Boolean circuits or parallel random access machines. As far as the quantum paradigm is concerned, this notion yields the complexity class FBQPOLYLOG of functions approximable in polylogarithmic time with a quantum random-access Turing machine. We introduce a quantum programming language with first-order recursive procedures, which provides the first programming-language-based characterization of FBQPOLYLOG. Each program computes a function in FBQPOLYLOG (soundness) and, conversely, each function of this complexity class is computed by a program (completeness). We also provide a compilation strategy from programs to uniform families of quantum circuits of polylogarithmic depth and polynomial size, whose set of computed functions is known as QNC, and recover the well-known separation result FBQPOLYLOG $\subsetneq$ QNC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15415v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florent Ferrari (ENS de Lyon), Emmanuel Hainry (MOCQUA, LORIA), Romain P\'echoux (LORIA, MOCQUA), M\'ario Silva (LORIA, MOCQUA)</dc:creator>
    </item>
    <item>
      <title>Don't exhaust, don't waste</title>
      <link>https://arxiv.org/abs/2507.13792</link>
      <description>arXiv:2507.13792v2 Announce Type: replace 
Abstract: We extend the semantics and type system of a lambda calculus equipped with common constructs to be resource-aware. That is, the semantics keep tracks of the usage of resources, and is stuck, besides in case of type errors, if either a needed resource is exhausted, or a provided resource would be wasted. In such way, the type system guarantees, besides standard soundness, that for well-typed programs there is a computation where no resource gets either exhausted or wasted.
  The no-waste extension is parametric on an arbitrary grade algebra, modeling an arbitrary assortment of possible usages, and does not require ad-hoc changes to the underlying language. To this end, the semantics needs to be formalized in big-step style; as a consequence, expressing and proving (resource-aware) soundness is challenging, and is achieved by applying recent techniques based on coinductive reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13792v2</guid>
      <category>cs.PL</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Riccardo Bianchini, Francesco Dagnino, Paola Giannini, Elena Zucca</dc:creator>
    </item>
  </channel>
</rss>
