<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 May 2024 04:13:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Testing Sign Congruence</title>
      <link>https://arxiv.org/abs/2405.11759</link>
      <description>arXiv:2405.11759v1 Announce Type: new 
Abstract: We consider testing the null hypothesis that two parameters $({\mu}_1, {\mu}_2)$ have the same sign, assuming that (asymptotically) normal estimators are available. Examples of this problem include the analysis of heterogeneous treatment effects, causal interpretation of reduced-form estimands, meta-studies, and mediation analysis. A number of tests were recently proposed. We recommend a test that is simple and rejects more often than many of these recent proposals. Like all other tests in the literature, it is conservative if the truth is near (0, 0) and therefore also biased. To clarify whether these features are avoidable, we also provide a test that is unbiased and has exact size control on the boundary of the null hypothesis, but which has counterintuitive properties and hence we do not recommend. The method that we recommend can be used to revisit existing findings using information typically reported in empirical research papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11759v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Douglas L. Miller, Francesca Molinari, J\"org Stoye</dc:creator>
    </item>
    <item>
      <title>Comparing predictive ability in presence of instability over a very short time</title>
      <link>https://arxiv.org/abs/2405.11954</link>
      <description>arXiv:2405.11954v1 Announce Type: new 
Abstract: We consider forecast comparison in the presence of instability when this affects only a short period of time. We demonstrate that global tests do not perform well in this case, as they were not designed to capture very short-lived instabilities, and their power vanishes altogether when the magnitude of the shock is very large. We then discuss and propose approaches that are more suitable to detect such situations, such as nonparametric methods (S test or MAX procedure). We illustrate these results in different Monte Carlo exercises and in evaluating the nowcast of the quarterly US nominal GDP from the Survey of Professional Forecasters (SPF) against a naive benchmark of no growth, over the period that includes the GDP instability brought by the Covid-19 crisis. We recommend that the forecaster should not pool the sample, but exclude the short periods of high local instability from the evaluation exercise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11954v1</guid>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabrizio Iacone, Luca Rossini, Andrea Viselli</dc:creator>
    </item>
    <item>
      <title>Instrumented Difference-in-Differences with heterogeneous treatment effects</title>
      <link>https://arxiv.org/abs/2405.12083</link>
      <description>arXiv:2405.12083v1 Announce Type: new 
Abstract: Many studies exploit variation in the timing of policy adoption across units as an instrument for treatment, and use instrumental variable techniques. This paper formalizes the underlying identification strategy as an instrumented difference-in-differences (DID-IV). In a simple setting with two periods and two groups, our DID-IV design mainly consists of a monotonicity assumption, and parallel trends assumptions in the treatment and the outcome. In this design, a Wald-DID estimand, which scales the DID estimand of the outcome by the DID estimand of the treatment, captures the local average treatment effect on the treated (LATET). In contrast to Fuzzy DID design considered in \cite{De_Chaisemartin2018-xe}, our DID-IV design does not {\it ex-ante} require strong restrictions on the treatment adoption behavior across units, and our target parameter, the LATET, is policy-relevant if the instrument is based on the policy change of interest to the researcher. We extend the canonical DID-IV design to multiple period settings with the staggered adoption of the instrument across units, which we call staggered DID-IV designs. We propose an estimation method in staggered DID-IV designs that is robust to treatment effect heterogeneity. We illustrate our findings in the setting of \cite{Oreopoulos2006-bn}, estimating returns to schooling in the United Kingdom. In this application, the two-way fixed effects instrumental variable regression, which is the conventional approach to implement staggered DID-IV designs, yields the negative estimate, whereas our estimation method indicates the substantial gain from schooling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12083v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sho Miyaji</dc:creator>
    </item>
    <item>
      <title>Estimating the Impact of Social Distance Policy in Mitigating COVID-19 Spread with Factor-Based Imputation Approach</title>
      <link>https://arxiv.org/abs/2405.12180</link>
      <description>arXiv:2405.12180v1 Announce Type: new 
Abstract: We identify the effectiveness of social distancing policies in reducing the transmission of the COVID-19 spread. We build a model that measures the relative frequency and geographic distribution of the virus growth rate and provides hypothetical infection distribution in the states that enacted the social distancing policies, where we control time-varying, observed and unobserved, state-level heterogeneities. Using panel data on infection and deaths in all US states from February 20 to April 20, 2020, we find that stay-at-home orders and other types of social distancing policies significantly reduced the growth rate of infection and deaths. We show that the effects are time-varying and range from the weakest at the beginning of policy intervention to the strongest by the end of our sample period. We also found that social distancing policies were more effective in states with higher income, better education, more white people, more democratic voters, and higher CNN viewership.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12180v1</guid>
      <category>econ.EM</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Difang Huang, Ying Liang, Boyao Wu, Yanyi Ye</dc:creator>
    </item>
    <item>
      <title>Lassoed Boosting and Linear Prediction in the Equities Market</title>
      <link>https://arxiv.org/abs/2112.08934</link>
      <description>arXiv:2112.08934v4 Announce Type: replace 
Abstract: We consider a two-stage estimation method for linear regression. First, it uses the lasso in Tibshirani (1996) to screen variables and, second, re-estimates the coefficients using the least-squares boosting method in Friedman (2001) on every set of selected variables. Based on the large-scale simulation experiment in Hastie et al. (2020), lassoed boosting performs as well as the relaxed lasso in Meinshausen (2007) and, under certain scenarios, can yield a sparser model. Applied to predicting equity returns, lassoed boosting gives the smallest mean-squared prediction error compared to several other methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.08934v4</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Huang</dc:creator>
    </item>
    <item>
      <title>Robust Design and Evaluation of Predictive Algorithms under Unobserved Confounding</title>
      <link>https://arxiv.org/abs/2212.09844</link>
      <description>arXiv:2212.09844v5 Announce Type: replace 
Abstract: Predictive algorithms inform consequential decisions in settings where the outcome is selectively observed given choices made by human decision makers. We propose a unified framework for the robust design and evaluation of predictive algorithms in selectively observed data. We impose general assumptions on how much the outcome may vary on average between unselected and selected units conditional on observed covariates and identified nuisance parameters, formalizing popular empirical strategies for imputing missing data such as proxy outcomes and instrumental variables. We develop debiased machine learning estimators for the bounds on a large class of predictive performance estimands, such as the conditional likelihood of the outcome, a predictive algorithm's mean square error, true/false positive rate, and many others, under these assumptions. In an administrative dataset from a large Australian financial institution, we illustrate how varying assumptions on unobserved confounding leads to meaningful changes in default risk predictions and evaluations of credit scores across sensitive groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.09844v5</guid>
      <category>econ.EM</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashesh Rambachan, Amanda Coston, Edward Kennedy</dc:creator>
    </item>
    <item>
      <title>Quasi Maximum Likelihood Estimation of High-Dimensional Factor Models: A Critical Review</title>
      <link>https://arxiv.org/abs/2303.11777</link>
      <description>arXiv:2303.11777v5 Announce Type: replace 
Abstract: We review Quasi Maximum Likelihood estimation of factor models for high-dimensional panels of time series. We consider two cases: (1) estimation when no dynamic model for the factors is specified (Bai and Li, 2012, 2016); (2) estimation based on the Kalman smoother and the Expectation Maximization algorithm thus allowing to model explicitly the factor dynamics (Doz et al., 2012, Barigozzi and Luciani, 2019). Our interest is in approximate factor models, i.e., when we allow for the idiosyncratic components to be mildly cross-sectionally, as well as serially, correlated. Although such setting apparently makes estimation harder, we show, in fact, that factor models do not suffer of the {\it curse of dimensionality} problem, but instead they enjoy a {\it blessing of dimensionality} property. In particular, given an approximate factor structure, if the cross-sectional dimension of the data, $N$, grows to infinity, we show that: (i) identification of the model is still possible, (ii) the mis-specification error due to the use of an exact factor model log-likelihood vanishes. Moreover, if we let also the sample size, $T$, grow to infinity, we can also consistently estimate all parameters of the model and make inference. The same is true for estimation of the latent factors which can be carried out by weighted least-squares, linear projection, or Kalman filtering/smoothing. We also compare the approaches presented with: Principal Component analysis and the classical, fixed $N$, exact Maximum Likelihood approach. We conclude with a discussion on efficiency of the considered estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11777v5</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Barigozzi</dc:creator>
    </item>
    <item>
      <title>Testing for Stationary or Persistent Coefficient Randomness in Predictive Regressions</title>
      <link>https://arxiv.org/abs/2309.04926</link>
      <description>arXiv:2309.04926v4 Announce Type: replace 
Abstract: This study considers tests for coefficient randomness in predictive regressions. Our focus is on how tests for coefficient randomness are influenced by the persistence of random coefficient. We show that when the random coefficient is stationary, or I(0), Nyblom's (1989) LM test loses its optimality (in terms of power), which is established against the alternative of integrated, or I(1), random coefficient. We demonstrate this by constructing a test that is more powerful than the LM test when the random coefficient is stationary, although the test is dominated in terms of power by the LM test when the random coefficient is integrated. This implies that the best test for coefficient randomness differs from context to context, and the persistence of the random coefficient determines which test is the best one. We apply those tests to the U.S. stock returns data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.04926v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikihito Nishi</dc:creator>
    </item>
    <item>
      <title>Estimations of the Local Conditional Tail Average Treatment Effect</title>
      <link>https://arxiv.org/abs/2109.08793</link>
      <description>arXiv:2109.08793v3 Announce Type: replace-cross 
Abstract: The conditional tail average treatment effect (CTATE) is defined as a difference between the conditional tail expectations of potential outcomes, which can capture heterogeneity and deliver aggregated local information on treatment effects over different quantile levels and is closely related to the notion of second-order stochastic dominance and the Lorenz curve. These properties render it a valuable tool for policy evaluation. In this paper, we study estimation of the CTATE locally for a group of compliers (local CTATE or LCTATE) under the two-sided noncompliance framework. We consider a semiparametric treatment effect framework under endogeneity for the LCTATE estimation using a newly introduced class of consistent loss functions jointly for the conditional tail expectation and quantile. We establish the asymptotic theory of our proposed LCTATE estimator and provide an efficient algorithm for its implementation. We then apply the method to evaluate the effects of participating in programs under the Job Training Partnership Act in the US.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.08793v3</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Le-Yu Chen, Yu-Min Yen</dc:creator>
    </item>
  </channel>
</rss>
