<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Jul 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On Differentially Private U Statistics</title>
      <link>https://arxiv.org/abs/2407.04945</link>
      <description>arXiv:2407.04945v1 Announce Type: new 
Abstract: We consider the problem of privately estimating a parameter $\mathbb{E}[h(X_1,\dots,X_k)]$, where $X_1$, $X_2$, $\dots$, $X_k$ are i.i.d. data from some distribution and $h$ is a permutation-invariant function. Without privacy constraints, standard estimators are U-statistics, which commonly arise in a wide range of problems, including nonparametric signed rank tests, symmetry testing, uniformity testing, and subgraph counts in random networks, and can be shown to be minimum variance unbiased estimators under mild conditions. Despite the recent outpouring of interest in private mean estimation, privatizing U-statistics has received little attention. While existing private mean estimation algorithms can be applied to obtain confidence intervals, we show that they can lead to suboptimal private error, e.g., constant-factor inflation in the leading term, or even $\Theta(1/n)$ rather than $O(1/n^2)$ in degenerate settings. To remedy this, we propose a new thresholding-based approach using \emph{local H\'ajek projections} to reweight different subsets of the data. This leads to nearly optimal private error for non-degenerate U-statistics and a strong indication of near-optimality for degenerate U-statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04945v1</guid>
      <category>math.ST</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kamalika Chaudhuri, Po-Ling Loh, Shourya Pandey, Purnamrita Sarkar</dc:creator>
    </item>
    <item>
      <title>Set Estimation from Projected Multidimensional Random Variables with Application to a Discrete-Time Skorokhod Problem</title>
      <link>https://arxiv.org/abs/2407.05011</link>
      <description>arXiv:2407.05011v1 Announce Type: new 
Abstract: This paper deals with sufficient conditions on the distribution of the random variable $H$, in the model $X =\Pi_C(H)$, for the convex hull $\widehat C_N$ of $N$ independent copies of $X$ to be a consistent estimator of the convex body $C$ with a rate of convergence. The convergence of $\widehat C_N$ is established for the Hausdorff distance under a uniform condition on the distribution of $H$, but also in a pointwise sense under a less demanding condition. Some of these convergence results on $\widehat C_N$ are applied to the estimation of the time-dependent constraint set involved in a discrete-time Skorokhod problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05011v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Marie</dc:creator>
    </item>
    <item>
      <title>Location and association measures for interval data based on Mallows' distance</title>
      <link>https://arxiv.org/abs/2407.05105</link>
      <description>arXiv:2407.05105v1 Announce Type: new 
Abstract: The increasing need to analyse large volumes of data has led to the development of Symbolic Data Analysis as a promising field to tackle the data challenges of our time. New data types, such as interval-valued data, have brought fresh theoretical and methodological problems to be solved. In this paper, we derive explicit formulas for computing the Mallows' distance, also known as $L_2$ Wasserstein distance, between two \textit{p}-dimensional intervals, using information regarding the distribution of the microdata. We establish this distance as a Mahalanobis' distance between two 2\textit{p}-dimensional vectors. Our comprehensive analysis leads to the generalisation of the definitions of the expected value and covariance matrix of an interval-valued random vector. These novel results bring theoretical support and interpretability to state-of-the-art contributions. Additionally, we discuss real examples that illustrate how we can model different levels of available information on the microdata, leading to proper estimates of the measures of location and association.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05105v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>M. Ros\'ario Oliveira, Diogo Pinheiro, Lina Oliveira</dc:creator>
    </item>
    <item>
      <title>Distributional stability of sparse inverse covariance matrix estimators</title>
      <link>https://arxiv.org/abs/2407.05110</link>
      <description>arXiv:2407.05110v1 Announce Type: new 
Abstract: Finding an approximation of the inverse of the covariance matrix, also known as precision matrix, of a random vector with empirical data is widely discussed in finance and engineering. In data-driven problems, empirical data may be ``contaminated''. This raises the question as to whether the approximate precision matrix is reliable from a statistical point of view. In this paper, we concentrate on a much-noticed sparse estimator of the precision matrix and investigate the issue from the perspective of distributional stability. Specifically, we derive an explicit local Lipschitz bound for the distance between the distributions of the sparse estimator under two different distributions (regarded as the true data distribution and the distribution of ``contaminated'' data). The distance is measured by the Kantorovich metric on the set of all probability measures on a matrix space. We also present analogous results for the standard estimators of the covariance matrix and its eigenvalues. Furthermore, we discuss two applications and conduct some numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05110v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renjie Chen, Huifu Xu, Henryk Z\"ahle</dc:creator>
    </item>
    <item>
      <title>Tail Index Estimation for Discrete Heavy-Tailed Distributions</title>
      <link>https://arxiv.org/abs/2407.05281</link>
      <description>arXiv:2407.05281v1 Announce Type: new 
Abstract: It is the purpose of this paper to investigate the issue
  of estimating the regularity index $\beta&gt;0$ of a discrete
  heavy-tailed r.v. $S$, \textit{i.e.} a r.v. $S$ valued
  in $\mathbb{N}^*$ such that $\mathbb{P}(S&gt;n)=L(n)\cdot n^{-\beta}$
  for all $n\geq 1$, where $L:\mathbb{R}^*_+\to \mathbb{R}_+$
  is a slowly varying function. As a first go, we consider the
  situation where inference is based on independent copies
  $S_1,\; \ldots,\; S_n$ of the generic variable $S$. Just
  like the popular Hill estimator in the continuous
  heavy-tail situation, the estimator $\widehat{\beta}$ we
  propose can be derived by means of a suitable
  reformulation of the regularly varying condition,
  replacing $S$'s survivor function by its empirical
  counterpart. Under mild assumptions, a non-asymptotic
  bound for the deviation between $\widehat{\beta}$ and
  $\beta$ is established, as well as limit results
  (consistency and asymptotic normality). Beyond the
  i.i.d. case, the inference method proposed is extended
  to the estimation of the regularity index of a
  regenerative $\beta$-null recurrent Markov chain. Since
  the parameter $\beta$ can be then viewed as the tail
  index of the (regularly varying) distribution of the
  return time of the chain $X$ to any (pseudo-)
  regenerative set, in this case, the estimator is
  constructed from the successive regeneration times.
  Because the durations between consecutive regeneration
  times are asymptotically independent, we can prove that
  the consistency of the estimator promoted is preserved.
  In addition to the theoretical analysis carried out,
  simulation results provide empirical evidence of the
  relevance of the inference technique proposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05281v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrice Bertail, Stephan Cl\'emen\c{c}on, Carlos Fern\'andez</dc:creator>
    </item>
    <item>
      <title>Regenerative bootstrap for $\beta$-null recurrent Markov chains</title>
      <link>https://arxiv.org/abs/2407.05284</link>
      <description>arXiv:2407.05284v1 Announce Type: new 
Abstract: Two regeneration-based bootstrap methods, namely, the
  \textit{Regeneration based-bootstrap} \cite{AthreyaFuh1992, Somnat-1993} and the
  \textit{Regenerative Block bootstrap} \cite{Bertail2006} are shown to be valid
  for the problem of estimating the integral of a function with respect to the invariant measure
  in a $\beta$-null recurrent Markov chain with an accessible atom.
  An extension of the Central Limit Theorem for randomly indexed sequences
  is also presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05284v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Fern\'andez</dc:creator>
    </item>
    <item>
      <title>Harris recurrent Markov chains and nonlinear monotone cointegrated models</title>
      <link>https://arxiv.org/abs/2407.05294</link>
      <description>arXiv:2407.05294v1 Announce Type: new 
Abstract: In this paper, we study a nonlinear cointegration-type model of the form
  \(Z_t = f_0(X_t) + W_t\) where \(f_0\) is a monotone function and \(X_t\)
  is a Harris recurrent Markov chain. We use a nonparametric Least Square
  Estimator to locally estimate \(f_0\), and under mild conditions, we show
  its strong consistency and obtain its rate of convergence. New results
  (of the Glivenko-Cantelli type) for localized null recurrent Markov chains
  are also proved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05294v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrice Bertail, C\'ecile Durot, Carlos Fern\'andez</dc:creator>
    </item>
    <item>
      <title>Pareto processes for threshold exceedances in spatial extremes</title>
      <link>https://arxiv.org/abs/2407.05699</link>
      <description>arXiv:2407.05699v1 Announce Type: new 
Abstract: We review some recent development in the theory of spatial extremes related to Pareto Processes and modeling of threshold exceedances. We provide theoretical background, methodology for modeling, simulation and inference as well as an illustration to wave height modelling. This preprint is an author version of a chapter to appear in a collaborative book.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05699v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Clement Dombry (UFC, LMB), Juliette Legrand (UBO, LMBA), Thomas Opitz (BioSP)</dc:creator>
    </item>
    <item>
      <title>On the differentiability of $\phi$-projections in the discrete finite case</title>
      <link>https://arxiv.org/abs/2407.05997</link>
      <description>arXiv:2407.05997v1 Announce Type: new 
Abstract: In the case of finite measures on finite spaces, we state conditions under which $\phi$-projections are continuously differentiable. When the set on which one wishes to $\phi$-project is convex, we show that the required assumptions are implied by easily verifiable conditions. In particular, for input probability vectors and a rather large class of \phidivergences, we obtain that $\phi$-projections are continuously differentiable when projecting on a set defined by linear equalities. The obtained results are applied to the derivation of the asymptotics of $\phi$-projection estimators (that is, minimum \phidivergence\, estimators) when projecting on parametric sets of probability vectors, on sets of probability vectors generated from distributions with certain moments fixed and on Fr\'echet classes of bivariate probability arrays. The resulting asymptotics hold whether the element to be $\phi$-projected belongs to the set on which one wishes to $\phi$-project or not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05997v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gery Geenens, Ivan Kojadinovic, Tommaso Martini</dc:creator>
    </item>
    <item>
      <title>Coupled Stochastic-Statistical Equations for Filtering Multiscale Turbulent Systems</title>
      <link>https://arxiv.org/abs/2407.04881</link>
      <description>arXiv:2407.04881v1 Announce Type: cross 
Abstract: We present a new strategy for filtering high-dimensional multiscale systems characterized by high-order non-Gaussian statistics using observations from leading-order moments. A closed stochastic-statistical modeling framework suitable for systematic theoretical analysis and efficient numerical simulations is designed. Optimal filtering solutions are derived based on the explicit coupling structures of stochastic and statistical equations subject to linear operators, which satisfy an infinite-dimensional Kalman-Bucy filter with conditional Gaussian dynamics. To facilitate practical implementation, we develop a finite-dimensional stochastic filter model that approximates the optimal filter solution. We prove that this approximating filter effectively captures key non-Gaussian features, demonstrating consistent statistics with the optimal filter first in its analysis step update, then at the long-time limit guaranteeing stable convergence to the optimal filter. Finally, we build a practical ensemble filter algorithm based on the approximating filtering model, which enables accurate recovery of the true model statistics. The proposed modeling and filtering strategies are applicable to a wide range challenging problems in science and engineering, particularly for statistical prediction and uncertainty quantification of multiscale turbulent states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04881v1</guid>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>nlin.CD</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Di Qi, Jian-Guo Liu</dc:creator>
    </item>
    <item>
      <title>Matrix perturbation bounds via contour bootstrapping</title>
      <link>https://arxiv.org/abs/2407.05230</link>
      <description>arXiv:2407.05230v1 Announce Type: cross 
Abstract: Matrix perturbation bounds play an essential role in the design and analysis of spectral algorithms. In this paper, we introduce a new method to deduce matrix perturbation bounds, which we call "contour bootstrapping". As applications, we work out several new bounds for eigensubspace computation and low rank approximation. Next, we use these bounds to study utility problems in the area of differential privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05230v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Phuc Tran, Van Vu</dc:creator>
    </item>
    <item>
      <title>Einstein from Noise: Statistical Analysis</title>
      <link>https://arxiv.org/abs/2407.05277</link>
      <description>arXiv:2407.05277v1 Announce Type: cross 
Abstract: ``Einstein from noise" (EfN) is a prominent example of the model bias phenomenon: systematic errors in the statistical model that lead to erroneous but consistent estimates. In the EfN experiment, one falsely believes that a set of observations contains noisy, shifted copies of a template signal (e.g., an Einstein image), whereas in reality, it contains only pure noise observations. To estimate the signal, the observations are first aligned with the template using cross-correlation, and then averaged. Although the observations contain nothing but noise, it was recognized early on that this process produces a signal that resembles the template signal! This pitfall was at the heart of a central scientific controversy about validation techniques in structural biology.
  This paper provides a comprehensive statistical analysis of the EfN phenomenon above. We show that the Fourier phases of the EfN estimator (namely, the average of the aligned noise observations) converge to the Fourier phases of the template signal, explaining the observed structural similarity. Additionally, we prove that the convergence rate is inversely proportional to the number of noise observations and, in the high-dimensional regime, to the Fourier magnitudes of the template signal. Moreover, in the high-dimensional regime, the Fourier magnitudes converge to a scaled version of the template signal's Fourier magnitudes. This work not only deepens the theoretical understanding of the EfN phenomenon but also highlights potential pitfalls in template matching techniques and emphasizes the need for careful interpretation of noisy observations across disciplines in engineering, statistics, physics, and biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05277v1</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amnon Balanov, Wasim Huleihel, Tamir Bendory</dc:creator>
    </item>
    <item>
      <title>Sharp Large Deviations for the Number of Descents and the Major Index in a Random Permutation</title>
      <link>https://arxiv.org/abs/2407.05708</link>
      <description>arXiv:2407.05708v1 Announce Type: cross 
Abstract: The aim of this paper is to improve the large deviation principle for the number of descents in a random permutation by establishing a sharp large deviation principle of any order. We shall also prove a sharp large deviation principle of any order for the major index in a random permutation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05708v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernard Bercu (IMB), Michel Bonnefont (IMB), Luis Fredes (IMB), Adrien Richou (IMB)</dc:creator>
    </item>
    <item>
      <title>Optimal Sparse Singular Value Decomposition for High-dimensional High-order Data</title>
      <link>https://arxiv.org/abs/1809.01796</link>
      <description>arXiv:1809.01796v2 Announce Type: replace 
Abstract: In this article, we consider the sparse tensor singular value decomposition, which aims for dimension reduction on high-dimensional high-order data with certain sparsity structure. A method named Sparse Tensor Alternating Thresholding for Singular Value Decomposition (STAT-SVD) is proposed. The proposed procedure features a novel double projection \&amp; thresholding scheme, which provides a sharp criterion for thresholding in each iteration. Compared with regular tensor SVD model, STAT-SVD permits more robust estimation under weaker assumptions. Both the upper and lower bounds for estimation accuracy are developed. The proposed procedure is shown to be minimax rate-optimal in a general class of situations. Simulation studies show that STAT-SVD performs well under a variety of configurations. We also illustrate the merits of the proposed procedure on a longitudinal tensor dataset on European country mortality rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:1809.01796v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anru Zhang, Rungang Han</dc:creator>
    </item>
    <item>
      <title>Inference for Non-Stationary Heavy Tailed Time Series</title>
      <link>https://arxiv.org/abs/2212.11253</link>
      <description>arXiv:2212.11253v3 Announce Type: replace 
Abstract: We consider the problem of inference for non-stationary time series with heavy-tailed error distribution. Under a time-varying linear process framework we show that there exists a suitable local approximation by a stationary process with heavy-tails. This enable us to introduce a local approximation-based estimator which estimates consistently time-varying parameters of the model at hand. To develop a robust method, we also suggest a self-weighing scheme which is shown to recover the asymptotic normality of the estimator regardless of whether the finite variance of the underlying process exists. Empirical evidence favoring this approach is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11253v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fumiya Akashi, Konstantinos Fokianos, Junichi Hirukawa</dc:creator>
    </item>
    <item>
      <title>Consistency of matrix decomposition factor analysis</title>
      <link>https://arxiv.org/abs/2403.06968</link>
      <description>arXiv:2403.06968v2 Announce Type: replace 
Abstract: For factor analysis, many estimators, starting with the maximum likelihood estimator, have been developed, and the statistical properties of most estimators have been well explored. In the early 2000s, a new estimator based on matrix factorization, called Matrix Decomposition Factor Analysis (MDFA), was developed. Although the estimator is obtained by minimizing the principal component analysis-like loss function, this estimator empirically behaves like other consistent estimators of factor analysis, not principal component analysis. Since the MDFA estimator cannot be formulated as a classical M-estimator, the statistical properties of the MDFA estimator have yet to be discussed. To explain this unexpected behavior theoretically, we establish the consistency of the MDFA estimator for factor analysis. That is, we show that the MDFA estimator converges to the same limit as other consistent estimators of factor analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06968v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yoshikazu Terada</dc:creator>
    </item>
    <item>
      <title>Model-based causal feature selection for general response types</title>
      <link>https://arxiv.org/abs/2309.12833</link>
      <description>arXiv:2309.12833v4 Announce Type: replace-cross 
Abstract: Discovering causal relationships from observational data is a fundamental yet challenging task. Invariant causal prediction (ICP, Peters et al., 2016) is a method for causal feature selection which requires data from heterogeneous settings and exploits that causal models are invariant. ICP has been extended to general additive noise models and to nonparametric settings using conditional independence tests. However, the latter often suffer from low power (or poor type I error control) and additive noise models are not suitable for applications in which the response is not measured on a continuous scale, but reflects categories or counts. Here, we develop transformation-model (TRAM) based ICP, allowing for continuous, categorical, count-type, and uninformatively censored responses (these model classes, generally, do not allow for identifiability when there is no exogenous heterogeneity). As an invariance test, we propose TRAM-GCM based on the expected conditional covariance between environments and score residuals with uniform asymptotic level guarantees. For the special case of linear shift TRAMs, we also consider TRAM-Wald, which tests invariance based on the Wald statistic. We provide an open-source R package 'tramicp' and evaluate our approach on simulated data and in a case study investigating causal features of survival in critically ill patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12833v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Kook, Sorawit Saengkyongam, Anton Rask Lundborg, Torsten Hothorn, Jonas Peters</dc:creator>
    </item>
    <item>
      <title>The optimizing mode classification stabilization of sampled stochastic jump systems via an improved hill-climbing algorithm based on Q-learning</title>
      <link>https://arxiv.org/abs/2402.17539</link>
      <description>arXiv:2402.17539v2 Announce Type: replace-cross 
Abstract: This paper addresses the stabilization problem of stochastic jump systems (SJSs) closed by a generally sampled controller. Because of the controller's switching and state both sampled, it is challenging to study its stabilization. A new stabilizing method deeply depending on the mode classifications is proposed to deal with the above sampling situation, whose quantity is equal to a Stirling number of the second kind. For the sake of finding the best stabilization effect among all the classifications, a convex optimization problem is developed, whose globally solution is proved to be existent and can be computed by an augmented Lagrangian function. More importantly, in order to further reduce the computation complexity but retaining a better performance as much as possible, a novelly improved hill-climbing algorithm is established by applying the Q-learning technique to provide an optimal attenuation coefficient. A numerical example is offered so as to verify the effectiveness and superiority of the methods proposed in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17539v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guoliang Wang</dc:creator>
    </item>
    <item>
      <title>Information limits and Thouless-Anderson-Palmer equations for spiked matrix models with structured noise</title>
      <link>https://arxiv.org/abs/2405.20993</link>
      <description>arXiv:2405.20993v2 Announce Type: replace-cross 
Abstract: We consider a prototypical problem of Bayesian inference for a structured spiked model: a low-rank signal is corrupted by additive noise. While both information-theoretic and algorithmic limits are well understood when the noise is a Gaussian Wigner matrix, the more realistic case of structured noise still proves to be challenging. To capture the structure while maintaining mathematical tractability, a line of work has focused on rotationally invariant noise. However, existing studies either provide sub-optimal algorithms or are limited to special cases of noise ensembles. In this paper, using tools from statistical physics (replica method) and random matrix theory (generalized spherical integrals) we establish the first characterization of the information-theoretic limits for a noise matrix drawn from a general trace ensemble. Remarkably, our analysis unveils the asymptotic equivalence between the rotationally invariant model and a surrogate Gaussian one. Finally, we show how to saturate the predicted statistical limits using an efficient algorithm inspired by the theory of adaptive Thouless-Anderson-Palmer (TAP) equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20993v2</guid>
      <category>cs.IT</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean Barbier, Francesco Camilli, Marco Mondelli, Yizhou Xu</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Doubly Robust Learning for Causal Inference</title>
      <link>https://arxiv.org/abs/2406.00853</link>
      <description>arXiv:2406.00853v2 Announce Type: replace-cross 
Abstract: Doubly robust learning offers a robust framework for causal inference from observational data by integrating propensity score and outcome modeling. Despite its theoretical appeal, practical adoption remains limited due to perceived complexity and inaccessible software. This tutorial aims to demystify doubly robust methods and demonstrate their application using the EconML package. We provide an introduction to causal inference, discuss the principles of outcome modeling and propensity scores, and illustrate the doubly robust approach through simulated case studies. By simplifying the methodology and offering practical coding examples, we intend to make doubly robust learning accessible to researchers and practitioners in data science and statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00853v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hlynur Dav\'i{\dh} Hlynsson</dc:creator>
    </item>
  </channel>
</rss>
