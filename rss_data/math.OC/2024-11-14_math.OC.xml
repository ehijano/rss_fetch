<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Nov 2024 02:35:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Input-to-State Stability of time-varying infinite-dimensional control systems</title>
      <link>https://arxiv.org/abs/2411.08075</link>
      <description>arXiv:2411.08075v1 Announce Type: new 
Abstract: The concept of input-to-state stability (ISS) proposed in the late 1980s is one of the central notions in robust nonlinear control. ISS has become indispensable for various branches of nonlinear systems theory, such as robust stabilization of nonlinear systems, design of nonlinear observers, analysis of large-scale networks, etc. The success of the ISS theory of ODEs and the need for robust stability analysis of partial differential equations (PDEs) motivated the development of ISS theory in the infinite-dimensional setting. For instance, the Lyapunov method for analysis of iISS of nonlinear parabolic equations. For an overview of the ISS theory for distributed parameter systems. ISS of control systems with application to robust global stabilization of the chemostat has been studied with the help of vector Lyapunov functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08075v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahma Heni</dc:creator>
    </item>
    <item>
      <title>On the inadequacy of nudging data assimilation algorithms for non-dissipative systems: A computational examination of the Korteweg de-Vries and Lorenz equations</title>
      <link>https://arxiv.org/abs/2411.08273</link>
      <description>arXiv:2411.08273v1 Announce Type: new 
Abstract: In this work, we study the applicability of the Azouani-Olson-Titi (AOT) nudging algorithm for continuous data assimilation to evolutionary dynamical systems that are not dissipative. Specifically, we apply the AOT algorithm to the Korteweg de-Vries (KdV) equation and a partially dissipative variant of the Lorenz 1963 system. Our analysis reveals that the KdV equation lacks the finitely many determining modes property, leading to the construction of infinitely many solutions with exactly the same sparse observational data, which data assimilation methods cannot distinguish between. We numerically verify that the AOT algorithm successfully recovers these counterexamples for the damped and driven KdV equation, as studied in [1], which is dissipative. Additionally, we demonstrate numerically that the AOT algorithm is not effective in accurately recovering solutions for a partially dissipative variant of the Lorenz 1963 system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08273v1</guid>
      <category>math.OC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edriss S. Titi, Collin Victor</dc:creator>
    </item>
    <item>
      <title>Communication Efficient Decentralization for Smoothed Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.08355</link>
      <description>arXiv:2411.08355v1 Announce Type: new 
Abstract: We study the multi-agent Smoothed Online Convex Optimization (SOCO) problem, where $N$ agents interact through a communication graph. In each round, each agent $i$ receives a strongly convex hitting cost function $f^i_t$ in an online fashion and selects an action $x^i_t \in \mathbb{R}^d$. The objective is to minimize the global cumulative cost, which includes the sum of individual hitting costs $f^i_t(x^i_t)$, a temporal "switching cost" for changing decisions, and a spatial "dissimilarity cost" that penalizes deviations in decisions among neighboring agents. We propose the first decentralized algorithm for multi-agent SOCO and prove its asymptotic optimality. Our approach allows each agent to operate using only local information from its immediate neighbors in the graph. For finite-time performance, we establish that the optimality gap in competitive ratio decreases with the time horizon $T$ and can be conveniently tuned based on the per-round computation available to each agent. Moreover, our results hold even when the communication graph changes arbitrarily and adaptively over time. Finally, we establish that the computational complexity per round depends only logarithmically on the number of agents and almost linearly on their degree within the graph, ensuring scalability for large-system implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08355v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neelkamal Bhuyan, Debankur Mukherjee, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>Auto-tuned Primal-dual Successive Convexification for Hypersonic Reentry Guidance</title>
      <link>https://arxiv.org/abs/2411.08361</link>
      <description>arXiv:2411.08361v2 Announce Type: new 
Abstract: This paper presents auto-tuned primal-dual successive convexification (Auto-SCvx), an algorithm designed to reliably achieve dynamically-feasible trajectory solutions for constrained hypersonic reentry optimal control problems across a large mission parameter space. In Auto-SCvx, we solve a sequence of convex subproblems until convergence to a solution of the original nonconvex problem. This method iteratively optimizes dual variables in closed-form in order to update the penalty hyperparameters used in the primal variable updates. A benefit of this method is that it is auto-tuning, and requires no hand-tuning by the user with respect to the constraint penalty weights. Several example hypersonic reentry problems are posed and solved using this method, and comparative studies are conducted against current methods. In these numerical studies, our algorithm demonstrates equal and often improved performance while not requiring hand-tuning of penalty hyperparameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08361v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Skye Mceowen, Daniel J. Calderone, Aman Tiwary, Jason S. K. Zhou, Taewan Kim, Purnanand Elango, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>Tractable Robust Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2411.08435</link>
      <description>arXiv:2411.08435v1 Announce Type: new 
Abstract: In this paper we investigate the tractability of robust Markov Decision Processes (RMDPs) under various structural assumptions on the uncertainty set. Surprisingly, we show that in all generality (i.e. without any assumption on the instantaneous rewards), s-rectangular and sa-rectangular uncertainty sets are the only models of uncertainty that are tractable. Our analysis also shows that existing non-rectangular models, including r-rectangular uncertainty and new generalizations, are only weakly tractable in that they require an additional structural assumption that the instantaneous rewards do not depend on the next state, and in this case they are equivalent to rectangular models, which severely undermines their significance and usefulness. Interestingly, our proof techniques rely on identifying a novel simultaneous solvability property, which we show is at the heart of several important properties of RMDPs, including the existence of stationary optimal policies and dynamic programming-based formulations. The simultaneous solvability property enables a unified approach to studying the tractability of all existing models of uncertainty, rectangular and non-rectangular alike.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08435v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Grand-Cl\'ement, Nian Si, Shengbo Wang</dc:creator>
    </item>
    <item>
      <title>Revisiting Atomic Norm Minimization: A Sequential Approach for Atom Identification and Refinement</title>
      <link>https://arxiv.org/abs/2411.08459</link>
      <description>arXiv:2411.08459v1 Announce Type: new 
Abstract: Atomic norm minimization (ANM) is a key approach for line spectral estimation (LSE). Most related algorithms formulate ANM as a semidefinite programming (SDP), which incurs high computational cost. In this letter, we revisit the ANM problem and present a novel limit-based formulation, which dissects the essential components of the semidefinite characterization of ANM. Our new formulation does not depend on SDP and can be extended to handle more general atomic sets beyond mixture of complex sinusoids. Furthermore, we reveal the connection between ANM and Bayesian LSE approaches, bridging the gap between these two methodologies. Based on this new formulation, we propose a low-complexity algorithm called Sequential Atom Identification and Refinement (SAIR) for ANM. Simulation results demonstrate that SAIR achieves superior estimation accuracy and computational efficiency compared to other state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08459v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaozhi Liu, Jinjiang Wei, Yong Xia</dc:creator>
    </item>
    <item>
      <title>$\ell_0$ factor analysis</title>
      <link>https://arxiv.org/abs/2411.08468</link>
      <description>arXiv:2411.08468v1 Announce Type: new 
Abstract: Factor Analysis is about finding a low-rank plus sparse additive decomposition from a noisy estimate of the signal covariance matrix. In order to get such a decomposition, we formulate an optimization problem using the nuclear norm for the low-rank component, the $\ell_0$ norm for the sparse component, and the Kullback-Leibler divergence to control the residual in the sample covariance matrix. An alternating minimization algorithm is designed for the solution of the optimization problem. The effectiveness of the algorithm is verified via simulations on synthetic and real datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08468v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linyang Wang, Wanquan Liu, Bin Zhu</dc:creator>
    </item>
    <item>
      <title>On the numerical integration of the Fokker-Planck equation driven by a mechanical force and the Bismut-Elworthy-Li formula</title>
      <link>https://arxiv.org/abs/2411.08518</link>
      <description>arXiv:2411.08518v1 Announce Type: new 
Abstract: Optimal control theory aims to find an optimal protocol to steer a system between assigned boundary conditions while minimizing a given cost functional in finite time. Equations arising from these types of problems are often non-linear and difficult to solve numerically. In this note, we describe numerical methods of integration for two partial differential equations that commonly arise in optimal control theory: the Fokker-Planck equation driven by a mechanical potential for which we use Girsanov theorem; and the Hamilton-Jacobi-Bellman, or dynamic programming, equation for which we find the gradient of its solution using the Bismut-Elworthy-Li formula. The computation of the gradient is necessary to specify the optimal protocol. Finally, we give an example application in solving an optimal control problem without spacial discretization by machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08518v1</guid>
      <category>math.OC</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Sanders, Paolo Muratore-Ginanneschi</dc:creator>
    </item>
    <item>
      <title>Convergence Rate of Payoff-based Generalized Nash Equilibrium Learning</title>
      <link>https://arxiv.org/abs/2411.08595</link>
      <description>arXiv:2411.08595v1 Announce Type: new 
Abstract: We consider generalized Nash equilibrium (GNE) problems in games with strongly monotone pseudo-gradients and jointly linear coupling constraints. We establish the convergence rate of a payoff-based approach intended to learn a variational GNE (v-GNE) in such games. While convergent algorithms have recently been proposed in this setting given full or partial information of the gradients, rate of convergence in the payoff-based information setting has been an open problem. Leveraging properties of a game extended from the original one by a dual player, we establish a convergence rate of $O(\frac{1}{t^{4/7}})$ to a v-GNE of the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08595v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatiana Tatarenko, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>Restoring Accessibility During Urban Rail Disruptions via Bus Network Redesign</title>
      <link>https://arxiv.org/abs/2411.08782</link>
      <description>arXiv:2411.08782v1 Announce Type: new 
Abstract: In broad terms, accessibility measures opportunities reachable (such as shops, residents, etc.) within a given time frame. Urban Rail Transit (URT) plays a crucial role in providing accessibility, but it is susceptible to disruptions. In city centers with dense public transport (PT) networks, travelers can often find alternative lines. However, in suburbs where PT is sparse, disruptions have a more significant impact on accessibility. The traditional approach consists in deploying bridge and replacement buses to mitigate URT disruptions without specific care to accessibility. Yet, the question arises: is this approach the most effective way to restore accessibility? To the best of our knowledge, our paper is the first to propose a bus re-routing method with the objective of restoring accessibility during URT disruptions. We formulate an integer program and develop a two-stage heuristic algorithm to maximize restored accessibility. The efficacy of our method is always the present assessed in \'Evry-Courcouronnes and Choisy-le-Roi, France. The results show that, compared to conventional replacement methods, our strategy improves accessibility in particular in the areas most affected by the disruption. Such results are observed even when no additional vehicles are deployed, and at the same time, achieving a reduction in the kilometers traveled. Despite it is well understood that accessibility is the most relevant benefit a transportation system can produce, this aspect is reflected by the traditional approaches in remediation to disruption. With this work, we show instead how to make accessibility the main guiding principle in remediation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08782v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zihao Guo, Andrea Araldo, Moun\^im A. El Yacoubi</dc:creator>
    </item>
    <item>
      <title>The Impact of Social Value Orientation on Nash Equilibria of Two Player Quadratic Games</title>
      <link>https://arxiv.org/abs/2411.08809</link>
      <description>arXiv:2411.08809v1 Announce Type: new 
Abstract: We consider two player quadratic games in a cooperative framework known as social value orientation, motivated by the need to account for complex interactions between humans and autonomous agents in dynamical systems. Social value orientation is a framework from psychology, that posits that each player incorporates the other player's cost into their own objective function, based on an individually pre-determined degree of cooperation. The degree of cooperation determines the weighting that a player puts on their own cost relative to the other player's cost. We characterize the Nash equilibria of two player quadratic games under social value orientation by creating expansions that elucidate the relative difference between this new equilibria (which we term the SVO-Nash equilibria) and more typical equilibria, such as the competitive Nash equilibria, individually optimal solutions, and the fully cooperative solution. Specifically, each expansion parametrizes the space of cooperative Nash equilibria as a family of one-dimensional curves where each curve is computed by solving an eigenvalue problem. We show that both bounded and unbounded equilibria may exist. For equilibria that are bounded, we can identify bounds as the intersection of various ellipses; for equilibria that are unbounded, we characterize conditions under which unboundedness will occur, and also compute the asymptotes that the unbounded solutions follow. We demonstrate these results in trajectory coordination scenario modeled as a linear time varying quadratic game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08809v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan Calderone, Meeko Oishi</dc:creator>
    </item>
    <item>
      <title>Conic programming to understand sums of squares of eigenvalues of graphs</title>
      <link>https://arxiv.org/abs/2411.08184</link>
      <description>arXiv:2411.08184v1 Announce Type: cross 
Abstract: In this paper we prove a conjecture by Wocjan, Elphick and Anekstein (2018) which upper bounds the sum of the squares of the positive (or negative) eigenvalues of the adjacency matrix of a graph by an expression that behaves monotonically in terms of the vector chromatic number. One of our lemmas is a strengthening of the Cauchy-Schwarz inequality for Hermitian matrices when one of the matrices is positive semidefinite.
  A related conjecture due to Bollob\'as and Nikiforov (2007) replaces the vector chromatic number by the clique number and sums over the first two eigenvalues only. We prove a version of this conjecture with weaker constants. An important consequence of our work is a proof that for any fixed $r$, computing a rank $r$ optimum solution to the vector chromatic number semidefinite programming is NP-hard.
  We also present a vertex weighted version of some of our results, and we show how it leads quite naturally to the known vertex-weighted version of the Motzkin-Straus quadratic optimization formulation for the clique number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08184v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Coutinho, Thom\'as Jung Spier, Shengtong Zhang</dc:creator>
    </item>
    <item>
      <title>Imitation Learning from Observations: An Autoregressive Mixture of Experts Approach</title>
      <link>https://arxiv.org/abs/2411.08232</link>
      <description>arXiv:2411.08232v1 Announce Type: cross 
Abstract: This paper presents a novel approach to imitation learning from observations, where an autoregressive mixture of experts model is deployed to fit the underlying policy. The parameters of the model are learned via a two-stage framework. By leveraging the existing dynamics knowledge, the first stage of the framework estimates the control input sequences and hence reduces the problem complexity. At the second stage, the policy is learned by solving a regularized maximum-likelihood estimation problem using the estimated control input sequences. We further extend the learning procedure by incorporating a Lyapunov stability constraint to ensure asymptotic stability of the identified model, for accurate multi-step predictions. The effectiveness of the proposed framework is validated using two autonomous driving datasets collected from human demonstrations, demonstrating its practical applicability in modelling complex nonlinear dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08232v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renzi Wang, Flavia Sofia Acerbo, Tong Duy Son, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Improving the convergence of Markov chains via permutations and projections</title>
      <link>https://arxiv.org/abs/2411.08295</link>
      <description>arXiv:2411.08295v1 Announce Type: cross 
Abstract: This paper aims at improving the convergence to equilibrium of finite ergodic Markov chains via permutations and projections. First, we prove that a specific mixture of permuted Markov chains arises naturally as a projection under the KL divergence or the squared-Frobenius norm. We then compare various mixing properties of the mixture with other competing Markov chain samplers and demonstrate that it enjoys improved convergence. This geometric perspective motivates us to propose samplers based on alternating projections to combine different permutations and to analyze their rate of convergence. We give necessary, and under some additional assumptions also sufficient, conditions for the projection to achieve stationarity in the limit in terms of the trace of the transition matrix. We proceed to discuss tuning strategies of the projection samplers when these permutations are viewed as parameters. Along the way, we reveal connections between the mixture and a Markov chain Sylvester's equation as well as assignment problems, and highlight how these can be used to understand and improve Markov chain mixing. We provide two examples as illustrations. In the first example, the projection sampler (with a suitable choice of the permutation) improves upon Metropolis-Hastings in a discrete bimodal distribution with a reduced relaxation time from exponential to polynomial in the system size, while in the second example, the mixture of permuted Markov chain yields a mixing time that is logarithmic in system size (with high probability under random permutation), compared to a linear mixing time in the Diaconis-Holmes-Neal sampler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08295v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Max Hird, Youjia Wang</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Algorithms for Online Concave Packing and Convex Covering Problems</title>
      <link>https://arxiv.org/abs/2411.08332</link>
      <description>arXiv:2411.08332v1 Announce Type: cross 
Abstract: Learning-augmented algorithms have been extensively studied across the computer science community in the recent years, driven by advances in machine learning predictors, which can provide additional information to augment classical algorithms. Such predictions are especially powerful in the context of online problems, where decisions have to be made without knowledge of the future, and which traditionally exhibits impossibility results bounding the performance of any online algorithm. The study of learning-augmented algorithms thus aims to use external advice prudently, to overcome classical impossibility results when the advice is accurate, and still perform comparably to the state-of-the-art online algorithms even when the advice is inaccurate.
  In this paper, we present learning-augmented algorithmic frameworks for two fundamental optimizations settings, extending and generalizing prior works. For online packing with concave objectives, we present a simple but overarching strategy that switches between the advice and the state-of-the-art online algorithm. For online covering with convex objectives, we greatly extend primal-dual methods for online convex covering programs by Azar et al. (FOCS 2016) and previous learning-augmented framework for online covering linear programs from the literature, to many new applications. We show that our algorithms break impossibility results when the advice is accurate, while maintaining comparable performance with state-of-the-art classical online algorithms even when the advice is erroneous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08332v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elena Grigorescu, Young-San Lin, Maoyuan Song</dc:creator>
    </item>
    <item>
      <title>An Ising Machine Formulation for Design Updates in Topology Optimization of Flow Channels</title>
      <link>https://arxiv.org/abs/2411.08405</link>
      <description>arXiv:2411.08405v1 Announce Type: cross 
Abstract: Topology optimization is an essential tool in computational engineering, for example, to improve the design and efficiency of flow channels. At the same time, Ising machines, including digital or quantum annealers, have been used as efficient solvers for combinatorial optimization problems. Beyond combinatorial optimization, recent works have demonstrated applicability to other engineering tasks by tailoring corresponding problem formulations. In this study, we present a novel Ising machine formulation for computing design updates during topology optimization with the goal of minimizing dissipation energy in flow channels. We explore the potential of this approach to improve the efficiency and performance of the optimization process. To this end, we conduct experiments to study the impact of various factors within the novel formulation. Additionally, we compare it to a classical method using the number of optimization steps and the final values of the objective function as indicators of the time intensity of the optimization and the performance of the resulting designs, respectively. Our findings show that the proposed update strategy can accelerate the topology optimization process while producing comparable designs. However, it tends to be less exploratory, which may lead to lower performance of the designs. These results highlight the potential of incorporating Ising formulations for optimization tasks but also show their limitations when used to compute design updates in an iterative optimization process. In conclusion, this work provides an efficient alternative for design updates in topology optimization and enhances the understanding of integrating Ising machine formulations in engineering optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08405v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yudai Suzuki, Shiori Aoki, Fabian Key, Katsuhiro Endo, Yoshiki Matsuda, Shu Tanaka, Marek Behr, Mayu Muramatsu</dc:creator>
    </item>
    <item>
      <title>Robust performance for switched systems with constrained switching and its application to weakly hard real-time control systems</title>
      <link>https://arxiv.org/abs/2411.08436</link>
      <description>arXiv:2411.08436v1 Announce Type: cross 
Abstract: Many cyber-physical systems can naturally be formulated as switched systems with constrained switching. This includes systems where one of the signals in the feedback loop may be lost. Possible sources for losses are shared or unreliable communication media in networked control systems, or signals which are discarded, e.g., when using a shared computation device such as a processor in real-time control applications. The use of switched systems with constrained switching is not limited to cyber-physical systems but, includes many other relevant applications such as power systems and modeling virus mutations. In this chapter, we introduce a framework for analyzing and designing controllers which guarantee robust quadratic performance for switched systems with constrained switching. The possible switching sequences are described by the language of a labeled graph where the labels are linked to the different subsystems. The subsystems are allowed to have different input and output dimensions, and their state-space representations can be affected by a broad class of uncertainties in a rational way. The proposed framework exploits ideas from dissipativity-based linear control theory to derive analysis and synthesis inequalities given by linear matrix inequalities. We demonstrate how the proposed framework can be applied to the design of controllers for uncertain weakly hard real-time control systems - a system class naturally appearing in networked and real-time control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08436v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Lang, Marc Seidel, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Deep Generative Demand Learning for Newsvendor and Pricing</title>
      <link>https://arxiv.org/abs/2411.08631</link>
      <description>arXiv:2411.08631v1 Announce Type: cross 
Abstract: We consider data-driven inventory and pricing decisions in the feature-based newsvendor problem, where demand is influenced by both price and contextual features and is modeled without any structural assumptions. The unknown demand distribution results in a challenging conditional stochastic optimization problem, further complicated by decision-dependent uncertainty and the integration of features. Inspired by recent advances in deep generative learning, we propose a novel approach leveraging conditional deep generative models (cDGMs) to address these challenges. cDGMs learn the demand distribution and generate probabilistic demand forecasts conditioned on price and features. This generative approach enables accurate profit estimation and supports the design of algorithms for two key objectives: (1) optimizing inventory for arbitrary prices, and (2) jointly determining optimal pricing and inventory levels. We provide theoretical guarantees for our approach, including the consistency of profit estimation and convergence of our decisions to the optimal solution. Extensive simulations-ranging from simple to complex scenarios, including one involving textual features-and a real-world case study demonstrate the effectiveness of our approach. Our method opens a new paradigm in management science and operations research, is adaptable to extensions of the newsvendor and pricing problems, and holds potential for solving other conditional stochastic optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08631v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijin Gong, Huihang Liu, Xinyu Zhang</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Algorithm for Finite-Horizon Stochastic Control Problems in Economics</title>
      <link>https://arxiv.org/abs/2411.08668</link>
      <description>arXiv:2411.08668v1 Announce Type: cross 
Abstract: We propose a machine learning algorithm for solving finite-horizon stochastic control problems based on a deep neural network representation of the optimal policy functions. The algorithm has three features: (1) It can solve high-dimensional (e.g., over 100 dimensions) and finite-horizon time-inhomogeneous stochastic control problems. (2) It has a monotonicity of performance improvement in each iteration, leading to good convergence properties. (3) It does not rely on the Bellman equation. To demonstrate the efficiency of the algorithm, it is applied to solve various finite-horizon time-inhomogeneous problems including recursive utility optimization under a stochastic volatility model, a multi-sector stochastic growth, and optimal control under a dynamic stochastic integration of climate and economy model with eight-dimensional state vectors and 600 time periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08668v1</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianhua Peng, Steven Kou, Lekang Zhang</dc:creator>
    </item>
    <item>
      <title>Cutting planes for signomial programming</title>
      <link>https://arxiv.org/abs/2212.02857</link>
      <description>arXiv:2212.02857v3 Announce Type: replace 
Abstract: Cutting planes are of crucial importance when solving nonconvex nonlinear programs to global optimality, for example using the spatial branch-and-bound algorithms. In this paper, we discuss the generation of cutting planes for signomial programming. Many global optimization algorithms lift signomial programs into an extended formulation such that these algorithms can construct relaxations of the signomial program by outer approximations of the lifted set encoding nonconvex signomial term sets, i.e., hypographs, or epigraphs of signomial terms. We show that any signomial term set can be transformed into the subset of the difference of two concave power functions, from which we derive two kinds of valid linear inequalities. Intersection cuts are constructed using signomial term-free sets which do not contain any point of the signomial term set in their interior. We show that these signomial term-free sets are maximal in the nonnegative orthant, and use them to derive intersection sets. We then convexify a concave power function in the reformulation of the signomial term set, resulting in a convex set containing the signomial term set. This convex outer approximation is constructed in an extended space, and we separate a class of valid linear inequalities by projection from this approximation. We implement the valid inequalities in a global optimization solver and test them on MINLPLib instances. Our results show that both types of valid inequalities provide comparable reductions in running time, number of search nodes, and duality gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02857v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liding Xu, Claudia D'Ambrosio, Leo Liberti, Sonia Haddad Vanier</dc:creator>
    </item>
    <item>
      <title>A Unified Analysis on the Subgradient Upper Bounds for the Subgradient Methods Minimizing Composite Nonconvex, Nonsmooth and Non-Lipschitz Functions</title>
      <link>https://arxiv.org/abs/2308.16362</link>
      <description>arXiv:2308.16362v2 Announce Type: replace 
Abstract: This paper presents a unified analysis for the proximal subgradient method (Prox-SubGrad) type approach to minimize an overall objective of $f(x)+r(x)$, subject to convex constraints, where both $f$ and $r$ are weakly convex, nonsmooth, and non-Lipschitz. Leveraging on the properties of the Moreau envelope of weakly convex functions, we are able to relate error-bound conditions, the growth conditions of the subgradients of the objective, and the behavior of the proximal subgradient iterates on some remarkably broad classes of objective functions. Various existing as well as new bounding conditions are studied, leading to novel iteration complexity results. The terrain of our exploration expands to stochastic proximal subgradient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16362v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daoli Zhu, Lei Zhao, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Controlling Large Electric Vehicle Charging Stations via User Behavior Modeling and Stochastic Programming</title>
      <link>https://arxiv.org/abs/2402.13224</link>
      <description>arXiv:2402.13224v4 Announce Type: replace 
Abstract: This paper introduces an Electric Vehicle Charging Station (EVCS) model that incorporates real-world constraints, such as slot power limitations, contract threshold overruns penalties, or early disconnections of electric vehicles (EVs). We propose a formulation of the problem of EVCS control under uncertainty, and implement two Multi-Stage Stochastic Programming approaches that leverage user-provided information, namely, Model Predictive Control and Two-Stage Stochastic Programming. The model addresses uncertainties in charging session start and end times, as well as in energy demand. A user's behavior model based on a sojourn-time-dependent stochastic process enhances cost reduction while maintaining customer satisfaction. The benefits of the two proposed methods are showcased against two baselines over a 22-day simulation using a real-world dataset. The two-stage approach demonstrates robustness against early disconnections by considering a wider range of uncertainty scenarios for optimization. The algorithm prioritizing user satisfaction over electricity cost achieves a 20% and 36% improvement in two user satisfaction metrics compared to an industry-standard baseline. Additionally, the algorithm striking the best balance between cost and user satisfaction exhibits a mere 3% relative cost increase compared to the theoretically optimal baseline - for which the nonanticipativity constraint is relaxed - while attaining 94% and 84% of the user satisfaction performance in the two used satisfaction metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13224v4</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alban Puech, Tristan Rigaut, William Templier, Maud Tournoud</dc:creator>
    </item>
    <item>
      <title>Almost-Surely Convergent Randomly Activated Monotone Operator Splitting Methods</title>
      <link>https://arxiv.org/abs/2403.10673</link>
      <description>arXiv:2403.10673v2 Announce Type: replace 
Abstract: We propose stochastic splitting algorithms for solving large-scale composite inclusion problems involving monotone and linear operators. They activate at each iteration blocks of randomly selected resolvents of monotone operators and, unlike existing methods, achieve almost sure convergence of the iterates to a solution without any regularity assumptions or knowledge of the norms of the linear operators. Applications to image recovery and machine learning are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10673v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>Optimal Transport and Wasserstein Barycenter for Radial Contoured Distributions</title>
      <link>https://arxiv.org/abs/2404.08383</link>
      <description>arXiv:2404.08383v3 Announce Type: replace 
Abstract: The optimal transport and Wasserstein barycenter of Gaussian distributions have been solved. In literature, the closed form formulas of the Monge map, the Wasserstein distance and the Wasserstein barycenter have been given. Moreover, when Gaussian distributions extend more generally to elliptical contoured distributions, similar results also hold true. In this case, Gaussian distributions are regarded as elliptical contoured distribution with generator function $e^{-x/2}$. However, there are few results about optimal transport for elliptical contoured distributions with different generator functions. In this paper, we degenerate elliptical contoured distributions to radial contoured distributions and study their optimal transport and prove their Wasserstein barycenter is still radial contoured. For general elliptical contoured distributions, we give two numerical counterexamples to show that the Wasserstein barycenter of elliptical contoured distributions does not have to be elliptical contoured.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08383v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keyu Chen, Yunxin Zhang</dc:creator>
    </item>
    <item>
      <title>Average-case optimization analysis for distributed consensus algorithms on regular graphs</title>
      <link>https://arxiv.org/abs/2409.00605</link>
      <description>arXiv:2409.00605v3 Announce Type: replace 
Abstract: The consensus problem in distributed computing involves a network of agents aiming to compute the average of their initial vectors through local communication, represented by an undirected graph. This paper focuses on the studying of this problem using an average-case analysis approach, particularly over regular graphs. Traditional algorithms for solving the consensus problem often rely on worst-case performance evaluation scenarios, which may not reflect typical performance in real-world applications. Instead, we apply average-case analysis, focusing on the expected spectral distribution of eigenvalues to obtain a more realistic view of performance. Key contributions include deriving the optimal method for consensus on regular graphs, showing its relation to the Heavy Ball method, analyzing its asymptotic convergence rate, and comparing it to various first-order methods through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00605v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nhat Trung Nguyen, Alexander Rogozin, Alexander Gasnikov</dc:creator>
    </item>
    <item>
      <title>On NP-Hardness of $L_1/L_2$ Minimization and Bound Theory of Nonzero Entries in Solutions</title>
      <link>https://arxiv.org/abs/2409.18748</link>
      <description>arXiv:2409.18748v3 Announce Type: replace 
Abstract: The \(L_1/L_2\) norm ratio has gained significant attention as a measure of sparsity due to three merits: sharper approximation to the \(L_0\) norm compared to the \(L_1\) norm, being parameter-free and scale-invariant, and exceptional performance with highly coherent matrices. These properties have led to its successful application across a wide range of fields. While several efficient algorithms have been proposed to compute stationary points for \(L_1/L_2\) minimization problems, their computational complexity has remained open. In this paper, we prove that finding the global minimum of both constrained and unconstrained \(L_1/L_2\) models is strongly NP-hard.
  In addition, we establish uniform upper bounds on the \(L_2\) norm for any local minimizer of both constrained and unconstrained \(L_1/L_2\) minimization models. We also derive upper and lower bounds on the magnitudes of the nonzero entries in any local minimizer of the unconstrained model, aiding in classifying nonzero entries. Finally, we extend our analysis to demonstrate that the constrained and unconstrained \(L_p/L_q\) (\(0 &lt; p \leq 1, 1 &lt; q &lt; +\infty\)) models are also strongly NP-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18748v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min Tao, Xiao-Ping Zhang, Yun-Bin Zhao</dc:creator>
    </item>
    <item>
      <title>Domain decomposition for entropic unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2410.08859</link>
      <description>arXiv:2410.08859v2 Announce Type: replace 
Abstract: Solving large scale entropic optimal transport problems with the Sinkhorn algorithm remains challenging, and domain decomposition has been shown to be an efficient strategy for problems on large grids. Unbalanced optimal transport is a versatile variant of the balanced transport problem and its entropic regularization can be solved with an adapted Sinkhorn algorithm. However, it is a priori unclear how to apply domain decomposition to unbalanced problems since the independence of the cell problems is lost. In this article we show how this difficulty can be overcome at a theoretical and practical level and demonstrate with experiments that domain decomposition is also viable and efficient on large unbalanced entropic transport problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08859v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ismael Medina, The Sang Nguyen, Bernhard Schmitzer</dc:creator>
    </item>
    <item>
      <title>Sensitivity analysis for linear changes of the constraint matrix of a linear program</title>
      <link>https://arxiv.org/abs/2410.14443</link>
      <description>arXiv:2410.14443v2 Announce Type: replace 
Abstract: Understanding the variation of the optimal value with respect to change in the data is an old problem of mathematical optimisation. This paper focuses on the linear problem $f(\lambda) = \min c^t x$ such that $(A+\lambda D)x \leq b$, where $\lambda$ is an unknown parameter that varies within an interval and $D$ is a matrix modifying the coefficients of the constraint matrix $A$. This problem is used to analyse the impact of multiple affine changes in the constraint matrix on the objective function. The function $f(\lambda)$ can have an erratic behaviour and computing it for a large number of points is computationally heavy while not providing any guarantees in between the computed points. As a new approach to the problem, we derive several bounding methods that provide guarantees on the objective function's behaviour. Those guarantees can be exploited to avoid recomputing the problem for numerous $\lambda$. The bounding methods are based on approaches from robust optimisation or Lagrangian relaxations. For each approach, we derive three methods of increasing complexity and precision, one that provides constant bounds, one that provides $\lambda$-dependant bounds and envelope bounds. We assess each bounding method in terms of precision, availability and timing. We show that for a large number of problems, the bound approach outperforms the naive sampling approach considered with 100 points while still providing a good precision and stronger guarantees on a large dataset of problems. We also introduce an iterative algorithm that uses these bounds to compute an approximation of the original function within a given error threshold and discuss its performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14443v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Bardhyl Miftari, Quentin Louveaux, Damien Ernst, Guillaume Derval</dc:creator>
    </item>
    <item>
      <title>Pathwise Optimal Control and Rough Fractional Hamilton-Jacobi-Bellman Equations for Rough-Fractional Dynamics</title>
      <link>https://arxiv.org/abs/2411.05488</link>
      <description>arXiv:2411.05488v2 Announce Type: replace 
Abstract: We use a rough path-based approach to investigate the degeneracy problem in the context of pathwise control. We extend the framework developed in arXiv:1902.05434 to treat admissible controls from a suitable class of H\"older continuous paths and simultaneously to handle a broader class of noise terms. Our approach uses fractional calculus to augment the original control equation, resulting in a system with added fractional dynamics. We adapt the existing analysis of fractional systems from the work of Gomoyunov arXiv:1908.01747, arXiv:2111.14400v1 , arXiv:2109.02451 to this new setting, providing a notion of a rough fractional viscosity solution for fractional systems that involve a noise term of arbitrarily low regularity. In this framework, following the method outlined in arXiv:1902.05434, we derive sufficient conditions to ensure that the control problem remains non-degenerate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05488v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Iannucci, Dan Crisan, Thomas Cass</dc:creator>
    </item>
    <item>
      <title>Reduced Sample Complexity in Scenario-Based Control System Design via Constraint Scaling</title>
      <link>https://arxiv.org/abs/2411.07361</link>
      <description>arXiv:2411.07361v2 Announce Type: replace 
Abstract: The scenario approach is widely used in robust control system design and chance-constrained optimization, maintaining convexity without requiring assumptions about the probability distribution of uncertain parameters. However, the approach can demand large sample sizes, making it intractable for safety-critical applications that require very low levels of constraint violation. To address this challenge, we propose a novel yet simple constraint scaling method, inspired by large deviations theory. Under mild nonparametric conditions on the underlying probability distribution, we show that our method yields an exponential reduction in sample size requirements for bilinear constraints with low violation levels compared to the classical approach, thereby significantly improving computational tractability. Numerical experiments on robust pole assignment problems support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07361v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaeseok Choi, Anand Deo, Constantino Lagoa, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Analyzing Meta-algorithms in Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2402.08621</link>
      <description>arXiv:2402.08621v3 Announce Type: replace-cross 
Abstract: In this paper, we analyze the problem of online convex optimization in different settings, including different feedback types (full-information/semi-bandit/bandit/etc) in either stochastic or non-stochastic setting and different notions of regret (static adversarial regret/dynamic regret/adaptive regret). This is done through a framework which allows us to systematically propose and analyze meta-algorithms for the various settings described above. We show that any algorithm for online linear optimization with fully adaptive adversaries is an algorithm for online convex optimization. We also show that any such algorithm that requires full-information feedback may be transformed to an algorithm with semi-bandit feedback with comparable regret bound. We further show that algorithms that are designed for fully adaptive adversaries using deterministic semi-bandit feedback can obtain similar bounds using only stochastic semi-bandit feedback when facing oblivious adversaries. We use this to describe general meta-algorithms to convert first order algorithms to zeroth order algorithms with comparable regret bounds. Our framework allows us to analyze online optimization in various settings, recovers several results in the literature with a simplified proof technique, and provides new results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08621v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Pedramfar, Vaneet Aggarwal</dc:creator>
    </item>
    <item>
      <title>Optimal Transport on the Lie Group of Roto-translations</title>
      <link>https://arxiv.org/abs/2402.15322</link>
      <description>arXiv:2402.15322v3 Announce Type: replace-cross 
Abstract: The roto-translation group SE2 has been of active interest in image analysis due to methods that lift the image data to multi-orientation representations defined on this Lie group. This has led to impactful applications of crossing-preserving flows for image de-noising, geodesic tracking, and roto-translation equivariant deep learning. In this paper, we develop a computational framework for optimal transportation over Lie groups, with a special focus on SE2. We make several theoretical contributions (generalizable to matrix Lie groups) such as the non-optimality of group actions as transport maps, invariance and equivariance of optimal transport, and the quality of the entropic-regularized optimal transport plan using geodesic distance approximations. We develop a Sinkhorn like algorithm that can be efficiently implemented using fast and accurate distance approximations of the Lie group and GPU-friendly group convolutions. We report valuable advancements in the experiments on 1) image barycentric interpolation, 2) interpolation of planar orientation fields, and 3) Wasserstein gradient flows on SE2. We observe that our framework of lifting images to SE2 and optimal transport with left-invariant anisotropic metrics leads to equivariant transport along dominant contours and salient line structures in the image. This yields sharper and more meaningful interpolations compared to their counterparts on R^2</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15322v3</guid>
      <category>cs.CV</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daan Bon, Gautam Pai, Gijs Bellaard, Olga Mula, Remco Duits</dc:creator>
    </item>
    <item>
      <title>Gradient Networks</title>
      <link>https://arxiv.org/abs/2404.07361</link>
      <description>arXiv:2404.07361v2 Announce Type: replace-cross 
Abstract: Directly parameterizing and learning gradients of functions has widespread significance, with specific applications in inverse problems, generative modeling, and optimal transport. This paper introduces gradient networks (GradNets): novel neural network architectures that parameterize gradients of various function classes. GradNets exhibit specialized architectural constraints that ensure correspondence to gradient functions. We provide a comprehensive GradNet design framework that includes methods for transforming GradNets into monotone gradient networks (mGradNets), which are guaranteed to represent gradients of convex functions. Our results establish that our proposed GradNet (and mGradNet) universally approximate the gradients of (convex) functions. Furthermore, these networks can be customized to correspond to specific spaces of potential functions, including transformed sums of (convex) ridge functions. Our analysis leads to two distinct GradNet architectures, GradNet-C and GradNet-M, and we describe the corresponding monotone versions, mGradNet-C and mGradNet-M. Our empirical results demonstrate that these architectures provide efficient parameterizations and outperform existing methods by up to 15 dB in gradient field tasks and by up to 11 dB in Hamiltonian dynamics learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07361v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreyas Chaudhari, Srinivasa Pranav, Jos\'e M. F. Moura</dc:creator>
    </item>
    <item>
      <title>Implicit Bias of Mirror Flow on Separable Data</title>
      <link>https://arxiv.org/abs/2406.12763</link>
      <description>arXiv:2406.12763v3 Announce Type: replace-cross 
Abstract: We examine the continuous-time counterpart of mirror descent, namely mirror flow, on classification problems which are linearly separable. Such problems are minimised `at infinity' and have many possible solutions; we study which solution is preferred by the algorithm depending on the mirror potential. For exponential tailed losses and under mild assumptions on the potential, we show that the iterates converge in direction towards a $\phi_\infty$-maximum margin classifier. The function $\phi_\infty$ is the \textit{horizon function} of the mirror potential and characterises its shape `at infinity'. When the potential is separable, a simple formula allows to compute this function. We analyse several examples of potentials and provide numerical experiments highlighting our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12763v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Pesme, Radu-Alexandru Dragomir, Nicolas Flammarion</dc:creator>
    </item>
    <item>
      <title>Gradient Normalization Provably Benefits Nonconvex SGD under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2410.16561</link>
      <description>arXiv:2410.16561v2 Announce Type: replace-cross 
Abstract: This paper investigates the roles of gradient normalization and clipping in ensuring the convergence of Stochastic Gradient Descent (SGD) under heavy-tailed noise. While existing approaches consider gradient clipping indispensable for SGD convergence, we theoretically demonstrate that gradient normalization alone without clipping is sufficient to ensure convergence. Furthermore, we establish that combining gradient normalization with clipping offers significantly improved convergence rates compared to using either technique in isolation, particularly as gradient noise diminishes. With these results, our work provides the first theoretical evidence demonstrating the benefits of gradient normalization in SGD under heavy-tailed noise. Finally, we introduce an accelerated SGD variant that incorporates both gradient normalization and clipping, further enhancing convergence rates under heavy-tailed noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16561v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 14 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tao Sun, Xinwang Liu, Kun Yuan</dc:creator>
    </item>
  </channel>
</rss>
