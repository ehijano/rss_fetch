<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 02:46:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Edgeworth Expansions for Linear Rank Statistics Using Stein's Method</title>
      <link>https://arxiv.org/abs/2511.12187</link>
      <description>arXiv:2511.12187v1 Announce Type: new 
Abstract: Edgeworth expansions of first and second order are established for general linear rank statistics under the null hypothesis with asymptotically ''sufficiently'' small remainder terms. The methods used are the Stein method combined with an extension of a combinatorial method of Bolthausen (1984). The conditions obtained for the validity of these Edgeworth expansions are very similar to the necessary and sufficient conditions found by Bickel and Robinson (1982) for the case of sums of iid random variables. But these conditions are often difficult to prove directly. For simple linear rank statistics, however, it is possible to use a result from van Zwet (1982) to verify these assumptions. Thus, we obtain conditions for the validity of Edgeworth expansions, which on the one hand are very easy to prove and on the other hand are much more general than all previously known conditions. Finally, this result is applied to the special case of approximating and exact scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12187v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.57714/d82m-ab78</arxiv:DOI>
      <dc:creator>Walter Schneller</dc:creator>
    </item>
    <item>
      <title>Transfer Learning and Locally Linear Regression for Locally Stationary Time Series</title>
      <link>https://arxiv.org/abs/2511.12948</link>
      <description>arXiv:2511.12948v2 Announce Type: new 
Abstract: This paper investigates locally linear regression for locally stationary time series and develops theoretical results for locally linear smoothing and transfer learning. Existing analyses have focused on local constant estimators and given samples, leaving the principles of transferring knowledge from auxiliary sources across heterogeneous time-varying domains insufficiently established. We derive uniform convergence for multivariate locally linear estimators under strong mixing. The resulting error expansion decomposes stochastic variation, smoothing bias, and a term induced by local stationarity. This additional term, originating from the locally stationary structure, has smaller order than in the Nadaraya-Watson benchmark, explaining the improved local linear performance. Building on these results, we propose bias-corrected transfer learned estimators that connect a sparsely observed series with densely observed related sources through a smoothly varying bias function defined over rescaled time and covariates. An additional refinement shows how local temporal adjustment of this bias enhances stability and enables efficient information borrowing across domains. Simulation studies and an empirical analysis of international fuel prices support the theoretical predictions and demonstrate the practical advantages of transfer learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12948v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinwoo Park</dc:creator>
    </item>
    <item>
      <title>On the Hierarchical Bayes justification of Empirical Bayes Confidence Intervals</title>
      <link>https://arxiv.org/abs/2511.13037</link>
      <description>arXiv:2511.13037v1 Announce Type: new 
Abstract: Multi-level normal hierarchical models, also interpreted as mixed effects models, play an important role in developing statistical theory in multi-parameter estimation for a wide range of applications. In this article, we propose a novel reconciliation framework of the empirical Bayes (EB) and hierarchical Bayes approaches for interval estimation of random effects under a two-level normal model. Our framework shows that a second-order efficient empirical Bayes confidence interval, with EB coverage error of order $O(m^{-3/2})$, $m$ being the number of areas in the area-level model, can also be viewed as a credible interval whose posterior coverage is close to the nominal level, provided a carefully chosen prior - referred to as a 'matching prior' - is placed on the hyperparameters. While existing literature has examined matching priors that reconcile frequentist and Bayesian inference in various settings, this paper is the first to study matching priors with the goal of interval estimation of random effects in a two-level model. We obtain an area-dependent matching prior on the variance component that achieves a proper posterior under mild regularity conditions. The theoretical results in the paper are corroborated through a Monte Carlo simulation study and a real data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13037v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditi Sen, Masayo Y. Hirose, Partha Lahiri</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic Analysis of Poisson randomized midpoint Langevin Monte Carlo</title>
      <link>https://arxiv.org/abs/2511.13085</link>
      <description>arXiv:2511.13085v1 Announce Type: new 
Abstract: The task of sampling from a high-dimensional distribution $\pi$ on $\R^d$ is a fundamental algorithmic problem with applications throughout statistics, engineering, and the sciences. Consider the Langevin diffusion on $\R^d$ \begin{align*} \dif X_t=-\nabla U(X_t)dt+\sqrt{2}dB_t, \end{align*} under mild conditions, it admits $\pi(\dif x)\propto \exp(-U(x))\dif x$ as its unique stationary distribution. Recently, Kandasamy and Nagaraj (2024) introduced a stochastic algorithm called Poisson Randomized Midpoint Langevin Monte Carlo (PRLMC) to enhance the rate of convergence towards the target distribution $\pi$. In this paper, we first show that under mild conditions, the PRLMC, as a Markov chain, admits a unique stationary distribution $\pi_\eta$ ($\eta$ is the step size) and obtain the convergence rate of PRLMC to $\pi_\eta$ in total variation distance. Then we establish a sharp error bound between $\pi_\eta$ and $\pi$ under the 2-Wasserstein distance. Finally, we propose a decreasing-step size version of PRLMC and provide its convergence rate to $\pi$ which is nearly optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13085v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tian Shen, Zhonggen Su</dc:creator>
    </item>
    <item>
      <title>Convergence rate of randomized midpoint Langevin Monte Carlo</title>
      <link>https://arxiv.org/abs/2511.13093</link>
      <description>arXiv:2511.13093v1 Announce Type: new 
Abstract: The randomized midpoint Langevin Monte Carlo (RLMC), introduced by Shen and Lee (2019), is a variant of classical Unadjusted Langevin Algorithm. It was shown in the literature that the RLMC is an efficient algorithm for approximating high-dimensional probability distribution $\pi$. In this paper, we establish the exponential ergodicity of RLMC with constant step-size. Moreover, we design a dereasing-step size RLMC and provide its convergence rate in terms of a functional class distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13093v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruinan Li, Tian Shen, Zhonggen Su</dc:creator>
    </item>
    <item>
      <title>Asymptotic confidence bands for centered purely random forests</title>
      <link>https://arxiv.org/abs/2511.13199</link>
      <description>arXiv:2511.13199v1 Announce Type: new 
Abstract: In a multivariate nonparametric regression setting we construct explicit asymptotic uniform confidence bands for centered purely random forests. Since the most popular example in this class of random forests, namely the uniformly centered purely random forests, is well known to suffer from suboptimal rates, we propose a new type of purely random forests, called the Ehrenfest centered purely random forests, which achieve minimax optimal rates. Our main confidence band theorem applies to both random forests. The proof is based on an interpretation of random forests as generalized U-Statistics together with a Gaussian approximation of the supremum of empirical processes. Our theoretical findings are illustrated in simulation examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13199v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Natalie Neumeyer, Jan Rabe, Mathias Trabs</dc:creator>
    </item>
    <item>
      <title>Local asymptotic normality for discretely observed McKean-Vlasov diffusions</title>
      <link>https://arxiv.org/abs/2511.13366</link>
      <description>arXiv:2511.13366v1 Announce Type: new 
Abstract: We study the local asymptotic normality (LAN) property for the likelihood function associated with discretely observed $d$-dimensional McKean-Vlasov stochastic differential equations over a fixed time interval. The model involves a joint parameter in both the drift and diffusion coefficients, introducing challenges due to its dependence on the process distribution. We derive a stochastic expansion of the log-likelihood ratio using Malliavin calculus techniques and establish the LAN property under appropriate conditions. The main technical challenge arises from the implicit nature of the transition densities, which we address through integration by parts and Gaussian-type bounds. This work extends existing LAN results for interacting particle systems to the mean-field regime, contributing to statistical inference in non-linear stochastic models</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13366v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akram Heidari, Mark Podolskij</dc:creator>
    </item>
    <item>
      <title>Random sets from the perspective of metric statistics</title>
      <link>https://arxiv.org/abs/2511.13440</link>
      <description>arXiv:2511.13440v1 Announce Type: new 
Abstract: Since the seminal work by Beresteanu and Molinari(2008), the random set theory and related inference methods have been widely applied in partially identified econometric models. Meanwhile, there is an emerging field in statistics for studying random objects in metric spaces, called metric statistics. This paper clarifies a relationship between two fundamental concepts in these literatures, the Aumann and Fr\'echet means, and presents some applications of metric statistics to econometric problems involving random sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13440v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daisuke Kurisu, Yuta Okamoto, Taisuke Otsu</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation of Joint Entropy through Partitioned Sample-Spacing Method</title>
      <link>https://arxiv.org/abs/2511.13602</link>
      <description>arXiv:2511.13602v1 Announce Type: new 
Abstract: We propose a nonparametric estimator of multivariate joint entropy based on partitioned sample spacings (PSS). The method extends univariate spacing ideas to multivariate settings by partitioning the sample space into localized cells and aggregating within-cell statistics, with strong consistency guarantees under mild conditions. In benchmarks across diverse distributions, PSS consistently outperforms k-nearest neighbor estimators and achieves accuracy competitive with recent normalizing flow-based methods, while requiring no training or auxiliary density modeling. The estimator scales favorably in moderately high dimensions (d = 10 to 40) and shows particular robustness to correlated or skewed distributions. These properties position PSS as a practical alternative to normalizing flow-based approaches, with broad potential in information-theoretic machine learning applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13602v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jungwoo Ho, Sangun Park, Soyeong Oh</dc:creator>
    </item>
    <item>
      <title>Rate-optimal and computationally efficient nonparametric estimation on the circle and the sphere</title>
      <link>https://arxiv.org/abs/2511.13664</link>
      <description>arXiv:2511.13664v1 Announce Type: new 
Abstract: We investigate the problem of density estimation on the unit circle and the unit sphere from a computational perspective. Our primary goal is to develop new density estimators that are both rate-optimal and computationally efficient for direct implementation. After establishing these estimators, we derive closed-form expressions for probability estimates over regions of the circle and the sphere. Then, the proposed theories are supported by extensive simulation studies. The considered settings naturally arise when analyzing phenomena on the Earth's surface or in the sky (sphere), as well as directional or periodic phenomena (circle). The proposed approaches are broadly applicable, and we illustrate their usefulness through case studies in zoology, climatology, geophysics, and astronomy, which may be of independent interest. The methodologies developed here can be readily applied across a wide range of scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13664v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Athanasios G. Georgiadis, Andrew P. Percival</dc:creator>
    </item>
    <item>
      <title>Compound Selection Decisions: An Almost SURE Approach</title>
      <link>https://arxiv.org/abs/2511.11862</link>
      <description>arXiv:2511.11862v1 Announce Type: cross 
Abstract: This paper proposes methods for producing compound selection decisions in a Gaussian sequence model. Given unknown, fixed parameters $\mu_ {1:n}$ and known $\sigma_{1:n}$ with observations $Y_i \sim \textsf{N}(\mu_i, \sigma_i^2)$, the decision maker would like to select a subset of indices $S$ so as to maximize utility $\frac{1}{n}\sum_{i\in S} (\mu_i - K_i)$, for known costs $K_i$. Inspired by Stein's unbiased risk estimate (SURE), we introduce an almost unbiased estimator, called ASSURE, for the expected utility of a proposed decision rule. ASSURE allows a user to choose a welfare-maximizing rule from a pre-specified class by optimizing the estimated welfare, thereby producing selection decisions that borrow strength across noisy estimates. We show that ASSURE produces decision rules that are asymptotically no worse than the optimal but infeasible decision rule in the pre-specified class. We apply ASSURE to the selection of Census tracts for economic opportunity, the identification of discriminating firms, and the analysis of $p$-value decision procedures in A/B testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11862v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiafeng Chen, Lihua Lei, Timothy Sudijono, Liyang Sun, Tian Xie</dc:creator>
    </item>
    <item>
      <title>Modeling group heterogeneity in spatio-temporal data via physics-informed semiparametric regression</title>
      <link>https://arxiv.org/abs/2511.13203</link>
      <description>arXiv:2511.13203v1 Announce Type: cross 
Abstract: In this work we propose a novel approach for modeling spatio-temporal data characterized by group structures. In particular, we extend classical mixed effect regression models by introducing a space-time nonparametric component, regularized through a partial differential equation, to embed the physical dynamics of the underlying process, while random effects capture latent variability associated with the group structure present in the data. We propose a two-step procedure to estimate the fixed and random components of the model, relying on a functional version of the Iterative Reweighted Least Squares algorithm. We investigate the asymptotic properties of both fixed and random components, and we assess the performance of the proposed model through a simulation study, comparing it with state-of-the-art alternatives from the literature. The proposed methodology is finally applied to the study of hourly nitrogen dioxide concentration data in Lombardy (Italy), using random effects to account for measurement heterogeneity across monitoring stations equipped with different sensor technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13203v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marco F. De Sanctis, Eleonora Arnone, Francesca Ieva, Laura M. Sangalli</dc:creator>
    </item>
    <item>
      <title>Novel Tau-Informed Initialization for Maximum Likelihood Estimation of Copulas with Discrete Margins</title>
      <link>https://arxiv.org/abs/2511.13337</link>
      <description>arXiv:2511.13337v1 Announce Type: cross 
Abstract: We study Gaussian-copula models with discrete margins, with primary emphasis on low-count (Poisson) data. Our goal is exact yet computationally efficient maximum likelihood (ML) estimation in regimes where many observations contain small counts, which imperils both identifiability and numerical stability. We develop three novel Kendall's tau-based approaches for initialization tailored to discrete margins in the low-count regime and embed it within an inference functions for margins (IFM) inspired start. We present three practical initializers (exact, low-intensity approximation, and a transformation-based approach) that substantially reduce the number of ML iterations and improve convergence. For the ML stage, we use an unconstrained reparameterization of the model's parameters using the log and spherical-Cholesky and compute exact rectangle probabilities. Analytical score functions are supplied throughout to stabilize Newton-type optimization. A simulation study across dimensions, dependence levels, and intensity regimes shows that the proposed initialization combined with exact ML achieves lower root-mean-squared error, lower bias and faster computation times than the alternative procedures. The methodology provides a pragmatic path to retain the statistical guarantees of ML (consistency, asymptotic normality, efficiency under correct specification) while remaining tractable for moderate- to high-dimensional discrete data. We conclude with guidance on initializer choice and discuss extensions to alternative correlation structures and different margins.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13337v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna van Es, Eva Cantoni</dc:creator>
    </item>
    <item>
      <title>Asymptotic analysis of rare events in high dimensions</title>
      <link>https://arxiv.org/abs/2511.13559</link>
      <description>arXiv:2511.13559v1 Announce Type: cross 
Abstract: Understanding rare events is critical across domains ranging from signal processing to reliability and structural safety, extreme-weather forecasting, and insurance. The analysis of rare events is a computationally challenging problem, particularly in high dimensions $d$. In this work, we develop the first asymptotic high-dimensional theory of rare events. First, we exploit asymptotic integral methods recently developed by the first author to provide an asymptotic expansion of rare event probabilities. The expansion employs the geometry of the rare event boundary and the local behavior of the log probability density. Generically, the expansion is valid if $d^2\ll\lambda$, where $\lambda$ characterizes the extremity of the event. We prove this condition is necessary by constructing an example in which the first-order remainder is bounded above and below by $d^2/\lambda$. We also provide a nonasymptotic remainder bound which specifies the precise dependence of the remainder on $d$, $\lambda$, the density, and the boundary, and which shows that in certain cases, the condition $d^2\ll \lambda$ can be relaxed. As an application of the theory, we derive asymptotic approximations to rare probabilities under the standard Gaussian density in high dimensions. In the second part of our work, we provide an asymptotic approximation to densities conditional on rare events. This gives rise to simple procedure for approximately sampling conditionally on the rare event using independent Gaussian and exponential random variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13559v1</guid>
      <category>math.PR</category>
      <category>math.CA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anya Katsevich, Alexander Katsevich</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation for I.I.D. Paths of a Martingale Driven Model with Application to Non-Autonomous Financial Models</title>
      <link>https://arxiv.org/abs/2110.15637</link>
      <description>arXiv:2110.15637v5 Announce Type: replace 
Abstract: This paper deals with a projection least squares estimator of the function $J_0$ computed from multiple independent observations on $[0,T]$ of the process $Z$ defined by $dZ_t = J_0(t)d\langle M\rangle_t + dM_t$, where $M$ is a continuous and square integrable martingale vanishing at $0$. Risk bounds are established on this estimator, on an associated adaptive estimator and on an associated discrete-time version used in practice. An appropriate transformation allows to rewrite the differential equation $dX_t = V(X_t)(b_0(t)dt +\sigma(t)dB_t)$, where $B$ is a fractional Brownian motion of Hurst parameter $H\in [1/2,1)$, as a model of the previous type. So, the second part of the paper deals with risk bounds on a nonparametric estimator of $b_0$ derived from the results on the projection least squares estimator of $J_0$. In particular, our results apply to the estimation of the drift function in a non-autonomous Black-Scholes model and to nonparametric estimation in a non-autonomous fractional stochastic volatility model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.15637v5</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s00780-022-00493-8</arxiv:DOI>
      <arxiv:journal_reference>Finance and Stochastics 27, 1, 97-126, 2023</arxiv:journal_reference>
      <dc:creator>Nicolas Marie</dc:creator>
    </item>
    <item>
      <title>Nonparametric Drift Estimation from Diffusions with Correlated Brownian Motions</title>
      <link>https://arxiv.org/abs/2210.13173</link>
      <description>arXiv:2210.13173v3 Announce Type: replace 
Abstract: In the present paper, we consider that $N$ diffusion processes $X^1,\dots,X^N$ are observed on $[0,T]$, where $T$ is fixed and $N$ grows to infinity. Contrary to most of the recent works, we no longer assume that the processes are independent. The dependency is modeled through correlations between the Brownian motions driving the diffusion processes. A nonparametric estimator of the drift function, which does not use the knowledge of the correlation matrix, is proposed and studied. Its integrated mean squared risk is bounded and an adaptive procedure is proposed. Few theoretical tools to handle this kind of dependency are available, and this makes our results new. Numerical experiments show that the procedure works in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.13173v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmva.2023.105222</arxiv:DOI>
      <arxiv:journal_reference>Journal of Multivariate Analysis 198, 23 pages, 2023</arxiv:journal_reference>
      <dc:creator>Fabienne Comte, Nicolas Marie</dc:creator>
    </item>
    <item>
      <title>Spatially Randomized Designs Can Enhance Policy Evaluation</title>
      <link>https://arxiv.org/abs/2403.11400</link>
      <description>arXiv:2403.11400v2 Announce Type: replace 
Abstract: This article studies the benefits of using spatially randomized experimental designs which partition the experimental area into distinct, non-overlapping units with treatments assigned randomly. Such designs offer improved policy evaluation in online experiments by providing more precise policy value estimators and more effective A/B testing algorithms than traditional global designs, which apply the same treatment across all units simultaneously. We examine both parametric and nonparametric methods for estimating and inferring policy values based on this randomized approach. Our analysis includes evaluating the mean squared error of the treatment effect estimator and the statistical power of the associated tests. Additionally, we extend our findings to experiments with spatio-temporal dependencies, where treatments are allocated sequentially over time, and account for potential temporal carryover effects. Our theoretical insights are supported by comprehensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11400v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Yang, Chengchun Shi, Fang Yao, Shouyang Wang, Hongtu Zhu</dc:creator>
    </item>
    <item>
      <title>Causality Pursuit from Heterogeneous Environments via Neural Adversarial Invariance Learning</title>
      <link>https://arxiv.org/abs/2405.04715</link>
      <description>arXiv:2405.04715v5 Announce Type: replace 
Abstract: Pursuing causality from data is a fundamental problem in scientific discovery, treatment intervention, and transfer learning. This paper introduces a novel algorithmic method for addressing nonparametric invariance and causality learning in regression models across multiple environments, where the joint distribution of response variables and covariates varies, but the conditional expectations of outcome given an unknown set of quasi-causal variables are invariant. The challenge of finding such an unknown set of quasi-causal or invariant variables is compounded by the presence of endogenous variables that have heterogeneous effects across different environments. The proposed Focused Adversarial Invariant Regularization (FAIR) framework utilizes an innovative minimax optimization approach that drives regression models toward prediction-invariant solutions through adversarial testing. Leveraging the representation power of neural networks, FAIR neural networks (FAIR-NN) are introduced for causality pursuit. It is shown that FAIR-NN can find the invariant variables and quasi-causal variables under a minimal identification condition and that the resulting procedure is adaptive to low-dimensional composition structures in a non-asymptotic analysis. Under a structural causal model, variables identified by FAIR-NN represent pragmatic causality and provably align with exact causal mechanisms under conditions of sufficient heterogeneity. Computationally, FAIR-NN employs a novel Gumbel approximation with decreased temperature and a stochastic gradient descent ascent algorithm. The procedures are demonstrated using simulated and real-data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04715v5</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Annals of Statistics, 53(5): 2230-2257, 2025</arxiv:journal_reference>
      <dc:creator>Yihong Gu, Cong Fang, Peter B\"uhlmann, Jianqing Fan</dc:creator>
    </item>
    <item>
      <title>Adaptive Estimation of Multivariate Binary Distributions under Sparse Generalized Correlation Structures</title>
      <link>https://arxiv.org/abs/2410.15166</link>
      <description>arXiv:2410.15166v5 Announce Type: replace 
Abstract: We consider the problem of estimating the joint distribution of an $M$-dimensional binary vector, which involves exponentially many parameters without additional assumptions. Using the representation from \citet{bahadur1959representation}, we relate the sparsity of its parameters to conditional independence among components. The maximum likelihood estimator is computationally infeasible and prone to overfitting. {We reformulate the problem as estimating a high-dimensional vector of generalized correlation coefficients, quantifying interaction effects among all component subsets, together with low or moderate-dimensional nuisance parameters corresponding to the marginal probabilities.} Since the marginal probabilities can be consistently estimated, we first propose a two-stage procedure that first estimates the marginal probabilities and then applies an $\ell_1$-regularized estimator for the generalized correlations, exploiting sparsity arising from potential independence structures. While computationally efficient, this estimator is not rate-optimal. We therefore further develop a regularized adversarial estimator that attains the optimal rate under standard regularity conditions while remaining tractable. The framework naturally extends to settings with covariates. We apply the proposed estimators to causal inference with multiple binary treatments and demonstrate substantial finite-sample improvements over non-adaptive estimators that estimate all probabilities directly. Simulation studies corroborate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15166v5</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Belloni, Yan Chen, Matthew Harding</dc:creator>
    </item>
    <item>
      <title>Method of Moments for Estimation of Noisy Curves</title>
      <link>https://arxiv.org/abs/2410.23220</link>
      <description>arXiv:2410.23220v2 Announce Type: replace 
Abstract: In this paper, we study the problem of recovering a ground truth high dimensional piecewise linear curve $C^*(t):[0, 1]\to\mathbb{R}^d$ from a high noise Gaussian point cloud with covariance $\sigma^2I$ centered around the curve. We establish that the sample complexity of recovering $C^*$ from data scales with order at least $\sigma^6$. We then show that recovery of a piecewise linear curve from the third moment is locally well-posed, and hence $O(\sigma^6)$ samples is also sufficient for recovery. We propose methods to recover a curve from data based on a fitting to the third moment tensor with a careful initialization strategy and conduct some numerical experiments verifying the ability of our methods to recover curves. All code for our numerical experiments is publicly available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23220v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Phillip Lo, Yuehaw Khoo</dc:creator>
    </item>
    <item>
      <title>Gaussian quasi-likelihood analysis for non-Gaussian linear mixed-effects model with system noise</title>
      <link>https://arxiv.org/abs/2412.00796</link>
      <description>arXiv:2412.00796v2 Announce Type: replace 
Abstract: We consider statistical inference for a class of mixed-effects models with system noise described by a non-Gaussian integrated Ornstein-Uhlenbeck process. Under the asymptotics where the number of individuals goes to infinity with possibly unbalanced sampling frequency across individuals, we prove some theoretical properties of the Gaussian quasi-likelihood function, followed by the asymptotic normality and the tail-probability estimate of the associated estimator. In addition to the joint inference, we propose and investigate the three-stage inference strategy, revealing that they are first-order equivalent while quantitatively different in the second-order terms. Numerical experiments are given to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00796v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Takumi Imamura, Hiroki Masuda</dc:creator>
    </item>
    <item>
      <title>Analyzing Scalogram Ridges in the Presence of Noise</title>
      <link>https://arxiv.org/abs/2501.00270</link>
      <description>arXiv:2501.00270v2 Announce Type: replace 
Abstract: While ridges in the scalogram, determined by the squared modulus of analytic wavelet transform (AWT), is a widely accepted concept and utilized in nonstationary time series analysis, their behavior in noisy environments remains underexplored. Our object is to provide a theoretical foundation for scalogram ridges by defining ridges as a potentially set-valued random process connecting local maxima of the scalogram along the scale axis and analyzing their properties when the signal fulfills the adaptive harmonic model and is contaminated by stationary Gaussian noise. In addition to establishing several key properties of the AWT for random processes, we investigate the probabilistic characteristics of the resulting random ridge points in the scalogram. Specifically, we establish the uniqueness property of the ridge point at individual time instances and prove the upper hemicontinuity of the ridge random process. Furthermore, we derive bounds on the probability that the deviation between the ridges of noisy and clean signals exceeds a specified threshold, and these bounds depend on the signal-to-noise ratio. To achieve these ridge deviation results, we derive maximal inequalities for the complex modulus of nonstationary Gaussian processes, leveraging classical tools such as the Borell-TIS inequality and Dudley's theorem, which might be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00270v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gi-Ren Liu, Yuan-Chung Sheu, Hau-Tieng Wu</dc:creator>
    </item>
    <item>
      <title>Asymptotic Distribution of Low-Dimensional Patterns Induced by Non-Differentiable Regularizers under General Loss Functions</title>
      <link>https://arxiv.org/abs/2506.12621</link>
      <description>arXiv:2506.12621v2 Announce Type: replace 
Abstract: This article investigates the asymptotic distribution of penalized estimators with non-differentiable penalties designed to recover low-dimensional pattern structures. Patterns play a central role in estimation, as they reveal the underlying structure of the parameter -- which coefficients are zero, which are equal, and how they are clustered. The main technical challenge stems from the discontinuous nature of these patterns (such as the sign function in the case of the Lasso penalty), a difficulty not previously addressed in the literature and only recently analyzed for the standard linear model. To overcome this, we extend classical results from empirical process theory for M-estimation by incorporating the distributional behavior of model patterns. We introduce a new mathematical framework for studying pattern convergence of regularized M-estimators. While classical approaches to distributional convergence rely on uniform conditions, our analysis employs a new local condition, stochastic Lipschitz differentiability (SLD), which controls fluctuations of the Taylor remainder. We demonstrate how this framework applies to a broad class of loss functions, covering generalized linear models (e.g., logistic and Poisson regression) and robust regression settings with non-smooth losses such as the Huber and quantile loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12621v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Hejn\'y, Jonas Wallin, Ma{\l}gorzata Bogdan</dc:creator>
    </item>
    <item>
      <title>Nonparametric Least squares estimators for interval censoring</title>
      <link>https://arxiv.org/abs/2511.01103</link>
      <description>arXiv:2511.01103v3 Announce Type: replace 
Abstract: The limit distribution of the nonparametric maximum likelihood estimator for interval censored data with more than one observation time per unobservable observation, is still unknown in general. For the so-called separated case, where one has observation times which are at a distance larger than a fixed $\epsilon&gt;0$, the limit distribution was derived in [4]. For the non-separated case there is a conjectured limit distribution, given in [9], Section 5.2 of Part 2. But the findings of the present paper suggest that this conjecture may not hold.
  We prove consistency of a closely related nonparametric isotonic least squares estimator and give a sketch of the proof for a result on its limit distribution. We also provide simulation results to show how the nonparametric MLE and least squares estimator behave in comparison. Moreover, we discuss a simpler least squares estimator that can be computed in one step, but is inferior to the other least squares estimator, since it does not use all information.
  For the simplest model of interval censoring, the current status model, the nonparametric maximum likelihood and least squares estimators are the same. This equivalence breaks down if there are more observation times per unobservable observation. The computations for the simulation of the more complicated interval censoring model were performed by using the iterative convex minorant algorithm. They are provided in the GitHub repository [6].</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01103v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piet Groeneboom</dc:creator>
    </item>
    <item>
      <title>Foundations of Structural Causal Models with Latent Selection</title>
      <link>https://arxiv.org/abs/2401.06925</link>
      <description>arXiv:2401.06925v3 Announce Type: replace-cross 
Abstract: Three distinct phenomena complicate statistical causal analysis: latent common causes, causal cycles, and latent selection. Foundational works on Structural Causal Models (SCMs), e.g., Bongers et al. (2021, Ann. Stat., 49(5): 2885-2915), treat cycles and latent variables, while an analogous account of latent selection is missing. The goal of this article is to develop a theoretical foundation for modeling latent selection with SCMs. To achieve that, we introduce a conditioning operation for SCMs: it maps an SCM with explicit selection mechanisms to one without them while preserving the causal semantics of the selected subpopulation. Graphically, in Directed Mixed Graphs we extend bidirected edge--beyond latent common cause--to also encode latent selection. We prove that the conditioning operation preserves simplicity, acyclicity, and linearity of SCMs, and interacts well with marginalization, conditioning, and interventions. These properties make those three operations valuable tools for causal modeling, reasoning, and learning after abstracting away latent details (latent common causes and selection). Examples show how this abstraction streamlines analysis and clarifies when standard tools (e.g., adjustment, causal calculus, instrumental variables) remain valid under selection bias. We hope that these results deepen the SCM-based understanding of selection bias and become part of the standard causal modeling toolbox to build more reliable causal analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06925v3</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leihao Chen, Onno Zoeter, Joris M. Mooij</dc:creator>
    </item>
    <item>
      <title>Regularised Canonical Correlation Analysis: graphical lasso, biplots and beyond</title>
      <link>https://arxiv.org/abs/2403.02979</link>
      <description>arXiv:2403.02979v2 Announce Type: replace-cross 
Abstract: Recent developments in regularized Canonical Correlation Analysis (CCA) promise powerful methods for high-dimensional, multiview data analysis. However, justifying the structural assumptions behind many popular approaches remains a challenge, and features of realistic biological datasets pose practical difficulties that are seldom discussed. We propose a novel CCA estimator rooted in an assumption of conditional independencies and based on the Graphical Lasso. Our method has desirable theoretical guarantees and good empirical performance, demonstrated through extensive simulations and real-world biological datasets. Recognizing the difficulties of model selection in high dimensions and other practical challenges of applying CCA in real-world settings, we introduce a novel framework for evaluating and interpreting regularized CCA models in the context of Exploratory Data Analysis (EDA), which we hope will empower researchers and pave the way for wider adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02979v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lennie Wells, Kumar Thurimella, Sergio Bacallado</dc:creator>
    </item>
    <item>
      <title>Learning Operators by Regularized Stochastic Gradient Descent with Operator-valued Kernels</title>
      <link>https://arxiv.org/abs/2504.18184</link>
      <description>arXiv:2504.18184v2 Announce Type: replace-cross 
Abstract: We consider a class of statistical inverse problems involving the estimation of a regression operator from a Polish space to a separable Hilbert space, where the target lies in a vector-valued reproducing kernel Hilbert space induced by an operator-valued kernel. To address the associated ill-posedness, we analyze regularized stochastic gradient descent (SGD) algorithms in both online and finite-horizon settings. The former uses polynomially decaying step sizes and regularization parameters, while the latter adopts fixed values. Under suitable structural and distributional assumptions, we establish dimension-independent bounds for prediction and estimation errors. The resulting convergence rates are near-optimal in expectation, and we also derive high-probability estimates that imply almost sure convergence. Our analysis introduces a general technique for obtaining high-probability guarantees in infinite-dimensional settings. Possible extensions to broader kernel classes and encoder-decoder structures are briefly discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18184v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia-Qi Yang, Lei Shi</dc:creator>
    </item>
    <item>
      <title>Static marginal expected shortfall: Systemic risk measurement under dependence uncertainty</title>
      <link>https://arxiv.org/abs/2504.19953</link>
      <description>arXiv:2504.19953v2 Announce Type: replace-cross 
Abstract: Measuring the contribution of a bank or an insurance company to overall systemic risk is a key concern, particularly in the aftermath of the 2007--2009 financial crisis and the 2020 downturn. In this paper, we derive worst-case and best-case bounds for the marginal expected shortfall (MES) -- a key measure of systemic risk contribution -- under the assumption that individual firms' risk distributions are known but their dependence structure is not. We further derive tighter MES bounds when partial information on companies' risk exposures, and thus their dependence, is available. To represent this partial information, we employ three standard factor models: additive, minimum-based, and multiplicative background risk models. Additionally, we propose an alternative set of improved MES bounds based on a linear relationship between firm-specific and market-wide risks, consistent with the Capital Asset Pricing Model in finance and the Weighted Insurance Pricing Model in insurance. Finally, empirical analyses demonstrate the practical relevance of the theoretical bounds for industry practitioners and policymakers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19953v2</guid>
      <category>q-fin.RM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinghui Chen, Edward Furman, X. Sheldon Lin</dc:creator>
    </item>
    <item>
      <title>Private Evolution Converges</title>
      <link>https://arxiv.org/abs/2506.08312</link>
      <description>arXiv:2506.08312v2 Announce Type: replace-cross 
Abstract: Private Evolution (PE) is a promising training-free method for differentially private (DP) synthetic data generation. While it achieves strong performance in some domains (e.g., images and text), its behavior in others (e.g., tabular data) is less consistent. To date, the only theoretical analysis of the convergence of PE depends on unrealistic assumptions about both the algorithm's behavior and the structure of the sensitive dataset. In this work, we develop a new theoretical framework to understand PE's practical behavior and identify sufficient conditions for its convergence. For $d$-dimensional sensitive datasets with $n$ data points from a convex and compact domain, we prove that under the right hyperparameter settings and given access to the Gaussian variation API proposed in \cite{PE23}, PE produces an $(\varepsilon, \delta)$-DP synthetic dataset with expected 1-Wasserstein distance $\tilde{O}(d(n\varepsilon)^{-1/d})$ from the original; this establishes worst-case convergence of the algorithm as $n \to \infty$. Our analysis extends to general Banach spaces as well. We also connect PE to the Private Signed Measure Mechanism, a method for DP synthetic data generation that has thus far not seen much practical adoption. We demonstrate the practical relevance of our theoretical findings in experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08312v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom\'as Gonz\'alez, Giulia Fanti, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Generalized quantum Chernoff bound</title>
      <link>https://arxiv.org/abs/2508.12889</link>
      <description>arXiv:2508.12889v2 Announce Type: replace-cross 
Abstract: We consider the task of distinguishing whether a quantum system is prepared in a state from one of several sets of quantum states. Assuming their convexity and stability under tensor product, we prove that the optimal error exponent for discrimination is precisely given by the regularized quantum Chernoff divergence between the sets, thereby establishing a generalized quantum Chernoff bound for the discrimination of multiple sets of quantum states. This extends the classical and quantum Chernoff bounds to the general setting of composite and correlated quantum hypotheses. Furthermore, leveraging minimax theorems, we show that discriminating between sets of quantum states is no harder than discriminating between their worst-case elements in terms of error probability. This implies the existence of an optimal state-agnostic test that achieves the minimum error probability for all states in the sets, matching the performance of the optimal state-dependent test for the most difficult pair of states. We provide explicit characterizations of the optimal state-agnostic test in the binary composite case. Finally, we show that the maximum overlap between a pure state and a set of free states, a quantity that frequently arises in quantum resource theories, is equal to the quantum Chernoff divergence between the sets, thereby providing an operational interpretation of this quantity in the context of symmetric hypothesis testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12889v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Fang, Masahito Hayashi</dc:creator>
    </item>
    <item>
      <title>Can Linear Probes Measure LLM Uncertainty?</title>
      <link>https://arxiv.org/abs/2510.04108</link>
      <description>arXiv:2510.04108v2 Announce Type: replace-cross 
Abstract: Effective Uncertainty Quantification (UQ) represents a key aspect for reliable deployment of Large Language Models (LLMs) in automated decision-making and beyond. Yet, for LLM generation with multiple choice structure, the state-of-the-art in UQ is still dominated by the naive baseline given by the maximum softmax score. To address this shortcoming, we demonstrate that taking a principled approach via Bayesian statistics leads to improved performance despite leveraging the simplest possible model, namely linear regression. More precisely, we propose to train multiple Bayesian linear models, each predicting the output of a layer given the output of the previous one. Based on the obtained layer-level posterior distributions, we infer the global uncertainty level of the LLM by identifying a sparse combination of distributional features, leading to an efficient UQ scheme. Numerical experiments on various LLMs show consistent improvement over state-of-the-art baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04108v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramzi Dakhmouche, Adrien Letellier, Hossein Gorji</dc:creator>
    </item>
    <item>
      <title>A Simple and Effective Random Forest Modelling for Nonlinear Time Series Data</title>
      <link>https://arxiv.org/abs/2511.06544</link>
      <description>arXiv:2511.06544v2 Announce Type: replace-cross 
Abstract: In this paper, we propose Random Forests by Random Weights (RF-RW), a theoretically grounded and practically effective alternative RF modelling for nonlinear time series data, where existing RF-based approaches struggle to adequately capture temporal dependence. RF-RW reconciles the strengths of classic RF with the temporal dependence inherent in time series forecasting. Specifically, it avoids the bootstrap resampling procedure, therefore preserves the serial dependence structure, whilst incorporates independent random weights to reduce correlations among trees. We establish non-asymptotic concentration bounds and asymptotic uniform consistency guarantees, for both fixed- and high-dimensional feature spaces, which extend beyond existing theoretical analyses of RF. Extensive simulation studies demonstrate that RF-RW outperforms existing RF-based approaches and other benchmarks such as SVM and LSTM. It also achieves the lowest error among competitors in our real-data example of predicting UK COVID-19 daily cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06544v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shihao Zhang, Zudi Lu, Chao Zheng</dc:creator>
    </item>
    <item>
      <title>Online Price Competition under Generalized Linear Demands</title>
      <link>https://arxiv.org/abs/2511.10718</link>
      <description>arXiv:2511.10718v2 Announce Type: replace-cross 
Abstract: We study sequential price competition among $N$ sellers, each influenced by the pricing decisions of their rivals. Specifically, the demand function for each seller $i$ follows the single index model $\lambda_i(\mathbf{p}) = \mu_i(\langle \boldsymbol{\theta}_{i,0}, \mathbf{p} \rangle)$, with known increasing link $\mu_i$ and unknown parameter $\boldsymbol{\theta}_{i,0}$, where the vector $\mathbf{p}$ denotes the vector of prices offered by all the sellers simultaneously at a given instant. Each seller observes only their own realized demand -- unobservable to competitors -- and the prices set by rivals. Our framework generalizes existing approaches that focus solely on linear demand models. We propose a novel decentralized policy, PML-GLUCB, that combines penalized MLE with an upper-confidence pricing rule, removing the need for coordinated exploration phases across sellers -- which is integral to previous linear models -- and accommodating both binary and real-valued demand observations. Relative to a dynamic benchmark policy, each seller achieves $O(N^{2}\sqrt{T}\log(T))$ regret, which essentially matches the optimal rate known in the linear setting. A significant technical contribution of our work is the development of a variant of the elliptical potential lemma -- typically applied in single-agent systems -- adapted to our competitive multi-agent environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10718v2</guid>
      <category>cs.GT</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 18 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Bracale, Moulinath Banerjee, Cong Shi, Yuekai Sun</dc:creator>
    </item>
  </channel>
</rss>
