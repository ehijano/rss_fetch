<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Mar 2025 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Computational Intractability of Strategizing against Online Learners</title>
      <link>https://arxiv.org/abs/2503.04202</link>
      <description>arXiv:2503.04202v1 Announce Type: new 
Abstract: Online learning algorithms are widely used in strategic multi-agent settings, including repeated auctions, contract design, and pricing competitions, where agents adapt their strategies over time. A key question in such environments is how an optimizing agent can best respond to a learning agent to improve its own long-term outcomes. While prior work has developed efficient algorithms for the optimizer in special cases - such as structured auction settings or contract design - no general efficient algorithm is known.
  In this paper, we establish a strong computational hardness result: unless $\mathsf{P} = \mathsf{NP}$, no polynomial-time optimizer can compute a near-optimal strategy against a learner using a standard no-regret algorithm, specifically Multiplicative Weights Update (MWU). Our result proves an $\Omega(T)$ hardness bound, significantly strengthening previous work that only showed an additive $\Theta(1)$ impossibility result. Furthermore, while the prior hardness result focused on learners using fictitious play - an algorithm that is not no-regret - we prove intractability for a widely used no-regret learning algorithm. This establishes a fundamental computational barrier to finding optimal strategies in general game-theoretic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04202v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Angelos Assos, Yuval Dagan, Nived Rajaraman</dc:creator>
    </item>
    <item>
      <title>Inducing Efficient and Equitable Professional Networks through Link Recommendations</title>
      <link>https://arxiv.org/abs/2503.04542</link>
      <description>arXiv:2503.04542v1 Announce Type: new 
Abstract: Professional networks are a key determinant of individuals' labor market outcomes. They may also play a role in either exacerbating or ameliorating inequality of opportunity across demographic groups. In a theoretical model of professional network formation, we show that inequality can increase even without exogenous in-group preferences, confirming and complementing existing theoretical literature. Increased inequality emerges from the differential leverage privileged and unprivileged individuals have in forming connections due to their asymmetric ex ante prospects. This is a formalization of a source of inequality in the labor market which has not been previously explored.
  We next show how inequality-aware platforms may reduce inequality by subsidizing connections, through link recommendations that reduce costs, between privileged and unprivileged individuals. Indeed, mixed-privilege connections turn out to be welfare improving, over all possible equilibria, compared to not recommending links or recommending some smaller fraction of cross-group links. Taken together, these two findings reveal a stark reality: professional networking platforms that fail to foster integration in the link formation process risk reducing the platform's utility to its users and exacerbating existing labor market inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04542v1</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cynthia Dwork, Chris Hays, Lunjia Hu, Nicole Immorlica, Juan Perdomo</dc:creator>
    </item>
    <item>
      <title>Control for Coalitions in Parliamentary Elections</title>
      <link>https://arxiv.org/abs/2503.04661</link>
      <description>arXiv:2503.04661v1 Announce Type: new 
Abstract: The traditional election control problem focuses on the use of control to promote a single candidate. In parliamentary elections, however, the focus shifts: voters care no less about the overall governing coalition than the individual parties' seat count. This paper introduces a new problem: controlling parliamentary elections, where the goal extends beyond promoting a single party to influencing the collective seat count of coalitions of parties.
  We focus on plurality rule and control through the addition or deletion of parties. Our analysis reveals that, without restrictions on voters' preferences, these control problems are W[1]-hard. In some cases, the problems are immune to control, making such efforts ineffective.
  We then study the special case where preferences are symmetric single-peaked. We show that in the single-peaked setting, aggregation of voters into types allows for a compact representation of the problem. Our findings show that for the single-peaked setting, some cases are solvable in polynomial time, while others are NP-hard for the compact representation - but admit a polynomial algorithm for the extensive representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04661v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hodaya Barr, Eden Hartman, Yonatan Aumann, Sarit Kraus</dc:creator>
    </item>
    <item>
      <title>Fair Play in the Fast Lane: Integrating Sportsmanship into Autonomous Racing Systems</title>
      <link>https://arxiv.org/abs/2503.03774</link>
      <description>arXiv:2503.03774v1 Announce Type: cross 
Abstract: Autonomous racing has gained significant attention as a platform for high-speed decision-making and motion control. While existing methods primarily focus on trajectory planning and overtaking strategies, the role of sportsmanship in ensuring fair competition remains largely unexplored. In human racing, rules such as the one-motion rule and the enough-space rule prevent dangerous and unsportsmanlike behavior. However, autonomous racing systems often lack mechanisms to enforce these principles, potentially leading to unsafe maneuvers. This paper introduces a bi-level game-theoretic framework to integrate sportsmanship (SPS) into versus racing. At the high level, we model racing intentions using a Stackelberg game, where Monte Carlo Tree Search (MCTS) is employed to derive optimal strategies. At the low level, vehicle interactions are formulated as a Generalized Nash Equilibrium Problem (GNEP), ensuring that all agents follow sportsmanship constraints while optimizing their trajectories. Simulation results demonstrate the effectiveness of the proposed approach in enforcing sportsmanship rules while maintaining competitive performance. We analyze different scenarios where attackers and defenders adhere to or disregard sportsmanship rules and show how knowledge of these constraints influences strategic decision-making. This work highlights the importance of balancing competition and fairness in autonomous racing and provides a foundation for developing ethical and safe AI-driven racing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03774v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenmin Huang, Ce Hao, Wei Zhan, Jun Ma, Masayoshi Tomizuka</dc:creator>
    </item>
    <item>
      <title>Learning to Negotiate via Voluntary Commitment</title>
      <link>https://arxiv.org/abs/2503.03866</link>
      <description>arXiv:2503.03866v1 Announce Type: cross 
Abstract: The partial alignment and conflict of autonomous agents lead to mixed-motive scenarios in many real-world applications. However, agents may fail to cooperate in practice even when cooperation yields a better outcome. One well known reason for this failure comes from non-credible commitments. To facilitate commitments among agents for better cooperation, we define Markov Commitment Games (MCGs), a variant of commitment games, where agents can voluntarily commit to their proposed future plans. Based on MCGs, we propose a learnable commitment protocol via policy gradients. We further propose incentive-compatible learning to accelerate convergence to equilibria with better social welfare. Experimental results in challenging mixed-motive tasks demonstrate faster empirical convergence and higher returns for our method compared with its counterparts. Our code is available at https://github.com/shuhui-zhu/DCL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03866v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuhui Zhu, Baoxiang Wang, Sriram Ganapathi Subramanian, Pascal Poupart</dc:creator>
    </item>
    <item>
      <title>Revisiting Ranking for Online Bipartite Matching with Random Arrivals: the Primal-Dual Analysis</title>
      <link>https://arxiv.org/abs/2503.04196</link>
      <description>arXiv:2503.04196v1 Announce Type: cross 
Abstract: We revisit the celebrated Ranking algorithm by Karp, Vazirani, and Vazirani (STOC 1990) for online bipartite matching under the random arrival model, that is shown to be $0.696$-competitive for unweighted graphs by Mahdian and Yan (STOC 2011) and $0.662$-competitive for vertex-weighted graphs by Jin and Williamson (WINE 2021).
  In this work, we explore the limitation of the primal-dual analysis of Ranking and aim to bridge the gap between unweighted and vertex-weighted graphs. We show that the competitive ratio of Ranking is between $0.686$ and $0.703$, under our current knowledge of Ranking and the framework of primal-dual analysis. This confirms a conjecture by Huang, Tang, Wu, and Zhang (TALG 2019), stating that the primal-dual analysis could lead to a competitive ratio that is very close to $0.696$. Our analysis involves proper discretizations of a variational problem and uses LP solver to pin down the numerical number. As a bonus of our discretization approach, our competitive analysis of Ranking applies to a more relaxed random arrival model. E.g., we show that even when each online vertex arrives independently at an early or late stage, the Ranking algorithm is at least $0.665$-competitive, beating the $1-1/e \approx 0.632$ competitive ratio under the adversarial arrival model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04196v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Peng, Zhihao Gavin Tang</dc:creator>
    </item>
    <item>
      <title>Generative Social Choice</title>
      <link>https://arxiv.org/abs/2309.01291</link>
      <description>arXiv:2309.01291v3 Announce Type: replace 
Abstract: The mathematical study of voting, social choice theory, has traditionally only been applicable to choices among a few predetermined alternatives, but not to open-ended decisions such as collectively selecting a textual statement. We introduce generative social choice, a design methodology for open-ended democratic processes that combines the rigor of social choice theory with the capability of large language models to generate text and extrapolate preferences. Our framework divides the design of AI-augmented democratic processes into two components: first, proving that the process satisfies representation guarantees when given access to oracle queries; second, empirically validating that these queries can be approximately implemented using a large language model. We apply this framework to the problem of summarizing free-form opinions into a proportionally representative slate of opinion statements; specifically, we develop a democratic process with representation guarantees and use this process to portray the opinions of participants in a survey about abortion policy. In a trial with 100 representative US residents, we find that 84 out of 100 participants feel "excellently" or "exceptionally" represented by the slate of five statements we extracted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01291v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Paul G\"olz, David C. Parkes, Ariel D. Procaccia, Gili Rusak, Itai Shapira, Manuel W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Whoever Said Money Won't Solve All Your Problems? Weighted Envy-free Allocation with Subsidy</title>
      <link>https://arxiv.org/abs/2502.09006</link>
      <description>arXiv:2502.09006v5 Announce Type: replace 
Abstract: We explore solutions for fairly allocating indivisible items among agents assigned weights representing their entitlements. Our fairness goal is weighted-envy-freeness (WEF), where each agent deems their allocated portion relative to their entitlement at least as favorable as any others relative to their own. Often, achieving WEF necessitates monetary transfers, which can be modeled as third-party subsidies. The goal is to attain WEF with bounded subsidies.
  Previous work relied on characterizations of unweighted envy-freeness (EF), that fail in the weighted setting. This makes our new setting challenging. We present polynomial-time algorithms that compute WEF allocations with a guaranteed upper bound on total subsidy for monotone valuations and various subclasses thereof.
  We also present an efficient algorithm to compute a fair allocation of items and money, when the budget is not enough to make the allocation WEF. This algorithm is new even for the unweighted setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09006v5</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noga Klein Elmalem, Haris Aziz, Rica Gonen, Xin Huang, Kei Kimura, Indrajit Saha, Erel Segal-Halevi, Zhaohong Sun, Mashbat Suzuki, Makoto Yokoo</dc:creator>
    </item>
    <item>
      <title>You Are the Best Reviewer of Your Own Papers: The Isotonic Mechanism</title>
      <link>https://arxiv.org/abs/2206.08149</link>
      <description>arXiv:2206.08149v2 Announce Type: replace-cross 
Abstract: Machine learning (ML) and artificial intelligence (AI) conferences including NeurIPS and ICML have experienced a significant decline in peer review quality in recent years. To address this growing challenge, we introduce the Isotonic Mechanism, a computationally efficient approach to enhancing the accuracy of noisy review scores by incorporating authors' private assessments of their submissions. Under this mechanism, authors with multiple submissions are required to rank their papers in descending order of perceived quality. Subsequently, the raw review scores are calibrated based on this ranking to produce adjusted scores. We prove that authors are incentivized to truthfully report their rankings because doing so maximizes their expected utility, modeled as an additive convex function over the adjusted scores. Moreover, the adjusted scores are shown to be more accurate than the raw scores, with improvements being particularly significant when the noise level is high and the author has many submissions -- a scenario increasingly prevalent at large-scale ML/AI conferences.
  We further investigate whether submission quality information beyond a simple ranking can be truthfully elicited from authors. We establish that a necessary condition for truthful elicitation is that the mechanism be based on pairwise comparisons of the author's submissions. This result underscores the optimality of the Isotonic Mechanism, as it elicits the most fine-grained truthful information among all mechanisms we consider. We then present several extensions, including a demonstration that the mechanism maintains truthfulness even when authors have only partial rather than complete information about their submission quality. Finally, we discuss future research directions, focusing on the practical implementation of the mechanism and the further development of a theoretical framework inspired by our mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08149v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Weijie Su</dc:creator>
    </item>
    <item>
      <title>Detecting and Deterring Manipulation in a Cognitive Hierarchy</title>
      <link>https://arxiv.org/abs/2405.01870</link>
      <description>arXiv:2405.01870v2 Announce Type: replace-cross 
Abstract: Social agents with finitely nested opponent models are vulnerable to manipulation by agents with deeper reasoning and more sophisticated opponent modelling. This imbalance, rooted in logic and the theory of recursive modelling frameworks, cannot be solved directly. We propose a computational framework, $\aleph$-IPOMDP, augmenting model-based RL agents' Bayesian inference with an anomaly detection algorithm and an out-of-belief policy. Our mechanism allows agents to realize they are being deceived, even if they cannot understand how, and to deter opponents via a credible threat. We test this framework in both a mixed-motive and zero-sum game. Our results show the $\aleph$ mechanism's effectiveness, leading to more equitable outcomes and less exploitation by more sophisticated agents. We discuss implications for AI safety, cybersecurity, cognitive science, and psychiatry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01870v2</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Fri, 07 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitay Alon, Joseph M. Barnby, Stefan Sarkadi, Lion Schulz, Jeffrey S. Rosenschein, Peter Dayan</dc:creator>
    </item>
  </channel>
</rss>
