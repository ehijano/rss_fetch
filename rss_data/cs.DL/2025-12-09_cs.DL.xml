<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Dec 2025 02:47:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Reproducible Research Platform establishes a unified open science environment bridging data and software lifecycles across disciplines, from proposal to publication</title>
      <link>https://arxiv.org/abs/2512.06039</link>
      <description>arXiv:2512.06039v1 Announce Type: new 
Abstract: Many research groups aspire to make data and code FAIR and reproducible, yet struggle because the data and code life cycles are disconnected, executable environments are often missing from published work, and technical skill requirements hinder adoption. Existing approaches rarely enable researchers to keep using their preferred tools or support seamless execution across domains. To close this gap, we developed the open-source Reproducible Research Platform (RRP), which unifies research data management with version-controlled, containerized computational environments in modular, shareable projects. RRP enables anyone to execute, reuse, and publish fully documented, FAIR research workflows without manual retrieval or platform-specific setup. We demonstrate RRP's impact by reproducing results from diverse published studies, including work over a decade old, showing sustained reproducibility and usability. With a minimal graphical interface focused on core tasks, modular tool installation, and compatibility with institutional servers or local computers, RRP makes reproducible science broadly accessible across scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06039v1</guid>
      <category>cs.DL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andreas P. Cuny, Henry L\"utcke, Andrei-Valentin Plamad\u{a}, Antti Luomi, John Hennig, Matthew Baker, Fabian Rudolf, Bernd Rinn</dc:creator>
    </item>
    <item>
      <title>Measuring the Potential of Scientific Literature: A Network-Based Approach to Identifying Paradigm-Shifting Research</title>
      <link>https://arxiv.org/abs/2512.06054</link>
      <description>arXiv:2512.06054v1 Announce Type: new 
Abstract: This study introduces the Disruption Index as a superior citation-based metric. This index quantitatively assesses the degree to which a publication redirects subsequent scholarly attention away from its preceding literature, thus measuring its novelty and disruptive impact. We tested the D metric's efficacy using a rigorous dataset comprising seminal publications by Nobel Prize winners across Physics, Chemistry, and Physiology or Medicine, benchmarked against control papers with comparable citation counts but non-transformative influence. Our analysis conclusively demonstrates that the D metric effectively distinguishes these prize-worthy, field-redefining works from highly cited but merely incremental research. Furthermore, we explore two contextual variables associated with high disruptive potential: (i) the scale of collaboration (author team size) and (ii) the linguistic structure of the article's title and summary text. The results reveal a strong positive correlation between larger collaborative teams and elevated average D scores, suggesting that extensive collaboration may be a facilitator for generating paradigm shifts. Additionally, publications with high D values tend to feature more expansive titles and greater density of specialized, technical jargon in their abstracts. These findings validate the D metric as a reliable and scalable instrument for both historical and predictive identification of transformative research. They also furnish empirical evidence concerning the team structures and communication patterns that optimize for the production of groundbreaking scientific knowledge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06054v1</guid>
      <category>cs.DL</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah James</dc:creator>
    </item>
    <item>
      <title>Enhancing Information Retrieval in Digital Libraries through Unit Harmonisation in Scholarly Knowledge Graphs</title>
      <link>https://arxiv.org/abs/2512.06395</link>
      <description>arXiv:2512.06395v1 Announce Type: new 
Abstract: Scientists have always used the studies and research of other researchers to achieve new objectives and perspectives. In particular, employing and operating the measured data in previous studies is so practical. Searching the content of other scientists' articles is a challenge that researchers have always struggled with. Nowadays, the use of knowledge graphs as a semantic database has helped a lot in saving and retrieving scholarly knowledge. Such technologies are crucial to upgrading traditional search systems to smart knowledge retrieval, which is crucial to getting the most relevant answers for a user query, especially in information and knowledge management. However, in most cases, only the metadata of a paper is searchable, and it is still cumbersome for scientists to have access to the content of the papers. In this paper, we present a novel method of faceted search \emph{structured content} for comparing and filtering measured data in scholarly knowledge graphs while different units of measurement are used in different studies. This search system proposes applicable units as facets to the user and would dynamically integrate content from further remote knowledge graphs to materialize the scholarly knowledge graph and achieve a higher order of exploration usability on scholarly content, which can be filtered to better satisfy the user's information needs. The state of the art is that, by using our faceted search system, users can not only search the contents of scientific articles, but also compare and filter heterogeneous data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06395v1</guid>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Golsa Heidari, Markus Stocker, S\"oren Auer</dc:creator>
    </item>
    <item>
      <title>Who Are Tweeting About Academic Publications? A Systematic Review and Meta-Analysis of Altmetric Studies</title>
      <link>https://arxiv.org/abs/2312.06399</link>
      <description>arXiv:2312.06399v3 Announce Type: replace 
Abstract: Understanding who shares academic publications on Twitter is critical to interpreting altmetrics as signals of scholarly or societal impact. Prior studies have used diverse and often incompatible user classification schemes, making synthesis difficult. This study presents a systematic review and meta-analysis of 23 empirical studies (covering 79,014 Twitter users, over 20 million tweets, and more than 5 million tweeted publications) to estimate category-specific engagement across three metrics: user counts, tweets, and tweeted publications. We developed a harmonized categorization scheme encompassing 11 user types and applied both Random Effects Models (REM) and Beta-Binomial Hierarchical Models (BBHM) to estimate proportions, account for study-level variation, and model uncertainty. Across all indicators, individual users were the most active, comprising 66% of users, 55% of tweets, and 50% of tweeted publications. BBHM further enabled in-category vs. out-of-category comparisons and revealed engagement differences not detected by REM. T-tests on study-level means confirmed significant differences between academic individuals and other user types. Despite methodological heterogeneity, results consistently show that academic and non-academic individuals statistically equally dominate Twitter engagement with scholarly content. Our findings support the need for standardized user classification schemes and demonstrate the value of Bayesian modeling for synthesizing altmetric data in study variation and sparsity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06399v3</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashraf Maleki, Kim Holmberg</dc:creator>
    </item>
  </channel>
</rss>
