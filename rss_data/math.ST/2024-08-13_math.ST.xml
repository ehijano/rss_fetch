<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2024 10:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Testing Elliptical Models in High Dimensions</title>
      <link>https://arxiv.org/abs/2408.05514</link>
      <description>arXiv:2408.05514v1 Announce Type: new 
Abstract: Due to the broad applications of elliptical models, there is a long line of research on goodness-of-fit tests for empirically validating them. However, the existing literature on this topic is generally confined to low-dimensional settings, and to the best of our knowledge, there are no established goodness-of-fit tests for elliptical models that are supported by theoretical guarantees in high dimensions. In this paper, we propose a new goodness-of-fit test for this problem, and our main result shows that the test is asymptotically valid when the dimension and sample size diverge proportionally. Remarkably, it also turns out that the asymptotic validity of the test requires no assumptions on the population covariance matrix. With regard to numerical performance, we confirm that the empirical level of the test is close to the nominal level across a range of conditions, and that the test is able to reliably detect non-elliptical distributions. Moreover, when the proposed test is specialized to the problem of testing normality in high dimensions, we show that it compares favorably with a state-of-the-art method, and hence, this way of using the proposed test is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05514v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siyao Wang, Miles E. Lopes</dc:creator>
    </item>
    <item>
      <title>M\"obius inversion and the bootstrap</title>
      <link>https://arxiv.org/abs/2408.05826</link>
      <description>arXiv:2408.05826v1 Announce Type: new 
Abstract: Estimating nonlinear functionals of probability distributions from samples is a fundamental statistical problem. The "plug-in" estimator obtained by applying the target functional to the empirical distribution of samples is biased. Resampling methods such as the bootstrap derive artificial datasets from the original one by resampling. Comparing the outcome of the plug-in estimator in the original and resampled datasets allows estimating and thus correcting the bias. In the asymptotic setting, iterations of this procedure attain an arbitrarily high order of bias correction, but finite sample results are scarce. This work develops a new theoretical understanding of bootstrap bias correction by viewing it as an iterative linear solver for the combinatorial operation of M\"obius inversion. It sharply characterizes the regime of linear convergence of the bootstrap bias reduction for moment polynomials. It uses these results to show its superalgebraic convergence rate for band-limited functionals. Finally, it derives a modified bootstrap iteration enabling the unbiased estimation of unknown order-$m$ moment polynomials in $m$ bootstrap iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05826v1</guid>
      <category>math.ST</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Sch\"afer</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification of Spectral Estimator and MLE for Orthogonal Group Synchronization</title>
      <link>https://arxiv.org/abs/2408.05944</link>
      <description>arXiv:2408.05944v1 Announce Type: new 
Abstract: Orthogonal group synchronization aims to recover orthogonal group elements from their noisy pairwise measurements. It has found numerous applications including computer vision, imaging science, and community detection. Due to the orthogonal constraints, it is often challenging to find the least squares estimator in presence of noise. In the recent years, semidefinite relaxation (SDR) and spectral methods have proven to be powerful tools in recovering the group elements. In particular, under additive Gaussian noise, the SDR exactly produces the maximum likelihood estimator (MLE), and both MLE and spectral methods are able to achieve near-optimal statistical error. In this work, we take one step further to quantify the uncertainty of the MLE and spectral estimators by considering their distributions. By leveraging the orthogonality constraints in the likelihood function, we obtain a second-order expansion of the MLE and spectral estimator with the leading terms as an anti-symmetric Gaussian random matrix that is on the tangent space of the orthogonal matrix. This also implies state-of-the-art min-max risk bounds as a by-product. Our works provide a general theoretical framework that is potentially useful to find an approximate distribution of the estimators arising from many statistical inference problems with manifold constraints. The numerical experiments confirm our theoretical contribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05944v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ziliang Samuel Zhong, Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>Non-asymptotic Estimates for Markov Transition Matrices with Rigorous Error Bounds</title>
      <link>https://arxiv.org/abs/2408.05963</link>
      <description>arXiv:2408.05963v1 Announce Type: new 
Abstract: We establish non-asymptotic error bounds for the classical Maximal Likelihood Estimation of the transition matrix of a given Markov chain. Meanwhile, in the reversible case, we propose a new reversibility-preserving online Symmetric Counting Estimation of the transition matrix with non-asymptotic deviation bounds. Our analysis is based on a convergence study of certain Markov chains on the length-2 path spaces induced by the original Markov chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05963v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>De Huang, Xiangyuan Li</dc:creator>
    </item>
    <item>
      <title>On bivariate lower semilinear copulas and the star product</title>
      <link>https://arxiv.org/abs/2408.05989</link>
      <description>arXiv:2408.05989v1 Announce Type: new 
Abstract: We revisit the family $\mathcal{C}^{LSL}$ of all bivariate lower semilinear (LSL) copulas first introduced by Durante et al. in 2008 and, using the characterization of LSL copulas in terms of diagonals with specific properties, derive several novel and partially unexpected results. In particular we prove that the star product (also known as Markov product) $S_{\delta_1}*S_{\delta_2}$ of two LSL copulas $S_{\delta_1},S_{\delta_2}$ is again a LSL copula, i.e., that the family $\mathcal{C}^{LSL}$ is closed with respect to the star product. Moreover, we show that translating the star product to the class of corresponding diagonals $\mathcal{D}^{LSL}$ allows to determine the limit of the sequence $S_\delta, S_\delta*S_\delta, S_\delta*S_\delta*S_\delta,\ldots$ for every diagonal $\delta \in \mathcal{D}^{LSL}$. In fact, for every LSL copula $S_\delta$ the sequence $(S_\delta^{*n})_{n \in \mathbb{N}}$ converges to some LSL copula $S_{\overline{\delta}}$, the limit $S_{\overline{\delta}}$ is idempotent, and the class of all idempotent LSL copulas allows for a simple characterization. Complementing these results we then focus on concordance of LSL copulas. After deriving simple formulas for Kendall's $\tau$ and Spearman's $\rho$ we study the exact region $\Omega^{LSL}$ determined by these two concordance measures of all elements in $\mathcal{C}^{LSL}$, derive a sharp lower bound and finally show that $\Omega^{LSL}$ is convex and compact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05989v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lea Maislinger, Wolfgang Trutschnig</dc:creator>
    </item>
    <item>
      <title>Auto-Calibration Tests for Discrete Finite Regression Functions</title>
      <link>https://arxiv.org/abs/2408.05993</link>
      <description>arXiv:2408.05993v1 Announce Type: new 
Abstract: Auto-calibration is an important property of regression functions for actuarial applications. Comparably little is known about statistical testing of auto-calibration. Denuit et al.~(2024) recently published a test with an asymptotic distribution that is not fully explicit and its evaluation needs non-parametric Monte Carlo sampling. In a simpler set-up, we present three test statistics with fully known and interpretable asymptotic distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05993v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario V. W\"uthrich</dc:creator>
    </item>
    <item>
      <title>Method-of-Moments Inference for GLMs and Doubly Robust Functionals under Proportional Asymptotics</title>
      <link>https://arxiv.org/abs/2408.06103</link>
      <description>arXiv:2408.06103v1 Announce Type: new 
Abstract: In this paper, we consider the estimation of regression coefficients and signal-to-noise (SNR) ratio in high-dimensional Generalized Linear Models (GLMs), and explore their implications in inferring popular estimands such as average treatment effects in high-dimensional observational studies. Under the ``proportional asymptotic'' regime and Gaussian covariates with known (population) covariance $\Sigma$, we derive Consistent and Asymptotically Normal (CAN) estimators of our targets of inference through a Method-of-Moments type of estimators that bypasses estimation of high dimensional nuisance functions and hyperparameter tuning altogether. Additionally, under non-Gaussian covariates, we demonstrate universality of our results under certain additional assumptions on the regression coefficients and $\Sigma$. We also demonstrate that knowing $\Sigma$ is not essential to our proposed methodology when the sample covariance matrix estimator is invertible. Finally, we complement our theoretical results with numerical experiments and comparisons with existing literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06103v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyu Chen, Lin Liu, Rajarshi Mukherjee</dc:creator>
    </item>
    <item>
      <title>On differentiability and mass distributions of typical bivariate copulas</title>
      <link>https://arxiv.org/abs/2408.06268</link>
      <description>arXiv:2408.06268v1 Announce Type: new 
Abstract: Despite the fact that copulas are commonly considered as analytically smooth/regular objects, derivatives of copulas have to be handled with care. Triggered by a recently published result characterizing multivariate copulas via $(d-1)$-increasingness of their partial derivative we study the bivariate setting in detail and show that the set of non-differentiability points of a copula may be quite large. We first construct examples of copulas $C$ whose first partial derivative $\partial_1C(x,y)$ is pathological in the sense that for almost every $x \in (0,1)$ it does not exist on a dense subset of $y \in (0,1)$, and then show that the family of these copulas is dense. Since in commonly considered subfamilies more regularity might be typical, we then focus on bivariate Extreme Value copulas (EVC) and show that a topologically typical EVC is not absolutely continuous but has degenerated discrete component, implying that in this class typically $\partial_1C(x,y)$ exists in full $(0,1)^2$. Considering that regularity of copulas is closely related to their mass distributions we then study mass distributions of topologically typical copulas and prove the surprising fact that topologically typical bivariate copulas are mutually completely dependent with full support. Furthermore, we use the characterization of EVCs in terms of their associated Pickands dependence measures $\vartheta$ on $[0,1]$, show that regularity of $\vartheta$ carries over to the corresponding EVC and prove that the subfamily of all EVCs whose absolutely continuous, discrete and singular component has full support is dense in the class of all EVCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06268v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Dietrich, Wolfgang Trutschnig</dc:creator>
    </item>
    <item>
      <title>Simple and Nearly-Optimal Sampling for Rank-1 Tensor Completion via Gauss-Jordan</title>
      <link>https://arxiv.org/abs/2408.05431</link>
      <description>arXiv:2408.05431v1 Announce Type: cross 
Abstract: We revisit the sample and computational complexity of completing a rank-1 tensor in $\otimes_{i=1}^{N} \mathbb{R}^{d}$, given a uniformly sampled subset of its entries. We present a characterization of the problem (i.e. nonzero entries) which admits an algorithm amounting to Gauss-Jordan on a pair of random linear systems. For example, when $N = \Theta(1)$, we prove it uses no more than $m = O(d^2 \log d)$ samples and runs in $O(md^2)$ time. Moreover, we show any algorithm requires $\Omega(d\log d)$ samples.
  By contrast, existing upper bounds on the sample complexity are at least as large as $d^{1.5} \mu^{\Omega(1)} \log^{\Omega(1)} d$, where $\mu$ can be $\Theta(d)$ in the worst case. Prior work obtained these looser guarantees in higher rank versions of our problem, and tend to involve more complicated algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05431v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Gomez-Leos, Oscar L\'opez</dc:creator>
    </item>
    <item>
      <title>Kernel Density Estimators in Large Dimensions</title>
      <link>https://arxiv.org/abs/2408.05807</link>
      <description>arXiv:2408.05807v1 Announce Type: cross 
Abstract: This paper studies Kernel density estimation for a high-dimensional distribution $\rho(x)$. Traditional approaches have focused on the limit of large number of data points $n$ and fixed dimension $d$. We analyze instead the regime where both the number $n$ of data points $y_i$ and their dimensionality $d$ grow with a fixed ratio $\alpha=(\log n)/d$. Our study reveals three distinct statistical regimes for the kernel-based estimate of the density $\hat \rho_h^{\mathcal {D}}(x)=\frac{1}{n h^d}\sum_{i=1}^n K\left(\frac{x-y_i}{h}\right)$, depending on the bandwidth $h$: a classical regime for large bandwidth where the Central Limit Theorem (CLT) holds, which is akin to the one found in traditional approaches. Below a certain value of the bandwidth, $h_{CLT}(\alpha)$, we find that the CLT breaks down. The statistics of $\hat \rho_h^{\mathcal {D}}(x)$ for a fixed $x$ drawn from $\rho(x)$ is given by a heavy-tailed distribution (an alpha-stable distribution). In particular below a value $h_G(\alpha)$, we find that $\hat \rho_h^{\mathcal {D}}(x)$ is governed by extreme value statistics: only a few points in the database matter and give the dominant contribution to the density estimator. We provide a detailed analysis for high-dimensional multivariate Gaussian data. We show that the optimal bandwidth threshold based on Kullback-Leibler divergence lies in the new statistical regime identified in this paper. Our findings reveal limitations of classical approaches, show the relevance of these new statistical regimes, and offer new insights for Kernel density estimation in high-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05807v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giulio Biroli, Marc M\'ezard</dc:creator>
    </item>
    <item>
      <title>High Probability Low Latency Sequential Change Detection over an Unknown Finite Horizon</title>
      <link>https://arxiv.org/abs/2408.05817</link>
      <description>arXiv:2408.05817v1 Announce Type: cross 
Abstract: A finite horizon variant of the quickest change detection problem is studied, in which the goal is to minimize a delay threshold (latency), under constraints on the probability of false alarm and the probability that the latency is exceeded. In addition, the horizon is not known to the change detector. A variant of the cumulative sum (CuSum) test with a threshold that increasing logarithmically with time is proposed as a candidate solution to the problem. An information-theoretic lower bound on the minimum value of the latency under the constraints is then developed. This lower bound is used to establish certain asymptotic optimality properties of the proposed test in terms of the horizon and the false alarm probability. Some experimental results are given to illustrate the performance of the test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05817v1</guid>
      <category>cs.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Han Huang, Venugopal V. Veeravalli</dc:creator>
    </item>
    <item>
      <title>On the Robustness of Kernel Goodness-of-Fit Tests</title>
      <link>https://arxiv.org/abs/2408.05854</link>
      <description>arXiv:2408.05854v1 Announce Type: cross 
Abstract: Goodness-of-fit testing is often criticized for its lack of practical relevance; since ``all models are wrong'', the null hypothesis that the data conform to our model is ultimately always rejected when the sample size is large enough. Despite this, probabilistic models are still used extensively, raising the more pertinent question of whether the model is good enough for a specific task. This question can be formalized as a robust goodness-of-fit testing problem by asking whether the data were generated by a distribution corresponding to our model up to some mild perturbation. In this paper, we show that existing kernel goodness-of-fit tests are not robust according to common notions of robustness including qualitative and quantitative robustness. We also show that robust techniques based on tilted kernels from the parameter estimation literature are not sufficient for ensuring both types of robustness in the context of goodness-of-fit testing. We therefore propose the first robust kernel goodness-of-fit test which resolves this open problem using kernel Stein discrepancy balls, which encompass perturbation models such as Huber contamination models and density uncertainty bands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05854v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xing Liu, Fran\c{c}ois-Xavier Briol</dc:creator>
    </item>
    <item>
      <title>Censored and extreme losses: functional convergence and applications to tail goodness-of-fit</title>
      <link>https://arxiv.org/abs/2408.05862</link>
      <description>arXiv:2408.05862v1 Announce Type: cross 
Abstract: This paper establishes the functional convergence of the Extreme Nelson--Aalen and Extreme Kaplan--Meier estimators, which are designed to capture the heavy-tailed behaviour of censored losses. The resulting limit representations can be used to obtain the distributions of pathwise functionals with respect to the so-called tail process. For instance, we may recover the convergence of a censored Hill estimator, and we further investigate two goodness-of-fit statistics for the tail of the loss distribution. Using the the latter limit theorems, we propose two rules for selecting a suitable number of order statistics, both based on test statistics derived from the functional convergence results. The effectiveness of these selection rules is investigated through simulations and an application to a real dataset comprised of French motor insurance claim sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05862v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bladt, Christoffer {\O}hlenschl{\ae}ger</dc:creator>
    </item>
    <item>
      <title>On the Exactness of SDP Relaxation for Quadratic Assignment Problem</title>
      <link>https://arxiv.org/abs/2408.05942</link>
      <description>arXiv:2408.05942v1 Announce Type: cross 
Abstract: Quadratic assignment problem (QAP) is a fundamental problem in combinatorial optimization and finds numerous applications in operation research, computer vision, and pattern recognition. However, it is a very well-known NP-hard problem to find the global minimizer to the QAP. In this work, we study the semidefinite relaxation (SDR) of the QAP and investigate when the SDR recovers the global minimizer. In particular, we consider the two input matrices satisfy a simple signal-plus-noise model, and show that when the noise is sufficiently smaller than the signal, then the SDR is exact, i.e., it recovers the global minimizer to the QAP. It is worth noting that this sufficient condition is purely algebraic and does not depend on any statistical assumption of the input data. We apply our bound to several statistical models such as correlated Gaussian Wigner model. Despite the sub-optimality in theory under those models, empirical studies show the remarkable performance of the SDR. Our work could be the first step towards a deeper understanding of the SDR exactness for the QAP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05942v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuyang Ling</dc:creator>
    </item>
    <item>
      <title>Identifying Total Causal Effects in Linear Models under Partial Homoscedasticity</title>
      <link>https://arxiv.org/abs/2408.06046</link>
      <description>arXiv:2408.06046v1 Announce Type: cross 
Abstract: A fundamental challenge of scientific research is inferring causal relations based on observed data. One commonly used approach involves utilizing structural causal models that postulate noisy functional relations among interacting variables. A directed graph naturally represents these models and reflects the underlying causal structure. However, classical identifiability results suggest that, without conducting additional experiments, this causal graph can only be identified up to a Markov equivalence class of indistinguishable models. Recent research has shown that focusing on linear relations with equal error variances can enable the identification of the causal structure from mere observational data. Nonetheless, practitioners are often primarily interested in the effects of specific interventions, rendering the complete identification of the causal structure unnecessary. In this work, we investigate the extent to which less restrictive assumptions of partial homoscedasticity are sufficient for identifying the causal effects of interest. Furthermore, we construct mathematically rigorous confidence regions for total causal effects under structure uncertainty and explore the performance gain of relying on stricter error assumptions in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06046v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Strieder, Mathias Drton</dc:creator>
    </item>
    <item>
      <title>PanIC: consistent information criteria for general model selection problems</title>
      <link>https://arxiv.org/abs/2303.03649</link>
      <description>arXiv:2303.03649v4 Announce Type: replace 
Abstract: Model selection is a ubiquitous problem that arises in the application of many statistical and machine learning methods. In the likelihood and related settings, it is typical to use the method of information criteria (IC) to choose the most parsimonious among competing models by penalizing the likelihood-based objective function. Theorems guaranteeing the consistency of IC can often be difficult to verify and are often specific and bespoke. We present a set of results that guarantee consistency for a class of IC, which we call PanIC (from the Greek root 'pan', meaning 'of everything'), with easily verifiable regularity conditions. The PanIC are applicable in any loss-based learning problem and are not exclusive to likelihood problems. We illustrate the verification of regularity conditions for model selection problems regarding finite mixture models, least absolute deviation and support vector regression, and principal component analysis, and we demonstrate the effectiveness of the PanIC for such problems via numerical simulations. Furthermore, we present new sufficient conditions for the consistency of BIC-like estimators and provide comparisons of the BIC to PanIC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.03649v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hien Duy Nguyen</dc:creator>
    </item>
    <item>
      <title>Mixed orthogonality graphs for continuous-time stationary processes</title>
      <link>https://arxiv.org/abs/2308.08890</link>
      <description>arXiv:2308.08890v2 Announce Type: replace 
Abstract: In this paper, we introduce different concepts of Granger causality and contemporaneous correlation for multivariate stationary continuous-time processes to model different dependencies between the component processes. Several equivalent characterisations are given for the different definitions, in particular by orthogonal projections. We then define two mixed graphs based on different definitions of Granger causality and contemporaneous correlation, the (mixed) orthogonality graph and the local (mixed) orthogonality graph. In these graphs, the components of the process are represented by vertices, directed edges between the vertices visualise Granger causal influences and undirected edges visualise contemporaneous correlation between the component processes. Further, we introduce various notions of Markov properties in analogy to Eichler (2012), which relate paths in the graphs to different dependence structures of subprocesses, and we derive sufficient criteria for the (local) orthogonality graph to satisfy them. Finally, as an example, for the popular multivariate continuous-time AR (MCAR) processes, we explicitly characterise the edges in the (local) orthogonality graph by the model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08890v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vicky Fasen-Hartmann, Lea Schenk</dc:creator>
    </item>
    <item>
      <title>Estimating Lagged (Cross-)Covariance Operators of $L^p$-$m$-approximable Processes in Cartesian Product Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2402.08110</link>
      <description>arXiv:2402.08110v4 Announce Type: replace 
Abstract: Estimating parameters of functional ARMA, GARCH and invertible processes requires estimating lagged covariance and cross-covariance operators of Cartesian product Hilbert space-valued processes. Asymptotic results have been derived in recent years, either less generally or under a strict condition. This article derives upper bounds of the estimation errors for such operators based on the mild condition Lp-m-approximability for each lag, Cartesian power(s) and sample size, where the two processes can take values in different spaces in the context of lagged cross-covariance operators. Implications of our results on eigenelements, parameters in functional AR(MA) models and other general situations are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08110v4</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastian K\"uhnert</dc:creator>
    </item>
    <item>
      <title>Nonparametric bootstrap of high-dimensional sample covariance matrices</title>
      <link>https://arxiv.org/abs/2406.16849</link>
      <description>arXiv:2406.16849v2 Announce Type: replace 
Abstract: We introduce a new "$(m,mp/n)$ out of $(n,p)$" sampling-with-replace\-ment bootstrap for eigenvalue statistics of high-dimensional sample covariance matrices based on $n$ independent $p$-dimensional random vectors. In the high-dimensional scenario $p/n\rightarrow c\in (0,\infty)$, this fully nonparametric and computationally tractable bootstrap is shown to consistently reproduce the empirical spectral measure if $m/n\rightarrow 0$. If $m^2/n\rightarrow 0$, it approximates correctly the distribution of linear spectral statistics. The crucial component is a suitably defined Representative Subpopulation Condition which is shown to be verified in a large variety of situations. Our proofs are conducted under minimal moment requirements and incorporate delicate results on non-centered quadratic forms, combinatorial trace moments estimates as well as a conditional bootstrap martingale CLT which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16849v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Holger Dette, Angelika Rohde</dc:creator>
    </item>
    <item>
      <title>E-backtesting</title>
      <link>https://arxiv.org/abs/2209.00991</link>
      <description>arXiv:2209.00991v4 Announce Type: replace-cross 
Abstract: In the recent Basel Accords, the Expected Shortfall (ES) replaces the Value-at-Risk (VaR) as the standard risk measure for market risk in the banking sector, making it the most important risk measure in financial regulation. One of the most challenging tasks in risk modeling practice is to backtest ES forecasts provided by financial institutions. To design a model-free backtesting procedure for ES, we make use of the recently developed techniques of e-values and e-processes. Backtest e-statistics are introduced to formulate e-processes for risk measure forecasts, and unique forms of backtest e-statistics for VaR and ES are characterized using recent results on identification functions. For a given backtest e-statistic, a few criteria for optimally constructing the e-processes are studied. The proposed method can be naturally applied to many other risk measures and statistical quantities. We conduct extensive simulation studies and data analysis to illustrate the advantages of the model-free backtesting method, and compare it with the ones in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.00991v4</guid>
      <category>q-fin.RM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qiuqi Wang, Ruodu Wang, Johanna Ziegel</dc:creator>
    </item>
    <item>
      <title>Variable Selection and Minimax Prediction in High-dimensional Functional Linear Model</title>
      <link>https://arxiv.org/abs/2310.14419</link>
      <description>arXiv:2310.14419v3 Announce Type: replace-cross 
Abstract: High-dimensional functional data have become increasingly prevalent in modern applications such as high-frequency financial data and neuroimaging data analysis. We investigate a class of high-dimensional linear regression models, where each predictor is a random element in an infinite-dimensional function space, and the number of functional predictors $p$ can potentially be ultra-high. Assuming that each of the unknown coefficient functions belongs to some reproducing kernel Hilbert space (RKHS), we regularize the fitting of the model by imposing a group elastic-net type of penalty on the RKHS norms of the coefficient functions. We show that our loss function is Gateaux sub-differentiable, and our functional elastic-net estimator exists uniquely in the product RKHS. Under suitable sparsity assumptions and a functional version of the irrepresentable condition, we derive a non-asymptotic tail bound for variable selection consistency of our method. Allowing the number of true functional predictors $q$ to diverge with the sample size, we also show a post-selection refined estimator can achieve the oracle minimax optimal prediction rate. The proposed methods are illustrated through simulation studies and a real-data application from the Human Connectome Project.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14419v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingche Guo, Yehua Li, Tailen Hsing</dc:creator>
    </item>
    <item>
      <title>The distribution of Bayes' ratio</title>
      <link>https://arxiv.org/abs/2404.00744</link>
      <description>arXiv:2404.00744v2 Announce Type: replace-cross 
Abstract: The ratio of Bayesian evidences is a popular tool in cosmology to compare different models. There are however several issues with this method: Bayes' ratio depends on the prior even in the limit of non-informative priors, and Jeffrey's scale, used to assess the test, is arbitrary. Moreover, the standard use of Bayes' ratio is often criticized for being unable to reject models. In this paper, we address these shortcoming by promoting evidences and evidence ratios to frequentist statistics and deriving their sampling distributions. By comparing the evidence ratios to their sampling distributions, poor fitting models can now be rejected. Our method additionally does not depend on the prior in the limit of very weak priors, thereby safeguarding the experimenter against premature rejection of a theory with a uninformative prior, and replaces the arbitrary Jeffrey's scale by probability thresholds for rejection. We provide analytical solutions for some simplified cases (Gaussian data, linear parameters, and nested models), and we apply the method to cosmological supernovae Ia data. We dub our method the FB method, for Frequentist-Bayesian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00744v2</guid>
      <category>astro-ph.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Amendola, Vrund Patel, Ziad Sakr, Elena Sellentin, Kevin Wolz</dc:creator>
    </item>
  </channel>
</rss>
