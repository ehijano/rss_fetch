<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Oct 2024 02:08:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Misleading Ourselves: How Disinformation Manipulates Sensemaking</title>
      <link>https://arxiv.org/abs/2410.14858</link>
      <description>arXiv:2410.14858v1 Announce Type: new 
Abstract: Informal sensemaking surrounding U.S. election processes has been fraught in recent years, due to the inherent uncertainty of elections, the complexity of election processes in the U.S., and to disinformation. Based on insights from qualitative analysis of election rumors spreading online in 2020 and 2022, we introduce the concept of manipulated sensemaking to describe how disinformation functions by disrupting online audiences ability to make sense of novel, uncertain, or ambiguous information. We describe how at the core of this disruption is the ability for disinformation to shape broad, underlying stories called deep stories which determine the frames we use to make sense of this novel information. Additionally, we explain how sensemakings orientation around plausible explanations over accurate explanations makes it vulnerable to manipulation. Lastly, we demonstrate how disinformed deep stories shape sensemaking not just for a single event, but for many events in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14858v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stephen Prochaska, Julie Vera, Douglas Lew Tan, Kate Starbird</dc:creator>
    </item>
    <item>
      <title>Vital Insight: Assisting Experts' Sensemaking Process of Multi-modal Personal Tracking Data Using Visualization and LLM</title>
      <link>https://arxiv.org/abs/2410.14879</link>
      <description>arXiv:2410.14879v1 Announce Type: new 
Abstract: Researchers have long recognized the socio-technical gaps in personal tracking research, where machines can never fully model the complexity of human behavior, making it only able to produce basic rule-based outputs or "black-box" results that lack clear explanations. Real-world deployments rely on experts for this complex translation from sparse data to meaningful insights. In this study, we consider this translation process from data to insights by experts as "sensemaking" and explore how HCI researchers can support it through Vital Insight, an evidence-based 'sensemaking' system that combines direct representation and indirect inference through visualization and Large Language Models. We evaluate Vital Insight in user testing sessions with 14 experts in multi-modal tracking, synthesize design implications, and develop an expert sensemaking model where they iteratively move between direct data representations and AI-supported inferences to explore, retrieve, question, and validate insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14879v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Li, Justin Steinberg, Xiwen Li, Akshat Choube, Bingsheng Yao, Dakuo Wang, Elizabeth Mynatt, Varun Mishra</dc:creator>
    </item>
    <item>
      <title>Testing and validation of innovative eXtended Reality technologies for astronaut training in a partial-gravity parabolic flight campaign</title>
      <link>https://arxiv.org/abs/2410.14922</link>
      <description>arXiv:2410.14922v1 Announce Type: new 
Abstract: The use of eXtended Reality (XR) technologies in the space domain has increased significantly over the past few years as it can offer many advantages when simulating complex and challenging environments. Space agencies are currently using these disruptive tools to train astronauts for Extravehicular Activities (EVAs), to test equipment and procedures, and to assess spacecraft and hardware designs. With the Moon being the current focus of the next generation of space exploration missions, simulating its harsh environment is one of the key areas where XR can be applied, particularly for astronaut training. Peculiar lunar lighting conditions in combination with reduced gravity levels will highly impact human locomotion especially for movements such as walking, jumping, and running. In order to execute operations on the lunar surface and to safely live on the Moon for an extended period of time, innovative training methodologies and tools such as XR are becoming paramount to perform pre-mission validation and certification. This research work presents the findings of the experiments aimed at exploring the integration of XR technology and parabolic flight activities for astronaut training. In addition, the study aims to consolidate these findings into a set of guidelines that can assist future researchers who wish to incorporate XR technology into lunar training and preparation activities, including the use of such XR tools during long duration missions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14922v1</guid>
      <category>cs.HC</category>
      <category>cs.MM</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Saling, Andrea Emanuele Maria Casini, Andreas Treuer, Martial Costantini, Leonie Bensch, Tommy Nilsson, Lionel Ferra</dc:creator>
    </item>
    <item>
      <title>"Confrontation or Acceptance": Understanding Novice Visual Artists' Perception towards AI-assisted Art Creation</title>
      <link>https://arxiv.org/abs/2410.14925</link>
      <description>arXiv:2410.14925v1 Announce Type: new 
Abstract: The rise of Generative Artificial Intelligence (G-AI) has transformed the creative arts landscape by producing novel artwork, whereas in the same time raising ethical concerns. While previous studies have addressed these concerns from technical and societal viewpoints, there is a lack of discussion from an HCI perspective, especially considering the community's perception and the visual artists as human factors. Our study investigates G-AI's impact on visual artists and their relationship with GAI to inform HCI research. We conducted semi-structured interviews with 20 novice visual artists from an art college in the university with G-AI courses and practices. Our findings reveal (1) the mis-conception and the evolving adoption of visual artists, (2) the miscellaneous opinions of the society on visual artists' creative work, and (3) the co-existence of confrontation and collaboration between visual artists and G-AI. We explore future HCI research opportunities to address these issues.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14925v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuning Zhang, Shixuan Li</dc:creator>
    </item>
    <item>
      <title>"Ghost of the past": identifying and resolving privacy leakage from LLM's memory through proactive user interaction</title>
      <link>https://arxiv.org/abs/2410.14931</link>
      <description>arXiv:2410.14931v1 Announce Type: new 
Abstract: Memories, encompassing past inputs in context window and retrieval-augmented generation (RAG), frequently surface during human-LLM interactions, yet users are often unaware of their presence and the associated privacy risks. To address this, we propose MemoAnalyzer, a system for identifying, visualizing, and managing private information within memories. A semi-structured interview (N=40) revealed that low privacy awareness was the primary challenge, while proactive privacy control emerged as the most common user need. MemoAnalyzer uses a prompt-based method to infer and identify sensitive information from aggregated past inputs, allowing users to easily modify sensitive content. Background color temperature and transparency are mapped to inference confidence and sensitivity, streamlining privacy adjustments. A 5-day evaluation (N=36) comparing MemoAnalyzer with the default GPT setting and a manual modification baseline showed MemoAnalyzer significantly improved privacy awareness and protection without compromising interaction speed. Our study contributes to privacy-conscious LLM design, offering insights into privacy protection for Human-AI interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14931v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shuning Zhang, Lyumanshan Ye, Xin Yi, Jingyu Tang, Bo Shui, Haobin Xing, Pengfei Liu, Hewu Li</dc:creator>
    </item>
    <item>
      <title>A Civics-oriented Approach to Understanding Intersectionally Marginalized Users' Experience with Hate Speech Online</title>
      <link>https://arxiv.org/abs/2410.14950</link>
      <description>arXiv:2410.14950v1 Announce Type: new 
Abstract: While content moderation in online platforms marginalizes users in the Global South at large, users of certain identities are further marginalized. Such users often come from Indigenous ethnic minority groups or identify as women. Through a qualitative study based on 18 semi-structured interviews, this paper explores how such users' experiences with hate speech online in Bangladesh are shaped by their intersectional identities. Through a civics-oriented approach, we examined the spectrum of their legal status, membership, rights, and participation as users of online platforms. Drawing analogies with the concept of citizenship, we develop the concept of usership that offers a user-centered metaphor in studying moderation and platform governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14950v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3700794.3700802</arxiv:DOI>
      <dc:creator>Achhiya Sultana, Dipto Das, Saadia Binte Alam, Mohammad Shidujaman, Syed Ishtiaque Ahmed</dc:creator>
    </item>
    <item>
      <title>PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM</title>
      <link>https://arxiv.org/abs/2410.15023</link>
      <description>arXiv:2410.15023v1 Announce Type: new 
Abstract: Listening to audio content, such as podcasts and audiobooks, is one of the ways people engage with knowledge. Listening affords people more mobility than reading by seeing, thus broadening learning opportunities. This study explores the potential applications of large language models (LLMs) to adapt text documents into audio content, addressing the lack of listening-friendly materials for niche content like research papers. LLMs can generate scripts of audio content in various styles tailored to specific needs, such as the duration of the content and whether it is a monologue or dialogue. To explore this potential, we developed PaperWave, a prototype that transforms academic paper PDFs into conversational podcasts. Our two-month investigation involving 11 participants (including the authors) employed autobiographical design, a field study, and a design workshop. The findings highlight the importance of considering listeners' interaction with their environment when designing document-to-audio systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15023v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchi Yahagi, Rintaro Chujo, Yuga Harada, Changyo Han, Kohei Sugiyama, Takeshi Naemura</dc:creator>
    </item>
    <item>
      <title>LLM-Driven Learning Analytics Dashboard for Teachers in EFL Writing Education</title>
      <link>https://arxiv.org/abs/2410.15025</link>
      <description>arXiv:2410.15025v1 Announce Type: new 
Abstract: This paper presents the development of a dashboard designed specifically for teachers in English as a Foreign Language (EFL) writing education. Leveraging LLMs, the dashboard facilitates the analysis of student interactions with an essay writing system, which integrates ChatGPT for real-time feedback. The dashboard aids teachers in monitoring student behavior, identifying noneducational interaction with ChatGPT, and aligning instructional strategies with learning objectives. By combining insights from NLP and Human-Computer Interaction (HCI), this study demonstrates how a human-centered approach can enhance the effectiveness of teacher dashboards, particularly in ChatGPT-integrated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15025v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minsun Kim, SeonGyeom Kim, Suyoun Lee, Yoosang Yoon, Junho Myung, Haneul Yoo, Hyunseung Lim, Jieun Han, Yoonsu Kim, So-Yeon Ahn, Juho Kim, Alice Oh, Hwajung Hong, Tak Yeon Lee</dc:creator>
    </item>
    <item>
      <title>Adanonymizer: Interactively Navigating and Balancing the Duality of Privacy and Output Performance in Human-LLM Interaction</title>
      <link>https://arxiv.org/abs/2410.15044</link>
      <description>arXiv:2410.15044v1 Announce Type: new 
Abstract: Current Large Language Models (LLMs) cannot support users to precisely balance privacy protection and output performance during individual consultations. We introduce Adanonymizer, an anonymization plug-in that allows users to control this balance by navigating a trade-off curve. A survey (N=221) revealed a privacy paradox, where users frequently disclosed sensitive information despite acknowledging privacy risks. The study further demonstrated that privacy risks were not significantly correlated with model output performance, highlighting the potential to navigate this trade-off. Adanonymizer normalizes privacy and utility ratings by type and automates the pseudonymization of sensitive terms based on user preferences, significantly reducing user effort. Its 2D color palette interface visualizes the privacy-utility trade-off, allowing users to adjust the balance by manipulating a point. An evaluation (N=36) compared Adanonymizer with ablation methods and differential privacy techniques, where Adanonymizer significantly reduced modification time, achieved better perceived model performance and overall user preference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15044v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shuning Zhang, Xin Yi, Haobin Xing, Lyumanshan Ye, Yongquan Hu, Hewu Li</dc:creator>
    </item>
    <item>
      <title>Emotionally Enriched Feedback via Generative AI</title>
      <link>https://arxiv.org/abs/2410.15077</link>
      <description>arXiv:2410.15077v1 Announce Type: new 
Abstract: This study investigates the impact of emotionally enriched AI feedback on student engagement and emotional responses in higher education. Leveraging the Control-Value Theory of Achievement Emotions, we conducted a randomized controlled experiment involving 425 participants where the experimental group received AI feedback enhanced with motivational elements, while the control group received neutral feedback. Our findings reveal that emotionally enriched feedback is perceived as more beneficial and helps reduce negative emotions, particularly anger, towards receiving feedback. However, it had no significant impact on the level of engagement with feedback or the quality of student work. These results suggest that incorporating emotional elements into AI-driven feedback can positively influence student perceptions and emotional well-being, without compromising work quality. Our study contributes to the growing body of research on AI in education by highlighting the importance of emotional considerations in educational technology design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15077v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Omar Alsaiari, Nilufar Baghaei, Hatim Lahza, Jason Lodge, Marie Boden, Hassan Khosravi</dc:creator>
    </item>
    <item>
      <title>Exploring the Design of Virtual Reality Museums to Support Remote Visitation With Older Adults</title>
      <link>https://arxiv.org/abs/2410.15092</link>
      <description>arXiv:2410.15092v1 Announce Type: new 
Abstract: Virtual Reality (VR) museums provide immersive visiting experiences. Despite growing efforts in VR museum design optimization, limited research addresses its efficacy for older adults. We sought to investigate the challenges of and preferences for VR museum visits among older adults through a user-centered participatory workshop. Our preliminary findings illuminate issues regarding spatial navigation, interpretive descriptions, collective aspiration for augmented multi-sensory interactions, and imagined content visualization. Based on our preliminary findings, we discuss potential design principles for enhancing the accessibility of VR museums for older adults.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15092v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingling Zhang, Qianjie Wei, Xiaoying Wei, Mingming Fan</dc:creator>
    </item>
    <item>
      <title>Evaluation Of P300 Speller Performance Using Large Language Models Along With Cross-Subject Training</title>
      <link>https://arxiv.org/abs/2410.15161</link>
      <description>arXiv:2410.15161v1 Announce Type: new 
Abstract: Amyotrophic lateral sclerosis (ALS), a progressive neuromuscular degenerative disease, severely restricts patient communication capacity within a few years of onset, resulting in a significant deterioration of quality of life. The P300 speller brain computer interface (BCI) offers an alternative communication medium by leveraging a subject's EEG response to characters traditionally highlighted on a character grid on a graphical user interface (GUI). A recurring theme in P300-based research is enhancing performance to enable faster subject interaction. This study builds on that theme by addressing key limitations, particularly in the training of multi-subject classifiers, and by integrating advanced language models to optimize stimuli presentation and word prediction, thereby improving communication efficiency. Furthermore, various advanced large language models such as Generative Pre-Trained Transformer (GPT2), BERT, and BART, alongside Dijkstra's algorithm, are utilized to optimize stimuli and provide word completion choices based on the spelling history. In addition, a multi-layered smoothing approach is applied to allow for out-of-vocabulary (OOV) words. By conducting extensive simulations based on randomly sampled EEG data from subjects, we show substantial speed improvements in typing passages that include rare and out-of-vocabulary (OOV) words, with the extent of improvement varying depending on the language model utilized. The gains through such character-level interface optimizations are approximately 10%, and GPT2 for multi-word prediction provides gains of around 40%. In particular, some large language models achieve performance levels within 10% of the theoretical performance limits established in this study. In addition, both within and across subjects, training techniques are explored, and speed improvements are shown to hold in both cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15161v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nithin Parthasarathy, James Soetedjo, Saarang Panchavati, Nitya Parthasarathy, Corey Arnold, Nader Pouratian, William Speier</dc:creator>
    </item>
    <item>
      <title>The Politics of Fear and the Experience of Bangladeshi Religious Minority Communities Using Social Media Platforms</title>
      <link>https://arxiv.org/abs/2410.15207</link>
      <description>arXiv:2410.15207v1 Announce Type: new 
Abstract: Despite significant research on online harm, polarization, public deliberation, and justice, CSCW still lacks a comprehensive understanding of the experiences of religious minorities, particularly in relation to fear, as prominently evident in our study. Gaining faith-sensitive insights into the expression, participation, and inter-religious interactions on social media can contribute to CSCW's literature on online safety and interfaith communication. In pursuit of this goal, we conducted a six-month-long, interview-based study with the Hindu, Buddhist, and Indigenous communities in Bangladesh. Our study draws on an extensive body of research encompassing the spiral of silence, the cultural politics of fear, and communication accommodation to examine how social media use by religious minorities is influenced by fear, which is associated with social conformity, misinformation, stigma, stereotypes, and South Asian postcolonial memory. Moreover, we engage with scholarly perspectives from religious studies, justice, and South Asian violence and offer important critical insights and design lessons for the CSCW literature on public deliberation, justice, and interfaith communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15207v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3686926</arxiv:DOI>
      <arxiv:journal_reference>published by PACMHCI (CSCW2) 2024</arxiv:journal_reference>
      <dc:creator>Mohammad Rashidujjaman Rifat, Dipto Das, Arpon Podder, Mahiratul Jannat, Robert Soden, Bryan Semaan, Syed Ishtiaque Ahmed</dc:creator>
    </item>
    <item>
      <title>ArchiTone: A LEGO-Inspired Gamified System for Visualized Music Education</title>
      <link>https://arxiv.org/abs/2410.15273</link>
      <description>arXiv:2410.15273v1 Announce Type: new 
Abstract: Participation in music activities has many benefits, but often requires music theory knowledge and aural skills, which can be challenging for beginners. To help them engage more easily, it's crucial to adopt teaching strategies that lower these barriers. Informed by formative investigation and inspired by LEGO, we introduce ArchiTone, a gamified system that employs constructivism by visualizing music theory concepts as musical blocks and buildings for music education. This system includes two modes: Learning Mode, which involves recognizing and learning common musical blocks through familiar musical works; Creation Mode, which allows learners to freely create and combine musical blocks to produce new musical works. User studies demonstrate that our gamified system is not only more engaging than traditional music education methods but also more effective in helping learners understand abstract music theory and apply it to music praxis. Additionally, learners demonstrate superior performance on music theory tasks after using ArchiTone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15273v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaxing Yu, Tieyao Zhang, Songruoyao Wu, Xinda Wu, Tingxiao Wu, Yanjun Chen, Kejun Zhang</dc:creator>
    </item>
    <item>
      <title>MAD: Move AI Decompiler to Improve Transparency and Auditability on Non-Open-Source Blockchain Smart Contract</title>
      <link>https://arxiv.org/abs/2410.15275</link>
      <description>arXiv:2410.15275v1 Announce Type: new 
Abstract: Web3 aims to enhance user control over data and assets, but this vision is challenged by non-transparent, scam-prone applications and vulnerable smart contracts. While code audits are one solution to this problem, the lack of smart contracts source code on many blockchain platforms, such as Sui, hinders the ease of auditing. A promising approach to this issue is the use of a decompiler to reverse-engineer smart contract bytecode. However, existing decompilers for Sui produce code that is difficult to understand and cannot be directly recompiled. To address this, we developed the Move AI Decompiler (MAD), a Large Language Model (LLM)-powered web application that decompiles smart contract bytecodes on Sui into logically correct, human-readable, and re-compilable source code.
  Our evaluation shows that MAD produces logically correct code that successfully passes original unit tests and achieves a 66.7% recompilation success rate on real-world smart contracts. Additionally, in a user study involving 12 developers, MAD significantly reduced the auditing workload compared to using traditional decompilers. Participants found MAD's outputs comparable to the original source code, simplifying the process of smart contract logic comprehension and auditing. Despite some limitations, such as occasional hallucinations and compile errors, MAD still provides significant improvements over traditional decompilers.
  MAD has practical implications for blockchain smart contract transparency, auditing, and education. It empowers users to review and audit non-open-source smart contracts, fostering trust and accountability. Additionally, MAD's approach could potentially extend to other smart contract languages, like Solidity, promoting transparency across various blockchains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15275v1</guid>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eason Chen, Xinyi Tang, Zimo Xiao, Chuangji Li, Shizhuo Li, Wu Tingguan, Siyun Wang, Kostas Kryptos Chalkias</dc:creator>
    </item>
    <item>
      <title>Human-Data Interaction: Thinking beyond individual datasets</title>
      <link>https://arxiv.org/abs/2410.15427</link>
      <description>arXiv:2410.15427v1 Announce Type: new 
Abstract: Having greater access to data leads to many benefits, from advancing science to promoting accountability in government to boosting innovation. However, merely providing data access does not make data easy to use; even when data is openly available online, people may struggle to work with it. In this article, we draw on prior work, including our own, and a case study of Kaggle (a large online data science community) to discuss the importance of moving away from viewing datasets as static resources. Instead, we describe the view of data as a process with its own interactional affordances that offer many different possibilities for data, as well as for social interaction. We advocate for the notion of Human Data Interactions and their potential implications for various audiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15427v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Koesten, Jude Yew, Kathleen Gregory</dc:creator>
    </item>
    <item>
      <title>Evaluating Transferable Emotion Expressions for Zoomorphic Social Robots using VR Prototyping</title>
      <link>https://arxiv.org/abs/2410.15486</link>
      <description>arXiv:2410.15486v1 Announce Type: new 
Abstract: Zoomorphic robots have the potential to offer companionship and well-being as accessible, low-maintenance alternatives to pet ownership. Many such robots, however, feature limited emotional expression, restricting their potential for rich affective relationships with everyday domestic users. Additionally, exploring this design space using hardware prototyping is obstructed by physical and logistical constraints. We leveraged virtual reality rapid prototyping with passive haptic interaction to conduct a broad mixed-methods evaluation of emotion expression modalities and participatory prototyping of multimodal expressions. We found differences in recognisability, effectiveness and user empathy between modalities while highlighting the importance of facial expressions and the benefits of combining animal-like and unambiguous modalities. We use our findings to inform promising directions for the affective zoomorphic robot design and potential implementations via hardware modification or augmented reality, then discuss how VR prototyping makes this field more accessible to designers and researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15486v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shaun Macdonald, Robin Bretin, Salma ElSayed</dc:creator>
    </item>
    <item>
      <title>FlexDoc: Flexible Document Adaptation through Optimizing both Content and Layout</title>
      <link>https://arxiv.org/abs/2410.15504</link>
      <description>arXiv:2410.15504v1 Announce Type: new 
Abstract: Designing adaptive documents that are visually appealing across various devices and for diverse viewers is a challenging task. This is due to the wide variety of devices and different viewer requirements and preferences. Alterations to a document's content, style, or layout often necessitate numerous adjustments, potentially leading to a complete layout redesign. We introduce FlexDoc, a framework for creating and consuming documents that seamlessly adapt to different devices, author, and viewer preferences and interactions. It eliminates the need for manually creating multiple document layouts, as FlexDoc enables authors to define desired document properties using templates and employs both discrete and continuous optimization in a novel comprehensive optimization process, which leverages automatic text summarization and image carving techniques to adapt both layout and content during consumption dynamically. Furthermore, we demonstrate FlexDoc in multiple real-world application scenarios, such as news readers and academic papers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15504v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yue Jiang, Christof Lutteroth, Rajiv Jain, Christopher Tensmeyer, Varun Manjunatha, Wolfgang Stuerzlinger, Vlad Morariu</dc:creator>
    </item>
    <item>
      <title>Who Puts the "Social" in "Social Computing"?: Using A Neurodiversity Framing to Review Social Computing Research</title>
      <link>https://arxiv.org/abs/2410.15527</link>
      <description>arXiv:2410.15527v1 Announce Type: new 
Abstract: Human-Computer Interaction (HCI) and Computer Supported Collaborative Work (CSCW) have a longstanding tradition of interrogating the values that underlie systems in order to create novel and accessible experiences. In this work, we use a neurodiversity framing to examine how people with ways of thinking, speaking, and being that differ from normative assumptions are perceived by researchers seeking to study and design social computing systems for neurodivergent people. From a critical analysis of 84 publications systematically gathered across a decade of social computing research, we determine that research into social computing with neurodiverse participants is largely medicalized, adheres to historical stereotypes of neurodivergent children and their families, and is insensitive to the wide spectrum of neurodivergent people that are potential users of social technologies. When social computing systems designed for neurodivergent people rely upon a conception of disability that restricts expression for the sake of preserving existing norms surrounding social experience, the result is often simplistic and restrictive systems that prevent users from "being social" in a way that feels natural and enjoyable. We argue that a neurodiversity perspective informed by critical disability theory allows us to engage with alternative forms of sociality as meaningful and desirable rather than a deficit to be compensated for. We conclude by identifying opportunities for researchers to collaborate with neurodivergent users and their communities, including the creation of spectrum-conscious social systems and the embedding of double empathy into systems for more equitable design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15527v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Philip Baillargeon, Jina Yoon, Amy Zhang</dc:creator>
    </item>
    <item>
      <title>The effect of self-efficacy and pair programming experience in learning results of introductory programming courses</title>
      <link>https://arxiv.org/abs/2410.15558</link>
      <description>arXiv:2410.15558v1 Announce Type: new 
Abstract: The purpose of this study was to explore the interactive effect of self-efficacy and pair programming experience to the final learning results in introductory programming courses. We developed a 2x2 fractional design to explore their roles and relationships. Data was collected by distributing questionnaires to students have learnt or are learning CS367 at UW-Madison. They were asked to evaluate their self-efficacy levels and pair programming experience. After that, they needed to complete a quiz of 11 Java knowledge quiz indicating their learning results. We present results from 36 participants which show that students with high self-efficacy levels tended to earn a higher score in the Java knowledge quiz. However, pair programming experience shows no significant effects on learning results.Our finding suggests that high self-efficacy levels have a positive impact on students' performance in introductory programming courses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15558v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Mei, Heng Ping, Mingren Shen</dc:creator>
    </item>
    <item>
      <title>Enhancing Personalised Cybersecurity Guidance for Older Adults in Ireland</title>
      <link>https://arxiv.org/abs/2410.15775</link>
      <description>arXiv:2410.15775v1 Announce Type: new 
Abstract: The term `Digital Divide' emerged in the mid-1990s, highlighting the gap between those with access to emerging information technologies and those without. This gap persists for older adults even in the 21st century. To address this, our study focused on how older adults in Ireland can feel safer online. We conducted a two-phase study. In Phase I, 58 participants used Dot Voting to identify top cyber-security priorities, including password management, privacy, and avoiding scams. This informed Phase II, where we held focus groups with 31 participants from rural and urban communities in Ireland. Researchers provided tailored advice through presentations and leaflets, followed by open discussions. Our findings show that, despite being highly aware of cyber-scams, older adults remain very concerned about them. Participants expressed hesitation about using online password managers and two-factor authentication but valued advice on privacy and tools that can help them feel more in control online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15775v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Sheil, Jacob Camilleri, Moya Cronin, Melanie Gruben, Michelle O Keefe, Hazel Murray, Sanchari Das</dc:creator>
    </item>
    <item>
      <title>Virtual Reality Games: Extending Unity Learn Games to VR</title>
      <link>https://arxiv.org/abs/2410.16061</link>
      <description>arXiv:2410.16061v1 Announce Type: new 
Abstract: Research involving virtual reality (VR) has dramatically increased since the introduction of consumer VR systems. In turn, research on VR games has gained popularity within several fields. However, most VR games are closed source, which limits research opportunities. Some VR games are open source, but most of them are either very basic or too complex to be easily used in research. In this paper, we present two source-available VR games developed from freely available Unity Learn games: a kart racing game and a 3D adventure game. Our hope is that other researchers find them easy to use for VR studies, as Unity Technologies developed the games for beginners and has provided tutorials on using them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16061v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ryan P. McMahan, Nayan N. Chawla, Christian S. Cassell, Christopher Peerapon Lee</dc:creator>
    </item>
    <item>
      <title>Privacy as Social Norm: Systematically Reducing Dysfunctional Privacy Concerns on Social Media</title>
      <link>https://arxiv.org/abs/2410.16137</link>
      <description>arXiv:2410.16137v1 Announce Type: new 
Abstract: Privacy is essential to fully enjoying the benefits of social media. While fear around privacy risks can sometimes motivate privacy management, the negative impact of such fear, particularly when it is perceived as unaddressable (i.e., "dysfunctional" fear), can significantly harm teen well-being. In a co-design study with 136 participants aged 13-18, we explored how teens can protect their privacy without experiencing heightened fear. We identified seven different sources of dysfunctional fear, such as `fear of a hostile environment' and `fear of overstepping privacy norms.' We also evaluated ten designs, co-created with teen participants, that address these fears. Our findings suggest that social media platforms can mitigate dysfunctional fear without compromising privacy by creating a culture where privacy protection is the norm through default privacy-protective features. However, we also found that even the most effective privacy features are not likely to be adopted unless they balance the multifaceted and diverse needs of teens. Individual teens have different needs -- for example, public and private account users have different needs -- and teens often want to enjoy the benefits they get from slightly reducing privacy and widening their social reach. Given these considerations, augmenting default privacy features by allowing them to be toggled on and off will allow individual users to choose their own balance while still maintaining a privacy-focused norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16137v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>JaeWon Kim, Soobin Cho, Robert Wolfe, Jishnu Hari Nair, Alexis Hiniker</dc:creator>
    </item>
    <item>
      <title>Musinger: Communication of Music over a Distance with Wearable Haptic Display and Touch Sensitive Surface</title>
      <link>https://arxiv.org/abs/2410.16202</link>
      <description>arXiv:2410.16202v1 Announce Type: new 
Abstract: This study explores the integration of auditory and tactile experiences in musical haptics, focusing on enhancing sensory dimensions of music through touch. Addressing the gap in translating auditory signals to meaningful tactile feedback, our research introduces a novel method involving a touch-sensitive recorder and a wearable haptic display that captures musical interactions via force sensors and converts these into tactile sensations. Previous studies have shown the potential of haptic feedback to enhance musical expressivity, yet challenges remain in conveying complex musical nuances. Our method aims to expand music accessibility for individuals with hearing impairments and deepen digital musical interactions. Experimental results reveal high accuracy ($98\%$ without noise, 93% with white noise) in melody recognition through tactile feedback, demonstrating effective transmission and perception of musical information. The findings highlight the potential of haptic technology to bridge sensory gaps, offering significant implications for music therapy, education, and remote musical collaboration, advancing the field of musical haptics and multi-sensory technology applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16202v1</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Miguel Altamirano Cabrera, Muhammad Haris Khan, Ali Alabbas, Luis Moreno, Issatay Tokmurziyev, Dzmitry Tsetserukou</dc:creator>
    </item>
    <item>
      <title>Accounting for Sycophancy in Language Model Uncertainty Estimation</title>
      <link>https://arxiv.org/abs/2410.14746</link>
      <description>arXiv:2410.14746v1 Announce Type: cross 
Abstract: Effective human-machine collaboration requires machine learning models to externalize uncertainty, so users can reflect and intervene when necessary. For language models, these representations of uncertainty may be impacted by sycophancy bias: proclivity to agree with users, even if they are wrong. For instance, models may be over-confident in (incorrect) problem solutions suggested by a user. We study the relationship between sycophancy and uncertainty estimation for the first time. We propose a generalization of the definition of sycophancy bias to measure downstream impacts on uncertainty estimation, and also propose a new algorithm (SyRoUP) to account for sycophancy in the uncertainty estimation process. Unlike previous works on sycophancy, we study a broad array of user behaviors, varying both correctness and confidence of user suggestions to see how model answers (and their certainty) change. Our experiments across conversation forecasting and question-answering tasks show that user confidence plays a critical role in modulating the effects of sycophancy, and that SyRoUP can better predict these effects. From these results, we argue that externalizing both model and user uncertainty can help to mitigate the impacts of sycophancy bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14746v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Sicilia, Mert Inan, Malihe Alikhani</dc:creator>
    </item>
    <item>
      <title>Unlocking the Full Potential of High-Density Surface EMG: Novel Non-Invasive High-Yield Motor Unit Decomposition</title>
      <link>https://arxiv.org/abs/2410.14800</link>
      <description>arXiv:2410.14800v1 Announce Type: cross 
Abstract: The decomposition of high-density surface electromyography (HD-sEMG) signals into motor unit discharge patterns has become a powerful tool for investigating the neural control of movement, providing insights into motor neuron recruitment and discharge behavior. However, current algorithms, while very effective under certain conditions, face significant challenges in complex scenarios, as their accuracy and motor unit yield are highly dependent on anatomical differences among individuals. This can limit the number of decomposed motor units, particularly in challenging conditions. To address this issue, we recently introduced Swarm-Contrastive Decomposition (SCD), which dynamically adjusts the separation function based on the distribution of the data and prevents convergence to the same source. Initially applied to intramuscular EMG signals, SCD is here adapted for HD-sEMG signals. We demonstrated its ability to address key challenges faced by existing methods, particularly in identifying low-amplitude motor unit action potentials and effectively handling complex decomposition scenarios, like high-interference signals. We extensively validated SCD using simulated and experimental HD-sEMG recordings and compared it with current state-of-the-art decomposition methods under varying conditions, including different excitation levels, noise intensities, force profiles, sexes, and muscle groups. The proposed method consistently outperformed existing techniques in both the quantity of decoded motor units and the precision of their firing time identification. For instance, under certain experimental conditions, SCD detected more than three times as many motor units compared to previous methods, while also significantly improving accuracy. These advancements represent a major step forward in non-invasive EMG technology for studying motor unit activity in complex scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14800v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agnese Grison, Irene Mendez Guerra, Alexander Kenneth Clarke, Silvia Muceli, Jaime Ibanez Pereda, Dario Farina</dc:creator>
    </item>
    <item>
      <title>SPRIG: Improving Large Language Model Performance by System Prompt Optimization</title>
      <link>https://arxiv.org/abs/2410.14826</link>
      <description>arXiv:2410.14826v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have shown impressive capabilities in many scenarios, but their performance depends, in part, on the choice of prompt. Past research has focused on optimizing prompts specific to a task. However, much less attention has been given to optimizing the general instructions included in a prompt, known as a system prompt. To address this gap, we propose SPRIG, an edit-based genetic algorithm that iteratively constructs prompts from prespecified components to maximize the model's performance in general scenarios. We evaluate the performance of system prompts on a collection of 47 different types of tasks to ensure generalizability. Our study finds that a single optimized system prompt performs on par with task prompts optimized for each individual task. Moreover, combining system and task-level optimizations leads to further improvement, which showcases their complementary nature. Experiments also reveal that the optimized system prompts generalize effectively across model families, parameter sizes, and languages. This study provides insights into the role of system-level instructions in maximizing LLM potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14826v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lechen Zhang, Tolga Ergen, Lajanugen Logeswaran, Moontae Lee, David Jurgens</dc:creator>
    </item>
    <item>
      <title>GUIDE: Real-Time Human-Shaped Agents</title>
      <link>https://arxiv.org/abs/2410.15181</link>
      <description>arXiv:2410.15181v1 Announce Type: cross 
Abstract: The recent rapid advancement of machine learning has been driven by increasingly powerful models with the growing availability of training data and computational resources. However, real-time decision-making tasks with limited time and sparse learning signals remain challenging. One way of improving the learning speed and performance of these agents is to leverage human guidance. In this work, we introduce GUIDE, a framework for real-time human-guided reinforcement learning by enabling continuous human feedback and grounding such feedback into dense rewards to accelerate policy learning. Additionally, our method features a simulated feedback module that learns and replicates human feedback patterns in an online fashion, effectively reducing the need for human input while allowing continual training. We demonstrate the performance of our framework on challenging tasks with sparse rewards and visual observations. Our human study involving 50 subjects offers strong quantitative and qualitative evidence of the effectiveness of our approach. With only 10 minutes of human feedback, our algorithm achieves up to 30% increase in success rate compared to its RL baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15181v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingyu Zhang, Zhengran Ji, Nicholas R Waytowich, Boyuan Chen</dc:creator>
    </item>
    <item>
      <title>AI Can Enhance Creativity in Social Networks</title>
      <link>https://arxiv.org/abs/2410.15264</link>
      <description>arXiv:2410.15264v1 Announce Type: cross 
Abstract: Can peer recommendation engines elevate people's creative performances in self-organizing social networks? Answering this question requires resolving challenges in data collection (e.g., tracing inspiration links and psycho-social attributes of nodes) and intervention design (e.g., balancing idea stimulation and redundancy in evolving information environments). We trained a model that predicts people's ideation performances using semantic and network-structural features in an online platform. Using this model, we built SocialMuse, which maximizes people's predicted performances to generate peer recommendations for them. We found treatment networks leveraging SocialMuse outperforming AI-agnostic control networks in several creativity measures. The treatment networks were more decentralized than the control, as SocialMuse increasingly emphasized network-structural features at large network sizes. This decentralization spreads people's inspiration sources, helping inspired ideas stand out better. Our study provides actionable insights into building intelligent systems for elevating creativity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15264v1</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raiyan Abdul Baten, Ali Sarosh Bangash, Krish Veera, Gourab Ghoshal, Ehsan Hoque</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Autonomous Driving (LLM4AD): Concept, Benchmark, Simulation, and Real-Vehicle Experiment</title>
      <link>https://arxiv.org/abs/2410.15281</link>
      <description>arXiv:2410.15281v1 Announce Type: cross 
Abstract: With the broader usage and highly successful development of Large Language Models (LLMs), there has been a growth of interest and demand for applying LLMs to autonomous driving technology. Driven by their natural language understanding and reasoning ability, LLMs have the potential to enhance various aspects of autonomous driving systems, from perception and scene understanding to language interaction and decision-making. In this paper, we first introduce novel concepts and approaches to designing LLMs for autonomous driving (LLM4AD). Then, we propose a comprehensive benchmark for evaluating the instruction-following abilities of LLMs within the autonomous driving domain. Furthermore, we conduct a series of experiments on both simulation and real-world vehicle platforms, thoroughly evaluating the performance and potential of our LLM4AD systems. Our research highlights the significant potential of LLMs to enhance various aspects of autonomous vehicle technology, from perception and scene understanding to language interaction and decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15281v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Can Cui, Yunsheng Ma, Zichong Yang, Yupeng Zhou, Peiran Liu, Juanwu Lu, Lingxi Li, Yaobin Chen, Jitesh H. Panchal, Amr Abdelraouf, Rohit Gupta, Kyungtae Han, Ziran Wang</dc:creator>
    </item>
    <item>
      <title>Customized FinGPT Search Agents Using Foundation Models</title>
      <link>https://arxiv.org/abs/2410.15284</link>
      <description>arXiv:2410.15284v1 Announce Type: cross 
Abstract: Current large language models (LLMs) have proven useful for analyzing financial data, but most existing models, such as BloombergGPT and FinGPT, lack customization for specific user needs. In this paper, we address this gap by developing FinGPT Search Agents tailored for two types of users: individuals and institutions. For individuals, we leverage Retrieval-Augmented Generation (RAG) to integrate local documents and user-specified data sources. For institutions, we employ dynamic vector databases and fine-tune models on proprietary data. There are several key issues to address, including data privacy, the time-sensitive nature of financial information, and the need for fast responses. Experiments show that FinGPT agents outperform existing models in accuracy, relevance, and response time, making them practical for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15284v1</guid>
      <category>cs.CE</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3677052.3698637</arxiv:DOI>
      <arxiv:journal_reference>5th ACM International Conference on AI in Finance, 2024</arxiv:journal_reference>
      <dc:creator>Felix Tian, Ajay Byadgi, Daniel Kim, Daochen Zha, Matt White, Kairong Xiao, Xiao-Yang Liu Yanglet</dc:creator>
    </item>
    <item>
      <title>Hey GPT, Can You be More Racist? Analysis from Crowdsourced Attempts to Elicit Biased Content from Generative AI</title>
      <link>https://arxiv.org/abs/2410.15467</link>
      <description>arXiv:2410.15467v1 Announce Type: cross 
Abstract: The widespread adoption of large language models (LLMs) and generative AI (GenAI) tools across diverse applications has amplified the importance of addressing societal biases inherent within these technologies. While the NLP community has extensively studied LLM bias, research investigating how non-expert users perceive and interact with biases from these systems remains limited. As these technologies become increasingly prevalent, understanding this question is crucial to inform model developers in their efforts to mitigate bias. To address this gap, this work presents the findings from a university-level competition, which challenged participants to design prompts for eliciting biased outputs from GenAI tools. We quantitatively and qualitatively analyze the competition submissions and identify a diverse set of biases in GenAI and strategies employed by participants to induce bias in GenAI. Our finding provides unique insights into how non-expert users perceive and interact with biases from GenAI tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15467v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hangzhi Guo, Pranav Narayanan Venkit, Eunchae Jang, Mukund Srinath, Wenbo Zhang, Bonam Mingole, Vipul Gupta, Kush R. Varshney, S. Shyam Sundar, Amulya Yadav</dc:creator>
    </item>
    <item>
      <title>Learning to Generate and Evaluate Fact-checking Explanations with Transformers</title>
      <link>https://arxiv.org/abs/2410.15669</link>
      <description>arXiv:2410.15669v1 Announce Type: cross 
Abstract: In an era increasingly dominated by digital platforms, the spread of misinformation poses a significant challenge, highlighting the need for solutions capable of assessing information veracity. Our research contributes to the field of Explainable Artificial Antelligence (XAI) by developing transformer-based fact-checking models that contextualise and justify their decisions by generating human-accessible explanations. Importantly, we also develop models for automatic evaluation of explanations for fact-checking verdicts across different dimensions such as \texttt{(self)-contradiction}, \texttt{hallucination}, \texttt{convincingness} and \texttt{overall quality}. By introducing human-centred evaluation methods and developing specialised datasets, we emphasise the need for aligning Artificial Intelligence (AI)-generated explanations with human judgements. This approach not only advances theoretical knowledge in XAI but also holds practical implications by enhancing the transparency, reliability and users' trust in AI-driven fact-checking systems. Furthermore, the development of our metric learning models is a first step towards potentially increasing efficiency and reducing reliance on extensive manual assessment. Based on experimental results, our best performing generative model \textsc{ROUGE-1} score of 47.77, demonstrating superior performance in generating fact-checking explanations, particularly when provided with high-quality evidence. Additionally, the best performing metric learning model showed a moderately strong correlation with human judgements on objective dimensions such as \texttt{(self)-contradiction and \texttt{hallucination}, achieving a Matthews Correlation Coefficient (MCC) of around 0.7.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15669v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Darius Feher, Abdullah Khered, Hao Zhang, Riza Batista-Navarro, Viktor Schlegel</dc:creator>
    </item>
    <item>
      <title>MIK: Modified Isolation Kernel for Biological Sequence Visualization, Classification, and Clustering</title>
      <link>https://arxiv.org/abs/2410.15688</link>
      <description>arXiv:2410.15688v1 Announce Type: cross 
Abstract: The t-Distributed Stochastic Neighbor Embedding (t-SNE) has emerged as a popular dimensionality reduction technique for visualizing high-dimensional data. It computes pairwise similarities between data points by default using an RBF kernel and random initialization (in low-dimensional space), which successfully captures the overall structure but may struggle to preserve the local structure efficiently. This research proposes a novel approach called the Modified Isolation Kernel (MIK) as an alternative to the Gaussian kernel, which is built upon the concept of the Isolation Kernel. MIK uses adaptive density estimation to capture local structures more accurately and integrates robustness measures. It also assigns higher similarity values to nearby points and lower values to distant points. Comparative research using the normal Gaussian kernel, the isolation kernel, and several initialization techniques, including random, PCA, and random walk initializations, are used to assess the proposed approach (MIK). Additionally, we compare the computational efficiency of all $3$ kernels with $3$ different initialization methods. Our experimental results demonstrate several advantages of the proposed kernel (MIK) and initialization method selection. It exhibits improved preservation of the local and global structure and enables better visualization of clusters and subclusters in the embedded space. These findings contribute to advancing dimensionality reduction techniques and provide researchers and practitioners with an effective tool for data exploration, visualization, and analysis in various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15688v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sarwan Ali, Prakash Chourasia, Haris Mansoor, Bipin koirala, Murray Patterson</dc:creator>
    </item>
    <item>
      <title>Two-stage Learning-to-Defer for Multi-Task Learning</title>
      <link>https://arxiv.org/abs/2410.15729</link>
      <description>arXiv:2410.15729v1 Announce Type: cross 
Abstract: The Learning-to-Defer approach has been explored for classification and, more recently, regression tasks separately. Many contemporary learning tasks, however, involves both classification and regression components. In this paper, we introduce a Learning-to-Defer approach for multi-task learning that encompasses both classification and regression tasks. Our two-stage approach utilizes a rejector that defers decisions to the most accurate agent among a pre-trained joint classifier-regressor models and one or more external experts. We show that our surrogate loss is $(\mathcal{H}, \mathcal{F}, \mathcal{R})$ and Bayes--consistent, ensuring an effective approximation of the optimal solution. Additionally, we derive learning bounds that demonstrate the benefits of employing multiple confident experts along a rich model in a two-stage learning framework. Empirical experiments conducted on electronic health record analysis tasks underscore the performance enhancements achieved through our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15729v1</guid>
      <category>stat.ML</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Montreuil Yannis, Yeo Shu Heng, Carlier Axel, Ng Lai Xing, Ooi Wei Tsang</dc:creator>
    </item>
    <item>
      <title>R2I-rPPG: A Robust Region of Interest Selection Method for Remote Photoplethysmography to Extract Heart Rate</title>
      <link>https://arxiv.org/abs/2410.15851</link>
      <description>arXiv:2410.15851v1 Announce Type: cross 
Abstract: The COVID-19 pandemic has underscored the need for low-cost, scalable approaches to measuring contactless vital signs, either during initial triage at a healthcare facility or virtual telemedicine visits. Remote photoplethysmography (rPPG) can accurately estimate heart rate (HR) when applied to close-up videos of healthy volunteers in well-lit laboratory settings. However, results from such highly optimized laboratory studies may not be readily translated to healthcare settings. One significant barrier to the practical application of rPPG in health care is the accurate localization of the region of interest (ROI). Clinical or telemedicine visits may involve sub-optimal lighting, movement artifacts, variable camera angle, and subject distance. This paper presents an rPPG ROI selection method based on 3D facial landmarks and patient head yaw angle. We then demonstrate the robustness of this ROI selection method when coupled to the Plane-Orthogonal-to-Skin (POS) rPPG method when applied to videos of patients presenting to an Emergency Department for respiratory complaints. Our results demonstrate the effectiveness of our proposed approach in improving the accuracy and robustness of rPPG in a challenging clinical environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15851v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sandeep Nagar, Mark Hasegawa-Johnson, David G. Beiser, Narendra Ahuja</dc:creator>
    </item>
    <item>
      <title>Yeah, Un, Oh: Continuous and Real-time Backchannel Prediction with Fine-tuning of Voice Activity Projection</title>
      <link>https://arxiv.org/abs/2410.15929</link>
      <description>arXiv:2410.15929v1 Announce Type: cross 
Abstract: In human conversations, short backchannel utterances such as "yeah" and "oh" play a crucial role in facilitating smooth and engaging dialogue. These backchannels signal attentiveness and understanding without interrupting the speaker, making their accurate prediction essential for creating more natural conversational agents. This paper proposes a novel method for real-time, continuous backchannel prediction using a fine-tuned Voice Activity Projection (VAP) model. While existing approaches have relied on turn-based or artificially balanced datasets, our approach predicts both the timing and type of backchannels in a continuous and frame-wise manner on unbalanced, real-world datasets. We first pre-train the VAP model on a general dialogue corpus to capture conversational dynamics and then fine-tune it on a specialized dataset focused on backchannel behavior. Experimental results demonstrate that our model outperforms baseline methods in both timing and type prediction tasks, achieving robust performance in real-time environments. This research offers a promising step toward more responsive and human-like dialogue systems, with implications for interactive spoken dialogue applications such as virtual assistants and robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15929v1</guid>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koji Inoue, Divesh Lala, Gabriel Skantze, Tatsuya Kawahara</dc:creator>
    </item>
    <item>
      <title>CiteClick: A Browser Extension for Real-Time Scholar Citation Tracking</title>
      <link>https://arxiv.org/abs/2410.16211</link>
      <description>arXiv:2410.16211v1 Announce Type: cross 
Abstract: This technical report presents CiteClick, a browser extension designed to monitor and track Google Scholar citation counts for multiple researchers in real-time. We discuss the motivation behind the tool, its key features, implementation details, and potential impact on the academic community. The report covers installation procedures, usage guidelines, and customization options, concluding with a discussion on future work and potential improvements. By automating the process of citation tracking, CiteClick aims to enhance research evaluation processes and facilitate more informed decision-making in academic contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16211v1</guid>
      <category>cs.DL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nishat Raihan</dc:creator>
    </item>
    <item>
      <title>Inspo: Writing with Crowds Alongside AI</title>
      <link>https://arxiv.org/abs/2311.16521</link>
      <description>arXiv:2311.16521v3 Announce Type: replace 
Abstract: The use of artificial intelligence (AI) to support creative writing has bloomed in recent years. However, it is less well understood how AI compares to on-demand human support. We explored how writers interact with both AI and crowd worker writing assistants in creative writing. We replicated the interface of the prior crowd-writing system, Heteroglossia, and developed Inspo, a text editor allowing users to request suggestions from AI models and crowd workers. In a one-week deployment study involving eight creative writers, we examined how often participants selected crowd workers when fluent AI text generators were also available. Findings showed a consistent decline in crowd worker usage, with participants favoring AI due to its faster responses and more consistent quality. We conclude with suggestions for future systems, recommending designs that account for the unique strengths and weaknesses of human versus AI assistants, strategies to address automation bias, and sociocultural views of writing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16521v3</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chieh-Yang Huang, Sanjana Gautam, Shannon McClellan Brooks, Ya-Fang Lin, Tiffany Knearem, Ting-Hao 'Kenneth' Huang</dc:creator>
    </item>
    <item>
      <title>Benchmarking Mobile Device Control Agents across Diverse Configurations</title>
      <link>https://arxiv.org/abs/2404.16660</link>
      <description>arXiv:2404.16660v2 Announce Type: replace 
Abstract: Mobile device control agents can largely enhance user interactions and productivity by automating daily tasks. However, despite growing interest in developing practical agents, the absence of a commonly adopted benchmark in this area makes it challenging to quantify scientific progress. In this work, we introduce B-MoCA: a novel benchmark with interactive environments for evaluating and developing mobile device control agents. To create a realistic benchmark, we develop B-MoCA based on the Android operating system and define 131 common daily tasks. Importantly, we incorporate a randomization feature that changes the configurations of mobile devices, including user interface layouts and language settings, to assess generalization performance. We benchmark diverse agents, including agents employing large language models (LLMs) or multi-modal LLMs as well as agents trained with imitation learning using human expert demonstrations. While these agents demonstrate proficiency in executing straightforward tasks, their poor performance on complex tasks highlights significant opportunities for future research to improve effectiveness. Our source code is publicly available at https://b-moca.github.io.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16660v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juyong Lee, Taywon Min, Minyong An, Dongyoon Hahm, Haeone Lee, Changyeon Kim, Kimin Lee</dc:creator>
    </item>
    <item>
      <title>AgentClinic: a multimodal agent benchmark to evaluate AI in simulated clinical environments</title>
      <link>https://arxiv.org/abs/2405.07960</link>
      <description>arXiv:2405.07960v4 Announce Type: replace 
Abstract: Evaluating large language models (LLM) in clinical scenarios is crucial to assessing their potential clinical utility. Existing benchmarks rely heavily on static question-answering, which does not accurately depict the complex, sequential nature of clinical decision-making. Here, we introduce AgentClinic, a multimodal agent benchmark for evaluating LLMs in simulated clinical environments that include patient interactions, multimodal data collection under incomplete information, and the usage of various tools, resulting in an in-depth evaluation across nine medical specialties and seven languages. We find that solving MedQA problems in the sequential decision-making format of AgentClinic is considerably more challenging, resulting in diagnostic accuracies that can drop to below a tenth of the original accuracy. Overall, we observe that agents sourced from Claude-3.5 outperform other LLM backbones in most settings. Nevertheless, we see stark differences in the LLMs' ability to make use of tools, such as experiential learning, adaptive retrieval, and reflection cycles. Strikingly, Llama-3 shows up to 92% relative improvements with the notebook tool that allows for writing and editing notes that persist across cases. To further scrutinize our clinical simulations, we leverage real-world electronic health records, perform a clinical reader study, perturb agents with biases, and explore novel patient-centric metrics that this interactive environment firstly enables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07960v4</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Schmidgall, Rojin Ziaei, Carl Harris, Eduardo Reis, Jeffrey Jopling, Michael Moor</dc:creator>
    </item>
    <item>
      <title>DracoGPT: Extracting Visualization Design Preferences from Large Language Models</title>
      <link>https://arxiv.org/abs/2408.06845</link>
      <description>arXiv:2408.06845v2 Announce Type: replace 
Abstract: Trained on vast corpora, Large Language Models (LLMs) have the potential to encode visualization design knowledge and best practices. However, if they fail to do so, they might provide unreliable visualization recommendations. What visualization design preferences, then, have LLMs learned? We contribute DracoGPT, a method for extracting, modeling, and assessing visualization design preferences from LLMs. To assess varied tasks, we develop two pipelines--DracoGPT-Rank and DracoGPT-Recommend--to model LLMs prompted to either rank or recommend visual encoding specifications. We use Draco as a shared knowledge base in which to represent LLM design preferences and compare them to best practices from empirical research. We demonstrate that DracoGPT can accurately model the preferences expressed by LLMs, enabling analysis in terms of Draco design constraints. Across a suite of backing LLMs, we find that DracoGPT-Rank and DracoGPT-Recommend moderately agree with each other, but both substantially diverge from guidelines drawn from human subjects experiments. Future work can build on our approach to expand Draco's knowledge base to model a richer set of preferences and to provide a robust and cost-effective stand-in for LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06845v2</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huichen Will Wang, Mitchell Gordon, Leilani Battle, Jeffrey Heer</dc:creator>
    </item>
    <item>
      <title>Secret Use of Large Language Model (LLM)</title>
      <link>https://arxiv.org/abs/2409.19450</link>
      <description>arXiv:2409.19450v2 Announce Type: replace 
Abstract: The advancements of Large Language Models (LLMs) have decentralized the responsibility for the transparency of AI usage. Specifically, LLM users are now encouraged or required to disclose the use of LLM-generated content for varied types of real-world tasks. However, an emerging phenomenon, users' secret use of LLM, raises challenges in ensuring end users adhere to the transparency requirement. Our study used mixed-methods with an exploratory survey (125 real-world secret use cases reported) and a controlled experiment among 300 users to investigate the contexts and causes behind the secret use of LLMs. We found that such secretive behavior is often triggered by certain tasks, transcending demographic and personality differences among users. Task types were found to affect users' intentions to use secretive behavior, primarily through influencing perceived external judgment regarding LLM usage. Our results yield important insights for future work on designing interventions to encourage more transparent disclosure of the use of LLMs or other AI technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19450v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiping Zhang, Chenxinran Shen, Bingsheng Yao, Dakuo Wang, Tianshi Li</dc:creator>
    </item>
    <item>
      <title>TR-LLM: Integrating Trajectory Data for Scene-Aware LLM-Based Human Action Prediction</title>
      <link>https://arxiv.org/abs/2410.03993</link>
      <description>arXiv:2410.03993v2 Announce Type: replace 
Abstract: Accurate prediction of human behavior is crucial for AI systems to effectively support real-world applications, such as autonomous robots anticipating and assisting with human tasks. Real-world scenarios frequently present challenges such as occlusions and incomplete scene observations, which can compromise predictive accuracy. Thus, traditional video-based methods often struggle due to limited temporal and spatial perspectives. Large Language Models (LLMs) offer a promising alternative. Having been trained on a large text corpus describing human behaviors, LLMs likely encode plausible sequences of human actions in a home environment. However, LLMs, trained primarily on text data, lack inherent spatial awareness and real-time environmental perception. They struggle with understanding physical constraints and spatial geometry. Therefore, to be effective in a real-world spatial scenario, we propose a multimodal prediction framework that enhances LLM-based action prediction by integrating physical constraints derived from human trajectories. Our experiments demonstrate that combining LLM predictions with trajectory data significantly improves overall prediction performance. This enhancement is particularly notable in situations where the LLM receives limited scene information, highlighting the complementary nature of linguistic knowledge and physical constraints in understanding and anticipating human behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03993v2</guid>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kojiro Takeyama, Yimeng Liu, Misha Sra</dc:creator>
    </item>
    <item>
      <title>Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting</title>
      <link>https://arxiv.org/abs/2410.12284</link>
      <description>arXiv:2410.12284v2 Announce Type: replace 
Abstract: The growing capabilities of AI models are leading to their wider use, including in safety-critical domains. Explainable AI (XAI) aims to make these models safer to use by making their inference process more transparent. However, current explainability methods are seldom evaluated in the way they are intended to be used: by real-world end users. To address this, we conducted a large-scale user study with 85 healthcare practitioners in the context of human-AI collaborative chest X-ray analysis. We evaluated three types of explanations: visual explanations (saliency maps), natural language explanations, and a combination of both modalities. We specifically examined how different explanation types influence users depending on whether the AI advice and explanations are factually correct. We find that text-based explanations lead to significant over-reliance, which is alleviated by combining them with saliency maps. We also observe that the quality of explanations, that is, how much factually correct information they entail, and how much this aligns with AI correctness, significantly impacts the usefulness of the different explanation types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12284v2</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxime Kayser, Bayar Menzat, Cornelius Emde, Bogdan Bercean, Alex Novak, Abdala Espinosa, Bartlomiej W. Papiez, Susanne Gaube, Thomas Lukasiewicz, Oana-Maria Camburu</dc:creator>
    </item>
    <item>
      <title>MindArm: Mechanized Intelligent Non-Invasive Neuro-Driven Prosthetic Arm System</title>
      <link>https://arxiv.org/abs/2403.19992</link>
      <description>arXiv:2403.19992v2 Announce Type: replace-cross 
Abstract: Currently, individuals with arm mobility impairments (referred to as "patients") face limited technological solutions due to two key challenges: (1) non-invasive prosthetic devices are often prohibitively expensive and costly to maintain, and (2) invasive solutions require high-risk, costly brain surgery, which can pose a health risk. Therefore, current technological solutions are not accessible for all patients with different financial backgrounds. Toward this, we propose a low-cost technological solution called MindArm, an affordable, non-invasive neuro-driven prosthetic arm system. MindArm employs a deep neural network (DNN) to translate brain signals, captured by low-cost surface electroencephalogram (EEG) electrodes, into prosthetic arm movements. Utilizing an Open Brain Computer Interface and UDP networking for signal processing, the system seamlessly controls arm motion. In the compute module, we run a trained DNN model to interpret filtered micro-voltage brain signals, and then translate them into a prosthetic arm action via serial communication seamlessly. Experimental results from a fully functional prototype show high accuracy across three actions, with 91% for idle/stationary, 85% for handshake, and 84% for cup pickup. The system costs approximately $500-550, including $400 for the EEG headset and $100-150 for motors, 3D printing, and assembly, offering an affordable alternative for mind-controlled prosthetic devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19992v2</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maha Nawaz, Abdul Basit, Muhammad Shafique</dc:creator>
    </item>
    <item>
      <title>Human-Agent Joint Learning for Efficient Robot Manipulation Skill Acquisition</title>
      <link>https://arxiv.org/abs/2407.00299</link>
      <description>arXiv:2407.00299v4 Announce Type: replace-cross 
Abstract: Employing a teleoperation system for gathering demonstrations offers the potential for more efficient learning of robot manipulation. However, teleoperating a robot arm equipped with a dexterous hand or gripper, via a teleoperation system presents inherent challenges due to the task's high dimensionality, complexity of motion, and differences between physiological structures. In this study, we introduce a novel system for joint learning between human operators and robots, that enables human operators to share control of a robot end-effector with a learned assistive agent, simplifies the data collection process, and facilitates simultaneous human demonstration collection and robot manipulation training. As data accumulates, the assistive agent gradually learns. Consequently, less human effort and attention are required, enhancing the efficiency of the data collection process. It also allows the human operator to adjust the control ratio to achieve a trade-off between manual and automated control. We conducted experiments in both simulated environments and physical real-world settings. Through user studies and quantitative evaluations, it is evident that the proposed system could enhance data collection efficiency and reduce the need for human adaptation while ensuring the collected data is of sufficient quality for downstream tasks. \textit{For more details, please refer to our webpage https://norweig1an.github.io/HAJL.github.io/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00299v4</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengcheng Luo, Quanquan Peng, Jun Lv, Kaiwen Hong, Katherine Rose Driggs-Campbell, Cewu Lu, Yong-Lu Li</dc:creator>
    </item>
    <item>
      <title>Human and LLM Biases in Hate Speech Annotations: A Socio-Demographic Analysis of Annotators and Targets</title>
      <link>https://arxiv.org/abs/2410.07991</link>
      <description>arXiv:2410.07991v3 Announce Type: replace-cross 
Abstract: The rise of online platforms exacerbated the spread of hate speech, demanding scalable and effective detection. However, the accuracy of hate speech detection systems heavily relies on human-labeled data, which is inherently susceptible to biases. While previous work has examined the issue, the interplay between the characteristics of the annotator and those of the target of the hate are still unexplored. We fill this gap by leveraging an extensive dataset with rich socio-demographic information of both annotators and targets, uncovering how human biases manifest in relation to the target's attributes. Our analysis surfaces the presence of widespread biases, which we quantitatively describe and characterize based on their intensity and prevalence, revealing marked differences. Furthermore, we compare human biases with those exhibited by persona-based LLMs. Our findings indicate that while persona-based LLMs do exhibit biases, these differ significantly from those of human annotators. Overall, our work offers new and nuanced results on human biases in hate speech annotations, as well as fresh insights into the design of AI-driven hate speech detection systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07991v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Giorgi, Lorenzo Cima, Tiziano Fagni, Marco Avvenuti, Stefano Cresci</dc:creator>
    </item>
  </channel>
</rss>
