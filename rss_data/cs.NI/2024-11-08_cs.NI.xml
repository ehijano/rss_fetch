<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A New Variant of Benes Network: Its Topological Characterisation and Comparative Analysis</title>
      <link>https://arxiv.org/abs/2411.04135</link>
      <description>arXiv:2411.04135v1 Announce Type: new 
Abstract: The modern era always looks into advancements in technology. Design and topology of interconnection networks play a mutual role in development of technology. Analysing the topological properties and characteristics of an interconnection network is not an easy task. Graph theory helps in solving this task analytically and efficiently through the use of numerical parameters known as distance based topological descriptors. These descriptors have considerable applications in various fields of computer science, chemistry, biology, etc. This paper deals with the evaluation of topological descriptors for an n-dimensional multistage interconnection network, the benes network,BB(n). Also, a new variant of interconnection network is derived from the benes network, named as augmented benes network and denoted as BB^* (n). The topological descriptors for the benes derived network are also determined in this work. Further, the benes network and augmented benes network undergoes a comparative analysis based on few network parameters, which helps to understand the efficiency of newly derived benes network. A broadcasting algorithm for the augmented benes network is also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04135v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parvez Ali, Annmaria Baby, D. Antony Xavier, Eddith Sarah Varghese, Theertha Nair A., Haidar Ali</dc:creator>
    </item>
    <item>
      <title>Large Language Models (LLMs) for Wireless Networks: An Overview from the Prompt Engineering Perspective</title>
      <link>https://arxiv.org/abs/2411.04136</link>
      <description>arXiv:2411.04136v1 Announce Type: new 
Abstract: Recently, large language models (LLMs) have been successfully applied to many fields, showing outstanding comprehension and reasoning capabilities. Despite their great potential, LLMs usually require dedicated pre-training and fine-tuning for domain-specific applications such as wireless networks. These adaptations can be extremely demanding for computational resources and datasets, while most network devices have limited computation power, and there are a limited number of high-quality networking datasets. To this end, this work explores LLM-enabled wireless networks from the prompt engineering perspective, i.e., designing prompts to guide LLMs to generate desired output without updating LLM parameters. Compared with other LLM-driven methods, prompt engineering can better align with the demands of wireless network devices, e.g., higher deployment flexibility, rapid response time, and lower requirements on computation power. In particular, this work first introduces LLM fundamentals and compares different prompting techniques such as in-context learning, chain-of-thought, and self-refinement. Then we propose two novel prompting schemes for network applications: iterative prompting for network optimization, and self-refined prompting for network prediction. The case studies show that the proposed schemes can achieve comparable performance as conventional machine learning techniques, and our proposed prompting-based methods avoid the complexity of dedicated model training and fine-tuning, which is one of the key bottlenecks of existing machine learning techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04136v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hao Zhou, Chengming Hu, Dun Yuan, Ye Yuan, Di Wu, Xi Chen, Hina Tabassum, Xue Liu</dc:creator>
    </item>
    <item>
      <title>Generative AI Enabled Matching for 6G Multiple Access</title>
      <link>https://arxiv.org/abs/2411.04137</link>
      <description>arXiv:2411.04137v1 Announce Type: new 
Abstract: In wireless networks, applying deep learning models to solve matching problems between different entities has become a mainstream and effective approach. However, the complex network topology in 6G multiple access presents significant challenges for the real-time performance and stability of matching generation. Generative artificial intelligence (GenAI) has demonstrated strong capabilities in graph feature extraction, exploration, and generation, offering potential for graph-structured matching generation. In this paper, we propose a GenAI-enabled matching generation framework to support 6G multiple access. Specifically, we first summarize the classical matching theory, discuss common GenAI models and applications from the perspective of matching generation. Then, we propose a framework based on generative diffusion models (GDMs) that iteratively denoises toward reward maximization to generate a matching strategy that meets specific requirements. Experimental results show that, compared to decision-based AI approaches, our framework can generate more effective matching strategies based on given conditions and predefined rewards, helping to solve complex problems in 6G multiple access, such as task allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04137v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xudong Wang, Hongyang Du, Dusit Niyato, Lijie Zhou, Lei Feng, Zhixiang Yang, Fanqin Zhou, Wenjing Li</dc:creator>
    </item>
    <item>
      <title>NetworkGym: Reinforcement Learning Environments for Multi-Access Traffic Management in Network Simulation</title>
      <link>https://arxiv.org/abs/2411.04138</link>
      <description>arXiv:2411.04138v1 Announce Type: new 
Abstract: Mobile devices such as smartphones, laptops, and tablets can often connect to multiple access networks (e.g., Wi-Fi, LTE, and 5G) simultaneously. Recent advancements facilitate seamless integration of these connections below the transport layer, enhancing the experience for apps that lack inherent multi-path support. This optimization hinges on dynamically determining the traffic distribution across networks for each device, a process referred to as \textit{multi-access traffic splitting}. This paper introduces \textit{NetworkGym}, a high-fidelity network environment simulator that facilitates generating multiple network traffic flows and multi-access traffic splitting. This simulator facilitates training and evaluating different RL-based solutions for the multi-access traffic splitting problem. Our initial explorations demonstrate that the majority of existing state-of-the-art offline RL algorithms (e.g. CQL) fail to outperform certain hand-crafted heuristic policies on average. This illustrates the urgent need to evaluate offline RL algorithms against a broader range of benchmarks, rather than relying solely on popular ones such as D4RL. We also propose an extension to the TD3+BC algorithm, named Pessimistic TD3 (PTD3), and demonstrate that it outperforms many state-of-the-art offline RL algorithms. PTD3's behavioral constraint mechanism, which relies on value-function pessimism, is theoretically motivated and relatively simple to implement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04138v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Momin Haider, Ming Yin, Menglei Zhang, Arpit Gupta, Jing Zhu, Yu-Xiang Wang</dc:creator>
    </item>
    <item>
      <title>Diffusion-based Auction Mechanism for Efficient Resource Management in 6G-enabled Vehicular Metaverses</title>
      <link>https://arxiv.org/abs/2411.04139</link>
      <description>arXiv:2411.04139v1 Announce Type: new 
Abstract: The rise of 6G-enable Vehicular Metaverses is transforming the automotive industry by integrating immersive, real-time vehicular services through ultra-low latency and high bandwidth connectivity. In 6G-enable Vehicular Metaverses, vehicles are represented by Vehicle Twins (VTs), which serve as digital replicas of physical vehicles to support real-time vehicular applications such as large Artificial Intelligence (AI) model-based Augmented Reality (AR) navigation, called VT tasks. VT tasks are resource-intensive and need to be offloaded to ground Base Stations (BSs) for fast processing. However, high demand for VT tasks and limited resources of ground BSs, pose significant resource allocation challenges, particularly in densely populated urban areas like intersections. As a promising solution, Unmanned Aerial Vehicles (UAVs) act as aerial edge servers to dynamically assist ground BSs in handling VT tasks, relieving resource pressure on ground BSs. However, due to high mobility of UAVs, there exists information asymmetry regarding VT task demands between UAVs and ground BSs, resulting in inefficient resource allocation of UAVs. To address these challenges, we propose a learning-based Modified Second-Bid (MSB) auction mechanism to optimize resource allocation between ground BSs and UAVs by accounting for VT task latency and accuracy. Moreover, we design a diffusion-based reinforcement learning algorithm to optimize the price scaling factor, maximizing the total surplus of resource providers and minimizing VT task latency. Finally, simulation results demonstrate that the proposed diffusion-based MSB auction outperforms traditional baselines, providing better resource distribution and enhanced service quality for vehicular users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04139v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawen Kang, Yongju Tong, Yue Zhong, Junlong Chen, Minrui Xu, Dusit Niyato, Runrong Deng, Shiwen Mao</dc:creator>
    </item>
    <item>
      <title>Cooperation and Personalization on a Seesaw: Choice-based FL for Safe Cooperation in Wireless Networks</title>
      <link>https://arxiv.org/abs/2411.04159</link>
      <description>arXiv:2411.04159v1 Announce Type: new 
Abstract: Federated learning (FL) is an innovative distributed artificial intelligence (AI) technique. It has been used for interdisciplinary studies in different fields such as healthcare, marketing and finance. However the application of FL in wireless networks is still in its infancy. In this work, we first overview benefits and concerns when applying FL to wireless networks. Next, we provide a new perspective on existing personalized FL frameworks by analyzing the relationship between cooperation and personalization in these frameworks. Additionally, we discuss the possibility of tuning the cooperation level with a choice-based approach. Our choice-based FL approach is a flexible and safe FL framework that allows participants to lower the level of cooperation when they feel unsafe or unable to benefit from the cooperation. In this way, the choice-based FL framework aims to address the safety and fairness concerns in FL and protect participants from malicious attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04159v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Zhang, Medhat Elsayed, Majid Bavand, Raimundas Gaigalas, Yigit Ozcan, Melike Erol-Kantarci</dc:creator>
    </item>
    <item>
      <title>Topology Bench: Systematic Graph Based Benchmarking for Core Optical Networks</title>
      <link>https://arxiv.org/abs/2411.04160</link>
      <description>arXiv:2411.04160v1 Announce Type: new 
Abstract: Topology Bench is a comprehensive topology dataset designed to accelerate benchmarking studies in optical networks. The dataset, focusing on core optical networks, comprises publicly accessible and ready-to-use topologies, including (a) 105 georeferenced real-world optical networks and (b) 270,900 validated synthetic topologies. Prior research on real-world core optical networks has been characterised by fragmented open data sources and disparate individual studies. Moreover, previous efforts have notably failed to provide synthetic data at a scale comparable to our present study. Topology Bench addresses this limitation, offering a unified resource and represents a 61.5% increase in spatially-referenced real world optical networks. To benchmark and identify the fundamental nature of optical network topologies through the lens of graph-theoretical analysis, we analyse both real and synthetic networks using structural, spatial and spectral metrics. Our comparative analysis identifies constraints in real optical network diversity and illustrates how synthetic networks can complement and expand the range of topologies available for use. Currently, topologies are selected based on subjective criteria, such as preference, data availability, or perceived suitability, leading to potential biases and limited representativeness. Our framework enhances the generalisability of optical network research by providing a more objective and systematic approach to topology selection. A statistical and correlation analysis reveals the quantitative range of all of these graph metrics and the relationships between them. Finally, we apply unsupervised machine learning to cluster real-world topologies into distinctive groups using nine optimal graph metrics using K-means. We conclude the analysis by providing guidance on how to use such clusters to select a diverse set of topologies for future studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04160v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Matzner, Akanksha Ahuja, Rasoul Sadeghi, Michael Doherty, Alejandra Beghelli, Seb J. Savory, Polina Bayvel</dc:creator>
    </item>
    <item>
      <title>Demo: Paving the Way for Smart Manufacturing with 5G/TSN Convergence and Augmented Reality</title>
      <link>https://arxiv.org/abs/2411.04336</link>
      <description>arXiv:2411.04336v1 Announce Type: new 
Abstract: The fifth-generation (5G) mobile/cellular and time-sensitive networking (TSN) technologies are widely recognized as the key to shaping smart manufacturing for Industry 4.0 and beyond. Converged operation of the two offers end-to-end real-time and deterministic connectivity over hybrid wired and wireless segments. On the other hand, the augmented reality (AR) technology provides various benefits for the manufacturing sector. To this end, this demonstration showcases AR-aided remote assistance use-case over a hybrid TSN and 5G system. The demonstration setup comprises off-the-shelf 5G and TSN devices, a near product-grade 5G system, and an AR solution based on smart glasses. The demonstration shows the viability of over-the air transmission of scheduled TSN traffic and real-time assistance for a local user from a remote environments. Performance results from the demonstration setup are also shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04336v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sajida Gufran, Adnan Aijaz</dc:creator>
    </item>
    <item>
      <title>Towards Secured Smart Grid 2.0: Exploring Security Threats, Protection Models, and Challenges</title>
      <link>https://arxiv.org/abs/2411.04365</link>
      <description>arXiv:2411.04365v1 Announce Type: new 
Abstract: Many nations are promoting the green transition in the energy sector to attain neutral carbon emissions by 2050. Smart Grid 2.0 (SG2) is expected to explore data-driven analytics and enhance communication technologies to improve the efficiency and sustainability of distributed renewable energy systems. These features are beyond smart metering and electric surplus distribution in conventional smart grids. Given the high dependence on communication networks to connect distributed microgrids in SG2, potential cascading failures of connectivity can cause disruption to data synchronization to the remote control systems. This paper reviews security threats and defense tactics for three stakeholders: power grid operators, communication network providers, and consumers. Through the survey, we found that SG2's stakeholders are particularly vulnerable to substation attacks/vandalism, malware/ransomware threats, blockchain vulnerabilities and supply chain breakdowns. Furthermore, incorporating artificial intelligence (AI) into autonomous energy management in distributed energy resources of SG2 creates new challenges. Accordingly, adversarial samples and false data injection on electricity reading and measurement sensors at power plants can fool AI-powered control functions and cause messy error-checking operations in energy storage, wrong energy estimation in electric vehicle charging, and even fraudulent transactions in peer-to-peer energy trading models. Scalable blockchain-based models, physical unclonable function, interoperable security protocols, and trustworthy AI models designed for managing distributed microgrids in SG2 are typical promising protection models for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04365v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lan-Huong Nguyen, Van-Linh Nguyen, Ren-Hung Hwang, Jian-Jhih Kuo, Yu-Wen Chen, Chien-Chung Huang, Ping-I Pan</dc:creator>
    </item>
    <item>
      <title>The Impact of Traffic Characteristics on System and User Performance in 5G/6G Cellular Systems</title>
      <link>https://arxiv.org/abs/2411.04474</link>
      <description>arXiv:2411.04474v1 Announce Type: new 
Abstract: The statistical characteristics of the propagation environment and traffic arrival process are known to affect the user performance in 5G/6G millimeter wave (mmWave) and subterahertz (sub-THz) systems. While the former topic has received considerable attention recently, little is known about the impact of traffic statistics. In this study, we characterize the effects of correlation and variability in the session arrival process on the performance of 5G/6G mmWave/sub-THz systems. To this end, we use the tools of stochastic geometry and queuing theory to model the service process at base stations (BS) and specifics of the mmWave/sub-THz radio part. The metrics considered include the system resource utilization and session loss probability. Our results show that the normalized autocorrelation function (NACF), coefficient of variation (CoV), and variance of the resource request distribution have a significant impact on the considered parameters. For the same arrival rate, high values of lag-1 NACF and CoV may lead the system out of the operational regime, affecting the loss probability and resource utilization by up to an order of magnitude. Even a slight deviation from the uncorrelated Poisson process decreases the utilization by 10-20% and increases the session loss probability multiple times. Radio and environmental characteristics may further increase the variability in resource request distribution and decrease resource utilization. In general, the use of the commonly accepted Poisson assumption leads to a severe underestimation of the actual performance of 5G/6G mmWave/sub-THz systems. Therefore, both traffic arrival and propagation statistics are equally important for accurate performance assessment of such systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04474v1</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduard Sopin, Vyacheslav Begishev, Vladislav Prosvirov, Konstantin Samouylov, Yevgeni Koucheryavy</dc:creator>
    </item>
    <item>
      <title>JC5A: Service Delay Minimization for Aerial MEC-assisted Industrial Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2411.04762</link>
      <description>arXiv:2411.04762v1 Announce Type: new 
Abstract: In the era of the sixth generation (6G) and industrial Internet of Things (IIoT), an industrial cyber-physical system (ICPS) drives the proliferation of sensor devices and computing-intensive tasks. To address the limited resources of IIoT sensor devices, unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) has emerged as a promising solution, providing flexible and cost-effective services in close proximity of IIoT sensor devices (ISDs). However, leveraging aerial MEC to meet the delay-sensitive and computation-intensive requirements of the ISDs could face several challenges, including the limited communication, computation and caching (3C) resources, stringent offloading requirements for 3C services, and constrained on-board energy of UAVs. To address these issues, we first present a collaborative aerial MEC-assisted ICPS architecture by incorporating the computing capabilities of the macro base station (MBS) and UAVs. We then formulate a service delay minimization optimization problem (SDMOP). Since the SDMOP is proved to be an NP-hard problem, we propose a joint computation offloading, caching, communication resource allocation, computation resource allocation, and UAV trajectory control approach (JC5A). Specifically, JC5A consists of a block successive upper bound minimization method of multipliers (BSUMM) for computation offloading and service caching, a convex optimization-based method for communication and computation resource allocation, and a successive convex approximation (SCA)-based method for UAV trajectory control. Moreover, we theoretically prove the convergence and polynomial complexity of JC5A. Simulation results demonstrate that the proposed approach can achieve superior system performance compared to the benchmark approaches and algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04762v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Jiaxu Wu, Long He, Jiacheng Wang, Dusit Niyato, Abbas Jamalipour, Shiwen Mao</dc:creator>
    </item>
    <item>
      <title>Joint wireless and computing resource management with optimal slice selection in in-network-edge metaverse system</title>
      <link>https://arxiv.org/abs/2411.04561</link>
      <description>arXiv:2411.04561v1 Announce Type: cross 
Abstract: This paper presents an approach to joint wireless and computing resource management in slice-enabled metaverse networks, addressing the challenges of inter-slice and intra-slice resource allocation in the presence of in-network computing. We formulate the problem as a mixed-integer nonlinear programming (MINLP) problem and derive an optimal solution using standard optimization techniques. Through extensive simulations, we demonstrate that our proposed method significantly improves system performance by effectively balancing the allocation of radio and computing resources across multiple slices. Our approach outperforms existing benchmarks, particularly in scenarios with high user demand and varying computational tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04561v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sulaiman Muhammad Rashid, Ibrahim Aliyu, Abubakar Isah, Jihoon Lee, Sangwon Oh, Minsoo Hahn, Jinsul Kim</dc:creator>
    </item>
    <item>
      <title>Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2411.04672</link>
      <description>arXiv:2411.04672v1 Announce Type: cross 
Abstract: This paper presents a semantic-aware multi-modal resource allocation (SAMRA) for multi-task using multi-agent reinforcement learning (MARL), termed SAMRAMARL, utilizing in platoon systems where cellular vehicle-to-everything (C-V2X) communication is employed. The proposed approach leverages the semantic information to optimize the allocation of communication resources. By integrating a distributed multi-agent reinforcement learning (MARL) algorithm, SAMRAMARL enables autonomous decision-making for each vehicle, channel assignment optimization, power allocation, and semantic symbol length based on the contextual importance of the transmitted information. This semantic-awareness ensures that both vehicle-to-vehicle (V2V) and vehicle-to-infrastructure (V2I) communications prioritize data that is critical for maintaining safe and efficient platoon operations. The framework also introduces a tailored quality of experience (QoE) metric for semantic communication, aiming to maximize QoE in V2V links while improving the success rate of semantic information transmission (SRS). Extensive simulations has demonstrated that SAMRAMARL outperforms existing methods, achieving significant gains in QoE and communication efficiency in C-V2X platooning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04672v1</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Shao, Qiong Wu, Pingyi Fan, Kezhi Wang, Qiang Fan, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Maximizing Real-Time Video QoE via Bandwidth Sharing under Markovian setting</title>
      <link>https://arxiv.org/abs/2401.10681</link>
      <description>arXiv:2401.10681v3 Announce Type: replace 
Abstract: We consider the problem of optimizing Quality of Experience (QoE) of clients streaming real-time video, served by networks managed by different operators that can share bandwidth with each other. The abundance of real-time video traffic is evident in the popularity of applications like video conferencing and video streaming of live events, which have increased significantly since the recent pandemic. We model the problem as a joint optimization of resource allocation for the clients and bandwidth sharing across the operators, with special attention to how the resource allocation impacts clients' perceived video quality. We propose an online policy as a solution, which involves dynamically sharing a portion of one operator's bandwidth with another operator. We provide strong theoretical optimality guarantees for the policy. We also use extensive simulations to demonstrate the policy's substantial performance improvements (of up to ninety percent), and identify insights into key system parameters (e.g., imbalance in arrival rates or channel conditions of the operators) that dictate the improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10681v3</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushi Anna George, Vinay Joseph</dc:creator>
    </item>
    <item>
      <title>RIS in Cellular Networks -- Challenges and Issues</title>
      <link>https://arxiv.org/abs/2404.04753</link>
      <description>arXiv:2404.04753v2 Announce Type: replace 
Abstract: Reconfigurable intelligent surface (RIS) has been suggested to be a key 6G feature and was suggested to be considered as a study-item in both 3GPP Releases 18 and 19. However, in both releases, it has been decided not to continue with it as a study-item, and to leave it for possible future specification. In this paper, we present the rationale for such a decision. Particularly, we demonstrate the practical issues which may affect the feasibility or usefulness of RIS in cellular networks, and present open problems to be addressed before RIS can be used in practice. Moreover, we compare the performance of RIS with network-controlled repeater, the node with the most similar characteristics to RIS and which has been standardized in 3GPP Release 18. Finally, different simulations are presented to evaluate the performance of RIS-assisted networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04753v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Magnus {\AA}str\"om, Philipp Gentner, Omer Haliloglu, Behrooz Makki, Ola Tageman</dc:creator>
    </item>
    <item>
      <title>Exploring QUIC Dynamics: A Large-Scale Dataset for Encrypted Traffic Analysis</title>
      <link>https://arxiv.org/abs/2410.03728</link>
      <description>arXiv:2410.03728v2 Announce Type: replace 
Abstract: QUIC, a new and increasingly used transport protocol, addresses and resolves the limitations of TCP by offering improved security, performance, and features such as stream multiplexing and connection migration. These features, however, also present challenges for network operators who need to monitor and analyze web traffic. In this paper, we introduce VisQUIC, a labeled dataset comprising over 100,000 QUIC traces from more than 44,000 websites (URLs), collected over a four-month period. These traces provide the foundation for generating more than seven million images, with configurable parameters of window length, pixel resolution, normalization, and labels. These images enable an observer looking at the interactions between a client and a server to analyze and gain insights about QUIC encrypted connections. To illustrate the dataset's potential, we offer a use-case example of an observer estimating the number of HTTP/3 responses/requests pairs in a given QUIC, which can reveal server behavior, client--server interactions, and the load imposed by an observed connection. We formulate the problem as a discrete regression problem, train a machine learning (ML) model for it, and then evaluate it using the proposed dataset on an example use case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03728v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Barak Gahtan, Robert J. Shahla, Alex M. Bronstein, Reuven Cohen</dc:creator>
    </item>
    <item>
      <title>Connection Performance Modeling and Analysis of a Radiosonde Network in a Typhoon</title>
      <link>https://arxiv.org/abs/2411.01906</link>
      <description>arXiv:2411.01906v2 Announce Type: replace 
Abstract: This paper is concerned with the theoretical modeling and analysis of uplink connection performance of a radiosonde network deployed in a typhoon. Similar to existing works, the stochastic geometry theory is leveraged to derive the expression of the uplink connection probability (CP) of a radiosonde. Nevertheless, existing works assume that network nodes are spherically or uniformly distributed. Different from the existing works, this paper investigates two particular motion patterns of radiosondes in a typhoon, which significantly challenges the theoretical analysis. According to their particular motion patterns, this paper first separately models the distributions of horizontal and vertical distances from a radiosonde to its receiver. Secondly, this paper derives the closed-form expressions of cumulative distribution function (CDF) and probability density function (PDF) of a radiosonde's three-dimensional (3D) propagation distance to its receiver. Thirdly, this paper derives the analytical expression of the uplink CP for any radiosonde in the network. Finally, extensive numerical simulations are conducted to validate the theoretical analysis, and the influence of various network design parameters are comprehensively discussed. Simulation results show that when the signal-to-interference-noise ratio (SINR) threshold is below -35 dB, and the density of radiosondes remains under 0.01/km^3, the uplink CP approaches 26%, 39%, and 50% in three patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01906v2</guid>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyi Liu, Xianbin Cao, Peng Yang, Zehui Xiong, Tony Q. S. Quek, Dapeng Oliver Wu</dc:creator>
    </item>
    <item>
      <title>A Survey on Task Allocation and Scheduling in Robotic Network Systems</title>
      <link>https://arxiv.org/abs/2303.12876</link>
      <description>arXiv:2303.12876v2 Announce Type: replace-cross 
Abstract: Cloud Robotics is helping to create a new generation of robots that leverage the nearly unlimited resources of large data centers (i.e., the cloud), overcoming the limitations imposed by on-board resources. Different processing power, capabilities, resource sizes, energy consumption, and so forth, make scheduling and task allocation critical components. The basic idea of task allocation and scheduling is to optimize performance by minimizing completion time, energy consumption, delays between two consecutive tasks, along with others, and maximizing resource utilization, number of completed tasks in a given time interval, and suchlike. In the past, several works have addressed various aspects of task allocation and scheduling. In this paper, we provide a comprehensive overview of task allocation and scheduling strategies and related metrics suitable for robotic network cloud systems. We discuss the issues related to allocation and scheduling methods and the limitations that need to be overcome. The literature review is organized according to three different viewpoints: Architectures and Applications, Methods and Parameters. In addition, the limitations of each method are highlighted for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.12876v2</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2024.3491944</arxiv:DOI>
      <dc:creator>Saeid Alirezazadeh, Lu\'is A. Alexandre</dc:creator>
    </item>
    <item>
      <title>Combinatorial Client-Master Multiagent Deep Reinforcement Learning for Task Offloading in Mobile Edge Computing</title>
      <link>https://arxiv.org/abs/2402.11653</link>
      <description>arXiv:2402.11653v2 Announce Type: replace-cross 
Abstract: Recently, there has been an explosion of mobile applications that perform computationally intensive tasks such as video streaming, data mining, virtual reality, augmented reality, image processing, video processing, face recognition, and online gaming. However, user devices (UDs), such as tablets and smartphones, have a limited ability to perform the computation needs of the tasks. Mobile edge computing (MEC) has emerged as a promising technology to meet the increasing computing demands of UDs. Task offloading in MEC is a strategy that meets the demands of UDs by distributing tasks between UDs and MEC servers. Deep reinforcement learning (DRL) is gaining attention in task-offloading problems because it can adapt to dynamic changes and minimize online computational complexity. However, the various types of continuous and discrete resource constraints on UDs and MEC servers pose challenges to the design of an efficient DRL-based task-offloading strategy. Existing DRL-based task-offloading algorithms focus on the constraints of the UDs, assuming the availability of enough storage resources on the server. Moreover, existing multiagent DRL (MADRL)--based task-offloading algorithms are homogeneous agents and consider homogeneous constraints as a penalty in their reward function. We proposed a novel combinatorial client-master MADRL (CCM\_MADRL) algorithm for task offloading in MEC (CCM\_MADRL\_MEC) that enables UDs to decide their resource requirements and the server to make a combinatorial decision based on the requirements of the UDs. CCM\_MADRL\_MEC is the first MADRL in task offloading to consider server storage capacity in addition to the constraints in the UDs. By taking advantage of the combinatorial action selection, CCM\_MADRL\_MEC has shown superior convergence over existing MADDPG and heuristic algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11653v2</guid>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tesfay Zemuy Gebrekidan, Sebastian Stein, Timothy J. Norman</dc:creator>
    </item>
  </channel>
</rss>
