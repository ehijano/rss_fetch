<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Apr 2024 04:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>State Discretization for Continuous-State MDPs in Infectious Disease Control</title>
      <link>https://arxiv.org/abs/2404.12540</link>
      <description>arXiv:2404.12540v1 Announce Type: new 
Abstract: Repeated decision-making problems under uncertainty may arise in the health policy context, such as infectious disease control for COVID-19 and other epidemics. These problems may sometimes be effectively solved using Markov decision processes (MDPs). However, the continuous or large state space of such problems for capturing infectious disease prevalence renders it difficult to implement tractable MDPs to identify the optimal disease control policy over time. We therefore develop an algorithm for discretizing continuous states for approximate MDP solutions in this context. We benchmark performance against a uniform discretization using both a synthetic example and an example of COVID-19 in Los Angeles County.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12540v1</guid>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suyanpeng Zhang, Sze-chuan Suen</dc:creator>
    </item>
    <item>
      <title>Curves of Minimax Curvature</title>
      <link>https://arxiv.org/abs/2404.12574</link>
      <description>arXiv:2404.12574v1 Announce Type: new 
Abstract: We consider the problem of finding curves of minimum pointwise-maximum curvature, i.e., curves of minimax curvature, among planar curves of fixed length with prescribed endpoints and tangents at the endpoints. We reformulate the problem in terms of optimal control and use the maximum principle, as well as some geometrical arguments, to produce a classification of the types of solutions. Using the classification, we devise a numerical method which reduces the infinite-dimensional optimization problem to a finite-dimensional problem with just six variables. The solution types, together with some further observations on optimality, are illustrated via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12574v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Yal\c{c}{\i}n Kaya, Lyle Noakes, Philip Schrader</dc:creator>
    </item>
    <item>
      <title>Surface Movement Method for Linear Programming</title>
      <link>https://arxiv.org/abs/2404.12640</link>
      <description>arXiv:2404.12640v1 Announce Type: new 
Abstract: The article presents a new method of linear programming, called the surface movement method. This method constructs an optimal objective path on the surface of the feasible polytope from the initial boundary point to the point at which the optimal value of the objective function is achieved. The optimality of the path means moving in the direction of maximum increase/decrease in the value of the objective function. A formal description of the algorithm implementing the surface movement method is described. The convergence theorem of this algorithm is proved. The presented method can be effectively implemented using a feed forward deep neural network to determine the optimal direction of movement along the faces of the feasible polytope. To do this, a multidimensional local image of the linear programming problem is constructed at the point of the current approximation. This image is fed to the input of the deep neural network, which returns a vector determining the direction of the optimal objective path on the polytope surface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12640v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nikolay A. Olkhovsky, Leonid B. Sokolinsky</dc:creator>
    </item>
    <item>
      <title>Speeding up VSLMS adaptation algorithms using dynamic adaptation gain: Analysis and Applications</title>
      <link>https://arxiv.org/abs/2404.12672</link>
      <description>arXiv:2404.12672v1 Announce Type: new 
Abstract: The paper explores the use of dynamic adaptation gain/step size (DAG) for improving the adaptation  transient performance of variable step-size LMS (VS-LMS) adaptation algorithms. A generic form for the implementation of the DAG  within the VS-LMS algorithms is provided. The properties of the VS-LMS algorithms using dynamic adaptation gain are discussed in detail. Stability issues in deterministic environment and convergence properties in stochastic environment are examined. A transient performance analysis is proposed.  Criteria for  the selection of the coefficients of the DAG filter are provided.The potential of the VS-LMS adaptation algorithms using a DAG is then illustrated by simulation results (adaptive line enhancer, filter identification)  and experimental results obtained on a relevant adaptive active noise attenuation system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12672v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioan Dor\'e Landau (GIPSA-SAFE), Dariusz Bismor (IMS), Tudor-Bogdan Airimitoaie (IMS), Bernard Vau (GIPSA-Services), Gabriel Buche (GIPSA-Services)</dc:creator>
    </item>
    <item>
      <title>Optimal transport maps as flows of control-affine systems</title>
      <link>https://arxiv.org/abs/2404.12793</link>
      <description>arXiv:2404.12793v1 Announce Type: new 
Abstract: We consider the controllability problem for the continuity equation where the dynamics is governed by a driftless control-affine system. Under suitable regularity conditions, the controllability of the system is a sufficient condition for the controllability of the continuity equation by means of time-varying feedback controls. Moreover, we show that there exist controls such that the flow of the control system is the optimal transport map, for the 2-Wasserstein distance, between two given probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12793v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Caponigro, Arianna Vicari</dc:creator>
    </item>
    <item>
      <title>Low solution rank of the matrix LASSO under RIP with consequences for rank-constrained algorithms</title>
      <link>https://arxiv.org/abs/2404.12828</link>
      <description>arXiv:2404.12828v1 Announce Type: new 
Abstract: We show that solutions to the popular convex matrix LASSO problem (nuclear-norm--penalized linear least-squares) have low rank under similar assumptions as required by classical low-rank matrix sensing error bounds. Although the purpose of the nuclear norm penalty is to promote low solution rank, a proof has not yet (to our knowledge) been provided outside very specific circumstances. Furthermore, we show that this result has significant theoretical consequences for nonconvex rank-constrained optimization approaches. Specifically, we show that if (a) the ground truth matrix has low rank, (b) the (linear) measurement operator has the matrix restricted isometry property (RIP), and (c) the measurement error is small enough relative to the nuclear norm penalty, then the (unique) LASSO solution has rank (approximately) bounded by that of the ground truth. From this, we show (a) that a low-rank--projected proximal gradient descent algorithm will converge linearly to the LASSO solution from any initialization, and (b) that the nonconvex landscape of the low-rank Burer-Monteiro--factored problem formulation is benign in the sense that all second-order critical points are globally optimal and yield the LASSO solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12828v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew D. McRae</dc:creator>
    </item>
    <item>
      <title>Getting to the Root of the Problem: Sums of Squares for Infinite Trees</title>
      <link>https://arxiv.org/abs/2404.12838</link>
      <description>arXiv:2404.12838v1 Announce Type: new 
Abstract: The inducibility of a graph represents its maximum density as an induced subgraph over all possible sequences of graphs of size growing to infinity. This invariant of graphs has been extensively studied since its introduction in $1975$ by Pippenger and Golumbic. In $2017$, Czabarka, Sz\'ekely and Wagner extended this notion to leaf-labeled rooted binary trees, which are objects widely studied in the field of phylogenetics. They obtain the first results and bounds for the densities and inducibilities of such trees. Following up on their work, we apply Razborov's flag algebra theory to this setting, introducing the flag algebra of rooted leaf-labeled binary trees. This framework allows us to use polynomial optimization methods, based on semidefinite programming, to efficiently obtain new upper bounds for the inducibility of trees and to improve existing ones. Additionally, we obtain the first outer approximations of profiles of trees, which represent all possible simultaneous densities of a pair of trees. Finally, we are able to prove the non-convexity of some of these profiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12838v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Brosch, Diane Puges</dc:creator>
    </item>
    <item>
      <title>Online Policy Optimization in Unknown Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2404.13009</link>
      <description>arXiv:2404.13009v1 Announce Type: new 
Abstract: We study online policy optimization in nonlinear time-varying dynamical systems where the true dynamical models are unknown to the controller. This problem is challenging because, unlike in linear systems, the controller cannot obtain globally accurate estimations of the ground-truth dynamics using local exploration. We propose a meta-framework that combines a general online policy optimization algorithm ($\texttt{ALG}$) with a general online estimator of the dynamical system's model parameters ($\texttt{EST}$). We show that if the hypothetical joint dynamics induced by $\texttt{ALG}$ with known parameters satisfies several desired properties, the joint dynamics under inexact parameters from $\texttt{EST}$ will be robust to errors. Importantly, the final policy regret only depends on $\texttt{EST}$'s predictions on the visited trajectory, which relaxes a bottleneck on identifying the true parameters globally. To demonstrate our framework, we develop a computationally efficient variant of Gradient-based Adaptive Policy Selection, called Memoryless GAPS (M-GAPS), and use it to instantiate $\texttt{ALG}$. Combining M-GAPS with online gradient descent to instantiate $\texttt{EST}$ yields (to our knowledge) the first local regret bound for online policy optimization in nonlinear time-varying systems with unknown dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13009v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiheng Lin, James A. Preiss, Fengze Xie, Emile Anand, Soon-Jo Chung, Yisong Yue, Adam Wierman</dc:creator>
    </item>
    <item>
      <title>Single-loop Projection-free and Projected Gradient-based Algorithms for Nonconvex-concave Saddle Point Problems with Bilevel Structure</title>
      <link>https://arxiv.org/abs/2404.13021</link>
      <description>arXiv:2404.13021v1 Announce Type: new 
Abstract: In this paper, we explore a class of constrained saddle point problems with a bilevel structure, where the upper-level objective function is nonconvex-concave and smooth subject to a strongly convex lower-level objective function. This class of problems finds wide applicability in machine learning, including robust multi-task learning, adversarial learning, and robust meta-learning. While some studies have focused on simpler formulations, e.g., when the upper-level objective function is linear in the maximization component, there remains a significant gap in developing efficient projection-free and projection-based algorithms with theoretical guarantees for more general settings. To bridge this gap, we propose efficient single-loop one-sided projection-free, and fully projection-based primal-dual methods. By leveraging regularization and nested approximation techniques, we initially devise a bilevel primal-dual one-sided projection-free algorithm, requiring $\mathcal{O}(\epsilon^{-4})$ iterations to attain an $\epsilon$-stationary point. Subsequently, we develop a bilevel primal-dual fully projected algorithm, capable of achieving an $\epsilon$-stationary solution within $\mathcal{O}(\epsilon^{-5})$ iterations. To the best of our knowledge, our proposed algorithms represent among the first methods for solving general non-bilinear saddle point problems with a bilevel structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13021v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Mahdi Ahmadi, Erfan Yazdandoost Hamedani</dc:creator>
    </item>
    <item>
      <title>Distributed Model Predictive Control for Heterogeneous Platoons with Affine Spacing Policies and Arbitrary Communication Topologies</title>
      <link>https://arxiv.org/abs/2404.12441</link>
      <description>arXiv:2404.12441v1 Announce Type: cross 
Abstract: This paper presents a distributed model predictive control (DMPC) algorithm for a heterogeneous platoon using arbitrary communication topologies, as long as each vehicle is able to communicate with a preceding vehicle in the platoon. The proposed DMPC algorithm is able to accommodate any spacing policy that is affine in a vehicle's velocity, which includes constant distance or constant time headway spacing policies. By analyzing the total cost for the entire platoon, a sufficient condition is derived to guarantee platoon asymptotic stability. Simulation experiments with a platoon of 50 vehicles and hardware experiments with a platoon of four 1/10th scale vehicles validate the algorithm and compare performance under different spacing policies and communication topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12441v1</guid>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael H. Shaham, Taskin Padir</dc:creator>
    </item>
    <item>
      <title>A rate-distortion framework for MCMC algorithms: geometry and factorization of multivariate Markov chains</title>
      <link>https://arxiv.org/abs/2404.12589</link>
      <description>arXiv:2404.12589v1 Announce Type: cross 
Abstract: We introduce a framework rooted in a rate distortion problem for Markov chains, and show how a suite of commonly used Markov Chain Monte Carlo (MCMC) algorithms are specific instances within it, where the target stationary distribution is controlled by the distortion function. Our approach offers a unified variational view on the optimality of algorithms such as Metropolis-Hastings, Glauber dynamics, the swapping algorithm and Feynman-Kac path models. Along the way, we analyze factorizability and geometry of multivariate Markov chains. Specifically, we demonstrate that induced chains on factors of a product space can be regarded as information projections with respect to a particular divergence. This perspective yields Han--Shearer type inequalities for Markov chains as well as applications in the context of large deviations and mixing time comparison.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12589v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael C. H. Choi, Youjia Wang, Geoffrey Wolfer</dc:creator>
    </item>
    <item>
      <title>On extremal points for some vectorial total variation seminorms</title>
      <link>https://arxiv.org/abs/2404.12831</link>
      <description>arXiv:2404.12831v1 Announce Type: cross 
Abstract: We consider the set of extremal points of the generalized unit ball induced by gradient total variation seminorms for vector-valued functions on bounded Euclidean domains. These extremal points are central to the understanding of sparse solutions and sparse optimization algorithms for variational regularization problems posed among such functions. For not fully vectorial cases in which either the domain or the target are one dimensional, or the sum of the total variations of each component is used, we prove that these extremals are fully characterized as in the scalar-valued case, that is, they consist of piecewise constant functions with two regions. For definitions involving more involved matrix norms and in particular spectral norms, which are of interest in image processing, we produce families of examples to show that the resulting set of extremal points is larger and includes piecewise constant functions with more than two regions. We also consider the total deformation induced by the symmetrized gradient, for which minimization with linear constraints appears in problems of determination of limit loads in a number of continuum mechanical models involving plasticity, bringing relevance to the corresponding extremal points. For this case, we show piecewise infinitesimally rigid functions with two pieces to be extremal under mild assumptions. Finally, as an example of an extremal which is not piecewise constant, we prove that unit radial vector fields are extremal for the Frobenius total variation in the plane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12831v1</guid>
      <category>math.FA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kristian Bredies, Jos\'e A. Iglesias, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>Optimal single threshold stopping rules and sharp prophet inequalities</title>
      <link>https://arxiv.org/abs/2404.12949</link>
      <description>arXiv:2404.12949v1 Announce Type: cross 
Abstract: This paper considers a finite horizon optimal stopping problem for a sequence of independent and identically distributed random variables. The objective is to design stopping rules that attempt to select the random variable with the highest value in the sequence. The performance of any stopping rule may be benchmarked relative to the selection of a "prophet" that has perfect foreknowledge of the largest value. Such comparisons are typically stated in the form of "prophet inequalities." In this paper we characterize sharp prophet inequalities for single threshold stopping rules as solutions to infinite two person zero sum games on the unit square with special payoff kernels. The proposed game theoretic characterization allows one to derive sharp non-asymptotic prophet inequalities for different classes of distributions. This, in turn, gives rise to a simple and computationally tractable algorithmic paradigm for deriving optimal single threshold stopping rules. Our results also indicate that several classical observations in the literature are either incorrect or incomplete in treating this problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12949v1</guid>
      <category>math.PR</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Goldenshluger, Yaakov Malinovsky, Assaf Zeevi</dc:creator>
    </item>
    <item>
      <title>Nonlinear conjugate gradient methods: worst-case convergence rates via computer-assisted analyses</title>
      <link>https://arxiv.org/abs/2301.01530</link>
      <description>arXiv:2301.01530v4 Announce Type: replace 
Abstract: We propose a computer-assisted approach to the analysis of the worst-case convergence of nonlinear conjugate gradient methods (NCGMs). Those methods are known for their generally good empirical performances for large-scale optimization, while having relatively incomplete analyses. Using our computer-assisted approach, we establish novel complexity bounds for the Polak-Ribi\`ere-Polyak (PRP) and the Fletcher-Reeves (FR) NCGMs for smooth strongly convex minimization. In particular, we construct mathematical proofs that establish the first non-asymptotic convergence bound for FR (which is historically the first developed NCGM), and a much improved non-asymptotic convergence bound for PRP. Additionally, we provide simple adversarial examples on which these methods do not perform better than gradient descent with exact line search, leaving very little room for improvements on the same class of problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.01530v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuvomoy Das Gupta, Robert M. Freund, Xu Andy Sun, Adrien Taylor</dc:creator>
    </item>
    <item>
      <title>Inverse Cubature and Quadrature Kalman filters</title>
      <link>https://arxiv.org/abs/2303.10322</link>
      <description>arXiv:2303.10322v2 Announce Type: replace 
Abstract: Recent research in inverse cognition with cognitive radar has led to the development of inverse stochastic filters that are employed by the target to infer the information the cognitive radar may have learned. Prior works addressed this inverse cognition problem by proposing inverse Kalman filter (I-KF) and inverse extended KF (I-EKF), respectively, for linear and non-linear Gaussian state-space models. However, in practice, many counter-adversarial settings involve highly non-linear system models, wherein EKF's linearization often fails. In this paper, we consider the efficient numerical integration techniques to address such non-linearities and, to this end, develop inverse cubature KF (I-CKF), inverse quadrature KF (I-QKF), and inverse cubature-quadrature KF (I-CQKF). For the unknown system model case, we develop reproducing kernel Hilbert space (RKHS)-based CKF. We derive the stochastic stability conditions for the proposed filters in the exponential-mean-squared-boundedness sense and prove the filters' consistency. Numerical experiments demonstrate the estimation accuracy of our I-CKF, I-QKF, and I-CQKF with the recursive Cram\'{e}r-Rao lower bound as a benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.10322v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Himali Singh, Kumar Vijay Mishra, Arpan Chattopadhyay</dc:creator>
    </item>
    <item>
      <title>Auxiliary-Variable Adaptive Control Barrier Functions for Safety Critical Systems</title>
      <link>https://arxiv.org/abs/2304.00372</link>
      <description>arXiv:2304.00372v3 Announce Type: replace 
Abstract: This paper studies safety guarantees for systems with time-varying control bounds. It has been shown that optimizing quadratic costs subject to state and control constraints can be reduced to a sequence of Quadratic Programs (QPs) using Control Barrier Functions (CBFs). One of the main challenges in this method is that the CBF-based QP could easily become infeasible under tight control bounds, especially when the control bounds are time-varying. The recently proposed adaptive CBFs have addressed such infeasibility issues, but require extensive and non-trivial hyperparameter tuning for the CBF-based QP and may introduce overshooting control near the boundaries of safe sets. To address these issues, we propose a new type of adaptive CBFs called Auxiliary-Variable Adaptive CBFs (AVCBFs). Specifically, we introduce an auxiliary variable that multiplies each CBF itself, and define dynamics for the auxiliary variable to adapt it in constructing the corresponding CBF constraint. In this way, we can improve the feasibility of the CBF-based QP while avoiding extensive parameter tuning with non-overshooting control since the formulation is identical to classical CBF methods. We demonstrate the advantages of using AVCBFs and compare them with existing techniques on an Adaptive Cruise Control (ACC) problem with time-varying control bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00372v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Wei Xiao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>An input-output framework for stability and synchronization analysis of networks of infinite-dimensional linear systems</title>
      <link>https://arxiv.org/abs/2305.14666</link>
      <description>arXiv:2305.14666v2 Announce Type: replace 
Abstract: This paper presents a synchronization criterion for networks of infinite-dimensional linear systems, extending a previous result for finite-dimensional systems. Our result, established in the general framework of input-output relations, requires an additional input-output stability property, compared to the finite-dimensional counterpart. We show that this this property holds for a large class of infinite-dimensional systems including abstract Cauchy problems, parabolic partial differential equations, and time-delay differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14666v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tian Xia, Luca Scardovi</dc:creator>
    </item>
    <item>
      <title>Explicit feedback synthesis for nonlinear robust model predictive control driven by quasi-interpolation</title>
      <link>https://arxiv.org/abs/2306.03027</link>
      <description>arXiv:2306.03027v3 Announce Type: replace 
Abstract: We present QuIFS (Quasi-Interpolation driven Feedback Synthesis): an offline feedback synthesis algorithm for explicit nonlinear robust minmax model predictive control (MPC) problems with guaranteed quality of approximation. The underlying technique is driven by a particular type of grid-based quasi-interpolation scheme. The QuIFS algorithm departs drastically from conventional approximation algorithms that are employed in the MPC industry (in particular, it is neither based on multi-parametric programming tools and nor does it involve kernel methods), and the essence of its point of departure is encoded in the following challenge-answer approach: Given an error margin $\varepsilon&gt;0$, compute in a single stroke a feasible feedback policy that is uniformly $\varepsilon$-close to the optimal MPC feedback policy for a given nonlinear system subjected to constraints and bounded uncertainties. Closed-loop stability and recursive feasibility under the approximate feedback policy are also established. We provide a library of numerical examples to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03027v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Ganguly, Debasish Chatterjee</dc:creator>
    </item>
    <item>
      <title>Null-controllability of the Generalized Baouendi-Grushin heat like equations</title>
      <link>https://arxiv.org/abs/2310.11215</link>
      <description>arXiv:2310.11215v2 Announce Type: replace 
Abstract: In this article, we prove null-controllability results for the heat equation associated tofractional Baouendi-Grushin operators $$\partial_t u+\bigl(-\Delta_x-V(x)\Delta_y\bigr)^s u= \mathbb{1}_\Omega h$$ where $V$ is a potential that satisfies some power growth conditions and the set $\Omega$is thick in some sense. This extends previously known results for potentials $V(x)=|x|^{2k}$.To do so, we study Zhu-Zhuge's spectral inequality for Schr{\"o}dinger operators with power growth potentials, and give a precised quantitative form of it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11215v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Jaming (IMB), Yunlei Wang (IMB)</dc:creator>
    </item>
    <item>
      <title>Stochastic Dissipativity for Systems with Probabilistic Input Delays</title>
      <link>https://arxiv.org/abs/2401.02569</link>
      <description>arXiv:2401.02569v2 Announce Type: replace 
Abstract: This work considers stochastic operators in general inner-product spaces, and in particular, systems with stochastically time-varying input delays of a known probability distribution. Stochastic dissipativity and stability are defined from an operator-theoretic perspective, and the well-known open-loop dissipativity conditions for closed-loop/network stability are extended to the stochastic case. Criteria are derived to identify dissipative nonlinear systems with stochastic input delays, and this result is used to find delay-distribution-dependent linear matrix inequality conditions for stochastic dissipativity of a linear system with input delays of a known probability distribution. A numerical experiment demonstrates the utility of the resulting criteria for robust plant analysis and controller design, highlighting significantly reduced conservatism compared to deterministic methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.02569v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan LoCicero, Amy Strong, Leila Bridgeman</dc:creator>
    </item>
    <item>
      <title>Data-Enabled Policy Optimization for Direct Adaptive Learning of the LQR</title>
      <link>https://arxiv.org/abs/2401.14871</link>
      <description>arXiv:2401.14871v3 Announce Type: replace 
Abstract: Direct data-driven design methods for the linear quadratic regulator (LQR) mainly use offline or episodic data batches, and their online adaptation has been acknowledged as an open problem. In this paper, we propose a direct adaptive method to learn the LQR from online closed-loop data. First, we propose a new policy parameterization based on the sample covariance to formulate a direct data-driven LQR problem, which is shown to be equivalent to the certainty-equivalence LQR with optimal non-asymptotic guarantees. Second, we design a novel data-enabled policy optimization (DeePO) method to directly update the policy, where the gradient is explicitly computed using only a batch of persistently exciting (PE) data. Third, we establish its global convergence via a projected gradient dominance property. Importantly, we efficiently use DeePO to adaptively learn the LQR by performing only one-step projected gradient descent per sample of the closed-loop system, which also leads to an explicit recursive update of the policy. Under PE inputs and for bounded noise, we show that the average regret of the LQR cost is upper-bounded by two terms signifying a sublinear decrease in time $\mathcal{O}(1/\sqrt{T})$ plus a bias scaling inversely with signal-to-noise ratio (SNR), which are independent of the noise statistics. Finally, we perform simulations to validate the theoretical results and demonstrate the computational and sample efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14871v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Florian D\"orfler, Alessandro Chiuso, Keyou You</dc:creator>
    </item>
    <item>
      <title>Algebraic Constraints on Common Lines in Cryo-EM</title>
      <link>https://arxiv.org/abs/2403.16879</link>
      <description>arXiv:2403.16879v2 Announce Type: replace 
Abstract: We revisit the topic of common lines between projection images in single particle cryo-electron microscopy (cryo-EM). We derive a novel low-rank constraint on a certain $2n \times n$ matrix storing properly-scaled basis vectors for the common lines between $n$ projection images of one molecular conformation. Using this algebraic constraint and others, we give optimization algorithms to denoise common lines and recover the unknown 3D rotations associated to the images. As an application, we develop a clustering algorithm to partition a set of noisy images into homogeneous communities using common lines, in the case of discrete heterogeneity in cryo-EM. We demonstrate the methods on synthetic and experimental datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16879v2</guid>
      <category>math.OC</category>
      <category>math.AG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tommi Muller, Adriana L. Duncan, Eric J. Verbeke, Joe Kileel</dc:creator>
    </item>
    <item>
      <title>Weak optimal transport with unnormalized kernels</title>
      <link>https://arxiv.org/abs/2203.16227</link>
      <description>arXiv:2203.16227v2 Announce Type: replace-cross 
Abstract: We introduce a new variant of the weak optimal transport problem where mass is distributed from one space to the other through unnormalized kernels. We give sufficient conditions for primal attainment and prove a dual formula for this transport problem. We also obtain dual attainment conditions for some specific cost functions. As a byproduct we obtain a transport characterization of the stochastic order defined by convex positively 1-homogenous functions, in the spirit of Strassen theorem for convex domination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.16227v2</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philippe Chon\'e (CREST), Nathael Gozlan (MAP5 - UMR 8145), Francis Kramarz (CREST)</dc:creator>
    </item>
    <item>
      <title>Equalised Odds is not Equal Individual Odds: Post-processing for Group and Individual Fairness</title>
      <link>https://arxiv.org/abs/2304.09779</link>
      <description>arXiv:2304.09779v3 Announce Type: replace-cross 
Abstract: Group fairness is achieved by equalising prediction distributions between protected sub-populations; individual fairness requires treating similar individuals alike. These two objectives, however, are incompatible when a scoring model is calibrated through discontinuous probability functions, where individuals can be randomly assigned an outcome determined by a fixed probability. This procedure may provide two similar individuals from the same protected group with classification odds that are disparately different -- a clear violation of individual fairness. Assigning unique odds to each protected sub-population may also prevent members of one sub-population from ever receiving equal chances of a positive outcome to another, which we argue is another type of unfairness called individual odds. We reconcile all this by constructing continuous probability functions between group thresholds that are constrained by their Lipschitz constant. Our solution preserves the model's predictive power, individual fairness and robustness while ensuring group fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.09779v3</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658989</arxiv:DOI>
      <dc:creator>Edward A. Small, Kacper Sokol, Daniel Manning, Flora D. Salim, Jeffrey Chan</dc:creator>
    </item>
    <item>
      <title>Noise Stability Optimization for Flat Minima with Tight Rates</title>
      <link>https://arxiv.org/abs/2306.08553</link>
      <description>arXiv:2306.08553v3 Announce Type: replace-cross 
Abstract: We consider minimizing a perturbed function $F(W) = \mathbb{E}_{U}[f(W + U)]$, given a function $f: \mathbb{R}^d \rightarrow \mathbb{R}$ and a random sample $U$ from a distribution $\mathcal{P}$ with mean zero. When $\mathcal{P}$ is the isotropic Gaussian, $F(W)$ is roughly equal to $f(W)$ plus a penalty on the trace of $\nabla^2 f(W)$, scaled by the variance of $\mathcal{P}$. This penalty on the Hessian has the benefit of improving generalization, through PAC-Bayes analysis. It is useful in low-sample regimes, for instance, when a (large) pre-trained model is fine-tuned on a small data set. One way to minimize $F$ is by adding $U$ to $W$, and then run SGD. We observe, empirically, that this noise injection does not provide significant gains over SGD, in our experiments of conducting fine-tuning on three image classification data sets. We design a simple, practical algorithm that adds noise along both $U$ and $-U$, with the option of adding several perturbations and taking their average. We analyze the convergence of this algorithm, showing tight rates on the norm of the output's gradient.
  We provide a comprehensive empirical analysis of our algorithm, by first showing that in an over-parameterized matrix sensing problem, it can find solutions with lower test loss than naive noise injection. Then, we compare our algorithm with four sharpness-reducing training methods (such as the Sharpness-Aware Minimization (Foret et al., 2021)). We find that our algorithm can outperform them by up to 1.8% test accuracy, for fine-tuning ResNet on six image classification data sets. It leads to a 17.7% (and 12.8%) reduction in the trace (and largest eigenvalue) of the Hessian matrix of the loss surface. This form of regularization on the Hessian is compatible with $\ell_2$ weight decay (and data augmentation), in the sense that combining both can lead to improved empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08553v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haotian Ju, Dongyue Li, Hongyang R. Zhang</dc:creator>
    </item>
    <item>
      <title>Lion Secretly Solves Constrained Optimization: As Lyapunov Predicts</title>
      <link>https://arxiv.org/abs/2310.05898</link>
      <description>arXiv:2310.05898v5 Announce Type: replace-cross 
Abstract: Lion (Evolved Sign Momentum), a new optimizer discovered through program search, has shown promising results in training large AI models. It performs comparably or favorably to AdamW but with greater memory efficiency. As we can expect from the results of a random search program, Lion incorporates elements from several existing algorithms, including signed momentum, decoupled weight decay, Polak, and Nesterov momentum, but does not fit into any existing category of theoretically grounded optimizers. Thus, even though Lion appears to perform well as a general-purpose optimizer for a wide range of tasks, its theoretical basis remains uncertain. This lack of theoretical clarity limits opportunities to further enhance and expand Lion's efficacy.
  This work aims to demystify Lion. Based on both continuous-time and discrete-time analysis, we demonstrate that Lion is a theoretically novel and principled approach for minimizing a general loss function $f(x)$ while enforcing a bound constraint $\|x\|_\infty \leq 1/\lambda$. Lion achieves this through the incorporation of decoupled weight decay, where $\lambda$ represents the weight decay coefficient. Our analysis is made possible by the development of a new Lyapunov function for the Lion updates. It applies to a broader family of Lion-$\kappa$ algorithms, where the $\text{sign}(\cdot)$ operator in Lion is replaced by the subgradient of a convex function $\kappa$, leading to the solution of a general composite optimization problem of $\min_x f(x) + \kappa^*(x)$. Our findings provide valuable insights into the dynamics of Lion and pave the way for further improvements and extensions of Lion-related algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05898v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lizhang Chen, Bo Liu, Kaizhao Liang, Qiang Liu</dc:creator>
    </item>
    <item>
      <title>Revisiting Decentralized ProxSkip: Achieving Linear Speedup</title>
      <link>https://arxiv.org/abs/2310.07983</link>
      <description>arXiv:2310.07983v2 Announce Type: replace-cross 
Abstract: The ProxSkip algorithm for decentralized and federated learning is gaining increasing attention due to its proven benefits in accelerating communication complexity while maintaining robustness against data heterogeneity. However, existing analyses of ProxSkip are limited to the strongly convex setting and do not achieve linear speedup, where convergence performance increases linearly with respect to the number of nodes. So far, questions remain open about how ProxSkip behaves in the non-convex setting and whether linear speedup is achievable.
  In this paper, we revisit decentralized ProxSkip and address both questions. We demonstrate that the leading communication complexity of ProxSkip is $\mathcal{O}\left(\frac{p\sigma^2}{n\epsilon^2}\right)$ for non-convex and convex settings, and $\mathcal{O}\left(\frac{p\sigma^2}{n\epsilon}\right)$ for the strongly convex setting, where $n$ represents the number of nodes, $p$ denotes the probability of communication, $\sigma^2$ signifies the level of stochastic noise, and $\epsilon$ denotes the desired accuracy level. This result illustrates that ProxSkip achieves linear speedup and can asymptotically reduce communication overhead proportional to the probability of communication. Additionally, for the strongly convex setting, we further prove that ProxSkip can achieve linear speedup with network-independent stepsizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07983v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyao Guo, Sulaiman A. Alghunaim, Kun Yuan, Laurent Condat, Jinde Cao</dc:creator>
    </item>
    <item>
      <title>High-probability Convergence Bounds for Nonlinear Stochastic Gradient Descent Under Heavy-tailed Noise</title>
      <link>https://arxiv.org/abs/2310.18784</link>
      <description>arXiv:2310.18784v5 Announce Type: replace-cross 
Abstract: We study high-probability convergence guarantees of learning on streaming data in the presence of heavy-tailed noise. In the proposed scenario, the model is updated in an online fashion, as new information is observed, without storing any additional data. To combat the heavy-tailed noise, we consider a general framework of nonlinear stochastic gradient descent (SGD), providing several strong results. First, for non-convex costs and component-wise nonlinearities, we establish a convergence rate arbitrarily close to $\mathcal{O}\left(t^{-\frac{1}{4}}\right)$, whose exponent is independent of noise and problem parameters. Second, for strongly convex costs and a broader class of nonlinearities, we establish convergence of the last iterate to the optimum, with a rate $\mathcal{O}\left(t^{-\zeta} \right)$, where $\zeta \in (0,1)$ depends on problem parameters, noise and nonlinearity. As we show analytically and numerically, $\zeta$ can be used to inform the preferred choice of nonlinearity for given problem settings. Compared to state-of-the-art, who only consider clipping, require bounded noise moments of order $\eta \in (1,2]$, and establish convergence rates whose exponents go to zero as $\eta \rightarrow 1$, we provide high-probability guarantees for a much broader class of nonlinearities and symmetric density noise, with convergence rates whose exponents are bounded away from zero, even when the noise has finite first moment only. Moreover, in the case of strongly convex functions, we demonstrate analytically and numerically that clipping is not always the optimal nonlinearity, further underlining the value of our general framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.18784v5</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Pranay Sharma, Gauri Joshi, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization</title>
      <link>https://arxiv.org/abs/2311.00944</link>
      <description>arXiv:2311.00944v2 Announce Type: replace-cross 
Abstract: In recent years, federated minimax optimization has attracted growing interest due to its extensive applications in various machine learning tasks. While Smoothed Alternative Gradient Descent Ascent (Smoothed-AGDA) has proved its success in centralized nonconvex minimax optimization, how and whether smoothing technique could be helpful in federated setting remains unexplored. In this paper, we propose a new algorithm termed Federated Stochastic Smoothed Gradient Descent Ascent (FESS-GDA), which utilizes the smoothing technique for federated minimax optimization. We prove that FESS-GDA can be uniformly used to solve several classes of federated minimax problems and prove new or better analytical convergence results for these settings. We showcase the practical efficiency of FESS-GDA in practical federated learning tasks of training generative adversarial networks (GANs) and fair classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00944v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Shen, Minhui Huang, Jiawei Zhang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>Solving Decision-Dependent Games by Learning from Feedback</title>
      <link>https://arxiv.org/abs/2312.17471</link>
      <description>arXiv:2312.17471v2 Announce Type: replace-cross 
Abstract: This paper tackles the problem of solving stochastic optimization problems with a decision-dependent distribution in the setting of stochastic strongly-monotone games and when the distributional dependence is unknown. A two-stage approach is proposed, which initially involves estimating the distributional dependence on decision variables, and subsequently optimizing over the estimated distributional map. The paper presents guarantees for the approximation of the cost of each agent. Furthermore, a stochastic gradient-based algorithm is developed and analyzed for finding the Nash equilibrium in a distributed fashion. Numerical simulations are provided for a novel electric vehicle charging market formulation using real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.17471v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Killian Wood, Ahmed Zamzam, Emiliano Dall'Anese</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of the Linear Quadratic Regulator: A Reinforcement Learning Lens</title>
      <link>https://arxiv.org/abs/2404.10851</link>
      <description>arXiv:2404.10851v2 Announce Type: replace-cross 
Abstract: We provide the first known algorithm that provably achieves $\varepsilon$-optimality within $\widetilde{\mathcal{O}}(1/\varepsilon)$ function evaluations for the discounted discrete-time LQR problem with unknown parameters, without relying on two-point gradient estimates. These estimates are known to be unrealistic in many settings, as they depend on using the exact same initialization, which is to be selected randomly, for two different policies. Our results substantially improve upon the existing literature outside the realm of two-point gradient estimates, which either leads to $\widetilde{\mathcal{O}}(1/\varepsilon^2)$ rates or heavily relies on stability assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10851v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Amirreza Neshaei Moghaddam, Alex Olshevsky, Bahman Gharesifard</dc:creator>
    </item>
  </channel>
</rss>
