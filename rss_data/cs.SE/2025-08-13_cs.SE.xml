<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Aug 2025 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Teaching Code Refactoring Using LLMs</title>
      <link>https://arxiv.org/abs/2508.09332</link>
      <description>arXiv:2508.09332v1 Announce Type: new 
Abstract: This Innovative Practice full paper explores how Large Language Models (LLMs) can enhance the teaching of code refactoring in software engineering courses through real-time, context-aware feedback. Refactoring improves code quality but is difficult to teach, especially with complex, real-world codebases. Traditional methods like code reviews and static analysis tools offer limited, inconsistent feedback. Our approach integrates LLM-assisted refactoring into a course project using structured prompts to help students identify and address code smells such as long methods and low cohesion. Implemented in Spring 2025 in a long-lived OSS project, the intervention is evaluated through student feedback and planned analysis of code quality improvements. Findings suggest that LLMs can bridge theoretical and practical learning, supporting a deeper understanding of maintainability and refactoring principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09332v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anshul Khairnar, Aarya Rajoju, Edward F. Gehringer</dc:creator>
    </item>
    <item>
      <title>Plug it and Play on Logs: A Configuration-Free Statistic-Based Log Parser</title>
      <link>https://arxiv.org/abs/2508.09366</link>
      <description>arXiv:2508.09366v1 Announce Type: new 
Abstract: Log parsing is an essential task in log analysis, and many tools have been designed to accomplish it. Existing log parsers can be categorized into statistic-based and semantic-based approaches. In comparison to semantic-based parsers, existing statistic-based parsers tend to be more efficient, require lower computational costs, and be more privacy-preserving thanks to on-premise deployment, but often fall short in their accuracy (e.g., grouping or parsing accuracy) and generalizability. Therefore, it became a common belief that statistic-based parsers cannot be as effective as semantic-based parsers since the latter could take advantage of external knowledge supported by pretrained language models. Our work, however, challenges this belief with a novel statistic-based parser, PIPLUP. PIPLUP eliminates the pre-assumption of the position of constant tokens for log grouping and relies on data-insensitive parameters to overcome the generalizability challenge, allowing "plug and play" on given log files. According to our experiments on an open-sourced large log dataset, PIPLUP shows promising accuracy and generalizability with the data-insensitive default parameter set. PIPLUP not only outperforms the state-of-the-art statistic-based log parsers, Drain and its variants, but also obtains a competitive performance compared to the best unsupervised semantic-based log parser (i.e., LUNAR). Further, PIPLUP exhibits low time consumption without GPU acceleration and external API usage; our simple, efficient, and effective approach makes it more practical in real-world adoptions, especially when costs and privacy are of major concerns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09366v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiaolin Qin, Xingfang Wu, Heng Li, Ettore Merlo</dc:creator>
    </item>
    <item>
      <title>Your Coding Intent is Secretly in the Context and You Should Deliberately Infer It Before Completion</title>
      <link>https://arxiv.org/abs/2508.09537</link>
      <description>arXiv:2508.09537v1 Announce Type: new 
Abstract: Large Language Models (LLMs) are increasingly used for function completion in repository-scale codebases. Prior studies demonstrate that when explicit instructions--such as docstrings--are provided, these models can generate highly accurate implementations. However, in real-world repositories, such annotations are frequently absent, and performance drops substantially without them. To address this gap, we frame the task as a three-stage process. The first stage focuses on intent inference, where the model analyzes the code preceding the target function to uncover cues about the desired functionality. Such preceding context often encodes subtle but critical information, and we design a reasoning-based prompting framework to guide the LLM through step-by-step extraction and synthesis of these signals before any code is generated. The second stage introduces an optional interactive refinement mechanism to handle cases where preceding context alone is insufficient for intent recovery. In this stage, the model proposes a small set of candidate intentions, enabling the developer to select or edit them so that the inferred intent closely matches the actual requirement. Finally, in the third stage, the LLM generates the target function conditioned on the finalized intent. To support this pipeline, we curate a dataset of 40,000 examples annotated with intermediate reasoning traces and corresponding docstrings. Extensive experiments on DevEval and ComplexCodeEval show that our approach consistently boosts multiple LLMs, achieving over 20\% relative gains in both reference-based and execution-based metrics, with the interactive refinement stage delivering additional improvements beyond these gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09537v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanzhou Li, Tianlin Li, Yiran Zhang, Shangqing Liu, Aishan Liu, Yang Liu</dc:creator>
    </item>
    <item>
      <title>ReqInOne: A Large Language Model-Based Agent for Software Requirements Specification Generation</title>
      <link>https://arxiv.org/abs/2508.09648</link>
      <description>arXiv:2508.09648v1 Announce Type: new 
Abstract: Software Requirements Specification (SRS) is one of the most important documents in software projects, but writing it manually is time-consuming and often leads to ambiguity. Existing automated methods rely heavily on manual analysis, while recent Large Language Model (LLM)-based approaches suffer from hallucinations and limited controllability. In this paper, we propose ReqInOne, an LLM-based agent that follows the common steps taken by human requirements engineers when writing an SRS to convert natural language into a structured SRS. ReqInOne adopts a modular architecture by decomposing SRS generation into three tasks: summary, requirement extraction, and requirement classification, each supported by tailored prompt templates to improve the quality and consistency of LLM outputs.
  We evaluate ReqInOne using GPT-4o, LLaMA 3, and DeepSeek-R1, and compare the generated SRSs against those produced by the holistic GPT-4-based method from prior work as well as by entry-level requirements engineers. Expert evaluations show that ReqInOne produces more accurate and well-structured SRS documents. The performance advantage of ReqInOne benefits from its modular design, and experimental results further demonstrate that its requirement classification component achieves comparable or even better results than the state-of-the-art requirement classification model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09648v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taohong Zhu, Lucas C. Cordeiro, Youcheng Sun</dc:creator>
    </item>
    <item>
      <title>DeputyDev -- AI Powered Developer Assistant: Breaking the Code Review Logjam through Contextual AI to Boost Developer Productivity</title>
      <link>https://arxiv.org/abs/2508.09676</link>
      <description>arXiv:2508.09676v1 Announce Type: new 
Abstract: This study investigates the implementation and efficacy of DeputyDev, an AI-powered code review assistant developed to address inefficiencies in the software development process. The process of code review is highly inefficient for several reasons, such as it being a time-consuming process, inconsistent feedback, and review quality not being at par most of the time. Using our telemetry data, we observed that at TATA 1mg, pull request (PR) processing exhibits significant inefficiencies, with average pick-up and review times of 73 and 82 hours, respectively, resulting in a 6.2 day closure cycle. The review cycle was marked by prolonged iterative communication between the reviewing and submitting parties. Research from the University of California, Irvine indicates that interruptions can lead to an average of 23 minutes of lost focus, critically affecting code quality and timely delivery. To address these challenges, we developed DeputyDev's PR review capabilities by providing automated, contextual code reviews. We conducted a rigorous double-controlled A/B experiment involving over 200 engineers to evaluate DeputyDev's impact on review times. The results demonstrated a statistically significant reduction in both average per PR (23.09%) and average per-line-of-code (40.13%) review durations. After implementing safeguards to exclude outliers, DeputyDev has been effectively rolled out across the entire organisation. Additionally, it has been made available to external companies as a Software-as-a-Service (SaaS) solution, currently supporting the daily work of numerous engineering professionals. This study explores the implementation and effectiveness of AI-assisted code reviews in improving development workflow timelines and code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09676v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishal Khare, Vijay Saini, Deepak Sharma, Anand Kumar, Ankit Rana, Anshul Yadav</dc:creator>
    </item>
    <item>
      <title>Inclusive Employment Pathways: Career Success Factors for Autistic Individuals in Software Engineering</title>
      <link>https://arxiv.org/abs/2508.09680</link>
      <description>arXiv:2508.09680v1 Announce Type: new 
Abstract: Research has highlighted the valuable contributions of autistic individuals in the Information and Communication Technology (ICT) sector, particularly in areas such as software development, testing, and cybersecurity. Their strengths in information processing, attention to detail, innovative thinking, and commitment to high-quality outcomes in the ICT domain are well-documented. However, despite their potential, autistic individuals often face barriers in Software Engineering (SE) roles due to a lack of personalised tools, complex work environments, non-inclusive recruitment practices, limited co-worker support, challenging social dynamics and so on. Motivated by the ethical framework of the neurodiversity movement and the success of pioneering initiatives like the Dandelion program, corporate Diversity, Equity, and Inclusion (DEI) in the ICT sector has increasingly focused on autistic talent. This movement fundamentally reframes challenges not as individual deficits but as failures of environments designed for a neurotypical majority. Despite this progress, there is no synthesis of knowledge reporting the full pathway from software engineering education through to sustainable workplace inclusion. To address this, we conducted a Systematic Review of 30 studies and identified 18 success factors grouped into four thematic categories: (1) Software Engineering Education, (2) Career and Employment Training, (3) Work Environment, and (4) Tools and Assistive Technologies. Our findings offer evidence-based recommendations for educational institutions, employers, organisations, and tool developers to enhance the inclusion of autistic individuals in SE. These include strategies for inclusive meeting and collaboration practices, accessible and structured work environments, clear role and responsibility definitions, and the provision of tailored workplace accommodations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09680v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Orvila Sarker, Mona Jamshaid, M. Ali Babar</dc:creator>
    </item>
    <item>
      <title>LibRec: Benchmarking Retrieval-Augmented LLMs for Library Migration Recommendations</title>
      <link>https://arxiv.org/abs/2508.09791</link>
      <description>arXiv:2508.09791v1 Announce Type: new 
Abstract: In this paper, we propose LibRec, a novel framework that integrates the capabilities of LLMs with retrieval-augmented generation(RAG) techniques to automate the recommendation of alternative libraries. The framework further employs in-context learning to extract migration intents from commit messages to enhance the accuracy of its recommendations. To evaluate the effectiveness of LibRec, we introduce LibEval, a benchmark designed to assess the performance in the library migration recommendation task. LibEval comprises 2,888 migration records associated with 2,368 libraries extracted from 2,324 Python repositories. Each migration record captures source-target library pairs, along with their corresponding migration intents and intent types. Based on LibEval, we evaluated the effectiveness of ten popular LLMs within our framework, conducted an ablation study to examine the contributions of key components within our framework, explored the impact of various prompt strategies on the framework's performance, assessed its effectiveness across various intent types, and performed detailed failure case analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09791v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junxiao Han, Yarong Wang, Xiaodong Gu, Cuiyun Gao, Yao Wan, Song Han, David Lo, Shuiguang Deng</dc:creator>
    </item>
    <item>
      <title>Fast and Accurate Heuristics for Bus-Factor Estimation</title>
      <link>https://arxiv.org/abs/2508.09828</link>
      <description>arXiv:2508.09828v1 Announce Type: new 
Abstract: The bus-factor is a critical risk indicator that quantifies how many key contributors a project can afford to lose before core knowledge or functionality is compromised. Despite its practical importance, accurately computing the bus-factor is NP-Hard under established formalizations, making scalable analysis infeasible for large software systems.
  In this paper, we model software projects as bipartite graphs of developers and tasks and propose two novel approximation heuristics, Minimum Coverage and Maximum Coverage, based on iterative graph peeling, for two influential bus-factor formalizations. Our methods significantly outperform the widely adopted degree-based heuristic, which we show can yield severely inflated estimates.
  We conduct a comprehensive empirical evaluation on over $1\,000$ synthetic power-law graphs and demonstrate that our heuristics provide tighter estimates while scaling to graphs with millions of nodes and edges in minutes. Our results reveal that the proposed heuristics are not only more accurate but also robust to structural variations in developer-task assignment graph. We release our implementation as open-source software to support future research and practical adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09828v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastiano Antonio Piccolo</dc:creator>
    </item>
    <item>
      <title>Exploring the Potential of Large Language Models in Fine-Grained Review Comment Classification</title>
      <link>https://arxiv.org/abs/2508.09832</link>
      <description>arXiv:2508.09832v1 Announce Type: new 
Abstract: Code review is a crucial practice in software development. As code review nowadays is lightweight, various issues can be identified, and sometimes, they can be trivial. Research has investigated automated approaches to classify review comments to gauge the effectiveness of code reviews. However, previous studies have primarily relied on supervised machine learning, which requires extensive manual annotation to train the models effectively. To address this limitation, we explore the potential of using Large Language Models (LLMs) to classify code review comments. We assess the performance of LLMs to classify 17 categories of code review comments. Our results show that LLMs can classify code review comments, outperforming the state-of-the-art approach using a trained deep learning model. In particular, LLMs achieve better accuracy in classifying the five most useful categories, which the state-of-the-art approach struggles with due to low training examples. Rather than relying solely on a specific small training data distribution, our results show that LLMs provide balanced performance across high- and low-frequency categories. These results suggest that the LLMs could offer a scalable solution for code review analytics to improve the effectiveness of the code review process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09832v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linh Nguyen, Chunhua Liu, Hong Yi Lin, Patanamon Thongtanunam</dc:creator>
    </item>
    <item>
      <title>An Empirical Study of CGO Usage in Go Projects -- Distribution, Purposes, Patterns and Critical Issues</title>
      <link>https://arxiv.org/abs/2508.09875</link>
      <description>arXiv:2508.09875v1 Announce Type: new 
Abstract: Multilingual software development integrates multiple languages into a single application, with the Foreign Function Interface (FFI) enabling seamless interaction. While FFI boosts efficiency and extensibility, it also introduces risks. Existing studies focus on FFIs in languages like Python and Java, neglecting CGO, the emerging FFI in Go, which poses unique risks.
  To address these concerns, we conduct an empirical study of CGO usage across 920 open-source Go projects. Our study aims to reveal the distribution, patterns, purposes, and critical issues associated with CGO, offering insights for developers and the Go team. We develop CGOAnalyzer, a tool to efficiently identify and quantify CGO-related features. Our findings reveal that: (1) 11.3% of analyzed Go projects utilize CGO, with usage concentrated in a subset of projects; (2) CGO serves 4 primary purposes, including system-level interactions and performance optimizations, with 15 distinct usage patterns observed; (3) 19 types of CGO-related issues exist, including one critical issue involving unnecessary pointer checks that pose risks of runtime crashes due to limitations in the current Go compilation toolchain; (4) a temporary solution reduces unnecessary pointer checks, mitigating crash risks, and (5) we submitted a proposal to improve the Go toolchain for a permanent fix, which has been grouped within an accepted proposal for future resolution. Our findings provide valuable insights for developers and the Go team, enhancing development efficiency and reliability while improving the robustness of the Go toolchain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09875v1</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinbao Chen, Boyao Ding, Yu Zhang, Qingwei Li, Fugen Tang</dc:creator>
    </item>
    <item>
      <title>Understanding Ethical Practices in AI: Insights from a Cross-Role, Cross-Region Survey of AI Development Teams</title>
      <link>https://arxiv.org/abs/2508.09219</link>
      <description>arXiv:2508.09219v1 Announce Type: cross 
Abstract: Recent advances in AI applications have raised growing concerns about the need for ethical guidelines and regulations to mitigate the risks posed by these technologies. In this paper, we present a mixed-method survey study - combining statistical and qualitative analyses - to examine the ethical perceptions, practices, and knowledge of individuals involved in various AI development roles. Our survey includes 414 participants from 43 countries, representing roles such as AI managers, analysts, developers, quality assurance professionals, and information security and privacy experts. The results reveal varying degrees of familiarity and experience with AI ethics principles, government initiatives, and risk mitigation strategies across roles, regions, and other demographic factors. Our findings highlight the importance of a collaborative, role-sensitive approach, involving diverse stakeholders in ethical decision-making throughout the AI development lifecycle. We advocate for developing tailored, inclusive solutions to address ethical challenges in AI development, and we propose future research directions and educational strategies to promote ethics-aware AI practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09219v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wilder Baldwin, Sepideh Ghanavati, Manuel Woersdoerfer</dc:creator>
    </item>
    <item>
      <title>Extending the OWASP Multi-Agentic System Threat Modeling Guide: Insights from Multi-Agent Security Research</title>
      <link>https://arxiv.org/abs/2508.09815</link>
      <description>arXiv:2508.09815v1 Announce Type: cross 
Abstract: We propose an extension to the OWASP Multi-Agentic System (MAS) Threat Modeling Guide, translating recent anticipatory research in multi-agent security (MASEC) into practical guidance for addressing challenges unique to large language model (LLM)-driven multi-agent architectures. Although OWASP's existing taxonomy covers many attack vectors, our analysis identifies gaps in modeling failures, including, but not limited to: reasoning collapse across planner-executor chains, metric overfitting, unsafe delegation escalation, emergent covert coordination, and heterogeneous multi-agent exploits. We introduce additional threat classes and scenarios grounded in practical MAS deployments, highlighting risks from benign goal drift, cross-agent hallucination propagation, affective prompt framing, and multi-agent backdoors. We also outline evaluation strategies, including robustness testing, coordination assessment, safety enforcement, and emergent behavior monitoring, to ensure complete coverage. This work complements the framework of OWASP by expanding its applicability to increasingly complex, autonomous, and adaptive multi-agent systems, with the goal of improving security posture and resilience in real world deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09815v1</guid>
      <category>cs.MA</category>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Klaudia Krawiecka, Christian Schroeder de Witt</dc:creator>
    </item>
    <item>
      <title>ARI3D: A Software for Interactive Quantification of Regions in X-Ray CT 3D Images</title>
      <link>https://arxiv.org/abs/2508.09849</link>
      <description>arXiv:2508.09849v1 Announce Type: cross 
Abstract: X-ray computed tomography (CT) is the main 3D technique for imaging the internal microstructures of materials. Quantitative analysis of the microstructures is usually achieved by applying a sequence of steps that are implemented to the entire 3D image. This is challenged by various imaging artifacts inherent from the technique, e.g., beam hardening and partial volume. Consequently, the analysis requires users to make a number of decisions to segment and classify the microstructures based on the voxel gray-values. In this context, a software tool, here called ARI3D, is proposed to interactively analyze regions in three-dimensional X-ray CT images, assisting users through the various steps of a protocol designed to classify and quantify objects within regions of a three-dimensional image. ARI3D aims to 1) Improve phase identification; 2) Account for partial volume effect; 3) Increase the detection limit and accuracy of object quantification; and 4) Harmonize quantitative 3D analysis that can be implemented in different fields of science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09849v1</guid>
      <category>cs.CV</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Phillipp Albrecht, Jose R. A. Godinho, Christina H\"ubers, Deborah Schmidt</dc:creator>
    </item>
    <item>
      <title>VulScribeR: Exploring RAG-based Vulnerability Augmentation with LLMs</title>
      <link>https://arxiv.org/abs/2408.04125</link>
      <description>arXiv:2408.04125v4 Announce Type: replace 
Abstract: Detecting vulnerabilities is vital for software security, yet deep learning-based vulnerability detectors (DLVD) face a data shortage, which limits their effectiveness. Data augmentation can potentially alleviate the data shortage, but augmenting vulnerable code is challenging and requires a generative solution that maintains vulnerability. Previous works have only focused on generating samples that contain single statements or specific types of vulnerabilities. Recently, large language models (LLMs) have been used to solve various code generation and comprehension tasks with inspiring results, especially when fused with retrieval augmented generation (RAG). Therefore, we propose VulScribeR, a novel LLM-based solution that leverages carefully curated prompt templates to augment vulnerable datasets. More specifically, we explore three strategies to augment both single and multi-statement vulnerabilities, with LLMs, namely Mutation, Injection, and Extension. Our extensive evaluation across four vulnerability datasets and DLVD models, using three LLMs, show that our approach beats two SOTA methods Vulgen and VGX, and Random Oversampling (ROS) by 27.48%, 27.93%, and 15.41% in f1-score with 5K generated vulnerable samples on average, and 53.84%, 54.10%, 69.90%, and 40.93% with 15K generated vulnerable samples. Our approach demonstrates its feasibility for large-scale data augmentation by generating 1K samples at as cheap as US$ 1.88.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04125v4</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyed Shayan Daneshvar, Yu Nong, Xu Yang, Shaowei Wang, Haipeng Cai</dc:creator>
    </item>
    <item>
      <title>Leveraging Reviewer Experience in Code Review Comment Generation</title>
      <link>https://arxiv.org/abs/2409.10959</link>
      <description>arXiv:2409.10959v2 Announce Type: replace 
Abstract: Modern code review is a ubiquitous software quality assurance process aimed at identifying potential issues within newly written code. Despite its effectiveness, the process demands large amounts of effort from the human reviewers involved. To help alleviate this workload, researchers have trained deep learning models to imitate human reviewers in providing natural language code reviews. Formally, this task is known as code review comment generation. Prior work has demonstrated improvements in this task by leveraging machine learning techniques and neural models, such as transfer learning and the transformer architecture. However, the quality of the model generated reviews remain sub-optimal due to the quality of the open-source code review data used in model training. This is in part due to the data obtained from open-source projects where code reviews are conducted in a public forum, and reviewers possess varying levels of software development experience, potentially affecting the quality of their feedback. To accommodate for this variation, we propose a suite of experience-aware training methods that utilise the reviewers' past authoring and reviewing experiences as signals for review quality. Specifically, we propose experience-aware loss functions (ELF), which use the reviewers' authoring and reviewing ownership of a project as weights in the model's loss function. Through this method, experienced reviewers' code reviews yield larger influence over the model's behaviour. Compared to the SOTA model, ELF was able to generate higher quality reviews in terms of accuracy, informativeness, and comment types generated. The key contribution of this work is the demonstration of how traditional software engineering concepts such as reviewer experience can be integrated into the design of AI-based automated code review models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10959v2</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hong Yi Lin, Patanamon Thongtanunam, Christoph Treude, Michael W. Godfrey, Chunhua Liu, Wachiraphan Charoenwet</dc:creator>
    </item>
    <item>
      <title>AUCAD: Automated Construction of Alignment Dataset from Log-Related Issues for Enhancing LLM-based Log Generation</title>
      <link>https://arxiv.org/abs/2412.18835</link>
      <description>arXiv:2412.18835v2 Announce Type: replace 
Abstract: Log statements have become an integral part of modern software systems. Prior research efforts have focused on supporting the decisions of placing log statements, such as where/what to log. With the increasing adoption of Large Language Models (LLMs) for code-related tasks such as code completion or generation, automated approaches for generating log statements have gained much momentum. However, the performance of these approaches still has a long way to go. This paper explores enhancing the performance of LLM-based solutions for automated log statement generation by post-training LLMs with a purpose-built dataset. Thus the primary contribution is a novel approach called AUCAD, which automatically constructs such a dataset with information extracting from log-related issues. Researchers have long noticed that a significant portion of the issues in the open-source community are related to log statements. However, distilling this portion of data requires manual efforts, which is labor-intensive and costly, rendering it impractical. Utilizing our approach, we automatically extract log-related issues from 1,537 entries of log data across 88 projects and identify 808 code snippets (i.e., methods) with retrievable source code both before and after modification of each issue (including log statements) to construct a dataset. Each entry in the dataset consists of a data pair representing high-quality and problematic log statements, respectively. With this dataset, we proceed to post-train multiple LLMs (primarily from the Llama series) for automated log statement generation. Both human and experimental evaluations indicate that these models significantly outperform existing LLM-based solutions, thereby validating the efficacy of our method for constructing a post-training dataset to enhance LLM-based log statement generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18835v2</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3755881.3755889</arxiv:DOI>
      <dc:creator>Hao Zhang, Dongjun Yu, Lei Zhang, Guoping Rong, Yongda Yu, Haifeng Shen, He Zhang, Dong Shao, Hongyu Kuang</dc:creator>
    </item>
    <item>
      <title>Can Automated Feedback Turn Students into Happy Prologians?</title>
      <link>https://arxiv.org/abs/2504.16742</link>
      <description>arXiv:2504.16742v2 Announce Type: replace 
Abstract: Providing valuable and personalized feedback is essential for effective learning, but delivering it promptly can be challenging in large-scale courses. Recent research has explored automated feedback mechanisms across various programming languages and paradigms, including logic programming.
  In this work, we present a student survey were we evaluate the perceived usefulness of different feedback types and identified which are most valued. Our results indicate that students found all implemented feedback types helpful, with automatic testing ranked as the most useful. We also introduce a dataset comprising 7201 correct and incorrect Prolog submissions, along with 200 manually annotated programs labeled with bug types and corresponding corrections. Finally, we explore student preferences for which types of feedback they would most like to see implemented in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16742v2</guid>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo Brancas, Pedro Orvalho, Carolina Carreira, Vasco Manquinho, Ruben Martins</dc:creator>
    </item>
    <item>
      <title>Forecasting steam mass flow in power plants using the parallel hybrid network</title>
      <link>https://arxiv.org/abs/2307.09483</link>
      <description>arXiv:2307.09483v3 Announce Type: replace-cross 
Abstract: Efficient and sustainable power generation is a crucial concern in the energy sector. In particular, thermal power plants grapple with accurately predicting steam mass flow, which is crucial for operational efficiency and cost reduction. In this study, we use a parallel hybrid neural network architecture that combines a parametrized quantum circuit and a conventional feed-forward neural network specifically designed for time-series prediction in industrial settings to enhance predictions of steam mass flow 15 minutes into the future. Our results show that the parallel hybrid model outperforms standalone classical and quantum models, achieving more than 5.7 and 4.9 times lower mean squared error loss on the test set after training compared to pure classical and pure quantum networks, respectively. Furthermore, the hybrid model demonstrates smaller relative errors between the ground truth and the model predictions on the test set, up to 2 times better than the pure classical model. These findings contribute to the broader scientific understanding of how integrating quantum and classical machine learning techniques can be applied to real-world challenges faced by the energy sector, ultimately leading to optimized power plant operations. To our knowledge, this study constitutes the first parallel hybrid quantum-classical architecture deployed on a real-world power-plant dataset, illustrating how near-term quantum resources can already augment classical analytics in the energy sector.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09483v3</guid>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <category>physics.data-an</category>
      <category>quant-ph</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2025.111912</arxiv:DOI>
      <arxiv:journal_reference>Eng. Appl. Artif. Intell. 160, 111912 (2025)</arxiv:journal_reference>
      <dc:creator>Andrii Kurkin, Jonas Hegemann, Mo Kordzanganeh, Alexey Melnikov</dc:creator>
    </item>
    <item>
      <title>Ear-Keeper: A Cross-Platform AI System for Rapid and Accurate Ear Disease Diagnosis</title>
      <link>https://arxiv.org/abs/2308.10610</link>
      <description>arXiv:2308.10610v5 Announce Type: replace-cross 
Abstract: Early and accurate detection systems for ear diseases, powered by deep learning, are essential for preventing hearing impairment and improving population health. However, the limited diversity of existing otoendoscopy datasets and the poor balance between diagnostic accuracy, computational efficiency, and model size have hindered the translation of artificial intelligence (AI) algorithms into healthcare applications. In this study, we constructed a large-scale, multi-center otoendoscopy dataset covering eight common ear diseases and healthy cases. Building upon this resource, we developed Best-EarNet, an ultrafast and lightweight deep learning architecture integrating a novel Local-Global Spatial Feature Fusion Module with a multi-scale supervision strategy, enabling real-time and accurate classification of ear conditions. Leveraging transfer learning, Best-EarNet, with a model size of only 2.94 MB, achieved diagnostic accuracies of 95.23% on an internal test set (22,581 images) and 92.14% on an external test set (1,652 images), while requiring only 0.0125 seconds (80 frames per second) to process a single image on a standard CPU. Further subgroup analysis by gender and age showed consistently excellent performance of Best-EarNet across all demographic groups. To enhance clinical interpretability and user trust, we incorporated Grad-CAM-based visualization, highlighting the specific abnormal ear regions contributing to AI predictions. Most importantly, we developed Ear-Keeper, a cross-platform intelligent diagnosis system built upon Best-EarNet, deployable on smartphones, tablets, and personal computers. Ear-Keeper enables public users and healthcare providers to perform comprehensive real-time video-based ear canal screening, supporting early detection and timely intervention of ear diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10610v5</guid>
      <category>cs.CV</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feiyan Lu, Yubiao Yue, Zhenzhang Li, Meiping Zhang, Wen Luo, Fan Zhang, Tong Liu, Jingyong Shi, Guang Wang, Xinyu Zeng</dc:creator>
    </item>
    <item>
      <title>A Taxonomy of System-Level Attacks on Deep Learning Models in Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2412.04510</link>
      <description>arXiv:2412.04510v2 Announce Type: replace-cross 
Abstract: The advent of deep learning and its astonishing performance has enabled its usage in complex systems, including autonomous vehicles. On the other hand, deep learning models are susceptible to mispredictions when small, adversarial changes are introduced into their input. Such mis-predictions can be triggered in the real world and can result in a failure of the entire system. In recent years, a growing number of research works have investigated ways to mount attacks against autonomous vehicles that exploit deep learning components. Such attacks are directed toward elements of the environment where these systems operate and their effectiveness is assessed in terms of system-level failures triggered by them. There has been however no systematic attempt to analyze and categorize such attacks. In this paper, we present the first taxonomy of system-level attacks against autonomous vehicles. We constructed our taxonomy by selecting 21 highly relevant papers, then we tagged them with 12 top-level taxonomy categories and several sub-categories. The taxonomy allowed us to investigate the attack features, the most attacked components and systems, the underlying threat models, and the failure chains from input perturbation to system-level failure. We distilled several lessons for practitioners and identified possible directions for future work for researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04510v2</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Jamshidiyan Tehrani, Jinhan Kim, Rosmael Zidane Lekeufack Foulefack, Alessandro Marchetto, Paolo Tonella</dc:creator>
    </item>
    <item>
      <title>Performant Automatic BLAS Offloading on Unified Memory Architecture with OpenMP First-Touch Style Data Movement</title>
      <link>https://arxiv.org/abs/2501.00279</link>
      <description>arXiv:2501.00279v4 Announce Type: replace-cross 
Abstract: BLAS is a fundamental building block of advanced linear algebra libraries and many modern scientific computing applications. GPUs are known for their strong arithmetic computing capabilities and are highly suited for BLAS operations. However, porting code to GPUs often requires significant effort, especially for large, complex codes or legacy codes, even for BLAS-heavy applications. While various tools exist to automatically offload BLAS to GPUs, they are often impractical due to the high costs associated with mandatory data transfers. The advent of unified memory architectures in recent GPU designs, such as the NVIDIA Grace-Hopper, allows cache-coherent memory access across all types of memory for both CPU and GPU, potentially eliminating the bottlenecks faced in conventional architectures. This breakthrough paves the way for innovative application developments and porting strategies. Building on our preliminary work demonstrating the potential of automatic *gemm offload, this paper extends the framework to all level-3 BLAS operations and introduces SCILIB-Accel, a novel tool for automatic BLAS offload. SCILIB-Accel leverages the memory coherency in Grace-Hopper and introduces a Device First-Use data movement policy inspired by the OpenMP First-Touch approach in multi-socket CPU programming, minimizing CPU-GPU data transfers for typical scientific computing codes. Additionally, utilizing dynamic binary instrumentation, the tool intercepts BLAS symbols directly from a CPU binary, requiring no code modifications or recompilation. SCILIB-Accel has been evaluated using multiple quantum physics codes on up to a few hundred GPU nodes, yielding promising speedups. Notably, for the LSMS method in the MuST suite, a 3x speedup was achieved on Grace-Hopper compared to Grace-Grace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00279v4</guid>
      <category>cs.DC</category>
      <category>cs.MS</category>
      <category>cs.PF</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junjie Li</dc:creator>
    </item>
    <item>
      <title>Out of Distribution, Out of Luck: How Well Can LLMs Trained on Vulnerability Datasets Detect Top 25 CWE Weaknesses?</title>
      <link>https://arxiv.org/abs/2507.21817</link>
      <description>arXiv:2507.21817v2 Announce Type: replace-cross 
Abstract: Automated vulnerability detection research has made substantial progress, yet its real-world impact remains limited. Current vulnerability datasets suffer from issues including label inaccuracy rates of 20-71%, extensive duplication, and poor coverage of critical CWE types. These issues create a significant "generalization gap" where models achieve misleading self-testing performance (measured on held-out data from the same dataset for training) by exploiting spurious correlations rather than learning true vulnerability patterns. Our analysis reveals that many models experience substantial performance drops of up to 33% when evaluated on independent data, with some performing close to random guessing. To address these limitations, we present a three-part solution. First, we introduce a manually curated test dataset, BenchVul, covering the MITRE Top 25 Most Dangerous CWEs. Second, we construct a high-quality training dataset, TitanVul, comprising 38,863 functions by aggregating seven public sources and applying deduplication and validation using a novel multi-agent LLM framework. Third, we propose a Realistic Vulnerability Generation (RVG) framework, which synthesizes context-aware vulnerability examples for underrepresented but critical CWE types through simulated development workflows. Our evaluation shows the strengths of each component in closing the generalization gap. First, BenchVul shows the limitations of self-testing: models trained on existing datasets, such as BigVul and CVEfixes, experience performance drops on BenchVul (from 0.776 to 0.519 and from 0.713 to 0.607). Second, training models on TitanVul demonstrates improved generalization, with model performance increasing from 0.584 when evaluated on the same dataset to 0.767 when tested on BenchVul. Third, supplementing TitanVul with RVG-generated data yields further gains, increasing model performance by 14.0% to 0.874.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21817v2</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yikun Li, Ngoc Tan Bui, Ting Zhang, Martin Weyssow, Chengran Yang, Xin Zhou, Jinfeng Jiang, Junkai Chen, Huihui Huang, Huu Hung Nguyen, Chiok Yew Ho, Jie Tan, Ruiyin Li, Yide Yin, Han Wei Ang, Frank Liauw, Eng Lieh Ouh, Lwin Khin Shar, David Lo</dc:creator>
    </item>
  </channel>
</rss>
