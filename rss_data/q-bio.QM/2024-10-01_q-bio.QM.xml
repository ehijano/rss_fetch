<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Oct 2024 02:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>ADEPT: A Noninvasive Method for Determining Elastic Properties of Valve Tissue</title>
      <link>https://arxiv.org/abs/2409.19081</link>
      <description>arXiv:2409.19081v1 Announce Type: new 
Abstract: Valvular heart disease accounts for up to 20% of cardiac surgery in the United States. Computer simulation of "virtual interventions" may inform optimal valve repair for a given patient prior to intervention. However, there is a paucity of methods to noninvasively determine in vivo mechanical properties of valve tissue from clinically acquired 3D images, limiting the accuracy of computer prediction and translational potential of in silico valve repairs. Here, we propose ADEPT, A noninvasive method for Determining Elastic Properties of valve Tissue, to overcome this methodological gap. Our framework combines image registration and physics-informed neural networks (PINNs) to estimate material properties of valve tissue from 3D echocardiograms (3DE). The PINN model was validated on a series of benchmarks before being applied to the 3DE of the tricuspid valve in a child with congenital heart disease. Our approach yielded accurate material parameter estimations in the examples accompanying this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19081v1</guid>
      <category>q-bio.QM</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wensi Wu, Mitchell Daneker, Christian Herz, Hannah Dewey, Jeffrey A. Weiss, Alison M. Pouch, Lu Lu, Matthew A. Jolley</dc:creator>
    </item>
    <item>
      <title>Reducing Overtreatment of Indeterminate Thyroid Nodules Using a Multimodal Deep Learning Model</title>
      <link>https://arxiv.org/abs/2409.19171</link>
      <description>arXiv:2409.19171v1 Announce Type: new 
Abstract: Objective: Molecular testing (MT) classifies cytologically indeterminate thyroid nodules as benign or malignant with high sensitivity but low positive predictive value (PPV), only using molecular profiles, ignoring ultrasound (US) imaging and biopsy. We address this limitation by applying attention multiple instance learning (AMIL) to US images.
  Methods: We retrospectively reviewed 333 patients with indeterminate thyroid nodules at UCLA medical center (259 benign, 74 malignant). A multi-modal deep learning AMIL model was developed, combining US images and MT to classify the nodules as benign or malignant and enhance the malignancy risk stratification of MT.
  Results: The final AMIL model matched MT sensitivity (0.946) while significantly improving PPV (0.477 vs 0.448 for MT alone), indicating fewer false positives while maintaining high sensitivity.
  Conclusion: Our approach reduces false positives compared to MT while maintaining the same ability to identify positive cases, potentially reducing unnecessary benign thyroid resections in patients with indeterminate nodules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19171v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreeram Athreya, Andrew Melehy, Sujit Silas Armstrong Suthahar, Vedrana Ivezi\'c, Ashwath Radhachandran, Vivek Sant, Chace Moleta, Henry Zheng, Maitraya Patel, Rinat Masamed, Corey W. Arnold, William Speier</dc:creator>
    </item>
    <item>
      <title>Deciphering Cell Systems: Machine Learning Perspectives And Approaches For The Analysis Of Single-Cell Data</title>
      <link>https://arxiv.org/abs/2409.19482</link>
      <description>arXiv:2409.19482v1 Announce Type: new 
Abstract: This dissertation explores the application of machine learning in molecular biology, focusing on gene expression regulation and cellular behavior at the single-cell level. Using modern neural networks, the research addresses key challenges in cell-cell communication, gene function inference, and protein expression analysis, with a special focus on single-cell RNA sequencing (scRNA-seq) data. Advanced computational methodologies integrating systems biology and neural network techniques were developed to handle the complexity and high-dimensionality of single-cell data, leading to a deeper understanding of genotype-phenotype relationships. This work proposes novel solutions to optimization problems in manifold learning, explores generative models for gene regulatory networks, and simulates gene knockout at single-cell resolution. Furthermore, the research enhances the interpretability of black-box neural models for multimodal data. Key contributions to cellular biology include the analysis of cell-cell interactions and their role in shaping cellular behavior, gene function prediction through knockout simulations, and the investigation of how gene expression patterns translate into protein expression. These findings have implications for understanding disease mechanisms and therapeutic development. Overall, this dissertation advances computational biology by providing new tools and insights into single-cell analysis, offering a valuable resource for future studies on cellular behavior and potential treatments for various diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19482v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongjian Yang</dc:creator>
    </item>
    <item>
      <title>The EAVI EMG/EEG Board: Hybrid physiological sensing</title>
      <link>https://arxiv.org/abs/2409.20026</link>
      <description>arXiv:2409.20026v1 Announce Type: new 
Abstract: We present an update on the EAVI physiological interface, a wireless, microcontroller based hardware design for the acquisition of bioelectrical signals. The system has been updated to process electroencephalogram brain signals in addition to muscle electromyogram. The hardware/firmware system interfaces with host software carrying out feature extraction and signal processing. Recent advances in electronics have made physiological computing applications practical and feasible. However, there is a gap between high end biomedical equipment and consumer DIY solutions. The hardware design we present here bridges this gap, and combines a specialized biosignal acquisition chip mated with a general-purpose microcontroller. It is based on the Texas Instruments ADS129x family a single chip integrated solution for high quality biosignal amplification and digitization. It serves as analogue front end via programmable gain amplifiers to a 24bit delta-sigma analog-digital converter. The microcontroller is the STMicroelectronics STM32F427, a Cortex-M4 family microcontroller with floating point unit . In addition to EMG acquisition, the board includes a Kionix KX122 three-axis accelerometer. The TI and Kionix sensing chipts communicate with the ST microcontroller over an I2C digital serial bus. The board communicates with the host computer or rest of the music system wirelessly over Bluetooth LE 4.2 using an ST SPBTLE-1S transceiver. The board can also communicate over USB where it registers with the host as a class compliant audio and MIDI device. Audio and physiological signals are treated in the same signal processing chain using the OWL framework. The demo will show multichannel EMG, and single channel EEG. We call this hybridization ''ExG''. We will present documentation of the EAVI board used in the lab and on stage, in user studies with neuro-diverse musicians and trained instrumentalists, as well as in performance with the experimental all-female band, Chicks on Speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20026v1</guid>
      <category>q-bio.QM</category>
      <category>eess.SP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.11189290</arxiv:DOI>
      <dc:creator>Atau Tanaka (Goldsmiths College), David Fierro (CICM, MSHPN), Francesco Di Maggio (MSHPN), Martin Klang (ICM), Stephen Whitmarsh (ICM)</dc:creator>
    </item>
    <item>
      <title>Group lasso based selection for high-dimensional mediation analysis</title>
      <link>https://arxiv.org/abs/2409.20036</link>
      <description>arXiv:2409.20036v1 Announce Type: new 
Abstract: Mediation analysis aims to identify and estimate the effect of an exposure on an outcome that is mediated through one or more intermediate variables. In the presence of multiple intermediate variables, two pertinent methodological questions arise: estimating mediated effects when mediators are correlated, and performing high-dimensional mediation analysis when the number of mediators exceeds the sample size. This paper presents a two-step procedure for high-dimensional mediation analysis. The first step selects a reduced number of candidate mediators using an ad-hoc lasso penalty. The second step applies a procedure we previously developed to estimate the mediated and direct effects, accounting for the correlation structure among the retained candidate mediators. We compare the performance of the proposed two-step procedure with state-of-the-art methods using simulated data. Additionally, we demonstrate its practical application by estimating the causal role of DNA methylation in the pathway between smoking and rheumatoid arthritis using real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20036v1</guid>
      <category>q-bio.QM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan J\'erolon (MAP5 - UMR 8145), Flora Alarcon (MAP5 - UMR 8145), Florence Pittion (TIMC), Magali Richard (TIMC), Olivier Fran\c{c}ois (TIMC), Etienne E. Birmel\'e (IRMA), Vittorio Perduca (MAP5 - UMR 8145)</dc:creator>
    </item>
    <item>
      <title>Persistent homology classifies parameter dependence of patterns in Turing systems</title>
      <link>https://arxiv.org/abs/2409.20491</link>
      <description>arXiv:2409.20491v1 Announce Type: new 
Abstract: This paper illustrates a further application of topological data analysis to the study of self-organising models for chemical and biological systems. In particular, we investigate whether topological summaries can capture the parameter dependence of pattern topology in reaction diffusion systems, by examining the homology of sublevel sets of solutions to Turing reaction diffusion systems for a range of parameters. We demonstrate that a topological clustering algorithm can reveal how pattern topology depends on parameters, using the chlorite--iodide--malonic acid system, and the prototypical Schnakenberg system for illustration. In addition, we discuss the prospective application of such clustering, for instance in refining priors for detailed parameter estimation for self-organising systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20491v1</guid>
      <category>q-bio.QM</category>
      <category>math.AT</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reemon Spector, Heather A. Harrington, Eamonn A. Gaffney</dc:creator>
    </item>
    <item>
      <title>Brain Tumor Classification on MRI in Light of Molecular Markers</title>
      <link>https://arxiv.org/abs/2409.19583</link>
      <description>arXiv:2409.19583v1 Announce Type: cross 
Abstract: In research findings, co-deletion of the 1p/19q gene is associated with clinical outcomes in low-grade gliomas. The ability to predict 1p19q status is critical for treatment planning and patient follow-up. This study aims to utilize a specially MRI-based convolutional neural network for brain cancer detection. Although public networks such as RestNet and AlexNet can effectively diagnose brain cancers using transfer learning, the model includes quite a few weights that have nothing to do with medical images. As a result, the diagnostic results are unreliable by the transfer learning model. To deal with the problem of trustworthiness, we create the model from the ground up, rather than depending on a pre-trained model. To enable flexibility, we combined convolution stacking with a dropout and full connect operation, it improved performance by reducing overfitting. During model training, we also supplement the given dataset and inject Gaussian noise. We use three--fold cross-validation to train the best selection model. Comparing InceptionV3, VGG16, and MobileNetV2 fine-tuned with pre-trained models, our model produces better results. On an validation set of 125 codeletion vs. 31 not codeletion images, the proposed network achieves 96.37\% percent F1-score, 97.46\% percent precision, and 96.34\% percent recall when classifying 1p/19q codeletion and not codeletion images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19583v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Springer Nature - Book Series: Transactions on Computational Science &amp; Computational Intelligence, 2022</arxiv:journal_reference>
      <dc:creator>Jun Liu, Geng Yuan, Weihao Zeng, Hao Tang, Wenbin Zhang, Xue Lin, XiaoLin Xu, Dong Huang, Yanzhi Wang</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Guide to Simulation-based Inference in Computational Biology</title>
      <link>https://arxiv.org/abs/2409.19675</link>
      <description>arXiv:2409.19675v1 Announce Type: cross 
Abstract: Computational models are invaluable in capturing the complexities of real-world biological processes. Yet, the selection of appropriate algorithms for inference tasks, especially when dealing with real-world observational data, remains a challenging and underexplored area. This gap has spurred the development of various parameter estimation algorithms, particularly within the realm of Simulation-Based Inference (SBI), such as neural and statistical SBI methods. Limited research exists on how to make informed choices on SBI methods when faced with real-world data, which often results in some form of model misspecification. In this paper, we provide comprehensive guidelines for deciding between SBI approaches for complex biological models. We apply the guidelines to two agent-based models that describe cellular dynamics using real-world data. Our study unveils a critical insight: while neural SBI methods demand significantly fewer simulations for inference results, they tend to yield biased estimations, a trend persistent even with robust variants of these algorithms. On the other hand, the accuracy of statistical SBI methods enhances substantially as the number of simulations increases. This finding suggests that, given a sufficient computational budget, statistical SBI can surpass neural SBI in performance. Our results not only shed light on the efficacy of different SBI methodologies in real-world scenarios but also suggest potential avenues for enhancing neural SBI approaches. This study is poised to be a useful resource for computational biologists navigating the intricate landscape of SBI in biological modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19675v1</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Wang, Ryan P. Kelly, Adrianne L. Jenner, David J. Warne, Christopher Drovandi</dc:creator>
    </item>
    <item>
      <title>A multimodal LLM for the non-invasive decoding of spoken text from brain recordings</title>
      <link>https://arxiv.org/abs/2409.19710</link>
      <description>arXiv:2409.19710v1 Announce Type: cross 
Abstract: Brain-related research topics in artificial intelligence have recently gained popularity, particularly due to the expansion of what multimodal architectures can do from computer vision to natural language processing. Our main goal in this work is to explore the possibilities and limitations of these architectures in spoken text decoding from non-invasive fMRI recordings. Contrary to vision and textual data, fMRI data represent a complex modality due to the variety of brain scanners, which implies (i) the variety of the recorded signal formats, (ii) the low resolution and noise of the raw signals, and (iii) the scarcity of pretrained models that can be leveraged as foundation models for generative learning. These points make the problem of the non-invasive decoding of text from fMRI recordings very challenging. In this paper, we propose and end-to-end multimodal LLM for decoding spoken text from fMRI signals. The proposed architecture is founded on (i) an encoder derived from a specific transformer incorporating an augmented embedding layer for the encoder and a better-adjusted attention mechanism than that present in the state of the art, and (ii) a frozen large language model adapted to align the embedding of the input text and the encoded embedding of brain activity to decode the output text. A benchmark in performed on a corpus consisting of a set of interactions human-human and human-robot interactions where fMRI and conversational signals are recorded synchronously. The obtained results are very promising, as our proposal outperforms the evaluated models, and is able to generate text capturing more accurate semantics present in the ground truth. The implementation code is provided in https://github.com/Hmamouche/brain_decode.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19710v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youssef Hmamouche, Ismail Chihab, Lahoucine Kdouri, Amal El Fallah Seghrouchni</dc:creator>
    </item>
    <item>
      <title>When Molecular GAN Meets Byte-Pair Encoding</title>
      <link>https://arxiv.org/abs/2409.19740</link>
      <description>arXiv:2409.19740v1 Announce Type: cross 
Abstract: Deep generative models, such as generative adversarial networks (GANs), are pivotal in discovering novel drug-like candidates via de novo molecular generation. However, traditional character-wise tokenizers often struggle with identifying novel and complex sub-structures in molecular data. In contrast, alternative tokenization methods have demonstrated superior performance. This study introduces a molecular GAN that integrates a byte level byte-pair encoding tokenizer and employs reinforcement learning to enhance de novo molecular generation. Specifically, the generator functions as an actor, producing SMILES strings, while the discriminator acts as a critic, evaluating their quality. Our molecular GAN also integrates innovative reward mechanisms aimed at improving computational efficiency. Experimental results assessing validity, uniqueness, novelty, and diversity, complemented by detailed visualization analysis, robustly demonstrate the effectiveness of our GAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19740v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huidong Tang, Chen Li, Yasuhiko Morimoto</dc:creator>
    </item>
    <item>
      <title>geom2vec: pretrained GNNs as geometric featurizers for conformational dynamics</title>
      <link>https://arxiv.org/abs/2409.19838</link>
      <description>arXiv:2409.19838v1 Announce Type: cross 
Abstract: Identifying informative low-dimensional features that characterize dynamics in molecular simulations remains a challenge, often requiring extensive hand-tuning and system-specific knowledge. Here, we introduce geom2vec, in which pretrained graph neural networks (GNNs) are used as universal geometric featurizers. By pretraining equivariant GNNs on a large dataset of molecular conformations with a self-supervised denoising objective, we learn transferable structural representations that capture molecular geometric patterns without further fine-tuning. We show that the learned representations can be directly used to analyze trajectory data, thus eliminating the need for manual feature selection and improving robustness of the simulation analysis workflows. Importantly, by decoupling GNN training from training for downstream tasks, we enable analysis of larger molecular graphs with limited computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19838v1</guid>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zihan Pengmei, Chatipat Lorpaiboon, Spencer C. Guo, Jonathan Weare, Aaron R. Dinner</dc:creator>
    </item>
    <item>
      <title>Robust Multi-view Co-expression Network Inference</title>
      <link>https://arxiv.org/abs/2409.19991</link>
      <description>arXiv:2409.19991v1 Announce Type: cross 
Abstract: Unraveling the co-expression of genes across studies enhances the understanding of cellular processes. Inferring gene co-expression networks from transcriptome data presents many challenges, including spurious gene correlations, sample correlations, and batch effects. To address these complexities, we introduce a robust method for high-dimensional graph inference from multiple independent studies. We base our approach on the premise that each dataset is essentially a noisy linear mixture of gene loadings that follow a multivariate $t$-distribution with a sparse precision matrix, which is shared across studies. This allows us to show that we can identify the co-expression matrix up to a scaling factor among other model parameters. Our method employs an Expectation-Maximization procedure for parameter estimation. Empirical evaluation on synthetic and gene expression data demonstrates our method's improved ability to learn the underlying graph structure compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19991v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teodora Pandeva, Martijs Jonker, Leendert Hamoen, Joris Mooij, Patrick Forr\'e</dc:creator>
    </item>
    <item>
      <title>Single-shot reconstruction of three-dimensional morphology of biological cells in digital holographic microscopy using a physics-driven neural network</title>
      <link>https://arxiv.org/abs/2409.20013</link>
      <description>arXiv:2409.20013v1 Announce Type: cross 
Abstract: Recent advances in deep learning-based image reconstruction techniques have led to significant progress in phase retrieval using digital in-line holographic microscopy (DIHM). However, existing deep learning-based phase retrieval methods have technical limitations in generalization performance and three-dimensional (3D) morphology reconstruction from a single-shot hologram of biological cells. In this study, we propose a novel deep learning model, named MorpHoloNet, for single-shot reconstruction of 3D morphology by integrating physics-driven and coordinate-based neural networks. By simulating the optical diffraction of coherent light through a 3D phase shift distribution, the proposed MorpHoloNet is optimized by minimizing the loss between the simulated and input holograms on the sensor plane. Compared to existing DIHM methods that face challenges with twin image and phase retrieval problems, MorpHoloNet enables direct reconstruction of 3D complex light field and 3D morphology of a test sample from its single-shot hologram without requiring multiple phase-shifted holograms or angle scanning. The performance of the proposed MorpHoloNet is validated by reconstructing 3D morphologies and refractive index distributions from synthetic holograms of ellipsoids and experimental holograms of biological cells. The proposed deep learning model is utilized to reconstruct spatiotemporal variations in 3D translational and rotational behaviors and morphological deformations of biological cells from consecutive single-shot holograms captured using DIHM. MorpHoloNet would pave the way for advancing label-free, real-time 3D imaging and dynamic analysis of biological cells under various cellular microenvironments in biomedical and engineering fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20013v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>physics.optics</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jihwan Kim, Youngdo Kim, Hyo Seung Lee, Eunseok Seo, Sang Joon Lee</dc:creator>
    </item>
    <item>
      <title>Manifold-Constrained Nucleus-Level Denoising Diffusion Model for Structure-Based Drug Design</title>
      <link>https://arxiv.org/abs/2409.10584</link>
      <description>arXiv:2409.10584v2 Announce Type: replace 
Abstract: Artificial intelligence models have shown great potential in structure-based drug design, generating ligands with high binding affinities. However, existing models have often overlooked a crucial physical constraint: atoms must maintain a minimum pairwise distance to avoid separation violation, a phenomenon governed by the balance of attractive and repulsive forces. To mitigate such separation violations, we propose NucleusDiff. It models the interactions between atomic nuclei and their surrounding electron clouds by enforcing the distance constraint between the nuclei and manifolds. We quantitatively evaluate NucleusDiff using the CrossDocked2020 dataset and a COVID-19 therapeutic target, demonstrating that NucleusDiff reduces violation rate by up to 100.00% and enhances binding affinity by up to 22.16%, surpassing state-of-the-art models for structure-based drug design. We also provide qualitative analysis through manifold sampling, visually confirming the effectiveness of NucleusDiff in reducing separation violations and improving binding affinities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10584v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.BM</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shengchao Liu, Divin Yan, Weitao Du, Weiyang Liu, Zhuoxinran Li, Hongyu Guo, Christian Borgs, Jennifer Chayes, Anima Anandkumar</dc:creator>
    </item>
    <item>
      <title>A benchmark for computational analysis of animal behavior, using animal-borne tags</title>
      <link>https://arxiv.org/abs/2305.10740</link>
      <description>arXiv:2305.10740v3 Announce Type: replace-cross 
Abstract: Animal-borne sensors (`bio-loggers') can record a suite of kinematic and environmental data, which are used to elucidate animal ecophysiology and improve conservation efforts. Machine learning techniques are used for interpreting the large amounts of data recorded by bio-loggers, but there exists no common framework for comparing the different machine learning techniques in this domain. This makes it difficult to, for example, identify patterns in what works well for machine learning-based analysis of bio-logger data. It also makes it difficult to evaluate the effectiveness of novel methods developed by the machine learning community.
  To address this, we present the Bio-logger Ethogram Benchmark (BEBE), a collection of datasets with behavioral annotations, as well as a modeling task and evaluation metrics. BEBE is to date the largest, most taxonomically diverse, publicly available benchmark of this type. Using BEBE, we compare the performance of deep and classical machine learning methods for identifying animal behaviors based on bio-logger data. As an example usage of BEBE, we test an approach based on self-supervised learning. To apply this approach to animal behavior classification, we adapt a deep neural network pre-trained with 700,000 hours of data collected from human wrist-worn accelerometers.
  We find that deep neural networks out-perform the classical machine learning methods we tested across all nine datasets in BEBE. We additionally find that the approach based on self-supervised learning out-performs the alternatives we tested, especially in settings when there is a low amount of training data available. In light of this, we are able to make concrete suggestions for designing studies that rely on machine learning to infer behavior from bio-logger data. Datasets and code are available at https://github.com/earthspecies/BEBE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10740v3</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Hoffman, Maddie Cusimano, Vittorio Baglione, Daniela Canestrari, Damien Chevallier, Dominic L. DeSantis, Lor\`ene Jeantet, Monique A. Ladds, Takuya Maekawa, Vicente Mata-Silva, V\'ictor Moreno-Gonz\'alez, Anthony Pagano, Eva Trapote, Outi Vainio, Antti Vehkaoja, Ken Yoda, Katherine Zacarian, Ari Friedlaender</dc:creator>
    </item>
    <item>
      <title>Improved prediction of ligand-protein binding affinities by meta-modeling</title>
      <link>https://arxiv.org/abs/2310.03946</link>
      <description>arXiv:2310.03946v4 Announce Type: replace-cross 
Abstract: The accurate screening of candidate drug ligands against target proteins through computational approaches is of prime interest to drug development efforts. Such virtual screening depends in part on methods to predict the binding affinity between ligands and proteins. Many computational models for binding affinity prediction have been developed, but with varying results across targets. Given that ensembling or meta-modeling approaches have shown great promise in reducing model-specific biases, we develop a framework to integrate published force-field-based empirical docking and sequence-based deep learning models. In building this framework, we evaluate many combinations of individual base models, training databases, and several meta-modeling approaches. We show that many of our meta-models significantly improve affinity predictions over base models. Our best meta-models achieve comparable performance to state-of-the-art deep learning tools exclusively based on 3D structures, while allowing for improved database scalability and flexibility through the explicit inclusion of features such as physicochemical properties or molecular descriptors. We further demonstrate improved generalization capability by our models using a large-scale benchmark of affinity prediction as well as a virtual screening application benchmark. Overall, we demonstrate that diverse modeling approaches can be ensembled together to gain meaningful improvement in binding affinity prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03946v4</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ho-Joon Lee, Prashant S. Emani, Mark B. Gerstein</dc:creator>
    </item>
    <item>
      <title>Recent progress in the physical principles of dynamic ground self-righting</title>
      <link>https://arxiv.org/abs/2402.16747</link>
      <description>arXiv:2402.16747v3 Announce Type: replace-cross 
Abstract: Animals and robots must self-right on the ground after overturning. Biology research described various strategies and motor patterns in many species. Robotics research devised many strategies. However, we do not well understand how the physical principles of how the need to generate mechanical energy to overcome the potential energy barrier governs behavioral strategies and 3-D body rotations given the morphology. Here I review progress on this which I led studying cockroaches self-righting on level, flat, solid, low-friction ground, by integrating biology experiments, robotic modeling, and physics modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16747v3</guid>
      <category>physics.bio-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1093/icb/icae124</arxiv:DOI>
      <arxiv:journal_reference>Integrative &amp; Comparative Biology (2024), 64 (3), 674-693</arxiv:journal_reference>
      <dc:creator>Chen Li</dc:creator>
    </item>
    <item>
      <title>Can virtual staining for high-throughput screening generalize?</title>
      <link>https://arxiv.org/abs/2407.06979</link>
      <description>arXiv:2407.06979v3 Announce Type: replace-cross 
Abstract: The large volume and variety of imaging data from high-throughput screening (HTS) in the pharmaceutical industry present an excellent resource for training virtual staining models. However, the potential of models trained under one set of experimental conditions to generalize to other conditions remains underexplored. This study systematically investigates whether data from three cell types (lung, ovarian, and breast) and two phenotypes (toxic and non-toxic conditions) commonly found in HTS can effectively train virtual staining models to generalize across three typical HTS distribution shifts: unseen phenotypes, unseen cell types, and the combination of both. Utilizing a dataset of 772,416 paired bright-field, cytoplasm, nuclei, and DNA-damage stain images, we evaluate the generalization capabilities of models across pixel-based, instance-wise, and biological-feature-based levels. Our findings indicate that training virtual nuclei and cytoplasm models on non-toxic condition samples not only generalizes to toxic condition samples but leads to improved performance across all evaluation levels compared to training on toxic condition samples. Generalization to unseen cell types shows variability depending on the cell type; models trained on ovarian or lung cell samples often perform well under other conditions, while those trained on breast cell samples consistently show poor generalization. Generalization to unseen cell types and phenotypes shows good generalization across all levels of evaluation compared to addressing unseen cell types alone. This study represents the first large-scale, data-centric analysis of the generalization capability of virtual staining models trained on diverse HTS datasets, providing valuable strategies for experimental training data generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06979v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Samuel Tonks, Cuong Nguyen, Steve Hood, Ryan Musso, Ceridwen Hopely, Steve Titus, Minh Doan, Iain Styles, Alexander Krull</dc:creator>
    </item>
    <item>
      <title>ReactZyme: A Benchmark for Enzyme-Reaction Prediction</title>
      <link>https://arxiv.org/abs/2408.13659</link>
      <description>arXiv:2408.13659v3 Announce Type: replace-cross 
Abstract: Enzymes, with their specific catalyzed reactions, are necessary for all aspects of life, enabling diverse biological processes and adaptations. Predicting enzyme functions is essential for understanding biological pathways, guiding drug development, enhancing bioproduct yields, and facilitating evolutionary studies. Addressing the inherent complexities, we introduce a new approach to annotating enzymes based on their catalyzed reactions. This method provides detailed insights into specific reactions and is adaptable to newly discovered reactions, diverging from traditional classifications by protein family or expert-derived reaction classes. We employ machine learning algorithms to analyze enzyme reaction datasets, delivering a much more refined view on the functionality of enzymes. Our evaluation leverages the largest enzyme-reaction dataset to date, derived from the SwissProt and Rhea databases with entries up to January 8, 2024. We frame the enzyme-reaction prediction as a retrieval problem, aiming to rank enzymes by their catalytic ability for specific reactions. With our model, we can recruit proteins for novel reactions and predict reactions in novel proteins, facilitating enzyme discovery and function annotation (https://github.com/WillHua127/ReactZyme).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13659v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>38th Conference on Neural Information Processing Systems (NeurIPS 2024) Track on Datasets and Benchmarks</arxiv:journal_reference>
      <dc:creator>Chenqing Hua, Bozitao Zhong, Sitao Luan, Liang Hong, Guy Wolf, Doina Precup, Shuangjia Zheng</dc:creator>
    </item>
  </channel>
</rss>
