<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 04:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Resilient LLM-Empowered Semantic MAC Protocols via Zero-Shot Adaptation and Knowledge Distillation</title>
      <link>https://arxiv.org/abs/2505.21518</link>
      <description>arXiv:2505.21518v1 Announce Type: new 
Abstract: Neural network-based medium access control (MAC) protocol models (NPMs) improve goodput through site-specific operations but are vulnerable to shifts from their training network environments, such as changes in the number of user equipments (UEs) severely degrade goodput. To enhance resilience against such environmental shifts, we propose three novel semantic MAC protocol frameworks empowered by large language models (LLMs). First, we introduce a token-based protocol model (TPM), where an LLM generates MAC signaling messages. By editing LLM instruction prompts, TPM enables instant adaptation, which can be further enhanced by TextGrad, an LLM-based automated prompt optimizer. TPM inference is fast but coarse due to the lack of real interactions with the changed environment, and computationally intensive due to the large size of the LLM. To improve goodput and computation efficiency, we develop T2NPM, which transfers and augments TPM knowledge into an NPM via knowledge distillation (KD). Integrating TPM and T2NPM, we propose T3NPM, which employs TPM in the early phase and switches to T2NPM later. To optimize this phase switching, we design a novel metric of meta-resilience, which quantifies resilience to unknown target goodput after environmental shifts. Simulations corroborate that T3NPM achieves 20.56% higher meta-resilience than NPM with 19.8x lower computation cost than TPM in FLOPS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21518v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjun Kim, Jihong Park, Mehdi Bennis, Junil Choi</dc:creator>
    </item>
    <item>
      <title>Prospects and challenges of Bluetooth backscatters system</title>
      <link>https://arxiv.org/abs/2505.21526</link>
      <description>arXiv:2505.21526v1 Announce Type: new 
Abstract: Bluetooth backscatter systems, as a crucial technology for low-power communication in the Internet of Things (IoT), have witnessed remarkable development in recent years. This article comprehensively analyzes multiple related papers, including the latest advancements in RF-Transformer and B2Loc systems, summarizes their research progress, challenges faced, and classification, and explores the application prospects and future development directions of such systems. Bluetooth backscatter systems have achieved significant results in terms of compatibility with commercial devices, improvement of communication reliability, and increase in throughput. However, they still face challenges in areas such as communication range, anti-interference ability, and hardware costs. In the future, with continuous technological innovation exemplified by breakthroughs in unified hardware abstraction and decimeter-level localization, Bluetooth backscatter systems are expected to play a more significant role in the IoT field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21526v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyun Du</dc:creator>
    </item>
    <item>
      <title>WakeMod: A 6.9uW Wake-Up Radio Module with -72.6dBm Sensitivity for On-Demand IoT</title>
      <link>https://arxiv.org/abs/2505.21529</link>
      <description>arXiv:2505.21529v1 Announce Type: new 
Abstract: Large-scale Internet of Things (IoT) applications, such as asset tracking and remote sensing, demand multi-year battery lifetimes to minimize maintenance and operational costs. Traditional wireless protocols often employ duty cycling, introducing a tradeoff between latency and idle consumption - both unsuitable for event-driven and ultra-low power systems. A promising approach to address these issues is the integration of always-on wake-up radios (WuRs). They provide asynchronous, ultra-low power communication to overcome these constraints.
  This paper presents WakeMod, an open-source wake-up transceiver module for the 868MHz ISM band. Designed for easy integration and ultra-low power consumption, it leverages the -75dBm sensitive FH101RF WuR. WakeMod achieves a low idle power consumption of 6.9uW while maintaining responsiveness with a sensitivity of -72.6dBm. Reception of a wake-up call is possible from up to 130m of distance with a -2.1dBi antenna, consuming 17.7uJ with a latency below 54.3ms. WakeMod's capabilities have further been demonstrated in an e-ink price tag application, achieving 7.17uW idle consumption and enabling an estimated 8-year battery life with daily updates on a standard CR2032 coin cell. WakeMod offers a practical solution for energy-constrained, long-term IoT deployments, requiring low-latency, and on-demand communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21529v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Schulthess, Silvano Cortesi, Michele Magno</dc:creator>
    </item>
    <item>
      <title>Collaborative Agentic AI Needs Interoperability Across Ecosystems</title>
      <link>https://arxiv.org/abs/2505.21550</link>
      <description>arXiv:2505.21550v1 Announce Type: new 
Abstract: Collaborative agentic AI is projected to transform entire industries by enabling AI-powered agents to autonomously perceive, plan, and act within digital environments. Yet, current solutions in this field are all built in isolation, and we are rapidly heading toward a landscape of fragmented, incompatible ecosystems. In this position paper, we argue that interoperability, achieved by the adoption of minimal standards, is essential to ensure open, secure, web-scale, and widely-adopted agentic ecosystems. To this end, we devise a minimal architectural foundation for collaborative agentic AI, named Web of Agents, which is composed of four components: agent-to-agent messaging, interaction interoperability, state management, and agent discovery. Web of Agents adopts existing standards and reuses existing infrastructure where possible. With Web of Agents, we take the first but critical step toward interoperable agentic systems and offer a pragmatic path forward before ecosystem fragmentation becomes the norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21550v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rishi Sharma, Martijn de Vos, Pradyumna Chari, Ramesh Raskar, Anne-Marie Kermarrec</dc:creator>
    </item>
    <item>
      <title>MetaSTNet: Multimodal Meta-learning for Cellular Traffic Conformal Prediction</title>
      <link>https://arxiv.org/abs/2505.21553</link>
      <description>arXiv:2505.21553v1 Announce Type: new 
Abstract: Network traffic prediction techniques have attracted much attention since they are valuable for network congestion control and user experience improvement. While existing prediction techniques can achieve favorable performance when there is sufficient training data, it remains a great challenge to make accurate predictions when only a small amount of training data is available. To tackle this problem, we propose a deep learning model, entitled MetaSTNet, based on a multimodal meta-learning framework. It is an end-to-end network architecture that trains the model in a simulator and transfers the meta-knowledge to a real-world environment, which can quickly adapt and obtain accurate predictions on a new task with only a small amount of real-world training data. In addition, we further employ cross conformal prediction to assess the calibrated prediction intervals. Extensive experiments have been conducted on real-world datasets to illustrate the efficiency and effectiveness of MetaSTNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21553v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Ma, Kai Yang</dc:creator>
    </item>
    <item>
      <title>Fog Intelligence for Network Anomaly Detection</title>
      <link>https://arxiv.org/abs/2505.21563</link>
      <description>arXiv:2505.21563v1 Announce Type: new 
Abstract: Anomalies are common in network system monitoring. When manifested as network threats to be mitigated, service outages to be prevented, and security risks to be ameliorated, detecting such anomalous network behaviors becomes of great importance. However, the growing scale and complexity of the mobile communication networks, as well as the ever-increasing amount and dimensionality of the network surveillance data, make it extremely difficult to monitor a mobile network and discover abnormal network behaviors. Recent advances in machine learning allow for obtaining near-optimal solutions to complicated decision-making problems with many sources of uncertainty that cannot be accurately characterized by traditional mathematical models. However, most machine learning algorithms are centralized, which renders them inapplicable to a large-scale distributed wireless networks with tens of millions of mobile devices. In this article, we present fog intelligence, a distributed machine learning architecture that enables intelligent wireless network management. It preserves the advantage of both edge processing and centralized cloud computing. In addition, the proposed architecture is scalable, privacy-preserving, and well suited for intelligent management of a distributed wireless network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21563v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.001.1900156</arxiv:DOI>
      <dc:creator>Kai Yang, Hui Ma, Shaoyu Dou</dc:creator>
    </item>
    <item>
      <title>Scrapers selectively respect robots.txt directives: evidence from a large-scale empirical study</title>
      <link>https://arxiv.org/abs/2505.21733</link>
      <description>arXiv:2505.21733v1 Announce Type: new 
Abstract: Online data scraping has taken on new dimensions in recent years, as traditional scrapers have been joined by new AI-specific bots. To counteract unwanted scraping, many sites use tools like the Robots Exclusion Protocol (REP), which places a robots.txt file at the site root to dictate scraper behavior. Yet, the efficacy of the REP is not well-understood. Anecdotal evidence suggests some bots comply poorly with it, but no rigorous study exists to support (or refute) this claim. To understand the merits and limits of the REP, we conduct the first large-scale study of web scraper compliance with robots.txt directives using anonymized web logs from our institution. We analyze the behavior of 130 self-declared bots (and many anonymous ones) over 40 days, using a series of controlled robots.txt experiments. We find that bots are less likely to comply with stricter robots.txt directives, and that certain categories of bots, including AI search crawlers, rarely check robots.txt at all. These findings suggest that relying on robots.txt files to prevent unwanted scraping is risky and highlight the need for alternative approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21733v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taein Kim, Karstan Bock, Claire Luo, Amanda Liswood, Emily Wenger</dc:creator>
    </item>
    <item>
      <title>Video Streaming Over QUIC: A Comprehensive Study</title>
      <link>https://arxiv.org/abs/2505.21769</link>
      <description>arXiv:2505.21769v1 Announce Type: new 
Abstract: The QUIC transport protocol represents a significant evolution in web transport technologies, offering improved performance and reduced latency compared to traditional protocols like TCP. Given the growing number of QUIC implementations, understanding their performance, particularly in video streaming contexts, is essential. This paper presents a comprehensive analysis of various QUIC implementations, focusing on their congestion control (CC) performance in single-server, multi-client environments. Through extensive trace-driven experiments, we explore how different QUIC CCs impact adaptive bitrate (ABR) algorithms in two video streaming scenarios: video-on-demand (VoD) and low-latency live streaming (LLL). Our study aims to shed light on the impact of QUIC CC implementations, queuing strategies, and cooperative versus competitive dynamics of QUIC streams on user QoE under diverse network conditions. Our results demonstrate that identical CC algorithms across different QUIC implementations can lead to significant performance variations, directly impacting the QoE of video streaming sessions. These findings offer valuable insights into the effectiveness of various QUIC implementations and their implications for optimizing QoE, underscoring the need for intelligent cross-layer designs that integrate QUIC CC and ABR schemes to enhance overall streaming performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21769v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jashanjot Singh Sidhu, Abdelhak Bentaleb</dc:creator>
    </item>
    <item>
      <title>Leveraging 5G Physical Layer Monitoring for Adaptive Remote Rendering in XR Applications</title>
      <link>https://arxiv.org/abs/2505.22123</link>
      <description>arXiv:2505.22123v1 Announce Type: new 
Abstract: As immersive eXtended Reality (XR) applications demand substantial network resources, understanding their interaction with 5G networks becomes crucial to improve them. This paper investigates the role of 5G physical-layer monitoring to manage and enhance the remote rendering of XR content dynamically. By observing network metrics directly from the physical layer, we propose a system to adapt streaming parameters such as bitrate, framerate, and resolution in real time based on available network capacity. Using theoretical formulas to estimate maximum data rate, our approach evaluates network resource availability, enabling the renderer to self-adjust media content representation. This is critical for providing consistent and smooth XR experiences to users, especially as network conditions fluctuate. Our findings suggest that physical-layer monitoring offers valuable insights to increase the Quality of Service (QoS) and has the potential to elevate user experience in remote-rendered XR applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22123v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Inhar Yeregui, Daniel Mej\'ias, Mikel Zorrilla, Roberto Viola, Jasone Astorga, Eduardo Jacob</dc:creator>
    </item>
    <item>
      <title>Streaming Remote rendering services: Comparison of QUIC-based and WebRTC Protocols</title>
      <link>https://arxiv.org/abs/2505.22132</link>
      <description>arXiv:2505.22132v1 Announce Type: new 
Abstract: The proliferation of Extended Reality (XR) applications, requiring high-quality, low-latency media streaming, has driven the demand for efficient remote rendering solutions. This paper focuses on holographic conferencing in virtual environments and their required uplink and downlink media transmission capabilities. By examining Media over QUIC (MoQ), Real-time Transport Protocol (RTP) over QUIC (RoQ), and Web Real-Time Communication (WebRTC), we assess their latency performance over Wi-Fi and 5G networks. Improvements of approximately 30% in latency and 60% in connection startup are expected in QUIC-based protocols compared to WebRTC. The experimental setup transmits a remote-rendered virtual experience using real-time video streaming protocols to provide the content to the participant. Our findings contribute to understanding the maturity of streaming protocols, particularly within open-source frameworks, and evaluate their suitability in supporting latency-sensitive XR applications. The study highlights specific protocol advantages across varied remote rendering scenarios, informing the design of future XR communication solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22132v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Mej\'ias, Inhar Yeregui, \'Angel Mart\'in, Roberto Viola, Pablo Angueira, Jon Montalb\'an</dc:creator>
    </item>
    <item>
      <title>Real-World Modeling of Computation Offloading for Neural Networks with Early Exits and Splits</title>
      <link>https://arxiv.org/abs/2505.22149</link>
      <description>arXiv:2505.22149v1 Announce Type: new 
Abstract: We focus on computation offloading of applications based on convolutional neural network (CNN) from moving devices, such as mobile robots or autonomous vehicles, to MultiAccess Edge Computing (MEC) servers via a mobile network. In order to reduce overall CNN inference time, we design and implement CNN with early exits and splits, allowing a flexible partial or full offloading of CNN inference. Through real-world experiments, we analyze an impact of the CNN inference offloading on the total CNN processing delay, energy consumption, and classification accuracy in a practical road sign recognition task. The results confirm that offloading of CNN with early exits and splits can significantly reduce both total processing delay and energy consumption compared to full local processing while not impairing classification accuracy. Based on the results of real-world experiments, we derive practical models for energy consumption and total processing delay related to offloading of CNN with early exits and splits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22149v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Danek, Zdenek Becvar, Adam Janes</dc:creator>
    </item>
    <item>
      <title>Chain-of-Thought for Large Language Model-empowered Wireless Communications</title>
      <link>https://arxiv.org/abs/2505.22320</link>
      <description>arXiv:2505.22320v1 Announce Type: new 
Abstract: Recent advances in large language models (LLMs) have opened new possibilities for automated reasoning and decision-making in wireless networks. However, applying LLMs to wireless communications presents challenges such as limited capability in handling complex logic, generalization, and reasoning. Chain-of-Thought (CoT) prompting, which guides LLMs to generate explicit intermediate reasoning steps, has been shown to significantly improve LLM performance on complex tasks. Inspired by this, this paper explores the application potential of CoT-enhanced LLMs in wireless communications. Specifically, we first review the fundamental theory of CoT and summarize various types of CoT. We then survey key CoT and LLM techniques relevant to wireless communication and networking. Moreover, we introduce a multi-layer intent-driven CoT framework that bridges high-level user intent expressed in natural language with concrete wireless control actions. Our proposed framework sequentially parses and clusters intent, selects appropriate CoT reasoning modules via reinforcement learning, then generates interpretable control policies for system configuration. Using the unmanned aerial vehicle (UAV) network as a case study, we demonstrate that the proposed framework significantly outperforms a non-CoT baseline in both communication performance and quality of generated reasoning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22320v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xudong Wang, Jian Zhu, Ruichen Zhang, Lei Feng, Dusit Niyato, Jiacheng Wang, Hongyang Du, Shiwen Mao, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Hybrid Learning for Cold-Start-Aware Microservice Scheduling in Dynamic Edge Environments</title>
      <link>https://arxiv.org/abs/2505.22424</link>
      <description>arXiv:2505.22424v1 Announce Type: new 
Abstract: With the rapid growth of IoT devices and their diverse workloads, container-based microservices deployed at edge nodes have become a lightweight and scalable solution. However, existing microservice scheduling algorithms often assume static resource availability, which is unrealistic when multiple containers are assigned to an edge node. Besides, containers suffer from cold-start inefficiencies during early-stage training in currently popular reinforcement learning (RL) algorithms. In this paper, we propose a hybrid learning framework that combines offline imitation learning (IL) with online Soft Actor-Critic (SAC) optimization to enable a cold-start-aware microservice scheduling with dynamic allocation for computing resources. We first formulate a delay-and-energy-aware scheduling problem and construct a rule-based expert to generate demonstration data for behavior cloning. Then, a GRU-enhanced policy network is designed in the policy network to extract the correlation among multiple decisions by separately encoding slow-evolving node states and fast-changing microservice features, and an action selection mechanism is given to speed up the convergence. Extensive experiments show that our method significantly accelerates convergence and achieves superior final performance. Compared with baselines, our algorithm improves the total objective by $50\%$ and convergence speed by $70\%$, and demonstrates the highest stability and robustness across various edge configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22424v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingxi Lu, Wenhao Li, Jianxiong Guo, Xingjian Ding, Zhiqing Tang, Tian Wang, Weijia Jia</dc:creator>
    </item>
    <item>
      <title>Frequency Resource Management in 6G User-Centric CFmMIMO: A Hybrid Reinforcement Learning and Metaheuristic Approach</title>
      <link>https://arxiv.org/abs/2505.22443</link>
      <description>arXiv:2505.22443v1 Announce Type: new 
Abstract: As sixth-generation (6G) networks continue to evolve, AI-driven solutions are playing a crucial role in enabling more efficient and adaptive resource management in wireless communication. One of the key innovations in 6G is user-centric cell-free massive Multiple-Input Multiple-Output (UC-CFmMIMO), a paradigm that eliminates traditional cell boundaries and enhances network performance by dynamically assigning access points (APs) to users. This approach is particularly well-suited for vehicular networks, offering seamless, homogeneous, ultra-reliable, and low-latency connectivity. However, in dense networks, a key challenge lies in efficiently allocating frequency resources within a limited shared subband spectrum while accounting for frequency selectivity and the dependency of signal propagation on bandwidth. These factors make resource allocation increasingly complex, especially in dynamic environments where maintaining Quality of Service (QoS) is critical. This paper tackles these challenges by proposing a hybrid multi-user allocation strategy that integrates reinforcement learning (RL) and metaheuristic optimization to enhance spectral efficiency (SE), ensure fairness, and mitigate interference within shared subbands. To assess its effectiveness, we compare this hybrid approach with two other methods: the bio-inspired Aquila Optimizer (AO) and Deep Deterministic Policy Gradient (DDPG)-based Actor-Critic Reinforcement Learning (AC-RL). Our evaluation is grounded in real-world patterns and channel characteristics, utilizing the 3GPP-3D channel modeling framework (QuaDRiGa) to capture realistic propagation conditions. The results demonstrate that the proposed hybrid strategy achieves a superior balance among competing objectives, underscoring the role of AI-driven resource allocation in advancing UC-CFmMIMO systems for next-generation wireless networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22443v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Selina Cheggour, Valeria Loscri</dc:creator>
    </item>
    <item>
      <title>Real-World Deployment of Cloud Autonomous Mobility System Using 5G Networks for Outdoor and Indoor Environments</title>
      <link>https://arxiv.org/abs/2505.21676</link>
      <description>arXiv:2505.21676v1 Announce Type: cross 
Abstract: The growing complexity of both outdoor and indoor mobility systems demands scalable, cost-effective, and reliable perception and communication frameworks. This work presents the real-world deployment and evaluation of a Cloud Autonomous Mobility (CAM) system that leverages distributed sensor nodes connected via 5G networks, which integrates LiDAR- and camera-based perception at infrastructure units, cloud computing for global information fusion, and Ultra-Reliable Low Latency Communications (URLLC) to enable real-time situational awareness and autonomous operation. The CAM system is deployed in two distinct environments: a dense urban roundabout and a narrow indoor hospital corridor. Field experiments show improved traffic monitoring, hazard detection, and asset management capabilities. The paper also discusses practical deployment challenges and shares key insights for scaling CAM systems. The results highlight the potential of cloud-based infrastructure perception to advance both outdoor and indoor intelligent transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21676v1</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufeng Yang, Minghao Ning, Keqi Shu, Aladdin Saleh, Ehsan Hashemi, Amir Khajepour</dc:creator>
    </item>
    <item>
      <title>A Joint Reconstruction-Triplet Loss Autoencoder Approach Towards Unseen Attack Detection in IoV Networks</title>
      <link>https://arxiv.org/abs/2505.21703</link>
      <description>arXiv:2505.21703v1 Announce Type: cross 
Abstract: Internet of Vehicles (IoV) systems, while offering significant advancements in transportation efficiency and safety, introduce substantial security vulnerabilities due to their highly interconnected nature. These dynamic systems produce massive amounts of data between vehicles, infrastructure, and cloud services and present a highly distributed framework with a wide attack surface. In considering network-centered attacks on IoV systems, attacks such as Denial-of-Service (DoS) can prohibit the communication of essential physical traffic safety information between system elements, illustrating that the security concerns for these systems go beyond the traditional confidentiality, integrity, and availability concerns of enterprise systems. Given the complexity and volume of data generated by IoV systems, traditional security mechanisms are often inadequate for accurately detecting sophisticated and evolving cyberattacks. Here, we present an unsupervised autoencoder method trained entirely on benign network data for the purpose of unseen attack detection in IoV networks. We leverage a weighted combination of reconstruction and triplet margin loss to guide the autoencoder training and develop a diverse representation of the benign training set. We conduct extensive experiments on recent network intrusion datasets from two different application domains, industrial IoT and home IoT, that represent the modern IoV task. We show that our method performs robustly for all unseen attack types, with roughly 99% accuracy on benign data and between 97% and 100% performance on anomaly data. We extend these results to show that our model is adaptable through the use of transfer learning, achieving similarly high results while leveraging domain features from one domain to another.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21703v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julia Boone, Tolunay Seyfi, Fatemeh Afghah</dc:creator>
    </item>
    <item>
      <title>Multi-photon QKD for Practical Quantum Networks</title>
      <link>https://arxiv.org/abs/2505.21726</link>
      <description>arXiv:2505.21726v1 Announce Type: cross 
Abstract: Quantum key distribution (QKD) will most likely be an integral part of any practical quantum network in the future. However, not all QKD protocols can be used in today's networks because of the lack of single-photon emitters and noisy intermediate quantum hardware. Attenuated-photon transmission, typically used to simulate single-photon emitters, severely limits the achievable transmission distances and makes the integration of the QKD into existing classical networks, that use tens of thousands of photons per bit of transmission, difficult. Furthermore, it has been found that protocol performance varies with topology. In order to remove the reliance of QKD on single-photon emitters and increase transmission distances, it is worthwhile to explore QKD protocols that do not rely on single-photon transmissions for security, such as the 3-stage QKD protocol, which can tolerate multiple photons in each burst without information leakage. This paper compares and contrasts the 3-stage QKD protocol with conventional QKD protocols and its efficiency in different network topologies and conditions. Furthermore, we establish a mathematical relationship between achievable key rates to increase transmission distances in various topologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21726v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam</dc:creator>
    </item>
    <item>
      <title>The Tri-Hybrid MIMO Architecture</title>
      <link>https://arxiv.org/abs/2505.21971</link>
      <description>arXiv:2505.21971v1 Announce Type: cross 
Abstract: We present an evolution of multiple-input multiple-output (MIMO) wireless communications known as the tri-hybrid MIMO architecture. In this framework, the traditional operations of linear precoding at the transmitter are distributed across digital beamforming, analog beamforming, and reconfigurable antennas. Compared with the hybrid MIMO architecture, which combines digital and analog beamforming, the tri-hybrid approach introduces a third layer of electromagnetic beamforming through antenna reconfigurability. This added layer offers a pathway to scale MIMO spatial dimensions, important for 6G systems operating in centimeter-wave bands, where the tension between larger bandwidths and infrastructure reuse necessitates ultra-large antenna arrays. We introduce the key features of the tri-hybrid architecture by (i)~reviewing the benefits and challenges of communicating with reconfigurable antennas, (ii)~examining tradeoffs between spectral and energy efficiency enabled by reconfigurability, and (iii)~exploring configuration challenges across the three layers. Overall, the tri-hybrid MIMO architecture offers a new approach for integrating emerging antenna technologies in the MIMO precoding framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21971v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert W. Heath, Jr., Joseph Carlson, Nitish Vikas Deshpande, Miguel Rodrigo Castellanos, Mohamed Akrout, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Domainator: Detecting and Identifying DNS-Tunneling Malware Using Metadata Sequences</title>
      <link>https://arxiv.org/abs/2505.22220</link>
      <description>arXiv:2505.22220v1 Announce Type: cross 
Abstract: In recent years, malware with tunneling (or: covert channel) capabilities is on the rise. While malware research led to several methods and innovations, the detection and differentiation of malware solely based on its DNS tunneling features is still in its infancy. Moreover, no work so far has used the DNS tunneling traffic to gain knowledge over the current actions taken by the malware. In this paper, we present Domainator, an approach to detect and differentiate state-of-the-art malware and DNS tunneling tools without relying on trivial (but quickly altered) features such as "magic bytes" that are embedded into subdomains. Instead, we apply an analysis of sequential patterns to identify specific types of malware. We evaluate our approach with 7 different malware samples and tunneling tools and can identify the particular malware based on its DNS traffic. We further infer the rough behavior of the particular malware through its DNS tunneling artifacts. Finally, we compare our Domainator with related methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22220v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis Petrov, Pascal Ruffing, Sebastian Zillien, Steffen Wendzel</dc:creator>
    </item>
    <item>
      <title>From Large AI Models to Agentic AI: A Tutorial on Future Intelligent Communications</title>
      <link>https://arxiv.org/abs/2505.22311</link>
      <description>arXiv:2505.22311v1 Announce Type: cross 
Abstract: With the advent of 6G communications, intelligent communication systems face multiple challenges, including constrained perception and response capabilities, limited scalability, and low adaptability in dynamic environments. This tutorial provides a systematic introduction to the principles, design, and applications of Large Artificial Intelligence Models (LAMs) and Agentic AI technologies in intelligent communication systems, aiming to offer researchers a comprehensive overview of cutting-edge technologies and practical guidance. First, we outline the background of 6G communications, review the technological evolution from LAMs to Agentic AI, and clarify the tutorial's motivation and main contributions. Subsequently, we present a comprehensive review of the key components required for constructing LAMs. We further categorize LAMs and analyze their applicability, covering Large Language Models (LLMs), Large Vision Models (LVMs), Large Multimodal Models (LMMs), Large Reasoning Models (LRMs), and lightweight LAMs. Next, we propose a LAM-centric design paradigm tailored for communications, encompassing dataset construction and both internal and external learning approaches. Building upon this, we develop an LAM-based Agentic AI system for intelligent communications, clarifying its core components such as planners, knowledge bases, tools, and memory modules, as well as its interaction mechanisms. We also introduce a multi-agent framework with data retrieval, collaborative planning, and reflective evaluation for 6G. Subsequently, we provide a detailed overview of the applications of LAMs and Agentic AI in communication scenarios. Finally, we summarize the research challenges and future directions in current studies, aiming to support the development of efficient, secure, and sustainable next-generation intelligent communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22311v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feibo Jiang, Cunhua Pan, Li Dong, Kezhi Wang, Octavia A. Dobre, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>Revenue Optimization in Video Caching Networks with Privacy-Preserving Demand Predictions</title>
      <link>https://arxiv.org/abs/2505.07872</link>
      <description>arXiv:2505.07872v3 Announce Type: replace 
Abstract: Performance of video streaming, which accounts for most of the traffic in wireless communication, can be significantly improved by caching popular videos at the wireless edge. Determining the cache content that optimizes performance (defined via a revenue function) is thus an important task, and prediction of the future demands based on past history can make this process much more efficient. However, since practical video caching networks involve various parties (e.g., users, isp, and csp) that do not wish to reveal information such as past history to each other, privacy-preserving solutions are required. Motivated by this, we propose a proactive caching method based on users' privacy-preserving multi-slot future demand predictions -- obtained from a trained Transformer -- to optimize revenue. Specifically, we first use a privacy-preserving fl algorithm to train a Transformer to predict multi-slot future demands of the users. However, prediction accuracy is not perfect and decreases the farther into the future the prediction is done. We model the impact of prediction errors invoking the file popularities, based on which we formulate a long-term system revenue optimization to make the cache placement decisions. As the formulated problem is NP-hard, we use a greedy algorithm to efficiently obtain an approximate solution. Simulation results validate that (i) the fl solution achieves results close to the centralized (non-privacy-preserving) solution and (ii) optimization of revenue may provide different solutions than the classical chr criterion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07872v3</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijing Zhang, Ferdous Pervej, Andreas F. Molisch</dc:creator>
    </item>
    <item>
      <title>LibIQ: Toward Real-Time Spectrum Classification in O-RAN dApps</title>
      <link>https://arxiv.org/abs/2505.10537</link>
      <description>arXiv:2505.10537v2 Announce Type: replace 
Abstract: The O-RAN architecture is transforming cellular networks by adopting RAN softwarization and disaggregation concepts to enable data-driven monitoring and control of the network. Such management is enabled by RICs, which facilitate near-real-time and non-real-time network control through xApps and rApps. However, they face limitations, including latency overhead in data exchange between the RAN and RIC, restricting real-time monitoring, and the inability to access user plain data due to privacy and security constraints, hindering use cases like beamforming and spectrum classification. In this paper, we leverage the dApps concept to enable real-time RF spectrum classification with LibIQ, a novel library for RF signals that facilitates efficient spectrum monitoring and signal classification by providing functionalities to read I/Q samples as time-series, create datasets and visualize time-series data through plots and spectrograms. Thanks to LibIQ, I/Q samples can be efficiently processed to detect external RF signals, which are subsequently classified using a CNN inside the library. To achieve accurate spectrum analysis, we created an extensive dataset of time-series-based I/Q samples, representing distinct signal types captured using a custom dApp running on a 5G deployment over the Colosseum network emulator and an OTA testbed. We evaluate our model by deploying LibIQ in heterogeneous scenarios with varying center frequencies, time windows, and external RF signals. In real-time analysis, the model classifies the processed I/Q samples, achieving an average accuracy of approximately 97.8% in identifying signal types across all scenarios. We pledge to release both LibIQ and the dataset created as a publicly available framework upon acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10537v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Olimpieri, Noemi Giustini, Andrea Lacava, Salvatore D'Oro, Tommaso Melodia, Francesca Cuomo</dc:creator>
    </item>
    <item>
      <title>Effect of noise and topologies on multi-photon quantum protocols</title>
      <link>https://arxiv.org/abs/2505.19270</link>
      <description>arXiv:2505.19270v2 Announce Type: replace-cross 
Abstract: Quantum-augmented networks aim to use quantum phenomena to improve detection and protection against malicious actors in a classical communication network. This may include multiplexing quantum signals into classical fiber optical channels and incorporating purely quantum links alongside classical links in the network. In such hybrid networks, quantum protocols based on single photons become a bottleneck for transmission distances and data speeds, thereby reducing entire network performance. Furthermore, many of the security assumptions of the single-photon protocols do not hold up in practice because of the impossibility of manufacturing single-photon emitters. Multi-photon quantum protocols, on the other hand, are designed to operate under practical assumptions and do not require single photon emitters. As a result, they provide higher levels of security guarantees and longer transmission distances. However, the effect of channel and device noise on multiphoton protocols in terms of security, transmission distances, and bit rates has not been investigated. In this paper, we focus on channel noise and present our observations on the effect of various types of noise on multi-photon protocols. We also investigate the effect of topologies such as ring, star, and torus on the noise characteristics of the multi-photon protocols. Our results show the possible advantages of switching to multi-photon protocols and give insights into the repeater placement and topology choice for quantum-augmented networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19270v2</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 29 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3000586</arxiv:DOI>
      <arxiv:journal_reference>In Quantum computing, communication, and simulation IV (Vol. 12911, pp. 148-161). SPIE 2024</arxiv:journal_reference>
      <dc:creator>Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam</dc:creator>
    </item>
  </channel>
</rss>
