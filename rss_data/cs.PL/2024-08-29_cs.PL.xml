<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Aug 2024 01:34:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Generation of Compiler Backends from Formal Models of Hardware</title>
      <link>https://arxiv.org/abs/2408.15429</link>
      <description>arXiv:2408.15429v1 Announce Type: new 
Abstract: Compilers convert between representations -- usually, from higher-level, human writable code to lower-level, machine-readable code. A compiler backend is the portion of the compiler containing optimizations and code generation routines for a specific hardware target. In this dissertation, I advocate for a specific way of building compiler backends: namely, by automatically generating them from explicit, formal models of hardware using automated reasoning algorithms. I describe how automatically generating compilers from formal models of hardware leads to increased optimization ability, stronger correctness guarantees, and reduced development time for compiler backends. As evidence, I present two case studies: first, Glenside, which uses equality saturation to increase the 3LA compiler's ability to offload operations to machine learning accelerators, and second, Lakeroad, a technology mapper for FPGAs which uses program synthesis and semantics extracted from Verilog to map hardware designs to complex, programmable hardware primitives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15429v1</guid>
      <category>cs.PL</category>
      <category>cs.AR</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gus Henry Smith</dc:creator>
    </item>
    <item>
      <title>Verifying Solutions to Semantics-Guided Synthesis Problems</title>
      <link>https://arxiv.org/abs/2408.15475</link>
      <description>arXiv:2408.15475v1 Announce Type: new 
Abstract: Semantics-Guided Synthesis (SemGuS) provides a framework to specify synthesis problems in a solver-agnostic and domain-agnostic way, by allowing a user to provide both the syntax and semantics of the language in which the desired program should be synthesized. Because synthesis and verification are closely intertwined, the SemGuS framework raises the problem of how to verify programs in a solver and domain-agnostic way.
  We prove that the problem of verifying whether a program is a valid solution to a SemGuS problem can be reduced to proving validity of a query in the `CLP calculus, a fixed-point logic that generalizes Constrained Horn Clauses and co-Constrained Horn Clauses. Our encoding into `CLP allows us to further classify the SemGuS verification problems into ones that are reducible to validity of (i) first-order-logic formulas, (ii) Constrained Horn Clauses, (iii) co-Constrained Horn Clauses, and (iv) `CLP queries. Furthermore, our encoding shines light on some limitations of the SemGuS framework, such as its inability to model nondeterminism and reactive synthesis. We thus propose a modification to SemGuS that makes it more expressive, and for which verifying solutions is exactly equivalent to proving validity of a query in the `CLP calculus. Our implementation of SemGuS verifiers based on the above encoding can verify instances that were not even encodable in previous work. Furthermore, we use our SemGuS verifiers within an enumeration-based SemGuS solver to correctly synthesize solutions to SemGuS problems that no previous SemGuS synthesizer could solve.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15475v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charlie Murphy, Keith Johnson, Thomas Reps, Loris D'Antoni</dc:creator>
    </item>
    <item>
      <title>Omega: The Power of Visual Simplicity</title>
      <link>https://arxiv.org/abs/2408.15631</link>
      <description>arXiv:2408.15631v1 Announce Type: new 
Abstract: We are currently developing an innovative and visually-driven programming language called Omega.Although the Omega code is stored in text files, these files are not intended for manual editing or traditional printing.Furthermore, parsing these files using a context-free grammar is not possible.The parsing of the code and the facilitation of user-friendly manual editing both necessitate a global knowledge of the codebase.Strictly speaking, code visualization is not an integral part of the Omega language; instead, this task is delegated to the editing tools.Thanks to the global knowledge of the code, the editing process becomes remarkably straightforward, with numerous automatic completion features that enhance usability.Omega leverages a visual-oriented approach to encompass all fundamental aspects of software engineering.It offers robust features, including safe static typing, design by contracts, rules for accessing slots, operator definitions, and more,all presented in an intuitively and visually comprehensible manner, eliminating the need for obscure syntax.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15631v1</guid>
      <category>cs.PL</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benoit Sonntag (LSIIT), Dominique Colnet (KIWI)</dc:creator>
    </item>
    <item>
      <title>Automating Pruning in Top-Down Enumeration for Program Synthesis Problems with Monotonic Semantics</title>
      <link>https://arxiv.org/abs/2408.15822</link>
      <description>arXiv:2408.15822v1 Announce Type: new 
Abstract: In top-down enumeration for program synthesis, abstraction-based pruning uses an abstract domain to approximate the set of possible values that a partial program, when completed, can output on a given input. If the set does not contain the desired output, the partial program and all its possible completions can be pruned. In its general form, abstraction-based pruning requires manually designed, domain-specific abstract domains and semantics, and thus has only been used in domain-specific synthesizers.
  This paper provides sufficient conditions under which a form of abstraction-based pruning can be automated for arbitrary synthesis problems in the general-purpose Semantics-Guided Synthesis (SemGuS) framework without requiring manually-defined abstract domains. We show that if the semantics of the language for which we are synthesizing programs exhibits some monotonicity properties, one can obtain an abstract interval-based semantics for free from the concrete semantics of the programming language, and use such semantics to effectively prune the search space. We also identify a condition that ensures such abstract semantics can be used to compute a precise abstraction of the set of values that a program derivable from a given hole in a partial program can produce. These precise abstractions make abstraction-based pruning more effective.
  We implement our approach in a tool, Moito, which can tackle synthesis problems defined in the SemGuS framework. Moito can automate interval-based pruning without any a-priori knowledge of the problem domain, and solve synthesis problems that previously required domain-specific, abstraction-based synthesizers -- e.g., synthesis of regular expressions, CSV file schema, and imperative programs from examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15822v1</guid>
      <category>cs.PL</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keith J. C. Johnson, Rahul Krishnan, Thomas Reps, Loris D'Antoni</dc:creator>
    </item>
    <item>
      <title>Proving Confluence in the Confluence Framework with CONFident</title>
      <link>https://arxiv.org/abs/2306.16330</link>
      <description>arXiv:2306.16330v3 Announce Type: replace-cross 
Abstract: This article describes the *Confluence Framework*, a novel framework for proving and disproving confluence using a divide-and-conquer modular strategy, and its implementation in CONFident. Using this approach, we are able to automatically prove and disprove confluence of *Generalized Term Rewriting Systems*, where (i) only selected arguments of function symbols can be rewritten and (ii) a rather general class of conditional rules can be used. This includes, as particular cases, several variants of rewrite systems such as (context-sensitive) *term rewriting systems*, *string rewriting systems*, and (context-sensitive) *conditional term rewriting systems*. The divide-and-conquer modular strategy allows us to combine in a proof tree different techniques for proving confluence, including modular decompositions, checking joinability of (conditional) critical and variable pairs, transformations, etc., and auxiliary tasks required by them, e.g., joinability of terms, joinability of conditional pairs, etc.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16330v3</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ra\'ul Guti\'errez, Salvador Lucas, Miguel V\'itores</dc:creator>
    </item>
    <item>
      <title>QEDCartographer: Automating Formal Verification Using Reward-Free Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2408.09237</link>
      <description>arXiv:2408.09237v2 Announce Type: replace-cross 
Abstract: Formal verification is a promising method for producing reliable software, but the difficulty of manually writing verification proofs severely limits its utility in practice. Recent methods have automated some proof synthesis by guiding a search through the proof space using a theorem prover. Unfortunately, the theorem prover provides only the crudest estimate of progress, resulting in effectively undirected search. To address this problem, we create QEDCartographer, an automated proof-synthesis tool that combines supervised and reinforcement learning to more effectively explore the proof space. QEDCartographer incorporates the proofs' branching structure, enabling reward-free search and overcoming the sparse reward problem inherent to formal verification. We evaluate QEDCartographer using the CoqGym benchmark of 68.5K theorems from 124 open-source Coq projects. QEDCartographer fully automatically proves 21.4% of the test-set theorems. Previous search-based proof-synthesis tools Tok, Tac, ASTactic, Passport, and Proverbot9001, which rely only on supervised learning, prove 9.6%, 9.8%, 10.9%, 12.5%, and 19.8%, respectively. Diva, which combines 62 tools, proves 19.2%. Comparing to the most effective prior tool, Proverbot9001, QEDCartographer produces 26% shorter proofs 27% faster, on average over the theorems both tools prove. Together, QEDCartographer and non-learning-based CoqHammer prove 31.8% of the theorems, while CoqHammer alone proves 26.6%. Our work demonstrates that reinforcement learning is a fruitful research direction for improving proof-synthesis tools' search mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09237v2</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Thu, 29 Aug 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alex Sanchez-Stern, Abhishek Varghese, Zhanna Kaufman, Dylan Zhang, Talia Ringer, Yuriy Brun</dc:creator>
    </item>
  </channel>
</rss>
