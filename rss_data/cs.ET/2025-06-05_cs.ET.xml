<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Jun 2025 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Prosthetics of the Indian State: The e-Shram Portal for Unorganized Workers in India</title>
      <link>https://arxiv.org/abs/2503.05714</link>
      <description>arXiv:2503.05714v1 Announce Type: cross 
Abstract: This research paper examines the digital portal/database for unorganized workers in the informal sector economy of India today: e-Shram. Using affordance theory, I criticize the operationalization of this database for the labourers, alongside problems of accessibility and perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.05714v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rozin Hasin</dc:creator>
    </item>
    <item>
      <title>ChemReservoir -- An Open-Source Framework for Chemically-Inspired Reservoir Computing</title>
      <link>https://arxiv.org/abs/2506.04249</link>
      <description>arXiv:2506.04249v1 Announce Type: cross 
Abstract: Reservoir computing is a type of a recurrent neural network, mapping the inputs into higher dimensional space using fixed and nonlinear dynamical systems, called reservoirs. In the literature, there are various types of reservoirs ranging from in-silico to in-vitro. In cheminformatics, previous studies contributed to the field by developing simulation-based chemically inspired in-silico reservoir models. Yahiro used a DNA-based chemical reaction network as its reservoir and Nguyen developed a DNA chemistry-inspired tool based on Gillespie algorithm. However, these software tools were designed mainly with the focus on DNA chemistry and their maintenance status has limited their current usability. Due to these limitations, there was a need for a proper open-source tool. This study introduces ChemReservoir, an open-source framework for chemically-inspired reservoir computing. In contrast to the former studies focused on DNA-chemistry, ChemReservoir is a general framework for the construction and analysis of chemically-inspired reservoirs, which also addresses the limitations in these previous studies by ensuring enhanced testing, evaluation, and reproducibility. The tool was evaluated using various cycle-based reservoir topologies and demonstrated stable performance across a range of configurations in memory capacity tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04249v1</guid>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehmet Aziz Yirik, Jakob Lykke Andersen, Rolf Fagerberg, Daniel Merkle</dc:creator>
    </item>
    <item>
      <title>Bridging the Silos of Digitalization and Sustainability by Twin Transition: A Multivocal Literature Review</title>
      <link>https://arxiv.org/abs/2506.04267</link>
      <description>arXiv:2506.04267v1 Announce Type: cross 
Abstract: Twin transition is the method of parallel digital and sustainability transitions in a mutually supporting way or, in common terms, "greening of and by IT and data." Twin transition reacts to the growing problem of unsustainable digitalization, particularly in the ecological sense. Ignoring this problem will eventually limit the digital adeptness of society and the problem-solving capacity of humankind. Information systems engineering must find ways to support twin transition journeys through its substantial body of knowledge, methods, and techniques. To this end, we systematically survey the academic and gray literature on twin transition, clarify key concepts, and derive leads for researchers and practitioners to steer their innovation efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04267v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.ET</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baran Shajari, Istvan David</dc:creator>
    </item>
    <item>
      <title>Experience Paper: Scaling WiFi Sensing to Millions of Commodity Devices for Ubiquitous Home Monitoring</title>
      <link>https://arxiv.org/abs/2506.04322</link>
      <description>arXiv:2506.04322v1 Announce Type: cross 
Abstract: WiFi-based home monitoring has emerged as a compelling alternative to traditional camera- and sensor-based solutions, offering wide coverage with minimal intrusion by leveraging existing wireless infrastructure. This paper presents key insights and lessons learned from developing and deploying a large-scale WiFi sensing solution, currently operational across over 10 million commodity off-the-shelf routers and 100 million smart bulbs worldwide. Through this extensive deployment, we identify four real-world challenges that hinder the practical adoption of prior research: 1) Non-human movements (e.g., pets) frequently trigger false positives; 2) Low-cost WiFi chipsets and heterogeneous hardware introduce inconsistencies in channel state information (CSI) measurements; 3) Motion interference in multi-user environments complicates occupant differentiation; 4) Computational constraints on edge devices and limited cloud transmission impede real-time processing. To address these challenges, we present a practical and scalable system, validated through comprehensive two-year evaluations involving 280 edge devices, across 16 scenarios, and over 4 million motion samples. Our solutions achieve an accuracy of 92.61% in diverse real-world homes while reducing false alarms due to non-human movements from 63.1% to 8.4% and lowering CSI transmission overhead by 99.72%. Notably, our system integrates sensing and communication, supporting simultaneous WiFi sensing and data transmission over home WiFi networks. While focused on home monitoring, our findings and strategies generalize to various WiFi sensing applications. By bridging the gaps between theoretical research and commercial deployment, this work offers practical insights for scaling WiFi sensing in real-world environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04322v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guozhen Zhu, Yuqian Hu, Chenshu Wu, Wei-Hsiang Wang, Beibei Wang, K. J. Ray Liu</dc:creator>
    </item>
    <item>
      <title>Perturbative Gradient Training: A novel training paradigm for bridging the gap between deep neural networks and physical reservoir computing</title>
      <link>https://arxiv.org/abs/2506.04523</link>
      <description>arXiv:2506.04523v1 Announce Type: cross 
Abstract: We introduce Perturbative Gradient Training (PGT), a novel training paradigm that overcomes a critical limitation of physical reservoir computing: the inability to perform backpropagation due to the black-box nature of physical reservoirs. Drawing inspiration from perturbation theory in physics, PGT uses random perturbations in the network's parameter space to approximate gradient updates using only forward passes. We demonstrate the feasibility of this approach on both simulated neural network architectures, including a dense network and a transformer model with a reservoir layer, and on experimental hardware using a magnonic auto-oscillation ring as the physical reservoir. Our results show that PGT can achieve performance comparable to that of standard backpropagation methods in cases where backpropagation is impractical or impossible. PGT represents a promising step toward integrating physical reservoirs into deeper neural network architectures and achieving significant energy efficiency gains in AI training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04523v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.mes-hall</category>
      <category>cs.ET</category>
      <category>cs.NE</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cliff B. Abbott, Mark Elo, Dmytro A. Bozhko</dc:creator>
    </item>
    <item>
      <title>Olfactory Inertial Odometry: Sensor Calibration and Drift Compensation</title>
      <link>https://arxiv.org/abs/2506.04539</link>
      <description>arXiv:2506.04539v1 Announce Type: cross 
Abstract: Visual inertial odometry (VIO) is a process for fusing visual and kinematic data to understand a machine's state in a navigation task. Olfactory inertial odometry (OIO) is an analog to VIO that fuses signals from gas sensors with inertial data to help a robot navigate by scent. Gas dynamics and environmental factors introduce disturbances into olfactory navigation tasks that can make OIO difficult to facilitate. With our work here, we define a process for calibrating a robot for OIO that generalizes to several olfaction sensor types. Our focus is specifically on calibrating OIO for centimeter-level accuracy in localizing an odor source on a slow-moving robot platform to demonstrate use cases in robotic surgery and touchless security screening. We demonstrate our process for OIO calibration on a real robotic arm and show how this calibration improves performance over a cold-start olfactory navigation task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04539v1</guid>
      <category>cs.RO</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kordel K. France, Ovidiu Daescu, Anirban Paul, Shalini Prasad</dc:creator>
    </item>
    <item>
      <title>TQml Simulator: Optimized Simulation of Quantum Machine Learning</title>
      <link>https://arxiv.org/abs/2506.04891</link>
      <description>arXiv:2506.04891v1 Announce Type: cross 
Abstract: Hardware-efficient circuits employed in Quantum Machine Learning are typically composed of alternating layers of uniformly applied gates. High-speed numerical simulators for such circuits are crucial for advancing research in this field. In this work, we numerically benchmark universal and gate-specific techniques for simulating the action of layers of gates on quantum state vectors, aiming to accelerate the overall simulation of Quantum Machine Learning algorithms. Our analysis shows that the optimal simulation method for a given layer of gates depends on the number of qubits involved, and that a tailored combination of techniques can yield substantial performance gains in the forward and backward passes for a given circuit. Building on these insights, we developed a numerical simulator, named TQml Simulator, that employs the most efficient simulation method for each layer in a given circuit. We evaluated TQml Simulator on circuits constructed from standard gate sets, such as rotations and CNOTs, as well as on native gates from IonQ and IBM quantum processing units. In most cases, our simulator outperforms equivalent Pennylane's default.qubit simulator by approximately 2- to 100-fold, depending on the circuit, the number of qubits, the batch size of the input data, and the hardware used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04891v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viacheslav Kuzmin, Basil Kyriacou, Mateusz Papierz, Mo Kordzanganeh, Alexey Melnikov</dc:creator>
    </item>
    <item>
      <title>From Screen to Space: Evaluating Siemens' Cinematic Reality</title>
      <link>https://arxiv.org/abs/2506.04972</link>
      <description>arXiv:2506.04972v1 Announce Type: cross 
Abstract: As one of the first research teams with full access to Siemens' Cinematic Reality, we evaluate its usability and clinical potential for cinematic volume rendering on the Apple Vision Pro. We visualized venous-phase liver computed tomography and magnetic resonance cholangiopancreatography scans from the CHAOS and MRCP\_DLRecon datasets. Fourteen medical experts assessed usability and anticipated clinical integration potential using the System Usability Scale, ISONORM 9242-110-S questionnaire, and an open-ended survey. Their feedback identified feasibility, key usability strengths, and required features to catalyze the adaptation in real-world clinical workflows. The findings provide insights into the potential of immersive cinematic rendering in medical imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04972v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <category>cs.GR</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gijs Luijten, Lisle Faray de Paiva, Sebastian Krueger, Alexander Brost, Laura Mazilescu, Ana Sofia Ferreira Santos, Peter Hoyer, Jens Kleesiek, Sophia Marie-Therese Schmitz, Ulf Peter Neumann, Jan Egger</dc:creator>
    </item>
    <item>
      <title>BRC20 Pinning Attack</title>
      <link>https://arxiv.org/abs/2410.11295</link>
      <description>arXiv:2410.11295v3 Announce Type: replace-cross 
Abstract: BRC20 tokens are a type of non-fungible asset on the Bitcoin network. They allow users to embed customised content within Bitcoin's satoshis. The token frenzy reached a market size of US\$2.811\,b (2023Q3--2025Q1). However, this intuitive design has not undergone serious security scrutiny.
  We present the first analysis of BRC20's \emph{transfer} mechanism and identify a new attack vector. A typical BRC20 transfer involves two "bundled" on-chain transactions with different fee levels: the first (i.e., \textbf{Tx1}) with a lower fee inscribes the \textsf{transfer} request, while the second (i.e., \textbf{Tx2}) with a higher fee finalizes the actual transfer. An adversary can send a manipulated fee transaction (falling between the two fee levels), which causes \textbf{Tx1} to be processed while \textbf{Tx2} is pinned in the mempool. This locks BRC20 liquidity and disrupts normal withdrawal requests from users. We term this the \emph{BRC20 pinning attack}.
  We validated the attack in real-world settings in collaboration with Binance researchers. With their knowledge and permission, we conducted a controlled test against Binance's ORDI hot wallet, resulting in a temporary suspension of ORDI withdrawals for 3.5 hours. Recovery was performed shortly after. Further analysis confirms that the attack can be applied to over \textbf{90\%} of inscription-based tokens within the Bitcoin ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11295v3</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minfeng Qi, Qin Wang, Zhipeng Wang, Lin Zhong, Zhixiong Gao, Tianqing Zhu, Shiping Chen, William Knottenbelt</dc:creator>
    </item>
    <item>
      <title>Spatial-RAG: Spatial Retrieval Augmented Generation for Real-World Spatial Reasoning Questions</title>
      <link>https://arxiv.org/abs/2502.18470</link>
      <description>arXiv:2502.18470v4 Announce Type: replace-cross 
Abstract: Spatial reasoning remains a challenge for Large Language Models (LLMs), which struggle with spatial data retrieval and reasoning. We propose Spatial Retrieval-Augmented Generation (Spatial-RAG), a framework that extends RAG to spatial tasks by integrating sparse spatial retrieval (spatial databases) and dense semantic retrieval (LLM-based similarity). A multi-objective ranking strategy balances spatial constraints and semantic relevance, while an LLM-guided generator ensures coherent responses. Experiments on a real-world tourism dataset show that Spatial-RAG significantly improves spatial question answering, bridging the gap between LLMs and spatial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18470v4</guid>
      <category>cs.IR</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dazhou Yu, Riyang Bao, Ruiyu Ning, Jinghong Peng, Gengchen Mai, Liang Zhao</dc:creator>
    </item>
  </channel>
</rss>
