<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Aug 2025 02:20:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Gerrymandering and geographic polarization have reduced electoral competition</title>
      <link>https://arxiv.org/abs/2508.15885</link>
      <description>arXiv:2508.15885v1 Announce Type: new 
Abstract: Changes in political geography and electoral district boundaries shape representation in the United States Congress. To disentangle the effects of geography and gerrymandering, we generate a large ensemble of alternative redistricting plans that follow each state's legal criteria. Comparing enacted plans to these simulations reveals partisan bias, while changes in the simulated plans over time identify shifts in political geography. Our analysis shows that geographic polarization has intensified between 2010 and 2020: Republicans improved their standing in rural and rural-suburban areas, while Democrats further gained in urban districts. These shifts offset nationally, reducing the Republican geographic advantage from 14 to 10 seats. Additionally, pro-Democratic gerrymandering in 2020 counteracted earlier Republican efforts, reducing the GOP redistricting advantage by two seats. In total, the pro-Republican bias declined from 16 to 10 seats. Crucially, shifts in political geography and gerrymandering reduced the number of highly competitive districts by over 25%, with geographic polarization driving most of the decline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15885v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ethan Jasny, Christopher T. Kenny, Cory McCartan, Tyler Simko, Melissa Wu, Michael Y. Zhao, Aneetej Arora, Emma Ebowe, Philip O'Sullivan, Taran Samarth, Kosuke Imai</dc:creator>
    </item>
    <item>
      <title>Dynamic Graph-Based Forecasts of Bookmakers' Odds in Professional Tennis</title>
      <link>https://arxiv.org/abs/2508.15956</link>
      <description>arXiv:2508.15956v1 Announce Type: new 
Abstract: Bookmakers' odds consistently provide one of the most accurate methods for predicting the results of professional tennis matches. However, these odds usually only become available shortly before a match takes place, limiting their usefulness as an analysis tool. To ameliorate this issue, we introduce a novel dynamic graph-based model which aims to forecast bookmaker odds for any match on any surface, allowing effective and detailed pre-tournament predictions to be made. By leveraging the high-quality information contained in the odds, our model can keep pace with new innovations in tennis modelling. By analysing major tennis championships from 2024 and 2025, we show that our model achieves comparable accuracy both to the bookmakers and other models in the literature, while significantly outperforming rankings-based predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15956v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew J Penn, Jed Michael, Samir Bhatt</dc:creator>
    </item>
    <item>
      <title>A nonstationary spatial model of PM2.5 with localized transfer learning from numerical model output</title>
      <link>https://arxiv.org/abs/2508.15978</link>
      <description>arXiv:2508.15978v1 Announce Type: new 
Abstract: Ambient air pollution measurements from regulatory monitoring networks are routinely used to support epidemiologic studies and environmental policy decision making. However, regulatory monitors are spatially sparse and preferentially located in areas with large populations. Numerical air pollution model output can be leveraged into the inference and prediction of air pollution data combining with measurements from monitors. Nonstationary covariance functions allow the model to adapt to spatial surfaces whose variability changes with location like air pollution data. In the paper, we employ localized covariance parameters learned from the numerical output model to knit together into a global nonstationary covariance, to incorporate in a fully Bayesian model. We model the nonstationary structure in a computationally efficient way to make the Bayesian model scalable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15978v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlong Gong, Brian J. Reich, Joseph Guinness</dc:creator>
    </item>
    <item>
      <title>Comparing Malaria Trends in the Comoros Islands: ARIMA Modeling and Retrospective Analysis</title>
      <link>https://arxiv.org/abs/2508.16018</link>
      <description>arXiv:2508.16018v1 Announce Type: new 
Abstract: Malaria remains a serious health challenge in the Comoros Islands, despite ongoing control efforts. Past studies have shown reductions in cases due to prevention and treatment measures, but little work has been done to forecast future malaria deaths and assess the long-term impact of these measures. Malaria mortality data from 1990 to 2019 were analyzed using an ARIMA(1,0,0) model. The model was validated through diagnostic tests, ensuring reliability for forecasting trends. The study confirmed significant reductions in malaria cases, such as in Grand Comoro, where cases fell from 235.36 to 5.47 per 1,000 people. The ARIMA model predicted that fatalities will remain low if current control measures, including bed nets, indoor spraying, and mass drug administration, are sustained. The findings highlight the success of these interventions in reducing malaria mortality. However, challenges like drug and insecticide resistance and financial limitations pose risks to further progress. Continued support and adaptation of strategies are essential to address these challenges and sustain low malaria mortality rates. The study demonstrates the effectiveness of malaria control efforts in the Comoros and underscores the importance of maintaining these measures to achieve malaria elimination and improve public health outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16018v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D. Baidoo, E. Kubuafor, O. O. Joshua, S. F. Osarfo, F. A. Agyei-Owusu, J. Akuoko-Frimpong, N. Appiah, A. Duah, R. Amevor, F. E. Boateng, F. Aboagye, B. Benyi</dc:creator>
    </item>
    <item>
      <title>Evaluation of Time Series Forecasting Models for Predicting Lung Cancer Mortality Rates in the United States: A Comparison with Altuhaifa (2023) Study</title>
      <link>https://arxiv.org/abs/2508.16052</link>
      <description>arXiv:2508.16052v1 Announce Type: new 
Abstract: This paper evaluates the performance of the following time series forecasting models - Simple Exponential Smoothing (SES), Holt's Double Exponential Smoothing (HDES), and Autoregressive Integrated Moving Average (ARIMA) - in predicting lung cancer mortality rates in the United States. It builds upon the work of Altuhaifa, which used Surveillance, Epidemiology, and End Results (SEER) data from 1975-2018 to evaluate these models. Altuhaifa's study found that ARIMA (0,2,2), SES with smoothing parameter $\alpha=0.995$, and HDES with parameters $\alpha=0.4$ and $\beta=0.9$ were the optimal models from their analysis, with HDES providing the lowest Root Mean Squared Error (RMSE) of 132.91. The paper extends the dataset to 2021 and re-evaluates the models. Using the same SEER data from 1975-2021, it identifies ARIMA (0,2,2), SES ($\alpha=0.999$), and HDES ($\alpha=0.5221$, $\beta=0.5219$) as the best-fitting models. Interestingly, ARIMA (0,2,2) and HDES yield the lowest RMSE of 2.56. To obtain forecasts with higher accuracy, an average model (HDES-ARIMA) consisting of HDES and ARIMA was constructed to leverage their strengths. The HDES-ARIMA model also achieves an RMSE of 2.56. The forecast from the average model suggests declining lung cancer mortality rates in the United States. The study highlights how expanding datasets and re-evaluating models can provide updated insights. It recommends further analysis using monthly data separated by gender, ethnicity, and state to understand lung cancer mortality dynamics in the United States. Overall, advanced time series methods like HDES and ARIMA show strong potential for accurately forecasting this major public health issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16052v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>E. Kubuafor, D. Baidoo, O. J. Okeke, R. Amevor, G. Arhin, J. T. Korley</dc:creator>
    </item>
    <item>
      <title>Multivariate Shared Frailty Cure-Rate models: a focus on Breast Cancer family history</title>
      <link>https://arxiv.org/abs/2508.16350</link>
      <description>arXiv:2508.16350v1 Announce Type: new 
Abstract: We discuss a shift in perspective from traditional approaches to breast cancer risk prediction: modelling families rather than individuals as unit of analysis. By investigating the latent familial risk underlying breast cancer diagnoses, we introduce a Multivariate Shared Frailty Cure-Rate model. This model captures the familial risk as a shared frailty among members and explicitly accounts for a fraction of women not susceptible to breast cancer. We aim at identifying the high-risk families to better target screening and prevention, ultimately improving early detection. A comparative analysis with Cox models and univariate models - where a binary risk indicator acts as best guess for the latent high-risk group - is conducted using simulation studies and data from the Swedish Multi-Generational Breast Cancer registry. We demonstrate the critical importance of using complete family history of breast cancer to accurately identify high-risk families and show that the Multivariate Shared Frailty Cure-Rate model, capturing both the fraction of non-susceptible subjects and the survival distribution among susceptibles, enhances explanatory power, improves prediction accuracy, and offers a broader representation of the disease process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16350v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Veronica Vinattieri, Marco Bonetti, Kamila Czene</dc:creator>
    </item>
    <item>
      <title>Dynamic Financial Analysis (DFA) of General Insurers under Climate Change</title>
      <link>https://arxiv.org/abs/2508.16444</link>
      <description>arXiv:2508.16444v1 Announce Type: new 
Abstract: Climate change is expected to significantly affect the physical, financial, and economic environments over the long term, posing risks to the financial health of general insurers. While general insurers typically use Dynamic Financial Analysis (DFA) for a comprehensive view of financial impacts, traditional DFA as presented in the literature does not consider the impact of climate change. To address this gap, we introduce a climate-dependent DFA approach that integrates climate risk into DFA, providing a holistic assessment of the long-term impact of climate change on the general insurance industry. The proposed framework has three key features. First, it captures the long-term impact of climate change on the assets and liabilities of general insurers by considering both physical and economic dimensions across different climate scenarios within an interconnected structure. Second, it addresses the uncertainty of climate change impacts using stochastic simulations within climate scenario analysis that are useful for actuarial applications. Finally, the framework is tailored to the general insurance sector by addressing its unique characteristics. To demonstrate the practical application of our model, we conduct an extensive empirical study using Australian data to assess the long-term financial impact of climate change on the general insurance market under various climate scenarios. The results show that the interaction between economic growth and physical risk plays a key role in shaping general insurers' risk-return profiles. Limitations of our framework are thoroughly discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16444v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Avanzi, Yanfeng Li, Greg Taylor, Bernard Wong</dc:creator>
    </item>
    <item>
      <title>Variable Neighborhood Descent Methods for Large-scale Single-assignment Multi-level Facility Location Problem</title>
      <link>https://arxiv.org/abs/2508.15954</link>
      <description>arXiv:2508.15954v1 Announce Type: cross 
Abstract: This paper addresses the single--assignment uncapacitated multi-level facility location (MFL) problem, which has numerous applications, including tactical and strategic supply chain management. We consider four-level and five-level facilities (4-LFL and 5-LFL). Although the MFL has been addressed in the literature in various settings, solutions to large-scale, realistic problems are still lacking. This paper considers several variants of the variable neighborhood descent (VND) method, including BVND, PVND, CVND, and UVND, for the problem. In each case, a multi-start strategy with strong diversification components is provided. Extensive computational experiments are presented to compare methods for large-scale problems involving up to 10,000 customers, 150 distribution centers, 50 warehouses, and 30 plants in the case of 4-LFL; and 8,000 customers, 150 distribution centers, 50 warehouses, 50 plants, and 100 suppliers in the case of 5-LFL. Sensitivity analyses, supported by appropriate statistical methods, validate the effectiveness of the heuristics' results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15954v1</guid>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Bahram Alidaee</dc:creator>
    </item>
    <item>
      <title>A regularized multi-state model for covariate selection with interval-censored survival data</title>
      <link>https://arxiv.org/abs/2508.16256</link>
      <description>arXiv:2508.16256v1 Announce Type: cross 
Abstract: In population-based cohorts, disease diagnoses are typically censored by intervals as made during scheduled follow-up visits. The exact disease onset time is thus unknown, and in the presence of semi-competing risk of death, subjects may also die in between two visits before any diagnosis can be made. Illness-death models can be used to handle uncertainty about illness timing and the possible absence of diagnosis due to death. However, they are so far limited in the number of covariates. We developed a regularized estimation procedure for illness-death models with interval-censored illness diagnosis that performs variable selection in the case of high-dimensional predictors. We considered a proximal gradient hybrid algorithm maximizing the regularized likelihood with an elastic-net penalty. The algorithm simultaneously estimates the regression parameters of the three transitions under proportional transition intensities with transition-specific penalty parameters determined in an outer gridsearch. The algorithm, implemented in the R package HIDeM, shows high performances in predicting illness probability, as well as correct selection of transition-specific risk factors across different simulation scenarios. In comparison, the cause-specific competing risk model neglecting interval-censoring systematically showed worse predictive ability and tended to select irrelevant illness predictors, originally associated with death. Applied to the population-based cohort Three-City, the method identified predictors of clinical dementia onset among a large set of brain imaging, cognitive and clinical markers.
  Keywords: Interval censoring; Multi-state model; Semi-competing risk; Survival Analysis; Variable Selection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16256v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariane Bercu, Agathe Guilloux, C\'ecile Proust-Lima, H\'el\`ene Jacqmin-Gadda</dc:creator>
    </item>
    <item>
      <title>Identifying Treatment Effect Heterogeneity with Bayesian Hierarchical Adjustable Random Partition in Adaptive Enrichment Trials</title>
      <link>https://arxiv.org/abs/2508.16523</link>
      <description>arXiv:2508.16523v1 Announce Type: cross 
Abstract: Treatment effect heterogeneity refers to the systematic variation in treatment effects across subgroups. There is an increasing need for clinical trials that aim to investigate treatment effect heterogeneity and estimate subgroup-specific responses. While several statistical methods have been proposed to address this problem, existing partitioning-based methods often depend on auxiliary analysis, overlook model uncertainty, or impose inflexible borrowing strength. We propose the Bayesian Hierarchical Adjustable Random Partition (BHARP) model, a self-contained framework that applies a finite mixture model with an unknown number of components to explore the partition space accounting for model uncertainty. The BHARP model jointly estimates subgroup-specific effects and the heterogeneity patterns, and adjusts the borrowing strengths based on within-cluster cohesion without requiring manual calibration. Posterior sampling is performed via a custom reversible-jump Markov chain Monte Carlo sampler tailored to partitioning-based information borrowing in clinical trials. Simulation studies across a range of treatment effect heterogeneity patterns show that the BHARP model achieves better accuracy and precision compared to conventional and advanced methods. We showcase the utilities of the BHARP model in the context of a multi-arm adaptive enrichment trial investigating physical activity interventions in patients with type 2 diabetes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16523v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianglin Zhao, Shirin Golchi, Jean-Philippe Gouin, Kaberi Dasgupta</dc:creator>
    </item>
    <item>
      <title>Exploring natural variation in tendon constitutive parameters via Bayesian data selection and mixed effects models</title>
      <link>https://arxiv.org/abs/2412.12983</link>
      <description>arXiv:2412.12983v2 Announce Type: replace 
Abstract: Combining microstructural mechanical models with experimental data enhances our understanding of the mechanics of soft tissue, such as tendons. In previous work, a Bayesian framework was used to infer constitutive parameters from uniaxial stress-strain experiments on horse tendons, specifically the superficial digital flexor tendon (SDFT) and common digital extensor tendon (CDET), on a per-experiment basis. Here, we extend this analysis to investigate the natural variation of these parameters across a population of horses. Using a Bayesian mixed effects model, we infer population distributions of these parameters. Given that the chosen hyperelastic model does not account for tendon damage, careful data selection is necessary. Avoiding ad hoc methods, we introduce a hierarchical Bayesian data selection method. This two-stage approach selects data per experiment, and integrates data weightings into the Bayesian mixed effects model. Our results indicate that the CDET is stiffer than the SDFT, likely due to a higher collagen volume fraction. The modes of the parameter distributions yield estimates of the product of the collagen volume fraction and Young's modulus as 811.5 MPa for the SDFT and 1430.2 MPa for the CDET. This suggests that positional tendons have stiffer collagen fibrils and/or higher collagen volume density than energy-storing tendons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12983v2</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Casey, Jessica Forsyth, Timothy Waite, Simon Cotter, Tom Shearer</dc:creator>
    </item>
    <item>
      <title>Toward a Principled Framework for Disclosure Avoidance</title>
      <link>https://arxiv.org/abs/2502.07105</link>
      <description>arXiv:2502.07105v3 Announce Type: replace 
Abstract: Responsible disclosure limitation is an iterative exercise in risk assessment and mitigation. From time to time, as disclosure risks grow and evolve and as data users' needs change, agencies must consider redesigning the disclosure avoidance system(s) they use. Discussions about candidate systems often conflate inherent features of those systems with implementation decisions independent of those systems. For example, a system's ability to calibrate the strength of protection to suit the underlying disclosure risk of the data (e.g., by varying suppression thresholds), is a worthwhile feature regardless of the independent decision about how much protection is actually necessary. Having a principled discussion of candidate disclosure avoidance systems requires a framework for distinguishing these inherent features of the systems from the implementation decisions that need to be made independent of the system selected. For statistical agencies, this framework must also reflect the applied nature of these systems, acknowledging that candidate systems need to be adaptable to requirements stemming from the legal, scientific, resource, and stakeholder environments within which they would be operating. This paper proposes such a framework. No approach will be perfectly adaptable to every potential system requirement. Because the selection of some methodologies over others may constrain the resulting systems' efficiency and flexibility to adapt to particular statistical product specifications, data user needs, or disclosure risks, agencies may approach these choices in an iterative fashion, adapting system requirements, product specifications, and implementation parameters as necessary to ensure the resulting quality of the statistical product.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07105v3</guid>
      <category>stat.AP</category>
      <category>cs.CY</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.1162/99608f92.db29c137</arxiv:DOI>
      <arxiv:journal_reference>Harvard Data Science Review, Special Issue 6 (2025)</arxiv:journal_reference>
      <dc:creator>Michael B Hawes, Evan M Brassell, Anthony Caruso, Ryan Cumings-Menon, Jason Devine, Cassandra Dorius, David Evans, Kenneth Haase, Michele C Hedrick, Alexandra Krause, Philip Leclerc, James Livsey, Rolando A Rodriguez, Luke T Rogers, Matthew Spence, Victoria Velkoff, Michael Walsh, James Whitehorne, Sallie Ann Keller</dc:creator>
    </item>
    <item>
      <title>Geodesic slice sampling on Riemannian manifolds</title>
      <link>https://arxiv.org/abs/2312.00417</link>
      <description>arXiv:2312.00417v3 Announce Type: replace-cross 
Abstract: We propose a theoretically justified and practically applicable slice sampling based Markov chain Monte Carlo (MCMC) method for approximate sampling from probability measures on Riemannian manifolds. The latter naturally arise as posterior distributions in Bayesian inference of matrix-valued parameters, for example belonging to either the Stiefel or the Grassmann manifold. Our method, called geodesic slice sampling, is reversible with respect to the distribution of interest, and generalizes Hit-and-run slice sampling on $\mathbb{R}^{d}$ to Riemannian manifolds by using geodesics instead of straight lines. We demonstrate the robustness of our sampler's performance compared to other MCMC methods dealing with manifold valued distributions through extensive numerical experiments, on both synthetic and real data. In particular, we illustrate its remarkable ability to cope with anisotropic target densities, without using gradient information and preconditioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00417v3</guid>
      <category>stat.CO</category>
      <category>math.PR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alain Durmus, Samuel Gruffaz, Mareike Hasenpflug, Daniel Rudolf</dc:creator>
    </item>
    <item>
      <title>Does fertility affect woman's labor force participation in low- and middle-income settings? Findings from a Bayesian nonparametric analysis</title>
      <link>https://arxiv.org/abs/2508.10787</link>
      <description>arXiv:2508.10787v2 Announce Type: replace-cross 
Abstract: Estimating the causal effect of fertility on women's employment is challenging because fertility and labor decisions are jointly determined. The difficulty is amplified in low- and middle-income countries, where longitudinal data are scarce. In this study, we propose a novel approach to estimating the causal effect of fertility on employment using widely available Demographic and Health Survey (DHS) observational data. Using infecundity as an instrument for family size, our approach combines principal stratification with Bayesian Additive Regression Trees to flexibly account for covariate-dependent instrument validity, work with count-valued intermediate variables, and produce estimates of causal effects and effect heterogeneity, i.e., how effects vary with covariates in the survey population. We apply the approach to DHS data from Nigeria, Senegal, and Kenya. We find in the survey sample and general population that an additional child significantly reduces employment among women in Nigeria but has no clear average effect in Senegal or Kenya. Across all three countries, however, there is strong evidence of effect heterogeneity: younger, less-educated women experience large employment penalties, while older or more advantaged women are largely unaffected. Robustness checks confirm that these findings are not sensitive to key modeling assumptions. While limitations remain due to the cross-sectional nature of the DHS data, our results illustrate how flexible non-parametric models can uncover important effect variation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10787v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 25 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Godoy Garraza, Leontine Alkema</dc:creator>
    </item>
  </channel>
</rss>
