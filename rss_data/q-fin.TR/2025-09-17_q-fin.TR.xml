<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.TR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.TR</link>
    <description>q-fin.TR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.TR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 01:34:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Reinforcement Learning-Based Market Making as a Stochastic Control on Non-Stationary Limit Order Book Dynamics</title>
      <link>https://arxiv.org/abs/2509.12456</link>
      <description>arXiv:2509.12456v1 Announce Type: new 
Abstract: Reinforcement Learning has emerged as a promising framework for developing adaptive and data-driven strategies, enabling market makers to optimize decision-making policies based on interactions with the limit order book environment. This paper explores the integration of a reinforcement learning agent in a market-making context, where the underlying market dynamics have been explicitly modeled to capture observed stylized facts of real markets, including clustered order arrival times, non-stationary spreads and return drifts, stochastic order quantities and price volatility. These mechanisms aim to enhance stability of the resulting control agent, and serve to incorporate domain-specific knowledge into the agent policy learning process. Our contributions include a practical implementation of a market making agent based on the Proximal-Policy Optimization (PPO) algorithm, alongside a comparative evaluation of the agent's performance under varying market conditions via a simulator-based environment. As evidenced by our analysis of the financial return and risk metrics when compared to a closed-form optimal solution, our results suggest that the reinforcement learning agent can effectively be used under non-stationary market conditions, and that the proposed simulator-based environment can serve as a valuable tool for training and pre-training reinforcement learning agents in market-making scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12456v1</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Zimmer, Oswaldo Luiz do Valle Costa</dc:creator>
    </item>
    <item>
      <title>Myopic Optimality: why reinforcement learning portfolio management strategies lose money</title>
      <link>https://arxiv.org/abs/2509.12764</link>
      <description>arXiv:2509.12764v1 Announce Type: new 
Abstract: Myopic optimization (MO) outperforms reinforcement learning (RL) in portfolio management: RL yields lower or negative returns, higher variance, larger costs, heavier CVaR, lower profitability, and greater model risk. We model execution/liquidation frictions with mark-to-market accounting. Using Malliavin calculus (Clark-Ocone/BEL), we derive policy gradients and risk shadow price, unifying HJB and KKT. This gives dual gap and convergence results: geometric MO vs. RL floors. We quantify phantom profit in RL via Malliavin policy-gradient contamination analysis and define a control-affects-dynamics (CAD) premium of RL indicating plausibly positive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12764v1</guid>
      <category>q-fin.TR</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <category>q-fin.RM</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuming Ma</dc:creator>
    </item>
    <item>
      <title>Optimal Liquidation with Signals: the General Propagator Case</title>
      <link>https://arxiv.org/abs/2211.00447</link>
      <description>arXiv:2211.00447v2 Announce Type: replace 
Abstract: We consider a class of optimal liquidation problems where the agent's transactions create transient price impact driven by a Volterra-type propagator along with temporary price impact. We formulate these problems as maximization of a revenue-risk functionals, where the agent also exploits available information on a progressively measurable price predicting signal. By using an infinite dimensional stochastic control approach, we characterize the value function in terms of a solution to a free-boundary $L^2$-valued backward stochastic differential equation and an operator-valued Riccati equation. We then derive analytic solutions to these equations which yields an explicit expression for the optimal trading strategy. We show that our formulas can be implemented in a straightforward and efficient way for a large class of price impact kernels with possible singularities such as the power-law kernel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.00447v2</guid>
      <category>q-fin.TR</category>
      <category>math.PR</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eduardo Abi Jaber, Eyal Neuman</dc:creator>
    </item>
    <item>
      <title>Returns and Order Flow Imbalances: Intraday Dynamics and Macroeconomic News Effects</title>
      <link>https://arxiv.org/abs/2508.06788</link>
      <description>arXiv:2508.06788v3 Announce Type: replace 
Abstract: We study the interaction between returns and order flow imbalances in the S&amp;P 500 E-mini futures market using a structural VAR model identified through heteroskedasticity. The model is estimated at one-second frequency for each 15-minute interval, capturing both intraday variation and endogeneity due to time aggregation. We find that macroeconomic news announcements sharply reshape price-flow dynamics: price impact rises, flow impact declines, return volatility spikes, and flow volatility falls. Pooling across days, both price and flow impacts are significant at the one-second horizon, with estimates broadly consistent with stylized limit-order-book predictions. Impulse responses indicate that shocks dissipate almost entirely within a second. Structural parameters and volatilities also exhibit pronounced intraday variation tied to liquidity, trading intensity, and spreads. These results provide new evidence on high-frequency price formation and liquidity, highlighting the role of public information and order submission in shaping market quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06788v3</guid>
      <category>q-fin.TR</category>
      <category>econ.EM</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Makoto Takahashi</dc:creator>
    </item>
  </channel>
</rss>
