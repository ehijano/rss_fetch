<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 Jan 2025 05:00:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Revisiting gender bias research in bibliometrics: Standardizing methodological variability using Scholarly Data Analysis (SoDA) Cards</title>
      <link>https://arxiv.org/abs/2501.18129</link>
      <description>arXiv:2501.18129v1 Announce Type: new 
Abstract: Gender biases in scholarly metrics remain a persistent concern, despite numerous bibliometric studies exploring their presence and absence across productivity, impact, acknowledgment, and self-citations. However, methodological inconsistencies, particularly in author name disambiguation and gender identification, limit the reliability and comparability of these studies, potentially perpetuating misperceptions and hindering effective interventions. A review of 70 relevant publications over the past 12 years reveals a wide range of approaches, from name-based and manual searches to more algorithmic and gold-standard methods, with no clear consensus on best practices. This variability, compounded by challenges such as accurately disambiguating Asian names and managing unassigned gender labels, underscores the urgent need for standardized and robust methodologies. To address this critical gap, we propose the development and implementation of ``Scholarly Data Analysis (SoDA) Cards." These cards will provide a structured framework for documenting and reporting key methodological choices in scholarly data analysis, including author name disambiguation and gender identification procedures. By promoting transparency and reproducibility, SoDA Cards will facilitate more accurate comparisons and aggregations of research findings, ultimately supporting evidence-informed policymaking and enabling the longitudinal tracking of analytical approaches in the study of gender and other social biases in academia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18129v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>HaeJin Lee, Shubhanshu Mishra, Apratim Mishra, Zhiwen You, Jinseok Kim, Jana Diesner</dc:creator>
    </item>
    <item>
      <title>Mining for Species, Locations, Habitats, and Ecosystems from Scientific Papers in Invasion Biology: A Large-Scale Exploratory Study with Large Language Models</title>
      <link>https://arxiv.org/abs/2501.18287</link>
      <description>arXiv:2501.18287v1 Announce Type: cross 
Abstract: This paper presents an exploratory study that harnesses the capabilities of large language models (LLMs) to mine key ecological entities from invasion biology literature. Specifically, we focus on extracting species names, their locations, associated habitats, and ecosystems, information that is critical for understanding species spread, predicting future invasions, and informing conservation efforts. Traditional text mining approaches often struggle with the complexity of ecological terminology and the subtle linguistic patterns found in these texts. By applying general-purpose LLMs without domain-specific fine-tuning, we uncover both the promise and limitations of using these models for ecological entity extraction. In doing so, this study lays the groundwork for more advanced, automated knowledge extraction tools that can aid researchers and practitioners in understanding and managing biological invasions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18287v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jennifer D'Souza, Zachary Laubach, Tarek Al Mustafa, Sina Zarrie{\ss}, Robert Fr\"uhst\"uckl, Phyllis Illari</dc:creator>
    </item>
    <item>
      <title>Citation Recommendation based on Argumentative Zoning of User Queries</title>
      <link>https://arxiv.org/abs/2501.18292</link>
      <description>arXiv:2501.18292v1 Announce Type: cross 
Abstract: Citation recommendation aims to locate the important papers for scholars to cite. When writing the citing sentences, the authors usually hold different citing intents, which are referred to citation function in citation analysis. Since argumentative zoning is to identify the argumentative and rhetorical structure in scientific literature, we want to use this information to improve the citation recommendation task. In this paper, a multi-task learning model is built for citation recommendation and argumentative zoning classification. We also generated an annotated corpus of the data from PubMed Central based on a new argumentative zoning schema. The experimental results show that, by considering the argumentative information in the citing sentence, citation recommendation model will get better performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18292v1</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.joi.2024.101607</arxiv:DOI>
      <arxiv:journal_reference>Journal of Informetrics, 2025</arxiv:journal_reference>
      <dc:creator>Shutian Ma, Chengzhi Zhang, Heng Zhang, Zheng Gao</dc:creator>
    </item>
    <item>
      <title>Cultural Differences and Perverse Incentives in Science Create a Bad Mix: Exploring Country-Level Publication Bias in Select ACM Conferences</title>
      <link>https://arxiv.org/abs/2501.17150</link>
      <description>arXiv:2501.17150v2 Announce Type: replace 
Abstract: In the era of big science, many national governments are helping to build well-funded teams of scientists to serve nationalistic ambitions, providing financial incentives for certain outcomes for purposes other than advancing science. This in turn can impact the behavior of scientists and create distorted country-level bias in publication rates, frequency, and publication venues targeted. To that end, we have found evidence that indicates significant inequality among the publication rates of individual scientists from various countries, based on an intensive analysis of papers published in several well-known ACM conferences (HRI, IUI, KDD, CHI, SIGGRAPH, UIST, and UBICOMP) over 15 years between 2010 to 2024. Furthermore, scientists who were affiliated with the top-5 countries (in terms of research expenditure) were found to be contributing significantly more to the inequality in publication rates than others. Given evidence of certain countries aggressively pushing their scientists via $\textit{perverse incentives}$ to publish in well-regarded publication venues and produce significant results (by any means necessary), we detected and present several examples of potential ethical problems in publications caused by such systems. Additionally, topic modeling using LDA and semantic similarity revealed that some countries are not pursuing diverse scientific topics relative to others, indicating those incentives may be limiting genuine scientific curiosity. All in all, our findings raise awareness of systems put in place by certain national governments that not only erodes the pursuit of truth through science, but also appears to be gradually undermining the integrity of the global scientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17150v2</guid>
      <category>cs.DL</category>
      <category>cs.CY</category>
      <pubDate>Fri, 31 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aksheytha Chelikavada, Casey C. Bennett</dc:creator>
    </item>
  </channel>
</rss>
