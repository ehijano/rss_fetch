<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unsupervised and semi-supervised clustering methods to identify and refine participant experience levels in educational research</title>
      <link>https://arxiv.org/abs/2508.03840</link>
      <description>arXiv:2508.03840v1 Announce Type: cross 
Abstract: The progression from novice to disciplinary expert is a longstanding area of inquiry in educational research. Studies investigating such progressions have often resorted to participants' self-assessments or other qualitative indicators as a starting point to define experience. But does a participant's estimated experience coincide with metrics derived from their conceptual understanding of a discipline? Using data extracted from over 150 concept maps, we first demonstrate that disciplinary experience is a reliable variable to explain differences in conceptual understanding across a highly diverse learners' population. Through a comparison of unsupervised and semi-supervised models, we then motivate clustering participants into three distinguished experience levels, and support such a classification performed in other studies of educational research. By analysing cluster composition, we also identify discrepancies between the perceived and predicted experience levels of the study participants. Lastly, for studies processing participants data through network analysis, we present insights into statistically significant metrics that can characterise each experience level, and advocate for the use of node-level metrics in such studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03840v1</guid>
      <category>physics.ed-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Julien-Pooya Weihs, Adrien Weihs, Vegard Gjerde, Helge Drange</dc:creator>
    </item>
    <item>
      <title>Rediscovering the Standard Model with AI</title>
      <link>https://arxiv.org/abs/2508.04923</link>
      <description>arXiv:2508.04923v1 Announce Type: cross 
Abstract: We investigate whether artificial intelligence can autonomously recover known structures of the Standard Model of particle physics using only experimental data and without theoretical inputs. By applying unsupervised machine learning techniques -- including data dimensionality reduction and clustering algorithms -- to intrinsic particle properties and decay modes, we uncover key organizational features of particle physics, such as the relative strength of different interactions and the difference between baryons and mesons. We also identify conserved quantities such as baryon number, strangeness and charm as well as the structure of isospin and the Eightfold Way multiplets. Our analysis then reveals that clustering can separate particles by interaction, flavor symmetries as well as quantum numbers. Additionally, we observe patterns consistent with Regge trajectories in baryon excitations. Our results demonstrate that machine learning can reproduce key aspects of the Standard Model directly from data, suggesting a promising path toward data-driven discovery in fundamental physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04923v1</guid>
      <category>hep-ph</category>
      <category>hep-th</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aya Abdelhaq, Pellegrino Piantadosi, Fernando Quevedo</dc:creator>
    </item>
    <item>
      <title>Supervised Machine Learning Methods with Uncertainty Quantification for Exoplanet Atmospheric Retrievals from Transmission Spectroscopy</title>
      <link>https://arxiv.org/abs/2508.04982</link>
      <description>arXiv:2508.04982v1 Announce Type: cross 
Abstract: Standard Bayesian retrievals for exoplanet atmospheric parameters from transmission spectroscopy, while well understood and widely used, are generally computationally expensive. In the era of the JWST and other upcoming observatories, machine learning approaches have emerged as viable alternatives that are both efficient and robust. In this paper we present a systematic study of several existing machine learning regression techniques and compare their performance for retrieving exoplanet atmospheric parameters from transmission spectra. We benchmark the performance of the different algorithms on the accuracy, precision, and speed. The regression methods tested here include partial least squares (PLS), support vector machines (SVM), k nearest neighbors (KNN), decision trees (DT), random forests (RF), voting (VOTE), stacking (STACK), and extreme gradient boosting (XGB). We also investigate the impact of different preprocessing methods of the training data on the model performance. We quantify the model uncertainties across the entire dynamical range of planetary parameters. The best performing combination of ML model and preprocessing scheme is validated on a the case study of JWST observation of WASP-39b.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04982v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roy T. Forestano, Konstantin T. Matchev, Katia Matcheva, Eyup B. Unlu</dc:creator>
    </item>
    <item>
      <title>The Fast Stochastic Matching Pursuit for Neutrino and Dark Matter Experiments</title>
      <link>https://arxiv.org/abs/2403.03156</link>
      <description>arXiv:2403.03156v5 Announce Type: replace-cross 
Abstract: Photomultiplier tubes (PMTs) are widely deployed at neutrino and dark matter experiments for photon counting. When multiple photons hit a PMT consecutively, their photo-electron (PE) pulses pile up to hinder the precise measurements of the count and timings. We introduce Fast Stochastic Matching Pursuit (FSMP) to analyze the PMT signal waveforms into individual PEs with the strategy of reversible-jump Markov-chain Monte Carlo. We demonstrate that FSMP improves the energy and time resolution of PMT-based experiments and gains acceleration on GPUs. It is suitable for dynode PMTs, and is extensible to microchannel-plate (MCP) PMTs. In the condition of our laboratory characterization of 8-inch MCP-PMTs, FSMP improves the energy resolution by up to 10% from the conventional method of waveform integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03156v5</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuyi Wang, Aiqiang Zhang, Yiyang Wu, Benda Xu, Xuewei Liu, Jiajie Chen, Zhe Wang, Shaomin Chen</dc:creator>
    </item>
  </channel>
</rss>
