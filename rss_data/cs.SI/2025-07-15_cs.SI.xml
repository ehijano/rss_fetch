<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 15 Jul 2025 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Analysing Health Misinformation with Advanced Centrality Metrics in Online Social Networks</title>
      <link>https://arxiv.org/abs/2507.09055</link>
      <description>arXiv:2507.09055v1 Announce Type: new 
Abstract: The rapid spread of health misinformation on online social networks (OSNs) during global crises such as the COVID-19 pandemic poses challenges to public health, social stability, and institutional trust. Centrality metrics have long been pivotal in understanding the dynamics of information flow, particularly in the context of health misinformation. However, the increasing complexity and dynamism of online networks, especially during crises, highlight the limitations of these traditional approaches. This study introduces and compares three novel centrality metrics: dynamic influence centrality (DIC), health misinformation vulnerability centrality (MVC), and propagation centrality (PC). These metrics incorporate temporal dynamics, susceptibility, and multilayered network interactions. Using the FibVID dataset, we compared traditional and novel metrics to identify influential nodes, propagation pathways, and misinformation influencers. Traditional metrics identified 29 influential nodes, while the new metrics uncovered 24 unique nodes, resulting in 42 combined nodes, an increase of 44.83%. Baseline interventions reduced health misinformation by 50%, while incorporating the new metrics increased this to 62.5%, an improvement of 25%. To evaluate the broader applicability of the proposed metrics, we validated our framework on a second dataset, Monant Medical Misinformation, which covers a diverse range of health misinformation discussions beyond COVID-19. The results confirmed that the advanced metrics generalised successfully, identifying distinct influential actors not captured by traditional methods. In general, the findings suggest that a combination of traditional and novel centrality measures offers a more robust and generalisable framework for understanding and mitigating the spread of health misinformation in different online network contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09055v1</guid>
      <category>cs.SI</category>
      <category>cs.IR</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1371/journal.pdig.0000888</arxiv:DOI>
      <dc:creator>Mkululi Sikosana, Sean Maudsley-Barton, Oluwaseun Ajao</dc:creator>
    </item>
    <item>
      <title>Advanced Health Misinformation Detection Through Hybrid CNN-LSTM Models Informed by the Elaboration Likelihood Model (ELM)</title>
      <link>https://arxiv.org/abs/2507.09149</link>
      <description>arXiv:2507.09149v1 Announce Type: new 
Abstract: Health misinformation during the COVID-19 pandemic has significantly challenged public health efforts globally. This study applies the Elaboration Likelihood Model (ELM) to enhance misinformation detection on social media using a hybrid Convolutional Neural Network (CNN) and Long Short-Term Memory (LSTM) model. The model aims to enhance the detection accuracy and reliability of misinformation classification by integrating ELM-based features such as text readability, sentiment polarity, and heuristic cues (e.g., punctuation frequency). The enhanced model achieved an accuracy of 97.37%, precision of 96.88%, recall of 98.50%, F1-score of 97.41%, and ROC-AUC of 99.50%. A combined model incorporating feature engineering further improved performance, achieving a precision of 98.88%, recall of 99.80%, F1-score of 99.41%, and ROC-AUC of 99.80%. These findings highlight the value of ELM features in improving detection performance, offering valuable contextual information. This study demonstrates the practical application of psychological theories in developing advanced machine learning algorithms to address health misinformation effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09149v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mkululi Sikosana, Sean Maudsley-Barton, Oluwaseun Ajao</dc:creator>
    </item>
    <item>
      <title>Negotiating Comfort: Simulating Personality-Driven LLM Agents in Shared Residential Social Networks</title>
      <link>https://arxiv.org/abs/2507.09657</link>
      <description>arXiv:2507.09657v1 Announce Type: new 
Abstract: We use generative agents powered by large language models (LLMs) to simulate a social network in a shared residential building, driving the temperature decisions for a central heating system. Agents, divided into Family Members and Representatives, consider personal preferences, personal traits, connections, and weather conditions. Daily simulations involve family-level consensus followed by building-wide decisions among representatives. We tested three personality traits distributions (positive, mixed, and negative) and found that positive traits correlate with higher happiness and stronger friendships. Temperature preferences, assertiveness, and selflessness have a significant impact on happiness and decisions. This work demonstrates how LLM-driven agents can help simulate nuanced human behavior where complex real-life human simulations are difficult to set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09657v1</guid>
      <category>cs.SI</category>
      <category>cs.MA</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ann Nedime Nese Rende, Tolga Yilmaz, \"Ozg\"ur Ulusoy</dc:creator>
    </item>
    <item>
      <title>Experimental Analysis and Evaluation of Cohesive Subgraph Discovery</title>
      <link>https://arxiv.org/abs/2507.10262</link>
      <description>arXiv:2507.10262v1 Announce Type: new 
Abstract: Retrieving cohesive subgraphs in networks is a fundamental problem in social network analysis and graph data management. These subgraphs can be used for marketing strategies or recommendation systems. Despite the introduction of numerous models over the years, a systematic comparison of their performance, especially across varied network configurations, remains unexplored. In this study, we evaluated various cohesive subgraph models using task-based evaluations and conducted extensive experimental studies on both synthetic and real-world networks. Thus, we unveil the characteristics of cohesive subgraph models, highlighting their efficiency and applicability. Our findings not only provide a detailed evaluation of current models but also lay the groundwork for future research by shedding light on the balance between the interpretability and cohesion of the subgraphs. This research guides the selection of suitable models for specific analytical needs and applications, providing valuable insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10262v1</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dahee Kim, Song Kim, Jeongseon Kim, Junghoon Kim, Kaiyu Feng, Sungsu Lim, Jungeun Kim</dc:creator>
    </item>
    <item>
      <title>FlowsDT: A Geospatial Digital Twin for Navigating Urban Flood Dynamics</title>
      <link>https://arxiv.org/abs/2507.08850</link>
      <description>arXiv:2507.08850v1 Announce Type: cross 
Abstract: Communities worldwide increasingly confront flood hazards intensified by climate change, urban expansion, and environmental degradation. Addressing these challenges requires real-time flood analysis, precise flood forecasting, and robust risk communications with stakeholders to implement efficient mitigation strategies. Recent advances in hydrodynamic modeling and digital twins afford new opportunities for high-resolution flood modeling and visualization at the street and basement levels. Focusing on Galveston City, a barrier island in Texas, U.S., this study created a geospatial digital twin (GDT) supported by 1D-2D coupled hydrodynamic models to strengthen urban resilience to pluvial and fluvial flooding. The objectives include: (1) developing a GDT (FlowsDT-Galveston) incorporating topography, hydrography, and infrastructure; (2) validating the twin using historical flood events and social sensing; (3) modeling hyperlocal flood conditions under 2-, 10-, 25-, 50-, and 100-year return period rainfall scenarios; and (4) identifying at-risk zones under different scenarios. This study employs the PCSWMM to create dynamic virtual replicas of urban landscapes and accurate flood modeling. By integrating LiDAR data, land cover, and storm sewer geometries, the model can simulate flood depth, extent, duration, and velocity in a 4-D environment across different historical and design storms. Results show buildings inundated over one foot increased by 5.7% from 2- to 100-year flood. Road inundations above 1 foot increased by 6.7% from 2- to 100-year floods. The proposed model can support proactive flood management and urban planning in Galveston; and inform disaster resilience efforts and guide sustainable infrastructure development. The framework can be extended to other communities facing similar challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08850v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Debayan Mandal, Lei Zou, Abhinav Wadhwa, Rohan Singh Wilkho, Zhenhang Cai, Bing Zhou, Xinyue Ye, Galen Newman, Nasir Gharaibeh, Burak G\"uneralp</dc:creator>
    </item>
    <item>
      <title>The Consistency-Acceptability Divergence of LLMs in Judicial Decision-Making: Task and Stakeholder Dimensions</title>
      <link>https://arxiv.org/abs/2507.08881</link>
      <description>arXiv:2507.08881v1 Announce Type: cross 
Abstract: The integration of large language model (LLM) technology into judicial systems is fundamentally transforming legal practice worldwide. However, this global transformation has revealed an urgent paradox requiring immediate attention. This study introduces the concept of ``consistency-acceptability divergence'' for the first time, referring to the gap between technical consistency and social acceptance. While LLMs achieve high consistency at the technical level, this consistency demonstrates both positive and negative effects. Through comprehensive analysis of recent data on LLM judicial applications from 2023--2025, this study finds that addressing this challenge requires understanding both task and stakeholder dimensions. This study proposes the Dual-Track Deliberative Multi-Role LLM Judicial Governance Framework (DTDMR-LJGF), which enables intelligent task classification and meaningful interaction among diverse stakeholders. This framework offers both theoretical insights and practical guidance for building an LLM judicial ecosystem that balances technical efficiency with social legitimacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08881v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhang MingDa, Xu Qing</dc:creator>
    </item>
    <item>
      <title>Te Ahorr\'e Un Click: A Revised Definition of Clickbait and Detection in Spanish News</title>
      <link>https://arxiv.org/abs/2507.09777</link>
      <description>arXiv:2507.09777v1 Announce Type: cross 
Abstract: We revise the definition of clickbait, which lacks current consensus, and argue that the creation of a curiosity gap is the key concept that distinguishes clickbait from other related phenomena such as sensationalism and headlines that do not deliver what they promise or diverge from the article. Therefore, we propose a new definition: clickbait is a technique for generating headlines and teasers that deliberately omit part of the information with the goal of raising the readers' curiosity, capturing their attention and enticing them to click. We introduce a new approach to clickbait detection datasets creation, by refining the concept limits and annotations criteria, minimizing the subjectivity in the decision as much as possible. Following it, we created and release TA1C (for Te Ahorr\'e Un Click, Spanish for Saved You A Click), the first open source dataset for clickbait detection in Spanish. It consists of 3,500 tweets coming from 18 well known media sources, manually annotated and reaching a 0.825 Fleiss' K inter annotator agreement. We implement strong baselines that achieve 0.84 in F1-score.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09777v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-80366-6_32</arxiv:DOI>
      <arxiv:journal_reference>Advances in Artificial Intelligence IBERAMIA 2024, Lecture Notes in Computer Science (LNCS), volume 14312</arxiv:journal_reference>
      <dc:creator>Gabriel Mordecki, Guillermo Moncecchi, Javier Couto</dc:creator>
    </item>
    <item>
      <title>Quantification of Interdependent Emotion Dynamics in Online Interactions</title>
      <link>https://arxiv.org/abs/2408.05700</link>
      <description>arXiv:2408.05700v3 Announce Type: replace 
Abstract: A growing share of human interactions now occurs online, where the expression and perception of emotions are often amplified and distorted. Yet, the interplay between different emotions and the extent to which they are driven by external stimuli or social feedback remains poorly understood. We calibrate a multivariate Hawkes self-exciting point process to model the temporal expression of six basic emotions in YouTube Live chats. This framework captures both temporal and cross-emotional dependencies while allowing us to disentangle the influence of video content (exogenous) from peer interactions (endogenous). We find that emotional expressions are up to four times more strongly driven by peer interaction than by video content. Positivity is more contagious, spreading three times more readily, whereas negativity is more memorable, lingering nearly twice as long. Moreover, we observe asymmetric cross-excitation, with negative emotions frequently triggering positive ones, a pattern consistent with trolling dynamics, but not the reverse. These findings highlight the central role of social interaction in shaping emotional dynamics online and the risks of emotional manipulation as human-chatbot interactions become increasingly realistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05700v3</guid>
      <category>cs.SI</category>
      <category>cs.HC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yishan Luo, Didier Sornette, Sandro Claudio Lera</dc:creator>
    </item>
    <item>
      <title>PureRank: A Parameter-Free Recursive Importance Measure for Network Nodes</title>
      <link>https://arxiv.org/abs/2501.00417</link>
      <description>arXiv:2501.00417v5 Announce Type: replace 
Abstract: This study focuses on parameter-free importance measures, based on the recursive definition of importance (RDI), for network nodes. The best-known examples of such RDI-based measures are eigenvector centrality and Seeley centrality, but they are applicable only to strongly connected networks. In contrast, Katz centrality and its variants, including PageRank, are RDI-inspired measures that introduce free parameters to handle general networks. This motivates the overlooked question of whether an RDI-based measure can be defined for arbitrary networks without introducing free parameters. This question is addressed by introducing $PureRank$, a parameter-free recursive importance measure. PureRank proceeds in three steps: (i) nodes are classified into recurrent, transient, and dangling classes via strongly connected component decomposition; (ii) local importance vectors for these classes are formulated as solutions to Katz parameter optimization problems aimed at best approximating eigenvector centrality within each class; and (iii) these vectors are aggregated into global scores via the RDI principle. This modular design enables parallel and incremental computation. PureRank also admits a probabilistic interpretation via a random-surfer model. The effectiveness and characteristics of PureRank are evaluated through numerical experiments on large-scale real-world networks, in comparison with PageRank. Finally, extension of PureRank to multi-attribute networks is discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00417v5</guid>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroyuki Masuyama</dc:creator>
    </item>
    <item>
      <title>Preserving spreading dynamics and information flow in complex network reduction</title>
      <link>https://arxiv.org/abs/2506.18641</link>
      <description>arXiv:2506.18641v2 Announce Type: replace 
Abstract: Effectively preserving both the structural and dynamical properties during the reduction of complex networks remains a significant research topic. Existing network reduction methods based on renormalization group or sampling often face challenges such as high computational complexity and the loss of critical dynamic attributes. This paper proposes an efficient network reduction framework based on subgraph extraction, which accurately preserves epidemic spreading dynamics and information flow through a coordinated optimization strategy of node removal and edge pruning. Specifically, a node removal algorithm driven by enhanced degree centrality is introduced to preferentially remove low-centrality nodes, thereby constructing a smaller-scale subnetwork. Subsequently, an edge pruning algorithm is designed to regulate the edge density of the subnetwork, ensuring that its average degree remains approximately consistent with that of the original network. Experimental results on Erd\"os-R\'enyi random graphs, Barab\'asi-Albert scale-free networks, and real-world social contact networks from various domains demonstrate that this proposed method can reduce the size of networks with heterogeneous structures by more than 85\%, while preserving their epidemic dynamics and information flow. More importantly, our method almost always achieves the highest accuracy compared to state-of-the-art techniques. These findings provide valuable insights for predicting the dynamical behavior of large-scale real-world networks, and also reveal that a large number of nodes and edges in real-world networks play redundant roles in information transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18641v2</guid>
      <category>cs.SI</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dan Chen, Housheng Su, Yong Wang, Jie Liu</dc:creator>
    </item>
    <item>
      <title>Scalable Signed Exponential Random Graph Models under Local Dependence</title>
      <link>https://arxiv.org/abs/2507.07660</link>
      <description>arXiv:2507.07660v2 Announce Type: replace 
Abstract: Traditional network analysis focuses on binary edges, while real-world relationships are more nuanced, encompassing cooperation, neutrality, and conflict. The rise of negative edges in social media discussions spurred interest in analyzing signed interactions, especially in polarized debates. However, the vast data generated by digital networks presents challenges for traditional methods like Stochastic Block Models (SBM) and Exponential Family Random Graph Models (ERGM), particularly due to the homogeneity assumption and global dependence, which become increasingly unrealistic as network size grows. To address this, we propose a novel method that combines the strengths of SBM and ERGM while mitigating their weaknesses by incorporating local dependence based on non-overlapping blocks. Our approach involves a two-step process: first, decomposing the network into sub-networks using SBM approximation, and then estimating parameters using ERGM methods. We validate our method on large synthetic networks and apply it to a signed Wikipedia network of thousands of editors. Through the use of local dependence, we find patterns consistent with structural balance theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07660v2</guid>
      <category>cs.SI</category>
      <category>stat.CO</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marc Schalberger, Cornelius Fritz</dc:creator>
    </item>
    <item>
      <title>Introduction to correlation networks: Interdisciplinary approaches beyond thresholding</title>
      <link>https://arxiv.org/abs/2311.09536</link>
      <description>arXiv:2311.09536v3 Announce Type: replace-cross 
Abstract: Many empirical networks originate from correlational data, arising in domains as diverse as psychology, neuroscience, genomics, microbiology, finance, and climate science. Specialized algorithms and theory have been developed in different application domains for working with such networks, as well as in statistics, network science, and computer science, often with limited communication between practitioners in different fields. This leaves significant room for cross-pollination across disciplines. A central challenge is that it is not always clear how to best transform correlation matrix data into networks for the application at hand, and probably the most widespread method, i.e., thresholding on the correlation value to create either unweighted or weighted networks, suffers from multiple problems. In this article, we review various methods of constructing and analyzing correlation networks, ranging from thresholding and its improvements to weighted networks, regularization, dynamic correlation networks, threshold-free approaches, comparison with null models, and more. Finally, we propose and discuss recommended practices and a variety of key open questions currently confronting this field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09536v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.physrep.2025.06.002</arxiv:DOI>
      <arxiv:journal_reference>Physics Reports, 1136, 1-39 (2025)</arxiv:journal_reference>
      <dc:creator>Naoki Masuda, Zachary M. Boyd, Diego Garlaschelli, Peter J. Mucha</dc:creator>
    </item>
    <item>
      <title>Leveraging Large Language Models for Multi-Class and Multi-Label Detection of Drug Use and Overdose Symptoms on Social Media</title>
      <link>https://arxiv.org/abs/2504.12355</link>
      <description>arXiv:2504.12355v2 Announce Type: replace-cross 
Abstract: Drug overdose remains a critical global health issue, often driven by misuse of opioids, painkillers, and psychiatric medications. Traditional research methods face limitations, whereas social media offers real-time insights into self-reported substance use and overdose symptoms. This study proposes an AI-driven NLP framework trained on annotated social media data to detect commonly used drugs and associated overdose symptoms. Using a hybrid annotation strategy with LLMs and human annotators, we applied traditional ML models, neural networks, and advanced transformer-based models. Our framework achieved 98% accuracy in multi-class and 97% in multi-label classification, outperforming baseline models by up to 8%. These findings highlight the potential of AI for supporting public health surveillance and personalized intervention strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12355v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ahmad, Fida Ullah, Ummhy Habiba, ldar Batyrshin, Grigori Sidorov</dc:creator>
    </item>
    <item>
      <title>LLM Agents Are the Antidote to Walled Gardens</title>
      <link>https://arxiv.org/abs/2506.23978</link>
      <description>arXiv:2506.23978v2 Announce Type: replace-cross 
Abstract: While the Internet's core infrastructure was designed to be open and universal, today's application layer is dominated by closed, proprietary platforms. Open and interoperable APIs require significant investment, and market leaders have little incentive to enable data exchange that could erode their user lock-in. We argue that LLM-based agents fundamentally disrupt this status quo. Agents can automatically translate between data formats and interact with interfaces designed for humans: this makes interoperability dramatically cheaper and effectively unavoidable. We name this shift universal interoperability: the ability for any two digital services to exchange data seamlessly using AI-mediated adapters. Universal interoperability undermines monopolistic behaviours and promotes data portability. However, it can also lead to new security risks and technical debt. Our position is that the ML community should embrace this development while building the appropriate frameworks to mitigate the downsides. By acting now, we can harness AI to restore user freedom and competitive markets without sacrificing security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23978v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Tue, 15 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuele Marro, Philip Torr</dc:creator>
    </item>
  </channel>
</rss>
