<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.GN</link>
    <description>q-bio.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Aug 2025 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>NucEL: Single-Nucleotide ELECTRA-Style Genomic Pre-training for Efficient and Interpretable Representations</title>
      <link>https://arxiv.org/abs/2508.13191</link>
      <description>arXiv:2508.13191v1 Announce Type: new 
Abstract: Pre-training large language models on genomic sequences is a powerful approach for learning biologically meaningful representations. Masked language modeling (MLM) methods, such as DNABERT and Nucleotide Transformer (NT), achieve strong performance but suffer from partial token supervision, pre-training/fine-tuning mismatches, and high computational costs. We introduce NucEL, the first ELECTRA-style pre-training framework for genomic foundation models, addressing these limitations. Using a discriminator to identify tokens altered by a generator, NucEL provides comprehensive token-level supervision across all sequence positions, improving efficiency over the partial supervision of MLM. Incorporating ModernBERT's hybrid local-global attention and flash attention, NucEL offers an optimized BERT architecture for genomic modeling. Unlike 6-mer tokenization, NucEL uses single-nucleotide tokens for fine-grained resolution, boosting both efficiency and interpretability. Pre-trained on the human genome, NucEL achieves state-of-the-art results on diverse downstream tasks -- regulatory element identification (e.g., promoters, enhancers), transcription factor binding prediction, open chromatin classification, and histone modification profiling -- surpassing similarly sized MLM-based models and rivaling models 25x larger, such as NT. Ablation studies highlight optimal tokenization and masking strategies for ELECTRA-style DNA pre-training. Attention analysis reveals NucEL's superior capture of biologically relevant motifs compared to NT, providing insights into hierarchical learning and regulatory element modeling. These findings demonstrate ELECTRA-style pre-training as an efficient, effective strategy for genomic representation learning with broad implications for genomic research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13191v1</guid>
      <category>q-bio.GN</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Ding, Brian Parker, Jiayu Wen</dc:creator>
    </item>
    <item>
      <title>Benchmarking LLM-based Agents for Single-cell Omics Analysis</title>
      <link>https://arxiv.org/abs/2508.13201</link>
      <description>arXiv:2508.13201v1 Announce Type: new 
Abstract: The surge in multimodal single-cell omics data exposes limitations in traditional, manually defined analysis workflows. AI agents offer a paradigm shift, enabling adaptive planning, executable code generation, traceable decisions, and real-time knowledge fusion. However, the lack of a comprehensive benchmark critically hinders progress. We introduce a novel benchmarking evaluation system to rigorously assess agent capabilities in single-cell omics analysis. This system comprises: a unified platform compatible with diverse agent frameworks and LLMs; multidimensional metrics assessing cognitive program synthesis, collaboration, execution efficiency, bioinformatics knowledge integration, and task completion quality; and 50 diverse real-world single-cell omics analysis tasks spanning multi-omics, species, and sequencing technologies. Our evaluation reveals that Grok-3-beta achieves state-of-the-art performance among tested agent frameworks. Multi-agent frameworks significantly enhance collaboration and execution efficiency over single-agent approaches through specialized role division. Attribution analyses of agent capabilities identify that high-quality code generation is crucial for task success, and self-reflection has the most significant overall impact, followed by retrieval-augmented generation (RAG) and planning. This work highlights persistent challenges in code generation, long-context handling, and context-aware knowledge retrieval, providing a critical empirical foundation and best practices for developing robust AI agents in computational biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13201v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Liu, Lu Zhou, Ruikun He, Rongbo Shen, Yixue Li</dc:creator>
    </item>
    <item>
      <title>Improving the FAIRness and Sustainability of the NHGRI Resources Ecosystem</title>
      <link>https://arxiv.org/abs/2508.13498</link>
      <description>arXiv:2508.13498v1 Announce Type: new 
Abstract: In 2024, NHGRI-funded genomic resource projects completed a Self-Assessment Tool (SAT) and interviews to evaluate their application of FAIR (Findable, Accessible, Interoperable, Reusable) principles and sustainability. Key challenges were identified in metadata tools, data curation, variant identifiers, and data processing. Addressing these needs, we engaged the community through webinars and discussions, leading to a two-day workshop in March 2025. The workshop developed targeted recommendations, including improving transparency, standardizing identifiers, enhancing usability, implementing APIs, leveraging AI/ML for curation, and evaluating impact. These outcomes provide a framework for advancing FAIR practices, fostering collaboration, and strengthening the sustainability of NHGRI resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13498v1</guid>
      <category>q-bio.GN</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Larry Babb, Carol Bult, Vincent J. Carey, Robert J. Carroll, Benjamin C. Hitz, Chris J. Mungall, Heidi L. Rehm, Michael C. Schatz, Alex Wagner, NHGRI Resource Workshop Community</dc:creator>
    </item>
  </channel>
</rss>
