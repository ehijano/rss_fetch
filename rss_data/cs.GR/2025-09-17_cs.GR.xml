<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GR</link>
    <description>cs.GR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>CraftMesh: High-Fidelity Generative Mesh Manipulation via Poisson Seamless Fusion</title>
      <link>https://arxiv.org/abs/2509.13688</link>
      <description>arXiv:2509.13688v1 Announce Type: new 
Abstract: Controllable, high-fidelity mesh editing remains a significant challenge in 3D content creation. Existing generative methods often struggle with complex geometries and fail to produce detailed results. We propose CraftMesh, a novel framework for high-fidelity generative mesh manipulation via Poisson Seamless Fusion. Our key insight is to decompose mesh editing into a pipeline that leverages the strengths of 2D and 3D generative models: we edit a 2D reference image, then generate a region-specific 3D mesh, and seamlessly fuse it into the original model. We introduce two core techniques: Poisson Geometric Fusion, which utilizes a hybrid SDF/Mesh representation with normal blending to achieve harmonious geometric integration, and Poisson Texture Harmonization for visually consistent texture blending. Experimental results demonstrate that CraftMesh outperforms state-of-the-art methods, delivering superior global consistency and local detail in complex editing tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13688v1</guid>
      <category>cs.GR</category>
      <category>cs.AI</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Jincheng, Youcheng Cai, Ligang Liu</dc:creator>
    </item>
    <item>
      <title>Hyperspectral Polarimetric BRDFs of Real-world Materials</title>
      <link>https://arxiv.org/abs/2509.13779</link>
      <description>arXiv:2509.13779v1 Announce Type: new 
Abstract: Acquiring bidirectional reflectance distribution functions (BRDFs) is essential for simulating light transport and analytically modeling material properties. Over the past two decades, numerous intensity-only BRDF datasets in the visible spectrum have been introduced, primarily for RGB image rendering applications. However, in scientific and engineering domains, there remains an unmet need to model light transport with polarization--a fundamental wave property of light--across hyperspectral bands. To address this gap, we present the first hyperspectral-polarimetric BRDF (hpBRDF) dataset of real-world materials, spanning wavelengths from 414 to 950\,nm and densely sampled at 68 spectral bands. This dataset covers both the visible and near-infrared (NIR) spectra, enabling detailed material analysis and light reflection simulations that incorporate polarization at each narrow spectral band. We develop an efficient hpBRDF acquisition system that captures high-dimensional hpBRDFs within a feasible acquisition time. Using this system, we demonstrate hyperspectral-polarimetric rendering using the acquired hpBRDFs. To provide insights on hpBRDF, we analyze the hpBRDFs with respect to their dependencies on wavelength, polarization state, material type, and illumination/viewing geometry. Also, we propose compact representations through principal component analysis and implicit neural hpBRDF modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13779v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunseong Moon, Ryota Maeda, Suhyun Shin, Inseung Hwang, Youngchan Kim, Min H. Kim, Seung-Hwan Baek</dc:creator>
    </item>
    <item>
      <title>Plug-and-Play PDE Optimization for 3D Gaussian Splatting: Toward High-Quality Rendering and Reconstruction</title>
      <link>https://arxiv.org/abs/2509.13938</link>
      <description>arXiv:2509.13938v1 Announce Type: new 
Abstract: 3D Gaussian Splatting (3DGS) has revolutionized radiance field reconstruction by achieving high-quality novel view synthesis with fast rendering speed, introducing 3D Gaussian primitives to represent the scene. However, 3DGS encounters blurring and floaters when applied to complex scenes, caused by the reconstruction of redundant and ambiguous geometric structures. We attribute this issue to the unstable optimization of the Gaussians. To address this limitation, we present a plug-and-play PDE-based optimization method that overcomes the optimization constraints of 3DGS-based approaches in various tasks, such as novel view synthesis and surface reconstruction. Firstly, we theoretically derive that the 3DGS optimization procedure can be modeled as a PDE, and introduce a viscous term to ensure stable optimization. Secondly, we use the Material Point Method (MPM) to obtain a stable numerical solution of the PDE, which enhances both global and local constraints. Additionally, an effective Gaussian densification strategy and particle constraints are introduced to ensure fine-grained details. Extensive qualitative and quantitative experiments confirm that our method achieves state-of-the-art rendering and reconstruction quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13938v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Mo (University of Science,Technology of China), Youcheng Cai (University of Science,Technology of China), Ligang Liu (University of Science,Technology of China)</dc:creator>
    </item>
    <item>
      <title>Progressing Level-of-Detail Animation of Volumetric Elastodynamics</title>
      <link>https://arxiv.org/abs/2509.14177</link>
      <description>arXiv:2509.14177v1 Announce Type: new 
Abstract: We extend the progressive dynamics model (Zhang et al., 2024) from cloth and shell simulation to volumetric finite elements, enabling an efficient level-of-detail (LOD) animation-design pipeline with predictive coarse-resolution previews facilitating rapid iterative design for a final, to-be-generated, high-resolution animation of volumetric elastodynamics. This extension to volumetric domains poses significant new challenges, including the construction of suitable mesh hierarchies and the definition of effective prolongation operators for codimension-0 progressive dynamics. To address these challenges, we propose a practical method for defining multiresolution hierarchies and, more importantly, introduce a simple yet effective topology-aware algorithm for constructing prolongation operators between overlapping (but not necessarily conforming) volumetric meshes. Our key insight is a boundary binding strategy that enables the computation of barycentric coordinates, allowing several off-the-shelf interpolants -- such as standard barycentric coordinates, Biharmonic Coordinates (Wang et al., 2015), and Phong Deformation (James, 2020) -- to serve as "plug-and-play" components for prolongation with minimal modification. We show that our progressive volumetric simulation framework achieves high-fidelity matching LOD animation across resolutions including challenging dynamics with high speeds, large deformations, and frictional contact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14177v1</guid>
      <category>cs.GR</category>
      <pubDate>Thu, 18 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Eris Zhang, Doug L. James, Danny M. Kaufman</dc:creator>
    </item>
  </channel>
</rss>
