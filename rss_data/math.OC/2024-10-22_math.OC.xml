<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Oct 2024 02:08:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Simultaneously Solving FBSDEs with Neural Operators of Logarithmic Depth, Constant Width, and Sub-Linear Rank</title>
      <link>https://arxiv.org/abs/2410.14788</link>
      <description>arXiv:2410.14788v1 Announce Type: new 
Abstract: Forward-backwards stochastic differential equations (FBSDEs) are central in optimal control, game theory, economics, and mathematical finance. Unfortunately, the available FBSDE solvers operate on \textit{individual} FBSDEs, meaning that they cannot provide a computationally feasible strategy for solving large families of FBSDEs as these solvers must be re-run several times. \textit{Neural operators} (NOs) offer an alternative approach for \textit{simultaneously solving} large families of FBSDEs by directly approximating the solution operator mapping \textit{inputs:} terminal conditions and dynamics of the backwards process to \textit{outputs:} solutions to the associated FBSDE. Though universal approximation theorems (UATs) guarantee the existence of such NOs, these NOs are unrealistically large. We confirm that ``small'' NOs can uniformly approximate the solution operator to structured families of FBSDEs with random terminal time, uniformly on suitable compact sets determined by Sobolev norms, to any prescribed error $\varepsilon&gt;0$ using a depth of $\mathcal{O}(\log(1/\varepsilon))$, a width of $\mathcal{O}(1)$, and a sub-linear rank; i.e. $\mathcal{O}(1/\varepsilon^r)$ for some $r&lt;1$. This result is rooted in our second main contribution, which shows that convolutional NOs of similar depth, width, and rank can approximate the solution operator to a broad class of Elliptic PDEs. A key insight here is that the convolutional layers of our NO can efficiently encode the Green's function associated to the Elliptic PDEs linked to our FBSDEs. A byproduct of our analysis is the first theoretical justification for the benefit of lifting channels in NOs: they exponentially decelerate the growth rate of the NO's rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14788v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Furuya, Anastasis Kratsios</dc:creator>
    </item>
    <item>
      <title>Performance Estimation for Smooth and Strongly Convex Sets</title>
      <link>https://arxiv.org/abs/2410.14811</link>
      <description>arXiv:2410.14811v1 Announce Type: new 
Abstract: We extend recent computer-assisted design and analysis techniques for first-order optimization over structured functions--known as performance estimation--to apply to structured sets. We prove "interpolation theorems" for smooth and strongly convex sets with Slater points and bounded diameter, showing a wide range of extremal questions amount to structured mathematical programs. Prior function interpolation theorems are recovered as a limit of our set interpolation theory. Our theory provides finite-dimensional formulations of performance estimation problems for algorithms utilizing separating hyperplane oracles, linear optimization oracles, and/or projection oracles of smooth/strongly convex sets. As direct applications of this computer-assisted machinery, we identify the minimax optimal separating hyperplane method and several areas for improvement in the theory of Frank-Wolfe, Alternating Projections, and non-Lipschitz Smooth Optimization. While particular applications and methods are not our primary focus, several simple theorems and numerically supported conjectures are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14811v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Luner, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Beyond Discretization: Learning the Optimal Solution Path</title>
      <link>https://arxiv.org/abs/2410.14885</link>
      <description>arXiv:2410.14885v1 Announce Type: new 
Abstract: Many applications require minimizing a family of optimization problems indexed by some hyperparameter $\lambda \in \Lambda$ to obtain an entire solution path. Traditional approaches proceed by discretizing $\Lambda$ and solving a series of optimization problems. We propose an alternative approach that parameterizes the solution path with a set of basis functions and solves a \emph{single} stochastic optimization problem to learn the entire solution path. Our method offers substantial complexity improvements over discretization. When using constant-step size SGD, the uniform error of our learned solution path relative to the true path exhibits linear convergence to a constant related to the expressiveness of the basis. When the true solution path lies in the span of the basis, this constant is zero. We also prove stronger results for special cases common in machine learning: When $\lambda \in [-1, 1]$ and the solution path is $\nu$-times differentiable, constant step-size SGD learns a path with $\epsilon$ uniform error after at most $O(\epsilon^{\frac{1}{1-\nu}} \log(1/\epsilon))$ iterations, and when the solution path is analytic, it only requires $O\left(\log^2(1/\epsilon)\log\log(1/\epsilon)\right)$. By comparison, the best-known discretization schemes in these settings require at least $O(\epsilon^{-1/2})$ discretization points (and even more gradient calls). Finally, we propose an adaptive variant of our method that sequentially adds basis functions and demonstrates strong numerical performance through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14885v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiran Dong, Paul Grigas, Vishal Gupta</dc:creator>
    </item>
    <item>
      <title>Extreme Points of Spectrahedrons</title>
      <link>https://arxiv.org/abs/2410.14889</link>
      <description>arXiv:2410.14889v1 Announce Type: new 
Abstract: We consider the problem of characterizing extreme points of the convex set of positive linear operators on a possibly infinite-dimensional Hilbert space under linear constraints. We show that even perturbations of points in such sets admit what resembles a Douglas factorization. Using this result, we prove that an operator is extreme iff a corresponding set of linear operators is dense in the space of trace-class self-adjoint operators with range contained in the closure of the range of that operator. If the number of constraints is finite, we show that the extreme point must be of low-rank relative to the number of constraints and derive a purely rank-based characterization of the extreme points.
  In the finite-dimensional setting, our results lead to a remarkably simple characterization of the elliptope, that is, the set of correlation matrices, in terms of the Hadamard product which allows us to characterize the set of matrices which constitute the equality case of the Hadamard rank inequality when the involved matrices are equal and positive semi-definite. We illustrate the importance of our results using examples from statistics and quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14889v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kartik G. Waghmare, Victor M. Panaretos</dc:creator>
    </item>
    <item>
      <title>Out-of-distribution Robust Optimization</title>
      <link>https://arxiv.org/abs/2410.14899</link>
      <description>arXiv:2410.14899v1 Announce Type: new 
Abstract: In this paper, we consider the contextual robust optimization problem under an out-of-distribution setting. The contextual robust optimization problem considers a risk-sensitive objective function for an optimization problem with the presence of a context vector (also known as covariates or side information) capturing related information. While the existing works mainly consider the in-distribution setting, and the resultant robustness achieved is in an out-of-sample sense, our paper studies an out-of-distribution setting where there can be a difference between the test environment and the training environment where the data are collected. We propose methods that handle this out-of-distribution setting, and the key relies on a density ratio estimation for the distribution shift. We show that additional structures such as covariate shift and label shift are not only helpful in defending distribution shift but also necessary in avoiding non-trivial solutions compared to other principled methods such as distributionally robust optimization. We also illustrate how the covariates can be useful in this procedure. Numerical experiments generate more intuitions and demonstrate that the proposed methods can help avoid over-conservative solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14899v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhongze Cai, Hansheng Jiang, Xiaocheng Li</dc:creator>
    </item>
    <item>
      <title>A Scalable Interior-Point Gauss-Newton Method for PDE-Constrained Optimization with Bound Constraints</title>
      <link>https://arxiv.org/abs/2410.14918</link>
      <description>arXiv:2410.14918v1 Announce Type: new 
Abstract: We present a scalable approach to solve a class of elliptic partial differential equation (PDE)-constrained optimization problems with bound constraints. This approach utilizes a robust full-space interior-point (IP)-Gauss-Newton optimization method. To cope with the poorly-conditioned IP-Gauss-Newton saddle-point linear systems that need to be solved, once per optimization step, we propose two spectrally related preconditioners. These preconditioners leverage the limited informativeness of data in regularized PDE-constrained optimization problems. A block Gauss-Seidel preconditioner is proposed for the GMRES-based solution of the IP-Gauss-Newton linear systems. It is shown, for a large-class of PDE- and bound-constrained optimization problems, that the spectrum of the block Gauss-Seidel preconditioned IP-Gauss-Newton matrix is asymptotically independent of discretization and is not impacted by the ill-conditioning that notoriously plagues interior-point methods. We propose a regularization and log-barrier Hessian preconditioner for the preconditioned conjugate gradient (PCG)-based solution of the related IP-Gauss-Newton-Schur complement linear systems. The scalability of the approach is demonstrated on an example problem with bound and nonlinear elliptic PDE constraints. The numerical solution of the optimization problem is shown to require a discretization independent number of IP-Gauss-Newton linear solves. Furthermore, the linear systems are solved in a discretization and IP ill-conditioning independent number of preconditioned Krylov subspace iterations. The parallel scalability of preconditioner and linear system matrix applies, achieved with algebraic multigrid based solvers, and the aforementioned algorithmic scalability permits a parallel scalable means to compute solutions of a large class of PDE- and bound-constrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14918v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tucker Hartland, Cosmin G. Petra, Noemi Petra, Jingyi Wang</dc:creator>
    </item>
    <item>
      <title>Achieving O(1/N) Optimality Gap in Restless Bandits through Diffusion Approximation</title>
      <link>https://arxiv.org/abs/2410.15003</link>
      <description>arXiv:2410.15003v1 Announce Type: new 
Abstract: We study the finite horizon Restless Multi-Armed Bandit (RMAB) problem with $N$ homogeneous arms, focusing on the challenges posed by degenerate RMABs, which are prevalent in practical applications. While previous work has shown that Linear Programming (LP)-based policies achieve exponentially fast convergence relative to the LP upper bound in non-degenerate models, applying these LP-based policies to degenerate RMABs results in slower convergence rates of $O(1/\sqrt{N})$. We construct a diffusion system that incorporates both the mean and variance of the stochastic processes, in contrast to the fluid system from the LP, which only accounts for the mean, thereby providing a more accurate representation of RMAB dynamics. Consequently, our novel diffusion-resolving policy achieves an optimality gap of $O(1/N)$ relative to the true optimal value, rather than the LP upper bound, revealing that the fluid approximation and the LP upper bound are too loose in degenerate settings. These insights pave the way for constructing policies that surpass the $O(1/\sqrt{N})$ optimality gap for any RMAB, whether degenerate or not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15003v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chen Yan, Weina Wang, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Time-Varying Convex Optimization with O(n) Computational Complexity</title>
      <link>https://arxiv.org/abs/2410.15009</link>
      <description>arXiv:2410.15009v1 Announce Type: new 
Abstract: In this article, we consider the problem of unconstrained time-varying convex optimization, where the cost function changes with time. We provide an in-depth technical analysis of the problem and argue why freezing the cost at each time step and taking finite steps toward the minimizer is not the best tracking solution for this problem. We propose a set of algorithms that by taking into account the temporal variation of the cost aim to reduce the tracking error of the time-varying minimizer of the problem. The main contribution of our work is that our proposed algorithms only require the first-order derivatives of the cost function with respect to the decision variable. This approach significantly reduces computational cost compared to the existing algorithms, which use the inverse of the Hessian of the cost. Specifically, the proposed algorithms reduce the computational cost from $O(n^3)$ to $O(n)$ per timestep, where $n$ is the size of the decision variable. Avoiding the inverse of the Hessian also makes our algorithms applicable to non-convex optimization problems. We refer to these algorithms as $O(n)$-algorithms. These $O(n)$-algorithms are designed to solve the problem for different scenarios based on the available temporal information about the cost. We illustrate our results through various examples, including the solution of a model predictive control problem framed as a convex optimization problem with a streaming time-varying cost function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15009v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Rostami, S. S. Kia</dc:creator>
    </item>
    <item>
      <title>Numerical optimal control for distributed delay differential equations: A simultaneous approach based on linearization of the delayed variables</title>
      <link>https://arxiv.org/abs/2410.15083</link>
      <description>arXiv:2410.15083v1 Announce Type: new 
Abstract: Time delays are ubiquitous in industrial processes, and they must be accounted for when designing control algorithms because they have a significant effect on the process dynamics. Therefore, in this work, we propose a simultaneous approach for numerical optimal control of delay differential equations with distributed time delays. Specifically, we linearize the delayed variables around the current time, and we discretize the resulting implicit differential equations using Euler's implicit method. Furthermore, we transcribe the infinite-dimensional optimal control problem into a finite-dimensional nonlinear program, which we solve using Matlab's fmincon. Finally, we demonstrate the efficacy of the approach using a numerical example involving a molten salt nuclear fission reactor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15083v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias K. S. Ritschel</dc:creator>
    </item>
    <item>
      <title>Cut-based Conflict Analysis in Mixed Integer Programming</title>
      <link>https://arxiv.org/abs/2410.15110</link>
      <description>arXiv:2410.15110v1 Announce Type: new 
Abstract: For almost two decades, mixed integer programming (MIP) solvers have used graph-based conflict analysis to learn from local infeasibilities during branch-and-bound search. In this paper, we improve MIP conflict analysis by instead using reasoning based on cuts, inspired by the development of conflict-driven solvers for pseudo-Boolean optimization. Phrased in MIP terminology, this type of conflict analysis can be understood as a sequence of linear combinations, integer roundings, and cut generation. We leverage this MIP perspective to design a new conflict analysis algorithm based on mixed integer rounding cuts, which theoretically dominates the state-of-the-art method in pseudo-Boolean optimization using Chv\'atal-Gomory cuts. Furthermore, we extend this cut-based conflict analysis from pure binary programs to mixed binary programs and-in limited form-to general MIP with also integer-valued variables. We perform an empirical evaluation of cut-based conflict analysis as implemented in the open-source MIP solver SCIP, testing it on a large and diverse set of MIP instances from MIPLIB 2017. Our experimental results indicate that the new algorithm improves the default performance of SCIP in terms of running time, number of nodes in the search tree, and the number of instances solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15110v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gioni Mexi, Felipe Serrano, Timo Berthold, Ambros Gleixner, Jakob Nordstr\"om</dc:creator>
    </item>
    <item>
      <title>Mean Field LQG Social Optimization: A Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2410.15119</link>
      <description>arXiv:2410.15119v1 Announce Type: new 
Abstract: This paper presents a novel model-free method to solve linear quadratic Gaussian mean field social control problems in the presence of multiplicative noise. The objective is to achieve a social optimum by solving two algebraic Riccati equations (AREs) and determining a mean field (MF) state, both without requiring prior knowledge of individual system dynamics for all agents. In the proposed approach, we first employ integral reinforcement learning techniques to develop two model-free iterative equations that converge to solutions for the stochastic ARE and the induced indefinite ARE respectively. Then, the MF state is approximated, either through the Monte Carlo method with the obtained gain matrices or through the system identification with the measured data. Notably, a unified state and input samples collected from a single agent are used in both iterations and identification procedure, making the method more computationally efficient and scalable. Finally, a numerical example is given to demonstrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15119v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenhui Xu, Bing-Chang Wang, Tielong Shen</dc:creator>
    </item>
    <item>
      <title>Backstepping for Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2410.15146</link>
      <description>arXiv:2410.15146v1 Announce Type: new 
Abstract: Systems modeled by partial differential equations (PDEs) are at least as ubiquitous as systems that are by nature finite-dimensional and modeled by ordinary differential equations (ODEs). And yet, systematic and readily usable methodologies, for such a significant portion of real systems, have been historically scarce. Around the year 2000, the backstepping approach to PDE control began to offer not only a less abstract alternative to PDE control techniques replicating optimal and spectrum assignment techniques of the 1960s, but also enabled the methodologies of adaptive and nonlinear control, matured in the 1980s and 1990s, to be extended from ODEs to PDEs, allowing feedback synthesis for physical and engineering systems that are uncertain, nonlinear, and infinite-dimensional. The PDE backstepping literature has grown in its nearly a quarter century of development to many hundreds of papers and nearly a dozen books. This survey aims to facilitate the entry, for a new researcher, into this thriving area of overwhelming size and topical diversity. Designs of controllers and observers, for parabolic, hyperbolic, and other classes of PDEs, in one and more dimensions (in box and spherical geometries), with nonlinear, adaptive, sampled-data, and event-triggered extensions, are covered in the survey. The lifeblood of control are technology and physics. The survey places a particular emphasis on applications that have motivated the development of the theory and which have benefited from the theory and designs: applications involving flows, flexible structures, materials, thermal and chemically reacting dynamics, energy (from oil drilling to batteries and magnetic confinement fusions), and vehicles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15146v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael Vazquez, Jean Auriol, Federico Bribiesca-Argomedo, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Robust Low-rank Tensor Train Recovery</title>
      <link>https://arxiv.org/abs/2410.15224</link>
      <description>arXiv:2410.15224v1 Announce Type: new 
Abstract: Tensor train (TT) decomposition represents an $N$-order tensor using $O(N)$ matrices (i.e., factors) of small dimensions, achieved through products among these factors. Due to its compact representation, TT decomposition has found wide applications, including various tensor recovery problems in signal processing and quantum information. In this paper, we study the problem of reconstructing a TT format tensor from measurements that are contaminated by outliers with arbitrary values. Given the vulnerability of smooth formulations to corruptions, we use an $\ell_1$ loss function to enhance robustness against outliers. We first establish the $\ell_1/\ell_2$-restricted isometry property (RIP) for Gaussian measurement operators, demonstrating that the information in the TT format tensor can be preserved using a number of measurements that grows linearly with $N$. We also prove the sharpness property for the $\ell_1$ loss function optimized over TT format tensors. Building on the $\ell_1/\ell_2$-RIP and sharpness property, we then propose two complementary methods to recover the TT format tensor from the corrupted measurements: the projected subgradient method (PSubGM), which optimizes over the entire tensor, and the factorized Riemannian subgradient method (FRSubGM), which optimizes directly over the factors. Compared to PSubGM, the factorized approach FRSubGM significantly reduces the memory cost at the expense of a slightly slower convergence rate. Nevertheless, we show that both methods, with diminishing step sizes, converge linearly to the ground-truth tensor given an appropriate initialization, which can be obtained by a truncated spectral method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15224v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Two-stage Online Reusable Resource Allocation: Reservation, Overbooking and Confirmation Call</title>
      <link>https://arxiv.org/abs/2410.15245</link>
      <description>arXiv:2410.15245v1 Announce Type: new 
Abstract: We study a two-stage online reusable resource allocation problem over T days involving advance reservations and walk-ins. Each day begins with a reservation stage (Stage I), where reservation requests arrive sequentially. When service starts (Stage II), both reserved and walk-in customers arrive to check in and occupy resources for several days. Reserved customers can cancel without penalty before or during a confirmation call initiated by the decision maker (DM) before day's end. The DM must immediately accept or reject each booking or check-in request, potentially overbooking by accepting more reservations than capacity. An overbooking loss occurs if a reserved customer's check-in is rejected in Stage II; a reward is obtained for each occupied resource unit daily. Our goal is to develop an online policy that controls bookings and check-ins to maximize total revenue over the T-day horizon. We show that due to cancellation uncertainties and complex correlations between occupancy durations, any online policy incurs a regret of \Omega(T) compared to the offline optimal policy when the \textit{busy season} assumption does not hold. To address this, we introduce decoupled adaptive safety stocks, which use only single-day information to hedge against overbooking risks and reduce resource idling. Under the busy season condition, our policy decouples the overall offline optimal into single-day offline optimal policies. Consequently, the regret between our policy and the offline optimal decays exponentially with the time between the confirmation call and day's end, suggesting the DM can delay confirmation calls while maintaining near-optimal performance. We validate our algorithm through sythetic experiments and empirical data from an Algarve resort hotel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15245v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruicheng Ao, Hengyu Fu, David Simchi-levi</dc:creator>
    </item>
    <item>
      <title>Tighter Performance Theory of FedExProx</title>
      <link>https://arxiv.org/abs/2410.15368</link>
      <description>arXiv:2410.15368v1 Announce Type: new 
Abstract: We revisit FedExProx - a recently proposed distributed optimization method designed to enhance convergence properties of parallel proximal algorithms via extrapolation. In the process, we uncover a surprising flaw: its known theoretical guarantees on quadratic optimization tasks are no better than those offered by the vanilla Gradient Descent (GD) method. Motivated by this observation, we develop a novel analysis framework, establishing a tighter linear convergence rate for non-strongly convex quadratic problems. By incorporating both computation and communication costs, we demonstrate that FedExProx can indeed provably outperform GD, in stark contrast to the original analysis. Furthermore, we consider partial participation scenarios and analyze two adaptive extrapolation strategies - based on gradient diversity and Polyak stepsizes - again significantly outperforming previous results. Moving beyond quadratics, we extend the applicability of our analysis to general functions satisfying the Polyak-Lojasiewicz condition, outperforming the previous strongly convex analysis while operating under weaker assumptions. Backed by empirical results, our findings point to a new and stronger potential of FedExProx, paving the way for further exploration of the benefits of extrapolation in federated learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15368v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Wojciech Anyszka, Kaja Gruntkowska, Alexander Tyurin, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>A distributed proximal splitting method with linesearch for locally Lipschitz data</title>
      <link>https://arxiv.org/abs/2410.15583</link>
      <description>arXiv:2410.15583v1 Announce Type: new 
Abstract: In this paper, we propose a distributed first-order algorithm with backtracking linesearch for solving multi-agent minimisation problems, where each agent handles a local objective involving nonsmooth and smooth components. Unlike existing methods that require global Lipschitz continuity and predefined stepsizes, our algorithm adjusts stepsizes using distributed linesearch procedures, making it suitable for problems where global constants are unavailable or difficult to compute. The proposed algorithm is designed within an abstract linesearch framework for a primal-dual proximal-gradient method to solve min-max convex-concave problems, enabling the consensus constraint to be decoupled from the optimisation task. Our theoretical analysis allows for gradients of functions to be locally Lipschitz continuous, relaxing the prevalent assumption of globally Lipschitz continuous gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15583v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Atenas, Minh N. Dao, Matthew K. Tam</dc:creator>
    </item>
    <item>
      <title>A Mathematical Programming Model for Minimizing Energy Consumption on a Selective Laser Melting Machine</title>
      <link>https://arxiv.org/abs/2410.15604</link>
      <description>arXiv:2410.15604v1 Announce Type: new 
Abstract: The scheduling problem in additive manufacturing is receiving increasing attention; however, few have considered the effect of scheduling decisions on machine energy consumption. This research focuses on the nesting and scheduling problem of a single selective laser melting (SLM) machine to reduce total energy consumption. Based on an energy consumption model, a nesting and scheduling problem is formulated, and a mixed integer linear programming model is proposed. This model simultaneously determines part-to-batch assignments, part placement in the batch, and the choice of build orientation to reduce the total energy consumption of the SLM machine. The energy-saving potential of the model is validated through numerical experiments. Additionally, the effect of the number of alternative build orientations on energy consumption is explored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15604v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/math12162507</arxiv:DOI>
      <arxiv:journal_reference>Mathematics 2024,12(16),2507</arxiv:journal_reference>
      <dc:creator>Chunlong Yu, Junjie Lin</dc:creator>
    </item>
    <item>
      <title>Domain decomposition for integer optimal control with total variation regularization</title>
      <link>https://arxiv.org/abs/2410.15672</link>
      <description>arXiv:2410.15672v1 Announce Type: new 
Abstract: Total variation integer optimal control problems admit solutions and necessary optimality conditions via geometric variational analysis. In spite of the existence of said solutions, algorithms which solve the discretized objective suffer from high numerical cost associated with the combinatorial nature of integer programming. Hence, such methods are often limited to small- and medium-sized problems.
  We propose a globally convergent, coordinate descent-inspired algorithm that allows tractable subproblem solutions restricted to a partition of the domain. Our decomposition method solves relatively small trust-region subproblems that modify the control variable on a subdomain only. Given sufficient subdomain overlap, we prove that first-order optimality is equivalent to first-order optimality per subdomain. We additionally show that sufficient decrease is achieved on a single subdomain by way of a trust region subproblem solver. We utilize this to prove convergence of our algorithm, which operates via greedy patch selection. Finally, our method demonstrates the capacity to accelerate large PDE-constrained integer control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15672v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Baraldi, Paul Manns</dc:creator>
    </item>
    <item>
      <title>Distance geometry with and without the graph</title>
      <link>https://arxiv.org/abs/2410.15677</link>
      <description>arXiv:2410.15677v1 Announce Type: new 
Abstract: We survey theoretical, algorithmic, and computational results at the intersection of distance geometry problems and mathematical programming, both with and without adjacencies as part of the input. While mathematical programming methods can solve large-scale distance geometry problems with adjacencies, they are severely challenged in the absence thereof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15677v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Liberti, Carlile Lavor</dc:creator>
    </item>
    <item>
      <title>Note about network decomposition by maximum flow</title>
      <link>https://arxiv.org/abs/2410.15718</link>
      <description>arXiv:2410.15718v1 Announce Type: new 
Abstract: The goal of this paper is to establish a decomposition of the network based on the maximum flow problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15718v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianhang Lu</dc:creator>
    </item>
    <item>
      <title>IPM-LSTM: A Learning-Based Interior Point Method for Solving Nonlinear Programs</title>
      <link>https://arxiv.org/abs/2410.15731</link>
      <description>arXiv:2410.15731v1 Announce Type: new 
Abstract: Solving constrained nonlinear programs (NLPs) is of great importance in various domains such as power systems, robotics, and wireless communication networks. One widely used approach for addressing NLPs is the interior point method (IPM). The most computationally expensive procedure in IPMs is to solve systems of linear equations via matrix factorization. Recently, machine learning techniques have been adopted to expedite classic optimization algorithms. In this work, we propose using Long Short-Term Memory (LSTM) neural networks to approximate the solution of linear systems and integrate this approximating step into an IPM. The resulting approximate NLP solution is then utilized to warm-start an interior point solver. Experiments on various types of NLPs, including Quadratic Programs and Quadratically Constrained Quadratic Programs, show that our approach can significantly accelerate NLP solving, reducing iterations by up to 60% and solution time by up to 70% compared to the default solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15731v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Gao, Jinxin Xiong, Akang Wang, Qihong Duan, Jiang Xue, Qingjiang Shi</dc:creator>
    </item>
    <item>
      <title>Three connected problems: principal with multiple agents in cooperation, Principal--Agent with Mckean--Vlasov dynamics and multitask Principal--Agent</title>
      <link>https://arxiv.org/abs/2410.15818</link>
      <description>arXiv:2410.15818v2 Announce Type: new 
Abstract: In this paper, we address three Principal--Agent problems in a moral hazard context and show that they are connected. We start by studying the problem of Principal with multiple Agents in cooperation. The term cooperation is manifested here by the fact that the agents optimize their criteria through Pareto equilibria. We show that as the number of agents tends to infinity, the principal's value function converges to the value function of a McKean--Vlasov control problem. Using the solution to this McKean--Vlasov control problem, we derive a constructive method for obtaining approximately optimal contracts for the principal's problem with multiple agents in cooperation. In a second step, we show that the problem of Principal with multiple Agents turns out to also converge, when the number of agents goes to infinity, towards a new Principal--Agent problem which is the Principal--Agent problem with Mckean--Vlasov dynamics. This is a Principal--Agent problem where the agent--controlled production follows a Mckean-Vlasov dynamics and the contract can depend of the distribution of the production. The value function of the principal in this setting is equivalent to that of the same McKean--Vlasov control problem from the multi--agent scenario. Furthermore, we show that an optimal contract can be constructed from the solution to this McKean--Vlasov control problem. We conclude by discussing, in a simple example, the connection of these problems with the multitask Principal--Agent problem which is a situation when a principal delegates multiple tasks that can be correlated to a single agent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15818v2</guid>
      <category>math.OC</category>
      <category>econ.GN</category>
      <category>math.PR</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mao Fabrice Djete</dc:creator>
    </item>
    <item>
      <title>Safety-critical Control with Control Barrier Functions: A Hierarchical Optimization Framework</title>
      <link>https://arxiv.org/abs/2410.15877</link>
      <description>arXiv:2410.15877v1 Announce Type: new 
Abstract: The control barrier function (CBF) has become a fundamental tool in safety-critical systems design since its invention. Typically, the quadratic optimization framework is employed to accommodate CBFs, control Lyapunov functions (CLFs), other constraints and nominal control design. However, the constrained optimization framework involves hyper-parameters to tradeoff different objectives and constraints, which, if not well-tuned beforehand, impact system performance and even lead to infeasibility. In this paper, we propose a hierarchical optimization framework that decomposes the multi-objective optimization problem into nested optimization sub-problems in a safety-first approach. The new framework addresses potential infeasibility on the premise of ensuring safety and performance as much as possible and applies easily in multi-certificate cases. With vivid visualization aids, we systematically analyze the advantages of our proposed method over existing QP-based ones in terms of safety, feasibility and convergence rates. Moreover, two numerical examples are provided that verify our analysis and show the superiority of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15877v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junjun Xie, Liang Hu, Jiahu Qin, Jun Yang, Huijun Gao</dc:creator>
    </item>
    <item>
      <title>Automatic Differentiation of Optimization Algorithms with Time-Varying Updates</title>
      <link>https://arxiv.org/abs/2410.15923</link>
      <description>arXiv:2410.15923v1 Announce Type: new 
Abstract: Numerous Optimization Algorithms have a time-varying update rule thanks to, for instance, a changing step size, momentum parameter or, Hessian approximation. In this paper, we apply unrolled or automatic differentiation to a time-varying iterative process and provide convergence (rate) guarantees for the resulting derivative iterates. We adapt these convergence results and apply them to proximal gradient descent with variable step size and FISTA when solving partly smooth problems. We confirm our findings numerically by solving $\ell_1$ and $\ell_2$-regularized linear and logisitc regression respectively. Our theoretical and numerical results show that the convergence rate of the algorithm is reflected in its derivative iterates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15923v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheheryar Mehmood, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>An Efficient Local Optimizer-Tracking Solver for Differential-Algebriac Equations with Optimization Criteria</title>
      <link>https://arxiv.org/abs/2410.15963</link>
      <description>arXiv:2410.15963v1 Announce Type: new 
Abstract: A sequential solver for differential-algebraic equations with embedded optimization criteria (DAEOs) was developed to take advantage of the theoretical work done by Deussen et al. Solvers of this type separate the optimization problem from the differential equation and solve each individually. The new solver relies on the reduction of a DAEO to a sequence of differential inclusions separated by jump events. These jump events occur when the global solution to the optimization problem jumps to a new value. Without explicit treatment, these events will reduce the order of convergence of the integration step to one. The solver implements a "local optimizer tracking" procedure to detect and correct these jump events. Local optimizer tracking is much less expensive than running a deterministic global optimizer at every time step. This preserves the order of convergence of the integrator component without sacrificing performance to perform deterministic global optimization at every time step. The newly developed solver produces correct solutions to DAEOs and runs much faster than sequential DAEO solvers that rely only on global optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15963v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Alexander Fleming, Jens Deussen, Uwe Naumann</dc:creator>
    </item>
    <item>
      <title>A quantitative Robbins-Siegmund theorem</title>
      <link>https://arxiv.org/abs/2410.15986</link>
      <description>arXiv:2410.15986v1 Announce Type: new 
Abstract: The Robbins-Siegmund theorem is one of the most important results in stochastic optimization, where it is widely used to prove the convergence of stochastic algorithms. We provide a quantitative version of the theorem, establishing a bound on how far one needs to look in order to locate a region of metastability in the sense of Tao. Our proof involves a metastable analogue of Doob's theorem for $L_1$-supermartingales along with a series of technical lemmas that make precise how quantitative information propagates through sums and products of stochastic processes. In this way, our paper establishes a general methodology for finding metastable bounds for stochastic processes that can be reduced to supermartingales, and therefore for obtaining quantitative convergence information across a broad class of stochastic algorithms whose convergence proof relies on some variation of the Robbins-Siegmund theorem. We conclude by discussing how our general quantitative result might be used in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15986v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.LO</category>
      <category>math.PR</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morenikeji Neri, Thomas Powell</dc:creator>
    </item>
    <item>
      <title>Composing Optimized Stepsize Schedules for Gradient Descent</title>
      <link>https://arxiv.org/abs/2410.16249</link>
      <description>arXiv:2410.16249v1 Announce Type: new 
Abstract: Recent works by Altschuler and Parrilo and the authors have shown that it is possible to accelerate the convergence of gradient descent on smooth convex functions, even without momentum, just by picking special stepsizes. In this paper, we provide a general theory for composing stepsize schedules capturing all recent advances in this area and more. We propose three notions of ``composable'' stepsize schedules with elementary associated composition operations for combining them. From these operations, in addition to recovering recent works, we construct three highly optimized sequences of stepsize schedules. We first construct optimized stepsize schedules of every length generalizing the exponentially spaced silver stepsizes. We then construct highly optimized stepsizes schedules for minimizing final objective gap or gradient norm, improving on prior rates by constants and, more importantly, matching or beating the numerically computed minimax optimal schedules. We conjecture these schedules are in fact minimax (information theoretic) optimal. Several novel tertiary results follow from our theory including recovery of the recent dynamic gradient norm minimizing short stepsizes and extending them to objective gap minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16249v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Kevin Shu, Alex L. Wang</dc:creator>
    </item>
    <item>
      <title>Double Distributionally Robust Bid Shading for First Price Auctions</title>
      <link>https://arxiv.org/abs/2410.14864</link>
      <description>arXiv:2410.14864v1 Announce Type: cross 
Abstract: Bid shading has become a standard practice in the digital advertising industry, in which most auctions for advertising (ad) opportunities are now of first price type. Given an ad opportunity, performing bid shading requires estimating not only the value of the opportunity but also the distribution of the highest bid from competitors (i.e. the competitive landscape). Since these two estimates tend to be very noisy in practice, first-price auction participants need a bid shading policy that is robust against relatively significant estimation errors. In this work, we provide a max-min formulation in which we maximize the surplus against an adversary that chooses a distribution both for the value and the competitive landscape, each from a Kullback-Leibler-based ambiguity set. As we demonstrate, the two ambiguity sets are essential to adjusting the shape of the bid-shading policy in a principled way so as to effectively cope with uncertainty. Our distributionally robust bid shading policy is efficient to compute and systematically outperforms its non-robust counterpart on real datasets provided by Yahoo DSP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14864v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanlin Qu, Ravi Kant, Yan Chen, Brendan Kitts, San Gultekin, Aaron Flores, Jose Blanchet</dc:creator>
    </item>
    <item>
      <title>Optimizing Individualized Incentives from Grid Measurements and Limited Knowledge of Agent Behavior</title>
      <link>https://arxiv.org/abs/2410.14936</link>
      <description>arXiv:2410.14936v1 Announce Type: cross 
Abstract: As electrical generation becomes more distributed and volatile, and loads become more uncertain, controllability of distributed energy resources (DERs), regardless of their ownership status, will be necessary for grid reliability. Grid operators lack direct control over end-users' grid interactions, such as energy usage, but incentives can influence behavior -- for example, an end-user that receives a grid-driven incentive may adjust their consumption or expose relevant control variables in response. A key challenge in studying such incentives is the lack of data about human behavior, which usually motivates strong assumptions, such as distributional assumptions on compliance or rational utility-maximization. In this paper, we propose a general incentive mechanism in the form of a constrained optimization problem -- our approach is distinguished from prior work by modeling human behavior (e.g., reactions to an incentive) as an arbitrary unknown function. We propose feedback-based optimization algorithms to solve this problem that each leverage different amounts of information and/or measurements. We show that each converges to an asymptotically stable incentive with (near)-optimality guarantees given mild assumptions on the problem. Finally, we evaluate our proposed techniques in voltage regulation simulations on standard test beds. We test a variety of settings, including those that break assumptions required for theoretical convergence (e.g., convexity, smoothness) to capture realistic settings. In this evaluation, our proposed algorithms are able to find near-optimal incentives even when the reaction to an incentive is modeled by a theoretically difficult (yet realistic) function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14936v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Lechowicz, Joshua Comden, Andrey Bernstein</dc:creator>
    </item>
    <item>
      <title>2D Basement Relief Inversion using Sparse Regularization</title>
      <link>https://arxiv.org/abs/2410.14942</link>
      <description>arXiv:2410.14942v1 Announce Type: cross 
Abstract: Basement relief gravimetry is crucial in geophysics, especially for oil exploration and mineral prospecting. It involves solving an inverse problem to infer geological model parameters from observed data. The model represents basement relief with constant-density prisms, and the data reflect gravitational anomalies from these prisms. Inverse problems are often ill-posed, meaning small data changes can lead to large solution variations. To mitigate this, regularization techniques like Tikhonov's are used to stabilize solutions. This study compares regularization methods applied to gravimetric inversion, including Smoothness Constraints, Total Variation, Discrete Cosine Transform (DCT), and Discrete Wavelet Transform (DWT) using Daubechies D4 wavelets. Optimization, particularly with Genetic Algorithms (GA), is used to find prism depths that best match observed anomalies. GA, inspired by natural selection, selects the best solutions to minimize the objective function. The results, evaluated through fit metrics and error analysis, show the effectiveness of all regularization methods and GA, with the Smoothness constraint performing best in synthetic models. For the real data model, all methods performed similarly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14942v1</guid>
      <category>physics.geo-ph</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco M\'arcio Barboza, Arthur Anthony da Cunha Rom\~ao E Silva, Bruno Motta de Carvalho</dc:creator>
    </item>
    <item>
      <title>Learning Infinite-Horizon Average-Reward Linear Mixture MDPs of Bounded Span</title>
      <link>https://arxiv.org/abs/2410.14992</link>
      <description>arXiv:2410.14992v1 Announce Type: cross 
Abstract: This paper proposes a computationally tractable algorithm for learning infinite-horizon average-reward linear mixture Markov decision processes (MDPs) under the Bellman optimality condition. Our algorithm for linear mixture MDPs achieves a nearly minimax optimal regret upper bound of $\widetilde{\mathcal{O}}(d\sqrt{\mathrm{sp}(v^*)T})$ over $T$ time steps where $\mathrm{sp}(v^*)$ is the span of the optimal bias function $v^*$ and $d$ is the dimension of the feature mapping. Our algorithm applies the recently developed technique of running value iteration on a discounted-reward MDP approximation with clipping by the span. We prove that the value iteration procedure, even with the clipping operation, converges. Moreover, we show that the associated variance term due to random transitions can be bounded even under clipping. Combined with the weighted ridge regression-based parameter estimation scheme, this leads to the nearly minimax optimal regret guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14992v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Woojin Chae, Kihyuk Hong, Yufan Zhang, Ambuj Tewari, Dabeen Lee</dc:creator>
    </item>
    <item>
      <title>Pipeline Gradient-based Model Training on Analog In-memory Accelerators</title>
      <link>https://arxiv.org/abs/2410.15155</link>
      <description>arXiv:2410.15155v1 Announce Type: cross 
Abstract: Aiming to accelerate the training of large deep neural models (DNN) in an energy-efficient way, an analog in-memory computing (AIMC) accelerator emerges as a solution with immense potential. In AIMC accelerators, trainable weights are kept in memory without the need to move from memory to processors during the training, reducing a bunch of overhead. However, although the in-memory feature enables efficient computation, it also constrains the use of data parallelism since copying weights from one AIMC to another is expensive. To enable parallel training using AIMC, we propose synchronous and asynchronous pipeline parallelism for AIMC accelerators inspired by the pipeline in digital domains. This paper provides a theoretical convergence guarantee for both synchronous and asynchronous pipelines in terms of both sampling and clock cycle complexity, which is non-trivial since the physical characteristic of AIMC accelerators leads to analog updates that suffer from asymmetric bias. The simulations of training DNN on real datasets verify the efficiency of pipeline training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15155v1</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Hsinyu Tsai, Kaoutar El Maghraoui, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>Cascade equation for the discontinuities in the Stefan problem with surface tension</title>
      <link>https://arxiv.org/abs/2410.15249</link>
      <description>arXiv:2410.15249v1 Announce Type: cross 
Abstract: The Stefan problem with surface tension is well known to exhibit discontinuities in the associated moving aggregate (i.e., in the domain occupied by the solid), whose structure has only been understood under translational or radial symmetry so far. In this paper, we derive an auxiliary partial differential equation of second-order hyperbolic type, referred to as the cascade equation, that captures said discontinuities in the absence of any symmetry assumptions. Specializing to the one-phase setting, we introduce a novel (global) notion of weak solution to the cascade equation, which is defined as a limit of mean-field game equilibria. For the spatial dimension two, we show the existence of such a weak solution and prove a natural perimeter estimate on the associated moving aggregate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15249v1</guid>
      <category>math.AP</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yucheng Guo, Sergey Nadtochiy, Mykhaylo Shkolnikov</dc:creator>
    </item>
    <item>
      <title>Learning-Augmented Algorithms for the Bahncard Problem</title>
      <link>https://arxiv.org/abs/2410.15257</link>
      <description>arXiv:2410.15257v1 Announce Type: cross 
Abstract: In this paper, we study learning-augmented algorithms for the Bahncard problem. The Bahncard problem is a generalization of the ski-rental problem, where a traveler needs to irrevocably and repeatedly decide between a cheap short-term solution and an expensive long-term one with an unknown future. Even though the problem is canonical, only a primal-dual-based learning-augmented algorithm was explicitly designed for it. We develop a new learning-augmented algorithm, named PFSUM, that incorporates both history and short-term future to improve online decision making. We derive the competitive ratio of PFSUM as a function of the prediction error and conduct extensive experiments to show that PFSUM outperforms the primal-dual-based algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15257v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hailiang Zhao, Xueyan Tang, Peng Chen, Shuiguang Deng</dc:creator>
    </item>
    <item>
      <title>A New Adaptive Balanced Augmented Lagrangian Method with Application to ISAC Beamforming Design</title>
      <link>https://arxiv.org/abs/2410.15358</link>
      <description>arXiv:2410.15358v1 Announce Type: cross 
Abstract: In this paper, we consider a class of convex programming problems with linear equality constraints, which finds broad applications in machine learning and signal processing. We propose a new adaptive balanced augmented Lagrangian (ABAL) method for solving these problems. The proposed ABAL method adaptively selects the stepsize parameter and enjoys a low per-iteration complexity, involving only the computation of a proximal mapping of the objective function and the solution of a linear equation. These features make the proposed method well-suited to large-scale problems. We then custom-apply the ABAL method to solve the ISAC beamforming design problem, which is formulated as a nonlinear semidefinite program in a previous work. This customized application requires careful exploitation of the problem's special structure such as the property that all of its signal-to-interference-and-noise-ratio (SINR) constraints hold with equality at the solution and an efficient computation of the proximal mapping of the objective function. Simulation results demonstrate the efficiency of the proposed ABAL method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15358v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiageng Wu, Bo Jiang, Xinxin Li, Ya-Feng Liu, Jianhua Yuan</dc:creator>
    </item>
    <item>
      <title>A Global Coordinate-Free Approach to Invariant Contraction on Homogeneous Manifolds</title>
      <link>https://arxiv.org/abs/2410.15441</link>
      <description>arXiv:2410.15441v1 Announce Type: cross 
Abstract: In this work, we provide a global condition for contraction with respect to an invariant Riemannian metric on reductive homogeneous spaces. Using left-invariant frames, vector fields on the manifold are horizontally lifted to the ambient Lie group, where the Levi-Civita connection is globally characterized as a real matrix multiplication. By linearizing in these left-invariant frames, we characterize contraction using matrix measures on real square matrices, avoiding the use of local charts. Applying this global condition, we provide a necessary condition for a prescribed subset of the manifold to possibly admit a contracting system with respect to an invariant metric. Applied to the sphere, this condition implies that no closed hemisphere can be contained in a contraction region. Finally, we apply our results to compute reachable sets for an attitude control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15441v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akash Harapanahalli, Samuel Coogan</dc:creator>
    </item>
    <item>
      <title>Quasi-Static Continuum Model of Octopus-Like Soft Robot Arm Under Water Actuated by Twisted and Coiled Artificial Muscles (TCAMs)</title>
      <link>https://arxiv.org/abs/2410.15498</link>
      <description>arXiv:2410.15498v1 Announce Type: cross 
Abstract: The current work is a qualitative study that aims to explore the implementation of Twisted and Coiled Artificial Muscles (TCAMs) for actuating and replicating the bending motion of an octopus-like soft robot arm underwater. Additionally, it investigates the impact of hydrostatic and dynamic forces from steady-state fluid flow on the arm's motion. The artificial muscles are lightweight and low-cost actuators that generate a high power-to-weight ratio, producing tensile force up to 12,600 times their own weight, which is close to the functionality of biological muscles. The "extended" Cosserat theory of rods is employed to formulate a quasi-static continuum model of arm motion, where the arm's cross-section is not only capable of rigid rotation but also deforms within its plane. This planar deformation of the arm cross-section aligns with the biological behavior of the octopus arm, where the stiffness of the hydrostat is directly induced by the incompressibility of the tissues. In line with the main goal, a constitutive model is derived for the material of the octopus arm to capture its characteristic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15498v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amirreza Fahim Golestaneh, Venanzio Cichella, Caterina Lamuta</dc:creator>
    </item>
    <item>
      <title>Distributed Thompson sampling under constrained communication</title>
      <link>https://arxiv.org/abs/2410.15543</link>
      <description>arXiv:2410.15543v1 Announce Type: cross 
Abstract: In Bayesian optimization, a black-box function is maximized via the use of a surrogate model. We apply distributed Thompson sampling, using a Gaussian process as a surrogate model, to approach the multi-agent Bayesian optimization problem. In our distributed Thompson sampling implementation, each agent receives sampled points from neighbors, where the communication network is encoded in a graph; each agent utilizes a Gaussian process to model the objective function. We demonstrate a theoretical bound on Bayesian Simple Regret, where the bound depends on the size of the largest complete subgraph of the communication graph. Unlike in batch Bayesian optimization, this bound is applicable in cases where the communication graph amongst agents is constrained. When compared to sequential Thompson sampling, our bound guarantees faster convergence with respect to time as long as there is a fully connected subgraph of at least two agents. We confirm the efficacy of our algorithm with numerical simulations on traditional optimization test functions, illustrating the significance of graph connectivity on improving regret convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15543v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saba Zerefa, Zhaolin Ren, Haitong Ma, Na Li</dc:creator>
    </item>
    <item>
      <title>All You Need is an Improving Column: Enhancing Column Generation for Parallel Machine Scheduling via Transformers</title>
      <link>https://arxiv.org/abs/2410.15601</link>
      <description>arXiv:2410.15601v1 Announce Type: cross 
Abstract: We present a neural network-enhanced column generation (CG) approach for a parallel machine scheduling problem. The proposed approach utilizes an encoder-decoder attention model, namely the transformer and pointer architectures, to develop job sequences with negative reduced cost and thus generate columns to add to the master problem. By training the neural network offline and using it in inference mode to predict negative reduced costs columns, we achieve significant computational time savings compared to dynamic programming (DP). Since the exact DP procedure is used to verify that no further columns with negative reduced cost can be identified at termination, the optimality guarantee of the original CG procedure is preserved. For small to medium-sized instances, our approach achieves an average 45% reduction in computation time compared to solving the subproblems with DP. Furthermore, the model generalizes not only to unseen, larger problem instances from the same probability distribution but also to instances from different probability distributions than those presented at training time. For large-sized instances, the proposed approach achieves an 80% improvement in the objective value in under 500 seconds, demonstrating both its scalability and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15601v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amira Hijazi, Osman Ozaltin, Reha Uzsoy</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Instrumental Variables Estimation</title>
      <link>https://arxiv.org/abs/2410.15634</link>
      <description>arXiv:2410.15634v1 Announce Type: cross 
Abstract: Instrumental variables (IV) estimation is a fundamental method in econometrics and statistics for estimating causal effects in the presence of unobserved confounding. However, challenges such as untestable model assumptions and poor finite sample properties have undermined its reliability in practice. Viewing common issues in IV estimation as distributional uncertainties, we propose DRIVE, a distributionally robust framework of the classical IV estimation method. When the ambiguity set is based on a Wasserstein distance, DRIVE minimizes a square root ridge regularized variant of the two stage least squares (TSLS) objective. We develop a novel asymptotic theory for this regularized regression estimator based on the square root ridge, showing that it achieves consistency without requiring the regularization parameter to vanish. This result follows from a fundamental property of the square root ridge, which we call ``delayed shrinkage''. This novel property, which also holds for a class of generalized method of moments (GMM) estimators, ensures that the estimator is robust to distributional uncertainties that persist in large samples. We further derive the asymptotic distribution of Wasserstein DRIVE and propose data-driven procedures to select the regularization parameter based on theoretical results. Simulation studies confirm the superior finite sample performance of Wasserstein DRIVE. Thanks to its regularization and robustness properties, Wasserstein DRIVE could be preferable in practice, particularly when the practitioner is uncertain about model assumptions or distributional shifts in data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15634v1</guid>
      <category>econ.EM</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaonan Qu, Yongchan Kwon</dc:creator>
    </item>
    <item>
      <title>Large Deviations and Improved Mean-squared Error Rates of Nonlinear SGD: Heavy-tailed Noise and Power of Symmetry</title>
      <link>https://arxiv.org/abs/2410.15637</link>
      <description>arXiv:2410.15637v1 Announce Type: cross 
Abstract: We study large deviations and mean-squared error (MSE) guarantees of a general framework of nonlinear stochastic gradient methods in the online setting, in the presence of heavy-tailed noise. Unlike existing works that rely on the closed form of a nonlinearity (typically clipping), our framework treats the nonlinearity in a black-box manner, allowing us to provide unified guarantees for a broad class of bounded nonlinearities, including many popular ones, like sign, quantization, normalization, as well as component-wise and joint clipping. We provide several strong results for a broad range of step-sizes in the presence of heavy-tailed noise with symmetric probability density function, positive in a neighbourhood of zero and potentially unbounded moments. In particular, for non-convex costs we provide a large deviation upper bound for the minimum norm-squared of gradients, showing an asymptotic tail decay on an exponential scale, at a rate $\sqrt{t} / \log(t)$. We establish the accompanying rate function, showing an explicit dependence on the choice of step-size, nonlinearity, noise and problem parameters. Next, for non-convex costs and the minimum norm-squared of gradients, we derive the optimal MSE rate $\widetilde{\mathcal{O}}(t^{-1/2})$. Moreover, for strongly convex costs and the last iterate, we provide an MSE rate that can be made arbitrarily close to the optimal rate $\mathcal{O}(t^{-1})$, improving on the state-of-the-art results in the presence of heavy-tailed noise. Finally, we establish almost sure convergence of the minimum norm-squared of gradients, providing an explicit rate, which can be made arbitrarily close to $o(t^{-1/4})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15637v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Shuhua Yu, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>S-CFE: Simple Counterfactual Explanations</title>
      <link>https://arxiv.org/abs/2410.15723</link>
      <description>arXiv:2410.15723v1 Announce Type: cross 
Abstract: We study the problem of finding optimal sparse, manifold-aligned counterfactual explanations for classifiers. Canonically, this can be formulated as an optimization problem with multiple non-convex components, including classifier loss functions and manifold alignment (or \emph{plausibility}) metrics. The added complexity of enforcing \emph{sparsity}, or shorter explanations, complicates the problem further. Existing methods often focus on specific models and plausibility measures, relying on convex $\ell_1$ regularizers to enforce sparsity. In this paper, we tackle the canonical formulation using the accelerated proximal gradient (APG) method, a simple yet efficient first-order procedure capable of handling smooth non-convex objectives and non-smooth $\ell_p$ (where $0 \leq p &lt; 1$) regularizers. This enables our approach to seamlessly incorporate various classifiers and plausibility measures while producing sparser solutions. Our algorithm only requires differentiable data-manifold regularizers and supports box constraints for bounded feature ranges, ensuring the generated counterfactuals remain \emph{actionable}. Finally, experiments on real-world datasets demonstrate that our approach effectively produces sparse, manifold-aligned counterfactual explanations while maintaining proximity to the factual data and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15723v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shpresim Sadiku, Moritz Wagner, Sai Ganesh Nagarajan, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Solving Sparse \&amp; High-Dimensional-Output Regression via Compression</title>
      <link>https://arxiv.org/abs/2410.15762</link>
      <description>arXiv:2410.15762v1 Announce Type: cross 
Abstract: Multi-Output Regression (MOR) has been widely used in scientific data analysis for decision-making. Unlike traditional regression models, MOR aims to simultaneously predict multiple real-valued outputs given an input. However, the increasing dimensionality of the outputs poses significant challenges regarding interpretability and computational scalability for modern MOR applications. As a first step to address these challenges, this paper proposes a Sparse \&amp; High-dimensional-Output REgression (SHORE) model by incorporating additional sparsity requirements to resolve the output interpretability, and then designs a computationally efficient two-stage optimization framework capable of solving SHORE with provable accuracy via compression on outputs. Theoretically, we show that the proposed framework is computationally scalable while maintaining the same order of training loss and prediction loss before-and-after compression under arbitrary or relatively weak sample set conditions. Empirically, numerical results further validate the theoretical findings, showcasing the efficiency and accuracy of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15762v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renyuan Li, Zhehui Chen, Guanyi Wang</dc:creator>
    </item>
    <item>
      <title>Karush-Kuhn-Tucker Condition-Trained Neural Networks (KKT Nets)</title>
      <link>https://arxiv.org/abs/2410.15973</link>
      <description>arXiv:2410.15973v1 Announce Type: cross 
Abstract: This paper presents a novel approach to solving convex optimization problems by leveraging the fact that, under certain regularity conditions, any set of primal or dual variables satisfying the Karush-Kuhn-Tucker (KKT) conditions is necessary and sufficient for optimality. Similar to Theory-Trained Neural Networks (TTNNs), the parameters of the convex optimization problem are input to the neural network, and the expected outputs are the optimal primal and dual variables. A choice for the loss function in this case is a loss, which we refer to as the KKT Loss, that measures how well the network's outputs satisfy the KKT conditions. We demonstrate the effectiveness of this approach using a linear program as an example. For this problem, we observe that minimizing the KKT Loss alone outperforms training the network with a weighted sum of the KKT Loss and a Data Loss (the mean-squared error between the ground truth optimal solutions and the network's output). Moreover, minimizing only the Data Loss yields inferior results compared to those obtained by minimizing the KKT Loss. While the approach is promising, the obtained primal and dual solutions are not sufficiently close to the ground truth optimal solutions. In the future, we aim to develop improved models to obtain solutions closer to the ground truth and extend the approach to other problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15973v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Arvind, Rishabh Pomaje, Rajshekhar V Bhat</dc:creator>
    </item>
    <item>
      <title>Optimization of an eigenvalue arising in optimal insulation with a lower bound</title>
      <link>https://arxiv.org/abs/2410.16050</link>
      <description>arXiv:2410.16050v1 Announce Type: cross 
Abstract: An eigenvalue problem arising in optimal insulation related to the minimization of the heat decay rate of an insulated body is adapted to enforce a positive lower bound imposed on the distribution of insulating material. We prove the existence of optimal domains among a class of convex shapes and propose a numerical scheme to approximate the eigenvalue. The stability of the shape optimization among convex, bounded domains in $\mathbb{R}^3$ is proven for an approximation with polyhedral domains under a non-conformal convexity constraint. We prove that on the ball, symmetry breaking of the optimal insulation can be expected in general. To observe how the lower bound affects the breaking of symmetry in the optimal insulation and the shape optimization, the eigenvalue and optimal domains are approximated for several values of mass $m$ and lower bounds $\ell_{\min}\ge0$. The numerical experiments suggest, that in general symmetry breaking still arises, unless $m$ is close to a critical value $m_0$, and $\ell_{\min}$ large enough such that almost all of the mass $m$ is fixed through the lower bound. For $\ell_{\min}=0$, the numerical results are consistent with previous numerical experiments on shape optimization restricted to rotationally symmetric, convex domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16050v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Bartels, Giuseppe Buttazzo, Hedwig Keller</dc:creator>
    </item>
    <item>
      <title>LDAdam: Adaptive Optimization from Low-Dimensional Gradient Statistics</title>
      <link>https://arxiv.org/abs/2410.16103</link>
      <description>arXiv:2410.16103v1 Announce Type: cross 
Abstract: We introduce LDAdam, a memory-efficient optimizer for training large models, that performs adaptive optimization steps within lower dimensional subspaces, while consistently exploring the full parameter space during training. This strategy keeps the optimizer's memory footprint to a fraction of the model size. LDAdam relies on a new projection-aware update rule for the optimizer states that allows for transitioning between subspaces, i.e., estimation of the statistics of the projected gradients. To mitigate the errors due to low-rank projection, LDAdam integrates a new generalized error feedback mechanism, which explicitly accounts for both gradient and optimizer state compression. We prove the convergence of LDAdam under standard assumptions, and show that LDAdam allows for accurate and efficient fine-tuning and pre-training of language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16103v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Robert, Mher Safaryan, Ionut-Vlad Modoranu, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>Denoising Hyperbolic-Valued Data by Relaxed Regularizations</title>
      <link>https://arxiv.org/abs/2410.16149</link>
      <description>arXiv:2410.16149v1 Announce Type: cross 
Abstract: We introduce a novel relaxation strategy for denoising hyperbolic-valued data. The main challenge is here the non-convexity of the hyperbolic sheet. Instead of considering the denoising problem directly on the hyperbolic space, we exploit the Euclidean embedding and encode the hyperbolic sheet using a novel matrix representation. For denoising, we employ the Euclidean Tikhonov and total variation (TV) model, where we incorporate our matrix representation. The major contribution is then a convex relaxation of the variational ans\"atze allowing the utilization of well-established convex optimization procedures like the alternating directions method of multipliers (ADMM). The resulting denoisers are applied to a real-world Gaussian image processing task, where we simultaneously restore the pixelwise mean and standard deviation of a retina scan series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16149v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Beinert, Jonas Bresch</dc:creator>
    </item>
    <item>
      <title>Quantum Algorithms for Non-smooth Non-convex Optimization</title>
      <link>https://arxiv.org/abs/2410.16189</link>
      <description>arXiv:2410.16189v1 Announce Type: cross 
Abstract: This paper considers the problem for finding the $(\delta,\epsilon)$-Goldstein stationary point of Lipschitz continuous objective, which is a rich function class to cover a great number of important applications. We construct a zeroth-order quantum estimator for the gradient of the smoothed surrogate. Based on such estimator, we propose a novel quantum algorithm that achieves a query complexity of $\tilde{\mathcal{O}}(d^{3/2}\delta^{-1}\epsilon^{-3})$ on the stochastic function value oracle, where $d$ is the dimension of the problem. We also enhance the query complexity to $\tilde{\mathcal{O}}(d^{3/2}\delta^{-1}\epsilon^{-7/3})$ by introducing a variance reduction variant. Our findings demonstrate the clear advantages of utilizing quantum techniques for non-convex non-smooth optimization, as they outperform the optimal classical methods on the dependency of $\epsilon$ by a factor of $\epsilon^{-2/3}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16189v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengchang Liu, Chaowen Guan, Jianhao He, John C. S. Lui</dc:creator>
    </item>
    <item>
      <title>Feedback strategies in the market with uncertainties</title>
      <link>https://arxiv.org/abs/2410.16203</link>
      <description>arXiv:2410.16203v1 Announce Type: cross 
Abstract: We explore how dynamic entry deterrence operates through feedback strategies in markets experiencing stochastic demand fluctuations. The incumbent firm, aware of its own cost structure, can deter a potential competitor by strategically adjusting prices. The potential entrant faces a one-time, irreversible decision to enter the market, incurring a fixed cost, with profits determined by market conditions and the incumbent's hidden type. Market demand follows a Chan-Karolyi-Longstaff-Sanders Brownian motion. If the demand is low, the threat of entry diminishes, making deterrence less advantageous. In equilibrium, a weak incumbent may be incentivized to reveal its type by raising prices. We derive an optimal equilibrium using path integral control, where the entrant enters once demand reaches a high enough level, and the weak incumbent mixes strategies between revealing itself when demand is sufficiently low.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16203v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mustapha Nyenye Issah</dc:creator>
    </item>
    <item>
      <title>A Quantum Optimization Algorithm for Optimal Electric Vehicle Charging Station Placement for Intercity Trips</title>
      <link>https://arxiv.org/abs/2410.16231</link>
      <description>arXiv:2410.16231v1 Announce Type: cross 
Abstract: Electric vehicles (EVs) play a significant role in enhancing the sustainability of transportation systems. However, their widespread adoption is hindered by inadequate public charging infrastructure, particularly to support long-distance travel. Identifying optimal charging station locations in large transportation networks presents a well-known NP-hard combinatorial optimization problem, as the search space grows exponentially with the number of potential charging station locations. This paper introduces a quantum search-based optimization algorithm designed to enhance the efficiency of solving this NP-hard problem for transportation networks. By leveraging quantum parallelism, amplitude amplification, and quantum phase estimation as a subroutine, the optimal solution is identified with a quadratic improvement in complexity compared to classical exact methods, such as branch and bound. The detailed design and complexity of a resource-efficient quantum circuit are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16231v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tina Radvand, Alireza Talebpour</dc:creator>
    </item>
    <item>
      <title>Implicit Regularization for Tubal Tensor Factorizations via Gradient Descent</title>
      <link>https://arxiv.org/abs/2410.16247</link>
      <description>arXiv:2410.16247v1 Announce Type: cross 
Abstract: We provide a rigorous analysis of implicit regularization in an overparametrized tensor factorization problem beyond the lazy training regime. For matrix factorization problems, this phenomenon has been studied in a number of works. A particular challenge has been to design universal initialization strategies which provably lead to implicit regularization in gradient-descent methods. At the same time, it has been argued by Cohen et. al. 2016 that more general classes of neural networks can be captured by considering tensor factorizations. However, in the tensor case, implicit regularization has only been rigorously established for gradient flow or in the lazy training regime. In this paper, we prove the first tensor result of its kind for gradient descent rather than gradient flow. We focus on the tubal tensor product and the associated notion of low tubal rank, encouraged by the relevance of this model for image data. We establish that gradient descent in an overparametrized tensor factorization model with a small random initialization exhibits an implicit bias towards solutions of low tubal rank. Our theoretical findings are illustrated in an extensive set of numerical simulations show-casing the dynamics predicted by our theory as well as the crucial role of using a small random initialization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16247v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Santhosh Karnik, Anna Veselovska, Mark Iwen, Felix Krahmer</dc:creator>
    </item>
    <item>
      <title>Fixed-Point Automatic Differentiation of Forward--Backward Splitting Algorithms for Partly Smooth Functions</title>
      <link>https://arxiv.org/abs/2208.03107</link>
      <description>arXiv:2208.03107v2 Announce Type: replace 
Abstract: A large class of non-smooth practical optimization problems can be written as minimization of a sum of smooth and partly smooth functions. We examine such structured problems which also depend on a parameter vector and study the problem of differentiating its solution mapping with respect to the parameter which has far reaching applications in sensitivity analysis and parameter learning problems. Under partial smoothness and other mild assumptions, we apply Implicit (ID) and Automatic Differentiation (AD) to the fixed-point iterations of proximal splitting algorithms. We show that AD of the sequence generated by these algorithms converges (linearly under further assumptions) to the derivative of the solution mapping. For a variant of automatic differentiation, which we call Fixed-Point Automatic Differentiation (FPAD), we remedy the memory overhead problem of the Reverse Mode AD and moreover provide faster convergence theoretically. We numerically illustrate the convergence and convergence rates of AD and FPAD on Lasso and Group Lasso problems and demonstrate the working of FPAD on prototypical image denoising problems by learning the regularization term.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.03107v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheheryar Mehmood, Peter Ochs</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Molecular Dynamics Optimization: A Stochastic Pontryagin Maximum Principle Approach</title>
      <link>https://arxiv.org/abs/2212.03320</link>
      <description>arXiv:2212.03320v2 Announce Type: replace 
Abstract: In this paper, we present a novel reinforcement learning framework designed to optimize molecular dynamics by focusing on the entire trajectory rather than just the final molecular configuration. Leveraging a stochastic version of Pontryagin's Maximum Principle (PMP) and Soft Actor-Critic (SAC) algorithm, our framework effectively explores non-convex molecular energy landscapes, escaping local minima to stabilize in low-energy states. Our approach operates in continuous state and action spaces without relying on labeled data, making it applicable to a wide range of molecular systems. Through extensive experimentation on six distinct molecules, including Bradykinin and Oxytocin, we demonstrate competitive performance against other unsupervised physics-based methods, such as the Greedy and NEMO-based algorithms. Our method's adaptability and focus on dynamic trajectory optimization make it suitable for applications in areas such as drug discovery and molecular design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.03320v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chandrajit Bajaj, Minh Nguyen, Conrad Li</dc:creator>
    </item>
    <item>
      <title>A Theory of the NEPv Approach for Optimization On the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2305.00091</link>
      <description>arXiv:2305.00091v4 Announce Type: replace 
Abstract: The NEPv approach has been increasingly used lately for optimization on the Stiefel manifold arising from machine learning. General speaking, the approach first turns the first order optimality condition, also known as the KKT condition, into a nonlinear eigenvalue problem with eigenvector dependency (NEPv) or a nonlinear polar decomposition with orthogonal factor dependency (NPDo) and then solve the nonlinear problem via some variations of the self-consistent-field (SCF) iteration. The difficulty, however, lies in designing a proper SCF iteration so that a maximizer is found at the end. Currently, each use of the approach is very much individualized, especially in its convergence analysis to show that the approach does work or otherwise. In this paper, a unifying framework is established. The framework is built upon some basic assumptions. If the basic assumptions are satisfied, globally convergence is guaranteed to a stationary point and during the SCF iterative process that leads to the stationary point, the objective function increases monotonically. Also a notion of atomic functions is proposed, which include commonly used matrix traces of linear and quadratic forms as special ones. It is shown that the basic assumptions are satisfied by atomic functions and by convex compositions of atomic functions. Together they provide a large collection of objectives for which the NEPv/NPDo approach is guaranteed to work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00091v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ren-Cang Li</dc:creator>
    </item>
    <item>
      <title>Modeling Nonlinear Control Systems via Koopman Control Family: Universal Forms and Subspace Invariance Proximity</title>
      <link>https://arxiv.org/abs/2307.15368</link>
      <description>arXiv:2307.15368v3 Announce Type: replace 
Abstract: This paper introduces the Koopman Control Family (KCF), a mathematical framework for modeling general (not necessarily control-affine) discrete-time nonlinear control systems with the aim of providing a solid theoretical foundation for the use of Koopman-based methods in systems with inputs. We demonstrate that the concept of KCF captures the behavior of nonlinear control systems on a (potentially infinite-dimensional) function space. By employing a generalized notion of subspace invariance under the KCF, we establish a universal form for finite-dimensional models, which encompasses the commonly used linear, bilinear, and linear switched models as specific instances. In cases where the subspace is not invariant under the KCF, we propose a method for approximating models in general form and characterize the model's accuracy using the concept of invariance proximity. We end by discussing how the proposed framework naturally lends itself to data-driven modeling of control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15368v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Masih Haseli, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>Adjoint-based calibration of nonlinear stochastic differential equations</title>
      <link>https://arxiv.org/abs/2311.18422</link>
      <description>arXiv:2311.18422v2 Announce Type: replace 
Abstract: To study the nonlinear properties of complex natural phenomena, the evolution of the quantity of interest can be often represented by systems of coupled nonlinear stochastic differential equations (SDEs). These SDEs typically contain several parameters which have to be chosen carefully to match the experimental data and to validate the effectiveness of the model. In the present paper the calibration of these parameters is described by nonlinear SDE-constrained optimization problems. In the optimize-before-discretize setting a rigorous analysis is carried out to ensure the existence of optimal solutions and to derive necessary first-order optimality conditions. For the numerical solution a Monte-Carlo method is applied using parallelization strategies to compensate for the high computational time. In the numerical examples an Ornstein-Uhlenbeck and a stochastic Prandtl-Tomlinson bath model are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18422v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00245-024-10181-y</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematics &amp; Optimization, 90, 50, 2024</arxiv:journal_reference>
      <dc:creator>Jan Bartsch, Robert Denk, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Fundamental Convergence Analysis of Sharpness-Aware Minimization</title>
      <link>https://arxiv.org/abs/2401.08060</link>
      <description>arXiv:2401.08060v3 Announce Type: replace 
Abstract: The paper investigates the fundamental convergence properties of Sharpness-Aware Minimization (SAM), a recently proposed gradient-based optimization method [Foret et al., 2021] that significantly improves the generalization of deep neural networks. The convergence properties, including the stationarity of accumulation points, the convergence of the sequence of gradients to the origin, the sequence of function values to the optimal value, and the sequence of iterates to the optimal solution, are established for the method. The universality of the provided convergence analysis, based on inexact gradient descent frameworks Khanh et al. [2023b], allows its extensions to efficient normalized versions of SAM such as F-SAM [Li et al., 2024], VaSSO [Li and Giannakis, 2023], RSAM [Liu et al., 2022], and to the unnormalized versions of SAM such as USAM [Andriushchenko and Flammarion, 2022]. Numerical experiments are conducted on classification tasks using deep learning models to confirm the practical aspects of our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08060v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:journal_reference>Advances in Neural Information Processing Systems 2024</arxiv:journal_reference>
      <dc:creator>Pham Duy Khanh, Hoang-Chau Luong, Boris S. Mordukhovich, Dat Ba Tran</dc:creator>
    </item>
    <item>
      <title>The minimal control time for the exact controllability by internal controls of 1D linear hyperbolic balance laws</title>
      <link>https://arxiv.org/abs/2403.20113</link>
      <description>arXiv:2403.20113v2 Announce Type: replace 
Abstract: In this article we study the internal controllability of 1D linear hyperbolic balance laws when the number of controls is equal to the number of state variables. The controls are supported in space in an arbitrary open subset. Our main result is a complete characterization of the minimal control time for the exact controllability property.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20113v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Long Hu, Guillaume Olive</dc:creator>
    </item>
    <item>
      <title>John property of anisotropic minimal surfaces</title>
      <link>https://arxiv.org/abs/2406.06906</link>
      <description>arXiv:2406.06906v2 Announce Type: replace 
Abstract: For a convex set $K\subset \mathbb R^n$ and the associated anisotropic perimeter $P_K$, we establish that every $(\epsilon,\,r)$-minimizer for $P_K$ satisfies a local John property. Furthermore, we prove that a certain class of John domains, including $(\epsilon,\,r)$-minimizers close to $K$, admits a trace inequality. As a consequence, we provide a more concrete proof for a crucial step in the quantitative Wulff inequality, thereby complementing the seminal work of Figalli, Maggi, and Pratelli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06906v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weicong Su, Yi Ru-Ya Zhang</dc:creator>
    </item>
    <item>
      <title>A Unified Approach to Extract Interpretable Rules from Tree Ensembles via Integer Programming</title>
      <link>https://arxiv.org/abs/2407.00843</link>
      <description>arXiv:2407.00843v2 Announce Type: replace 
Abstract: Tree ensemble methods represent a popular machine learning model, known for their effectiveness in supervised classification and regression tasks. Their performance derives from aggregating predictions of multiple decision trees, which are renowned for their interpretability properties. However, tree ensemble methods do not reliably exhibit interpretable output. Our work aims to extract an optimized list of rules from a trained tree ensemble, providing the user with a condensed, interpretable model that retains most of the predictive power of the full model. Our approach consists of solving a clean and neat set partitioning problem formulated through Integer Programming. The proposed method works with either tabular or time series data, for both classification and regression tasks, and does not require parameter tuning under the most common setting. Through rigorous computational experiments, we offer statistically significant evidence that our method is competitive with other rule extraction methods and effectively handles time series.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00843v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Bonasera, Emilio Carrizosa</dc:creator>
    </item>
    <item>
      <title>Numerical optimal control for delay differential equations: A simultaneous approach based on linearization of the delayed state</title>
      <link>https://arxiv.org/abs/2410.02687</link>
      <description>arXiv:2410.02687v2 Announce Type: replace 
Abstract: Time delays are ubiquitous in industry, and they must be accounted for when designing control strategies. However, numerical optimal control (NOC) of delay differential equations (DDEs) is challenging because it requires specialized discretization methods and the time delays may depend on the manipulated inputs or state variables. Therefore, in this work, we propose to linearize the delayed states around the current time. This results in a set of implicit differential equations, and we compare the steady states and the corresponding stability criteria of the DDEs and the approximate system. Furthermore, we propose a simultaneous approach for NOC of DDEs based on the linearization, and we discretize the approximate system using Euler's implicit method. Finally, we present a numerical example involving a molten salt nuclear fission reactor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02687v2</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias K. S. Ritschel, S{\o}ren Stange</dc:creator>
    </item>
    <item>
      <title>Generic continuity of the perturbed minima of certain parametric optimization problems</title>
      <link>https://arxiv.org/abs/2410.09526</link>
      <description>arXiv:2410.09526v2 Announce Type: replace 
Abstract: We show that in a quite general framework, the parameterized optimization problem can be so perturbed as to be generically well-posed. As an application, we provide a contribution to Stechkin theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09526v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hristina Topalova, Nadia Zlateva</dc:creator>
    </item>
    <item>
      <title>Complexity and numerical experiments of a new adaptive generic proximal bundle method</title>
      <link>https://arxiv.org/abs/2410.11066</link>
      <description>arXiv:2410.11066v2 Announce Type: replace 
Abstract: This paper develops an adaptive generic proximal bundle method, shows its complexity, and presents numerical experiments comparing this method with two bundle methods on a set of optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11066v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Renato Monteiro, Benoit Tran</dc:creator>
    </item>
    <item>
      <title>Inpatient Overflow Management with Proximal Policy Optimization</title>
      <link>https://arxiv.org/abs/2410.13767</link>
      <description>arXiv:2410.13767v2 Announce Type: replace 
Abstract: Overflowing patients to non-primary wards can effectively alleviate congestion in hospitals, while undesired overflow also leads to issues like mismatched service quality. Therefore, we need to trade off between congestion and undesired overflow. This overflow management problem is modeled as a discrete-time Markov Decision Process with large state and action space. To overcome the curse-of-dimensionality, we decompose the action at each time into a sequence of atomic actions and use an actor-critic algorithm, Proximal Policy Optimization (PPO), to guide the atomic actions. Moreover, we tailor the design of neural network which represents policy to account for the daily periodic pattern of the system flows. Under hospital settings of different scales, the PPO policies consistently outperform commonly used state-of-art policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13767v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jingjing Sun, Jim Dai, Pengyi Shi</dc:creator>
    </item>
    <item>
      <title>Algorithmic Challenges in Ensuring Fairness at the Time of Decision</title>
      <link>https://arxiv.org/abs/2103.09287</link>
      <description>arXiv:2103.09287v3 Announce Type: replace-cross 
Abstract: Algorithmic decision-making in societal contexts, such as retail pricing, loan administration, recommendations on online platforms, etc., can be framed as stochastic optimization under bandit feedback, which typically requires experimentation with different decisions for the sake of learning. Such experimentation often results in perceptions of unfairness among people impacted by these decisions; for instance, there have been several recent lawsuits accusing companies that deploy algorithmic pricing practices of price gouging. Motivated by the changing legal landscape surrounding algorithmic decision-making, we introduce the well-studied fairness notion of envy-freeness within the context of stochastic convex optimization. Our notion requires that upon receiving decisions in the present time, groups do not envy the decisions received by any of the other groups, both in the present as well as the past. This results in a novel trajectory-constrained stochastic optimization problem that renders existing techniques inapplicable.
  The main technical contribution of this work is to show problem settings where there is no gap in achievable regret (up to logarithmic factors) when envy-freeness is imposed. In particular, in our main result, we develop a near-optimal envy-free algorithm that achieves $\tilde{O}(\sqrt{T})$ regret for smooth convex functions that satisfy the PL inequality. This algorithm has a coordinate-descent structure, in which we carefully leverage gradient information to ensure monotonic sampling along each dimension, while avoiding overshooting the constrained optimum with high probability. This latter aspect critically uses smoothness and the structure of the envy-freeness constraints, while the PL inequality allows for sufficient progress towards the optimal solution. We discuss several open questions that arise from this analysis, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.09287v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jad Salem, Swati Gupta, Vijay Kamble</dc:creator>
    </item>
    <item>
      <title>Experimenting under Stochastic Congestion</title>
      <link>https://arxiv.org/abs/2302.12093</link>
      <description>arXiv:2302.12093v4 Announce Type: replace-cross 
Abstract: We study randomized experiments in a service system when stochastic congestion can arise from temporarily limited supply or excess demand. Such congestion gives rise to cross-unit interference between the waiting customers, and analytic strategies that do not account for this interference may be biased. In current practice, one of the most widely used ways to address stochastic congestion is to use switchback experiments that alternatively turn a target intervention on and off for the whole system. We find, however, that under a queueing model for stochastic congestion, the standard way of analyzing switchbacks is inefficient, and that estimators that leverage the queueing model can be materially more accurate. Additionally, we show how the queueing model enables estimation of total policy gradients from unit-level randomized experiments, thus giving practitioners an alternative experimental approach they can use without needing to pre-commit to a fixed switchback length before data collection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12093v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuangning Li, Ramesh Johari, Xu Kuang, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>Variational formulations of ODE-Net as a mean-field optimal control problem and existence results</title>
      <link>https://arxiv.org/abs/2303.05924</link>
      <description>arXiv:2303.05924v4 Announce Type: replace-cross 
Abstract: This paper presents a mathematical analysis of ODE-Net, a continuum model of deep neural networks (DNNs). In recent years, Machine Learning researchers have introduced ideas of replacing the deep structure of DNNs with ODEs as a continuum limit. These studies regard the "learning" of ODE-Net as the minimization of a "loss" constrained by a parametric ODE. Although the existence of a minimizer for this minimization problem needs to be assumed, only a few studies have investigated its existence analytically in detail. In the present paper, the existence of a minimizer is discussed based on a formulation of ODE-Net as a measure-theoretic mean-field optimal control problem. The existence result is proved when a neural network, which describes a vector field of ODE-Net, is linear with respect to learnable parameters. The proof employs the measure-theoretic formulation combined with the direct method of Calculus of Variations. Secondly, an idealized minimization problem is proposed to remove the above linearity assumption. Such a problem is inspired by a kinetic regularization associated with the Benamou--Brenier formula and universal approximation theorems for neural networks. The proofs of these existence results use variational methods, differential equations, and mean-field optimal control theory. They will stand for a new analytic way to investigate the learning process of deep neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05924v4</guid>
      <category>math.AP</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noboru Isobe, Mizuho Okumura</dc:creator>
    </item>
    <item>
      <title>Relative Arbitrage Opportunities in an Extended Mean Field System</title>
      <link>https://arxiv.org/abs/2311.02690</link>
      <description>arXiv:2311.02690v2 Announce Type: replace-cross 
Abstract: This paper studies relative arbitrage opportunities in a market with infinitely many interacting investors. We establish a conditional McKean-Vlasov system to study the market dynamics coupled with investors. We then provide a theoretical framework to study a mean-field system, where the mean-field terms consist of a joint distribution of wealth and strategies. The optimal relative arbitrage is characterized by the equilibrium of extended mean-field games. We show the conditions on the existence and the uniqueness of the mean field equilibrium, then prove the propagation of chaos results for the finite-player game, and demonstrate that the Nash equilibrium converges to the mean field equilibrium when the population grows to infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02690v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicole Tianjiao Yang, Tomoyuki Ichiba</dc:creator>
    </item>
    <item>
      <title>Covariance-Based Activity Detection in Cooperative Multi-Cell Massive MIMO: Scaling Law and Efficient Algorithms</title>
      <link>https://arxiv.org/abs/2311.15299</link>
      <description>arXiv:2311.15299v3 Announce Type: replace-cross 
Abstract: This paper focuses on the covariance-based activity detection problem in a multi-cell massive multiple-input multiple-output (MIMO) system. In this system, active devices transmit their signature sequences to multiple base stations (BSs), and the BSs cooperatively detect the active devices based on the received signals. While the scaling law for the covariance-based activity detection in the single-cell scenario has been extensively analyzed in the literature, this paper aims to analyze the scaling law for the covariance-based activity detection in the multi-cell massive MIMO system. Specifically, this paper demonstrates a quadratic scaling law in the multi-cell system, under the assumption that the path-loss exponent of the fading channel $\gamma &gt; 2.$ This finding shows that, in the multi-cell massive MIMO system, the maximum number of active devices that can be correctly detected in each cell increases quadratically with the length of the signature sequence and decreases logarithmically with the number of cells (as the number of antennas tends to infinity). Moreover, in addition to analyzing the scaling law for the signature sequences randomly and uniformly distributed on a sphere, the paper also establishes the scaling law for signature sequences based on a finite alphabet, which are easier to generate and store. Finally, this paper proposes two efficient accelerated coordinate descent (CD) algorithms with a convergence guarantee for solving the device activity detection problem. The first algorithm reduces the complexity of CD by using an inexact coordinate update strategy. The second algorithm avoids unnecessary computations of CD by using an active set selection strategy. Simulation results show that the proposed algorithms exhibit excellent performance in terms of computational efficiency and detection error probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15299v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TIT.2024.3470952</arxiv:DOI>
      <dc:creator>Ziyue Wang, Ya-Feng Liu, Zhaorui Wang, Wei Yu</dc:creator>
    </item>
    <item>
      <title>How Free is Parameter-Free Stochastic Optimization?</title>
      <link>https://arxiv.org/abs/2402.03126</link>
      <description>arXiv:2402.03126v3 Announce Type: replace-cross 
Abstract: We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free stochastic convex optimization infeasible, and provide a method which is (partially) parameter-free up to the limit indicated by our lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03126v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Attia, Tomer Koren</dc:creator>
    </item>
    <item>
      <title>An RADI-type method for stochastic continuous-time algebraic Riccati equations</title>
      <link>https://arxiv.org/abs/2403.02940</link>
      <description>arXiv:2403.02940v2 Announce Type: replace-cross 
Abstract: In this paper, we propose an RADI-type method for large-scale stochastic continuous-time algebraic Riccati equations with sparse and low-rank matrices. This new variant of RADI-type methods is developed by integrating the core concept of the original RADI method with the implicit appearance of the left semi-tensor product in stochastic continuous-time algebraic Riccati equations.The method employs different shifts to accelerate convergence and uses compression techniques to reduce storage requirements and computational complexity.Unlike many existing methods for large-scale problems such as Newton-type methods and homotopy method, it calculates the residual at a low cost and does not require a stabilizing initial approximation, which can often be challenging to find. Numerical experiments are provided to demonstrate its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02940v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen-Chen Guo, Xin Liang</dc:creator>
    </item>
    <item>
      <title>Gain-Only Neural Operators for PDE Backstepping</title>
      <link>https://arxiv.org/abs/2403.19344</link>
      <description>arXiv:2403.19344v2 Announce Type: replace-cross 
Abstract: In this work we advance the recently-introduced deep learning-powered approach to PDE backstepping control by proposing a method that approximates only the control gain function -- a function of one variable -- instead of the entire kernel function of the backstepping transformation, which depends on two variables. This idea is introduced using several benchmark unstable PDEs, including hyperbolic and parabolic types, and extended to 2X2 hyperbolic systems. By employing a backstepping transformation that utilizes the exact kernel (suitable for gain scheduling) rather than an approximated one (suitable for adaptive control), we alter the quantification of the approximation error. This leads to a significant simplification in the target system, shifting the perturbation due to approximation from the domain to the boundary condition. Despite the notable differences in the Lyapunov analysis, we are able to retain stability guarantees with this simplified approximation approach. Approximating only the control gain function simplifies the operator being approximated and the training of its neural approximation, potentially reducing the neural network size. The trade-off for these simplifications is a more intricate Lyapunov analysis, involving higher Sobolev spaces for some PDEs, and certain restrictions on initial conditions arising from these spaces. It is crucial to carefully consider the specific requirements and constraints of each problem to determine the most suitable approach; indeed, recent works have demonstrated successful applications of both full-kernel and gain-only approaches in adaptive control and gain scheduling contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19344v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rafael Vazquez, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really Optimal?</title>
      <link>https://arxiv.org/abs/2405.14468</link>
      <description>arXiv:2405.14468v2 Announce Type: replace-cross 
Abstract: Deep neural networks (DNNs) exhibit a surprising structure in their final layer known as neural collapse (NC), and a growing body of works has currently investigated the propagation of neural collapse to earlier layers of DNNs -- a phenomenon called deep neural collapse (DNC). However, existing theoretical results are restricted to special cases: linear models, only two layers or binary classification. In contrast, we focus on non-linear models of arbitrary depth in multi-class classification and reveal a surprising qualitative shift. As soon as we go beyond two layers or two classes, DNC stops being optimal for the deep unconstrained features model (DUFM) -- the standard theoretical framework for the analysis of collapse. The main culprit is a low-rank bias of multi-layer regularization schemes: this bias leads to optimal solutions of even lower rank than the neural collapse. We support our theoretical findings with experiments on both DUFM and real data, which show the emergence of the low-rank structure in the solution found by gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14468v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peter S\'uken\'ik, Marco Mondelli, Christoph Lampert</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Framework for Analyzing the Convergence of Adam: Bridging the Gap with SGD</title>
      <link>https://arxiv.org/abs/2410.04458</link>
      <description>arXiv:2410.04458v2 Announce Type: replace-cross 
Abstract: Adaptive Moment Estimation (Adam) is a cornerstone optimization algorithm in deep learning, widely recognized for its flexibility with adaptive learning rates and efficiency in handling large-scale data. However, despite its practical success, the theoretical understanding of Adam's convergence has been constrained by stringent assumptions, such as almost surely bounded stochastic gradients or uniformly bounded gradients, which are more restrictive than those typically required for analyzing stochastic gradient descent (SGD).
  In this paper, we introduce a novel and comprehensive framework for analyzing the convergence properties of Adam. This framework offers a versatile approach to establishing Adam's convergence. Specifically, we prove that Adam achieves asymptotic (last iterate sense) convergence in both the almost sure sense and the \(L_1\) sense under the relaxed assumptions typically used for SGD, namely \(L\)-smoothness and the ABC inequality. Meanwhile, under the same assumptions, we show that Adam attains non-asymptotic sample complexity bounds similar to those of SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04458v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruinan Jin, Xiao Li, Yaoliang Yu, Baoxiang Wang</dc:creator>
    </item>
    <item>
      <title>A Differentially Private Energy Trading Mechanism Approaching Social Optimum</title>
      <link>https://arxiv.org/abs/2410.04787</link>
      <description>arXiv:2410.04787v2 Announce Type: replace-cross 
Abstract: This paper proposes a differentially private energy trading mechanism for prosumers in peer-to-peer (P2P) markets, offering provable privacy guarantees while approaching the Nash equilibrium with nearly socially optimal efficiency. We first model the P2P energy trading as a (generalized) Nash game and prove the vulnerability of traditional distributed algorithms to privacy attacks through an adversarial inference model. To address this challenge, we develop a privacy-preserving Nash equilibrium seeking algorithm incorporating carefully calibrated Laplacian noise. We prove that the proposed algorithm achieves $\epsilon$-differential privacy while converging in expectation to the Nash equilibrium with a suitable stepsize. Numerical experiments are conducted to evaluate the algorithm's robustness against privacy attacks, convergence behavior, and optimality compared to the non-private solution. Results demonstrate that our mechanism effectively protects prosumers' sensitive information while maintaining near-optimal market outcomes, offering a practical approach for privacy-preserving coordination in P2P markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04787v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuji Cao, Yue Chen</dc:creator>
    </item>
    <item>
      <title>Provable Acceleration of Nesterov's Accelerated Gradient for Rectangular Matrix Factorization and Linear Neural Networks</title>
      <link>https://arxiv.org/abs/2410.09640</link>
      <description>arXiv:2410.09640v2 Announce Type: replace-cross 
Abstract: We study the convergence rate of first-order methods for rectangular matrix factorization, which is a canonical nonconvex optimization problem. Specifically, given a rank-$r$ matrix $\mathbf{A}\in\mathbb{R}^{m\times n}$, we prove that gradient descent (GD) can find a pair of $\epsilon$-optimal solutions $\mathbf{X}_T\in\mathbb{R}^{m\times d}$ and $\mathbf{Y}_T\in\mathbb{R}^{n\times d}$, where $d\geq r$, satisfying $\lVert\mathbf{X}_T\mathbf{Y}_T^\top-\mathbf{A}\rVert_\mathrm{F}\leq\epsilon\lVert\mathbf{A}\rVert_\mathrm{F}$ in $T=O(\kappa^2\log\frac{1}{\epsilon})$ iterations with high probability, where $\kappa$ denotes the condition number of $\mathbf{A}$. Furthermore, we prove that Nesterov's accelerated gradient (NAG) attains an iteration complexity of $O(\kappa\log\frac{1}{\epsilon})$, which is the best-known bound of first-order methods for rectangular matrix factorization. Different from small balanced random initialization in the existing literature, we adopt an unbalanced initialization, where $\mathbf{X}_0$ is large and $\mathbf{Y}_0$ is $0$. Moreover, our initialization and analysis can be further extended to linear neural networks, where we prove that NAG can also attain an accelerated linear convergence rate. In particular, we only require the width of the network to be greater than or equal to the rank of the output label matrix. In contrast, previous results achieving the same rate require excessive widths that additionally depend on the condition number and the rank of the input data matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09640v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 22 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenghao Xu, Yuqing Wang, Tuo Zhao, Rachel Ward, Molei Tao</dc:creator>
    </item>
  </channel>
</rss>
