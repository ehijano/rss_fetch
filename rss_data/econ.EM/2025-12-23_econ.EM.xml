<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 24 Dec 2025 02:30:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Inference in partially identified moment models via regularized optimal transport</title>
      <link>https://arxiv.org/abs/2512.18084</link>
      <description>arXiv:2512.18084v1 Announce Type: new 
Abstract: Partial identification often arises when the joint distribution of the data is known only up to its marginals. We consider the corresponding partially identified GMM model and develop a methodology for identification, estimation, and inference in this model. We characterize the sharp identified set for the parameter of interest via a support-function/optimal-transport (OT) representation. For estimation, we employ entropic regularization, which provides a smooth approximation to classical OT and can be computed efficiently by the Sinkhorn algorithm. We also propose a statistic for testing hypotheses and constructing confidence regions for the identified set. To derive the asymptotic distribution of this statistic, we establish a novel central limit theorem for the entropic OT value under general smooth costs. We then obtain valid critical values using the bootstrap for directionally differentiable functionals of Fang and Santos (2019). The resulting testing procedure controls size locally uniformly, including at parameter values on the boundary of the identified set. We illustrate its performance in a Monte Carlo simulation. Our methodology is applicable to a wide range of empirical settings, such as panels with attrition and refreshment samples, nonlinear treatment effects, nonparametric instrumental variables without large-support conditions, and Euler equations with repeated cross-sections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18084v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigory Franguridi, Laura Liu</dc:creator>
    </item>
    <item>
      <title>(Debiased) Inference for Fixed Effects Estimators with Three-Dimensional Panel and Network Data</title>
      <link>https://arxiv.org/abs/2512.18678</link>
      <description>arXiv:2512.18678v1 Announce Type: new 
Abstract: Inference for fixed effects estimators of linear and nonlinear panel models is often unreliable due to Nickell- and/or incidental parameter biases. This article develops new inferential theory for (non)linear fixed effects M-estimators with data featuring a three-dimensional panel structure, such as sender x receiver x time. Our theory accommodates bipartite, directed, and undirected network panel data, integrates distinct specifications for additively separable unobserved effects with different layers of variation, and allows for weakly exogenous regressors. Our analysis reveals that the asymptotic properties of fixed effects estimators with three-dimensional panel data can deviate substantially from those with two-dimensional panel data. While for some specifications the estimator turns out to be asymptotically unbiased, in other specifications, it suffers from a particularly severe inference problem, characterized by a degenerate asymptotic distribution and complex bias structures. We address this atypical inference problem, by deriving explicit expressions to debias the fixed effects estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18678v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Czarnowske, Amrei Stammann</dc:creator>
    </item>
    <item>
      <title>Semiparametric Efficiency in Policy Learning with General Treatments</title>
      <link>https://arxiv.org/abs/2512.19230</link>
      <description>arXiv:2512.19230v1 Announce Type: new 
Abstract: Recent literature on policy learning has primarily focused on regret bounds of the learned policy. We provide a new perspective by developing a unified semiparametric efficiency framework for policy learning, allowing for general treatments that are discrete, continuous, or mixed. We provide a characterization of the failure of pathwise differentiability for parameters arising from deterministic policies. We then establish efficiency bounds for pathwise differentiable parameters in randomized policies, both when the propensity score is known and when it must be estimated. Building on the convolution theorem, we introduce a notion of efficiency for the asymptotic distribution of welfare regret, showing that inefficient policy estimators not only inflate the variance of the asymptotic regret but also shift its mean upward. We derive the asymptotic theory of several common policy estimators, with a key contribution being a policy-learning analogue of the Hirano-Imbens-Ridder (HIR) phenomenon: the inverse propensity weighting estimator with an estimated propensity is efficient, whereas the same estimator using the true propensity is not. We illustrate the theoretical results with an empirically calibrated simulation study based on data from a job training program and an empirical application to a commitment savings program.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19230v1</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Fang, Geert Ridder, Haitian Xie</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Monetary Policy Under Macroeconomic Uncertainty: Analyzing Tabular and Function Approximation Methods</title>
      <link>https://arxiv.org/abs/2512.17929</link>
      <description>arXiv:2512.17929v1 Announce Type: cross 
Abstract: We study how a central bank should dynamically set short-term nominal interest rates to stabilize inflation and unemployment when macroeconomic relationships are uncertain and time-varying. We model monetary policy as a sequential decision-making problem where the central bank observes macroeconomic conditions quarterly and chooses interest rate adjustments. Using publically accessible historical Federal Reserve Economic Data (FRED), we construct a linear-Gaussian transition model and implement a discrete-action Markov Decision Process with a quadratic loss reward function. We chose to compare nine different reinforcement learning style approaches against Taylor Rule and naive baselines, including tabular Q-learning variants, SARSA, Actor-Critic, Deep Q-Networks, Bayesian Q-learning with uncertainty quantification, and POMDP formulations with partial observability. Surprisingly, standard tabular Q-learning achieved the best performance (-615.13 +- 309.58 mean return), outperforming both enhanced RL methods and traditional policy rules. Our results suggest that while sophisticated RL techniques show promise for monetary policy applications, simpler approaches may be more robust in this domain, highlighting important challenges in applying modern RL to macroeconomic policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17929v1</guid>
      <category>q-fin.ST</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheryl Chen, Tony Wang, Kyle Feinstein</dc:creator>
    </item>
    <item>
      <title>Accuracy of Uniform Inference on Fine Grid Points</title>
      <link>https://arxiv.org/abs/2512.18627</link>
      <description>arXiv:2512.18627v1 Announce Type: cross 
Abstract: Uniform confidence bands for functions are widely used in empirical analysis. A variety of simple implementation methods (most notably multiplier bootstrap) have been proposed and theoretically justified. However, an implementation over a literally continuous index set is generally computationally infeasible, and practitioners therefore compute the critical value by evaluating the statistic on a finite evaluation grid. This paper quantifies how fine the evaluation grid must be for a multiplier bootstrap procedure over finite grid points to deliver valid uniform confidence bands. We derive an explicit bound on the resulting coverage error that separates discretization effects from the intrinsic high-dimensional bootstrap approximation error on the grid. The bound yields a transparent workflow for choosing the grid size in practice, and we illustrate the implementation through an example of kernel density estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18627v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunsuke Imai</dc:creator>
    </item>
    <item>
      <title>srvar-toolkit: A Python Implementation of Shadow-Rate Vector Autoregressions with Stochastic Volatility</title>
      <link>https://arxiv.org/abs/2512.19589</link>
      <description>arXiv:2512.19589v1 Announce Type: cross 
Abstract: We introduce srvar-toolkit, an open-source Python package for Bayesian vector autoregression with shadow-rate constraints and stochastic volatility. The toolkit implements the methodology of Grammatikopoulos (2025, Journal of Forecasting) for forecasting macroeconomic variables when interest rates hit the effective lower bound. We provide conjugate Normal-Inverse-Wishart priors with Minnesota-style shrinkage, latent shadow-rate data augmentation via Gibbs sampling, diagonal stochastic volatility using the Kim-Shephard-Chib mixture approximation, and stochastic search variable selection. Core dependencies are NumPy, SciPy, and Pandas, with optional extras for plotting and a configuration-driven command-line interface. We release the software under the MIT licence at https://github.com/shawcharles/srvar-toolkit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19589v1</guid>
      <category>stat.CO</category>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Shaw</dc:creator>
    </item>
    <item>
      <title>A Consistent ICM-based $\chi^2$ Specification Test</title>
      <link>https://arxiv.org/abs/2208.13370</link>
      <description>arXiv:2208.13370v3 Announce Type: replace 
Abstract: In spite of the omnibus property of Integrated Conditional Moment (ICM) specification tests, they are not commonly used in empirical practice owing to features such as the non-pivotality of the test and the high computational cost of available bootstrap schemes, especially in large samples. This paper proposes specification and mean independence tests based on ICM metrics. The proposed test exhibits consistency, asymptotic $\chi^2$-distribution under the null hypothesis, and computational efficiency. Moreover, it demonstrates robustness to heteroskedasticity of unknown form and can be adapted to enhance power towards specific alternatives. A power comparison with classical bootstrap-based ICM tests using Bahadur slopes is also provided. Monte Carlo simulations are conducted to showcase the excellent size control and competitive power of the proposed test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.13370v3</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feiyu Jiang, Emmanuel Selorm Tsyawo</dc:creator>
    </item>
    <item>
      <title>Jackknife inference with two-way clustering</title>
      <link>https://arxiv.org/abs/2406.08880</link>
      <description>arXiv:2406.08880v3 Announce Type: replace 
Abstract: For linear regression models with cross-section or panel data, it is natural to assume that the disturbances are clustered in two dimensions. However, the finite-sample properties of two-way cluster-robust tests and confidence intervals are often poor. We discuss several ways to improve inference with two-way clustering. Two of these are existing methods for avoiding, or at least ameliorating, the problem of undefined standard errors when a cluster-robust variance matrix estimator (CRVE) is not positive definite. One is a new method that always avoids the problem. More importantly, we propose a family of new two-way CRVEs based on the cluster jackknife and prove that they yield valid inferences asymptotically. Simulations for models with two-way fixed effects suggest that, in many cases, the cluster-jackknife CRVE combined with our new method yields surprisingly accurate inferences. We provide a simple software package, twowayjack for Stata, that implements our recommended variance estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08880v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>James G. MacKinnon, Morten {\O}rregaard Nielsen, Matthew D. Webb</dc:creator>
    </item>
    <item>
      <title>Robust Bayes Treatment Choice with Partial Identification</title>
      <link>https://arxiv.org/abs/2408.11621</link>
      <description>arXiv:2408.11621v2 Announce Type: replace 
Abstract: We study a class of binary treatment choice problems with partial identification through the lens of robust (multiple prior) Bayesian analysis. We use a convenient set of prior distributions to derive ex-ante and ex-post robust Bayes decision rules, both for decision makers who can randomize and for decision makers who cannot.
  Our main messages are as follows: First, ex-ante and ex-post robust Bayes decision rules do not agree in general, whether or not randomized rules are allowed. Second, randomized treatment assignment for some data realizations can be optimal in both ex-ante and, perhaps more surprisingly, ex-post problems. Therefore, it is usually with loss of generality to exclude randomized rules from consideration, even when regret is evaluated ex post.
  We apply our results to a stylized problem where a policy maker uses experimental data to choose whether to implement a new policy in a population of interest, but is concerned about the external validity of the experiment at hand (Stoye, 2012); and to the aggregation of data generated by multiple randomized control trials in different sites to make a policy choice in a population for which no experimental data are available (Manski, 2020; Ishihara and Kitagawa, 2021).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11621v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andr\'es Aradillas Fern\'andez, Jos\'e Luis Montiel Olea, Chen Qiu, J\"org Stoye, Serdil Tinda</dc:creator>
    </item>
    <item>
      <title>Inference in High-Dimensional Panel Models: Two-Way Dependence and Unobserved Heterogeneity</title>
      <link>https://arxiv.org/abs/2504.18772</link>
      <description>arXiv:2504.18772v2 Announce Type: replace 
Abstract: Panel data allows for the modeling of unobserved heterogeneity, significantly raising the number of nuisance parameters and making high dimensionality a practical issue. Meanwhile, temporal and cross-sectional dependence in panel data further complicates high-dimensional estimation and inference. This paper proposes a toolkit for high-dimensional panel models with large cross-sectional and time sample sizes. To reduce the dimensionality, I propose a variant of LASSO for two-way clustered panels. While being consistent, the convergence rate of LASSO is slow due to the cluster dependence, rendering inference challenging in general. Nevertheless, asymptotic normality can be established in a semiparametric moment-restriction model by leveraging a clustered-panel cross-fitting approach and, as a special case, in a partial linear model using the full sample. In an exercise of estimating multiplier using panel data, I demonstrate how high dimensionality could be hidden and the proposed toolkit enables flexible modeling and robust inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18772v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaicheng Chen</dc:creator>
    </item>
    <item>
      <title>NA-DiD: Extending Difference-in-Differences with Capabilities</title>
      <link>https://arxiv.org/abs/2507.12690</link>
      <description>arXiv:2507.12690v2 Announce Type: replace 
Abstract: This paper introduces the Non-Additive Difference-in-Differences (NA-DiD) framework, which extends classical DiD by incorporating non-additive measures the Choquet integral for effect aggregation. It serves as a novel econometric tool for impact evaluation, particularly in settings with non-additive treatment effects. First, we introduce the integral representation of the classial DiD model, and then extend it to non-additive measures, therefore deriving the formulae for NA-DiD estimation. Then, we give its theoretical properties. Applying NA-DiD to a simulated hospital hygiene intervention, we find that classical DiD can overestimate treatment effects, f.e. failing to account for compliance erosion. In contrast, NA-DiD provides a more accurate estimate by incorporating non-linear aggregation. The Julia implementation of the techniques used and introduced in this article is provided in the appendices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12690v2</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanis{\l}aw M. S. Halkiewicz</dc:creator>
    </item>
    <item>
      <title>Treatment-Effect Estimation in Complex Designs under a Parallel-trends Assumption</title>
      <link>https://arxiv.org/abs/2508.07808</link>
      <description>arXiv:2508.07808v3 Announce Type: replace 
Abstract: This paper considers the identification of dynamic treatment effects with panel data, in complex designs where the treatment may not be binary and may not be absorbing. We first show that under no-anticipation and parallel-trends assumptions, we can identify event-study effects comparing outcomes under the actual treatment path and under the status-quo path where all units would have kept their period-one treatment throughout the panel. Those effects can be helpful to evaluate ex-post the policies that effectively took place, and once properly normalized they estimate weighted averages of marginal effects of the current and lagged treatments on the outcome. Yet, they may still be hard to interpret, and they cannot be used to evaluate the effects of other policies than the ones that were conducted. To make progress, we impose another restriction, namely a random coefficients distributed-lag linear model, where effects remain constant over time. Under this model, the usual distributed-lag two-way-fixed-effects regression may be misleading. Instead, we show that this random coefficients model can be estimated simply. We illustrate our findings by revisiting Gentzkow, Shapiro and Sinkinson (2011).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07808v3</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cl\'ement de Chaisemartin, Xavier D'Haultf{\oe}uille</dc:creator>
    </item>
    <item>
      <title>Cautions on Tail Index Regressions and a Comparative Study with Extremal Quantile Regression</title>
      <link>https://arxiv.org/abs/2510.01535</link>
      <description>arXiv:2510.01535v2 Announce Type: replace 
Abstract: We re-visit tail the index regressions framework. For linear specifications, we find that the usual full rank condition can fail because conditioning on extreme outcomes causes regressors to degenerate to constants. Taking this into account, we provide additional regular conditions and establish its asymptotics in this irregular setup. For more general specifications, the conditional distribution of the covariates in the tails concentrates on the values at which the tail index is minimized. Such issue does not exist for the extremal quantile regression framework, where the tail index is assumed constant. Simulations support these findings. Using daily S&amp;P 500 returns, we find that the extremal quantile regression framework appears more suitable than tail-index regression with respect to the tail rank condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01535v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Thomas T. Yang</dc:creator>
    </item>
    <item>
      <title>Robust Two-Sample Mean Inference under Serial Dependence</title>
      <link>https://arxiv.org/abs/2512.11259</link>
      <description>arXiv:2512.11259v2 Announce Type: replace 
Abstract: We propose robust two-sample tests for comparing means in time series. The framework accommodates a wide range of applications, including structural breaks, treatment-control comparisons, and group-averaged panel data. We first consider series HAR two-sample t-tests, where standardization employs orthonormal basis projections, ensuring valid inference under heterogeneity and nonparametric dependence structures. We propose a Welch-type t-approximation with adjusted degrees of freedom to account for long-run variance heterogeneity across the series. We further develop a series-based HAR wild bootstrap test, extending traditional wild bootstrap methods to the time-series setting. Our bootstrap avoids resampling blocks of observations and delivers superior finite-sample performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11259v2</guid>
      <category>econ.EM</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ulrich Hounyo, Min Seong Kim</dc:creator>
    </item>
  </channel>
</rss>
