<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Apr 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fundamentals of Caching Layered Data objects</title>
      <link>https://arxiv.org/abs/2504.01104</link>
      <description>arXiv:2504.01104v1 Announce Type: new 
Abstract: The effective management of large amounts of data processed or required by today's cloud or edge computing systems remains a fundamental challenge. This paper focuses on cache management for applications where data objects can be stored in layered representations. In such representations, each additional data layer enhances the "quality" of the object's version but comes with an incremental cost of memory space. This layered approach proves beneficial in various scenarios, including the delivery of zoomable maps, video coding, future Virtual Reality gaming, and layered neural network models where additional data layers improve inference accuracy. In systems where users or devices demand different versions of a data object, layered representations offer flexibility for caching policies to achieve improved hit rates.
  In this paper, we explore the performance of various traditionally studied caching policies, such as Belady, LRU, and LFU, both with and without layering. To this end, we develop an asymptotically accurate analytical model for Layered LRU (LLRU). We study how the performance of LLRU is impacted by factors such as the number of layers, the popularity of different objects and layers, and overheads associated with storing layered representations. For instance, we show that, for LLRU, more layers are not always beneficial and indeed performance depends in subtle ways on the popularity and size profiles of layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01104v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agrim Bari, Gustavo de Veciana, George Kesidis</dc:creator>
    </item>
    <item>
      <title>The Multifractal IP Address Structure: Physical Explanation and Implications</title>
      <link>https://arxiv.org/abs/2504.01374</link>
      <description>arXiv:2504.01374v1 Announce Type: new 
Abstract: The structure of IP addresses observed in Internet traffic plays a critical role for a wide range of networking problems of current interest. For example, modern network telemetry systems that take advantage of existing data plane technologies for line rate traffic monitoring and processing cannot afford to waste precious data plane resources on traffic that comes from "uninteresting" regions of the IP address space. However, there is currently no well-established structural model or analysis toolbox that enables a first-principles approach to the specific problem of identifying "uninteresting" regions of the address space or the myriad of other networking problems that prominently feature IP addresses.
  To address this key missing piece, we present in this paper a first-of-its-kind empirically validated physical explanation for why the observed IP address structure in measured Internet traffic is multifractal in nature. Our root cause analysis overcomes key limitations of mostly forgotten findings from ~20 years ago and demonstrates that the Internet processes and mechanisms responsible for how IP addresses are allocated, assigned, and used in today's Internet are consistent with and well modeled by a class of evocative mathematical models called conservative cascades. We complement this root cause analysis with the development of an improved toolbox that is tailor-made for analyzing finite and discrete sets of IP addresses and includes statistical estimators that engender high confidence in the inferences they produce. We illustrate the use of this toolbox in the context of a novel address structure anomaly detection method we designed and conclude with a discussion of a range of challenging open networking problems that are motivated or inspired by our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01374v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Misa, Ram Durairajan, Arpit Gupta, Reza Rejaie, Walter Willinger</dc:creator>
    </item>
    <item>
      <title>Balancing Subjectivity and Objectivity in Network Selection: A Decision-Making Framework Towards Digital Twins</title>
      <link>https://arxiv.org/abs/2504.01414</link>
      <description>arXiv:2504.01414v1 Announce Type: new 
Abstract: Selecting the optimal radio access technology (RAT) during vertical handovers (VHO) in heterogeneous wireless networks (HWNs) is critical. Multi-attribute decision-making (MADM) is the most common approach used for network selection (NS) in HWNs. However, existing MADM-NS methods face two major challenges: the rank reversal problem (RRP), where the relative ranking of alternatives changes unexpectedly, and inefficient handling of user and/or service requirements. These limitations result in suboptimal RAT selection and diminished quality of service, which becomes particularly critical for time-sensitive applications. To address these issues, we introduce in this work a novel weighting assignment technique called BWM-GWO, which integrates the Best-Worst Method (BWM) with the Grey Wolf Optimization (GWO) algorithm through a convex linear combination. The proposed framework achieves a balanced decision-making process by using BWM to compute subjective weights that capture user/service preferences, while employing GWO to derive objective weights aimed at minimizing RRP. The development and validation of this framework establish a digital model for NS in HWNs, marking the initial step toward realizing a digital twin (DT). Experimental results show that integrating the proposed BWM-GWO technique with MADM-NS reduces RRP occurrence by up to 71.3% while significantly improving user and service satisfaction compared to benchmark approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01414v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brahim Mefgouda, Hanen Idoudi, Mohammad Al-Quraan, Ismail Lotfi, Omar Alhussein, Lina Mohjazi, Sami Muhaidat</dc:creator>
    </item>
    <item>
      <title>Optimization of BLE Broadcast Mode in Offline Finding Network</title>
      <link>https://arxiv.org/abs/2504.01422</link>
      <description>arXiv:2504.01422v1 Announce Type: new 
Abstract: In the Offline Finding Network(OFN), offline Bluetooth tags broadcast to the surrounding area, the finder devices receiving the broadcast signal and upload location information to the IoT(Internet of Things) cloud servers, thereby achieving offline finding of lost items. This process is essentially a Bluetooth low energy (BLE) neighbor discovery process(NDP). In the process, the variety of Bluetooth scan modes caused by the scan interval and scan window settings affects the discovery latency of finder devices finding the tag broadcast packets. To optimize the experience of searching for lost devices, we propose the CPBIS-mechanism, a certain proportion broadcast-intervals screening mechanism that calculates the most suitable two broadcast intervals and their proportion for offline tags. This reduces discovery latency in the BLE NDP, improves the discovery success rate, further enhances the user experience. To our knowledge, we are the first to propose a comprehensive solution for configuring the broadcast interval parameters of advertisers in BLE NDP, particularly for configurations involving two or more broadcast intervals. We evaluated the results obtained by CPBIS on the nRF52832 chip. The data shows that the CPBIS-mechanism achieves relatively low discovery latencies for multiple scan modes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01422v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Zhang, Cheng Feng, Tian Xia</dc:creator>
    </item>
    <item>
      <title>AI-Driven Framework for Multi-Service Multi-Modal Devices in NextG ORAN Systems</title>
      <link>https://arxiv.org/abs/2504.01730</link>
      <description>arXiv:2504.01730v1 Announce Type: new 
Abstract: In this paper, an artificial intelligence (AI)-driven efficient RAN management framework is proposed. This framework introduces the concept of a introducing the multi-service-modal UE (MSMU) system, which allows a single UE to handle both eMBB and uRLLC services. The proposed framework integrates traffic demand prediction, route optimization, RAN slicing, service identification, and radio resource management under uncertainty. The challenge of dynamic environments in such a system is addressed by decomposing the optimization problem into long-term (L-SP) and short-term (S-SP) subproblems. Using a long short-term memory (LSTM) model, the proposed approach allows the prediction of eMBB and uRLLC traffic demands and optimal routes for RAN slicing in the L-SP. For the S-SP, another LSTM model is employed to handle real-time service type identification and resource management based on long-term predictions. To support continuous adaptation, continual learning is incorporated into the S-SP framework, allowing the model to learn new service types while retaining prior knowledge. Experimental results show that the proposed framework efficiently manages dual-mode UEs, achieving low mean square error for traffic demand (0.003), resource block prediction (0.003), and power prediction (0.002), with 99\% accuracy in service type and route selection and over 95\% average accuracy for continual service adaptation across seven tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01730v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mrityunjoy Gain, Kitae Kim, Avi Deb Raha, Apurba Adhikary, Walid Saad, Zhu Han, Choong Seon Hong</dc:creator>
    </item>
    <item>
      <title>Asynchronous Traffic Shaping and Redundancy: Avoiding Unbounded Latencies in In-Car Networks</title>
      <link>https://arxiv.org/abs/2504.01946</link>
      <description>arXiv:2504.01946v1 Announce Type: new 
Abstract: Time-Sensitive Networking (TSN) enhances Ethernet based In-Vehicle Networks (IVNs) with real-time capabilities. Different traffic shaping algorithms have been proposed for time-critical communication, of which the Asynchronous Traffic Shaper (ATS) is an upcoming candidate. However, recent research has shown that ATS can introduce unbounded latencies when shaping traffic from non-FIFO systems. This impacts the applicability of ATS in IVNs, as these networks often use redundancy mechanisms that can cause non-FIFO behavior. In this paper, we approach the problem of accumulated delays from ATS by analyzing the scenarios that generate latency and by devising placement and configurations of ATS schedulers to prevent this behavior. Our solution successfully mitigates problematic preconditions that lead to unbounded delays, which we evaluate in simulations. Through a realistic IVN simulation case study, we demonstrate the occurrence of unbounded latencies and validate the effectiveness of our approach in avoiding them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01946v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teresa L\"ubeck, Philipp Meyer, Timo H\"ackel, Franz Korf, Thomas C. Schmidt</dc:creator>
    </item>
    <item>
      <title>How to Maximize Efficiency in Systems with Exhausted Workers</title>
      <link>https://arxiv.org/abs/2504.01186</link>
      <description>arXiv:2504.01186v1 Announce Type: cross 
Abstract: We consider the problem of assigning tasks efficiently to a set of workers that can exhaust themselves as a result of processing tasks. If a worker is exhausted, it will take a longer time to recover. To model efficiency of workers with exhaustion, we use a continuous-time Markov chain (CTMC). By taking samples from the internal states of the workers, the source assigns tasks to the workers when they are found to be in their efficient states. We consider two different settings where (i) the source can assign tasks to the workers only when they are in their most efficient state, and (ii) it can assign tasks to workers when they are also moderately efficient in spite of a potentially reduced success probability. In the former case, we find the optimal policy to be a threshold-based sampling policy where the thresholds depend on the workers' recovery and exhaustion rates. In the latter case, we solve a non-convex sum-of-ratios problem using a branch-and-bound approach which performs well compared with the globally optimal solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01186v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elif Beray Sariisik, Melih Bastopcu, Nail Akar, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Satellite Edge Artificial Intelligence with Large Models: Architectures and Technologies</title>
      <link>https://arxiv.org/abs/2504.01676</link>
      <description>arXiv:2504.01676v1 Announce Type: cross 
Abstract: Driven by the growing demand for intelligent remote sensing applications, large artificial intelligence (AI) models pre-trained on large-scale unlabeled datasets and fine-tuned for downstream tasks have significantly improved learning performance for various downstream tasks due to their generalization capabilities. However, many specific downstream tasks, such as extreme weather nowcasting (e.g., downburst and tornado), disaster monitoring, and battlefield surveillance, require real-time data processing. Traditional methods via transferring raw data to ground stations for processing often cause significant issues in terms of latency and trustworthiness. To address these challenges, satellite edge AI provides a paradigm shift from ground-based to on-board data processing by leveraging the integrated communication-and-computation capabilities in space computing power networks (Space-CPN), thereby enhancing the timeliness, effectiveness, and trustworthiness for remote sensing downstream tasks. Moreover, satellite edge large AI model (LAM) involves both the training (i.e., fine-tuning) and inference phases, where a key challenge lies in developing computation task decomposition principles to support scalable LAM deployment in resource-constrained space networks with time-varying topologies. In this article, we first propose a satellite federated fine-tuning architecture to split and deploy the modules of LAM over space and ground networks for efficient LAM fine-tuning. We then introduce a microservice-empowered satellite edge LAM inference architecture that virtualizes LAM components into lightweight microservices tailored for multi-task multimodal inference. Finally, we discuss the future directions for enhancing the efficiency and scalability of satellite edge LAM, including task-oriented communication, brain-inspired computing, and satellite edge AI network optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01676v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanming Shi, Jingyang Zhu, Chunxiao Jiang, Linling Kuang, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>Path Assignment in Mesh Networks at the Edge of Wireless Networks</title>
      <link>https://arxiv.org/abs/2411.10228</link>
      <description>arXiv:2411.10228v2 Announce Type: replace 
Abstract: We consider a mesh network at the edge of a wireless network that connects users to the core network via multiple base stations. For this scenario, we present a novel tree-search-based algorithm that strives to identify effective communication path to the core network for each user by maximizing the signal-to-noise-plus-interference ratio (SNIR) along the chosen path. We show that, for three mesh networks of varying sizes, our algorithm selects paths with minimum SNIR values that are 3 dB to 18 dB higher than those obtained through an algorithm that disregards interference within the network, 16 dB to 20 dB higher than those chosen randomly by a random path selection algorithm, and 0.5 dB to 7 dB higher compared to a recently introduced genetic algorithm (GA). Furthermore, we demonstrate that our algorithm has lower computational complexity compared to the GA in networks where its performance is within 2 dB of ours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10228v2</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siddhartha Kumar, Mohammad Hossein Moghaddam, Andreas Wolfgang, Tommy Svensson</dc:creator>
    </item>
    <item>
      <title>Wall-Proximity Matters: Understanding the Effect of Device Placement with Respect to the Wall for Indoor Wi-Fi Sensing</title>
      <link>https://arxiv.org/abs/2412.13208</link>
      <description>arXiv:2412.13208v2 Announce Type: replace 
Abstract: Wi-Fi sensing has been extensively explored for various applications, including vital sign monitoring, human activity recognition, indoor localization, and tracking. However, practical implementation in real-world scenarios is hindered by unstable sensing performance and limited knowledge of wireless sensing coverage. While previous works have aimed to address these challenges, they have overlooked the impact of walls on dynamic sensing capabilities in indoor environments. To fill this gap, we present a theoretical model that accounts for the effect of wall-device distance on sensing coverage. By incorporating both the wall-reflected path and the line-of-sight (LoS) path for dynamic signals, we develop a comprehensive sensing coverage model tailored for indoor environments. This model demonstrates that strategically deploying the transmitter and receiver in proximity to the wall within a specific range can significantly expand sensing coverage. We assess the performance of our model through experiments in respiratory monitoring and stationary crowd counting applications, showcasing a notable 11.2% improvement in counting accuracy. These findings pave the way for optimized deployment strategies in Wi-Fi sensing, facilitating more effective and accurate sensing solutions across various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13208v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Wang, Yunpeng Ge, Ivan Wang-Hei Ho</dc:creator>
    </item>
    <item>
      <title>Measuring Discrete Sensing Capability for ISAC via Task Mutual Information</title>
      <link>https://arxiv.org/abs/2405.09497</link>
      <description>arXiv:2405.09497v4 Announce Type: replace-cross 
Abstract: 6G technology offers a broader range of possibilities for communication systems to perform ubiquitous sensing tasks, including health monitoring, object recognition, and autonomous driving. Since even minor environmental changes can significantly degrade system performance, and conducting long-term posterior experimental evaluations in all scenarios is often infeasible, it is crucial to perform a priori performance assessments to design robust and reliable systems. In this paper, we consider a discrete ubiquitous sensing system where the sensing target has \(m\) different states \(W\), which can be characterized by \(n\)-dimensional independent features \(X^n\). This model not only provides the possibility of optimizing the sensing systems at a finer granularity and balancing communication and sensing resources, but also provides theoretical explanations for classical intuitive feelings (like more modalities and more accuracy) in wireless sensing. Furthermore, we validate the effectiveness of the proposed channel model through real-case studies, including person identification, displacement detection, direction estimation, and device recognition. The evaluation results indicate a Pearson correlation coefficient exceeding 0.9 between our task mutual information and conventional experimental metrics (e.g., accuracy). The open source address of the code is: https://github.com/zaoanhh/DTMI</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09497v4</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Thu, 03 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fei Shang, Haohua Du, Panlong Yang, Xin He, Jingjing Wang, Xiang-Yang Li</dc:creator>
    </item>
  </channel>
</rss>
