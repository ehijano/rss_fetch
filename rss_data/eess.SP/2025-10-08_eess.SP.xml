<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 Oct 2025 04:01:01 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Model-based Deep Learning for Joint RIS Phase Shift Compression and WMMSE Beamforming</title>
      <link>https://arxiv.org/abs/2510.05438</link>
      <description>arXiv:2510.05438v1 Announce Type: new 
Abstract: A model-based deep learning (DL) architecture is proposed for reconfigurable intelligent surface (RIS)-assisted multi-user communications to reduce the overhead of transmitting phase shift information from the access point (AP) to the RIS controller. The phase shifts are computed at the AP, which has access to the channel state information, and then encoded into a compressed binary control message that is sent to the RIS controller for element configuration. To help reduce beamformer mismatches due to phase shift compression errors, the beamformer is updated using weighted minimum mean square error (WMMSE) based on the effective channel resulting from the actual (decompressed) RIS reflection coefficients. By unrolling the iterative WMMSE algorithm as part of the wireless communication informed DL architecture, joint phase shift compression and WMMSE beamforming can be trained end-to-end. Simulations show that accounting for phase shift compression errors during beamforming significantly improves the sum-rate performance, even when the number of control bits is lower than the number of RIS elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05438v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander James Fernandes, Ioannis Psaromiligkos</dc:creator>
    </item>
    <item>
      <title>Efficient Coherence Inference Using the Demodulated Band Transform and a Generalized Linear Model</title>
      <link>https://arxiv.org/abs/2510.05559</link>
      <description>arXiv:2510.05559v1 Announce Type: new 
Abstract: Statistical significance testing of neural coherence is essential for distinguishing genuine cross-signal coupling from spurious correlations. A widely accepted approach uses surrogate-based inference, where null distributions are generated via time-shift or phase-randomization procedures. While effective, these methods are computationally expensive and yield discrete p-values that can be unstable near decision thresholds, limiting scalability to large EEG/iEEG datasets. We introduce and validate a parametric alternative based on a generalized linear model (GLM) applied to complex-valued time--frequency coefficients (e.g., from DBT or STFT), using a likelihood-ratio test. Using real respiration belt traces as a driver and simulated neural signals contaminated with broadband Gaussian noise, we perform dense sweeps of ground-truth coherence and compare GLM-based inference against time-shift/phase-randomized surrogate testing under matched conditions. GLM achieved comparable or superior sensitivity while producing continuous, stable p-values and a substantial computational advantage. At 80% detection power, GLM detects at C=0.25, whereas surrogate testing requires C=0.49, corresponding to an approximately 6--7 dB SNR improvement. Runtime benchmarking showed GLM to be nearly 200x faster than surrogate approaches. These results establish GLM-based inference on complex time--frequency coefficients as a robust, scalable alternative to surrogate testing, enabling efficient analysis of large EEG/iEEG datasets across channels, frequencies, and participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05559v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Md Rakibul Mowla, Sukhbinder Kumar, Ariane E. Rhone, Brian J. Dlouhy, Christopher K. Kovach</dc:creator>
    </item>
    <item>
      <title>Leveraging Vision Transformers for Enhanced Classification of Emotions using ECG Signals</title>
      <link>https://arxiv.org/abs/2510.05826</link>
      <description>arXiv:2510.05826v1 Announce Type: new 
Abstract: Biomedical signals provide insights into various conditions affecting the human body. Beyond diagnostic capabilities, these signals offer a deeper understanding of how specific organs respond to an individual's emotions and feelings. For instance, ECG data can reveal changes in heart rate variability linked to emotional arousal, stress levels, and autonomic nervous system activity. This data offers a window into the physiological basis of our emotional states. Recent advancements in the field diverge from conventional approaches by leveraging the power of advanced transformer architectures, which surpass traditional machine learning and deep learning methods. We begin by assessing the effectiveness of the Vision Transformer (ViT), a forefront model in image classification, for identifying emotions in imaged ECGs. Following this, we present and evaluate an improved version of ViT, integrating both CNN and SE blocks, aiming to bolster performance on imaged ECGs associated with emotion detection. Our method unfolds in two critical phases: first, we apply advanced preprocessing techniques for signal purification and converting signals into interpretable images using continuous wavelet transform and power spectral density analysis; second, we unveil a performance-boosted vision transformer architecture, cleverly enhanced with convolutional neural network components, to adeptly tackle the challenges of emotion recognition. Our methodology's robustness and innovation were thoroughly tested using ECG data from the YAAD and DREAMER datasets, leading to remarkable outcomes. For the YAAD dataset, our approach outperformed existing state-of-the-art methods in classifying seven unique emotional states, as well as in valence and arousal classification. Similarly, in the DREAMER dataset, our method excelled in distinguishing between valence, arousal and dominance, surpassing current leading techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05826v1</guid>
      <category>eess.SP</category>
      <category>cs.CV</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pubudu L. Indrasiri, Bipasha Kashyap, Pubudu N. Pathirana</dc:creator>
    </item>
    <item>
      <title>Time-causal and time-recursive wavelets</title>
      <link>https://arxiv.org/abs/2510.05834</link>
      <description>arXiv:2510.05834v1 Announce Type: new 
Abstract: When to apply wavelet analysis to real-time temporal signals, where the future cannot be accessed, it is essential to base all the steps in the signal processing pipeline on computational mechanisms that are truly time-causal.
  This paper describes how a time-causal wavelet analysis can be performed based on concepts developed in the area of temporal scale-space theory, originating from a complete classification of temporal smoothing kernels that guarantee non-creation of new structures from finer to coarser temporal scale levels. By necessity, convolution with truncated exponential kernels in cascade constitutes the only permissable class of kernels, as well as their temporal derivatives as a natural complement to fulfil the admissibility conditions of wavelet representations. For a particular way of choosing the time constants in the resulting infinite convolution of truncated exponential kernels, to ensure temporal scale covariance and thus self-similarity over temporal scales, we describe how mother wavelets can be chosen as temporal derivatives of the resulting time-causal limit kernel.
  By developing connections between wavelet theory and scale-space theory, we characterize and quantify how the continuous scaling properties transfer to the discrete implementation, demonstrating how the proposed time-causal wavelet representation can reflect the duration of locally dominant temporal structures in the input signals.
  We propose that this notion of time-causal wavelet analysis could be a valuable tool for signal processing tasks, where streams of signals are to be processed in real time, specifically for signals that may contain local variations over a rich span of temporal scales, or more generally for analysing physical or biophysical temporal phenomena, where a fully time-causal analysis is called for to be physically realistic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05834v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Lindeberg</dc:creator>
    </item>
    <item>
      <title>Time-reassigned synchrosqueezing frequency-domain chirplet transform for multicomponent signals with intersecting group delay curves</title>
      <link>https://arxiv.org/abs/2510.06173</link>
      <description>arXiv:2510.06173v1 Announce Type: new 
Abstract: To analyze signals with rapid frequency variations or transient components, the time-reassigned synchrosqueezing transform (TSST) and its variants have been recently proposed. Unlike the traditional synchrosqueezing transform, TSST squeezes the time-frequency (TF) coefficients along the group delay (GD) trajectories rather than the instantaneous frequency trajectories. Although TSST methods perform well in analyzing transient signals, they are fundamentally limited in processing multicomponent signals with intersecting GD curves. This limitation compromises the accuracy of both feature extraction and signal component recovery, thereby significantly reducing the interpretability of time-frequency representations (TFRs). This is particularly problematic in broadband signal processing systems, where the linearity of the phase response is critical and precise measurement of group delay dispersion (GDD) is essential.
  Motivated by the superior capability of frequency-domain signal modeling in characterizing rapidly frequency-varying signals, this paper proposes a novel three-dimensional time-frequency-group delay dispersion (TF-GDD) representation based on the frequency-domain chirplet transform. A subsequent time-reassigned synchrosqueezing frequency-domain chirplet transform (TSFCT) is introduced to achieve a sharper TF-GDD distribution and more accurate GD estimation. For mode retrieval, a novel frequency-domain group signal separation operation (FGSSO) is proposed.The theoretical contributions include a derivation of the approximation error for the GD and GDD reference functions and an establishment of the error bounds for FGSSO-based mode retrieval. Experimental results demonstrate that the proposed TSFCT and FGSSO effectively estimate GDs and retrieve modes--even for modes with intersecting GD trajectories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06173v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuixin Li, Jiecheng Chen, Qingtang Jiang, Lin Li</dc:creator>
    </item>
    <item>
      <title>Tiny but Mighty: A Software-Hardware Co-Design Approach for Efficient Multimodal Inference on Battery-Powered Small Devices</title>
      <link>https://arxiv.org/abs/2510.05109</link>
      <description>arXiv:2510.05109v1 Announce Type: cross 
Abstract: Large Multimodal Models (LMMs) are inherently modular, consisting of vision and audio encoders, projectors, and large language models. Yet, they are almost always executed monolithically, which underutilizes the heterogeneous accelerators (NPUs, GPUs, DSPs) in modern SoCs and leads to high end-to-end latency. In this paper, we present NANOMIND, a hardware--software co-design inference framework for Large Multimodal Models (LMMs) that breaks large models into modular ``bricks'' (vision, language, audio, etc.) and maps each to its ideal accelerator. The key insight is that large models can be broken into modular components and scheduled to run on the most appropriate compute units. It performs module-level dynamic offloading across accelerators on unified-memory SoCs. By combining customized hardware design, system-level scheduling, and optimized low-bit computation kernels, we demonstrate our framework with a compact, battery-powered device capable of running LMMs entirely on device. This prototype functions as a self-contained intelligent assistant that requires no network connectivity, while achieving higher throughput and superior power efficiency under strict resource constraints. The design further bypasses CPU bottlenecks and reduces redundant memory usage through token-aware buffer management and module-level coordination. Our system outperforms existing implementations in resource efficiency, cutting energy consumption by 42.3\% and GPU memory usage by 11.2\%. This enables a battery-powered device to run LLaVA-OneVision with a camera for nearly half a day and LLaMA-3-8B for voice interactions up to almost 20.8 hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05109v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yilong Li, Shuai Zhang, Yijing Zeng, Hao Zhang, Xinmiao Xiong, Jingyu Liu, Pan Hu, Suman Banerjee</dc:creator>
    </item>
    <item>
      <title>WaveSP-Net: Learnable Wavelet-Domain Sparse Prompt Tuning for Speech Deepfake Detection</title>
      <link>https://arxiv.org/abs/2510.05305</link>
      <description>arXiv:2510.05305v1 Announce Type: cross 
Abstract: Modern front-end design for speech deepfake detection relies on full fine-tuning of large pre-trained models like XLSR. However, this approach is not parameter-efficient and may lead to suboptimal generalization to realistic, in-the-wild data types. To address these limitations, we introduce a new family of parameter-efficient front-ends that fuse prompt-tuning with classical signal processing transforms. These include FourierPT-XLSR, which uses the Fourier Transform, and two variants based on the Wavelet Transform: WSPT-XLSR and Partial-WSPT-XLSR. We further propose WaveSP-Net, a novel architecture combining a Partial-WSPT-XLSR front-end and a bidirectional Mamba-based back-end. This design injects multi-resolution features into the prompt embeddings, which enhances the localization of subtle synthetic artifacts without altering the frozen XLSR parameters. Experimental results demonstrate that WaveSP-Net outperforms several state-of-the-art models on two new and challenging benchmarks, Deepfake-Eval-2024 and SpoofCeleb, with low trainable parameters and notable performance gains. The code and models are available at https://github.com/xxuan-acoustics/WaveSP-Net.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05305v1</guid>
      <category>eess.AS</category>
      <category>cs.CL</category>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Xuan, Xuechen Liu, Wenxin Zhang, Yi-Cheng Lin, Xiaojian Lin, Tomi Kinnunen</dc:creator>
    </item>
    <item>
      <title>Higher-Order Feature Attribution: Bridging Statistics, Explainable AI, and Topological Signal Processing</title>
      <link>https://arxiv.org/abs/2510.06165</link>
      <description>arXiv:2510.06165v1 Announce Type: cross 
Abstract: Feature attributions are post-training analysis methods that assess how various input features of a machine learning model contribute to an output prediction. Their interpretation is straightforward when features act independently, but becomes less direct when the predictive model involves interactions such as multiplicative relationships or joint feature contributions. In this work, we propose a general theory of higher-order feature attribution, which we develop on the foundation of Integrated Gradients (IG). This work extends existing frameworks in the literature on explainable AI. When using IG as the method of feature attribution, we discover natural connections to statistics and topological signal processing. We provide several theoretical results that establish the theory, and we validate our theory on a few examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06165v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kurt Butler, Guanchao Feng, Petar Djuric</dc:creator>
    </item>
    <item>
      <title>Conformalized Gaussian processes for online uncertainty quantification over graphs</title>
      <link>https://arxiv.org/abs/2510.06181</link>
      <description>arXiv:2510.06181v1 Announce Type: cross 
Abstract: Uncertainty quantification (UQ) over graphs arises in a number of safety-critical applications in network science. The Gaussian process (GP), as a classical Bayesian framework for UQ, has been developed to handle graph-structured data by devising topology-aware kernel functions. However, such GP-based approaches are limited not only by the prohibitive computational complexity, but also the strict modeling assumptions that might yield poor coverage, especially with labels arriving on the fly. To effect scalability, we devise a novel graph-aware parametric GP model by leveraging the random feature (RF)-based kernel approximation, which is amenable to efficient recursive Bayesian model updates. To further allow for adaptivity, an ensemble of graph-aware RF-based scalable GPs have been leveraged, with per-GP weight adapted to data arriving incrementally. To ensure valid coverage with robustness to model mis-specification, we wed the GP-based set predictors with the online conformal prediction framework, which post-processes the prediction sets using adaptive thresholds. Experimental results the proposed method yields improved coverage and efficient prediction sets over existing baselines by adaptively ensembling the GP models and setting the key threshold parameters in CP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06181v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>stat.ML</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jinwen Xu, Qin Lu, Georgios B. Giannakis</dc:creator>
    </item>
    <item>
      <title>Multi-Segment Photonic Power Converters for Energy Harvesting and High-Speed Optical Wireless Communication</title>
      <link>https://arxiv.org/abs/2510.06205</link>
      <description>arXiv:2510.06205v1 Announce Type: cross 
Abstract: The demand for energy-efficient high-speed wireless communication, coupled with the rapid rise of IoT devices, requires systems that integrate power harvesting with optical data reception to eliminate the need for charging or battery replacements. Recent advances have explored the use of solar cells as optical receivers for high-speed data detection alongside power harvesting. \acs{GaAs}-based \acp{PPC} provide six times greater electron mobility than silicon- or cadmium telluride-based cells, enabling faster data detection and improved power efficiency. However, their bandwidth is constrained by junction capacitance, which increases with active area, creating a trade-off between power output and data rate. To address this, we propose and test multi-segment \acs{GaAs}-based \Acp{PPC} that serve as both energy harvesters and data detectors. By segmenting the active area into 2, 4, or 6 subcells, forming circular areas with diameters of 1, 1.5, or 2.08~mm, we reduce capacitance and boost bandwidth while preserving light collection. Fabricated on a semi-insulating \ac{GaAs} substrate with etched trenches for electrical isolation, the series-connected subcells optimize absorption and minimize parasitic effects. The \Acp{PPC} were used for an eye-safe 1.5~m optical wireless link, employing \ac{OFDM} with adaptive bit and power loading. The system achieved a world record data rate of 3.8~Gbps, which is four times higher than prior works. The system converts 39.7\% of optical power from a beam of 2.3~mW, although the segmentation increases the sensitivity of the alignment. These findings provide new solutions for off-grid backhaul for future communication networks, such as 6th generation (6G) cellular.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06205v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Othman Younus, Behnaz Majlesein, Richard Nacke, Isaac N. O. Osahon, Carmine Pellegrino, Sina Babadi, Iman Tavakkolnia, Henning Helmers, Harald Haas</dc:creator>
    </item>
    <item>
      <title>Miniature UAV-Aided Cooperative THz Networks with Reconfigurable Energy Harvesting Holographic Surfaces</title>
      <link>https://arxiv.org/abs/2411.18791</link>
      <description>arXiv:2411.18791v2 Announce Type: replace 
Abstract: This paper focuses on enhancing the energy efficiency (EE) of a cooperative network that features a miniature unmanned aerial vehicle (UAV) operating at terahertz (THz) frequencies and equipped with holographic surfaces to improve network performance. Unlike traditional reconfigurable intelligent surfaces (RIS), which serve as passive relays for signal reflection, this work introduces a novel concept: energy harvesting (EH) using reconfigurable holographic surfaces (RHS). These surfaces provide more powerful and focused energy delivery during wireless power transfer than RIS and are mounted on the miniature UAV. In this system, a source node enables the UAV to simultaneously receive both information and energy signals, with the harvested energy powering data transmission to a specific destination. The EE optimization problem involves adjusting non-orthogonal multiple access (NOMA) power coefficients and the UAV's flight path while accounting for the unique characteristics of the THz channel. The problem is solved in two stages to maximize EE and meet a target transmission rate. The UAV trajectory is optimized using a successive convex approximation (SCA) method, followed by the adjustment of NOMA power coefficients through a quadratic transform technique. Simulation results demonstrate the effectiveness of the proposed algorithm, showing significant improvements over baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18791v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifei Song, Jalal Jalali, Yanyu Qin, Mostafa Darabi, Filip Lemic, Natasha Devroye</dc:creator>
    </item>
    <item>
      <title>Machine Learning Based Probe Skew Correction for High-frequency BH Loop Measurements</title>
      <link>https://arxiv.org/abs/2501.12209</link>
      <description>arXiv:2501.12209v3 Announce Type: replace 
Abstract: Experimental characterization of magnetic components has grown to be increasingly important to understand and model their behaviours in high-frequency PWM converters. The BH loop measurement is the only available approach to separate the core loss as an electrical method, which, however, is susceptive to the probe phase skew. As an alternative to the regular de-skew approaches based on hardware, this work proposes a novel machine-learning-based method to identify and correct the probe skew, which builds on the newly discovered correlation between the skew and the shape/trajectory of the measured BH loop. A special technique is proposed to artificially generate skewed images from measured waveforms as augmented training sets. A machine learning pipeline is developed with the Convolutional Neural Network (CNN) to treat the problem as an image-based prediction task. The trained model has demonstrated a high accuracy and generalizability in identifying the skew value from a BH loop unseen by the model, which enables the compensation of the skew to yield the corrected core loss value and BH loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12209v3</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPEL.2025.3564663</arxiv:DOI>
      <dc:creator>Yakun Wang, Song Liu, Jun Wang, Binyu Cui, Jingrong Yang</dc:creator>
    </item>
    <item>
      <title>Modern Base Station Architecture: Enabling Passive Beamforming with Beyond Diagonal RISs</title>
      <link>https://arxiv.org/abs/2501.15382</link>
      <description>arXiv:2501.15382v3 Announce Type: replace 
Abstract: Beamforming plays a crucial role in millimeter wave (mmWave) communication systems to mitigate the severe attenuation inherent to this spectrum. However, the use of large active antenna arrays in conventional architectures often results in high implementation costs and excessive power consumption, limiting their practicality. As an alternative, deploying large arrays at transceivers using passive devices, such as reconfigurable intelligent surfaces (RISs), offers a more cost-effective and energy-efficient solution. In this paper, we investigate a promising base station (BS) architecture that integrates a beyond diagonal RIS (BD-RIS) within the BS to enable passive beamforming. By utilizing Takagi's decomposition and leveraging the effective beamforming vector, the RIS profile can be designed to enable passive beamforming directed toward the target. Through the beamforming analysis, we reveal that BD-RIS provides robust beamforming performance across various system configurations, whereas the traditional diagonal RIS (D-RIS) exhibits instability with increasing RIS size and decreasing BS-RIS separation-two critical factors in optimizing RIS-assisted systems. Comprehensive computer simulation results across various aspects validate the superiority of the proposed BS-integrated BD-RIS over conventional D-RIS architectures, showcasing performance comparable to active analog beamforming antenna arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.15382v3</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Raeisi, Hui Chen, Henk Wymeersch, Ertugrul Basar</dc:creator>
    </item>
    <item>
      <title>A Fairness-Aware Strategy for B5G Physical-layer Security Leveraging Reconfigurable Intelligent Surfaces</title>
      <link>https://arxiv.org/abs/2506.06344</link>
      <description>arXiv:2506.06344v3 Announce Type: replace 
Abstract: Reconfigurable Intelligent Surfaces are composed of physical elements that can dynamically alter electromagnetic wave properties to enhance beamforming and lead to improvements in areas with low coverage properties. Combined with Reinforcement Learning techniques, they have the potential to be conduct as well physical-layer security hardening. Yet, and in addition to security improvements, it is crucial to consider the concept of fair communication. Reconfigurable Intelligent Surfaces must ensure that User Equipment units receive their signals with adequate strength, without other units being deprived of service due to insufficient power. In this paper, we address such a problem. We explore the fairness properties of previous work and propose a novel method that aims at obtaining both an efficient and fair duplex Reconfigurable Intelligent Surface-Reinforcement Learning system for multiple legitimate User Equipment units without reducing the level of achieved physical-layer security hardening. In terms of contributions, we uncover a fairness imbalance of a previous physical-layer security hardening solution, validate our findings and report experimental work via simulation results. We also provide an alternative reward strategy to solve the uncovered problems and release both code and datasets to foster further research in the topics of this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06344v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Pierron, Michel Barbeau, Luca De Cicco, Jose Rubio-Hernan, Joaquin Garcia-Alfaro</dc:creator>
    </item>
    <item>
      <title>Quickest Change Detection with Cost-Constrained Experiment Design</title>
      <link>https://arxiv.org/abs/2509.14186</link>
      <description>arXiv:2509.14186v2 Announce Type: replace 
Abstract: In the classical quickest change detection problem, an observer performs a single experiment to monitor a stochastic process. The goal in the classical problem is to detect a change in the statistical properties of the process, with the minimum possible delay, subject to a constraint on the rate of false alarms. This paper considers the case where, at each observation time, the decision-maker must choose between multiple experiments with varying information qualities and costs. The change can be detected using any of the experiments. The goal here is to detect the change with the minimum delay, subject to constraints on the rate of false alarms and the fraction of time each experiment is performed before the time of change. The constraint on the fraction of time can be used to control the overall cost of using the system of experiments. An algorithm called the two-experiment cumulative sum (2E-CUSUM) algorithm is first proposed to solve the problem when there are only two experiments. The algorithm for the case of multiple experiments, starting with three experiments, is then designed iteratively using the 2E-CUSUM algorithm. Two key ideas used in the design are the scaling of undershoots and the truncation of tests. The multiple-experiment algorithm can be designed to satisfy the constraints and can achieve the delay performance of the experiment with the highest quality within a constant. The important concept of data efficiency, where the observer has the choice of not performing any experiment, is explored as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14186v2</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patrick Vincent N. Lubenia, Taposh Banerjee</dc:creator>
    </item>
    <item>
      <title>My First Five Years of Faculty Career at the University of Delaware</title>
      <link>https://arxiv.org/abs/2510.05000</link>
      <description>arXiv:2510.05000v2 Announce Type: replace 
Abstract: In this short article, I would like to briefly summarize my research in the first 5 years in my university academia life in USA. I think that my research results obtained in these 5 years are the best in my career, at least which I like the most by myself. I wish that my experience in my junior academia career could be of some help to young researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05000v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiang-Gen Xia</dc:creator>
    </item>
    <item>
      <title>Offline changepoint localization using a matrix of conformal p-values</title>
      <link>https://arxiv.org/abs/2505.00292</link>
      <description>arXiv:2505.00292v4 Announce Type: replace-cross 
Abstract: Changepoint localization is the problem of estimating the index at which a change occurred in the data generating distribution of an ordered list of data, or declaring that no change occurred. We present the broadly applicable MCP algorithm, which uses a matrix of conformal p-values to produce a confidence interval for a (single) changepoint under the mild assumption that the pre-change and post-change distributions are each exchangeable. We prove a novel conformal Neyman-Pearson lemma, motivating practical classifier-based choices for our conformal score function. Finally, we exemplify the MCP algorithm on a variety of synthetic and real-world datasets, including using black-box pre-trained classifiers to detect changes in sequences of images, text, and accelerometer data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00292v4</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 08 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sanjit Dandapanthula, Aaditya Ramdas</dc:creator>
    </item>
  </channel>
</rss>
