<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 May 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generative Social Choice: The Next Generation</title>
      <link>https://arxiv.org/abs/2505.22939</link>
      <description>arXiv:2505.22939v1 Announce Type: new 
Abstract: A key task in certain democratic processes is to produce a concise slate of statements that proportionally represents the full spectrum of user opinions. This task is similar to committee elections, but unlike traditional settings, the candidate set comprises all possible statements of varying lengths, and so it can only be accessed through specific queries. Combining social choice and large language models, prior work has approached this challenge through a framework of generative social choice. We extend the framework in two fundamental ways, providing theoretical guarantees even in the face of approximately optimal queries and a budget limit on the overall length of the slate. Using GPT-4o to implement queries, we showcase our approach on datasets related to city improvement measures and drug reviews, demonstrating its effectiveness in generating representative slates from unstructured user opinions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22939v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Niclas Boehmer, Sara Fish, Ariel D. Procaccia</dc:creator>
    </item>
    <item>
      <title>Learning Recommender Mechanisms for Bayesian Stochastic Games</title>
      <link>https://arxiv.org/abs/2505.22979</link>
      <description>arXiv:2505.22979v1 Announce Type: new 
Abstract: An important challenge in non-cooperative game theory is coordinating on a single (approximate) equilibrium from many possibilities - a challenge that becomes even more complex when players hold private information. Recommender mechanisms tackle this problem by recommending strategies to players based on their reported type profiles. A key consideration in such mechanisms is to ensure that players are incentivized to participate, report their private information truthfully, and follow the recommendations. While previous work has focused on designing recommender mechanisms for one-shot and extensive-form games, these approaches cannot be effectively applied to stochastic games, particularly if we constrain recommendations to be Markov stationary policies. To bridge this gap, we introduce a novel bi-level reinforcement learning approach for automatically designing recommender mechanisms in Bayesian stochastic games. Our method produces a mechanism represented by a parametric function (such as a neural network), and is therefore highly efficient at execution time. Experimental results on two repeated and two stochastic games demonstrate that our approach achieves social welfare levels competitive with cooperative multi-agent reinforcement learning baselines, while also providing significantly improved incentive properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22979v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bengisu Guresti, Chongjie Zhang, Yevgeniy Vorobeychik</dc:creator>
    </item>
    <item>
      <title>Online Selection with Uncertain Disruption</title>
      <link>https://arxiv.org/abs/2505.22999</link>
      <description>arXiv:2505.22999v1 Announce Type: new 
Abstract: In numerous online selection problems, decision-makers (DMs) must allocate on the fly limited resources to customers with uncertain values. The DM faces the tension between allocating resources to currently observed values and saving them for potentially better, unobserved values in the future. Addressing this tension becomes more demanding if an uncertain disruption occurs while serving customers. Without any disruption, the DM gets access to the capacity information to serve customers throughout the time horizon. However, with uncertain disruption, the DM must act more cautiously due to risk of running out of capacity abruptly or misusing the resources. Motivated by this tension, we introduce the Online Selection with Uncertain Disruption (OS-UD) problem. In OS-UD, a DM sequentially observes n non-negative values drawn from a common distribution and must commit to select or reject each value in real time, without revisiting past values. The disruption is modeled as a Bernoulli random variable with probability p each time DM selects a value. We aim to design an online algorithm that maximizes the expected sum of selected values before a disruption occurs, if any.
  We evaluate online algorithms using the competitive ratio. Using a quantile-based approach, we devise a non-adaptive single-threshold algorithm that attains a competitive ratio of at least 1-1/e, and an adaptive threshold algorithm characterized by a sequence of non-increasing thresholds that attains an asymptotic competitive ratio of at least 0.745. Both of these results are worst-case optimal within their corresponding class of algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22999v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihua Xu, S\"uleyman Kerimov, Sebastian Perez-Salazar</dc:creator>
    </item>
    <item>
      <title>Learning to Incentivize in Repeated Principal-Agent Problems with Adversarial Agent Arrivals</title>
      <link>https://arxiv.org/abs/2505.23124</link>
      <description>arXiv:2505.23124v1 Announce Type: new 
Abstract: We initiate the study of a repeated principal-agent problem over a finite horizon $T$, where a principal sequentially interacts with $K\geq 2$ types of agents arriving in an adversarial order. At each round, the principal strategically chooses one of the $N$ arms to incentivize for an arriving agent of unknown type. The agent then chooses an arm based on its own utility and the provided incentive, and the principal receives a corresponding reward. The objective is to minimize regret against the best incentive in hindsight. Without prior knowledge of agent behavior, we show that the problem becomes intractable, leading to linear regret. We analyze two key settings where sublinear regret is achievable. In the first setting, the principal knows the arm each agent type would select greedily for any given incentive. Under this setting, we propose an algorithm that achieves a regret bound of $O(\min\{\sqrt{KT\log N},K\sqrt{T}\})$ and provide a matching lower bound up to a $\log K$ factor. In the second setting, an agent's response varies smoothly with the incentive and is governed by a Lipschitz constant $L\geq 1$. Under this setting, we show that there is an algorithm with a regret bound of $\tilde{O}((LN)^{1/3}T^{2/3})$ and establish a matching lower bound up to logarithmic factors. Finally, we extend our algorithmic results for both settings by allowing the principal to incentivize multiple arms simultaneously in each round.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23124v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junyan Liu, Arnab Maiti, Artin Tajdini, Kevin Jamieson, Lillian J. Ratliff</dc:creator>
    </item>
    <item>
      <title>Achieving Equitability with Subsidy</title>
      <link>https://arxiv.org/abs/2505.23251</link>
      <description>arXiv:2505.23251v1 Announce Type: new 
Abstract: We study the fair allocation problem of indivisible items with subsidies. In this paper, we mainly consider the notion of fairness - equitability (EQ), which requires that items be allocated such that all agents value the bundle they receive equally. Firstly, we study the upper bounds of the required subsidy to achieve EQ in different settings of items and provide the corresponding lower bounds. Secondly, we consider the bounded subsidy for achieving EQ and another popular notion of fairness - envy-freeness (EF) and give a characterization of the allocations that can achieve both EQ and EF. Finally, we analyze the bounds of subsidy of the allocations achieving fairness and efficiency (utilitarian social welfare or Nash welfare), and design several polynomial-time algorithms to compute the desired allocation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23251v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanyuan Wang, Tianze Wei</dc:creator>
    </item>
    <item>
      <title>Learning to Charge More: A Theoretical Study of Collusion by Q-Learning Agents</title>
      <link>https://arxiv.org/abs/2505.22909</link>
      <description>arXiv:2505.22909v1 Announce Type: cross 
Abstract: There is growing experimental evidence that $Q$-learning agents may learn to charge supracompetitive prices. We provide the first theoretical explanation for this behavior in infinite repeated games. Firms update their pricing policies based solely on observed profits, without computing equilibrium strategies. We show that when the game admits both a one-stage Nash equilibrium price and a collusive-enabling price, and when the $Q$-function satisfies certain inequalities at the end of experimentation, firms learn to consistently charge supracompetitive prices. We introduce a new class of one-memory subgame perfect equilibria (SPEs) and provide conditions under which learned behavior is supported by naive collusion, grim trigger policies, or increasing strategies. Naive collusion does not constitute an SPE unless the collusive-enabling price is a one-stage Nash equilibrium, whereas grim trigger policies can.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22909v1</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristian Chica, Yinglong Guo, Gilad Lerman</dc:creator>
    </item>
    <item>
      <title>A Smart-Contract to Resolve Multiple Equilibrium in Intermediated Trade</title>
      <link>https://arxiv.org/abs/2505.22940</link>
      <description>arXiv:2505.22940v1 Announce Type: cross 
Abstract: We present a model of a market that is intermediated by broker-dealers where there is multiple equilibrium. We then design a smart-contract that receives messages and algorithmically sends trading instructions. The smart-contract resolves the multiple equilibrium by implementing broker-dealer joint profit maximization as a Nash equilibrium. This outcome relies upon several factors: Agent commitments to follow the smart contract protocol; selective privacy of information; a structured timing of trade offers and acceptances and, crucially, trust that the smart-contract will execute the correct algorithm. Commitment is achieved by a legal contract or contingent deposit that incentivizes agents to comply with the protocol. Privacy is maintained by using fully homomorphic encryption. Multiple equilibrium is resolved by imposing a sequential ordering of trade offers and acceptances, and trust in the smart-contract is achieved by appending the smart-contract to a public blockchain, thereby enabling verification of its computations. This model serves as an example of how a smart-contract implemented with cryptography and blockchain can improve market outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22940v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Aronoff, Robert M. Townsend</dc:creator>
    </item>
    <item>
      <title>Distortion of AI Alignment: Does Preference Optimization Optimize for Preferences?</title>
      <link>https://arxiv.org/abs/2505.23749</link>
      <description>arXiv:2505.23749v1 Announce Type: cross 
Abstract: After pre-training, large language models are aligned with human preferences based on pairwise comparisons. State-of-the-art alignment methods (such as PPO-based RLHF and DPO) are built on the assumption of aligning with a single preference model, despite being deployed in settings where users have diverse preferences. As a result, it is not even clear that these alignment methods produce models that satisfy users on average -- a minimal requirement for pluralistic alignment. Drawing on social choice theory and modeling users' comparisons through individual Bradley-Terry (BT) models, we introduce an alignment method's distortion: the worst-case ratio between the optimal achievable average utility, and the average utility of the learned policy.
  The notion of distortion helps draw sharp distinctions between alignment methods: Nash Learning from Human Feedback achieves the minimax optimal distortion of $(\frac{1}{2} + o(1)) \cdot \beta$ (for the BT temperature $\beta$), robustly across utility distributions, distributions of comparison pairs, and permissible KL divergences from the reference policy. RLHF and DPO, by contrast, suffer $\geq (1 - o(1)) \cdot \beta$ distortion already without a KL constraint, and $e^{\Omega(\beta)}$ or even unbounded distortion in the full setting, depending on how comparison pairs are sampled.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.23749v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul G\"olz, Nika Haghtalab, Kunhe Yang</dc:creator>
    </item>
    <item>
      <title>Partial Allocations in Budget-Feasible Mechanism Design: Bridging Multiple Levels of Service and Divisible Agents</title>
      <link>https://arxiv.org/abs/2307.07385</link>
      <description>arXiv:2307.07385v3 Announce Type: replace 
Abstract: Budget-feasible procurement has been a major paradigm in mechanism design since its introduction by Singer (2010). An auctioneer (buyer) with a strict budget constraint is interested in buying goods or services from a group of strategic agents (sellers). In many scenarios it makes sense to allow the auctioneer to only partially buy what an agent offers, e.g., an agent might have multiple copies of an item to sell, they might offer multiple levels of a service, or they may be available to perform a task for any fraction of a specified time interval. Nevertheless, the focus of the related literature has been on settings where each agent's services are either fully acquired or not at all. The main reason for this, is that in settings with partial allocations like the ones mentioned, there are strong inapproximability results. Under the mild assumption of being able to afford each agent entirely, we are able to circumvent such results in this work. We design a polynomial-time, deterministic, truthful, budget-feasible $(2+\sqrt{3})$-approximation mechanism for the setting where each agent offers multiple levels of service and the auctioneer has a discrete separable concave valuation function. We then use this result to design a deterministic, truthful and budget-feasible $O(1)$-approximation mechanism for the setting where any fraction of a service can be acquired and the auctioneer's valuation function is separable concave (i.e., the sum of concave functions). For the special case of a linear valuation function, we improve the best known approximation ratio for the problem from $1+\phi$ (by Klumper &amp; Sch\"afer (2022)) to $2$. This establishes a separation between this setting and its indivisible counterpart.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.07385v3</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3723883</arxiv:DOI>
      <arxiv:journal_reference>ACM Transactions on Economics and Computation, 13(2), 9, 2025</arxiv:journal_reference>
      <dc:creator>Georgios Amanatidis, Sophie Klumper, Evangelos Markakis, Guido Sch\"afer, Artem Tsikiridis</dc:creator>
    </item>
    <item>
      <title>On Sybil-proof Mechanisms</title>
      <link>https://arxiv.org/abs/2407.14485</link>
      <description>arXiv:2407.14485v3 Announce Type: replace 
Abstract: We show that in the single-parameter mechanism design environment, the only non-wasteful, symmetric, incentive compatible and Sybil-proof direct mechanism is a second price auction with symmetric tie-breaking. Thus, if there is private information, lotteries or other mechanisms that do not always allocate to a highest-value bidder are not Sybil-proof or not incentive compatible. Moreover, we show that our main (im)possibility result extends beyond linear valuations, but not to multi-unit object allocation with capacity constrained bidders.
  We also provide examples of mechanisms (with higher interim payoff for the bidders than a second price auction) that satisfy all of the other axioms and a weaker, Bayesian notion of Sybil-proofness. Thus, our (im)possibility result does not generalize to the Bayesian setting and we have a larger design space: With Sybil constraints, equivalence between dominant strategy and Bayesian implementation (that holds in classical single-parameter mechanism design without Sybils) no longer holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14485v3</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minghao Pan, Bruno Mazorra, Christoph Schlegel, Akaki Mamageishvili</dc:creator>
    </item>
    <item>
      <title>Efficient Approximation Schemes for Stochastic Probing and Selection-Stopping Problems</title>
      <link>https://arxiv.org/abs/2007.13121</link>
      <description>arXiv:2007.13121v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a general framework to design {efficient} polynomial time approximation schemes (EPTAS) for fundamental stochastic combinatorial optimization problems. Given an error parameter $\epsilon&gt;0$, such algorithmic schemes attain a $(1-\epsilon)$-approximation in $t(\epsilon)\cdot poly(|{\cal I}|)$ time, where $t(\cdot)$ is a function that depends only on $\epsilon$ and $|{\cal I}|$ denotes the input length. Technically speaking, our approach relies on presenting tailor-made reductions to a newly-introduced multi-dimensional Santa Claus problem. Even though the single-dimensional version of this problem is already known to be APX-Hard, we prove that an EPTAS can be designed for a constant number of machines and dimensions, which hold for each of our applications.
  To demonstrate the versatility of our framework, we first study selection-stopping settings to derive an EPTAS for the Free-Order Prophets problem [Agrawal et al., EC~'20] and for its cost-driven generalization, Pandora's Box with Commitment [Fu et al., ICALP~'18]. These results constitute the first approximation schemes in the non-adaptive setting and improve on known \emph{inefficient} polynomial time approximation schemes (PTAS) for their adaptive variants. Next, turning our attention to stochastic probing problems, we obtain an EPTAS for the adaptive ProbeMax problem as well as for its non-adaptive counterpart; in both cases, state-of-the-art approximability results have been inefficient PTASes [Chen et al., NIPS~'16; Fu et al., ICALP~'18].</description>
      <guid isPermaLink="false">oai:arXiv.org:2007.13121v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danny Segev, Sahil Singla</dc:creator>
    </item>
    <item>
      <title>Proper Dataset Valuation by Pointwise Mutual Information</title>
      <link>https://arxiv.org/abs/2405.18253</link>
      <description>arXiv:2405.18253v3 Announce Type: replace-cross 
Abstract: Data plays a central role in advancements in modern artificial intelligence, with high-quality data emerging as a key driver of model performance. This has prompted the development of principled and effective data curation methods in recent years. However, existing methods largely rely on heuristics, and whether they are truly effective remains unclear. For instance, standard evaluation methods that assess a trained model's performance on specific benchmarks may incentivize assigning high scores to data that merely resembles the test set. This issue exemplifies Goodhart's law: when a measure becomes a target, it ceases to be a good measure. To address this issue, we propose an information-theoretic framework for evaluating data curation methods. We define dataset quality in terms of its informativeness about the true model parameters, formalized using the Blackwell ordering of informativeness. Under this ordering, Blackwell's theorem ensures that more informative data yields optimal models with lower expected loss on the true underlying distribution. To measure informativeness, we show that the Blackwell order can be determined by the Shannon mutual information between the curated data and the test data. To estimate this mutual information, we introduce a novel method that trains Bayesian models on embedded datasets and computes mutual information from the posteriors of model parameters. Experiments on real-world data demonstrate that our mutual information-based evaluation assigns appropriately lower scores to data curation strategies that reduce dataset informativeness, while traditional test score-based evaluation methods may favor data curation strategies that overfit to the test set but compromise the training data's informativeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18253v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuran Zheng, Xuan Qi, Rui Ray Chen, Yongchan Kwon, James Zou</dc:creator>
    </item>
    <item>
      <title>Towards Logically Sound Natural Language Reasoning with Logic-Enhanced Language Model Agents</title>
      <link>https://arxiv.org/abs/2408.16081</link>
      <description>arXiv:2408.16081v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are increasingly explored as general-purpose reasoners, particularly in agentic contexts. However, their outputs remain prone to mathematical and logical errors. This is especially challenging in open-ended tasks, where unstructured outputs lack explicit ground truth and may contain subtle inconsistencies. To address this issue, we propose Logic-Enhanced Language Model Agents (LELMA), a framework that integrates LLMs with formal logic to enable validation and refinement of natural language reasoning. LELMA comprises three components: an LLM-Reasoner, an LLM-Translator, and a Solver, and employs autoformalization to translate reasoning into logic representations, which are then used to assess logical validity. Using game-theoretic scenarios such as the Prisoner's Dilemma as testbeds, we highlight the limitations of both less capable (Gemini 1.0 Pro) and advanced (GPT-4o) models in generating logically sound reasoning. LELMA achieves high accuracy in error detection and improves reasoning correctness via self-refinement, particularly in GPT-4o. The study also highlights challenges in autoformalization accuracy and in evaluation of inherently ambiguous open-ended reasoning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.16081v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Fri, 30 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Agnieszka Mensfelt, Kostas Stathis, Vince Trencsenyi</dc:creator>
    </item>
  </channel>
</rss>
