<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Sep 2024 04:00:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unraveling Challenges with Supply-Chain Levels for Software Artifacts (SLSA) for Securing the Software Supply Chain</title>
      <link>https://arxiv.org/abs/2409.05014</link>
      <description>arXiv:2409.05014v1 Announce Type: new 
Abstract: In 2023, Sonatype reported a 200\% increase in software supply chain attacks, including major build infrastructure attacks. To secure the software supply chain, practitioners can follow security framework guidance like the Supply-chain Levels for Software Artifacts (SLSA). However, recent surveys and industry summits have shown that despite growing interest, the adoption of SLSA is not widespread. To understand adoption challenges, \textit{the goal of this study is to aid framework authors and practitioners in improving the adoption and development of Supply-Chain Levels for Software Artifacts (SLSA) through a qualitative study of SLSA-related issues on GitHub}. We analyzed 1,523 SLSA-related issues extracted from 233 GitHub repositories. We conducted a topic-guided thematic analysis, leveraging the Latent Dirichlet Allocation (LDA) unsupervised machine learning algorithm, to explore the challenges of adopting SLSA and the strategies for overcoming these challenges. We identified four significant challenges and five suggested adoption strategies. The two main challenges reported are complex implementation and unclear communication, highlighting the difficulties in implementing and understanding the SLSA process across diverse ecosystems. The suggested strategies include streamlining provenance generation processes, improving the SLSA verification process, and providing specific and detailed documentation. Our findings indicate that some strategies can help mitigate multiple challenges, and some challenges need future research and tool enhancement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05014v1</guid>
      <category>cs.CE</category>
      <category>cs.SE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahzabin Tamanna, Sivana Hamer, Mindy Tran, Sascha Fahl, Yasemin Acar, Laurie Williams</dc:creator>
    </item>
    <item>
      <title>A Physics-Enforced Neural Network to Predict Polymer Melt Viscosity</title>
      <link>https://arxiv.org/abs/2409.05240</link>
      <description>arXiv:2409.05240v1 Announce Type: new 
Abstract: Achieving superior polymeric components through additive manufacturing (AM) relies on precise control of rheology. One key rheological property particularly relevant to AM is melt viscosity ($\eta$). Melt viscosity is influenced by polymer chemistry, molecular weight ($M_w$), polydispersity, induced shear rate ($\dot\gamma$), and processing temperature ($T$). The relationship of $\eta$ with $M_w$, $\dot\gamma$, and $T$ may be captured by parameterized equations. Several physical experiments are required to fit the parameters, so predicting $\eta$ of a new polymer material in unexplored physical domains is a laborious process. Here, we develop a Physics-Enforced Neural Network (PENN) model that predicts the empirical parameters and encodes the parametrized equations to calculate $\eta$ as a function of polymer chemistry, $M_w$, polydispersity, $\dot\gamma$, and $T$. We benchmark our PENN against physics-unaware Artificial Neural Network (ANN) and Gaussian Process Regression (GPR) models. Finally, we demonstrate that the PENN offers superior values of $\eta$ when extrapolating to unseen values of $M_w$, $\dot\gamma$, and $T$ for sparsely seen polymers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05240v1</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayush Jain, Rishi Gurnani, Arunkumar Rajan, H. Jerry Qi, Rampi Ramprasad</dc:creator>
    </item>
    <item>
      <title>Towards Determining Mechanical Properties of Brain-Skull Interface Under Tension and Compression</title>
      <link>https://arxiv.org/abs/2409.05365</link>
      <description>arXiv:2409.05365v1 Announce Type: new 
Abstract: Computational biomechanics models of the brain have become an important tool for investigating the brain responses to mechanical loads. The geometry, loading conditions, and constitutive properties of such brain models are well-studied and generally accepted. However, there is a lack of experimental evidence to support models of the layers of tissues (brain-skull interface) connecting the brain with the skull which determine boundary conditions for the brain. We present a new protocol for determining the biomechanical properties of the brain-skull interface and present the preliminary results (for a small number of tissue samples extracted from sheep cadaver heads). The method consists of biomechanical experiments using brain tissue and brain-skull complex (consisting of the brain tissue, brain-skull interface, and skull bone) and comprehensive computer simulation of the experiments using the finite element (FE) method. Application of the FE simulations allowed us to abandon the traditionally used approaches that rely on analytical formulations that assume cuboidal (or cylindrical) sample geometry when determining the parameters that describe the biomechanical behaviour of the brain tissue and brain-skull interface. In the simulations, we used accurate 3D geometry of the samples obtained from magnetic resonance images (MRIs). Our results indicate that the behaviour of the brain-skull interface under compressive loading appreciably differs from that under tension. Rupture of the interface was clearly visible for tensile load while no obvious indication of mechanical failure was observed under compression. These results suggest that assuming a rigid connection or frictionless sliding contact between the brain tissue and skull bone, the approaches often used in computational biomechanics models of the brain, may not accurately represent the mechanical behaviour of the brain-skull interface.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05365v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sajjad Arzemanzadeh, Benjamin Zwick, Karol Miller, Tim Rosenow, Stuart I. Hodgetts, Adam Wittek</dc:creator>
    </item>
    <item>
      <title>A semi-Lagrangian method for the direct numerical simulation of crystallization and precipitation at the pore scale</title>
      <link>https://arxiv.org/abs/2409.05449</link>
      <description>arXiv:2409.05449v1 Announce Type: new 
Abstract: This article introduces a new efficient particle method for the numerical simulation of crystallization and precipitation at the pore scale of real rock geometries extracted by X-Ray tomography. It is based on the coupling between superficial velocity models of porous media, Lagrangian description of chemistry using Transition-State-Theory, involving underlying grids. Its ability to successfully compute dissolution process has been established in the past and is presently generalized to precipitation and crystallization by means of adsorption modeling. Numerical simulations of mineral CO2 trapping are provided, showing evidence of clogging/non-clogging regimes, and one of the main results is the introduction of a new non-dimensional number needed for this characterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05449v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sarah Perez, Jean-Matthieu Etancelin, Philippe Poncet</dc:creator>
    </item>
    <item>
      <title>Ice viscosity governs hydraulic fracture that causes rapid drainage of supraglacial lakes</title>
      <link>https://arxiv.org/abs/2409.05478</link>
      <description>arXiv:2409.05478v1 Announce Type: new 
Abstract: Full thickness crevasses can transport water from the glacier surface to the bedrock where high water pressures can open kilometre-long cracks along the basal interface, which can accelerate glacier flow. We present a first computational modelling study that describes time-dependent fracture propagation in an idealised glacier causing rapid supraglacial lake drainage. A novel two-scale numerical method is developed to capture the elastic and viscoelastic deformations of ice along with crevasse propagation. The fluid-conserving thermo-hydro-mechanical model incorporates turbulent fluid flow and accounts for melting/refreezing in fractures. Applying this model to observational data from a 2008 rapid lake drainage event indicates that viscous deformation exerts a much stronger control on hydrofracture propagation compared to thermal effects. This finding contradicts the conventional assumption that elastic deformation is adequate to describe fracture propagation in glaciers over short timescales (minutes to several hours) and instead demonstrates that viscous deformation must be considered to reproduce observations of lake drainage rate and local ice surface elevation change. As supraglacial lakes continue expanding inland and as Greenland Ice Sheet temperatures become warmer than -8 degree C, our results suggest rapid lake drainages are likely to occur without refreezing, which has implications for the rate of sea level rise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05478v1</guid>
      <category>cs.CE</category>
      <category>physics.ao-ph</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5194/tc-18-3991-2024</arxiv:DOI>
      <arxiv:journal_reference>The Cryosphere, vol. 18, pp. 3991-4009, 2024</arxiv:journal_reference>
      <dc:creator>Tim Hageman, Jessica Mej\'ia, Ravindra Duddu, Emilio Mart\'inez-Pa\~neda</dc:creator>
    </item>
    <item>
      <title>Advanced LSTM Neural Networks for Predicting Directional Changes in Sector-Specific ETFs Using Machine Learning Techniques</title>
      <link>https://arxiv.org/abs/2409.05778</link>
      <description>arXiv:2409.05778v1 Announce Type: new 
Abstract: Trading and investing in stocks for some is their full-time career, while for others, it's simply a supplementary income stream. Universal among all investors is the desire to turn a profit. The key to achieving this goal is diversification. Spreading investments across sectors is critical to profitability and maximizing returns. This study aims to gauge the viability of machine learning methods in practicing the principle of diversification to maximize portfolio returns. To test this, the study evaluates the Long-Short Term Memory (LSTM) model across nine different sectors and over 2,200 stocks using Vanguard's sector-based ETFs. The R-squared value across all sectors showed promising results, with an average of 0.8651 and a high of 0.942 for the VNQ ETF. These findings suggest that the LSTM model is a capable and viable model for accurately predicting directional changes across various industry sectors, helping investors diversify and grow their portfolios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05778v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rifa Gowani, Zaryab Kanjiani</dc:creator>
    </item>
    <item>
      <title>New parametric identification method for a preference model</title>
      <link>https://arxiv.org/abs/2409.04462</link>
      <description>arXiv:2409.04462v1 Announce Type: cross 
Abstract: This article presents a contribution to multi-criteria decision support intended for industrial decision-makers in order to determine the best compromise between design criteria when working on risky or innovative products. In (RENAUD et al. 2008) we used the OWA operator (Ordered Weighted Average), a well-known multi-criteria analysis technique introduced by (YAGER 1988). The interest of this aggregation method is, beyond its ease of use, its ability to evaluate a product according to a single scale. When using the OWA method, the choice of criterion weights and their values remains an important and delicate operation. Indeed, the weights are not fixed by criterion but according to a level of utility (FISHBURN 1967). The weights can, in addition, be determined using different methods. A traditional approach consists in estimating the weights from an a priori selection of the most representative samples by an expert. We propose a new approach based on applied D-Optimality to determine the best sample. The results of the two approaches are compared. Indeed, in some multi-criteria decision problems, it is difficult to choose the method that best describes the behavior of the decision maker. As said above, the first part of this paper presents an original method based on D-optimality to determine the most representative set of samples to determine the decision parameters. This method has been applied and validated in an OWA approach. It has been shown that the accuracy and reliability of the method have been improved. Since the OWA application has been improved, the other goal of this paper is to verify whether the real decision maker has an OWA-based behavior or not. To achieve this, the D-optimality approach is applied to the MAUT (Multi-Attribute Utility Theory) approach to find the best set of samples. The results of the two methods are compared. Both approaches show that, while OWA better simulates the decision maker's behavior, there is still a gap between its scores and that of OWA. The question here is how to improve the accuracy of the score estimated by OWA compared to those given by the expert. Subsequently, a hybrid approach is tested, such as a linear combination of the MAUT and OWA approaches. The results obtained with this combination were found to be more accurate than those of OWA. However, we also tested the CHOQUET discrete integral approach. In other words, it is possible to find a model capable of better describing the decision maker's behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04462v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J Renaud (ERPI), M Camargo (ERPI), L Morel (ERPI), C Fonteix (ERPI)</dc:creator>
    </item>
    <item>
      <title>Discovering Governing equations from Graph-Structured Data by Sparse Identification of Nonlinear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2409.04463</link>
      <description>arXiv:2409.04463v1 Announce Type: cross 
Abstract: The combination of machine learning (ML) and sparsity-promoting techniques is enabling direct extraction of governing equations from data, revolutionizing computational modeling in diverse fields of science and engineering. The discovered dynamical models could be used to address challenges in climate science, neuroscience, ecology, finance, epidemiology, and beyond. However, most existing sparse identification methods for discovering dynamical systems treat the whole system as one without considering the interactions between subsystems. As a result, such models are not able to capture small changes in the emergent system behavior. To address this issue, we developed a new method called Sparse Identification of Nonlinear Dynamical Systems from Graph-structured data (SINDyG), which incorporates the network structure into sparse regression to identify model parameters that explain the underlying network dynamics. SINDyG discovers the governing equations of network dynamics while offering improvements in accuracy and model simplicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04463v1</guid>
      <category>eess.SY</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Amin Basiri, Sina Khanmohammadi</dc:creator>
    </item>
    <item>
      <title>Up-sampling-only and Adaptive Mesh-based GNN for Simulating Physical Systems</title>
      <link>https://arxiv.org/abs/2409.04740</link>
      <description>arXiv:2409.04740v1 Announce Type: cross 
Abstract: Traditional simulation of complex mechanical systems relies on numerical solvers of Partial Differential Equations (PDEs), e.g., using the Finite Element Method (FEM). The FEM solvers frequently suffer from intensive computation cost and high running time. Recent graph neural network (GNN)-based simulation models can improve running time meanwhile with acceptable accuracy. Unfortunately, they are hard to tailor GNNs for complex mechanical systems, including such disadvantages as ineffective representation and inefficient message propagation (MP). To tackle these issues, in this paper, with the proposed Up-sampling-only and Adaptive MP techniques, we develop a novel hierarchical Mesh Graph Network, namely UA-MGN, for efficient and effective mechanical simulation. Evaluation on two synthetic and one real datasets demonstrates the superiority of the UA-MGN. For example, on the Beam dataset, compared to the state-of-the-art MS-MGN, UA-MGN leads to 40.99% lower errors but using only 43.48% fewer network parameters and 4.49% fewer floating point operations (FLOPs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04740v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fu Lin, Jiasheng Shi, Shijie Luo, Qinpei Zhao, Weixiong Rao, Lei Chen</dc:creator>
    </item>
    <item>
      <title>Efficient Training of Transformers for Molecule Property Prediction on Small-scale Datasets</title>
      <link>https://arxiv.org/abs/2409.04909</link>
      <description>arXiv:2409.04909v1 Announce Type: cross 
Abstract: The blood-brain barrier (BBB) serves as a protective barrier that separates the brain from the circulatory system, regulating the passage of substances into the central nervous system. Assessing the BBB permeability of potential drugs is crucial for effective drug targeting. However, traditional experimental methods for measuring BBB permeability are challenging and impractical for large-scale screening. Consequently, there is a need to develop computational approaches to predict BBB permeability. This paper proposes a GPS Transformer architecture augmented with Self Attention, designed to perform well in the low-data regime. The proposed approach achieved a state-of-the-art performance on the BBB permeability prediction task using the BBBP dataset, surpassing existing models. With a ROC-AUC of 78.8%, the approach sets a state-of-the-art by 5.5%. We demonstrate that standard Self Attention coupled with GPS transformer performs better than other variants of attention coupled with GPS Transformer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04909v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shivesh Prakash</dc:creator>
    </item>
    <item>
      <title>Differential Inversion of the Implicit Euler Method: Symbolic Analysis</title>
      <link>https://arxiv.org/abs/2409.05445</link>
      <description>arXiv:2409.05445v1 Announce Type: cross 
Abstract: The implicit Euler method integrates systems of ordinary differential equations $$\frac{d x}{d t}=G(t,x(t))$$ with differentiable right-hand side $G : R \times R^n \rightarrow R^n$ from an initial state $x=x(0) \in R^n$ to a target time $t \in R$ as $x(t)=E(t,m,x)$ using an equidistant discretization of the time interval $[0,t]$ yielding $m&gt;0$ time steps. We aim to compute the product of its inverse Jacobian $$
  (E')^{-1} \equiv
  \left (\frac{d E}{d x}\right )^{-1} \in R^{n \times n}
  $$
  with a given vector efficiently. We show that the differential inverse $(E')^{-1} \cdot v$ can be evaluated for given $v \in R^n$ with a computational cost of $\mathcal{O}(m \cdot n^2)$ as opposed to the standard $\mathcal{O}(m \cdot n^3)$ or, naively, even $\mathcal{O}(m \cdot n^4).$ The theoretical results are supported by actual run times. A reference implementation is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05445v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uwe Naumann</dc:creator>
    </item>
    <item>
      <title>RegNLP in Action: Facilitating Compliance Through Automated Information Retrieval and Answer Generation</title>
      <link>https://arxiv.org/abs/2409.05677</link>
      <description>arXiv:2409.05677v1 Announce Type: cross 
Abstract: Regulatory documents, issued by governmental regulatory bodies, establish rules, guidelines, and standards that organizations must adhere to for legal compliance. These documents, characterized by their length, complexity and frequent updates, are challenging to interpret, requiring significant allocation of time and expertise on the part of organizations to ensure ongoing compliance.Regulatory Natural Language Processing (RegNLP) is a multidisciplinary subfield aimed at simplifying access to and interpretation of regulatory rules and obligations. We define an Automated Question-Passage Generation task for RegNLP, create the ObliQA dataset containing 27,869 questions derived from the Abu Dhabi Global Markets (ADGM) financial regulation document collection, design a baseline Regulatory Information Retrieval and Answer Generation system, and evaluate it with RePASs, a novel evaluation metric that tests whether generated answers accurately capture all relevant obligations and avoid contradictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05677v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <category>cs.IR</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Tuba Gokhan, Kexin Wang, Iryna Gurevych, Ted Briscoe</dc:creator>
    </item>
    <item>
      <title>MANA-Net: Mitigating Aggregated Sentiment Homogenization with News Weighting for Enhanced Market Prediction</title>
      <link>https://arxiv.org/abs/2409.05698</link>
      <description>arXiv:2409.05698v1 Announce Type: cross 
Abstract: It is widely acknowledged that extracting market sentiments from news data benefits market predictions. However, existing methods of using financial sentiments remain simplistic, relying on equal-weight and static aggregation to manage sentiments from multiple news items. This leads to a critical issue termed ``Aggregated Sentiment Homogenization'', which has been explored through our analysis of a large financial news dataset from industry practice. This phenomenon occurs when aggregating numerous sentiments, causing representations to converge towards the mean values of sentiment distributions and thereby smoothing out unique and important information. Consequently, the aggregated sentiment representations lose much predictive value of news data. To address this problem, we introduce the Market Attention-weighted News Aggregation Network (MANA-Net), a novel method that leverages a dynamic market-news attention mechanism to aggregate news sentiments for market prediction. MANA-Net learns the relevance of news sentiments to price changes and assigns varying weights to individual news items. By integrating the news aggregation step into the networks for market prediction, MANA-Net allows for trainable sentiment representations that are optimized directly for prediction. We evaluate MANA-Net using the S&amp;P 500 and NASDAQ 100 indices, along with financial news spanning from 2003 to 2018. Experimental results demonstrate that MANA-Net outperforms various recent market prediction methods, enhancing Profit &amp; Loss by 1.1% and the daily Sharpe ratio by 0.252.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05698v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3627673.3679653</arxiv:DOI>
      <dc:creator>Mengyu Wang, Tiejun Ma</dc:creator>
    </item>
    <item>
      <title>Accurate, scalable, and efficient Bayesian optimal experimental design with derivative-informed neural operators</title>
      <link>https://arxiv.org/abs/2312.14810</link>
      <description>arXiv:2312.14810v4 Announce Type: replace 
Abstract: We consider optimal experimental design (OED) problems in selecting the most informative observation sensors to estimate model parameters in a Bayesian framework. Such problems are computationally prohibitive when the parameter-to-observable (PtO) map is expensive to evaluate, the parameters are high-dimensional, and the optimization for sensor selection is combinatorial and high-dimensional. To address these challenges, we develop an accurate, scalable, and efficient computational framework based on derivative-informed neural operators (DINO). We propose to use derivative-informed dimension reduction to reduce the parameter dimensions, based on which we train DINO with derivative information as an accurate and efficient surrogate for the PtO map and its derivative. Moreover, we derive DINO-enabled efficient formulations in computing the maximum a posteriori (MAP) point, the eigenvalues of approximate posterior covariance, and three commonly used optimality criteria for the OED problems. Furthermore, we provide detailed error analysis for the approximations of the MAP point, the eigenvalues, and the optimality criteria. We also propose a modified swapping greedy algorithm for the sensor selection optimization and demonstrate that the proposed computational framework is scalable to preserve the accuracy for increasing parameter dimensions and achieves high computational efficiency, with an over 1000$\times$ speedup accounting for both offline construction and online evaluation costs, compared to high-fidelity Bayesian OED solutions for a three-dimensional nonlinear convection-diffusion-reaction example with tens of thousands of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14810v4</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinwoo Go, Peng Chen</dc:creator>
    </item>
    <item>
      <title>DEDEM: Discontinuity Embedded Deep Energy Method for solving fracture mechanics problems</title>
      <link>https://arxiv.org/abs/2407.11346</link>
      <description>arXiv:2407.11346v2 Announce Type: replace 
Abstract: Physics-Informed Neural Networks (PINNs) have aroused great attention for its ability to address forward and inverse problems of partial differential equations. However, approximating discontinuous functions by neural networks poses a considerable challenge, which results in high computational demands and low accuracy to solve fracture mechanics problems within standard PINNs framework. In this paper, we present a novel method called Discontinuity Embedded Deep Energy Method (DEDEM) for modeling fracture mechanics problems. In this method, interfaces and internal boundaries with weak/strong discontinuities are represented by discontinuous functions constructed by signed distance functions, then the representations are embedded to the input of the neural network so that specific discontinuous features can be imposed to the neural network solution. Results demonstrate that DEDEM can accurately model the mechanical behaviors of cracks on a large variety of fracture problems. Besides, it is also found that DEDEM achieves significantly higher computational efficiency and accuracy than the existing methods based on domain decomposition techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11346v2</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luyang Zhao, Qian Shao</dc:creator>
    </item>
  </channel>
</rss>
