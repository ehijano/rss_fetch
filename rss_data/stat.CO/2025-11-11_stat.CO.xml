<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 12 Nov 2025 02:54:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Comparison of Kernels for ABC-SMC</title>
      <link>https://arxiv.org/abs/2511.06351</link>
      <description>arXiv:2511.06351v1 Announce Type: new 
Abstract: A popular method for likelihood-free inference is approximate Bayesian computation sequential Monte Carlo (ABC-SMC) algorithms. These approximate the posterior using a population of particles, which are updated using Markov kernels. Several such kernels have been proposed. In this paper we review these, highlighting some less well known choices, and proposing some novel options. Further, we conduct an extensive empirical comparison of kernel choices. Our results suggest using a one-hit kernel with a mixture proposal as a default choice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06351v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dennis Prangle, Cecilia Viscardi, Sammy Ragy</dc:creator>
    </item>
    <item>
      <title>wdiexplorer: An R package Designed for Exploratory Analysis of World Development Indicators (WDI) Data</title>
      <link>https://arxiv.org/abs/2511.07027</link>
      <description>arXiv:2511.07027v1 Announce Type: new 
Abstract: The World Development Indicators (WDI) database provides a wide range of global development data, maintained and published by the World Bank. Our \textit{wdiexplorer} package offers a comprehensive workflow that sources WDI data via the \textit{WDI} R package, prepares and explores country-level panel data of the WDI through computational functions to calculate diagnostic metrics and visualise the outputs. By leveraging the functionalities of \textit{wdiexplorer} package, users can efficiently explore any indicator dataset of the WDI, compute diagnostic indices, and visualise the metrics by incorporating the pre-defined grouping structures to identify patterns, outliers, and other interesting features of temporal behaviours. This paper presents the \textit{wdiexplorer} package, demonstrates its functionalities using the WDI: PM$_{2.5}$ air pollution dataset, and discusses the observed patterns and outliers across countries and within groups of country-level panel data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07027v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oluwayomi Akinfenwa, Niamh Cahill, Catherine Hurley</dc:creator>
    </item>
    <item>
      <title>A BGe score for tied-covariance mixtures of Gaussian Bayesian networks</title>
      <link>https://arxiv.org/abs/2511.07050</link>
      <description>arXiv:2511.07050v1 Announce Type: new 
Abstract: Mixtures of Gaussian Bayesian networks have previously been studied under full-covariance assumptions, where each mixture component has its own covariance matrix. We propose a mixture model with tied-covariance, in which all components share a common covariance matrix. Our main contribution is the derivation of its marginal likelihood, which remains analytic. Unlike in the full-covariance case, however, the marginal likelihood no longer factorizes into component-specific terms. We refer to the new likelihood as the BGe scoring metric for tied-covariance mixtures of Gaussian Bayesian networks. For model inference, we implement MCMC schemes combining structure MCMC with a fast Gibbs sampler for mixtures, and we empirically compare the tied- and full-covariance mixtures of Gaussian Bayesian networks on simulated and benchmark data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07050v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Grzegorczyk</dc:creator>
    </item>
    <item>
      <title>Smoothing Out Sticking Points: Sampling from Discrete-Continuous Mixtures with Dynamical Monte Carlo by Mapping Discrete Mass into a Latent Universe</title>
      <link>https://arxiv.org/abs/2511.07340</link>
      <description>arXiv:2511.07340v1 Announce Type: new 
Abstract: Combining a continuous "slab" density with discrete "spike" mass at zero, spike-and-slab priors provide important tools for inducing sparsity and carrying out variable selection in Bayesian models. However, the presence of discrete mass makes posterior inference challenging. "Sticky" extensions to piecewise-deterministic Markov process samplers have shown promising performance, where sampling from the spike is achieved by the process sticking there for an exponentially distributed duration. As it turns out, the sampler remains valid when the exponential sticking time is replaced with its expectation. We justify this by mapping the spike to a continuous density over a latent universe, allowing the sampler to be reinterpreted as traversing this universe while being stuck in the original space. This perspective opens up an array of possibilities to carry out posterior computation under spike-and-slab type priors. Notably, it enables us to construct sticky samplers using other dynamics-based paradigms such as Hamiltonian Monte Carlo, and, in fact, original sticky process can be established as a partial position-momentum refreshment limit of our Hamiltonian sticky sampler. Further, our theoretical and empirical findings suggest these alternatives to be at least as efficient as the original sticky approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07340v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Chin, Akihiko Nishimura</dc:creator>
    </item>
    <item>
      <title>samsara: A Continuous-Time Markov Chain Monte Carlo Sampler for Trans-Dimensional Bayesian Analysis</title>
      <link>https://arxiv.org/abs/2511.07385</link>
      <description>arXiv:2511.07385v1 Announce Type: new 
Abstract: Bayesian inference requires determining the posterior distribution, a task that becomes particularly challenging when the dimension of the parameter space is large and unknown. This limitation arises in many physics problems, such as Mixture Models (MM) with an unknown number of components or the inference of overlapping signals in noisy data, as in the Laser Interferometer Space Antenna (LISA) Global Fit problem. Traditional approaches, such as product-space methods or Reversible-Jump Markov Chain Monte Carlo (RJMCMC), often face efficiency and convergence limitations. This paper presents samsara, a Continuous-Time Markov Chain Monte Carlo (CTMCMC) framework that models parameter evolution through Poisson-driven birth, death, and mutation processes. samsara is designed to sample models of unknown dimensionality. By requiring detailed balance through adaptive rate definitions, CTMCMC achieves automatic acceptance of trans-dimensional moves and high sampling efficiency. The code features waiting time weighted estimators, optimized memory storage, and a modular design for easy customization. We validate samsara on three benchmark problems: an analytic trans-dimensional distribution, joint inference of sine waves and Lorentzians in time series, and a Gaussian MM with an unknown number of components. In all cases, the code shows excellent agreement with analytical and Nested Sampling results. All these features push samsara as a powerful alternative to RJMCMC for large- and variable-dimensional Bayesian inference problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07385v1</guid>
      <category>stat.CO</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Astorino, Lorenzo Valbusa Dall'Armi, Riccardo Buscicchio, Joachim Pomper, Angelo Ricciardone, Walter Del Pozzo</dc:creator>
    </item>
    <item>
      <title>SAT-sampling for statistical significance testing in sparse contingency tables</title>
      <link>https://arxiv.org/abs/2511.05709</link>
      <description>arXiv:2511.05709v1 Announce Type: cross 
Abstract: Exact conditional tests for contingency tables require sampling from fibers with fixed margins. Classical Markov basis MCMC is general but often impractical: computing full Markov bases that connect all fibers of a given constraint matrix can be infeasible and the resulting chains may converge slowly, especially in sparse settings or in presence of structural zeros. We introduce a SAT-based alternative that encodes fibers as Boolean circuits which allows modern SAT samplers to generate tables randomly. We analyze the sampling bias that SAT samplers may introduce, provide diagnostics, and propose practical mitigation. We propose hybrid MCMC schemes that combine SAT proposals with local moves to ensure correct stationary distributions which do not necessarily require connectivity via local moves which is particularly beneficial in presence of structural zeros. Across benchmarks, including small and involved tables with many structural zeros where pure Markov-basis methods underperform, our methods deliver reliable conditional p-values and often outperform samplers that rely on precomputed Markov bases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05709v1</guid>
      <category>stat.ME</category>
      <category>math.CO</category>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Scharpfenecker, Tobias Windisch</dc:creator>
    </item>
    <item>
      <title>Scalable and Distributed Individualized Treatment Rules for Massive Datasets</title>
      <link>https://arxiv.org/abs/2511.05842</link>
      <description>arXiv:2511.05842v1 Announce Type: cross 
Abstract: Synthesizing information from multiple data sources is crucial for constructing accurate individualized treatment rules (ITRs). However, privacy concerns often present significant barriers to the integrative analysis of such multi-source data. Classical meta-learning, which averages local estimates to derive the final ITR, is frequently suboptimal due to biases in these local estimates. To address these challenges, we propose a convolution-smoothed weighted support vector machine for learning the optimal ITR. The accompanying loss function is both convex and smooth, which allows us to develop an efficient multi-round distributed learning procedure for ITRs. Such distributed learning ensures optimal statistical performance with a fixed number of communication rounds, thereby minimizing coordination costs across data centers while preserving data privacy. Our method avoids pooling subject-level raw data and instead requires only sharing summary statistics. Additionally, we develop an efficient coordinate gradient descent algorithm, which guarantees at least linear convergence for the resulting optimization problem. Extensive simulations and an application to sepsis treatment across multiple intensive care units validate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05842v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nan Qiao, Wangcheng Li, Jingxiao Zhang, Canyi Chen</dc:creator>
    </item>
    <item>
      <title>Fast Riemannian-manifold Hamiltonian Monte Carlo for hierarchical Gaussian-process models</title>
      <link>https://arxiv.org/abs/2511.06407</link>
      <description>arXiv:2511.06407v1 Announce Type: cross 
Abstract: Hierarchical Bayesian models based on Gaussian processes are considered useful for describing complex nonlinear statistical dependencies among variables in real-world data. However, effective Monte Carlo algorithms for inference with these models have not yet been established, except for several simple cases. In this study, we show that, compared with the slow inference achieved with existing program libraries, the performance of Riemannian-manifold Hamiltonian Monte Carlo (RMHMC) can be drastically improved by optimising the computation order according to the model structure and dynamically programming the eigendecomposition. This improvement cannot be achieved when using an existing library based on a naive automatic differentiator. We numerically demonstrate that RMHMC effectively samples from the posterior, allowing the calculation of model evidence, in a Bayesian logistic regression on simulated data and in the estimation of propensity functions for the American national medical expenditure data using several Bayesian multiple-kernel models. These results lay a foundation for implementing effective Monte Carlo algorithms for analysing real-world data with Gaussian processes, and highlight the need to develop a customisable library set that allows users to incorporate dynamically programmed objects and finely optimises the mode of automatic differentiation depending on the model structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06407v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Hayakawa, Satoshi Asai</dc:creator>
    </item>
    <item>
      <title>Approximate Bayesian inference for cumulative probit regression models</title>
      <link>https://arxiv.org/abs/2511.06967</link>
      <description>arXiv:2511.06967v1 Announce Type: cross 
Abstract: Ordinal categorical data are routinely encountered in a wide range of practical applications. When the primary goal is to construct a regression model for ordinal outcomes, cumulative link models represent one of the most popular choices to link the cumulative probabilities of the response with a set of covariates through a parsimonious linear predictor, shared across response categories. When the number of observations grows, standard sampling algorithms for Bayesian inference scale poorly, making posterior computation increasingly challenging in large datasets. In this article, we propose three scalable algorithms for approximating the posterior distribution of the regression coefficients in cumulative probit models relying on Variational Bayes and Expectation Propagation. We compare the proposed approaches with inference based on Markov Chain Monte Carlo, demonstrating superior computational performance and remarkable accuracy; finally, we illustrate the utility of the proposed algorithms on a challenging case study to investigate the structure of a criminal network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.06967v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuele Aliverti</dc:creator>
    </item>
    <item>
      <title>High-dimensional Bayesian filtering through deep density approximation</title>
      <link>https://arxiv.org/abs/2511.07261</link>
      <description>arXiv:2511.07261v1 Announce Type: cross 
Abstract: In this work, we benchmark two recently developed deep density methods for nonlinear filtering. Starting from the Fokker--Planck equation with Bayes updates, we model the filtering density of a discretely observed SDE. The two filters: the deep splitting filter and the deep BSDE filter, are both based on Feynman--Kac formulas, Euler--Maruyama discretizations and neural networks. The two methods are extended to logarithmic formulations providing sound and robust implementations in increasing state dimension. Comparing to the classical particle filters and ensemble Kalman filters, we benchmark the methods on numerous examples. In the low-dimensional examples the particle filters work well, but when we scale up to a partially observed 100-dimensional Lorenz-96 model the particle-based methods fail and the logarithmic deep density method prevails. In terms of computational efficiency, the deep density methods reduce inference time by roughly two to five orders of magnitude relative to the particle-based filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07261v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kasper B{\aa}gmark, Filip Rydin</dc:creator>
    </item>
    <item>
      <title>Optimal transport with a density-dependent cost function</title>
      <link>https://arxiv.org/abs/2511.02929</link>
      <description>arXiv:2511.02929v2 Announce Type: replace 
Abstract: A new pairwise cost function is proposed for the optimal transport barycenter problem, adopting the form of the minimal action between two points, with a Lagrangian that takes into account an underlying probability distribution. Under this notion of distance, two points can only be close if there exist paths joining them that do not traverse areas of small probability. A framework is proposed and developed for the numerical solution of the corresponding data-driven optimal transport problem. The procedure parameterizes the paths of minimal action through path dependent Chebyshev polynomials and enforces the agreement between the paths' endpoints and the given source and target distributions through an adversarial penalization. The methodology and its application to clustering and matching problems is illustrated through synthetic examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02929v2</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zichu Wang, Esteban G. Tabak</dc:creator>
    </item>
    <item>
      <title>Regularized Estimation of Sparse Spectral Precision Matrices</title>
      <link>https://arxiv.org/abs/2401.11128</link>
      <description>arXiv:2401.11128v3 Announce Type: replace-cross 
Abstract: Estimation of a sparse spectral precision matrix, the inverse of a spectral density matrix, is a canonical problem in frequency-domain analysis of high-dimensional time series (HDTS), with applications in neurosciences and environmental sciences. Existing estimators use off-the-shelf optimizers for complex variables that limit scalability, uniform (non-adaptive) penalization that is not tailored to handle heterogeneity across time series components, and lack a formal non-asymptotic theory that systematically analyzes approximation and estimation errors in high-dimension. In this work, develop fast pathwise coordinate descent (CD) algorithms and non-asymptotic theory for a complex graphical lasso (CGLASSO) and an adaptive version CAGLASSO, that adapts penalization to the underlying scale of variability. For fast algorithms, we devise a realification procedure based on ring isomorphism, a notion from abstract algebra, that can be used for other high-dimensional optimization problems over complex variables. Our non-asymptotic analysis shows that consistency is possible in high-dimension under suitable sparsity assumptions. A key step is to separately bound the approximation and estimation error arising from treating the finite-sample discrete Fourier Transforms (DFTs) as i.i.d. complex-valued data, an issue well-addressed in classical time series but relatively less explored in HDTS literature. We demonstrate the performance of our proposed estimators in several simulated data sets and a real data application from neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11128v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Navonil Deb, Amy Kuceyeski, Sumanta Basu</dc:creator>
    </item>
    <item>
      <title>MDNS: Masked Diffusion Neural Sampler via Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2508.10684</link>
      <description>arXiv:2508.10684v2 Announce Type: replace-cross 
Abstract: We study the problem of learning a neural sampler to generate samples from discrete state spaces where the target probability mass function $\pi\propto\mathrm{e}^{-U}$ is known up to a normalizing constant, which is an important task in fields such as statistical physics, machine learning, combinatorial optimization, etc. To better address this challenging task when the state space has a large cardinality and the distribution is multi-modal, we propose $\textbf{M}$asked $\textbf{D}$iffusion $\textbf{N}$eural $\textbf{S}$ampler ($\textbf{MDNS}$), a novel framework for training discrete neural samplers by aligning two path measures through a family of learning objectives, theoretically grounded in the stochastic optimal control of the continuous-time Markov chains. We validate the efficiency and scalability of MDNS through extensive experiments on various distributions with distinct statistical properties, where MDNS learns to accurately sample from the target distributions despite the extremely high problem dimensions and outperforms other learning-based baselines by a large margin. A comprehensive study of ablations and extensions is also provided to demonstrate the efficacy and potential of the proposed framework. Our code is available at https://github.com/yuchen-zhu-zyc/MDNS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10684v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 11 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Zhu, Wei Guo, Jaemoo Choi, Guan-Horng Liu, Yongxin Chen, Molei Tao</dc:creator>
    </item>
  </channel>
</rss>
