<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Feb 2025 05:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Learning Bayesian Game Families, with Application to Mechanism Design</title>
      <link>https://arxiv.org/abs/2502.14078</link>
      <description>arXiv:2502.14078v1 Announce Type: new 
Abstract: Learning or estimating game models from data typically entails inducing separate models for each setting, even if the games are parametrically related. In empirical mechanism design, for example, this approach requires learning a new game model for each candidate setting of the mechanism parameter. Recent work has shown the data efficiency benefits of learning a single parameterized model for families of related games. In Bayesian games - a typical model for mechanism design - payoffs depend on both the actions and types of the players. We show how to exploit this structure by learning an interim game-family model that conditions on a single player's type. We compare this approach to the baseline approach of directly learning the ex ante payoff function, which gives payoffs in expectation of all player types. By marginalizing over player type, the interim model can also provide ex ante payoff predictions. This dual capability not only facilitates Bayes-Nash equilibrium approximation, but also enables new types of analysis using the conditional model. We validate our method through a case study of a dynamic sponsored search auction. In our experiments, the interim model more reliably approximates equilibria than the ex ante model and exhibits effective parameter extrapolation. With local search over the parameter space, the learned game-family model can be used for mechanism design. Finally, without any additional sample data, we leverage the interim model to compute piecewise best-response strategies and refine our model to incorporate these strategies, enabling an iterative approach to empirical mechanism design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14078v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Madelyn Gatchel, Michael P. Wellman</dc:creator>
    </item>
    <item>
      <title>Efficient Inverse Multiagent Learning</title>
      <link>https://arxiv.org/abs/2502.14160</link>
      <description>arXiv:2502.14160v1 Announce Type: new 
Abstract: In this paper, we study inverse game theory (resp. inverse multiagent learning) in which the goal is to find parameters of a game's payoff functions for which the expected (resp. sampled) behavior is an equilibrium. We formulate these problems as generative-adversarial (i.e., min-max) optimization problems, for which we develop polynomial-time algorithms to solve, the former of which relies on an exact first-order oracle, and the latter, a stochastic one. We extend our approach to solve inverse multiagent simulacral learning in polynomial time and number of samples. In these problems, we seek a simulacrum, meaning parameters and an associated equilibrium that replicate the given observations in expectation. We find that our approach outperforms the widely-used ARIMA method in predicting prices in Spanish electricity markets based on time-series data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14160v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denizalp Goktas, Amy Greenwald, Sadie Zhao, Alec Koppel, Sumitra Ganesh</dc:creator>
    </item>
    <item>
      <title>Asymptotic Existence of Class Envy-free Matchings</title>
      <link>https://arxiv.org/abs/2502.14371</link>
      <description>arXiv:2502.14371v1 Announce Type: new 
Abstract: We consider a one-sided matching problem where agents who are partitioned into disjoint classes and each class must receive fair treatment in a desired matching. This model, proposed by Benabbou et al. [2019], aims to address various real-life scenarios, such as the allocation of public housing and medical resources across different ethnic, age, and other demographic groups. Our focus is on achieving class envy-free matchings, where each class receives a total utility at least as large as the maximum value of a matching they would achieve from the items matched to another class. While class envy-freeness for worst-case utilities is unattainable without leaving some valuable items unmatched, such extreme cases may rarely occur in practice. To analyze the existence of a class envy-free matching in practice, we study a distributional model where agents' utilities for items are drawn from a probability distribution. Our main result establishes the asymptotic existence of a desired matching, showing that a round-robin algorithm produces a class envy-free matching as the number of agents approaches infinity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14371v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomohiko Yokoyama, Ayumi Igarashi</dc:creator>
    </item>
    <item>
      <title>Online Envy Minimization and Multicolor Discrepancy: Equivalences and Separations</title>
      <link>https://arxiv.org/abs/2502.14624</link>
      <description>arXiv:2502.14624v1 Announce Type: new 
Abstract: We consider the fundamental problem of allocating $T$ indivisible items that arrive over time to $n$ agents with additive preferences, with the goal of minimizing envy. This problem is tightly connected to online multicolor discrepancy: vectors $v_1, \dots, v_T \in \mathbb{R}^d$ with $\| v_i \|_2 \leq 1$ arrive over time and must be, immediately and irrevocably, assigned to one of $n$ colors to minimize $\max_{i,j \in [n]} \| \sum_{v \in S_i} v - \sum_{v \in S_j} v \|_{\infty}$ at each step, where $S_\ell$ is the set of vectors that are assigned color $\ell$. The special case of $n = 2$ is called online vector balancing. Any bound for multicolor discrepancy implies the same bound for envy minimization. Against an adaptive adversary, both problems have the same optimal bound, $\Theta(\sqrt{T})$, but whether this holds for weaker adversaries is unknown.
  Against an oblivious adversary, Alweiss et al. give a $O(\log T)$ bound, with high probability, for multicolor discrepancy. Kulkarni et al. improve this to $O(\sqrt{\log T})$ for vector balancing and give a matching lower bound. Whether a $O(\sqrt{\log T})$ bound holds for multicolor discrepancy remains open. These results imply the best-known upper bounds for envy minimization (for an oblivious adversary) for $n$ and two agents, respectively; whether better bounds exist is open.
  In this paper, we resolve all aforementioned open problems. We prove that online envy minimization and multicolor discrepancy are equivalent against an oblivious adversary: we give a $O(\sqrt{\log T})$ upper bound for multicolor discrepancy, and a $\Omega(\sqrt{\log T})$ lower bound for envy minimization. For a weaker, i.i.d. adversary, we prove a separation: For online vector balancing, we give a $\Omega\left(\sqrt{\frac{\log T}{\log \log T}}\right)$ lower bound, while for envy minimization, we give an algorithm that guarantees a constant upper bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14624v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Halpern, Alexandros Psomas, Paritosh Verma, Daniel Xie</dc:creator>
    </item>
    <item>
      <title>Condorcet Winners and Anscombes Paradox Under Weighted Binary Voting</title>
      <link>https://arxiv.org/abs/2502.14639</link>
      <description>arXiv:2502.14639v1 Announce Type: new 
Abstract: We consider voting on multiple independent binary issues. In addition, a weighting vector for each voter defines how important they consider each issue. The most natural way to aggregate the votes into a single unified proposal is issue-wise majority (IWM): taking a majority opinion for each issue. However, in a scenario known as Ostrogorski's Paradox, an IWM proposal may not be a Condorcet winner, or it may even fail to garner majority support in a special case known as Anscombe's Paradox.
  We show that it is co-NP-hard to determine whether there exists a Condorcet-winning proposal even without weights. In contrast, we prove that the single-switch condition provides an Ostrogorski-free voting domain under identical weighting vectors. We show that verifying the condition can be achieved in linear time and no-instances admit short, efficiently computable proofs in the form of forbidden substructures. On the way, we give the simplest linear-time test for the voter/candidate-extremal-interval condition in approval voting and the simplest and most efficient algorithm for recognizing single-crossing preferences in ordinal voting.
  We then tackle Anscombe's Paradox. Under identical weight vectors, we can guarantee a majority-supported proposal agreeing with IWM on strictly more than half of the overall weight, while with two distinct weight vectors, such proposals can get arbitrarily far from IWM. The severity of such examples is controlled by the maximum average topic weight $\tilde{w}_{max}$: a simple bound derived from a partition-based approach is tight on a large portion of the range $\tilde{w}_{max} \in (0,1)$. Finally, we extend Wagner's rule to the weighted setting: an average majority across topics of at least $\frac{3}{4}$'s precludes Anscombe's paradox from occurring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14639v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carmel Baharav, Andrei Constantinescu, Roger Wattenhofer</dc:creator>
    </item>
    <item>
      <title>Two-Sided Matching with Resource-Regional Caps</title>
      <link>https://arxiv.org/abs/2502.14690</link>
      <description>arXiv:2502.14690v1 Announce Type: new 
Abstract: We study two-sided many-to-one matching problems under a novel type of distributional constraints, resource-regional caps. In the context of college admissions, under resource-regional caps, an admitted student may be provided with a unit of some resource through a college, which belongs to a region possessing some amount of this resource. A student may be admitted to a college with at most one unit of any resource, i.e., all resources are close substitutes, e.g., dorms on the campus, dorms outside the campus, subsidies for renting a room, etc. The core feature of our model is that students are allowed to be admitted without any resource, which breaks heredity property of previously studied models with regions.
  It is well known that a stable matching may not exist under markets with regional constraints. Thus, we focus on three weakened versions of stability that restore existence under resource-regional caps: envy-freeness, non-wastefulness, and novel direct-envy stability. For each version of stability we design corresponding matching mechanism(s). Finally, we compare stability performances of constructed mechanisms using simulations, and conclude that more sophisticated direct-envy stable mechanism is the go-to mechanism for maximal stability of the resulting matching under resource-regional caps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14690v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Garrido-Lucero, Denis Sokolov, Patrick Loiseau, Simon Mauras</dc:creator>
    </item>
    <item>
      <title>FLIGHT: Facility Location Integrating Generalized, Holistic Theory of Welfare</title>
      <link>https://arxiv.org/abs/2502.14732</link>
      <description>arXiv:2502.14732v1 Announce Type: new 
Abstract: The Facility Location Problem (FLP) is a well-studied optimization problem with applications in many real-world scenarios. Past literature has explored the solutions from different perspectives to tackle FLPs. These include investigating FLPs under objective functions such as utilitarian, egalitarian, Nash welfare, etc. Also, there is no treatment for asymmetric welfare functions around the facility. We propose a unified framework, FLIGHT, to accommodate a broad class of welfare notions. The framework undergoes rigorous theoretical analysis, and we prove some structural properties of the solution to FLP. Additionally, we provide approximation bounds, which provide insight into an interesting fact: as the number of agents arbitrarily increases, the choice of welfare notion is irrelevant. Furthermore, the paper also includes results around concentration bounds under certain distributional assumptions over the preferred locations of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14732v1</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avyukta Manjunatha Vummintala, Shivam Gupta, Shweta Jain, Sujit Gujar</dc:creator>
    </item>
    <item>
      <title>Byzantine Game Theory: Sun Tzus Boxes</title>
      <link>https://arxiv.org/abs/2502.14812</link>
      <description>arXiv:2502.14812v1 Announce Type: new 
Abstract: We introduce the Byzantine Selection Problem, living at the intersection of game theory and fault-tolerant distributed computing. Here, an event organizer is presented with a group of $n$ agents, and wants to select $\ell &lt; n$ of them to form a team. For these purposes, each agent $i$ self-reports a positive skill value $v_i$, and a team's value is the sum of its members' skill values. Ideally, the value of the team should be as large as possible, which can be easily achieved by selecting agents with the highest $\ell$ skill values. However, an unknown subset of at most $t &lt; n$ agents are byzantine and hence not to be trusted, rendering their true skill values as $0$. In the spirit of the distributed computing literature, the identity of the byzantine agents is not random but instead chosen by an adversary aiming to minimize the value of the chosen team. Can we still select a team with good guarantees in this adversarial setting? As it turns out, deterministically, it remains optimal to select agents with the highest $\ell$ values. Yet, if $t \geq \ell$, the adversary can choose to make all selected agents byzantine, leading to a team of value zero. To provide meaningful guarantees, one hence needs to allow for randomization, in which case the expected value of the selected team needs to be maximized, assuming again that the adversary plays to minimize it. For this case, we provide linear-time randomized algorithms that maximize the expected value of the selected team.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14812v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei Constantinescu, Roger Wattenhofer</dc:creator>
    </item>
    <item>
      <title>Human Misperception of Generative-AI Alignment: A Laboratory Experiment</title>
      <link>https://arxiv.org/abs/2502.14708</link>
      <description>arXiv:2502.14708v1 Announce Type: cross 
Abstract: We conduct an incentivized laboratory experiment to study people's perception of generative artificial intelligence (GenAI) alignment in the context of economic decision-making. Using a panel of economic problems spanning the domains of risk, time preference, social preference, and strategic interactions, we ask human subjects to make choices for themselves and to predict the choices made by GenAI on behalf of a human user. We find that people overestimate the degree of alignment between GenAI's choices and human choices. In every problem, human subjects' average prediction about GenAI's choice is substantially closer to the average human-subject choice than it is to the GenAI choice. At the individual level, different subjects' predictions about GenAI's choice in a given problem are highly correlated with their own choices in the same problem. We explore the implications of people overestimating GenAI alignment in a simple theoretical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14708v1</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin He, Ran Shorrer, Mengjia Xia</dc:creator>
    </item>
    <item>
      <title>An Adversarial Analysis of Thompson Sampling for Full-information Online Learning: from Finite to Infinite Action Spaces</title>
      <link>https://arxiv.org/abs/2502.14790</link>
      <description>arXiv:2502.14790v1 Announce Type: cross 
Abstract: We develop an analysis of Thompson sampling for online learning under full feedback - also known as prediction with expert advice - where the learner's prior is defined over the space of an adversary's future actions, rather than the space of experts. We show regret decomposes into regret the learner expected a priori, plus a prior-robustness-type term we call excess regret. In the classical finite-expert setting, this recovers optimal rates. As an initial step towards practical online learning in settings with a potentially-uncountably-infinite number of experts, we show that Thompson sampling with a certain Gaussian process prior widely-used in the Bayesian optimization literature has a $\mathcal{O}(\beta\sqrt{T\log(1+\lambda)})$ rate against a $\beta$-bounded $\lambda$-Lipschitz~adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14790v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Terenin, Jeffrey Negrea</dc:creator>
    </item>
    <item>
      <title>Producers Equilibria and Dynamics in Engagement-Driven Recommender Systems</title>
      <link>https://arxiv.org/abs/2401.16641</link>
      <description>arXiv:2401.16641v3 Announce Type: replace 
Abstract: Online platforms such as YouTube, Instagram heavily rely on recommender systems to decide what content to present to users. Producers, in turn, often create content that is likely to be recommended to users and have users engage with it. To do so, producers try to align their content with the preferences of their targeted user base. In this work, we explore the equilibrium behavior of producers who are interested in maximizing user engagement. We study two variants of the content-serving rule for the platform's recommender system, and provide a structural characterization of producer behavior at equilibrium: namely, each producer chooses to focus on a single embedded feature. We further show that specialization, defined as different producers optimizing for distinct types of content, naturally emerges from the competition among producers trying to maximize user engagement. We provide a heuristic for computing equilibria of our engagement game, and evaluate it experimentally. We highlight i) the performance and convergence of our heuristic, ii) the degree of producer specialization, and iii) the impact of the content-serving rule on producer and user utilities at equilibrium and provide guidance on how to set the content-serving rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16641v3</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishna Acharya, Varun Vangala, Jingyan Wang, Juba Ziani</dc:creator>
    </item>
    <item>
      <title>Scheduling With Time Discounts</title>
      <link>https://arxiv.org/abs/2402.08549</link>
      <description>arXiv:2402.08549v2 Announce Type: replace 
Abstract: We study a \emph{financial} version of the classic online problem of scheduling weighted packets with deadlines. The main novelty is that, while previous works assume packets have \emph{fixed} weights throughout their lifetime, this work considers packets with \emph{time-decaying} values. Such considerations naturally arise and have wide applications in financial environments, where the present value of future actions may be discounted. We analyze the competitive ratio guarantees of scheduling algorithms under a range of discount rates encompassing the ``traditional'' undiscounted case where weights are fixed (i.e., a discount rate of 1), the fully discounted ``myopic'' case (i.e., a rate of 0), and those in between. We show how existing methods from the literature perform suboptimally in the more general discounted setting. Notably, we devise a novel memoryless deterministic algorithm, and prove that it guarantees the best possible competitive ratio attainable by deterministic algorithms for discount factors up to $\approx 0.77$. Moreover, we develop a randomized algorithm and prove that it outperforms the best possible deterministic algorithm, for any discount rate. While we highlight the relevance of our framework and results to blockchain transaction scheduling in particular, our approach and analysis techniques are general and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08549v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yotam Gafni, Aviv Yaish</dc:creator>
    </item>
    <item>
      <title>Empirical Game-Theoretic Analysis: A Survey</title>
      <link>https://arxiv.org/abs/2403.04018</link>
      <description>arXiv:2403.04018v2 Announce Type: replace 
Abstract: In the empirical approach to game-theoretic analysis (EGTA), the model of the game comes not from declarative representation, but is derived by interrogation of a procedural description of the game environment. The motivation for developing this approach was to enable game-theoretic reasoning about strategic situations too complex for analytic specification and solution. Since its introduction over twenty years ago, EGTA has been applied to a wide range of multiagent domains, from auctions and markets to recreational games to cyber-security. We survey the extensive methodology developed for EGTA over the years, organized by the elemental subproblems comprising the EGTA process. We describe key EGTA concepts and techniques, and the questions at the frontier of EGTA research. Recent advances in machine learning have accelerated progress in EGTA, and promise to significantly expand our capacities for reasoning about complex game situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04018v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1613/jair.1.16146</arxiv:DOI>
      <arxiv:journal_reference>Journal of Artificial Intelligence Research 82:1017-1076, 2025</arxiv:journal_reference>
      <dc:creator>Michael P. Wellman, Karl Tuyls, Amy Greenwald</dc:creator>
    </item>
    <item>
      <title>Learning to Play Against Unknown Opponents</title>
      <link>https://arxiv.org/abs/2412.18297</link>
      <description>arXiv:2412.18297v2 Announce Type: replace 
Abstract: We consider the problem of a learning agent who has to repeatedly play a general sum game against a strategic opponent who acts to maximize their own payoff by optimally responding against the learner's algorithm. The learning agent knows their own payoff function, but is uncertain about the payoff of their opponent (knowing only that it is drawn from some distribution $\mathcal{D}$). What learning algorithm should the agent run in order to maximize their own total utility, either in expectation or in the worst-case over $\mathcal{D}$?
  When the learning algorithm is constrained to be a no-regret algorithm, we demonstrate how to efficiently construct an optimal learning algorithm (asymptotically achieving the optimal utility) in polynomial time for both the in-expectation and worst-case problems, independent of any other assumptions. When the learning algorithm is not constrained to no-regret, we show how to construct an $\varepsilon$-optimal learning algorithm (obtaining average utility within $\varepsilon$ of the optimal utility) for both the in-expectation and worst-case problems in time polynomial in the size of the input and $1/\varepsilon$, when either the size of the game or the support of $\mathcal{D}$ is constant. Finally, for the special case of the maximin objective, where the learner wishes to maximize their minimum payoff over all possible optimizer types, we construct a learner algorithm that runs in polynomial time in each step and guarantees convergence to the optimal learner payoff. All of these results make use of recently developed machinery that converts the analysis of learning algorithms to the study of the class of corresponding geometric objects known as menus.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18297v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eshwar Ram Arunachaleswaran, Natalie Collina, Jon Schneider</dc:creator>
    </item>
    <item>
      <title>Metric Distortion of Small-group Deliberation</title>
      <link>https://arxiv.org/abs/2502.01380</link>
      <description>arXiv:2502.01380v2 Announce Type: replace 
Abstract: We consider models for social choice where voters rank a set of choices (or alternatives) by deliberating in small groups of size at most $k$, and these outcomes are aggregated by a social choice rule to find the winning alternative. We ground these models in the metric distortion framework, where the voters and alternatives are embedded in a latent metric space, with closer alternative being more desirable for a voter. We posit that the outcome of a small-group interaction optimally uses the voters' collective knowledge of the metric, either deterministically or probabilistically.
  We characterize the distortion of our deliberation models for small $k$, showing that groups of size $k=3$ suffice to drive the distortion bound below the deterministic metric distortion lower bound of $3$, and groups of size $4$ suffice to break the randomized lower bound of $2.11$. We also show nearly tight asymptotic distortion bounds in the group size, showing that for any constant $\epsilon &gt; 0$, achieving a distortion of $1+\epsilon$ needs group size that only depends on $1/\epsilon$, and not the number of alternatives. We obtain these results via formulating a basic optimization problem in small deviations of the sum of $i.i.d.$ random variables, which we solve to global optimality via non-convex optimization. The resulting bounds may be of independent interest in probability theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01380v2</guid>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashish Goel, Mohak Goyal, Kamesh Munagala</dc:creator>
    </item>
    <item>
      <title>Density-Based Algorithms for Corruption-Robust Contextual Search and Convex Optimization</title>
      <link>https://arxiv.org/abs/2206.07528</link>
      <description>arXiv:2206.07528v2 Announce Type: replace-cross 
Abstract: We study the problem of contextual search, a generalization of binary search in higher dimensions, in the adversarial noise model. Let $d$ be the dimension of the problem, $T$ be the time horizon and $C$ be the total amount of adversarial noise in the system. We focus on the $\epsilon$-ball and the absolute loss. For the $\epsilon$-ball loss, we give a tight regret bound of $O(C + d \log(1/\epsilon))$ improving over the $O(d^3 \log(1/\epsilon) \log^2(T) + C \log(T) \log(1/\epsilon))$ bound of Krishnamurthy et al (Operations Research '23). For the absolute loss, we give an efficient algorithm with regret $O(C+d \log T)$. To tackle the absolute loss case, we study the more general setting of Corruption-Robust Convex Optimization with Subgradient feedback, which is of independent interest.
  Our techniques are a significant departure from prior approaches. Specifically, we keep track of density functions over the candidate target vectors instead of a knowledge set consisting of the candidate target vectors consistent with the feedback obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.07528v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Fri, 21 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Paes Leme, Chara Podimata, Jon Schneider</dc:creator>
    </item>
  </channel>
</rss>
