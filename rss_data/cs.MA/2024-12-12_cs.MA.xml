<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Dec 2024 02:43:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The B2Scala Tool: Integrating Bach in Scala with Security in Mind</title>
      <link>https://arxiv.org/abs/2412.08235</link>
      <description>arXiv:2412.08235v1 Announce Type: cross 
Abstract: Process algebras have been widely used to verify security protocols in a formal manner. However they mostly focus on synchronous communication based on the exchange of messages. We present an alternative approach relying on asynchronous communication obtained through information available on a shared space. More precisely this paper first proposes an embedding in Scala of a Linda-like language, called Bach.  It consists of a Domain Specific Language, internal to Scala, that allows us to experiment programs developed in Bach while benefiting from the Scala eco-system, in particular from its type system as well as program fragments developed in Scala. Moreover, we introduce a logic that allows to restrict the executions of programs to those meeting logic formulae. Our work is illustrated on the Needham-Schroeder security protocol, for which we manage to automatically rediscover the man-in-the-middle attack first put in evidence by G. Lowe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08235v1</guid>
      <category>cs.PL</category>
      <category>cs.MA</category>
      <category>cs.SC</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.414.4</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 414, 2024, pp. 58-76</arxiv:journal_reference>
      <dc:creator>Doha Ouardi (University of Namur), Manel Barkallah (University of Namur), Jean-Marie Jacquet (University of Namur)</dc:creator>
    </item>
    <item>
      <title>An End-to-End Collaborative Learning Approach for Connected Autonomous Vehicles in Occluded Scenarios</title>
      <link>https://arxiv.org/abs/2412.08562</link>
      <description>arXiv:2412.08562v1 Announce Type: cross 
Abstract: Collaborative navigation becomes essential in situations of occluded scenarios in autonomous driving where independent driving policies are likely to lead to collisions. One promising approach to address this issue is through the use of Vehicle-to-Vehicle (V2V) networks that allow for the sharing of perception information with nearby agents, preventing catastrophic accidents. In this article, we propose a collaborative control method based on a V2V network for sharing compressed LiDAR features and employing Proximal Policy Optimisation to train safe and efficient navigation policies. Unlike previous approaches that rely on expert data (behaviour cloning), our proposed approach learns the multi-agent policies directly from experience in the occluded environment, while effectively meeting bandwidth limitations. The proposed method first prepossesses LiDAR point cloud data to obtain meaningful features through a convolutional neural network and then shares them with nearby CAVs to alert for potentially dangerous situations. To evaluate the proposed method, we developed an occluded intersection gym environment based on the CARLA autonomous driving simulator, allowing real-time data sharing among agents. Our experimental results demonstrate the consistent superiority of our collaborative control method over an independent reinforcement learning method and a cooperative early fusion method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08562v1</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ITSC57777.2023.10422217</arxiv:DOI>
      <arxiv:journal_reference>Journal reference: 2023 IEEE 26th International Conference on Intelligent Transportation Systems, pp. 5548-5554, 2023</arxiv:journal_reference>
      <dc:creator>Leandro Parada, Hanlin Tian, Jose Escribano, Panagiotis Angeloudis</dc:creator>
    </item>
    <item>
      <title>Dynamics-Based Algorithm-Level Privacy Preservation for Push-Sum Average Consensus</title>
      <link>https://arxiv.org/abs/2304.08018</link>
      <description>arXiv:2304.08018v3 Announce Type: replace 
Abstract: In the intricate dance of multi-agent systems, achieving average consensus is not just vital--it is the backbone of their functionality. In conventional average consensus algorithms, all agents reach an agreement by individual calculations and sharing information with their respective neighbors. Nevertheless, the information interactions that occur in the communication network may make sensitive information be revealed. In this paper, we develop a new privacy-preserving average consensus method on unbalanced directed networks. Specifically, we ensure privacy preservation by carefully embedding randomness in mixing weights to confuse communications and introducing an extra auxiliary parameter to mask the state-updated rule in several initial iterations. In parallel, we exploit the intrinsic robustness of consensus dynamics to guarantee that the average consensus is precisely achieved. Theoretical results demonstrate that the designed algorithms can converge linearly to the exact average consensus value and can guarantee privacy preservation of agents against both honest-but-curious and eavesdropping attacks. The designed algorithms are fundamentally different compared to differential privacy based algorithms that enable privacy preservation via sacrificing consensus performance. Finally, numerical experiments validate the correctness of the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.08018v3</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huqiang Cheng, Mengying Xie, Xiaowei Yang, Qingguo L\"u, Huaqing Li</dc:creator>
    </item>
    <item>
      <title>Robust Multi-Agent Control via Maximum Entropy Heterogeneous-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2306.10715</link>
      <description>arXiv:2306.10715v5 Announce Type: replace 
Abstract: In multi-agent reinforcement learning, optimal control with robustness guarantees are critical for its deployment in real world. However, existing methods face challenges related to sample complexity, training instability, potential suboptimal Nash Equilibrium convergence and non-robustness to multiple perturbations. In this paper, we propose a unified framework for learning \emph{stochastic} policies to resolve these issues. We embed cooperative MARL problems into probabilistic graphical models, from which we derive the maximum entropy (MaxEnt) objective optimal for MARL. Based on the MaxEnt framework, we propose \emph{Heterogeneous-Agent Soft Actor-Critic} (HASAC) algorithm. Theoretically, we prove the monotonic improvement and convergence to \emph{quantal response equilibrium} (QRE) properties of HASAC. Furthermore, HASAC is provably robust against a wide range of real-world uncertainties, including perturbations in rewards, environment dynamics, states, and actions. Finally, we generalize a unified template for MaxEnt algorithmic design named \emph{Maximum Entropy Heterogeneous-Agent Mirror Learning} (MEHAML), which provides any induced method with the same guarantees as HASAC. We evaluate HASAC on seven benchmarks: Bi-DexHands, Multi-Agent MuJoCo, Pursuit-Evade, StarCraft Multi-Agent Challenge, Google Research Football, Multi-Agent Particle Environment, Light Aircraft Game. Results show that HASAC consistently outperforms strong baselines in 34 out of 38 tasks, exhibiting improved training stability, better sample efficiency and sufficient exploration. The robustness of HASAC was further validated when encountering uncertainties in rewards, dynamics, states, and actions of 14 magnitudes, and real-world deployment in a multi-robot arena against these four types of uncertainties. See our page at \url{https://sites.google.com/view/meharl}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10715v5</guid>
      <category>cs.MA</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simin Li, Yifan Zhong, Jiarong Liu, Jianing Guo, Siyuan Qi, Ruixiao Xu, Xin Yu, Siyi Hu, Haobo Fu, Qiang Fu, Xiaojun Chang, Yujing Hu, Bo An, Xianglong Liu, Yaodong Yang</dc:creator>
    </item>
    <item>
      <title>AgentMixer: Multi-Agent Correlated Policy Factorization</title>
      <link>https://arxiv.org/abs/2401.08728</link>
      <description>arXiv:2401.08728v2 Announce Type: replace 
Abstract: In multi-agent reinforcement learning, centralized training with decentralized execution (CTDE) methods typically assume that agents make decisions based on their local observations independently, which may not lead to a correlated joint policy with coordination. Coordination can be explicitly encouraged during training and individual policies can be trained to imitate the correlated joint policy. However, this may lead to an \textit{asymmetric learning failure} due to the observation mismatch between the joint and individual policies. Inspired by the concept of correlated equilibrium, we introduce a \textit{strategy modification} called AgentMixer that allows agents to correlate their policies. AgentMixer combines individual partially observable policies into a joint fully observable policy non-linearly. To enable decentralized execution, we introduce \textit{Individual-Global-Consistency} to guarantee mode consistency during joint training of the centralized and decentralized policies and prove that AgentMixer converges to an $\epsilon$-approximate Correlated Equilibrium. In the Multi-Agent MuJoCo, SMAC-v2, Matrix Game, and Predator-Prey benchmarks, AgentMixer outperforms or matches state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.08728v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan Li, Wenshuai Zhao, Lijun Wu, Joni Pajarinen</dc:creator>
    </item>
    <item>
      <title>Choreographing the Rhythms of Observation: Dynamics for Ranged Observer Bipartite-Unipartite SpatioTemporal (ROBUST) Networks</title>
      <link>https://arxiv.org/abs/2406.07473</link>
      <description>arXiv:2406.07473v4 Announce Type: replace 
Abstract: Existing network analysis methods struggle to optimize observer placements in dynamic environments with limited visibility. This dissertation introduces the novel ROBUST (Ranged Observer Bipartite-Unipartite SpatioTemporal) framework, offering a significant advancement in modeling, analyzing, and optimizing observer networks within complex spatiotemporal domains. ROBUST leverages a unique bipartite-unipartite approach, distinguishing between observer and observable entities while incorporating spatial constraints and temporal dynamics.
  This research extends spatiotemporal network theory by introducing novel graph-based measures, including myopic degree, spatial closeness centrality, and edge length proportion. These measures, coupled with advanced clustering techniques like Proximal Recurrence, provide insights into network structure, resilience, and the effectiveness of observer placements. The ROBUST framework demonstrates superior resource allocation and strategic responsiveness compared to conventional models. Case studies in oceanographic monitoring, urban safety networks, and multi-agent path planning showcases its practical applicability and adaptability. Results demonstrate significant improvements in coverage, response times, and overall network efficiency.
  This work paves the way for future research in incorporating imperfect knowledge, refining temporal pathing methodologies, and expanding the scope of applications. By bridging theoretical advancements with practical solutions, ROBUST stands as a significant contribution to the field, promising to inform and inspire ongoing and future endeavors in network optimization and multi-agent system planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07473v4</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.48550/arXiv.2406.07473</arxiv:DOI>
      <dc:creator>Ted Edward Holmberg</dc:creator>
    </item>
    <item>
      <title>Normative Feeling: Socially Patterned Affective Mechanisms</title>
      <link>https://arxiv.org/abs/2411.18037</link>
      <description>arXiv:2411.18037v2 Announce Type: replace 
Abstract: Norms and the normative processes that enforce them such as social maintenance are considered fundamental building blocks of human societies, shaping many aspects of our cognition. However, emerging work argues that the building blocks of normativity emerged much earlier in evolution than previously considered. In light of this, we argue that normative processes must be taken into account to consider the evolution of even ancient processes such as affect. We show through an agent-based model (with an evolvable model of affect) that different affective dispositions emerge when taking into account social maintenance. Further, we demonstrate that social maintenance results in the emergence of a minimal population regulation mechanism in a dynamic environment, without the need to predict the state of the environment or reason about the mental state of others. We use a cultural interpretation of our model to derive a new definition of norm emergence which distinguishes between indirect and direct social maintenance. Indirect social maintenance tends to one equilibrium (similar to environmental scaffolding) and the richer direct social maintenance results in many possible equilibria in behaviour, capturing an important aspect of normative behaviour in that it bears a certain degree of arbitrariness. We also distinguish between single-variable and mechanistic normative regularities. A mechanistic regularity, rather than a particular behaviour specified by one value e.g. walking speed, is a collection of values that specify a culturally patterned version of a psychological mechanism e.g. a disposition. This is how culture reprograms entire cognitive and physiological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18037v2</guid>
      <category>cs.MA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stavros Anagnou, Daniel Polani, Christoph Salge</dc:creator>
    </item>
    <item>
      <title>Counterfactual Multi-Agent Policy Gradients</title>
      <link>https://arxiv.org/abs/1705.08926</link>
      <description>arXiv:1705.08926v3 Announce Type: replace-cross 
Abstract: Cooperative multi-agent systems can be naturally used to model many real world problems, such as network packet routing and the coordination of autonomous vehicles. There is a great need for new reinforcement learning methods that can efficiently learn decentralised policies for such systems. To this end, we propose a new multi-agent actor-critic method called counterfactual multi-agent (COMA) policy gradients. COMA uses a centralised critic to estimate the Q-function and decentralised actors to optimise the agents' policies. In addition, to address the challenges of multi-agent credit assignment, it uses a counterfactual baseline that marginalises out a single agent's action, while keeping the other agents' actions fixed. COMA also uses a critic representation that allows the counterfactual baseline to be computed efficiently in a single forward pass. We evaluate COMA in the testbed of StarCraft unit micromanagement, using a decentralised variant with significant partial observability. COMA significantly improves average performance over other multi-agent actor-critic methods in this setting, and the best performing agents are competitive with state-of-the-art centralised controllers that get access to the full state.</description>
      <guid isPermaLink="false">oai:arXiv.org:1705.08926v3</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 12 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakob Foerster, Gregory Farquhar, Triantafyllos Afouras, Nantas Nardelli, Shimon Whiteson</dc:creator>
    </item>
  </channel>
</rss>
