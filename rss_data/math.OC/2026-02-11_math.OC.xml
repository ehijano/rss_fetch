<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Feb 2026 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Uniting Iteration Limits for Mixed-Integer Quadratic MPC</title>
      <link>https://arxiv.org/abs/2602.09133</link>
      <description>arXiv:2602.09133v1 Announce Type: new 
Abstract: Iteration limited model predictive control (MPC) can stabilize a feedback control system under sufficient conditions; this work explores combining a low iteration limit MPC with a high iteration limit MPC for mixed-integer quadratic programs (MIQPs) where the suboptimality is due to solver iteration limits. To combine the two MPCs a hybrid systems controller is developed that ``unites'' two MIQP-MPC solvers where the iteration limits of interest are the branch-and-bound and quadratic programming iteration limits. Asymptotic stability and robustness of the hybrid feedback control system are theoretically derived. Then an interpretable branch-and-bound algorithm and implementable uniting controller algorithm are developed. Finally, the developed algorithms and varying iteration limits are empirically evaluated in simulation for the switching thruster and minimum thrust spacecraft rendezvous problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09133v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Fina, Christopher Petersen</dc:creator>
    </item>
    <item>
      <title>Controllability of nonautonomous measure driven integrodifferential evolution equations with nonlocal conditions</title>
      <link>https://arxiv.org/abs/2602.09212</link>
      <description>arXiv:2602.09212v1 Announce Type: new 
Abstract: This research delves into the exact controllability of semilinear measure-driven integrodifferential systems in nonlocal settings. We provide sufficient controllability requirements using the measure of noncompactness and the M\"onch fixed point theorem without making any assumptions about how compact the evolution system is in relation to the linear part of the measure system. Here, we obtain results that both generalize and improve upon many prior findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09212v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.4418/2025.80.2.6</arxiv:DOI>
      <arxiv:journal_reference>Le Matematiche, 2025-12-05</arxiv:journal_reference>
      <dc:creator>Mamadou Niang, Mamadou Pathe LY, Abdoul Aziz Ndiaye, Abdoul Aziz Ndiaye, Mamadou Abdoul Diop</dc:creator>
    </item>
    <item>
      <title>Submodularity of the expected information gain in infinite-dimensional linear inverse problems</title>
      <link>https://arxiv.org/abs/2602.09285</link>
      <description>arXiv:2602.09285v1 Announce Type: new 
Abstract: We consider infinite-dimensional linear Gaussian Bayesian inverse problems with uncorrelated sensor data, and focus on the problem of finding sensor placements that maximize the expected information gain (EIG). This study is motivated by optimal sensor placement for linear inverse problems constrained by partial differential equations (PDEs). We consider measurement models where each sensor collects a single-snapshot measurement. This covers sensor placement for inverse problems governed by linear steady PDEs or evolution equations with final-in-time observations. It is well-known that in the finite-dimensional (discretized) formulations of such inverse problems, EIG is a monotone submodular function. This also entails a theoretical guarantee for greedy sensor placement in the discretized setting. We extend the result on submodularity of the EIG to the infinite-dimensional setting, proving that the approximation guarantee of greedy sensor placement remains valid in the infinite-dimensional limit. We also discuss computational considerations and present strategies that exploit problem structure and submodularity to yield an efficient implementation of the greedy procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09285v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alen Alexanderian, Steven Maio</dc:creator>
    </item>
    <item>
      <title>Split, Skip and Play: Variance-Reduced ProxSkip for Tomography Reconstruction is Extremely Fast</title>
      <link>https://arxiv.org/abs/2602.09527</link>
      <description>arXiv:2602.09527v1 Announce Type: new 
Abstract: Many modern iterative solvers for large-scale tomographic reconstruction incur two major computational costs per iteration: expensive forward/adjoint projections to update the data fidelity term and costly proximal computations for the regulariser, often done via inner iterations. This paper studies for the first time the application of methods that couple randomised skipping of the proximal with variance-reduced subset-based optimisation of data-fit term, to simultaneously reduce both costs in challenging tomographic reconstruction tasks. We provide a series of experiments using both synthetic and real data, demonstrating striking speed-ups of the order 5x--20x compared to the non-skipped counterparts which have been so far the standard approach for efficiently solving these problems. Our work lays the groundwork for broader adoption of these methods in inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09527v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evangelos Papoutsellis, Zeljko Kereta, Kostas Papafitsoros</dc:creator>
    </item>
    <item>
      <title>Optimization Problems with Nearly Convex Objective Functions and Nearly Convex Constraint Sets</title>
      <link>https://arxiv.org/abs/2602.09560</link>
      <description>arXiv:2602.09560v1 Announce Type: new 
Abstract: To every nearly convex optimization problem, that is a minimization problem with a nearly convex objective function and a nearly convex constraint set, we associate a uniquely defined convex optimization problem with a lower semicontinuous objective function and a closed constraint set. Interesting relationships between the original nearly convex problem and the associated convex problem are established. Optimality conditions in the form of Fermat's rules are obtained for both problems. We then get a Lagrange multiplier rule for a nearly convex optimization problem under a geometrical constraint and functional constraints from the Kuhn-Tucker conditions for the associated convex optimization problem. The obtained results are illustrated by concrete examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09560v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Nang Thieu, Nguyen Dong Yen</dc:creator>
    </item>
    <item>
      <title>Input-to-state stabilization of an ODE cascaded with a parabolic equation involving Dirichlet-Robin boundary disturbances</title>
      <link>https://arxiv.org/abs/2602.09671</link>
      <description>arXiv:2602.09671v1 Announce Type: new 
Abstract: This paper focuses on the input-to-state stabilization problem for an ordinary differential equation (ODE) cascaded by parabolic partial differential equation (PDE) in the presence of Dirichlet-Robin boundary disturbances, as well as in-domain disturbances. For the cascaded system with a Dirichlet pointwise interconnection, the ODE takes the value of a Robin boundary condition at the ODE-PDE interface as its direct input, and the PDE is driven by a Dirichlet boundary input at the opposite end. We first employ the backstepping method to design a boundary controller and to decouple the cascaded system. This decoupling facilitates independent stability analysis of the PDE and ODE systems sequentially. Then, to address the challenges posed by Dirichlet boundary disturbances to the application of the classical Lyapunov method, we utilize the generalized Lyapunov method to establish the ISS in the max-norm for the cascaded system involving Dirichlet boundary disturbances and two other types of disturbances. The obtained result indicates that even in the presence of different types of disturbances, ISS analysis can still be conducted within the framework of Lyapunov stability theory. For the well-posedness of the target system, it is conducted by using the technique of lifting and the semigroup method. Finally, numerical simulations are conducted to illustrate the effectiveness of the proposed control scheme and ISS properties for a cascaded system with different disturbances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09671v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yongchun Bi, Jun Zheng, Guchuan Zhu</dc:creator>
    </item>
    <item>
      <title>Real time filtering algorithms</title>
      <link>https://arxiv.org/abs/2602.09679</link>
      <description>arXiv:2602.09679v1 Announce Type: new 
Abstract: This paper presents a systematic review of recent advances in nonlinear filtering algorithms, structured into three principal categories: Kalman-type methods, Monte Carlo methods, and the Yau-Yau algorithm. For each category, we provide a comprehensive synthesis of theoretical developments, algorithmic variants, and practical applications that have emerged in recent years. Importantly, this review addresses both continuous-time and discrete-time system formulations, offering a unified review of filtering methodologies across different frameworks. Furthermore, our analysis reveals the transformative influence of artificial intelligence breakthroughs on the entire nonlinear filtering field, particularly in areas such as learning-based filters, neural network-augmented algorithms, and data-driven approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09679v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4310/CIS.260128105210</arxiv:DOI>
      <arxiv:journal_reference>pp. 87-117 Volume 26 (2026) Number 1</arxiv:journal_reference>
      <dc:creator>Chang Qin, Yikun Li, Ru Qian, Jiayi Kang, Yao Mao</dc:creator>
    </item>
    <item>
      <title>Linear Model Extraction via Factual and Counterfactual Queries</title>
      <link>https://arxiv.org/abs/2602.09748</link>
      <description>arXiv:2602.09748v1 Announce Type: new 
Abstract: In model extraction attacks, the goal is to reveal the parameters of a black-box machine learning model by querying the model for a selected set of data points. Due to an increasing demand for explanations, this may involve counterfactual queries besides the typically considered factual queries. In this work, we consider linear models and three types of queries: factual, counterfactual, and robust counterfactual. First, for an arbitrary set of queries, we derive novel mathematical formulations for the classification regions for which the decision of the unknown model is known, without recovering any of the model parameters. Second, we derive bounds on the number of queries needed to extract the model's parameters for (robust) counterfactual queries under arbitrary norm-based distances. We show that the full model can be recovered using just a single counterfactual query when differentiable distance measures are employed. In contrast, when using polyhedral distances for instance, the number of required queries grows linearly with the dimension of the data space. For robust counterfactuals, the latter number of queries doubles. Consequently, the applied distance function and robustness of counterfactuals have a significant impact on the model's security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09748v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daan Otto, Jannis Kurtz, Dick den Hertog, Ilker Birbil</dc:creator>
    </item>
    <item>
      <title>Adaptive Single-Loop Methods for Stochastic Minimax Optimization on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2602.09840</link>
      <description>arXiv:2602.09840v1 Announce Type: new 
Abstract: Stochastic minimax optimization on Riemannian manifolds has recently attracted significant attention due to its broad range of applications, such as robust training of neural networks and robust maximum likelihood estimation. Existing optimization methods for these problems typically require selecting stepsizes based on prior knowledge of specific problem parameters, such as Lipschitz-type constants and (geodesic) strong concavity constants. Unfortunately, these parameters are often unknown in practice. To overcome this issue, we develop single-loop adaptive methods that automatically adjust stepsizes using cumulative Riemannian (stochastic) gradient norms. We first propose a deterministic single-loop Riemannian adaptive gradient descent ascent method and show that it attains an $\epsilon$-stationary point within $O(\epsilon^{-2})$ iterations. This deterministic method is of independent interest and lays the foundation for our subsequent stochastic method. In particular, we propose the Riemannian stochastic adaptive gradient descent ascent method, which finds an $\epsilon$-stationary point in $O(\epsilon^{-6})$ iterations. Under additional second-order smoothness, this iteration complexity is further improved to $O(\epsilon^{-4})$, which even outperforms the corresponding complexity result in Euclidean space. Some numerical experiments on real-world applications are conducted, including the regularized robust maximum likelihood estimation problem, and the robust training of neural networks with orthonormal weights. The results are encouraging and demonstrate the effectiveness of adaptivity in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09840v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongye Wang, Chang He, Bo Jiang</dc:creator>
    </item>
    <item>
      <title>Step-Size Stability in Stochastic Optimization: A Theoretical Perspective</title>
      <link>https://arxiv.org/abs/2602.09842</link>
      <description>arXiv:2602.09842v1 Announce Type: new 
Abstract: We present a theoretical analysis of stochastic optimization methods in terms of their sensitivity with respect to the step size. We identify a key quantity that, for each method, describes how the performance degrades as the step size becomes too large. For convex problems, we show that this quantity directly impacts the suboptimality bound of the method. Most importantly, our analysis provides direct theoretical evidence that adaptive step-size methods, such as SPS or NGN, are more robust than SGD. This allows us to quantify the advantage of these adaptive methods beyond empirical evaluation. Finally, we show through experiments that our theoretical bound qualitatively mirrors the actual performance as a function of the step size, even for nonconvex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09842v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Schaipp, Robert M. Gower, Adrien Taylor</dc:creator>
    </item>
    <item>
      <title>The Increasing Gap Dynamics in a General Spatial Matching Model</title>
      <link>https://arxiv.org/abs/2602.09926</link>
      <description>arXiv:2602.09926v1 Announce Type: new 
Abstract: We study a representation of a problem that appears in numerous transport systems: $N$ servers distributed over a given space (e.g., cars on an urban network), receive random requests from arriving users who get assigned to the closest server, after which this server is replaced by a new one at a random location. We show that this creates a negative feedback loop, which we call \textit{Increasing Gap Dynamics} (IGD): when a server is assigned a spatial gap forms, which is more likely to attract new users that further widen the gap. The simplest version of our model is a one-dimensional circle, for which we derive analytical results showing that the system converges to an inefficient equilibrium, worse than both balanced and fully random distributions of servers. We prove that an optimal assignment policy always matches the user to one of its two neighbouring servers so that long gaps tend to widen. Hence, the IGD persists even when assigning optimally rather than greedily. In two dimensions, the appearance of the IGD is illustrated through simulations on a square region. Finally, simulations of a proper ride-hailing system using real data from Manhattan confirms that the IGD arises and that it is responsible for the appearance of the well-known Wild Goose Chase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09926v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fielbaum Andr\'es, Cominetti Roberto, Correa Jos\'e</dc:creator>
    </item>
    <item>
      <title>Safe Feedback Optimization through Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2602.09928</link>
      <description>arXiv:2602.09928v1 Announce Type: new 
Abstract: Feedback optimization refers to a class of methods that steer a control system to a steady state that solves an optimization problem. Despite tremendous progress on the topic, an important problem remains open: enforcing state constraints at all times. The difficulty in addressing it lies on mediating between the safety enforcement and the closed-loop stability, and ensuring the equivalence between closed-loop equilibria and the optimization problem's critical points. In this work, we present a feedback-optimization method that enforces state constraints at all times employing high-order control-barrier functions. We provide several results on the proposed controller dynamics, including well-posedness, safety guarantees, equivalence between equilibria and critical points, and local and global (in certain convex cases) asymptotic stability of optima. Various simulations illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09928v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Delimpaltadakis, Pol Mestres, Jorge Cort\'es, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Learning to Choose Branching Rules for Nonconvex MINLPs</title>
      <link>https://arxiv.org/abs/2602.09996</link>
      <description>arXiv:2602.09996v1 Announce Type: new 
Abstract: Outer-approximation-based branch-and-bound is a common algorithmic framework for solving MINLPs (mixed-integer nonlinear programs) to global optimality, with branching variable selection critically influencing overall performance. In modern global MINLP solvers, it is unclear whether branching on fractional integer variables should be prioritized over spatial branching on variables, potentially continuous, that show constraint violations, with different solvers following different defaults. We address this question using a data-driven approach. Based on a test set of hundreds of heterogeneous public and industrial MINLP instances, we train linear and random forest regression models to predict the relative speedup of the FICO(R) Xpress Global solver when using a branching rule that always prioritizes variables with violated integralities versus a mixed rule, allowing for early spatial branches.
  We introduce a practical evaluation methodology that measures the effect of the learned model directly in terms of the shifted geometric mean runtime. Using only four features derived from strong branching and the nonlinear structure, our linear regression model achieves an 8-9% reduction in geometric-mean solving time for the Xpress solver, with over 10% improvement on hard instances. We also analyze a random regression forest model. Experiments across solver versions show that a model trained on Xpress 9.6 still yields significant improvements on Xpress 9.8 without retraining.
  Our results demonstrate how regression models can successfully guide the branching-rule selection and improve the performance of a state-of-the-art commercial MINLP solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09996v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Berthold, Fritz Geis</dc:creator>
    </item>
    <item>
      <title>Acceleration for Polyak-{\L}ojasiewicz Functions with a Gradient Aiming Condition</title>
      <link>https://arxiv.org/abs/2602.10022</link>
      <description>arXiv:2602.10022v1 Announce Type: new 
Abstract: It is known that when minimizing smooth Polyak-{\L}ojasiewicz (PL) functions, momentum algorithms cannot significantly improve the convergence bound of gradient descent, contrasting with the acceleration phenomenon occurring in the strongly convex case. To bridge this gap, the literature has proposed strongly quasar-convex functions as an intermediate non-convex class, for which accelerated bounds have been suggested to persist. We show that this is not true in general: the additional structure of strong quasar-convexity does not suffice to guaranty better worst-case bounds for momentum compared to gradient descent. As an alternative, we study PL functions under an aiming condition that measures how well the descent direction points toward a minimizer. This perspective clarifies the geometric ingredient enabling provable acceleration by momentum when minimizing PL functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10022v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Hermant</dc:creator>
    </item>
    <item>
      <title>SVD-Preconditioned Gradient Descent Method for Solving Nonlinear Least Squares Problems</title>
      <link>https://arxiv.org/abs/2602.09057</link>
      <description>arXiv:2602.09057v1 Announce Type: cross 
Abstract: This paper introduces a novel optimization algorithm designed for nonlinear least-squares problems. The method is derived by preconditioning the gradient descent direction using the Singular Value Decomposition (SVD) of the Jacobian. This SVD-based preconditioner is then integrated with the first- and second-moment adaptive learning rate mechanism of the Adam optimizer. We establish the local linear convergence of the proposed method under standard regularity assumptions and prove global convergence for a modified version of the algorithm under suitable conditions. The effectiveness of the approach is demonstrated experimentally across a range of tasks, including function approximation, partial differential equation (PDE) solving, and image classification on the CIFAR-10 dataset. Results show that the proposed method consistently outperforms standard Adam, achieving faster convergence and lower error in both regression and classification settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09057v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhipeng Chang, Wenrui Hao, Nian Liu</dc:creator>
    </item>
    <item>
      <title>From Adam to Adam-Like Lagrangians: Second-Order Nonlocal Dynamics</title>
      <link>https://arxiv.org/abs/2602.09101</link>
      <description>arXiv:2602.09101v1 Announce Type: cross 
Abstract: In this paper, we derive an accelerated continuous-time formulation of Adam by modeling it as a second-order integro-differential dynamical system. We relate this inertial nonlocal model to an existing first-order nonlocal Adam flow through an $\alpha$-refinement limit, and we provide Lyapunov-based stability and convergence analyses. We also introduce an Adam-inspired nonlocal Lagrangian formulation, offering a variational viewpoint. Numerical simulations on Rosenbrock-type examples show agreement between the proposed dynamics and discrete Adam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09101v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Heredia</dc:creator>
    </item>
    <item>
      <title>From oblique-wave forcing to streak reinforcement: A perturbation-based frequency-response framework</title>
      <link>https://arxiv.org/abs/2602.09137</link>
      <description>arXiv:2602.09137v1 Announce Type: cross 
Abstract: We develop a perturbation-based frequency-response framework for analyzing amplification mechanisms that are central to subcritical routes to transition in wall-bounded shear flows. By systematically expanding the input-output dynamics of fluctuations about the laminar base flow with respect to forcing amplitude, we establish a rigorous correspondence between linear resolvent analysis and higher-order nonlinear interactions. At second order, quadratic interactions of unsteady oblique waves generate steady streamwise streaks via the lift-up mechanism. We demonstrate that the spatial structure of these streaks is captured by the second output singular function of the streamwise-constant resolvent operator. At higher orders, nonlinear coupling between oblique waves and induced streaks acts as structured forcing of the laminar linearized dynamics, yielding additional streak components whose relative phase governs reinforcement or attenuation of the leading-order streak response. Our analysis identifies a critical forcing amplitude marking the breakdown of the weakly nonlinear regime, beyond which direct numerical simulations exhibit sustained unsteadiness. We show that this breakdown coincides with the onset of secondary instability, revealing that the nonlinear interactions responsible for streak formation also drive the modal growth central to classical transition theory. The resulting framework provides a mechanistically transparent and computationally efficient description of transition that unifies non-modal amplification, streak formation, and modal instability within a single formulation derived directly from the Navier-Stokes equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09137v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Du\v{s}an Bo\v{z}i\'c, Anubhav Dwivedi, Mihailo R. Jovanovi\'c</dc:creator>
    </item>
    <item>
      <title>Existence of Multilateral Nash equilibria for families of games</title>
      <link>https://arxiv.org/abs/2602.09231</link>
      <description>arXiv:2602.09231v1 Announce Type: cross 
Abstract: This paper introduces two fundamentally new concepts to game theory: multilateral Nash equilibria and families of games. Starting with non-cooperative games, we show how these notions together seamlessly integrate into and naturally extend the classical theory, and simultaneously enable us to prove a powerful (multilateral) Nash equilibrium existence result with minimal assumptions on the game. Classically, a Nash equilibrium is a global strategy such that whichever player unilaterally deviates from the equilibrium, also reduces his own profit. For a k-lateral Nash equilibrium we now require that whichever group of k players collectively changes their strategies, also reduces all of the deviating players' profits. In this way, we obtain a filtration of equilibria, where the higher-lateral equilibria are less frequent. Furthermore, we derive an existence criterion for multilateral Nash equilibria and demonstrate how it reflects the increasing rarity of higher-lateral equilibria. Additionally, we show that some classical games have higher-lateral Nash equilibria, which in every case reveal the structure of these games from a new point of view. A family of games is a parameterized collection of non-cooperative games, where the parameter affects every aspect of the game. Typically, we assume that this dependence is continuous, thereby introducing a new structure. That way, we can avoid analyzing the games one at a time, and instead treat the family as a whole. This allows the parameter to take a central role in our theory, and shifts our attention from seeking a special strategy to searching for a special game with preferred strategies. Our main result proves the existence of a multilateral equilibrium in a family of games, maintaining minimalistic assumptions on the games individually. Surprisingly, the clique covering number of the Kneser graph makes a central appearance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09231v1</guid>
      <category>math.AT</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matija Blagojevic, Christof Sch\"utte</dc:creator>
    </item>
    <item>
      <title>Dieu khien he da tac tu</title>
      <link>https://arxiv.org/abs/2602.09412</link>
      <description>arXiv:2602.09412v1 Announce Type: cross 
Abstract: Since the early 2000s, control of multiagent systems has attracted significant research interest, with applications ranging from natural collective behaviors and social dynamics to engineered systems such as autonomous vehicles, sensor networks, and smart grids. Although research on multi-agent systems has diversified into numerous specialized directions, textbooks -- including those in English -- that provide a systematic treatment of the fundamental principles of multi-agent system control remain scarce. The material presented in this book has been developed and used in teaching since 2021, initially as a concise Vietnamese-language reference for the courses Networked Control Systems and Control of Multi-Agent Systems at Hanoi University of Science and Technology. The book focuses on a selection of fundamental topics of broad and continuing interest in the field. The complexity of several topics is asymptotic to that encountered in research-level studies, however, the analysis is presented in a step-by-step manner to facilitate access to commonly used methods and tools.
  The material is divided into three main parts. Part I introduces multiagent systems and basic graph-theoretic concepts. Part II addresses the design and analysis of linear consensus algorithms. Part III covers selected applications and research directions, including formation control, network localization, distributed optimization, opinion dynamics, and matrix-weighted networks. Each chapter concludes with notes on notable researchers in this field, further reading, and exercises.
  This book cannot be completed without the encouragement, support and suggestions from families, colleagues and friends. The authors appreciate feedback from readers to further improve the content of the book.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09412v1</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Hoang Trinh, Hieu Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Microswimmers for Trajectory Tracking Using Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2602.09563</link>
      <description>arXiv:2602.09563v1 Announce Type: cross 
Abstract: Trajectory tracking for microswimmers remains a key challenge in microrobotics, where low-Reynolds-number dynamics make control design particularly complex. In this work, we formulate the trajectory tracking problem as an optimal control problem and solve it using a combination of B-spline parametrization with Bayesian optimization, allowing the treatment of high computational costs without requiring complex gradient computations. Applied to a flagellated magnetic swimmer, the proposed method reproduces a variety of target trajectories, including biologically inspired paths observed in experimental studies. We further evaluate the approach on a three-sphere swimmer model, demonstrating that it can adapt to and partially compensate for wall-induced hydrodynamic effects. The proposed optimization strategy can be applied consistently across models of different fidelity, from low-dimensional ODE-based models to high-fidelity PDE-based simulations, showing its robustness and generality. These results highlight the potential of Bayesian optimization as a versatile tool for optimal control strategies in microscale locomotion under complex fluid-structure interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09563v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Palazzolo, Micka\"el Binois, La\"etitia Giraldi</dc:creator>
    </item>
    <item>
      <title>On semidefinite-representable sets over valued fields</title>
      <link>https://arxiv.org/abs/2602.09702</link>
      <description>arXiv:2602.09702v1 Announce Type: cross 
Abstract: Polyhedra and spectrahedra over the real numbers, or more generally their images under linear maps, are respectively the feasible sets of linear and semidefinite programming, and form the family of semidefinite-representable sets. This paper studies analogues of these sets, as well as the associated optimization problems, when the data are taken over a valued field $K$. For $K$-polyhedra and linear programming over $K$ we present an algorithm based on the computation of Smith normal forms. We prove that fundamental properties of semidefinite-representable sets extend to the valued setting. In particular, we exhibit examples of non-polyhedral $K$-spectrahedra, as well as sets that are semidefinite-representable over $K$ but are not $K$-spectrahedra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.09702v1</guid>
      <category>math.AG</category>
      <category>cs.SC</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Corentin Cornou, Simone Naldi, Tristan Vaccon</dc:creator>
    </item>
    <item>
      <title>Deep Learning for Data-Driven Districting-and-Routing</title>
      <link>https://arxiv.org/abs/2402.06040</link>
      <description>arXiv:2402.06040v2 Announce Type: replace 
Abstract: Districting-and-routing is a strategic problem aiming to aggregate basic geographical units (e.g., zip codes) into delivery districts. Its goal is to minimize the expected long-term routing cost of performing deliveries in each district separately. Solving this stochastic problem poses critical challenges since repeatedly evaluating routing costs on a set of scenarios while searching for optimal districts takes considerable time. Consequently, solution approaches usually replace the true cost estimation with continuous cost approximation formulas extending Beardwood-Halton-Hammersley and Daganzo's work. These formulas commit errors that can be magnified during the optimization step. To reconcile speed and solution quality, we introduce a supervised learning and optimization methodology leveraging a graph neural network for delivery-cost estimation. This network is trained to imitate known costs generated on a limited subset of training districts. It is used within an iterated local search procedure to produce high-quality districting plans. Our computational experiments, conducted on five metropolitan areas in the United Kingdom, demonstrate that the graph neural network predicts long-term district cost operations more accurately, and that optimizing over this oracle permits large economic gains (10.12% on average) over baseline methods that use continuous approximation formulas or shallow neural networks. Finally, we observe that having compact districts alone does not guarantee high-quality solutions and that other learnable geometrical features of the districts play an essential role.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06040v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arthur Ferraz, Cheikh Ahmed, Quentin Cappart, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>A Generalized Version of Chung's Lemma and its Applications</title>
      <link>https://arxiv.org/abs/2406.05637</link>
      <description>arXiv:2406.05637v2 Announce Type: replace 
Abstract: Chung's Lemma is a classical tool for establishing asymptotic convergence rates of (stochastic) optimization methods under strong convexity-type assumptions and appropriate polynomial diminishing step sizes. In this work, we develop a generalized version of Chung's Lemma, which provides a simple non-asymptotic convergence framework for a more general family of step size rules. We demonstrate broad applicability of the proposed generalized lemma by deriving tight non-asymptotic convergence rates for a large variety of stochastic methods. In particular, we obtain partially new non-asymptotic complexity results for stochastic optimization methods, such as Stochastic Gradient Descent (SGD) and Random Reshuffling (RR), under a general $(\theta,\mu)$-Polyak-Lojasiewicz (PL) condition and for various step sizes strategies, including polynomial, constant, exponential, and cosine step sizes rules. Notably, as a by-product of our analysis, we observe that exponential step sizes exhibit superior adaptivity to both landscape geometry and gradient noise; specifically, they achieve optimal convergence rates without requiring exact knowledge of the underlying landscape or separate parameter selection strategies for noisy and noise-free regimes. Our results demonstrate that the developed variant of Chung's Lemma offers a versatile, systematic, and streamlined approach to establish non-asymptotic convergence rates under general step size rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05637v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Li Jiang, Xiao Li, Andre Milzarek, Junwen Qiu</dc:creator>
    </item>
    <item>
      <title>Tracking controllability for finite-dimensional linear systems</title>
      <link>https://arxiv.org/abs/2407.18641</link>
      <description>arXiv:2407.18641v3 Announce Type: replace 
Abstract: We develop a functional-analytic characterization of output tracking controllability for finite-dimensional linear systems. By formulating tracking as the surjectivity of the control-to-output map on suitable trajectory spaces, we show that exact tracking is equivalent to a nonstandard observability inequality for the adjoint dynamics. This characterization enables a Hilbert Uniqueness Method (HUM) type variational construction of minimum-norm tracking controls and makes explicit the intrinsic regularity requirements on reference trajectories induced by the system dynamics and the output operator. The same framework also yields a natural notion of approximate tracking when exact tracking fails. We provide explicit formulas in the scalar case and report numerical experiments for ODEs and semi-discretized PDEs, demonstrating the method for both smooth and non-smooth targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18641v3</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebasti\'an Zamorano, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>On the growth of nonconvex functionals at strict local minimizers</title>
      <link>https://arxiv.org/abs/2409.01833</link>
      <description>arXiv:2409.01833v5 Announce Type: replace 
Abstract: We give new characterizations of growth conditions at strict local minimizers. The main characterizations are a variant of the so-called tilt stability property and an analog of the classical Polyak--\L{}ojasiewicz condition, where the gradient is replaced by linear perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01833v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Dom\'inguez Corella, Tr\'i Minh L\^e</dc:creator>
    </item>
    <item>
      <title>Optimally Controlling a Random Population</title>
      <link>https://arxiv.org/abs/2411.15181</link>
      <description>arXiv:2411.15181v4 Announce Type: replace 
Abstract: The population control problem is a parameterised problem where a controller sends messages to a whole population of identical finite-state agents, aiming to eventually move them all into a target state. The decision problem asks whether this can be achieved for arbitrarily large finite populations. We focus on the randomised version of this problem, where every agent is a copy of the same finite Markov Decision Process and non-determinism in the {global} action chosen by the controller is resolved independently and uniformly at random. Colcombet, Fijalkow and Ohlmann showed that this problem is decidable, but without any complexity upper bound. We show that the random population control problem is in fact EXPTIME-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15181v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Gimbert, Corto Mascle, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>On the Almost Sure Convergence of the Stochastic Three Points Algorithm</title>
      <link>https://arxiv.org/abs/2501.13886</link>
      <description>arXiv:2501.13886v5 Announce Type: replace 
Abstract: The stochastic three points (STP) algorithm is a derivative-free optimization technique designed for unconstrained optimization problems in $\mathbb{R}^d$. In this paper, we analyze this algorithm for three classes of functions: smooth functions that may lack convexity, smooth convex functions, and smooth functions that are strongly convex. Our work provides the first almost sure convergence results of the STP algorithm, alongside some convergence results in expectation. For the class of smooth functions, we establish that the best gradient iterate of the STP algorithm converges almost surely to zero at a rate of $o(1/{T^{\frac{1}{2}-\epsilon}})$ for any $\epsilon\in (0,\frac{1}{2})$, where $T$ is the number of iterations. Furthermore, within the same class of functions, we establish both almost sure convergence and convergence in expectation of the final gradient iterate towards zero. For the class of smooth convex functions, we establish that $f(\theta^T)$ converges to $\inf_{\theta \in \mathbb{R}^d} f(\theta)$ almost surely at a rate of $o(1/{T^{1-\epsilon}})$ for any $\epsilon\in (0,1)$, and in expectation at a rate of $O(\frac{d}{T})$ where $d$ is the dimension of the space. Finally, for the class of smooth functions that are strongly convex, we establish that when step sizes are obtained by approximating the directional derivatives of the function, $f(\theta^T)$ converges to $\inf_{\theta \in \mathbb{R}^d} f(\theta)$ in expectation at a rate of $O((1-\frac{\mu}{2\pi dL})^T)$, and almost surely at a rate of $o((1-s\frac{\mu}{2\pi dL})^T)$ for any $s\in (0,1)$, where $\mu$ and $L$ are the strong convexity and smoothness parameters of the function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13886v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Bakkali El Kadi, Omar Saadi</dc:creator>
    </item>
    <item>
      <title>Mirror Descent Under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2502.00753</link>
      <description>arXiv:2502.00753v3 Announce Type: replace 
Abstract: Smoothness is crucial for attaining fast rates in first-order optimization. However, many optimization problems in modern machine learning involve non-smooth objectives. Recent studies relax the smoothness assumption by allowing the Lipschitz constant of the gradient to grow with respect to the gradient norm, which accommodates a broad range of objectives in practice. Despite this progress, existing generalizations of smoothness are restricted to Euclidean geometry with $\ell_2$-norm and only have theoretical guarantees for optimization in the Euclidean space. In this paper, we address this limitation by introducing a new $\ell*$-smoothness concept that measures the norm of Hessians in terms of a general norm and its dual, and establish convergence for mirror-descent-type algorithms, matching the rates under the classic smoothness. Notably, we propose a generalized self-bounding property that facilitates bounding the gradients via controlling suboptimality gaps, serving as a principal component for convergence analysis. Beyond deterministic optimization, we establish sharp convergence for stochastic mirror descent, matching state-of-the-art under classic smoothness. Our theory also extends to non-convex and composite optimization, which may shed light on practical usages of mirror descent, including pre-training and post-training of LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00753v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dingzhi Yu, Wei Jiang, Hongyi Tao, Yuanyu Wan, Lijun Zhang</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization with Optimal Importance Sampling</title>
      <link>https://arxiv.org/abs/2504.03560</link>
      <description>arXiv:2504.03560v3 Announce Type: replace 
Abstract: Importance Sampling (IS) is a widely used variance reduction technique for enhancing the efficiency of Monte Carlo methods, particularly in rare-event simulation and related applications. Despite its effectiveness, the performance of IS is highly sensitive to the choice of the proposal distribution and often requires stochastic calibration. While the design and analysis of IS have been extensively studied in estimation settings, applying IS within stochastic optimization introduces a lesser-known fundamental challenge: the decision variable and the importance sampling distribution are mutually dependent, creating a circular optimization structure. This interdependence complicates both convergence analysis and variance control. In this paper, we consider the generic setting of convex stochastic optimization with linear constraints. We propose a single-loop stochastic approximation algorithm, based on a variant of Nesterov's dual averaging, that jointly updates the decision variable and the importance sampling distribution, notably without time-scale separation or nested optimization. The method is globally convergent and achieves the minimal asymptotic variance among stochastic gradient schemes, which moreover matches the performance of an oracle sampler adapted to the optimal solution and thus effectively resolves the circular optimization challenge.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03560v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liviu Aolaritei, Bart P. G. Van Parys, Henry Lam, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Conjugate continuous-discrete projection filter via sparse-Grid quadrature</title>
      <link>https://arxiv.org/abs/2504.17324</link>
      <description>arXiv:2504.17324v2 Announce Type: replace 
Abstract: In this article, we study the continuous-discrete projection filter for exponential-family manifolds with conjugate likelihoods. We first derive the local projection error of the prediction step of the continuous-discrete projection filter. We then derive the exact Bayesian update algorithm for a class of discrete measurement processes with additive Gaussian noise. To control the stiffness of the natural parameters' ordinary differential equations, we introduce a regularization method via projection to the Fisher information metric's eigenspace. Lastly, we apply the proposed method to approximate the filtering density of a modified Van der Pol oscillator problem and a coupled stochastic FitzHugh--Nagumo system. The proposed projection filter shows superior performance compared to several state-of-the-art parametric continuous-discrete filtering methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17324v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad F. Emzir, Zaid A. Sawlan, Sami El Ferik</dc:creator>
    </item>
    <item>
      <title>An adaptive data sampling strategy for stabilizing dynamical systems via controller inference</title>
      <link>https://arxiv.org/abs/2506.01816</link>
      <description>arXiv:2506.01816v2 Announce Type: replace 
Abstract: Learning stabilizing controllers from data is an important task in engineering applications; however, collecting informative data is challenging because unstable systems often lead to rapidly growing or erratic trajectories. In this work, we propose an adaptive sampling scheme that generates data while simultaneously stabilizing the system to avoid instabilities during the data collection. Under mild assumptions, the approach provably generates data sets that are informative for stabilization and have minimal size. The numerical experiments demonstrate that controller inference with the novel adaptive sampling approach learns controllers with up to one order of magnitude fewer data samples than unguided data generation. The results show that the proposed approach opens the door to stabilizing systems in edge cases and limit states where instabilities often occur and data collection is inherently difficult.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01816v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steffen W. R. Werner, Benjamin Peherstorfer</dc:creator>
    </item>
    <item>
      <title>The Sweet Spot of Bound Tightening for Topology Optimization</title>
      <link>https://arxiv.org/abs/2507.16496</link>
      <description>arXiv:2507.16496v3 Announce Type: replace 
Abstract: Topology optimization has emerged as a powerful and increasingly relevant strategy for enhancing the flexibility and efficiency of power system operations. However, solving these problems is computationally demanding due to their combinatorial nature and the use of big-M formulations. Optimization-based bound tightening (OBBT) is a well-known strategy to improve the solution of mixed-integer linear programs (MILPs) by computing tighter bounds for continuous variables. Yet, existing OBBT approaches in topology optimization typically relax all switching decisions in the bounding subproblems, leading to excessively loose feasible regions and limited bound improvements. In this work, we propose a topology-aware bound tightening method that uses network structure to determine which switching variables to relax. Through extensive computational experiments on the IEEE 118-bus system, we find that keeping a small subset of switching variables as binary, while relaxing the rest, strikes a sweet spot between the computational effort required to solve the bounding problems and the tightness of the resulting bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16496v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salvador Pineda, Juan Miguel Morales</dc:creator>
    </item>
    <item>
      <title>A Distributionally Robust Optimization Approach to Quick Response Models under Demand Uncertainty</title>
      <link>https://arxiv.org/abs/2508.00541</link>
      <description>arXiv:2508.00541v2 Announce Type: replace 
Abstract: Quick response is a widely adopted strategy to mitigate overproduction in the manufacturing industry, yet recent research reveals a counter-intuitive paradox: while it reduces waste from unsold finished goods, it may incentivize firms to procure more raw materials, potentially increasing total system waste. Additionally, existing models that guide quick response strategies rely on the assumption of a known demand distribution, whereas in practice, demand patterns are often ambiguous and historical data are scarce. To address these challenges, we develop a distributionally robust optimization (DRO) framework for the quick response model that builds robust policies even with limited data. We further integrate a novel waste-to-consumption ratio constraint into this framework, empowering firms to explicitly control the environmental impact of their operations. Our numerical experiments demonstrate that policies optimized for specific demand assumptions suffer severe performance degradation under distributional shifts, whereas our data-driven DRO approach consistently delivers superior robustness. Moreover, we find that the constrained quick response model resolves the central paradox: it can achieve higher profits with verifiably less total waste than a traditional, non-flexible alternative. These results resolve the `quick response or not' debate by showing that the question is not \emph{whether} to use quick response, but \emph{how} to manage it. By incorporating socially responsible metrics as constraints, the quick response system delivers a `win-win' outcome for both profitability and the environment compared to traditional systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00541v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panayotis P. Papavassilopoulos, Grani A. Hanasusanto, Yijie Wang</dc:creator>
    </item>
    <item>
      <title>LLM Serving Optimization with Variable Prefill and Decode Lengths</title>
      <link>https://arxiv.org/abs/2508.06133</link>
      <description>arXiv:2508.06133v3 Announce Type: replace 
Abstract: We study offline scheduling for large language model (LLM) serving under a fixed KV-cache memory budget, where requests have heterogeneous prompt (prefill) and response (decode) lengths. Prompt tokens determine initial KV usage, and each generated token increases memory by one unit. Given a backlog of n requests arriving together, we schedule mixed prefill and decode batches to minimize total end-to-end latency. We show that heterogeneity in prompt lengths makes the problem computationally intractable and that widely used heuristics such as first-come-first-served and shortest-first can be arbitrarily suboptimal. We propose Sorted-F, which repeatedly forms feasible batches using a new selection metric that balances batch size against downstream decode cost, and prove it achieves a constant-factor guarantee on total latency. We further develop practical variants -- an exact solver for small instances and fast heuristics for larger ones -- and evaluate them on a public workload spanning short conversations and long-document summarization, where they consistently reduce average latency relative to standard baselines. Our results highlight that during peak-hour tidal backlogs, greedy GPU packing or short-request prioritization can perform poorly when prompt lengths vary widely, and provide a principled, tunable framework for designing production batch schedulers and planning capacity in memory-constrained LLM serving systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06133v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meixuan Wang, Yinyu Ye, Zijie Zhou</dc:creator>
    </item>
    <item>
      <title>Bilateral facial reduction: qualification-free subdifferential calculus and exact duality</title>
      <link>https://arxiv.org/abs/2510.12244</link>
      <description>arXiv:2510.12244v5 Announce Type: replace 
Abstract: Qualification conditions (also termed constraint qualifications) help avoid pathological behavior at domain boundaries in convex analysis. By generalizing facial reduction from conic programming to general convex programs of the form $f(x) + g(Ax)$, we provide qualification-free generalizations of several key results: an exact Fenchel-Rockafellar dual, KKT optimality conditions, an attained infimal convolution for the conjugate of a sum, subdifferential sum and chain rules, and normal cones of intersections. All our results reduce seamlessly to their original formulations when qualification conditions hold.
  The core insight is that for a sum of two convex functions, there is an affine subspace$\unicode{x2014}$the joint supporting subspace$\unicode{x2014}$that contains the feasible region, and such that qualification conditions hold when restricting the effective domain of each function to it. We offer a number of characterizations for the joint supporting subspace, including one that obtains the affine subspace via iterative, bilateral reduction between the two domains. In our proofs, which are self-contained, we develop a structured induction on faces where inductive steps are associated with normal vectors nested in supporting subspaces (a generalization of supporting hyperplanes). With this tool, we characterize the facial structure of the difference of two convex sets from the facial structures of the individual convex sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12244v5</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew S. Scott</dc:creator>
    </item>
    <item>
      <title>Model-Free Optimization and Control of Rigid Body Dynamics: An Extremum Seeking for Vibrational Stabilization Approach</title>
      <link>https://arxiv.org/abs/2510.22402</link>
      <description>arXiv:2510.22402v5 Announce Type: replace 
Abstract: In this paper, we introduce a model-free, real-time, dynamic optimization and control method for a class of rigid body dynamics. Our method is based on a recent extremum seeking control for vibrational stabilization (ESC-VS) approach that is applicable to a class of second-order mechanical systems. The new ESC-VS method is able to stabilize a rigid body dynamic system about the optimal state of an objective function that can be unknown expression-wise, but assessable through measurements; the ESC-VS is operable by using only one perturbation/vibrational signal. We demonstrate the effectiveness and the applicability of our ESC-VS approach via three rigid-body systems: (1) satellite attitude dynamics, (2) quadcopter attitude dynamics, and (3) acceleration-controlled unicycle dynamics. The results, including simulations with and without measurement delays/noise, illustrate the ability of our ESC-VS to operate successfully as a new methodology of optimization and control for rigid body dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22402v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohan Palanikumar, Ahmed A. Elgohary, Simone Martini, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Stopping Rules for SGD via Anytime-Valid Confidence Sequences</title>
      <link>https://arxiv.org/abs/2512.13123</link>
      <description>arXiv:2512.13123v4 Announce Type: replace 
Abstract: Deciding when to stop stochastic gradient descent (SGD) has long remained unresolved in a statistically rigorous sense. While SGD is routinely monitored as it runs, the classical theory of SGD provides guarantees only at pre-specified iteration horizons and offers no valid way to decide, based on the observed trajectory, when further computation is justified. We address this gap by developing anytime-valid confidence sequences for stochastic gradient methods, which remain valid under continuous monitoring and directly induce statistically valid, trajectory-dependent stopping rules: stop as soon as the current upper confidence bound on an appropriate performance measure falls below a user-specified tolerance. The confidence sequences are constructed using nonnegative supermartingales, are time-uniform, and depend only on observable quantities along the SGD trajectory, without requiring prior knowledge of the optimization horizon. In convex optimization, this yields anytime-valid certificates for weighted suboptimality of projected SGD under general stepsize schedules, without assuming smoothness or strong convexity. In nonconvex optimization, it yields time-uniform certificates for weighted first-order stationarity under smoothness assumptions. We further characterize the stopping-time complexity of the resulting stopping rules under standard stepsize schedules. To the best of our knowledge, this is the first framework that provides statistically valid, time-uniform stopping rules for SGD across both convex and nonconvex settings based solely on its observed trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13123v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liviu Aolaritei, Michael I. Jordan</dc:creator>
    </item>
    <item>
      <title>Branch-Price-and-Cut Accelerated with a Pricing for Integrality Heuristic for the Electrical Vehicle Routing Problem with Time Windows and Charging Time Slots</title>
      <link>https://arxiv.org/abs/2602.08673</link>
      <description>arXiv:2602.08673v2 Announce Type: replace 
Abstract: Branch-price-and-cut is the state-of-the-art exact method for solving many types of vehicle routing problems, and is particularly effective for vehicle routing problems with time windows. A well-known challenge in branch-price-and-cut is that the generation of columns is guided by information from the linear relaxation of the master problem, with no guarantee that they will be useful from an integer perspective. As a consequence, high-quality primal solutions are often found only after significant cutting and branching or the use of primal heuristics. In this work, based on the ideas of pricing for integrality, we propose a new primal heuristic for vehicle routing problems. The heuristic is designed to generate columns that are more likely to be part of high-quality integer solutions. It begins by constructing a partial integer solution from a given column pool and then iteratively searches for columns that complement this solution. The search is done by modifying the pricing problem with respect to the partial solution, linear program dual information as well as previously generated columns in the heuristic. Computational tests are performed on the electrical vehicle routing problem with time windows extended with charging time slots, a problem that has both scheduling and routing aspects, making it well-suited to evaluate the performance of the proposed heuristic. The results show that the proposed heuristic closes 30% - 40% of the root node gap on average in comparison to a restricted master heuristic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08673v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Eveborn, Elina R\"onnberg</dc:creator>
    </item>
    <item>
      <title>Semi-on-Demand Hybrid Transit Route Design with Shared Autonomous Mobility Services</title>
      <link>https://arxiv.org/abs/2403.15804</link>
      <description>arXiv:2403.15804v3 Announce Type: replace-cross 
Abstract: Shared Autonomous Vehicles (SAVs) enable transit agencies to design more agile and responsive services at lower operating costs. This study designs and evaluates a semi-on-demand hybrid route directional service in the public transit network, offering on-demand flexible route service in low-density areas and fixed route service in higher-density areas. We develop analytically tractable cost expressions that capture access, waiting, and riding costs for users, and distance-based operating and time-based vehicle costs for operators. Two formulations are presented for strategic and tactical decisions in flexible route portion, fleet size, headway, and vehicle size optimization, enabling the determination of route types between fixed, hybrid, and flexible routes based on demand, cost, and operational parameters. Analytical results demonstrate that the lower operating costs of SAVs favor more flexible route services. The practical applications and benefits of semi-on-demand feeders are presented with numerical examples and a large-scale case study in the Chicago metropolitan area, USA. Findings reveal scenarios in which flexible route portions serving passengers located further away reduce total costs, particularly user costs, whereas higher demand densities favor more traditional line-based operations. Current cost forecasts suggest smaller vehicles with fully flexible routes are optimal, but operating constraints or higher operating costs would favor larger vehicles with hybrid routes. The study provides an analytical tool to design SAVs as directional services and transit feeders, and tractable continuous approximation formulations for planning and research in transit network design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15804v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Florian Dandl, Hani S. Mahmassani, Klaus Bogenberger</dc:creator>
    </item>
    <item>
      <title>Nonnegativity of signomials with Newton simplex over $\mathcal{A}$-convex sets</title>
      <link>https://arxiv.org/abs/2504.10302</link>
      <description>arXiv:2504.10302v2 Announce Type: replace-cross 
Abstract: We study a class of signomials whose positive support is the set of vertices of a simplex and which may have several negative support points in the simplex. Various groups of authors have provided an exact characterization for the global nonnegativity of a signomial in this class in terms of circuit signomials and that characterization provides a tractable nonnegativity test. We generalize this characterization to the constrained nonnegativity over a set $X$ under an additional convexity precondition in the exponential moment space. This provides a tractable nonnegativity test over $X$ for the class in terms of a power cone program. Our proof methods rely on a variant of the convex cone of constrained SAGE signomials (sums of arithmetic-geometric exponentials) and the duality theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10302v2</guid>
      <category>math.CO</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gennadiy Averkov, Jonas Ellwanger, Thorsten Theobald, Timo de Wolff</dc:creator>
    </item>
    <item>
      <title>Virtual Force-Based Routing of Modular Agents on a Graph</title>
      <link>https://arxiv.org/abs/2505.00928</link>
      <description>arXiv:2505.00928v2 Announce Type: replace-cross 
Abstract: Modular vehicles present a novel area of academic and industrial interest in the field of multi-agent systems. Modularity allows vehicles to connect and disconnect with each other mid-transit which provides a balance between efficiency and flexibility when solving complex and large scale tasks in urban or aerial transportation. This paper details a generalized scheme to route multiple modular agents on a graph to a predetermined set of target nodes. The objective is to visit all target nodes while incurring minimum resource expenditure. Agents that are joined together will incur the equivalent cost of a single agent, which is motivated by the logistical benefits of traffic reduction and increased fuel efficiency. To solve this problem, we introduce a novel algorithm that seeks to balance the optimality of the path that every single module takes and the cost benefit of joining modules. Our approach models the agents and targets as point charges, where the modules take the path of highest attractive force from its target node and neighboring agents. We validate our approach by simulating multiple modular agents along real-world transportation routes in the road network of Champaign-Urbana, Illinois, USA. The proposed method easily exceeds the available benchmarks and illustrates the benefits of modularity in multi-target planning problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00928v2</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Casselman, Manav Vora, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>Input Convex Kolmogorov Arnold Networks</title>
      <link>https://arxiv.org/abs/2505.21208</link>
      <description>arXiv:2505.21208v3 Announce Type: replace-cross 
Abstract: This article presents an input convex neural network architecture using Kolmogorov-Arnold networks (ICKAN). Two specific networks are presented: the first is based on a low-order, linear-by-part, representation of functions, and a universal approximation theorem is provided. The second is based on cubic splines, for which only numerical results support convergence. We demonstrate on simple tests that these networks perform competitively with classical input convex neural networks (ICNNs). In a second part, we use the networks to solve some optimal transport problems needing a convex approximation of functions and demonstrate their effectiveness. Comparisons with ICNNs show that cubic ICKANs produce results similar to those of classical ICNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21208v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Deschatre, Xavier Warin</dc:creator>
    </item>
    <item>
      <title>Sharp High-Probability Rates for Nonlinear SGD under Heavy-Tailed Noise via Symmetrization</title>
      <link>https://arxiv.org/abs/2507.09093</link>
      <description>arXiv:2507.09093v2 Announce Type: replace-cross 
Abstract: We study convergence in high-probability of SGD-type methods in non-convex optimization and the presence of heavy-tailed noise. To combat the heavy-tailed noise, a general black-box nonlinear framework is considered, subsuming nonlinearities like sign, clipping, normalization and their smooth counterparts. Our first result shows that nonlinear SGD (N-SGD) achieves the rate $\widetilde{\mathcal{O}}(t^{-1/2})$, for any noise with unbounded moments and a symmetric probability density function (PDF). Crucially, N-SGD has exponentially decaying tails, matching the performance of linear SGD under light-tailed noise. To handle non-symmetric noise, we propose two novel estimators, based on the idea of noise symmetrization. The first, dubbed Symmetrized Gradient Estimator (SGE), assumes a noiseless gradient at any reference point is available at the start of training, while the second, dubbed Mini-batch SGE (MSGE), uses mini-batches to estimate the noiseless gradient. Combined with the nonlinear framework, we get N-SGE and N-MSGE methods, respectively, both achieving the same convergence rate and exponentially decaying tails as N-SGD, while allowing for non-symmetric noise with unbounded moments and PDF satisfying a mild technical condition, with N-MSGE additionally requiring bounded noise moment of order $p \in (1,2]$. Compared to works assuming noise with bounded $p$-th moment, our results: 1) are based on a novel symmetrization approach; 2) provide a unified framework and relaxed moment conditions; 3) imply optimal oracle complexity of N-SGD and N-SGE, strictly better than existing works when $p &lt; 2$, while the complexity of N-MSGE is close to existing works. Compared to works assuming symmetric noise with unbounded moments, we: 1) provide a sharper analysis and improved rates; 2) facilitate state-dependent symmetric noise; 3) extend the strong guarantees to non-symmetric noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09093v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Dragana Bajovic, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Simultaneous Calibration of Noise Covariance and Kinematics for State Estimation of Legged Robots via Bi-level Optimization</title>
      <link>https://arxiv.org/abs/2510.11539</link>
      <description>arXiv:2510.11539v3 Announce Type: replace-cross 
Abstract: Accurate state estimation is critical for legged and aerial robots operating in dynamic, uncertain environments. A key challenge lies in specifying process and measurement noise covariances, which are typically unknown or manually tuned. In this work, we introduce a bi-level optimization framework that jointly calibrates covariance matrices and kinematic parameters in an estimator-in-the-loop manner. The upper level treats noise covariances and model parameters as optimization variables, while the lower level executes a full-information estimator. Differentiating through the estimator allows direct optimization of trajectory-level objectives, resulting in accurate and consistent state estimates. We validate our approach on quadrupedal and humanoid robots, demonstrating significantly improved estimation accuracy and uncertainty calibration compared to hand-tuned baselines. Our method unifies state estimation, sensor, and kinematics calibration into a principled, data-driven framework applicable across diverse robotic platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11539v3</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denglin Cheng, Jiarong Kang, Xiaobin Xiong</dc:creator>
    </item>
    <item>
      <title>Minimal Regret Walras Equilibria for Combinatorial Markets</title>
      <link>https://arxiv.org/abs/2511.09021</link>
      <description>arXiv:2511.09021v3 Announce Type: replace-cross 
Abstract: We consider combinatorial multi-item markets and propose the notion of a $\Delta$-regret Walras equilibrium, which is an allocation of items to players and a set of item prices that achieve the following goals: prices clear the market, the allocation is capacity-feasible, and the players' strategies lead to a total regret of $\Delta$. The regret is defined as the sum of individual player regrets measured by the utility gap with respect to the optimal item bundle given the prices. We derive a complete characterization for the existence of $\Delta$-regret equilibria by introducing the concept of a parameterized social welfare problem, where the right-hand side of the original social welfare problem is changed. Our characterization then relates the achievable regret value with the associated duality/integrality gap of the parameterized social welfare problem. For the special case of monotone valuations this translates to regret bounds recovering the duality/integrality gap of the original social welfare problem. We further establish an interesting connection to the area of sensitivity theory in linear optimization. We show that the sensitivity gap of the optimal-value function of two (configuration) linear programs with changed right-hand side can be used to establish a bound on the achievable regret. Finally, we use these general structural results to translate known approximation algorithms for the social welfare optimization problem into algorithms computing low-regret Walras equilibria. We also demonstrate how to derive strong lower bounds based on integrality and duality gaps but also based on NP-complexity theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09021v3</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alo\"is Duguet, Tobias Harks, Martin Schmidt, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>A Simple, Optimal and Efficient Algorithm for Online Exp-Concave Optimization</title>
      <link>https://arxiv.org/abs/2512.23190</link>
      <description>arXiv:2512.23190v2 Announce Type: replace-cross 
Abstract: Online eXp-concave Optimization (OXO) is a fundamental problem in online learning, where the goal is to minimize regret when loss functions are exponentially concave. The standard algorithm, Online Newton Step (ONS), guarantees an optimal $O(d \log T)$ regret, where $d$ is the dimension and $T$ is the time horizon. Despite its simplicity, ONS may face a computational bottleneck due to the Mahalanobis projection at each round. This step costs $\Omega(d^\omega)$ arithmetic operations for bounded domains, even for simple domains such as the unit ball, where $\omega \in (2,3]$ is the matrix-multiplication exponent. As a result, the total runtime can reach $\tilde{O}(d^\omega T)$, particularly when iterates frequently oscillate near the domain boundary. This paper proposes a simple variant of ONS, called LightONS, which reduces the total runtime to $O(d^2 T + d^\omega \sqrt{T \log T})$ while preserving the optimal regret. Deploying LightONS with the online-to-batch conversion implies a method for stochastic exp-concave optimization with runtime $\tilde{O}(d^3/\epsilon)$, thereby answering an open problem posed by Koren [2013]. The design leverages domain-conversion techniques from parameter-free online learning and defers expensive Mahalanobis projections until necessary, thereby preserving the elegant structure of ONS and enabling LightONS to act as an efficient plug-in replacement in broader scenarios, including gradient-norm adaptivity, parametric stochastic bandits, and memory-efficient OXO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.23190v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Han Wang, Peng Zhao, Zhi-Hua Zhou</dc:creator>
    </item>
    <item>
      <title>A Primal-Dual Level Set Method for Computing Geodesic Distances</title>
      <link>https://arxiv.org/abs/2601.23244</link>
      <description>arXiv:2601.23244v2 Announce Type: replace-cross 
Abstract: The numerical computation of shortest paths or geodesics on surfaces, along with the associated geodesic distance, has a wide range of applications. Compared to Euclidean distance computation, these tasks are more complex due to the influence of surface geometry on the behavior of shortest paths. This paper introduces a primal-dual level set method for computing geodesic distances. A key insight is that the underlying surface can be implicitly represented as a zero level set, allowing us to formulate a constraint minimization problem. We employ the primal-dual methodology, along with regularization and acceleration techniques, to develop our algorithm. This approach is robust, efficient, and easy to implement. We establish a convergence result for the high-resolution PDE system, and numerical evidence suggests that the method converges to a geodesic in the limit of refinement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23244v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hailiang Liu, Laura Zinnel</dc:creator>
    </item>
    <item>
      <title>Automatic regularization parameter choice for tomography using a double model approach</title>
      <link>https://arxiv.org/abs/2602.08528</link>
      <description>arXiv:2602.08528v2 Announce Type: replace-cross 
Abstract: Image reconstruction in X-ray tomography is an ill-posed inverse problem, particularly with limited available data. Regularization is thus essential, but its effectiveness hinges on the choice of a regularization parameter that balances data fidelity against a priori information. We present a novel method for automatic parameter selection based on the use of two distinct computational discretizations of the same problem. A feedback control algorithm dynamically adjusts the regularization strength, driving an iterative reconstruction toward the smallest parameter that yields sufficient similarity between reconstructions on the two grids. The effectiveness of the proposed approach is demonstrated using real tomographic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08528v2</guid>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Wed, 11 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuyang Wu, Samuli Siltanen</dc:creator>
    </item>
  </channel>
</rss>
