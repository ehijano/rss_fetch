<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 May 2025 04:01:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Fully Data-Driven Value Iteration for Stochastic LQR: Convergence, Robustness and Stability</title>
      <link>https://arxiv.org/abs/2505.02970</link>
      <description>arXiv:2505.02970v1 Announce Type: new 
Abstract: Unlike traditional model-based reinforcement learning approaches that extract the underlying system structure by estimating parameters from data, non-model-based data-driven control learns the optimal policy directly from input-state data without any intermediate model identification. Although this direct reinforcement learning approach offers increased adaptability and resilience to model misspecification, its reliance on raw data leaves it vulnerable to system noise and disturbances that may undermine convergence, robustness, and stability. In this article, we establish the convergence, robustness, and stability of value iteration (VI) for data-driven control of stochastic linear quadratic (LQ) systems in discrete-time with entirely unknown dynamics and cost. Our contributions are three-fold. First, we prove that VI is globally exponentially stable for any positive semidefinite initial value matrix in noise-free settings, thereby significantly relaxing restrictive assumptions on initial value functions in existing literature. Second, we extend our analysis to scenarios with external disturbances, proving that VI maintains small-disturbance input-to-state stability (ISS) and converges within a small neighborhood of the optimal solution when disturbances are sufficiently small. Third, we propose a new non-model-based robust adaptive dynamic programming (ADP) algorithm for adaptive optimal controller design, which, unlike existing procedures, requires no prior knowledge of an initial admissible control policy. Numerical experiments on a ``data center cooling'' problem demonstrate the convergence and stability of the algorithm compared to established methods, highlighting its robustness and adaptability for data-driven control in noisy environments. Finally, we present a fully data-driven solution to dynamic portfolio allocation, an important problem in quantitative finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02970v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Leilei Cui, Zhong-Ping Jiang, Petter N. Kolm, Gr\'egoire G. Macqueron</dc:creator>
    </item>
    <item>
      <title>Convergence of First-Order Algorithms with Momentum from the Perspective of an Inexact Gradient Descent Method</title>
      <link>https://arxiv.org/abs/2505.03050</link>
      <description>arXiv:2505.03050v1 Announce Type: new 
Abstract: This paper introduces a novel inexact gradient descent method with momentum (IGDm) considered as a general framework for various first-order methods with momentum. This includes, in particular, the inexact proximal point method (IPPm), extragradient method (EGm), and sharpness-aware minimization (SAMm). Asymptotic convergence properies of IGDm are established under both global and local assumptions on objective functions with providing constructive convergence rates depending on the Polyak-\L ojasiewicz-Kurdyka (PLK) conditions for the objective function. Global convergence of EGm and SAMm for general smooth functions and of IPPM for weakly convex functions is derived in this way. Moreover, local convergence properties of EGm and SAMm for locally smooth functions as well as of IPPm for prox-regular functions are established. Numerical experiments for derivative-free optimization problems are conducted to confirm the efficiency of the momentum effects of the developed methods under inexactness of gradient computations</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03050v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Pham Duy Khanh, Boris Mordukhovich, Dat Ba Tran</dc:creator>
    </item>
    <item>
      <title>A Stochastic Gradient Descent Method with Global Convergence for Minimizing Nearly Convex Functions</title>
      <link>https://arxiv.org/abs/2505.03222</link>
      <description>arXiv:2505.03222v1 Announce Type: new 
Abstract: This paper proposes a stochastic gradient descent method with an adaptive Gaussian noise term for minimizing nonconvex differentiable functions. The noise term in the algorithm, independent of the gradient, is determined by the difference between the function value at the current step and a lower bound estimate of the optimal value. In both probability space and state space, our theoretical analysis shows that for a class of nonconvex functions, represented by nearly convex functions, the proposed algorithm converges linearly to a certain neighborhood of the global optimal solution whose diameter depends on the variance of the gradient and the deviation between the estimated lower bound and the optimal value. Specifically, when full gradient information is utilized and the sharp lower bound of the objective function is available, the algorithm converges linearly to the global optimal solution. Furthermore, we propose a double-loop method that alternatively updates the lower bound estimate of the optimal value and the sequence, achieving the convergence to a neighborhood of the global optimal solution depending only on the variance of the gradient, provided that the lower bound estimate is asymptotically accurate. Numerical experiments on several concrete problems demonstrate the effectiveness of the proposed algorithm and validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03222v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Liang Chen, Weizhi Shao</dc:creator>
    </item>
    <item>
      <title>Optimal Abort Policy for Mission-Critical Systems under Imperfect Condition Monitoring</title>
      <link>https://arxiv.org/abs/2505.03225</link>
      <description>arXiv:2505.03225v1 Announce Type: new 
Abstract: While most on-demand mission-critical systems are engineered to be reliable to support critical tasks, occasional failures may still occur during missions. To increase system survivability, a common practice is to abort the mission before an imminent failure. We consider optimal mission abort for a system whose deterioration follows a general three-state (normal, defective, failed) semi-Markov chain. The failure is assumed self-revealed, while the healthy and defective states have to be {inferred} from imperfect condition monitoring data. Due to the non-Markovian process dynamics, optimal mission abort for this partially observable system is an intractable stopping problem. For a tractable solution, we introduce a novel tool of Erlang mixtures to approximate non-exponential sojourn times in the semi-Markov chain. This allows us to approximate the original process by a surrogate continuous-time Markov chain whose optimal control policy can be solved through a partially observable Markov decision process (POMDP). We show that the POMDP optimal policies converge almost surely to the optimal abort decision rules when the Erlang rate parameter diverges. This implies that the expected cost by adopting the POMDP solution converges to the optimal expected cost. Next, we provide comprehensive structural results on the optimal policy of the surrogate POMDP. Based on the results, we develop a modified point-based value iteration algorithm to numerically solve the surrogate POMDP. We further consider mission abort in a multi-task setting where a system executes several tasks consecutively before a thorough inspection. Through a case study on an unmanned aerial vehicle, we demonstrate the capability of real-time implementation of our model, even when the condition-monitoring signals are generated with high frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03225v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiuzhuang Sun, Jiawen Hu, Zhi-Sheng Ye</dc:creator>
    </item>
    <item>
      <title>A novel implementation of Yau-Yau filter for time-variant nonlinear problems</title>
      <link>https://arxiv.org/abs/2505.03240</link>
      <description>arXiv:2505.03240v1 Announce Type: new 
Abstract: Nonlinear filter has long been an important problem in practical industrial applications. The Yau-Yau method is a highly versatile framework that transforms nonlinear filtering problems into initial-value problems governed by the Forward Kolmogorov Equation (FKE). Previous researches have shown that the method can be applied to highly nonlinear and high dimensional problems. However, when time-varying coefficients are involved in the system models, developing an implementation of the method with high computational speed and low data storage still presents a challenge. To address these limitations, this paper proposes a novel numerical algorithm that incorporates physics-informed neural network (PINN) and principal component analysis (PCA) to solve the FKE approximately. Equipped with this algorithm, the Yau-Yau filter can be implemented by an offline stage for the training of a solver for the approximate solution of FKE and an online stage for its execution. Results of three examples indicate that this implementation is accurate, both time-efficient and storage-efficient for online computation, and is superior than existing nonlinear filtering methods such as extended Kalman filter and particle filter. It is capable of applications to practical nonlinear time-variant filtering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03240v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuzhong Hu, Jiayi Kang, Lei Ma, Xiaoming Zhang</dc:creator>
    </item>
    <item>
      <title>Fast Large Deformation Matching with the Energy Distance Kernel</title>
      <link>https://arxiv.org/abs/2505.03342</link>
      <description>arXiv:2505.03342v1 Announce Type: new 
Abstract: We propose an efficient framework for point cloud and measure registration using bi-Lipschitz homeomorphisms, achieving O(n log n) complexity, where n is the number of points. By leveraging the Energy-Distance (ED) kernel, which can be approximated by its sliced one-dimensional projections, each computable in O(n log n), our method avoids hyperparameter tuning and enables efficient large-scale optimization. The main issue to be solved is the lack of regularity of the ED kernel. To this goal, we introduce two models that regularize the deformations and retain a low computational footprint. The first model relies on TV regularization, while the second model avoids the non-smooth TV regularization at the cost of restricting its use to the space of measures, or cloud of points. Last, we demonstrate the numerical robustness and scalability of our models on synthetic and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03342v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siwan Boufadene (LIGM, MOKAPLAN), Fran\c{c}ois-Xavier Vialard (LIGM), Jean Feydy (HeKA)</dc:creator>
    </item>
    <item>
      <title>Data-Enabled Predictive Control for Nonlinear Systems Based on a Koopman Bilinear Realization</title>
      <link>https://arxiv.org/abs/2505.03346</link>
      <description>arXiv:2505.03346v1 Announce Type: new 
Abstract: This paper extends the Willems' Fundamental Lemma to nonlinear control-affine systems using the Koopman bilinear realization. This enables us to bypass the Extended Dynamic Mode Decomposition (EDMD)-based system identification step in conventional Koopman-based methods and design controllers for nonlinear systems directly from data. Leveraging this result, we develop a Data-Enabled Predictive Control (DeePC) framework for nonlinear systems with unknown dynamics. A case study demonstrates that our direct data-driven control method achieves improved optimality compared to conventional Koopman-based methods. Furthermore, in examples where an exact Koopman realization with a finite-dimensional lifting function set of the controlled nonlinear system does not exist, our method exhibits advanced robustness to finite Koopman approximation errors compared to existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03346v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zuxun Xiong, Zhenyi Yuan, Keyan Miao, Han Wang, Jorge Cortes, Antonis Papachristodoulou</dc:creator>
    </item>
    <item>
      <title>$L^p$- Partially null controllability of abstract fractional differential inclusion with nonlocal condition</title>
      <link>https://arxiv.org/abs/2505.03476</link>
      <description>arXiv:2505.03476v1 Announce Type: new 
Abstract: In this work, we investigate the $L^p$- partial null controllability of the abstract semilinear fractional-order differential inclusion with nonlocal conditions. The set of admissible controls is characterized by $u\in L^p(I,U)$, $1&lt;p&lt;\infty$, $I=[0,\nu]$, where $U$ is a uniformly convex Banach space. Assuming partial null controllability for the fractional-order linear system with a source term, we employ an approximate solvability method to simplify the problem to reduce it to finite-dimensional subspaces. Consequently, the solutions of the original problem are obtained as limiting functions within these subspaces. The paper tackles a challenge stemming from the assumption that $U$ is a uniformly convex Banach space, which introduces convexity issues in constructing the required control. These complications do not occur if $U$ is a separable Hilbert space. This study introduces a novel approach by resolving the convexity issue, thereby enabling $L^p(I, U)$ partially null controllability of the semilinear fractional-order differential control system, with $U$ being a uniformly convex Banach space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03476v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bholanath Kumbhakar,  Deeksha, Dwijendra Narain Pandey</dc:creator>
    </item>
    <item>
      <title>A New Complexity Result for Strongly Convex Optimization with Locally $\alpha$-H{\"o}lder Continuous Gradients</title>
      <link>https://arxiv.org/abs/2505.03506</link>
      <description>arXiv:2505.03506v1 Announce Type: new 
Abstract: In this paper, we present a new complexity result for the gradient descent method with an appropriately fixed stepsize for minimizing a strongly convex function with locally $\alpha$-H{\"o}lder continuous gradients ($0 &lt; \alpha \leq 1$). The complexity bound for finding an approximate minimizer with a distance to the true minimizer less than $\varepsilon$ is $O(\log (\varepsilon^{-1}) \varepsilon^{2 \alpha - 2})$, which extends the well-known complexity result for $\alpha = 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03506v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaojun Chen, C. T. Kelley, Lei Wang</dc:creator>
    </item>
    <item>
      <title>A note on the uniformity of strong subregularity around the reference point</title>
      <link>https://arxiv.org/abs/2505.03605</link>
      <description>arXiv:2505.03605v1 Announce Type: new 
Abstract: This paper investigates strong metric subregularity around a reference point as introduced by H. Gfrerer and J. V. Outrata. In the setting of Banach spaces, we analyse its stability under Lipschitz continuous perturbations and establish its uniformity over compact sets. Our results ensure that the property is preserved under small Lipschitz perturbations, which is crucial for maintaining robustness in variational analysis. Furthermore, we apply the developed theory to parametric inclusion problems. The analysis demonstrates that the uniformity of strong metric subregularity provides a theoretical foundation for addressing stability issues in parametrized optimization and control applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03605v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom\'a\v{s} Roubal</dc:creator>
    </item>
    <item>
      <title>A self-adaptive subgradient extragradient method with conjugate gradient-type direction for pseudomonotone variational inequalities</title>
      <link>https://arxiv.org/abs/2505.03614</link>
      <description>arXiv:2505.03614v1 Announce Type: new 
Abstract: This paper introduces a subgradient extragradient algorithm with a conjugate gradient-type direction to solve pseudomonotone variational inequality problems in Hilbert spaces. The algorithm features a self-adaptive strategy that eliminates the need for prior knowledge of the Lipschitz constant and incorporate a conjugate gradient-type direction to enhance convergence speed. We establish a result describing the behavior generated therefrom toward the solution set. Using this result, we prove the strong convergence of the proposed method and provide numerical experiments to demonstrate its computational efficacy and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03614v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim Arzuka, Parin Chaipunya, Poom Kumam</dc:creator>
    </item>
    <item>
      <title>Meta-Learning the Optimal Mixture of Strategies for Online Portfolio Selection</title>
      <link>https://arxiv.org/abs/2505.03659</link>
      <description>arXiv:2505.03659v1 Announce Type: new 
Abstract: This paper presents an innovative online portfolio selection model, situated within a meta-learning framework, that leverages a mixture policies strategy. The core idea is to simulate a fund that employs multiple fund managers, each skilled in handling different market environments, and dynamically allocate our funding to these fund managers for investment. To address the non-stationary nature of financial markets, we divide the long-term process into multiple short-term processes to adapt to changing environments. We use a clustering method to identify a set of historically high-performing policies, characterized by low similarity, as candidate policies. Additionally, we employ a meta-learning method to search for initial parameters that can quickly adapt to upcoming target investment tasks, effectively providing a set of well-suited initial strategies. Subsequently, we update the initial parameters using the target tasks and determine the optimal mixture weights for these candidate policies. Empirical tests show that our algorithm excels in terms of training time and data requirements, making it particularly suitable for high-frequency algorithmic trading. To validate the effectiveness of our method, we conduct numerical tests on cross-training datasets, demonstrating its excellent transferability and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03659v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiayu Shen, Jia Liu, Zhiping Chen</dc:creator>
    </item>
    <item>
      <title>Logarithmic Convexity and impulse Approximate Controllability for Degenerate Parabolic Equations with Robin Boundary Conditions</title>
      <link>https://arxiv.org/abs/2505.03663</link>
      <description>arXiv:2505.03663v1 Announce Type: new 
Abstract: In this work, we investigate the approximate controllability of a class of one-dimensional degenerate parabolic equations with Robin boundary conditions. The degeneracy occurs at one endpoint of the spatial domain, and we apply an impulsive control in a small region at a fixed moment. Our main result establishes an observability inequality for the adjoint system, from which we deduce approximate controllability at final time . The proof relies on a logarithmic convexity argument, developed through a Carleman commutator approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03663v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hind El Baggari, Ilham Ouelddris</dc:creator>
    </item>
    <item>
      <title>Policy Gradient Adaptive Control for the LQR: Indirect and Direct Approaches</title>
      <link>https://arxiv.org/abs/2505.03706</link>
      <description>arXiv:2505.03706v1 Announce Type: new 
Abstract: Motivated by recent advances of reinforcement learning and direct data-driven control, we propose policy gradient adaptive control (PGAC) for the linear quadratic regulator (LQR), which uses online closed-loop data to improve the control policy while maintaining stability. Our method adaptively updates the policy in feedback by descending the gradient of the LQR cost and is categorized as indirect, when gradients are computed via an estimated model, versus direct, when gradients are derived from data using sample covariance parameterization. Beyond the vanilla gradient, we also showcase the merits of the natural gradient and Gauss-Newton methods for the policy update. Notably, natural gradient descent bridges the indirect and direct PGAC, and the Gauss-Newton method of the indirect PGAC leads to an adaptive version of the celebrated Hewer's algorithm. To account for the uncertainty from noise, we propose a regularization method for both indirect and direct PGAC. For all the considered PGAC approaches, we show closed-loop stability and convergence of the policy to the optimal LQR gain. Simulations validate our theoretical findings and demonstrate the robustness and computational efficiency of PGAC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03706v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feiran Zhao, Alessandro Chiuso, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Nonnegative Low-rank Matrix Recovery Can Have Spurious Local Minima</title>
      <link>https://arxiv.org/abs/2505.03717</link>
      <description>arXiv:2505.03717v1 Announce Type: new 
Abstract: The classical low-rank matrix recovery problem is well-known to exhibit \emph{benign nonconvexity} under the restricted isometry property (RIP): local optimization is guaranteed to converge to the global optimum, where the ground truth is recovered. We investigate whether benign nonconvexity continues to hold when the factor matrices are constrained to be elementwise nonnegative -- a common practical requirement. In the simple setting of a rank-1 nonnegative ground truth, we confirm that benign nonconvexity holds in the fully-observed case with RIP constant $\delta=0$. Surprisingly, however, this property fails to extend to the partially-observed case with any arbitrarily small RIP constant $\delta\to0^{+}$, irrespective of rank overparameterization. This finding exposes a critical theoretical gap: the continuity argument widely used to explain the empirical robustness of low-rank matrix recovery fundamentally breaks down once nonnegative constraints are imposed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03717v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>Accelerated Decentralized Constraint-Coupled Optimization: A Dual$^2$ Approach</title>
      <link>https://arxiv.org/abs/2505.03719</link>
      <description>arXiv:2505.03719v1 Announce Type: new 
Abstract: In this paper, we focus on a class of decentralized constraint-coupled optimization problem: $\min_{x_i \in \mathbb{R}^{d_i}, i \in \mathcal{I}; y \in \mathbb{R}^p}$ $\sum_{i=1}^n\left(f_i(x_i) + g_i(x_i)\right) + h(y) \ \text{s.t.} \ \sum_{i=1}^{n}A_ix_i = y$, over an undirected and connected network of $n$ agents. Here, $f_i$, $g_i$, and $A_i$ represent private information of agent $i \in \mathcal{I} = \{1, \cdots, n\}$, while $h$ is public for all agents. Building on a novel dual$^2$ approach, we develop two accelerated algorithms for solving this problem: the inexact Dual$^2$ Accelerated (iD2A) gradient method and the Multi-consensus inexact Dual$^2$ Accelerated (MiD2A) gradient method. We demonstrate that both iD2A and MiD2A can guarantee asymptotic convergence under a milder condition on $h$ compared to existing algorithms. Furthermore, linear convergence is established under additional assumptions. By employing specialized saddle-point subproblem solvers, iD2A and MiD2A attain significantly lower communication and computational complexities than existing algorithms across various scenarios. Finally, we conduct several numerical experiments to validate our theoretical results and to showcase the superior performance of iD2A and MiD2A in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03719v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwang Li, Vincent Lau</dc:creator>
    </item>
    <item>
      <title>Decentralized Nonconvex Optimization under Heavy-Tailed Noise: Normalization and Optimal Convergence</title>
      <link>https://arxiv.org/abs/2505.03736</link>
      <description>arXiv:2505.03736v1 Announce Type: new 
Abstract: Heavy-tailed noise in nonconvex stochastic optimization has garnered increasing research interest, as empirical studies, including those on training attention models, suggest it is a more realistic gradient noise condition. This paper studies first-order nonconvex stochastic optimization under heavy-tailed gradient noise in a decentralized setup, where each node can only communicate with its direct neighbors in a predefined graph. Specifically, we consider a class of heavy-tailed gradient noise that is zero-mean and has only $p$-th moment for $p \in (1, 2]$. We propose GT-NSGDm, Gradient Tracking based Normalized Stochastic Gradient Descent with momentum, that utilizes normalization, in conjunction with gradient tracking and momentum, to cope with heavy-tailed noise on distributed nodes. We show that, when the communication graph admits primitive and doubly stochastic weights, GT-NSGDm guarantees, for the \textit{first} time in the literature, that the expected gradient norm converges at an optimal non-asymptotic rate $O\big(1/T^{(p-1)/(3p-2)}\big)$, which matches the lower bound in the centralized setup. When tail index $p$ is unknown, GT-NSGDm attains a non-asymptotic rate $O\big( 1/T^{(p-1)/(2p)} \big)$ that is, for $p &lt; 2$, topology independent and has a speedup factor $n^{1-1/p}$ in terms of the number of nodes $n$. Finally, experiments on nonconvex linear regression with tokenized synthetic data and decentralized training of language models on a real-world corpus demonstrate that GT-NSGDm is more robust and efficient than baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03736v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuhua Yu, Dusan Jakovetic, Soummya Kar</dc:creator>
    </item>
    <item>
      <title>Learning Stabilizing Policies via an Unstable Subspace Representation</title>
      <link>https://arxiv.org/abs/2505.01348</link>
      <description>arXiv:2505.01348v1 Announce Type: cross 
Abstract: We study the problem of learning to stabilize (LTS) a linear time-invariant (LTI) system. Policy gradient (PG) methods for control assume access to an initial stabilizing policy. However, designing such a policy for an unknown system is one of the most fundamental problems in control, and it may be as hard as learning the optimal policy itself. Existing work on the LTS problem requires large data as it scales quadratically with the ambient dimension. We propose a two-phase approach that first learns the left unstable subspace of the system and then solves a series of discounted linear quadratic regulator (LQR) problems on the learned unstable subspace, targeting to stabilize only the system's unstable dynamics and reduce the effective dimension of the control space. We provide non-asymptotic guarantees for both phases and demonstrate that operating on the unstable subspace reduces sample complexity. In particular, when the number of unstable modes is much smaller than the state dimension, our analysis reveals that LTS on the unstable subspace substantially speeds up the stabilization process. Numerical experiments are provided to support this sample complexity reduction achieved by our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01348v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo F. Toso, Lintao Ye, James Anderson</dc:creator>
    </item>
    <item>
      <title>More Optimal Fractional-Order Stochastic Gradient Descent for Non-Convex Optimization Problems</title>
      <link>https://arxiv.org/abs/2505.02985</link>
      <description>arXiv:2505.02985v1 Announce Type: cross 
Abstract: Fractional-order stochastic gradient descent (FOSGD) leverages fractional exponents to capture long-memory effects in optimization. However, its utility is often limited by the difficulty of tuning and stabilizing these exponents. We propose 2SED Fractional-Order Stochastic Gradient Descent (2SEDFOSGD), which integrates the Two-Scale Effective Dimension (2SED) algorithm with FOSGD to adapt the fractional exponent in a data-driven manner. By tracking model sensitivity and effective dimensionality, 2SEDFOSGD dynamically modulates the exponent to mitigate oscillations and hasten convergence. Theoretically, for onoconvex optimization problems, this approach preserves the advantages of fractional memory without the sluggish or unstable behavior observed in na\"ive fractional SGD. Empirical evaluations in Gaussian and $\alpha$-stable noise scenarios using an autoregressive (AR) model highlight faster convergence and more robust parameter estimates compared to baseline methods, underscoring the potential of dimension-aware fractional techniques for advanced modeling and estimation tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02985v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Partohaghighi, Roummel Marcia, YangQuan Chen</dc:creator>
    </item>
    <item>
      <title>Numerical study of a Transmission Problem in Elasticity with kind damping</title>
      <link>https://arxiv.org/abs/2505.03043</link>
      <description>arXiv:2505.03043v1 Announce Type: cross 
Abstract: We investigate a transmission problem featuring a specific type of damping. Our primary focus is on analyzing the asymptotic behavior of the associated semigroup, $({\mathcal S}_{\mathcal A}(t))_{t\geq 0}$. We demonstrate that this semigroup exhibits a polynomial rate of decay towards zero when the initial data is taken over the domain ${\mathcal D}({\mathcal A})$. Furthermore, we establish that this decay rate is optimal. To support our theoretical findings, we present a comprehensive numerical study that validates and illustrates the sharpness of the obtained decay rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03043v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Kais Ammari, Vilmos Komornik, Mauricio Sep\'ulveda, Octavio Vera</dc:creator>
    </item>
    <item>
      <title>$\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems by multivariate rational interpolation</title>
      <link>https://arxiv.org/abs/2505.03057</link>
      <description>arXiv:2505.03057v1 Announce Type: cross 
Abstract: This paper addresses the $\mathcal{H}_2$-optimal approximation of linear dynamical systems with quadratic-output functions, also known as linear quadratic-output systems. Our major contributions are threefold. First, we derive interpolation-based first-order optimality conditions for the linear quadratic-output $\mathcal{H}_2$ minimization problem. These conditions correspond to the mixed-multipoint tangential interpolation of the full-order linear- and quadratic-output transfer functions, and generalize the Meier-Luenberger optimality framework for the $\mathcal{H}_2$-optimal model reduction of linear time-invariant systems. Second, given the interpolation data, we show how to enforce these mixed-multipoint tangential interpolation conditions explicitly by Petrov-Galerkin projection of the full-order model matrices. Third, to find the optimal interpolation data, we build on this projection framework and propose a generalization of the iterative rational Krylov algorithm for the $\mathcal{H}_2$-optimal model reduction of linear quadratic-output systems, called LQO-IRKA. Upon convergence, LQO-IRKA produces a reduced linear quadratic-output system that satisfies the interpolatory optimality conditions. The method only requires solving shifted linear systems and matrix-vector products, thus making it suitable for large-scale problems. Numerical examples are included to illustrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03057v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean Reiter, Ion Victor Gosea, Igor Pontes Duff, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Variable projection framework for the reduced-rank matrix approximation problem by weighted least-squares</title>
      <link>https://arxiv.org/abs/2505.03347</link>
      <description>arXiv:2505.03347v1 Announce Type: cross 
Abstract: In this monograph, we review and develop variable projection Gauss-Newton, Levenberg-Marquardt and Newton methods for the Weighted Low-Rank Approximation (WLRA) problem, which has now an increasing number of applications in many scientific fields. Particular attention is drawn at the robustness, efficiency and scalability of these variable projection second-order algorithms such that they can be used also on larger datasets now commonly found in many practical problems for which only first-order algorithms based on sequential repetitions of local optimization (e.g., majorization, Expectation-Maximization or alternating least-squares methods) or variations of gradient descent (e.g., conjugate, proximal or stochastic gradient descent methods), or hybrid algorithms from these two classes of methods, were only feasible due to their lower cost and memory requirement per iteration. In parallel with this review of variable projection algorithms, we develop new formulae for the Jacobian and Hessian matrices involved in these variable projection methods and demonstrate their very specific properties such as the uniform rank deficiency of the Jacobian matrix or the rank deficiency of the Hessian matrix at the (local) minimizers of the cost function associated with the WLRA problem. These systematic deficiencies must be taken into account in any practical implementations of the algorithms. These different properties and the very particular geometry of the WLRA problem have not been well appreciated in the past and have been the main obstacles in the development of robust variable projection second-order algorithms for solving the WLRA problem. In addition, we demonstrate that the variable projection framework gives original insights on the solvability, the landscape and the non-smoothness of the WLRA problem. It also helps to describe the tight links between previously unrelated methods, which have been proposed to solve it. Specifically, we illustrate the closed links between the variable projection framework and Riemannian optimization on the Grassmann manifold for the WLRA problem. We expect that software's developers and practitioners in different fields such as computer vision, signal processing, recommender systems, machine learning, multivariate statistics and geophysical sciences will benefit from the results in this monograph in order to devise more robust and accurate algorithms to solve the WLRA problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03347v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pascal Terray (LOCEAN, IRD)</dc:creator>
    </item>
    <item>
      <title>SPAP: Structured Pruning via Alternating Optimization and Penalty Methods</title>
      <link>https://arxiv.org/abs/2505.03373</link>
      <description>arXiv:2505.03373v1 Announce Type: cross 
Abstract: The deployment of large language models (LLMs) is often constrained by their substantial computational and memory demands. While structured pruning presents a viable approach by eliminating entire network components, existing methods suffer from performance degradation, reliance on heuristic metrics, or expensive finetuning. To address these challenges, we propose SPAP (Structured Pruning via Alternating Optimization and Penalty Methods), a novel and efficient structured pruning framework for LLMs grounded in optimization theory. SPAP formulates the pruning problem through a mixed-integer optimization model, employs a penalty method that effectively makes pruning decisions to minimize pruning errors, and introduces an alternating minimization algorithm tailored to the splittable problem structure for efficient weight updates and performance recovery. Extensive experiments on OPT, LLaMA-3/3.1/3.2, and Qwen2.5 models demonstrate SPAP's superiority over state-of-the-art methods, delivering linear inference speedups (1.29$\times$ at 30% sparsity) and proportional memory reductions. Our work offers a practical, optimization-driven solution for pruning LLMs while preserving model performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03373v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyu Hu, Xiaoming Yuan</dc:creator>
    </item>
    <item>
      <title>Wasserstein Convergence of Score-based Generative Models under Semiconvexity and Discontinuous Gradients</title>
      <link>https://arxiv.org/abs/2505.03432</link>
      <description>arXiv:2505.03432v1 Announce Type: cross 
Abstract: Score-based Generative Models (SGMs) approximate a data distribution by perturbing it with Gaussian noise and subsequently denoising it via a learned reverse diffusion process. These models excel at modeling complex data distributions and generating diverse samples, achieving state-of-the-art performance across domains such as computer vision, audio generation, reinforcement learning, and computational biology. Despite their empirical success, existing Wasserstein-2 convergence analysis typically assume strong regularity conditions-such as smoothness or strict log-concavity of the data distribution-that are rarely satisfied in practice. In this work, we establish the first non-asymptotic Wasserstein-2 convergence guarantees for SGMs targeting semiconvex distributions with potentially discontinuous gradients. Our upper bounds are explicit and sharp in key parameters, achieving optimal dependence of $O(\sqrt{d})$ on the data dimension $d$ and convergence rate of order one. The framework accommodates a wide class of practically relevant distributions, including symmetric modified half-normal distributions, Gaussian mixtures, double-well potentials, and elastic net potentials. By leveraging semiconvexity without requiring smoothness assumptions on the potential such as differentiability, our results substantially broaden the theoretical foundations of SGMs, bridging the gap between empirical success and rigorous guarantees in non-smooth, complex data regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03432v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Bruno, Sotirios Sabanis</dc:creator>
    </item>
    <item>
      <title>Multi-Class Stackelberg Games for the Co-Design of Networked Systems</title>
      <link>https://arxiv.org/abs/2505.03468</link>
      <description>arXiv:2505.03468v1 Announce Type: cross 
Abstract: We investigate a co-design problem, encompassing simultaneous design of system infrastructure and control, through a game-theoretical framework. To this end, we propose the co-design problem as a two-layer hierarchical strategic interaction. At the upper layer, a leader (or multiple leaders) determines system design parameters, while at the lower layer, a follower (or multiple followers) optimizes the control strategy. To capture this hierarchy, we propose four novel classes of Stackelberg games that integrate diverse strategic behaviors, including combinations of cooperative and non-cooperative interactions across two different layers. Notably, the leaders' interactions are represented using a normal-form game, whereas the followers' interactions are modeled by different games (dynamic games in discrete time). These distinct game structures result in a Stackelberg game that accommodates different game types per layer, and/or supports heterogeneous strategic behaviors involving cooperation and non-cooperation simultaneously. Learning algorithms using the best-response dynamics are used to solve the game problems when considering a discrete strategic space for the leaders. The efficacy of the proposed approach is demonstrated through an application to the co-design of the Barcelona drinking water network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03468v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Julian Barreiro-Gomez, Ye Wang</dc:creator>
    </item>
    <item>
      <title>Learning-based Homothetic Tube MPC</title>
      <link>https://arxiv.org/abs/2505.03482</link>
      <description>arXiv:2505.03482v1 Announce Type: cross 
Abstract: In this paper, we study homothetic tube model predictive control (MPC) of discrete-time linear systems subject to bounded additive disturbance and mixed constraints on the state and input. Different from most existing work on robust MPC, we assume that the true disturbance set is unknown but a conservative surrogate is available a priori. Leveraging the real-time data, we develop an online learning algorithm to approximate the true disturbance set. This approximation and the corresponding constraints in the MPC optimisation are updated online using computationally convenient linear programs. We provide statistical gaps between the true and learned disturbance sets, based on which, probabilistic recursive feasibility of homothetic tube MPC problems is discussed. Numerical simulations are provided to demonstrate the efficacy of our proposed algorithm and compare with state-of-the-art MPC algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03482v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulong Gao, Shuhao Yan, Jian Zhou, Mark Cannon</dc:creator>
    </item>
    <item>
      <title>Heavy traffic limit of stationary distribution of the multi-level single server queue</title>
      <link>https://arxiv.org/abs/2505.03504</link>
      <description>arXiv:2505.03504v1 Announce Type: cross 
Abstract: Atar and Miyazawa recently introduced a single server queue with queue length dependent arrival and service processes, and name it a multi-level queue. They prove that the heavy traffic limit of its queue length process weakly converges to a reflected diffusion with discontinuously state-dependent drift and deviations.
  We derive the heavy traffic limit of the stationary queue length distribution of this multi-level queue in a closed form, which agrees with the stationary distribution of the reflected diffusion obtained by Miyazawa (2024, Journal of the Indian Society for Probability and Statistics). Thus, those results show the limit interchange of process and stationary distribution in heavy traffic.
  The multi-level queue is a simpler version of the 2-level GI/G/1 queue of Miyazawa (2025, Advances in Applied Probability, to appear) and its extension for multi-levels. For this 2-level queue in heavy traffic, the process limit is unknown, and the distributional limit is obtained for limited cases under extra conditions. Nevertheless, it is shown that the method developed in Miyazawa (2025) perfectly works for the present multi-level queue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03504v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kobayashi, Masakiyo Miyazawa, Yutaka Sakuma</dc:creator>
    </item>
    <item>
      <title>Efficient Training of Physics-enhanced Neural ODEs via Direct Collocation and Nonlinear Programming</title>
      <link>https://arxiv.org/abs/2505.03552</link>
      <description>arXiv:2505.03552v1 Announce Type: cross 
Abstract: We propose a novel approach for training Physics-enhanced Neural ODEs (PeNODEs) by expressing the training process as a dynamic optimization problem. The full model, including neural components, is discretized using a high-order implicit Runge-Kutta method with flipped Legendre-Gauss-Radau points, resulting in a large-scale nonlinear program (NLP) efficiently solved by state-of-the-art NLP solvers such as Ipopt. This formulation enables simultaneous optimization of network parameters and state trajectories, addressing key limitations of ODE solver-based training in terms of stability, runtime, and accuracy. Extending on a recent direct collocation-based method for Neural ODEs, we generalize to PeNODEs, incorporate physical constraints, and present a custom, parallelized, open-source implementation. Benchmarks on a Quarter Vehicle Model and a Van-der-Pol oscillator demonstrate superior accuracy, speed, and generalization with smaller networks compared to other training techniques. We also outline a planned integration into OpenModelica to enable accessible training of Neural DAEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03552v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linus Langenkamp, Philip Hannebohm, Bernhard Bachmann</dc:creator>
    </item>
    <item>
      <title>Troika algorithm: approximate optimization for accurate clique partitioning and clustering of weighted networks</title>
      <link>https://arxiv.org/abs/2505.03573</link>
      <description>arXiv:2505.03573v1 Announce Type: cross 
Abstract: Clique partitioning is a fundamental network clustering task, with applications in a wide range of computational sciences. It involves identifying an optimal partition of the nodes for a real-valued weighted graph according to the edge weights. An optimal partition is one that maximizes the sum of within-cluster edge weights over all possible node partitions. This paper introduces a novel approximation algorithm named Troika to solve this NP-hard problem in small to mid-sized networks for instances of theoretical and practical relevance. Troika uses a branch-and-cut scheme for branching on node triples to find a partition that is within a user-specified optimality gap tolerance. Troika offers advantages over alternative methods like integer programming solvers and heuristics for clique partitioning. Unlike existing heuristics, Troika returns solutions within a guaranteed proximity to global optimality. And our results indicate that Troika is faster than using the state-of-the-art integer programming solver Gurobi for most benchmark instances. Besides its advantages for solving the clique partitioning problem, we demonstrate the applications of Troika in community detection and portfolio analysis. Troika returns partitions with higher proximity to optimal compared to eight modularity-based community detection algorithms. When used on networks of correlations among stocks, Troika reveals the dynamic changes in the structure of portfolio networks including downturns from the 2008 financial crisis and the reaction to the COVID-19 pandemic. Our comprehensive results based on benchmarks from the literature and new real and random networks point to Troika as a reliable and accurate method for solving clique partitioning instances with up to 5000 edges on standard hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03573v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samin Aref, Boris Ng</dc:creator>
    </item>
    <item>
      <title>Characterizing Trust and Resilience in Distributed Consensus for Cyberphysical Systems</title>
      <link>https://arxiv.org/abs/2103.05464</link>
      <description>arXiv:2103.05464v3 Announce Type: replace 
Abstract: This work considers the problem of resilient consensus where stochastic values of trust between agents are available. Specifically, we derive a unified mathematical framework to characterize convergence, deviation of the consensus from the true consensus value, and expected convergence rate, when there exists additional information of trust between agents. We show that under certain conditions on the stochastic trust values and consensus protocol: 1) almost sure convergence to a common limit value is possible even when malicious agents constitute more than half of the network connectivity, 2) the deviation of the converged limit, from the case where there is no attack, i.e., the true consensus value, can be bounded with probability that approaches 1 exponentially, and 3) correct classification of malicious and legitimate agents can be attained in finite time almost surely. Further, the expected convergence rate decays exponentially as a function of the quality of the trust observations between agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.05464v3</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michal Yemini, Angelia Nedi\'c, Andrea Goldsmith, Stephanie Gil</dc:creator>
    </item>
    <item>
      <title>Sharp Global Guarantees for Nonconvex Low-rank Recovery in the Noisy Overparameterized Regime</title>
      <link>https://arxiv.org/abs/2104.10790</link>
      <description>arXiv:2104.10790v3 Announce Type: replace 
Abstract: Recent work established that rank overparameterization eliminates spurious local minima in nonconvex low-rank matrix recovery under the restricted isometry property (RIP). But this does not fully explain the practical success of overparameterization, because real algorithms can still become trapped at nonstrict saddle points (approximate second-order points with arbitrarily small negative curvature) even when all local minima are global. Moreover, the result does not accommodate for noisy measurements, but it is unclear whether such an extension is even possible, in view of the many discontinuous and unintuitive behaviors already known for the overparameterized regime. In this paper, we introduce a novel proof technique that unifies, simplifies, and strengthens two previously competing approaches -- one based on escape directions and the other based on the inexistence of counterexample -- to provide sharp global guarantees in the noisy overparameterized regime. We show, once local minima have been converted into global minima through slight overparameterization, that near-second-order points achieve the same minimax-optimal recovery bounds (up to small constant factors) as significantly more expensive convex approaches. Our results are sharp with respect to the noise level and the solution accuracy, and hold for both the symmetric parameterization $XX^{T}$, as well as the asymmetric parameterization $UV^{T}$ under a balancing regularizer; we demonstrate that the balancing regularizer is indeed necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2104.10790v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Optimization under Heavy-Tailed Noises</title>
      <link>https://arxiv.org/abs/2312.15847</link>
      <description>arXiv:2312.15847v2 Announce Type: replace 
Abstract: This paper studies the distributed optimization problem under the influence of heavy-tailed gradient noises. Here, a heavy-tailed noise means that the noise does not necessarily satisfy the bounded variance assumption. Instead, it satisfies a more general assumption. The commonly-used bounded variance assumption is a special case of the considered noise assumption. A typical example of this kind of noise is a Pareto distribution noise with tail index within (1,2], which has infinite variance. Despite that there has been several distributed optimization algorithms proposed for the heavy-tailed noise scenario, these algorithms need a centralized server in the network which collects the information of all clients. Different from these algorithms, this paper considers that there is no centralized server and the agents can only exchange information with neighbors in a communication graph. A distributed method combining gradient clipping and distributed stochastic subgradient projection is proposed. It is proven that when the gradient descent step-size and the gradient clipping step-size meet certain conditions, the state of each agent converges to the optimal solution of the distributed optimization problem with probability 1. The simulation results validate the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.15847v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Sun, Huiming Zhang, Bo Chen, Li Yu</dc:creator>
    </item>
    <item>
      <title>Sparse $H_\infty$ Controller for Networked Control Systems: Non-Structured and Optimal Structured Design</title>
      <link>https://arxiv.org/abs/2411.00370</link>
      <description>arXiv:2411.00370v2 Announce Type: replace 
Abstract: This paper provides a comprehensive analysis of the design of optimal structured and sparse $H_\infty$ controllers for continuous-time linear time-invariant (LTI) systems. Three problems are considered. First, designing the sparsest $H_\infty$ controller, which minimizes the sparsity of the controller while satisfying the given performance requirements. Second, designing a sparsity-promoting $H_\infty$ controller, which balances system performance and controller sparsity. Third, designing a $H_\infty$ controller subject to a structural constraint, which enhances system performance with a specified sparsity pattern. For each problem, we adopt a linearization technique that transforms the original nonconvex problem into a convex semidefinite programming (SDP) problem. Subsequently, we design an iterative linear matrix inequality (ILMI) algorithm for each problem, which ensures guaranteed convergence. We further characterize the first-order optimality using the Karush-Kuhn-Tucker (KKT) conditions and prove that any limit point of the solution sequence generated by the ILMI algorithm is a stationary point. For the first and second problems, we validate that our algorithms can reduce the number of non-zero elements and thus the communication burden through several numerical simulations. For the third problem, we refine the solutions obtained in existing literature, demonstrating that our approaches achieve significant improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00370v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaohua Yang, Pengyu Wang, Haishan Zhang, Shiyue Jia, Nachuan Yang, Yuxing Zhong, Ling Shi</dc:creator>
    </item>
    <item>
      <title>Tight MIP Formulations for Optimal Operation and Investment of Storage Including Reserves</title>
      <link>https://arxiv.org/abs/2411.17484</link>
      <description>arXiv:2411.17484v2 Announce Type: replace 
Abstract: Fast and accurate large-scale energy system models are needed to investigate the potential of storage to complement the fluctuating energy production of renewable energy systems. However, standard Mixed-Integer Programming (MIP) models that describe optimal investment and operation of these storage units, including the optional capacity to provide up/down reserves, do not scale well. To improve scalability, the integrality constraints are often relaxed, resulting in Linear Programming (LP) relaxations that allow simultaneous charging and discharging, while this is not feasible in practice. To address this, we derive the convex hull of the solutions for the optimal operation of storage for one time period, as well as for problems including investments and reserves, guaranteeing that no tighter MIP formulation or better LP approximation exists for one time period. When incorporating this convex hull into a multi-period formulation and including it in large-scale energy system models, the improved LP relaxations can better prevent simultaneous charging and discharging, and the tighter MIP can speed up the solving time. We demonstrate this with illustrative case studies of a unit commitment problem and a transmission expansion planning problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17484v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maaike B. Elgersma, Germ\'an Morales-Espa\~na, Karen I. Aardal, Niina Helist\"o, Juha Kiviluoma, Mathijs M. de Weerdt</dc:creator>
    </item>
    <item>
      <title>Exact Verification of First-Order Methods via Mixed-Integer Linear Programming</title>
      <link>https://arxiv.org/abs/2412.11330</link>
      <description>arXiv:2412.11330v3 Announce Type: replace 
Abstract: We present exact mixed-integer linear programming formulations for verifying the performance of first-order methods for parametric quadratic optimization. We formulate the verification problem as a mixed-integer linear program where the objective is to maximize the infinity norm of the fixed-point residual after a given number of iterations. Our approach captures a wide range of gradient, projection, proximal iterations through affine or piecewise affine constraints. We derive tight polyhedral convex hull formulations of the constraints representing the algorithm iterations. To improve the scalability, we develop a custom bound tightening technique combining interval propagation, operator theory, and optimization-based bound tightening. Numerical examples, including linear and quadratic programs from network optimization, sparse coding using Lasso, and optimal control, show that our method provides several orders of magnitude reductions in the worst-case fixed-point residuals, closely matching the true worst-case performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11330v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vinit Ranjan, Jisun Park, Stefano Gualandi, Andrea Lodi, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>A truncated epsilon-subdifferential method for global DC optimization</title>
      <link>https://arxiv.org/abs/2501.04291</link>
      <description>arXiv:2501.04291v2 Announce Type: replace 
Abstract: We consider the difference of convex (DC) optimization problem subject to box constraints. Utilizing epsilon-subdifferentials of DC components of the objective, we develop a new method for finding global solutions to this problem. The method combines a local search approach with a special procedure for escaping non-global solutions by identifying improved initial points for a local search. The method terminates when the solution cannot be improved further. The escaping procedure is designed using subsets of the epsilon-subdifferentials of DC components. We compute the deviation between these subsets and determine epsilon-subgradients, providing this deviation. Using these specific epsilon-subgradients, we formulate a subproblem with a convex objective function. The solution to this subproblem serves as a starting point for a local search. We study the convergence of the conceptual version of the proposed method and discuss its implementation. A large number of academic test problems demonstrate that the method requires reasonable computational effort to find higher-quality solutions than other local DC optimization methods. Additionally, we apply the new method to find global solutions to DC optimization problems and compare its performance with two benchmark global optimization solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04291v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adil M. Bagirov, Kaisa Joki, Marko M. Makela, Sona Taheri</dc:creator>
    </item>
    <item>
      <title>A laplace duality for integration</title>
      <link>https://arxiv.org/abs/2502.20842</link>
      <description>arXiv:2502.20842v3 Announce Type: replace 
Abstract: We consider the integral v(y) = Ky f (x)dx on a domain Ky = {x $\in$ R d\,: g(x) $\le$ y}, where g is nonnegative and Ky is compact for all y $\in$ [0, +$\infty$). Under some assumptions, we show that for every y $\in$ (0, $\infty$) there exists a distinguished scalar $\lambda$y $\in$ (0, +$\infty$) such that which is the counterpart analogue for integration of Lagrangian duality for optimization. A crucial ingredient is the Laplace transform, the analogue for integration of Legendre-Fenchel transform in optimization. In particular, if both f and g are positively homogeneous then $\lambda$y is a simple explicitly rational function of y. In addition if g is quadratic form then computing v(y) reduces to computing the integral of f with respect to a specific Gaussian measure for which exact and approximate numerical methods (e.g. cubatures) are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20842v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean B Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>Enhancing the controllability of quantum systems via a static field</title>
      <link>https://arxiv.org/abs/2504.17303</link>
      <description>arXiv:2504.17303v3 Announce Type: replace 
Abstract: We provide a sufficient condition for the controllability of a bilinear closed quantum system based on the notion of static field and weakly conically connected spectrum. More precisely, we show that if a controlled Hamiltonian with two inputs has a weakly conically connected spectrum, then, freezing one of the two inputs at almost every constant value, the obtained single-input system is controllable. The result is illustrated with two examples, enantiomer-selective excitation in a chiral molecule and the driven Jaynes--Cummings Hamiltonian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17303v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruikang Liang (LJLL), Eugenio Pozzoli (IRMAR, CNRS), Monika Leibscher (LJLL), Mario Sigalotti (LJLL), Christiane P Koch (LJLL), Ugo Boscain (LJLL)</dc:creator>
    </item>
    <item>
      <title>Delta-modular ILP Problems of Bounded Codimension, Discrepancy, and Convolution (new version)</title>
      <link>https://arxiv.org/abs/2405.17001</link>
      <description>arXiv:2405.17001v4 Announce Type: replace-cross 
Abstract: For integers $k,n \geq 0$ and a cost vector $c \in Z^n$, we study two fundamental integer linear programming (ILP) problems: \[
  \text{(Standard Form)} \quad \max\bigl\{c^\top x \colon Ax = b,\ x \in Z^n_{\geq 0}\bigr\} \text{ with } A \in Z^{k \times n}, \text{rank}(A) = k, b \in Z^k, \] \[
  \text{(Canonical Form)} \quad \max\bigl\{c^\top x \colon Ax \leq b,\ x \in Z^n\bigr\} \text{ with } A \in Z^{(n+k) \times n}, \text{rank}(A) = n, b \in Z^{n+k}. \] We present improved algorithms for both problems and their feasibility versions, parameterized by $k$ and $\Delta$, where $\Delta$ denotes the maximum absolute value of $\text{rank}(A) \times \text{rank}(A)$ subdeterminants of $A$. Our main complexity results, stated in terms of required arithmetic operations, are: \[ \text{Optimization:}\quad O(\log k)^{2k} \cdot \Delta^2 / 2^{\Omega(\sqrt{\log \Delta})} + 2^{O(k)} \cdot \text{poly}(\varphi), \] \[ \text{Feasibility:} \quad O(\log k)^k \cdot \Delta \cdot (\log \Delta)^3 + 2^{O(k)} \cdot \text{poly}(\varphi), \] where $\varphi$ represents the input size measured by the bit-encoding length of $(A,b,c)$. We also examine several special cases when $k \in \{0,1\}$, which have important applications in: expected computational complexity of ILP with varying right-hand side $b$, ILP problems with generic constraint matrices, ILP problems on simplices. Our results yield improved complexity bounds for these specific scenarios.
  As independent contributions, we present: An $n^2/2^{\Omega(\sqrt{\log n})}$-time algorithm for the tropical convolution problem on sequences indexed by elements of a finite Abelian group of order $n$; A complete and self-contained error analysis of the generalized DFT over Abelian groups in the Word-RAM model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17001v4</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.AC</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. Cherniavskii, D. Gribanov, D. Malyshev, P. M. Pardalos</dc:creator>
    </item>
    <item>
      <title>Sensor-Based Distributionally Robust Control for Safe Robot Navigation in Dynamic Environments</title>
      <link>https://arxiv.org/abs/2405.18251</link>
      <description>arXiv:2405.18251v4 Announce Type: replace-cross 
Abstract: We introduce a novel method for mobile robot navigation in dynamic, unknown environments, leveraging onboard sensing and distributionally robust optimization to impose probabilistic safety constraints. Our method introduces a distributionally robust control barrier function (DR-CBF) that directly integrates noisy sensor measurements and state estimates to define safety constraints. This approach is applicable to a wide range of control-affine dynamics, generalizable to robots with complex geometries, and capable of operating at real-time control frequencies. Coupled with a control Lyapunov function (CLF) for path following, the proposed CLF-DR-CBF control synthesis method achieves safe, robust, and efficient navigation in challenging environments. We demonstrate the effectiveness and robustness of our approach for safe autonomous navigation under uncertainty in simulations and real-world experiments with differential-drive robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18251v4</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kehan Long, Yinzhuang Yi, Zhirui Dai, Sylvia Herbert, Jorge Cort\'es, Nikolay Atanasov</dc:creator>
    </item>
    <item>
      <title>Alon's transmitting problem and multicolor Beck--Spencer Lemma</title>
      <link>https://arxiv.org/abs/2406.19945</link>
      <description>arXiv:2406.19945v3 Announce Type: replace-cross 
Abstract: The Hamming graph $H(n,q)$ is defined on the vertex set $\{1,2,\ldots,q\}^n$ and two vertices are adjacent if and only if they differ in precisely one coordinate. Alon (1992) proved that for any sequence $v_1,\ldots,v_b$ of $b=\lceil\frac n2\rceil$ vertices of $H(n,2)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$. In this note, we prove that for any $q\geq 3$ and any sequence $v_1,\ldots,v_b$ of $b=\lfloor(1-\frac1q)n\rfloor$ vertices of $H(n,q)$, there is a vertex whose distance from $v_i$ is at least $b-i+1$ for all $1\leq i\leq b$.
  Alon used a lemma due to Beck and Spencer (1983) which, in turn, was based on the floating variable method introduced by Beck and Fiala (1981) who studied combinatorial discrepancies. For our proof, we extend the Beck--Spencer Lemma by using a multicolor version of the floating variable method due to Doerr and Srivastav (2003).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19945v3</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 07 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Norihide Tokushige</dc:creator>
    </item>
  </channel>
</rss>
