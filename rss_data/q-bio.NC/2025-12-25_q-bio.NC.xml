<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 25 Dec 2025 05:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Decoding Predictive Inference in Visual Language Processing via Spatiotemporal Neural Coherence</title>
      <link>https://arxiv.org/abs/2512.20929</link>
      <description>arXiv:2512.20929v1 Announce Type: new 
Abstract: Human language processing relies on the brain's capacity for predictive inference. We present a machine learning framework for decoding neural (EEG) responses to dynamic visual language stimuli in Deaf signers. Using coherence between neural signals and optical flow-derived motion features, we construct spatiotemporal representations of predictive neural dynamics. Through entropy-based feature selection, we identify frequency-specific neural signatures that differentiate interpretable linguistic input from linguistically disrupted (time-reversed) stimuli. Our results reveal distributed left-hemispheric and frontal low-frequency coherence as key features in language comprehension, with experience-dependent neural signatures correlating with age. This work demonstrates a novel multimodal approach for probing experience-driven generative models of perception in the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20929v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sean C. Borneman, Julia Krebs, Ronnie B. Wilbur, Evie A. Malaia</dc:creator>
    </item>
    <item>
      <title>Active inference and artificial reasoning</title>
      <link>https://arxiv.org/abs/2512.21129</link>
      <description>arXiv:2512.21129v1 Announce Type: new 
Abstract: This technical note considers the sampling of outcomes that provide the greatest amount of information about the structure of underlying world models. This generalisation furnishes a principled approach to structure learning under a plausible set of generative models or hypotheses. In active inference, policies - i.e., combinations of actions - are selected based on their expected free energy, which comprises expected information gain and value. Information gain corresponds to the KL divergence between predictive posteriors with, and without, the consequences of action. Posteriors over models can be evaluated quickly and efficiently using Bayesian Model Reduction, based upon accumulated posterior beliefs about model parameters. The ensuing information gain can then be used to select actions that disambiguate among alternative models, in the spirit of optimal experimental design. We illustrate this kind of active selection or reasoning using partially observed discrete models; namely, a 'three-ball' paradigm used previously to describe artificial insight and 'aha moments' via (synthetic) introspection or sleep. We focus on the sample efficiency afforded by seeking outcomes that resolve the greatest uncertainty about the world model, under which outcomes are generated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.21129v1</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Friston, Lancelot Da Costa, Alexander Tschantz, Conor Heins, Christopher Buckley, Tim Verbelen, Thomas Parr</dc:creator>
    </item>
    <item>
      <title>Gradient Diffusion: Sensitivity-Matrix Co-Simulation Enables Activity Adaptation and Learnable Plasticity in Neural Simulators</title>
      <link>https://arxiv.org/abs/2412.07327</link>
      <description>arXiv:2412.07327v4 Announce Type: replace 
Abstract: Computational neuroscience relies on large-scale dynamical-systems models of neurons, with a vast amount of offline, pre-simulation, tuned parameters, with models often tied to their brain simulators. These fixed parameters lead to stiff models, that show unnatural behaviour when introduced to new environments, or when combined into larger networks. In contrast to offline tuning, in biology, cells continuously adapt via homeostatic plasticity to stay in desired dynamical regimes. In this work, we aim to introduce such online tuning of cellular parameters into brain simulation. We show that the sensitivity equation of a biorealistic neural models has the same shape as a general neuron model, and can be simulated within existing brain simulators. Via co-simulation with the sensitivity equation, we enable both offline, and online tuning of activity of arbitrary biophysically realistic brain models. Furthermore, we show that this opens the possibility to study the biological mechanisms underlying homeostatic plasticity, via both meta-learning plasticity mechanism as well as treating online tuning as a black-box plasticity mechanism. Through the generality of our methods, we hope that more computational science fields can capitalize on the similarity between the simulated model and its gradient system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07327v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lennart P. L. Landsmeer, Mario Negrello, Said Hamdioui, Christos Strydis</dc:creator>
    </item>
    <item>
      <title>Coherence in the brain unfolds across separable temporal regimes</title>
      <link>https://arxiv.org/abs/2512.20481</link>
      <description>arXiv:2512.20481v2 Announce Type: replace 
Abstract: Coherence in language requires the brain to satisfy two competing temporal demands: gradual accumulation of meaning across extended context and rapid reconfiguration of representations at event boundaries. Despite their centrality to language and thought, how these processes are implemented in the human brain during naturalistic listening remains unclear. Here, we tested whether these two processes can be captured by annotation-free drift and shift signals and whether their neural expression dissociates across large-scale cortical systems. These signals were derived from a large language model (LLM) and formalized contextual drift and event shifts directly from the narrative input. To enable high-precision voxelwise encoding models with stable parameter estimates, we densely sampled one healthy adult across more than 7 hours of listening to thirteen crime stories while collecting ultra high-field (7T) BOLD data. We then modeled the feature-informed hemodynamic response using a regularized encoding framework validated on independent stories. Drift predictions were prevalent in default-mode network hubs, whereas shift predictions were evident bilaterally in the primary auditory cortex and language association cortex. Furthermore, activity in default-mode and parietal networks was best explained by a signal capturing how meaning accumulates and gradually fades over the course of the narrative. Together, these findings show that coherence during language comprehension is implemented through dissociable neural regimes of slow contextual integration and rapid event-driven reconfiguration, offering a mechanistic entry point for understanding disturbances of language coherence in psychiatric disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.20481v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CL</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Davide Stauba, Finn Rabe, Akhil Misra, Yves Pauli, Roya H\"uppi, Ni Yang, Nils Lang, Lars Michels, Victoria Edkins, Sascha Fr\"uhholz, Iris Sommer, Wolfram Hinzen, Philipp Homan</dc:creator>
    </item>
    <item>
      <title>EEG Foundation Models: A Critical Review of Current Progress and Future Directions</title>
      <link>https://arxiv.org/abs/2507.11783</link>
      <description>arXiv:2507.11783v3 Announce Type: replace-cross 
Abstract: Premise. Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubrics for long-term research progress remain unclear. Objective. In this work, we conduct a review of ten early EEG-FMs to capture common trends and identify key directions for future development of EEG-FMs. Methods. We comparatively analyze each EEG-FM using three fundamental pillars of foundation modeling, namely the representation of input data, self-supervised modeling, and the evaluation strategy. Based on this analysis, we present a critical synthesis of EEG-FM methodology, empirical findings, and outstanding research gaps. Results. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked temporal EEG sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. Significance. Our review indicates that the development of benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may advance the translational utility and real-world adoption of EEG-FMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11783v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gayal Kuruppu, Neeraj Wagh, Vaclav Kremen, Sandipan Pati, Gregory Worrell, Yogatheesan Varatharajah</dc:creator>
    </item>
    <item>
      <title>Stabilizing Fractional Dynamical Networks Suppresses Epileptic Seizures</title>
      <link>https://arxiv.org/abs/2511.20950</link>
      <description>arXiv:2511.20950v3 Announce Type: replace-cross 
Abstract: Medically uncontrolled epileptic seizures affect nearly 15 million people worldwide, resulting in enormous economic and psychological burdens. Treatment of medically refractory epilepsy is essential for patients to achieve remission, improve psychological functioning, and enhance social and vocational outcomes. Here, we show a state-of-the-art method that stabilizes fractional dynamical networks modeled from intracranial EEG data, effectively suppressing seizure activity in 34 out of 35 total spontaneous episodes from patients at the University of Pennsylvania and the Mayo Clinic. We perform a multi-scale analysis and show that the fractal behavior and stability properties of these data distinguish between four epileptic states: interictal, pre-ictal, ictal, and post-ictal. Furthermore, the simulated controlled signals exhibit substantial amplitude reduction ($49\%$ average). These findings highlight the potential of fractional dynamics to characterize seizure-related brain states and demonstrate its capability to suppress epileptic activity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20950v3</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 25 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaoyue Wang, Arian Ashourvan, Guilherme Ramos, Paul Bogdan, Emily Pereira</dc:creator>
    </item>
  </channel>
</rss>
