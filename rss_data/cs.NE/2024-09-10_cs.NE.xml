<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Sep 2024 01:46:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Evaluating Open-Source Sparse Autoencoders on Disentangling Factual Knowledge in GPT-2 Small</title>
      <link>https://arxiv.org/abs/2409.04478</link>
      <description>arXiv:2409.04478v1 Announce Type: cross 
Abstract: A popular new method in mechanistic interpretability is to train high-dimensional sparse autoencoders (SAEs) on neuron activations and use SAE features as the atomic units of analysis. However, the body of evidence on whether SAE feature spaces are useful for causal analysis is underdeveloped. In this work, we use the RAVEL benchmark to evaluate whether SAEs trained on hidden representations of GPT-2 small have sets of features that separately mediate knowledge of which country a city is in and which continent it is in. We evaluate four open-source SAEs for GPT-2 small against each other, with neurons serving as a baseline, and linear features learned via distributed alignment search (DAS) serving as a skyline. For each, we learn a binary mask to select features that will be patched to change the country of a city without changing the continent, or vice versa. Our results show that SAEs struggle to reach the neuron baseline, and none come close to the DAS skyline. We release code here: https://github.com/MaheepChaudhary/SAE-Ravel</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04478v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maheep Chaudhary, Atticus Geiger</dc:creator>
    </item>
    <item>
      <title>Advanced LSTM Neural Networks for Predicting Directional Changes in Sector-Specific ETFs Using Machine Learning Techniques</title>
      <link>https://arxiv.org/abs/2409.05778</link>
      <description>arXiv:2409.05778v1 Announce Type: cross 
Abstract: Trading and investing in stocks for some is their full-time career, while for others, it's simply a supplementary income stream. Universal among all investors is the desire to turn a profit. The key to achieving this goal is diversification. Spreading investments across sectors is critical to profitability and maximizing returns. This study aims to gauge the viability of machine learning methods in practicing the principle of diversification to maximize portfolio returns. To test this, the study evaluates the Long-Short Term Memory (LSTM) model across nine different sectors and over 2,200 stocks using Vanguard's sector-based ETFs. The R-squared value across all sectors showed promising results, with an average of 0.8651 and a high of 0.942 for the VNQ ETF. These findings suggest that the LSTM model is a capable and viable model for accurately predicting directional changes across various industry sectors, helping investors diversify and grow their portfolios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05778v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rifa Gowani, Zaryab Kanjiani</dc:creator>
    </item>
    <item>
      <title>An Introduction to Quantum Reinforcement Learning (QRL)</title>
      <link>https://arxiv.org/abs/2409.05846</link>
      <description>arXiv:2409.05846v1 Announce Type: cross 
Abstract: Recent advancements in quantum computing (QC) and machine learning (ML) have sparked considerable interest in the integration of these two cutting-edge fields. Among the various ML techniques, reinforcement learning (RL) stands out for its ability to address complex sequential decision-making problems. RL has already demonstrated substantial success in the classical ML community. Now, the emerging field of Quantum Reinforcement Learning (QRL) seeks to enhance RL algorithms by incorporating principles from quantum computing. This paper offers an introduction to this exciting area for the broader AI and ML community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05846v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Yen-Chi Chen</dc:creator>
    </item>
    <item>
      <title>Migrant Resettlement by Evolutionary Multi-objective Optimization</title>
      <link>https://arxiv.org/abs/2310.08896</link>
      <description>arXiv:2310.08896v3 Announce Type: replace 
Abstract: Migration has been a universal phenomenon, which brings opportunities as well as challenges for global development. As the number of migrants (e.g., refugees) increases rapidly in recent years, a key challenge faced by each country is the problem of migrant resettlement. This problem has attracted scientific research attention, from the perspective of maximizing the employment rate. Previous works mainly formulated migrant resettlement as an approximately submodular optimization problem subject to multiple matroid constraints and employed the greedy algorithm, whose performance, however, may be limited due to its greedy nature. In this paper, we propose a new framework MR-EMO based on Evolutionary Multi-objective Optimization, which reformulates Migrant Resettlement as a bi-objective optimization problem that maximizes the expected number of employed migrants and minimizes the number of dispatched migrants simultaneously, and employs a Multi-Objective Evolutionary Algorithm (MOEA) to solve the bi-objective problem. We implement MR-EMO using three MOEAs, the popular NSGA-II, MOEA/D as well as the theoretically grounded GSEMO. To further improve the performance of MR-EMO, we propose a specific MOEA, called GSEMO-SR, using matrix-swap mutation and repair mechanism, which has a better ability to search for feasible solutions. We prove that MR-EMO using either GSEMO or GSEMO-SR can achieve better theoretical guarantees than the previous greedy algorithm. Experimental results under the interview and coordination migration models clearly show the superiority of MR-EMO (with either NSGA-II, MOEA/D, GSEMO or GSEMO-SR) over previous algorithms, and that using GSEMO-SR leads to the best performance of MR-EMO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08896v3</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan-Xuan Liu, Yu-Ran Gu, Chao Qian, Xin Mu, Ke Tang</dc:creator>
    </item>
    <item>
      <title>Genetic Algorithms with Neural Cost Predictor for Solving Hierarchical Vehicle Routing Problems</title>
      <link>https://arxiv.org/abs/2310.14157</link>
      <description>arXiv:2310.14157v4 Announce Type: replace 
Abstract: When vehicle routing decisions are intertwined with higher-level decisions, the resulting optimization problems pose significant challenges for computation. Examples are the multi-depot vehicle routing problem (MDVRP), where customers are assigned to depots before delivery, and the capacitated location routing problem (CLRP), where the locations of depots should be determined first. A simple and straightforward approach for such hierarchical problems would be to separate the higher-level decisions from the complicated vehicle routing decisions. For each higher-level decision candidate, we may evaluate the underlying vehicle routing problems to assess the candidate. As this approach requires solving vehicle routing problems multiple times, it has been regarded as impractical in most cases. We propose a novel deep-learning-based approach called Genetic Algorithm with Neural Cost Predictor (GANCP) to tackle the challenge and simplify algorithm developments. For each higher-level decision candidate, we predict the objective function values of the underlying vehicle routing problems using a pre-trained graph neural network without actually solving the routing problems. In particular, our proposed neural network learns the objective values of the HGS-CVRP open-source package that solves capacitated vehicle routing problems. Our numerical experiments show that this simplified approach is effective and efficient in generating high-quality solutions for both MDVRP and CLRP and has the potential to expedite algorithm developments for complicated hierarchical problems. We provide computational results evaluated in the standard benchmark instances used in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14157v4</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhay Sobhanan, Junyoung Park, Jinkyoo Park, Changhyun Kwon</dc:creator>
    </item>
    <item>
      <title>Deep Oscillatory Neural Network</title>
      <link>https://arxiv.org/abs/2405.03725</link>
      <description>arXiv:2405.03725v2 Announce Type: replace 
Abstract: We propose a novel, brain-inspired deep neural network model known as the Deep Oscillatory Neural Network (DONN). Deep neural networks like the Recurrent Neural Networks indeed possess sequence processing capabilities but the internal states of the network are not designed to exhibit brain-like oscillatory activity. With this motivation, the DONN is designed to have oscillatory internal dynamics. Neurons of the DONN are either nonlinear neural oscillators or traditional neurons with sigmoidal or ReLU activation. The neural oscillator used in the model is the Hopf oscillator, with the dynamics described in the complex domain. Input can be presented to the neural oscillator in three possible modes. The sigmoid and ReLU neurons also use complex-valued extensions. All the weight stages are also complex-valued. Training follows the general principle of weight change by minimizing the output error and therefore has an overall resemblance to complex backpropagation. A generalization of DONN to convolutional networks known as the Oscillatory Convolutional Neural Network is also proposed. The two proposed oscillatory networks are applied to a variety of benchmark problems in signal and image/video processing. The performance of the proposed models is either comparable or superior to published results on the same data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03725v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nurani Rajagopal Rohan, Vigneswaran C, Sayan Ghosh, Kishore Rajendran, Gaurav A, V Srinivasa Chakravarthy</dc:creator>
    </item>
    <item>
      <title>BMR and BWR: Two simple metaphor-free optimization algorithms for solving real-life non-convex constrained and unconstrained problems</title>
      <link>https://arxiv.org/abs/2407.11149</link>
      <description>arXiv:2407.11149v2 Announce Type: replace 
Abstract: Two simple yet powerful optimization algorithms, named the Best-Mean-Random (BMR) and Best-Worst-Random (BWR) algorithms, are developed and presented in this paper to handle both constrained and unconstrained optimization problems. These algorithms are free of metaphors and algorithm-specific parameters. The BMR algorithm is based on the best, mean, and random solutions of the population generated for solving a given problem, and the BWR algorithm is based on the best, worst, and random solutions. The performances of the proposed two algorithms are investigated by implementing them on 26 real-life nonconvex constrained optimization problems given in the Congress on Evolutionary Computation (CEC) 2020 competition, and comparisons are made with those of the other prominent optimization algorithms. The performances on 12 constrained engineering problems are also investigated, and the results are compared with those of very recent algorithms (in some cases, compared with more than 30 algorithms). Furthermore, computational experiments are conducted on 30 unconstrained standard benchmark optimization problems, including 5 recently developed benchmark problems with distinct characteristics. The results demonstrated the superior competitiveness and superiority of the proposed simple algorithms. The optimization research community may gain an advantage by adapting these algorithms to solve various constrained and unconstrained real-life optimization problems across various scientific and engineering disciplines. The codes of the BMR and BWR algorithms are available at https://sites.google.com/view/bmr-bwr-optimization-algorithm/home?authuser=0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11149v2</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ravipudi Venkata Rao, Ravikumar shah</dc:creator>
    </item>
    <item>
      <title>Hardware-Algorithm Re-engineering of Retinal Circuit for Intelligent Object Motion Segmentation</title>
      <link>https://arxiv.org/abs/2408.08320</link>
      <description>arXiv:2408.08320v2 Announce Type: replace 
Abstract: Recent advances in retinal neuroscience have fueled various hardware and algorithmic efforts to develop retina-inspired solutions for computer vision tasks. In this work, we focus on a fundamental visual feature within the mammalian retina, Object Motion Sensitivity (OMS). Using DVS data from EV-IMO dataset, we analyze the performance of an algorithmic implementation of OMS circuitry for motion segmentation in presence of ego-motion. This holistic analysis considers the underlying constraints arising from the hardware circuit implementation. We present novel CMOS circuits that implement OMS functionality inside image sensors, while providing run-time re-configurability for key algorithmic parameters. In-sensor technologies for dynamical environment adaptation are crucial for ensuring high system performance. Finally, we verify the functionality and re-configurability of the proposed CMOS circuit designs through Cadence simulations in 180nm technology. In summary, the presented work lays foundation for hardware-algorithm re-engineering of known biological circuits to suit application needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08320v2</guid>
      <category>cs.NE</category>
      <category>eess.IV</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Sinaga, Victoria Clerico, Md Abdullah-Al Kaiser, Shay Snyder, Arya Lohia, Gregory Schwartz, Maryam Parsa, Akhilesh Jaiswal</dc:creator>
    </item>
    <item>
      <title>CoLaNET -- A Spiking Neural Network with Columnar Layered Architecture for Classification</title>
      <link>https://arxiv.org/abs/2409.01230</link>
      <description>arXiv:2409.01230v3 Announce Type: replace 
Abstract: In the present paper, I describe a spiking neural network (SNN) architecture which, can be used in wide range of supervised learning classification tasks. It is assumed, that all participating signals (the classified object description, correct class label and SNN decision) have spiking nature. The distinctive feature of this architecture is a combination of prototypical network structures corresponding to different classes and significantly distinctive instances of one class (=columns) and functionally differing populations of neurons inside columns (=layers). The other distinctive feature is a novel combination of anti-Hebbian and dopamine-modulated plasticity. The plasticity rules are local and do not use the backpropagation principle. Besides that, as in my previous studies, I was guided by the requirement that the all neuron/plasticity models should be easily implemented on modern neurochips. I illustrate the high performance of my network on a task related to model-based reinforcement learning, namely, evaluation of proximity of an external world state to the target state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01230v3</guid>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mikhail Kiselev</dc:creator>
    </item>
    <item>
      <title>Deep Convolutional Autoencoder for Assessment of Drive-Cycle Anomalies in Connected Vehicle Sensor Data</title>
      <link>https://arxiv.org/abs/2202.07592</link>
      <description>arXiv:2202.07592v3 Announce Type: replace-cross 
Abstract: This work investigates a practical and novel method for automated unsupervised fault detection in vehicles using a fully convolutional autoencoder. The results demonstrate the algorithm we developed can detect anomalies which correspond to powertrain faults by learning patterns in the multivariate time-series data of hybrid-electric vehicle powertrain sensors. Data was collected by engineers at Ford Motor Company from numerous sensors over several drive cycle variations. This study provides evidence of the anomaly detecting capability of our trained autoencoder and investigates the suitability of our autoencoder relative to other unsupervised methods for automatic fault detection in this data set. Preliminary results of testing the autoencoder on the powertrain sensor data indicate the data reconstruction approach availed by the autoencoder is a robust technique for identifying the abnormal sequences in the multivariate series. These results support that irregularities in hybrid-electric vehicles' powertrains are conveyed via sensor signals in the embedded electronic communication system, and therefore can be identified mechanistically with a trained algorithm. Additional unsupervised methods are tested and show the autoencoder performs better at fault detection than outlier detectors and other novel deep learning techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.07592v3</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/SSCI51031.2022.10022233</arxiv:DOI>
      <arxiv:journal_reference>2022 IEEE Symposium Series on Computational Intelligence (SSCI), Singapore, Singapore, 2022</arxiv:journal_reference>
      <dc:creator>Anthony Geglio, Eisa Hedayati, Mark Tascillo, Dyche Anderson, Jonathan Barker, Timothy C. Havens</dc:creator>
    </item>
    <item>
      <title>Keypoint Action Tokens Enable In-Context Imitation Learning in Robotics</title>
      <link>https://arxiv.org/abs/2403.19578</link>
      <description>arXiv:2403.19578v2 Announce Type: replace-cross 
Abstract: We show that off-the-shelf text-based Transformers, with no additional training, can perform few-shot in-context visual imitation learning, mapping visual observations to action sequences that emulate the demonstrator's behaviour. We achieve this by transforming visual observations (inputs) and trajectories of actions (outputs) into sequences of tokens that a text-pretrained Transformer (GPT-4 Turbo) can ingest and generate, via a framework we call Keypoint Action Tokens (KAT). Despite being trained only on language, we show that these Transformers excel at translating tokenised visual keypoint observations into action trajectories, performing on par or better than state-of-the-art imitation learning (diffusion policies) in the low-data regime on a suite of real-world, everyday tasks. Rather than operating in the language domain as is typical, KAT leverages text-based Transformers to operate in the vision and action domains to learn general patterns in demonstration data for highly efficient imitation learning, indicating promising new avenues for repurposing natural language models for embodied tasks. Videos are available at https://www.robot-learning.uk/keypoint-action-tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19578v2</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Norman Di Palo, Edward Johns</dc:creator>
    </item>
    <item>
      <title>Random walk model that universally generates inverse square L\'evy walk by eliminating search cost minimization constraint</title>
      <link>https://arxiv.org/abs/2405.07541</link>
      <description>arXiv:2405.07541v3 Announce Type: replace-cross 
Abstract: The L\'evy walk, a type of random walk characterized by linear step lengths that follow a power-law distribution, is observed in the migratory behaviors of various organisms, ranging from bacteria to humans. Notably, L\'evy walks with power exponents close to two are frequently observed, though their underlying causes remain elusive. This study introduces a simplified, abstract random walk model designed to produce inverse square L\'evy walks, also known as Cauchy walks and explores the conditions that facilitate these phenomena. In our model, agents move toward a randomly selected destination in multi-dimensional space, and their movement strategy is parameterized by the extent to which they pursue the shortest path. When the search cost is proportional to the distance traveled, this parameter effectively reflects the emphasis on minimizing search costs. Our findings reveal that strict adherence to this cost minimization constraint results in a Brownian walk pattern. However, removing this constraint transitions the movement to an inverse square L\'evy walk. Therefore, by modulating the prioritization of search costs, our model can seamlessly alternate between Brownian and Cauchy walk dynamics. This model has the potential to be utilized for exploring the parameter space of an optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07541v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuji Shinohara, Daiki Morita, Hayato Hirai, Ryosuke Kuribayashi, Nobuhito Manome, Toru Moriyama, Hiroshi Okamoto, Yoshihiro Nakajima, Pegio-Yukio Gunji, Ung-il Chung</dc:creator>
    </item>
    <item>
      <title>On the Expressivity of Recurrent Neural Cascades with Identity</title>
      <link>https://arxiv.org/abs/2405.11657</link>
      <description>arXiv:2405.11657v2 Announce Type: replace-cross 
Abstract: Recurrent Neural Cascades (RNC) are the class of recurrent neural networks with no cyclic dependencies among recurrent neurons. Their subclass RNC+ with positive recurrent weights has been shown to be closely connected to the star-free regular languages, which are the expressivity of many well-established temporal logics. The existing expressivity results show that the regular languages captured by RNC+ are the star-free ones, and they leave open the possibility that RNC+ may capture languages beyond regular. We exclude this possibility for languages that include an identity element, i.e., an input that can occur an arbitrary number of times without affecting the output. Namely, in the presence of an identity element, we show that the languages captured by RNC+ are exactly the star-free regular languages. Identity elements are ubiquitous in temporal patterns, and hence our results apply to a large number of applications. The implications of our results go beyond expressivity. At their core, we establish a close structural correspondence between RNC+ and semiautomata cascades, showing that every neuron can be equivalently captured by a three-state semiautomaton. A notable consequence of this result is that RNC+ are no more succinct than cascades of three-state semiautomata.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11657v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadezda Alexandrovna Knorozova, Alessandro Ronca</dc:creator>
    </item>
    <item>
      <title>Biased Pareto Optimization for Subset Selection with Dynamic Cost Constraints</title>
      <link>https://arxiv.org/abs/2406.12383</link>
      <description>arXiv:2406.12383v2 Announce Type: replace-cross 
Abstract: Subset selection with cost constraints aims to select a subset from a ground set to maximize a monotone objective function without exceeding a given budget, which has various applications such as influence maximization and maximum coverage. In real-world scenarios, the budget, representing available resources, may change over time, which requires that algorithms must adapt quickly to new budgets. However, in this dynamic environment, previous algorithms either lack theoretical guarantees or require a long running time. The state-of-the-art algorithm, POMC, is a Pareto optimization approach designed for static problems, lacking consideration for dynamic problems. In this paper, we propose BPODC, enhancing POMC with biased selection and warm-up strategies tailored for dynamic environments. We focus on the ability of BPODC to leverage existing computational results while adapting to budget changes. We prove that BPODC can maintain the best known $(\alpha_f/2)(1-e^{-\alpha_f})$-approximation guarantee when the budget changes. Experiments on influence maximization and maximum coverage show that BPODC adapts more effectively and rapidly to budget changes, with a running time that is less than that of the static greedy algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12383v2</guid>
      <category>cs.DS</category>
      <category>cs.NE</category>
      <pubDate>Tue, 10 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dan-Xuan Liu, Chao Qian</dc:creator>
    </item>
  </channel>
</rss>
