<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Dec 2024 02:47:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A personalized model and optimization strategy for estimating blood glucose concentrations from sweat measurements</title>
      <link>https://arxiv.org/abs/2412.02870</link>
      <description>arXiv:2412.02870v1 Announce Type: new 
Abstract: Background and objective: Diabetes is one of the four leading causes of death worldwide, necessitating daily blood glucose monitoring. While sweat offers a promising non-invasive alternative for glucose monitoring, its application remains limited due to the low to moderate correlation between sweat and blood glucose concentrations, which has been obtained until now by assuming a linear relationship. This study proposes a novel model-based strategy to estimate blood glucose concentrations from sweat samples, setting the stage for non-invasive glucose monitoring through sweat-sensing technology.
  Methods: We first developed a pharmacokinetic glucose transport model that describes the glucose transport from blood to sweat. Secondly, we designed a novel optimization strategy leveraging the proposed model to solve the inverse problem and infer blood glucose levels from measured glucose concentrations in sweat. To this end, the pharmacokinetic model parameters with the highest sensitivity were also optimized so as to achieve a personalized estimation. Our strategy was tested on a dataset composed of 108 samples from healthy volunteers and diabetic patients.
  Results: Our glucose transport model improves over the state-of-the-art in estimating sweat glucose concentrations from blood levels (higher accuracy, p&lt;0.001). Additionally, our optimization strategy effectively solved the inverse problem, yielding a Pearson correlation coefficient of 0.98 across all 108 data points, with an average root-mean-square-percent-error of 12%+/-8%. This significantly outperforms the best sweat-blood glucose correlation reported in the existing literature (0.75).
  Conclusion: Our innovative optimization strategy, also leveraging more accurate modeling, shows promising results, paving the way for non-invasive blood glucose monitoring and, possibly, improved diabetes management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02870v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Yin, Elisabetta Peri, Eduard Pelssers, Jaap den Toonder, Lisa Klous, Hein Daanen, Massimo Mischi</dc:creator>
    </item>
    <item>
      <title>Sifting through the haystack -- efficiently finding rare animal behaviors in large-scale datasets</title>
      <link>https://arxiv.org/abs/2412.03452</link>
      <description>arXiv:2412.03452v1 Announce Type: new 
Abstract: In the study of animal behavior, researchers often record long continuous videos, accumulating into large-scale datasets. However, the behaviors of interest are often rare compared to routine behaviors. This incurs a heavy cost on manual annotation, forcing users to sift through many samples before finding their needles. We propose a pipeline to efficiently sample rare behaviors from large datasets, enabling the creation of training datasets for rare behavior classifiers. Our method only needs an unlabeled animal pose or acceleration dataset as input and makes no assumptions regarding the type, number, or characteristics of the rare behaviors.
  Our pipeline is based on a recent graph-based anomaly detection model for human behavior, which we apply to this new data domain. It leverages anomaly scores to automatically label normal samples while directing human annotation efforts toward anomalies. In research data, anomalies may come from many different sources (e.g., signal noise versus true rare instances). Hence, the entire labeling budget is focused on the abnormal classes, letting the user review and label samples according to their needs.
  We tested our approach on three datasets of freely-moving animals, acquired in the laboratory and the field. We found that graph-based models are particularly useful when studying motion-based behaviors in animals, yielding good results while using a small labeling budget. Our method consistently outperformed traditional random sampling, offering an average improvement of 70% in performance and creating datasets even when the behavior of interest was only 0.02% of the data. Even when the performance gain was minor (e.g., when the behavior is not rare), our method still reduced the annotation effort by half</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03452v1</guid>
      <category>q-bio.QM</category>
      <category>eess.IV</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shir Bar, Or Hirschorn, Roi Holzman, Shai Avidan</dc:creator>
    </item>
    <item>
      <title>Hybrid deep learning-based strategy for the hepatocellular carcinoma cancer grade classification of H&amp;E stained liver histopathology images</title>
      <link>https://arxiv.org/abs/2412.03084</link>
      <description>arXiv:2412.03084v1 Announce Type: cross 
Abstract: Hepatocellular carcinoma (HCC) is a common type of liver cancer whose early-stage diagnosis is a common challenge, mainly due to the manual assessment of hematoxylin and eosin-stained whole slide images, which is a time-consuming process and may lead to variability in decision-making. For accurate detection of HCC, we propose a hybrid deep learning-based architecture that uses transfer learning to extract the features from pre-trained convolutional neural network (CNN) models and a classifier made up of a sequence of fully connected layers. This study uses a publicly available The Cancer Genome Atlas Hepatocellular Carcinoma (TCGA-LIHC)database (n=491) for model development and database of Kasturba Gandhi Medical College (KMC), India for validation. The pre-processing step involves patch extraction, colour normalization, and augmentation that results in 3920 patches for the TCGA dataset. The developed hybrid deep neural network consisting of a CNN-based pre-trained feature extractor and a customized artificial neural network-based classifier is trained using five-fold cross-validation. For this study, eight different state-of-the-art models are trained and tested as feature extractors for the proposed hybrid model. The proposed hybrid model with ResNet50-based feature extractor provided the sensitivity, specificity, F1-score, accuracy, and AUC of 100.00%, 100.00%, 100.00%, 100.00%, and 1.00, respectively on the TCGA database. On the KMC database, EfficientNetb3 resulted in the optimal choice of the feature extractor giving sensitivity, specificity, F1-score, accuracy, and AUC of 96.97, 98.85, 96.71, 96.71, and 0.99, respectively. The proposed hybrid models showed improvement in accuracy of 2% and 4% over the pre-trained models in TCGA-LIHC and KMC databases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03084v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Deshpande, Deep Gupta, Ankit Bhurane, Nisha Meshram, Sneha Singh, Petia Radeva</dc:creator>
    </item>
    <item>
      <title>tcrLM: a lightweight protein language model for predicting T cell receptor and epitope binding specificity</title>
      <link>https://arxiv.org/abs/2406.16995</link>
      <description>arXiv:2406.16995v2 Announce Type: replace 
Abstract: The anti-cancer immune response relies on the bindings between T-cell receptors (TCRs) and antigens, which elicits adaptive immunity to eliminate tumor cells. This ability of the immune system to respond to novel various neoantigens arises from the immense diversity of TCR repository. However, TCR diversity poses a significant challenge on accurately predicting antigen-TCR bindings. In this study, we introduce a lightweight masked language model, termed tcrLM, to address this challenge. Our approach involves randomly masking segments of TCR sequences and training tcrLM to infer the masked segments, thereby enabling the extraction of expressive features from TCR sequences. To further enhance robustness, we incorporate virtual adversarial training into tcrLM. We construct the largest TCR CDR3 sequence set with more than 100 million distinct sequences, and pretrain tcrLM on these sequences. The pre-trained encoder is subsequently applied to predict TCR-antigen binding specificity. We evaluate model performance on three test datasets: independent, external, and COVID-19 test set. The results demonstrate that tcrLM not only surpasses existing TCR-antigen binding prediction methods, but also outperforms other mainstream protein language models. More interestingly, tcrLM effectively captures the biochemical properties and positional preference of amino acids within TCR sequences. Additionally, the predicted TCR-neoantigen binding scores indicates the immunotherapy responses and clinical outcomes in a melanoma cohort. These findings demonstrate the potential of tcrLM in predicting TCR-antigen binding specificity, with significant implications for advancing immunotherapy and personalized medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16995v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xing Fang, Chenpeng Yu, Shiye Tian, Hui Liu</dc:creator>
    </item>
    <item>
      <title>Entropy and Diversity: The Axiomatic Approach</title>
      <link>https://arxiv.org/abs/2012.02113</link>
      <description>arXiv:2012.02113v4 Announce Type: replace-cross 
Abstract: This book brings new mathematical rigour to the ongoing vigorous debate on how to quantify biological diversity. The question "what is diversity?" has surprising mathematical depth, and breadth too: this book involves parts of mathematics ranging from information theory, functional equations and probability theory to category theory, geometric measure theory and number theory. It applies the power of the axiomatic method to a biological problem of pressing concern, but the new concepts and theorems are also motivated from a purely mathematical perspective.
  The main narrative thread requires no more than an undergraduate course in analysis. No familiarity with entropy or diversity is assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2012.02113v4</guid>
      <category>q-bio.PE</category>
      <category>cs.IT</category>
      <category>math.CA</category>
      <category>math.CT</category>
      <category>math.IT</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Cambridge University Press 2021, ISBN 9781108965576 (paperback), 9781108832700 (hardback)</arxiv:journal_reference>
      <dc:creator>Tom Leinster</dc:creator>
    </item>
    <item>
      <title>Breast Cancer Classification Using Gradient Boosting Algorithms Focusing on Reducing the False Negative and SHAP for Explainability</title>
      <link>https://arxiv.org/abs/2403.09548</link>
      <description>arXiv:2403.09548v2 Announce Type: replace-cross 
Abstract: Cancer is one of the diseases that kill the most women in the world, with breast cancer being responsible for the highest number of cancer cases and consequently deaths. However, it can be prevented by early detection and, consequently, early treatment. Any development for detection or perdition this kind of cancer is important for a better healthy life. Many studies focus on a model with high accuracy in cancer prediction, but sometimes accuracy alone may not always be a reliable metric. This study implies an investigative approach to studying the performance of different machine learning algorithms based on boosting to predict breast cancer focusing on the recall metric. Boosting machine learning algorithms has been proven to be an effective tool for detecting medical diseases. The dataset of the University of California, Irvine (UCI) repository has been utilized to train and test the model classifier that contains their attributes. The main objective of this study is to use state-of-the-art boosting algorithms such as AdaBoost, XGBoost, CatBoost and LightGBM to predict and diagnose breast cancer and to find the most effective metric regarding recall, ROC-AUC, and confusion matrix. Furthermore, our study is the first to use these four boosting algorithms with Optuna, a library for hyperparameter optimization, and the SHAP method to improve the interpretability of our model, which can be used as a support to identify and predict breast cancer. We were able to improve AUC or recall for all the models and reduce the False Negative for AdaBoost and LigthGBM the final AUC were more than 99.41\% for all models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09548v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.4114/intartif.vol28iss75pp63-80</arxiv:DOI>
      <arxiv:journal_reference>Inteligencia Artificial, 28(75) (2025), 63-80</arxiv:journal_reference>
      <dc:creator>Jo\~ao Manoel Herrera Pinheiro, Marcelo Becker</dc:creator>
    </item>
    <item>
      <title>SurvMamba: State Space Model with Multi-grained Multi-modal Interaction for Survival Prediction</title>
      <link>https://arxiv.org/abs/2404.08027</link>
      <description>arXiv:2404.08027v2 Announce Type: replace-cross 
Abstract: Multi-modal learning that combines pathological images with genomic data has significantly enhanced the accuracy of survival prediction. Nevertheless, existing methods have not fully utilized the inherent hierarchical structure within both whole slide images (WSIs) and transcriptomic data, from which better intra-modal representations and inter-modal integration could be derived. Moreover, many existing studies attempt to improve multi-modal representations through attention mechanisms, which inevitably lead to high complexity when processing high-dimensional WSIs and transcriptomic data. Recently, a structured state space model named Mamba emerged as a promising approach for its superior performance in modeling long sequences with low complexity. In this study, we propose Mamba with multi-grained multi-modal interaction (SurvMamba) for survival prediction. SurvMamba is implemented with a Hierarchical Interaction Mamba (HIM) module that facilitates efficient intra-modal interactions at different granularities, thereby capturing more detailed local features as well as rich global representations. In addition, an Interaction Fusion Mamba (IFM) module is used for cascaded inter-modal interactive fusion, yielding more comprehensive features for survival prediction. Comprehensive evaluations on five TCGA datasets demonstrate that SurvMamba outperforms other existing methods in terms of performance and computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08027v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 05 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Chen, Jiajing Xie, Yuxiang Lin, Yuhang Song, Wenxian Yang, Rongshan Yu</dc:creator>
    </item>
  </channel>
</rss>
