<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jan 2025 05:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Generalized Linear Models with 1-Bit Measurements: Asymptotics of the Maximum Likelihood Estimator</title>
      <link>https://arxiv.org/abs/2501.04937</link>
      <description>arXiv:2501.04937v1 Announce Type: new 
Abstract: This work establishes regularity conditions for consistency and asymptotic normality of the multiple parameter maximum likelihood estimator(MLE) from censored data, where the censoring mechanism is in the form of $1$-bit measurements. The underlying distribution of the uncensored data is assumed to belong to the exponential family, with natural parameters expressed as a linear combination of the predictors, known as generalized linear model (GLM). As part of the analysis, the Fisher information matrix is also derived for both censored and uncensored data, which helps to quantify the impact of censoring and assess the performance of the MLE. The choice of GLM allows one to consider a variety of practical examples where 1-bit estimation is of interest. In particular, it is shown how the derived results can be used to analyze two practically relevant scenarios: the Gaussian model with both unknown mean and variance, and the Poisson model with an unknown mean.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04937v1</guid>
      <category>math.ST</category>
      <category>cs.SY</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jaimin Shah, Martina Cardone, Cynthia Rush, Alex Dytso</dc:creator>
    </item>
    <item>
      <title>Comparing latent inequality with ordinal data</title>
      <link>https://arxiv.org/abs/2501.05338</link>
      <description>arXiv:2501.05338v1 Announce Type: cross 
Abstract: We propose new ways to compare two latent distributions when only ordinal data are available and without imposing parametric assumptions on the underlying continuous distributions. First, we contribute identification results. We show how certain ordinal conditions provide evidence of between-group inequality, quantified by particular quantiles being higher in one latent distribution than in the other. We also show how other ordinal conditions provide evidence of higher within-group inequality in one distribution than in the other, quantified by particular interquantile ranges being wider in one latent distribution than in the other. Second, we propose an "inner" confidence set for the quantiles that are higher for the first latent distribution. We also describe frequentist and Bayesian inference on features of the ordinal distributions relevant to our identification results. Our contributions are illustrated by empirical examples with mental health and general health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05338v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/ectj/utac030</arxiv:DOI>
      <arxiv:journal_reference>The Econometrics Journal 26 (2023) 189-214</arxiv:journal_reference>
      <dc:creator>David M. Kaplan, Wei Zhao</dc:creator>
    </item>
    <item>
      <title>Entangled Mean Estimation in High-Dimensions</title>
      <link>https://arxiv.org/abs/2501.05425</link>
      <description>arXiv:2501.05425v1 Announce Type: cross 
Abstract: We study the task of high-dimensional entangled mean estimation in the subset-of-signals model. Specifically, given $N$ independent random points $x_1,\ldots,x_N$ in $\mathbb{R}^D$ and a parameter $\alpha \in (0, 1)$ such that each $x_i$ is drawn from a Gaussian with mean $\mu$ and unknown covariance, and an unknown $\alpha$-fraction of the points have identity-bounded covariances, the goal is to estimate the common mean $\mu$. The one-dimensional version of this task has received significant attention in theoretical computer science and statistics over the past decades. Recent work [LY20; CV24] has given near-optimal upper and lower bounds for the one-dimensional setting. On the other hand, our understanding of even the information-theoretic aspects of the multivariate setting has remained limited.
  In this work, we design a computationally efficient algorithm achieving an information-theoretically near-optimal error. Specifically, we show that the optimal error (up to polylogarithmic factors) is $f(\alpha,N) + \sqrt{D/(\alpha N)}$, where the term $f(\alpha,N)$ is the error of the one-dimensional problem and the second term is the sub-Gaussian error rate. Our algorithmic approach employs an iterative refinement strategy, whereby we progressively learn more accurate approximations $\hat \mu$ to $\mu$. This is achieved via a novel rejection sampling procedure that removes points significantly deviating from $\hat \mu$, as an attempt to filter out unusually noisy samples. A complication that arises is that rejection sampling introduces bias in the distribution of the remaining points. To address this issue, we perform a careful analysis of the bias, develop an iterative dimension-reduction strategy, and employ a novel subroutine inspired by list-decodable learning that leverages the one-dimensional result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05425v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Thanasis Pittas</dc:creator>
    </item>
    <item>
      <title>Learning cross-layer dependence structure in multilayer networks</title>
      <link>https://arxiv.org/abs/2307.14982</link>
      <description>arXiv:2307.14982v2 Announce Type: replace 
Abstract: We propose a novel class of separable multilayer network models to capture cross-layer dependencies in multilayer networks, enabling the analysis of how interactions in one or more layers may influence interactions in other layers. Our approach separates the network formation process from the layer formation process, and is able to extend existing single-layer network models to multilayer network models that accommodate cross-layer dependence. We establish non-asymptotic and minimax-optimal error bounds for maximum likelihood estimators and demonstrate the convergence rate in scenarios of increasing parameter dimension. Additionally, we establish non-asymptotic error bounds for multivariate normal approximations and propose a model selection method that controls the false discovery rate. Simulation studies and an application to the Lazega lawyers network show that our framework and method perform well in realistic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14982v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaheng Li, Jonathan R. Stewart</dc:creator>
    </item>
    <item>
      <title>Sequentializing a Test: Anytime Validity is Free</title>
      <link>https://arxiv.org/abs/2501.03982</link>
      <description>arXiv:2501.03982v2 Announce Type: replace 
Abstract: An anytime valid sequential test permits us to peek at observations as they arrive. This means we can stop, continue or adapt the testing process based on the current data, without invalidating the inference. Given a maximum number of observations $N$, one may believe that this benefit must be paid for in terms of power when compared to a conventional test that waits until all $N$ observations have arrived. Our key contribution is to show that this is false: for any valid test based on $N$ observations, we derive an anytime valid sequential test that matches it after $N$ observations. In addition, we show that the value of the sequential test before a rejection is attained can be directly used as a significance level for a subsequent test. We illustrate this for the $z$-test. There, we find that the current state-of-the-art based on log-optimal $e$-values can be obtained as a special limiting case that replicates a $z$-test with level $\alpha \to 0$ as $N \to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03982v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nick W. Koning, Sam van Meer</dc:creator>
    </item>
    <item>
      <title>Asymptotic Expansions of the Limit Laws of Gaussian and Laguerre (Wishart) Ensembles at the Soft Edge</title>
      <link>https://arxiv.org/abs/2403.07628</link>
      <description>arXiv:2403.07628v4 Announce Type: replace-cross 
Abstract: The large-matrix limit laws of the rescaled largest eigenvalue of the orthogonal, unitary, and symplectic $n$-dimensional Gaussian ensembles -- and of the corresponding Laguerre ensembles (Wishart distributions) for various regimes of the parameter $\alpha$ (degrees of freedom $p$) -- are known to be the Tracy-Widom distributions $F_\beta$ ($\beta=1,2,4$). We establish (paying particular attention to large or small ratios $p/n$) that, with careful choices of the rescaling constants and of the expansion parameter $h$, the limit laws embed into asymptotic expansions in powers of $h$, where $h \asymp n^{-2/3}$ resp. $h \asymp (n\,\wedge\,p)^{-2/3}$. We find explicit analytic expressions of the first few expansion terms as linear combinations of higher-order derivatives of the limit law $F_\beta$ with rational polynomial coefficients. The parametrizations are fine-tuned so that the expansion coefficients in the Gaussian cases are, for given $n$, the limits $p\to\infty$ of those of the Laguerre cases. Whereas the results for $\beta=2$ are presented with proof, the discussion of the cases $\beta=1,4$ is based on some hypotheses, focusing on the algebraic aspects of actually computing the polynomial coefficients. For the purposes of illustration and validation, the various results are checked against simulation data with large sample sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07628v4</guid>
      <category>math.PR</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Folkmar Bornemann</dc:creator>
    </item>
  </channel>
</rss>
