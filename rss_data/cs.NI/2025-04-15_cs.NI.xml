<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Apr 2025 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Introducing Large Language Models as the Next Challenging Internet Traffic Source</title>
      <link>https://arxiv.org/abs/2504.10688</link>
      <description>arXiv:2504.10688v1 Announce Type: new 
Abstract: This article explores the growing impact of large language models (LLMs) and Generative AI (GenAI) tools on Internet traffic, focusing on their role as a new and significant source of network load. As these AI tools continue to gain importance in applications ranging from virtual assistants to content generation, the volume of traffic they generate is expected to increase massively. These models use the Internet as the global infrastructure for delivering multimedia messages (text, voice, images, video, etc.) to users, by interconnecting users and devices with AI agents typically deployed in the cloud. We believe this represents a new paradigm that will lead to a considerable increase in network traffic, and network operators must be prepared to address the resulting demands. To support this claim, we provide a proof-of-concept and source code for measuring traffic in remote user-agent interactions, estimating the traffic generated per prompt for some of the most popular open-source LLMs in 2025. The average size of each prompt query and response is 7,593 bytes, with a standard deviation of 369 bytes. These numbers are comparable with email and web browsing traffic. However, we envision AI as the next ``killer application" that will saturate networks with traffic, such as Peer-to-Peer traffic and Video-on-demand dominated in previous decades.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10688v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nataliia Koneva, Alejandro Leonardo Garc\'ia Navarro, Alfonso S\'anchez-Maci\'an, Jos\'e Alberto Hern\'andez, Moshe Zukerman, \'Oscar Gonz\'alez de Dios</dc:creator>
    </item>
    <item>
      <title>AutoRAN: Automated and Zero-Touch Open RAN Systems</title>
      <link>https://arxiv.org/abs/2504.11233</link>
      <description>arXiv:2504.11233v1 Announce Type: new 
Abstract: [...] This paper presents AutoRAN, an automated, intent-driven framework for zero-touch provisioning of open, programmable cellular networks. Leveraging cloud-native principles, AutoRAN employs virtualization, declarative infrastructure-as-code templates, and disaggregated micro-services to abstract physical resources and protocol stacks. Its orchestration engine integrates Language Models (LLMs) to translate high-level intents into machine-readable configurations, enabling closed-loop control via telemetry-driven observability. Implemented on a multi-architecture OpenShift cluster with heterogeneous compute (x86/ARM CPUs, NVIDIA GPUs) and multi-vendor Radio Access Network (RAN) hardware (Foxconn, NI), AutoRAN automates deployment of O-RAN-compliant stacks-including OpenAirInterface, NVIDIA ARC RAN, Open5GS core, and O-RAN Software Community (OSC) RIC components-using CI/CD pipelines. Experimental results demonstrate that AutoRAN is capable of deploying an end-to-end Private 5G network in less than 60 seconds with 1.6 Gbps throughput, validating its ability to streamline configuration, accelerate testing, and reduce manual intervention with similar performance than non cloud-based implementations. With its novel LLM-assisted intent translation mechanism, and performance-optimized automation workflow for multi-vendor environments, AutoRAN has the potential of advancing the robustness of next-generation cellular supply chains through reproducible, intent-based provisioning across public and private deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11233v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefano Maxenti, Ravis Shirkhani, Maxime Elkael, Leonardo Bonati, Salvatore D'Oro, Tommaso Melodia, Michele Polese</dc:creator>
    </item>
    <item>
      <title>A Mathematical Framework of Semantic Communication based on Category Theory</title>
      <link>https://arxiv.org/abs/2504.11334</link>
      <description>arXiv:2504.11334v1 Announce Type: new 
Abstract: While semantic communication (SemCom) has recently demonstrated great potential to enhance transmission efficiency and reliability by leveraging machine learning (ML) and knowledge base (KB), there is a lack of mathematical modeling to rigorously characterize SemCom system and quantify the performance gain obtained from ML and KB. In this paper, we develop a mathematical framework for SemCom based on category theory, rigorously model the concepts of semantic entities and semantic probability space. Within this framework, semantic entropy is introduced to quantify the uncertainty of semantic entities. We theoretically prove that semantic entropy can be effectively reduced by exploiting KB, which capture semantic dependencies. Specifically, semantic entities can be combined based on semantic ambiguity, and are encoded based on contextual relationships among them. Then we refine semantic channel capacity modeling, which considers the mutual information contained in KB to better reflect SemCom efficiency. Numerical simulations validate the effectiveness of the proposed framework, showing that SemCom with KB integration outperforms traditional communication in both entropy reduction and coding efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11334v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuheng Hua, Yao Sun, Kairong Ma, Muhammad Ali Imran</dc:creator>
    </item>
    <item>
      <title>A Quantum Advantage in Localizing Transmission Loss Change in Optical Networks</title>
      <link>https://arxiv.org/abs/2504.10882</link>
      <description>arXiv:2504.10882v1 Announce Type: cross 
Abstract: The ability to localize transmission loss change to a subset of links in optical networks is crucial for maintaining network reliability, performance and security. \emph{Quantum probes}, implemented by sending blocks of $n$ coherent-state pulses augmented with continuous-variable (CV) squeezing ($n=1$) or weak temporal-mode entanglement ($n&gt;1$) over a lossy channel to a receiver with homodyne detection capabilities, are known to be more sensitive than their quasi-classical counterparts in detecting a sudden increase in channel loss. The enhanced sensitivity can be characterized by the increased Kullback-Leibler (KL) divergence of the homodyne output, before and after the loss change occurs. When combined with the theory of quickest change detection (QCD), the increase in KL divergence translates into a decrease in detection latency.
  In this work, we first revisit quantum probes over a channel, generalizing previous results on $n=1$ (CV squeezed states) to arbitrary values of $n$. Assuming a subset of nodes in an optical network is capable of sending and receiving such probes through intermediate nodes with all-optical switching capabilities, we present a scheme for quickly detecting the links that have suffered a sudden drop in transmissivity. Since quantum probes lose their sensitivity with increasing loss in the channel, we first propose a probe construction algorithm that makes the set of links suffering transmission loss change identifiable, while minimizing the longest distance a probe traverses. We then introduce new cumulative sum (CUSUM) statistics with a stopping rule, which allows us to run the CUSUM algorithm to quickly localize the lossy links using our constructed probes. Finally, we show that the proposed scheme achieves a quantum advantage in decreasing the detection delay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10882v1</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufei Zheng, Yu-Zhen Janice Chen, Prithwish Basu, Don Towsley</dc:creator>
    </item>
    <item>
      <title>Reconstructing Fine-Grained Network Data using Autoencoder Architectures with Domain Knowledge Penalties</title>
      <link>https://arxiv.org/abs/2504.11255</link>
      <description>arXiv:2504.11255v1 Announce Type: cross 
Abstract: The ability to reconstruct fine-grained network session data, including individual packets, from coarse-grained feature vectors is crucial for improving network security models. However, the large-scale collection and storage of raw network traffic pose significant challenges, particularly for capturing rare cyberattack samples. These challenges hinder the ability to retain comprehensive datasets for model training and future threat detection. To address this, we propose a machine learning approach guided by formal methods to encode and reconstruct network data. Our method employs autoencoder models with domain-informed penalties to impute PCAP session headers from structured feature representations. Experimental results demonstrate that incorporating domain knowledge through constraint-based loss terms significantly improves reconstruction accuracy, particularly for categorical features with session-level encodings. By enabling efficient reconstruction of detailed network sessions, our approach facilitates data-efficient model training while preserving privacy and storage efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11255v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Cheung, Sridhar Venkatesan</dc:creator>
    </item>
    <item>
      <title>Advanced Architectures Integrated with Agentic AI for Next-Generation Wireless Networks</title>
      <link>https://arxiv.org/abs/2502.01089</link>
      <description>arXiv:2502.01089v2 Announce Type: replace 
Abstract: This paper investigates a range of cutting-edge technologies and architectural innovations aimed at simplifying network operations, reducing operational expenditure (OpEx), and enabling the deployment of new service models. The focus is on (i) Proposing novel, more efficient 6G architectures, with both Control and User planes enabling the seamless expansion of services, while addressing long-term 6G network evolution. (ii) Exploring advanced techniques for constrained artificial intelligence (AI) operations, particularly the design of AI agents for real-time learning, optimizing energy consumption, and the allocation of computational resources. (iii) Identifying technologies and architectures that support the orchestration of backend services using serverless computing models across multiple domains, particularly for vertical industries. (iv) Introducing optically-based, ultra-high-speed, low-latency network architectures, with fast optical switching and real-time control, replacing conventional electronic switching to reduce power consumption by an order of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01089v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kapal Dev, Sunder Ali Khowaja, Keshav Singh, Engin Zeydan, Merouane Debbah</dc:creator>
    </item>
    <item>
      <title>O-RAN xApps Conflict Management using Graph Convolutional Networks</title>
      <link>https://arxiv.org/abs/2503.03523</link>
      <description>arXiv:2503.03523v2 Announce Type: replace 
Abstract: The lack of a unified mechanism to coordinate and prioritize the actions of different applications can create three types of conflicts (direct, indirect, and implicit). Conflict management in O-RAN refers to the process of identifying and resolving conflicts between network applications. In our paper, we introduce a novel data-driven GCN-based method called GRAPH-based Intelligent xApp Conflict Prediction and Analysis (GRAPHICA) based on Graph Convolutional Network (GCN). It predicts three types of conflicts (direct, indirect, and implicit) and pinpoints the root causes (xApps). GRAPHICA captures the complex and hidden dependencies among the xApps, controlled parameters, and KPIs in O-RAN to predict possible conflicts. Then, it identifies the root causes (xApps) contributing to the predicted conflicts. The proposed method was tested on highly imbalanced synthesized datasets where conflict instances range from 40% to 10%. The model is tested in a setting that simulates real-world scenarios where conflicts are rare to assess its performance. Experimental results demonstrate a high F1-score over 98% for the synthesized datasets with different levels of class imbalance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.03523v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maryam Al Shami, Jun Yan, Emmanuel Thepie Fapi</dc:creator>
    </item>
    <item>
      <title>Deep Learning Based Service Composition in Integrated Aerial-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2504.07528</link>
      <description>arXiv:2504.07528v2 Announce Type: replace 
Abstract: The explosive growth of user devices and emerging applications is driving unprecedented traffic demands, accompanied by stringent Quality of Service (QoS) requirements. Addressing these challenges necessitates innovative service orchestration methods capable of seamless integration across the edge-cloud continuum. Terrestrial network-based service orchestration methods struggle to deliver timely responses to growing traffic demands or support users with poor or lack of access to terrestrial infrastructure. Exploiting both aerial and terrestrial resources in service composition increases coverage and facilitates the use of full computing and communication potentials. This paper proposes a service placement and composition mechanism for integrated aerial-terrestrial networks over the edge-cloud continuum while considering the dynamic nature of the network. The service function placement and service orchestration are modeled in an optimization framework. Considering the dynamicity, the Aerial Base Station (ABS) trajectory might not be deterministic, and their mobility pattern might not be known as assumed knowledge. Also, service requests can traverse through access nodes due to users' mobility. By incorporating predictive algorithms, including Deep Reinforcement Learning (DRL) approaches, the proposed method predicts ABS locations and service requests. Subsequently, a heuristic isomorphic graph matching approach is proposed to enable efficient, latency-aware service orchestration. Simulation results demonstrate the efficiency of the proposed prediction and service composition schemes in terms of accuracy, cost optimization, scalability, and responsiveness, ensuring timely and reliable service delivery under diverse network conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07528v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Farhoudi, Masoud Shokrnezhad, Somayeh Kianpisheh, Tarik Taleb</dc:creator>
    </item>
    <item>
      <title>RoboComm: A DID-based scalable and privacy-preserving Robot-to-Robot interaction over state channels</title>
      <link>https://arxiv.org/abs/2504.09517</link>
      <description>arXiv:2504.09517v2 Announce Type: replace 
Abstract: In a multi robot system establishing trust amongst untrusted robots from different organisations while preserving a robot's privacy is a challenge. Recently decentralized technologies such as smart contract and blockchain are being explored for applications in robotics. However, the limited transaction processing and high maintenance cost hinder the widespread adoption of such approaches. Moreover, blockchain transactions be they on public or private permissioned blockchain are publically readable which further fails to preserve the confidentiality of the robot's data and privacy of the robot.
  In this work, we propose RoboComm a Decentralized Identity based approach for privacy-preserving interaction between robots. With DID a component of Self-Sovereign Identity; robots can authenticate each other independently without relying on any third-party service. Verifiable Credentials enable private data associated with a robot to be stored within the robot's hardware, unlike existing blockchain based approaches where the data has to be on the blockchain. We improve throughput by allowing message exchange over state channels. Being a blockchain backed solution RoboComm provides a trustworthy system without relying on a single party. Moreover, we implement our proposed approach to demonstrate the feasibility of our solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.09517v2</guid>
      <category>cs.NI</category>
      <category>cs.RO</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roshan Singh, Sushant Pandey</dc:creator>
    </item>
    <item>
      <title>Toward Intelligent and Secure Cloud: Large Language Model Empowered Proactive Defense</title>
      <link>https://arxiv.org/abs/2412.21051</link>
      <description>arXiv:2412.21051v2 Announce Type: replace-cross 
Abstract: The rapid evolution of cloud computing technologies and the increasing number of cloud applications have provided a large number of benefits in daily lives. However, the diversity and complexity of different components pose a significant challenge to cloud security, especially when dealing with sophisticated and advanced cyberattacks. Recent advancements in generative foundation models (GFMs), particularly in the large language models (LLMs), offer promising solutions for security intelligence. By exploiting the powerful abilities in language understanding, data analysis, task inference, action planning, and code generation, we present LLM-PD, a novel proactive defense architecture that defeats various threats in a proactive manner. LLM-PD can efficiently make a decision through comprehensive data analysis and sequential reasoning, as well as dynamically creating and deploying actionable defense mechanisms on the target cloud. Furthermore, it can flexibly self-evolve based on experience learned from previous interactions and adapt to new attack scenarios without additional training. The experimental results demonstrate its remarkable ability in terms of defense effectiveness and efficiency, particularly highlighting an outstanding success rate when compared with other existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21051v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 16 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Zhou, Guang Cheng, Kang Du, Zihan Chen, Yuyu Zhao</dc:creator>
    </item>
  </channel>
</rss>
