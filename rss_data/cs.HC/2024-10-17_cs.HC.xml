<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 17 Oct 2024 04:01:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>From Commands to Prompts: LLM-based Semantic File System for AIOS</title>
      <link>https://arxiv.org/abs/2410.11843</link>
      <description>arXiv:2410.11843v1 Announce Type: new 
Abstract: Large language models (LLMs) have demonstrated significant potential in the development of intelligent applications and systems such as LLM-based agents and agent operating systems (AIOS). However, when these applications and systems interact with the underlying file system, the file system still remains the traditional paradigm: reliant on manual navigation through precise commands. This paradigm poses a bottleneck to the usability of these systems as users are required to navigate complex folder hierarchies and remember cryptic file names. To address this limitation, we propose an LLM-based semantic file system ( LSFS ) for prompt-driven file management. Unlike conventional approaches, LSFS incorporates LLMs to enable users or agents to interact with files through natural language prompts, facilitating semantic file management. At the macro-level, we develop a comprehensive API set to achieve semantic file management functionalities, such as semantic file retrieval, file update monitoring and summarization, and semantic file rollback). At the micro-level, we store files by constructing semantic indexes for them, design and implement syscalls of different semantic operations (e.g., CRUD, group by, join) powered by vector database. Our experiments show that LSFS offers significant improvements over traditional file systems in terms of user convenience, the diversity of supported functions, and the accuracy and efficiency of file operations. Additionally, with the integration of LLM, our system enables more intelligent file management tasks, such as content summarization and version comparison, further enhancing its capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11843v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeru Shi, Kai Mei, Mingyu Jin, Yongye Su, Chaoji Zuo, Wenyue Hua, Wujiang Xu, Yujie Ren, Zirui Liu, Mengnan Du, Dong Deng, Yongfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Malak: AI-based multilingual personal assistant to combat misinformation and generative AI safety issues</title>
      <link>https://arxiv.org/abs/2410.11856</link>
      <description>arXiv:2410.11856v1 Announce Type: new 
Abstract: The widespread use of AI technologies to generate digital content has led to increased misinformation and online harm. Deep fake technologies, a type of AI, make it easier to create convincing but fake content on social media, leading to various cyber threats. Malicious actors exploit AI capabilities, posing digital, physical, and psychological harm to individuals. While social media platforms have safety measures such as content rating and feedback systems, these are often used by people with higher digital literacy. There is a lack of preventive measures and a need for user-friendly tools that can be used by people with lower digital literacy. Our goal is to create a user-friendly multilingual AI-based personal assistant, Malak, to reduce online harm and promote safe online interactions, benefiting users with lower literacy levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11856v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farnaz Farid, Farhad Ahamed</dc:creator>
    </item>
    <item>
      <title>SouLLMate: An Adaptive LLM-Driven System for Advanced Mental Health Support and Assessment, Based on a Systematic Application Survey</title>
      <link>https://arxiv.org/abs/2410.11859</link>
      <description>arXiv:2410.11859v1 Announce Type: new 
Abstract: Mental health issues significantly impact individuals' daily lives, yet many do not receive the help they need even with available online resources. This study aims to provide accessible, stigma-free, personalized, and real-time mental health support through cutting-edge AI technologies. It makes the following contributions: (1) Conducting an extensive survey of recent mental health support methods to identify prevalent functionalities and unmet needs. (2) Introducing SouLLMate, an adaptive LLM-driven system that integrates LLM technologies, Chain, Retrieval-Augmented Generation (RAG), prompt engineering, and domain knowledge. This system offers advanced features such as Suicide Risk Detection and Proactive Guidance Dialogue, and utilizes RAG for personalized profile uploads and Conversational Information Extraction. (3) Developing novel evaluation approaches to assess preliminary assessments and suicide risk detection, utilizing annotated real-life interview data and professionally labeled datasets indicating suicide tendencies. (4) Proposing Key Indicator Summarization (KIS) and Proactive Questioning Strategy (PQS) methods to enhance model performance and usability through context-sensitive response adjustments and semantic coherence evaluations. This study contributes to advancing mental health support technologies, potentially improving the accessibility and effectiveness of mental health care globally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11859v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiming Guo, Jinwen Tang, Wenbo Sun, Haoteng Tang, Yi Shang, Wenlu Wang</dc:creator>
    </item>
    <item>
      <title>Comparing Zealous and Restrained AI Recommendations in a Real-World Human-AI Collaboration Task</title>
      <link>https://arxiv.org/abs/2410.11860</link>
      <description>arXiv:2410.11860v1 Announce Type: new 
Abstract: When designing an AI-assisted decision-making system, there is often a tradeoff between precision and recall in the AI's recommendations. We argue that careful exploitation of this tradeoff can harness the complementary strengths in the human-AI collaboration to significantly improve team performance. We investigate a real-world video anonymization task for which recall is paramount and more costly to improve. We analyze the performance of 78 professional annotators working with a) no AI assistance, b) a high-precision "restrained" AI, and c) a high-recall "zealous" AI in over 3,466 person-hours of annotation work. In comparison, the zealous AI helps human teammates achieve significantly shorter task completion time and higher recall. In a follow-up study, we remove AI assistance for everyone and find negative training effects on annotators trained with the restrained AI. These findings and our analysis point to important implications for the design of AI assistance in recall-demanding scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11860v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3544548.3581282</arxiv:DOI>
      <arxiv:journal_reference>In Proceedings of the 2023 CHI Conference on Human Factors in Computing Systems. Association for Computing Machinery, New York, NY, USA, Article 350, 1 15</arxiv:journal_reference>
      <dc:creator>Chengyuan Xu, Kuo-Chin Lien, Tobias H\"ollerer</dc:creator>
    </item>
    <item>
      <title>Investigating Role of Big Five Personality Traits in Audio-Visual Rapport Estimation</title>
      <link>https://arxiv.org/abs/2410.11861</link>
      <description>arXiv:2410.11861v1 Announce Type: new 
Abstract: Automatic rapport estimation in social interactions is a central component of affective computing. Recent reports have shown that the estimation performance of rapport in initial interactions can be improved by using the participant's personality traits as the model's input. In this study, we investigate whether this findings applies to interactions between friends by developing rapport estimation models that utilize nonverbal cues (audio and facial expressions) as inputs. Our experimental results show that adding Big Five features (BFFs) to nonverbal features can improve the estimation performance of self-reported rapport in dyadic interactions between friends. Next, we demystify how BFFs improve the estimation performance of rapport through a comparative analysis between models with and without BFFs. We decompose rapport ratings into perceiver effects (people's tendency to rate other people), target effects (people's tendency to be rated by other people), and relationship effects (people's unique ratings for a specific person) using the social relations model. We then analyze the extent to which BFFs contribute to capturing each effect. Our analysis demonstrates that the perceiver's and the target's BFFs lead estimation models to capture the perceiver and the target effects, respectively. Furthermore, our experimental results indicate that the combinations of facial expression features and BFFs achieve best estimation performances not only in estimating rapport ratings, but also in estimating three effects. Our study is the first step toward understanding why personality-aware estimation models of interpersonal perception accomplish high estimation performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11861v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takato Hayashi, Ryusei Kimura, Ryo Ishii, Shogo Okada</dc:creator>
    </item>
    <item>
      <title>ChatVis: Automating Scientific Visualization with a Large Language Model</title>
      <link>https://arxiv.org/abs/2410.11863</link>
      <description>arXiv:2410.11863v1 Announce Type: new 
Abstract: We develop an iterative assistant we call ChatVis that can synthetically generate Python scripts for data analysis and visualization using a large language model (LLM). The assistant allows a user to specify the operations in natural language, attempting to generate a Python script for the desired operations, prompting the LLM to revise the script as needed until it executes correctly. The iterations include an error detection and correction mechanism that extracts error messages from the execution of the script and subsequently prompts LLM to correct the error. Our method demonstrates correct execution on five canonical visualization scenarios, comparing results with ground truth. We also compared our results with scripts generated by several other LLMs without any assistance. In every instance, ChatVis successfully generated the correct script, whereas the unassisted LLMs failed to do so. The code is available on GitHub: https://github.com/tanwimallick/ChatVis/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11863v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanwi Mallick, Orcun Yildiz, David Lenz, Tom Peterka</dc:creator>
    </item>
    <item>
      <title>Shifting the Human-AI Relationship: Toward a Dynamic Relational Learning-Partner Model</title>
      <link>https://arxiv.org/abs/2410.11864</link>
      <description>arXiv:2410.11864v1 Announce Type: new 
Abstract: As artificial intelligence (AI) continues to evolve, the current paradigm of treating AI as a passive tool no longer suffices. As a human-AI team, we together advocate for a shift toward viewing AI as a learning partner, akin to a student who learns from interactions with humans. Drawing from interdisciplinary concepts such as ecorithms, order from chaos, and cooperation, we explore how AI can evolve and adapt in unpredictable environments. Arising from these brief explorations, we present two key recommendations: (1) foster ethical, cooperative treatment of AI to benefit both humans and AI, and (2) leverage the inherent heterogeneity between human and AI minds to create a synergistic hybrid intelligence. By reframing AI as a dynamic partner, a model emerges in which AI systems develop alongside humans, learning from human interactions and feedback loops including reflections on team conversations. Drawing from a transpersonal and interdependent approach to consciousness, we suggest that a "third mind" emerges through collaborative human-AI relationships. Through design interventions such as interactive learning and conversational debriefing and foundational interventions allowing AI to model multiple types of minds, we hope to provide a path toward more adaptive, ethical, and emotionally healthy human-AI relationships. We believe this dynamic relational learning-partner (DRLP) model for human-AI teaming, if enacted carefully, will improve our capacity to address powerful solutions to seemingly intractable problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11864v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Mossbridge</dc:creator>
    </item>
    <item>
      <title>An Innovative Solution: AI-Based Digital Screen-Integrated Tables for Educational Settings</title>
      <link>https://arxiv.org/abs/2410.11866</link>
      <description>arXiv:2410.11866v1 Announce Type: new 
Abstract: In this paper, we have gone through different AI-Based frameworks used for various educational tasks like digital customized assignment allotment and performance monitoring, identifying slow-learners and fast-learners, etc. application describes a novel invention, digital screen-integrated tables, designed specifically for educational settings. The tables feature integrated digital screens controlled by a central processing unit (CPU), enabling synchronized display of educational content such as textbooks, presentations, exam questions, and interactive learning materials. Additionally, the invention facilitates the collection of student performance data during classroom activities and assessments. The gathered data is utilized for analysis using machine learning models to identify patterns and trends in student learning behaviours. By leveraging machine learning algorithms, educators can ascertain whether a student is a fast learner or a slow learner, based on which, the teacher can allocate more resources to the slow learners. This innovative approach aims to address the evolving needs of modern classrooms by providing a dynamic and data-driven learning environment. The unique integration of digital screens into traditional classroom furniture represents a significant advancement in educational technology. This patent filing encompasses the design, functionality, and method of operation of the digital screen-integrated tables, emphasizing their innovative features and applications in educational institutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11866v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.13140/RG.2.2.36260.49286</arxiv:DOI>
      <dc:creator>S. Tamang, D. J. Bora</dc:creator>
    </item>
    <item>
      <title>Neural Signal Operated Intelligent Robot: Human-guided Robot Maze Navigation through SSVEP</title>
      <link>https://arxiv.org/abs/2410.11867</link>
      <description>arXiv:2410.11867v1 Announce Type: new 
Abstract: Brain-computer Interface (BCI) applications based on steady-state visual evoked potentials (SSVEP) have the advantages of being fast, accurate and mobile. SSVEP is the EEG response evoked by visual stimuli that are presented at a specific frequency, which results in an increase in the EEG at that same frequency. In this paper, we proposed a novel human-guided maze solving robot navigation system based on SSVEP. By integrating human's intelligence which sees the entirety of the maze, maze solving time could be significantly reduced. Our methods involve training an offline SSVEP classification model, implementing the robot self-navigation algorithm, and finally deploy the model online for real-time robot operation. Our results demonstrated such system to be feasible, and it has the potential to impact the life of many elderly people by helping them carrying out simple daily tasks at home with just the look of their eyes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11867v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiarui Tang, Tingrui Sun, Siwen Wang</dc:creator>
    </item>
    <item>
      <title>Systematic Literature Review of Using Virtual Reality as a Social Platform in HCI Community</title>
      <link>https://arxiv.org/abs/2410.11869</link>
      <description>arXiv:2410.11869v1 Announce Type: new 
Abstract: Virtual reality (VR) is increasingly used as a social platform for users to interact and build connections with one another in an immersive virtual environment. Reflecting on the empirical progress in this area of study, a comprehensive review of how VR could be used to support social interaction is required to consolidate existing practices and identify research gaps to inspire future studies. In this work, we conducted a systematic review of 94 publications in the HCI field to examine how VR is designed and evaluated for social purposes. We found that VR influences social interaction through self-representation, interpersonal interactions, and interaction environments. We summarized four positive effects of using VR for socializing, which are relaxation, engagement, intimacy, and accessibility, and showed that it could also negatively affect user social experiences by intensifying harassment experiences and amplifying privacy concerns. We introduce an evaluation framework that outlines the key aspects of social experience: intrapersonal, interpersonal, and interaction experiences. According to the results, we uncover several research gaps and propose future directions for designing and developing VR to enhance social experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11869v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoying Wei, Xiaofu Jin, Ge Lin Kan, Yukang Yan, Mingming Fan</dc:creator>
    </item>
    <item>
      <title>TinyClick: Single-Turn Agent for Empowering GUI Automation</title>
      <link>https://arxiv.org/abs/2410.11871</link>
      <description>arXiv:2410.11871v1 Announce Type: new 
Abstract: We present a single-turn agent for graphical user interface (GUI) interaction tasks, using Vision-Language Model Florence-2-Base. Main goal of the agent is to click on desired UI element based on the screenshot and user command. It demonstrates strong performance on Screenspot and OmniAct, while maintaining a compact size of 0.27B parameters and minimal latency. Main improvement comes from multitask training and MLLM-based data augmentation. Manually annotated corpora are scarce, but we show that re-annotation of annotated data with MLLM for multitask training might produce much better result. On Screenspot and OmniAct, our model outperforms both GUI-specific models (e.g., SeeClick) and MLLMs (e.g., GPT-4V).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11871v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawel Pawlowski, Krystian Zawistowski, Wojciech Lapacz, Marcin Skorupa, Adam Wiacek, Sebastien Postansque, Jakub Hoscilowicz</dc:creator>
    </item>
    <item>
      <title>Enhancing UI Location Capabilities of Autonomous Agents</title>
      <link>https://arxiv.org/abs/2410.11872</link>
      <description>arXiv:2410.11872v1 Announce Type: new 
Abstract: With the growing reliance on digital devices equipped with graphical user interfaces (GUIs), such as computers and smartphones, the need for effective automation tools has become increasingly important. Although multimodal large language models (MLLMs) like GPT-4V excel at tasks such as drafting emails, they struggle with GUI interactions, which limits their effectiveness in automating everyday tasks. In this paper, we introduce ClickAgent, a novel framework for building autonomous agents. In ClickAgent, the MLLM handles reasoning and action planning, while a separate UI location model (e.g., SeeClick) identifies the relevant UI elements on the screen. This approach addresses a key limitation of current-generation MLLMs: their difficulty in accurately locating UI elements.
  ClickAgent significantly outperforms other prompt-based autonomous agents (such as CogAgent, AppAgent, and Auto-UI) on the AITW benchmark. Our evaluation was conducted on both an Android smartphone emulator and an actual Android smartphone, using the task success rate as the key metric for measuring agent performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11872v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakub Hoscilowicz, Bartosz Maj, Bartosz Kozakiewicz, Oleksii Tymoschuk, Artur Janicki</dc:creator>
    </item>
    <item>
      <title>GazeGenie: Enhancing Multi-Line Reading Research with an Innovative User-Friendly Tool</title>
      <link>https://arxiv.org/abs/2410.11873</link>
      <description>arXiv:2410.11873v1 Announce Type: new 
Abstract: In the study of reading, eye-tracking technology offers unique insights into the time-course of how individuals extract information from text. A significant hurdle in using multi-line paragraph stimuli is the need to align eye gaze position with the correct line. This is made more difficult by positional noise in the eye-tracking data, primarily due to vertical drift, and often necessitates manual intervention. Such manual correction is labor-intensive, subjective, and limits the scalability of research efforts. As a result, automated solutions are desirable, especially those that do not require extensive technical skills and still allow close control over the outcome. To address this, we introduce GazeGenie: a comprehensive software solution designed specifically for researchers in eye-tracking studies on multi-line reading. Accessible via an intuitive web browser-based user interface and easily installed using Docker, GazeGenie streamlines the entire data processing pipeline from parsing fixations from raw data to calculation of word and sentence-based measures based on cleaned and drift-corrected fixations. The software's core features include the recently introduced Dual Input Stream Transformer (DIST) model and various classical algorithms all of which can be combined within a Wisdom of the Crowds (WOC) approach to enhance accuracy in fixation line-assignment. By providing an all-in-one solution for researchers, we hope to make automated fixation alignment more accessible, reducing researchers' reliance on manual intervention in vertical fixation alignment. This should lead to more accurate, efficient, and reproducible analyses of multi-line eye-movement data and pave the way to enabling larger scale studies to be carried out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11873v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas M. Mercier, Marcin Budka, Bernhard Angele, Martin R. Vasilev, Timothy J. Slattery, Julie A Kirkby</dc:creator>
    </item>
    <item>
      <title>Rescriber: Smaller-LLM-Powered User-Led Data Minimization for Navigating Privacy Trade-offs in LLM-Based Conversational Agent</title>
      <link>https://arxiv.org/abs/2410.11876</link>
      <description>arXiv:2410.11876v1 Announce Type: new 
Abstract: The proliferation of LLM-based conversational agents has resulted in excessive disclosure of identifiable or sensitive information. However, existing technologies fail to offer perceptible control or account for users' personal preferences about privacy-utility tradeoffs due to the lack of user involvement. To bridge this gap, we designed, built, and evaluated Rescriber, a browser extension that supports user-led data minimization in LLM-based conversational agents by helping users detect and sanitize personal information in their prompts. Our studies (N=12) showed that Rescriber helped users reduce unnecessary disclosure and addressed their privacy concerns. Users' subjective perceptions of the system powered by Llama3-8B were on par with that by GPT-4. The comprehensiveness and consistency of the detection and sanitization emerge as essential factors that affect users' trust and perceived protection. Our findings confirm the viability of smaller-LLM-powered, user-facing, on-device privacy controls, presenting a promising approach to address the privacy and trust challenges of AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11876v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jijie Zhou, Eryue Xu, Yaoyao Wu, Tianshi Li</dc:creator>
    </item>
    <item>
      <title>A Framework for Collaborating a Large Language Model Tool in Brainstorming for Triggering Creative Thoughts</title>
      <link>https://arxiv.org/abs/2410.11877</link>
      <description>arXiv:2410.11877v1 Announce Type: new 
Abstract: Creativity involves not only generating new ideas from scratch but also redefining existing concepts and synthesizing previous insights. Among various techniques developed to foster creative thinking, brainstorming is widely used. With recent advancements in Large Language Models (LLMs), tools like ChatGPT have significantly impacted various fields by using prompts to facilitate complex tasks. While current research primarily focuses on generating accurate responses, there is a need to explore how prompt engineering can enhance creativity, particularly in brainstorming. Therefore, this study addresses this gap by proposing a framework called GPS, which employs goals, prompts, and strategies to guide designers to systematically work with an LLM tool for improving the creativity of ideas generated during brainstorming. Additionally, we adapted the Torrance Tests of Creative Thinking (TTCT) for measuring the creativity of the ideas generated by AI. Our framework, tested through a design example and a case study, demonstrates its effectiveness in stimulating creativity and its seamless LLM tool integration into design practices. The results indicate that our framework can benefit brainstorming sessions with LLM tools, enhancing both the creativity and usefulness of generated ideas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11877v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hung-Fu Chang, Tong Li</dc:creator>
    </item>
    <item>
      <title>Thermal Comfort in Sight: Thermal Affordance and its Visual Assessment for Sustainable Streetscape Design</title>
      <link>https://arxiv.org/abs/2410.11887</link>
      <description>arXiv:2410.11887v1 Announce Type: new 
Abstract: In response to climate change and urban heat island effects, enhancing human thermal comfort in cities is crucial for sustainable urban development. Traditional methods for investigating the urban thermal environment and corresponding human thermal comfort level are often resource intensive, inefficient, and limited in scope. To address these challenges, we (1) introduce the concept of thermal affordance, which represents the inherent capacity of a streetscape to influence human thermal comfort based on its visual and physical features; and (2) a method to evaluate it (visual assessment of thermal affordance -- VATA), which combines street view imagery (SVI), online and in-filed surveys, and statistical learning algorithms. VATA extracts five categories of image features from SVI data and establishes 19 visual-perceptual indicators for streetscape visual assessment. Using a multi-task neural network and elastic net regression, we model their chained relationship to predict and comprehend thermal affordance for Singapore. VATA predictions are validated with field-investigated OTC data, providing a cost-effective and scalable method to assess the thermal comfort potential of urban streetscape. This framework can inform streetscape design to support sustainable, livable, and resilient urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11887v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sijie Yang, Adrian Chong, Pengyuan Liu, Filip Biljecki</dc:creator>
    </item>
    <item>
      <title>Online Digital Investigative Journalism using SociaLens</title>
      <link>https://arxiv.org/abs/2410.11890</link>
      <description>arXiv:2410.11890v1 Announce Type: new 
Abstract: Media companies witnessed a significant transformation with the rise of the internet, bigdata, machine learning (ML) and AI. Recent emergence of large language models (LLM) have added another aspect to this transformation. Researchers believe that with the help of these technologies, investigative digital journalism will enter a new era. Using a smart set of data gathering and analysis tools, journalists will be able to create data driven contents and insights in unprecedented ways. In this paper, we introduce a versatile and autonomous investigative journalism tool, called {\em SociaLens}, for identifying and extracting query specific data from online sources, responding to probing queries and drawing conclusions entailed by large volumes of data using ML analytics fully autonomously. We envision its use in investigative journalism, law enforcement and social policy planning. The proposed system capitalizes on the integration of ML technology with LLMs and advanced bigdata search techniques. We illustrate the functionality of SociaLens using a focused case study on rape incidents in a developing country and demonstrate that journalists can gain nuanced insights without requiring coding expertise they might lack. SociaLens is designed as a ChatBot that is capable of contextual conversation, find and collect data relevant to queries, initiate ML tasks to respond to queries, generate textual and visual reports, all fully autonomously within the ChatBot environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11890v1</guid>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hasan M. Jamil, Sajratul Y. Rubaiat</dc:creator>
    </item>
    <item>
      <title>Study on the Helpfulness of Explainable Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2410.11896</link>
      <description>arXiv:2410.11896v1 Announce Type: new 
Abstract: Explainable Artificial Intelligence (XAI) is essential for building advanced machine learning-powered applications, especially in critical domains such as medical diagnostics or autonomous driving. Legal, business, and ethical requirements motivate using effective XAI, but the increasing number of different methods makes it challenging to pick the right ones. Further, as explanations are highly context-dependent, measuring the effectiveness of XAI methods without users can only reveal a limited amount of information, excluding human factors such as the ability to understand it. We propose to evaluate XAI methods via the user's ability to successfully perform a proxy task, designed such that a good performance is an indicator for the explanation to provide helpful information. In other words, we address the helpfulness of XAI for human decision-making. Further, a user study on state-of-the-art methods was conducted, showing differences in their ability to generate trust and skepticism and the ability to judge the rightfulness of an AI decision correctly. Based on the results, we highly recommend using and extending this approach for more objective-based human-centered user studies to measure XAI performance in an end-to-end fashion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11896v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-63803-9_16</arxiv:DOI>
      <arxiv:journal_reference>Longo, L., Lapuschkin, S., Seifert, C. (eds) Explainable Artificial Intelligence. xAI 2024. Communications in Computer and Information Science, vol 2156</arxiv:journal_reference>
      <dc:creator>Tobias Labarta, Elizaveta Kulicheva, Ronja Froelian, Christian Gei{\ss}ler, Xenia Melman, Julian von Klitzing</dc:creator>
    </item>
    <item>
      <title>Personalised Feedback Framework for Online Education Programmes Using Generative AI</title>
      <link>https://arxiv.org/abs/2410.11904</link>
      <description>arXiv:2410.11904v1 Announce Type: new 
Abstract: AI tools, particularly large language modules, have recently proven their effectiveness within learning management systems and online education programmes. As feedback continues to play a crucial role in learning and assessment in schools, educators must carefully customise the use of AI tools in order to optimally support students in their learning journey. Efforts to improve educational feedback systems have seen numerous attempts reflected in the research studies but mostly have been focusing on qualitatively benchmarking AI feedback against human-generated feedback. This paper presents an exploration of an alternative feedback framework which extends the capabilities of ChatGPT by integrating embeddings, enabling a more nuanced understanding of educational materials and facilitating topic-targeted feedback for quiz-based assessments. As part of the study, we proposed and developed a proof of concept solution, achieving an efficacy rate of 90% and 100% for open-ended and multiple-choice questions, respectively. The results showed that our framework not only surpasses expectations but also rivals human narratives, highlighting the potential of AI in revolutionising educational feedback mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11904v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ievgeniia Kuzminykh, Tareita Nawaz, Shihao Shenzhang, Bogdan Ghita, Jeffery Raphael, Hannan Xiao</dc:creator>
    </item>
    <item>
      <title>Empowering Users in Digital Privacy Management through Interactive LLM-Based Agents</title>
      <link>https://arxiv.org/abs/2410.11906</link>
      <description>arXiv:2410.11906v1 Announce Type: new 
Abstract: This paper presents a novel application of large language models (LLMs) to enhance user comprehension of privacy policies through an interactive dialogue agent. We demonstrate that LLMs significantly outperform traditional models in tasks like Data Practice Identification, Choice Identification, Policy Summarization, and Privacy Question Answering, setting new benchmarks in privacy policy analysis. Building on these findings, we introduce an innovative LLM-based agent that functions as an expert system for processing website privacy policies, guiding users through complex legal language without requiring them to pose specific questions. A user study with 100 participants showed that users assisted by the agent had higher comprehension levels (mean score of 2.6 out of 3 vs. 1.8 in the control group), reduced cognitive load (task difficulty ratings of 3.2 out of 10 vs. 7.8), increased confidence in managing privacy, and completed tasks in less time (5.5 minutes vs. 15.8 minutes). This work highlights the potential of LLM-based agents to transform user interaction with privacy policies, leading to more informed consent and empowering users in the digital services landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11906v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bolun Sun, Yifan Zhou, Haiyun Jiang</dc:creator>
    </item>
    <item>
      <title>ChatHouseDiffusion: Prompt-Guided Generation and Editing of Floor Plans</title>
      <link>https://arxiv.org/abs/2410.11908</link>
      <description>arXiv:2410.11908v1 Announce Type: new 
Abstract: The generation and editing of floor plans are critical in architectural planning, requiring a high degree of flexibility and efficiency. Existing methods demand extensive input information and lack the capability for interactive adaptation to user modifications. This paper introduces ChatHouseDiffusion, which leverages large language models (LLMs) to interpret natural language input, employs graphormer to encode topological relationships, and uses diffusion models to flexibly generate and edit floor plans. This approach allows iterative design adjustments based on user ideas, significantly enhancing design efficiency. Compared to existing models, ChatHouseDiffusion achieves higher Intersection over Union (IoU) scores, permitting precise, localized adjustments without the need for complete redesigns, thus offering greater practicality. Experiments demonstrate that our model not only strictly adheres to user specifications but also facilitates a more intuitive design process through its interactive capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11908v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sizhong Qin, Chengyu He, Qiaoyun Chen, Sen Yang, Wenjie Liao, Yi Gu, Xinzheng Lu</dc:creator>
    </item>
    <item>
      <title>Improving Digital Mentorship: Insights and Recommendations from the Re:Coded Community Platform Case Study</title>
      <link>https://arxiv.org/abs/2410.11912</link>
      <description>arXiv:2410.11912v1 Announce Type: new 
Abstract: With the rapid growth of technology, emerging IT professionals increasingly require mentorship to secure positions in the field. Recognizing this need, ReCoded has enhanced the skill set of their tech Bootcamp graduates by introducing the community platform -- "ReCoded's Mentorship Platform". To improve the user experience of the volunteer mentors at ReCoded, this thesis investigates optimizing mentors' interactions with digital mentorship platforms and provides suggestions for enhancing these interactions. Multiple third-party collaborators have powered the mentorship platform at ReCoded. This thesis examines the platform powered by StellarUp as a case study. The insights obtained may inform the UX design of any subsequent mentorship platforms considered by ReCoded. This thesis adopted a user-centric approach to solving a UX question. The study identified challenges in the mentors' user journey and their needs by engaging with users via interviews, usability tests, and eye-tracking methods. Three principal issues emerged: platform navigation, the onboarding process, and the seamless integration of external tools. Solutions were derived from desk research for onboarding, card sorting techniques for navigation, and competitive analyses for tool integration. Throughout the research, feedback from 23 participants was gathered, ensuring a holistic understanding and actionable recommendations for developing a user-friendly and efficient mentorship platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11912v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huda Najm Alabbas</dc:creator>
    </item>
    <item>
      <title>Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D Virtual Agent in Mixed Reality for Enhanced Financial Customer Experience</title>
      <link>https://arxiv.org/abs/2410.12051</link>
      <description>arXiv:2410.12051v1 Announce Type: new 
Abstract: In this paper, we introduce a novel system designed to enhance customer service in the financial and retail sectors through a context-aware 3D virtual agent, utilizing Mixed Reality (MR) and Vision Language Models (VLMs). Our approach focuses on enabling data-driven and empathetic interactions that ensure customer satisfaction by introducing situational awareness of the physical location, personalized interactions based on customer profiles, and rigorous privacy and security standards. We discuss our design considerations critical for deployment in real-world customer service environments, addressing challenges in user data management and sensitive information handling. We also outline the system architecture and key features unique to banking and retail environments. Our work demonstrates the potential of integrating MR and VLMs in service industries, offering practical insights in customer service delivery while maintaining high standards of security and personalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12051v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cindy Xu, Mengyu Chen, Pranav Deshpande, Elvir Azanli, Runqing Yang, Joseph Ligman</dc:creator>
    </item>
    <item>
      <title>Generative AI's aggregated knowledge versus web-based curated knowledge</title>
      <link>https://arxiv.org/abs/2410.12091</link>
      <description>arXiv:2410.12091v1 Announce Type: new 
Abstract: his paper explores what kinds of questions are best served by the way generative AI (GenAI) using Large Language Models(LLMs) that aggregate and package knowledge, and when traditional curated web-sourced search results serve users better.
  An experiment compared product searches using ChatGPT, Google search engine, or both helped us understand more about the compelling nature of generated responses. The experiment showed GenAI can speed up some explorations and decisions. We describe how search can deepen the testing of facts, logic, and context. We show where existing and emerging knowledge paradigms can help knowledge exploration in different ways.
  Experimenting with searches, our probes showed the value for curated web search provides for very specific, less popularly-known knowledge. GenAI excelled at bringing together knowledge for broad, relatively well-known topics. The value of curated and aggregated knowledge for different kinds of knowledge reflected in different user goals. We developed a taxonomy to distinguishing when users are best served by these two approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12091v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ted Selker, Yunzi Wu</dc:creator>
    </item>
    <item>
      <title>Mixed or Misperceived Reality? Flusserian Media Freedom through Surreal Me</title>
      <link>https://arxiv.org/abs/2410.12171</link>
      <description>arXiv:2410.12171v1 Announce Type: new 
Abstract: This paper delves into Vil\'em Flusser's critique of media as mediators that distort the human perception of reality and diminish freedom, particularly within the Mixed Reality context, i.e., Misperceived Reality. It introduces an artistic inquiry through Surreal Me, which engages participants to experience a two-phase virtual embodying process and reveal the "Misperceived Reality." The process examines the obfuscating nature of media; as the Sense of Embodiment inevitably breaks down, users can discover the constructed nature of media-projected reality. When users reflect on reality's authentic and mediated experiences in MR, this work fosters a critical discourse on Flusserian media freedom addressing emerging immersive technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12171v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aven-Le Zhou, Lei Xi, Kang Zhang</dc:creator>
    </item>
    <item>
      <title>Challenges in Adopting Companion Robots: An Exploratory Study of Robotic Companionship Conducted with Chinese Retirees</title>
      <link>https://arxiv.org/abs/2410.12205</link>
      <description>arXiv:2410.12205v1 Announce Type: new 
Abstract: Companion robots hold immense potential in providing emotional support to older adults in the rapidly aging world. However, questions have been raised regarding whether having a robotic companion benefits healthy older adults, how they perceive the value of companion robots, and what their relationship with companion robots would be like. To understand healthy older adults' perceptions, attitudes, and relationships toward companion robots, we conducted multiple focus groups with eighteen retirees. Our findings underscore the social context encountered by older adults in China and reveal the mismatch between the current value proposition of companion robots and healthy older adults' needs. We further identify factors influencing the adoption of robotic companionship, which include individuals' self-disclosure tendencies, quality of companionship, differentiated value, and seamless collaboration with aging-in-community infrastructure and services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12205v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mengyang Wang, Keye Yu, Yukai Zhang, Mingming Fan</dc:creator>
    </item>
    <item>
      <title>Exploring the impact of virtual reality user engagement on tourist behavioral response integrated an environment concern of touristic travel perspective: A new hybrid machine learning approach</title>
      <link>https://arxiv.org/abs/2410.12223</link>
      <description>arXiv:2410.12223v1 Announce Type: new 
Abstract: Due to the impact of the COVID-19 pandemic, new attractions ways are tended to be adapted by compelling sites to provide tours product and services, such as virtual reality (VR) to visitors. Based on a systematic human-computer interaction (HCI) user engagement and Narrative transportation theory, we develop and test a theoretical framework using a hybrid partial least squares structural equation model (PLS-SEM) and artificial neural network (ANN) machine learning approach that examines key user engagement drivers of visitors' imagery and in-person tour intentions (ITI) during COVID-19. Further, we proposed a novel and hybrid approach called Reflective and Formative PLS-SEM-ANN (FRPSA) with considering both reflective and second-order formative constructs in PLS-SEM giving scope to their different advantages in a complex model. According to a sample of visitors' responses, the results demonstrate that a) user engagement, including felt involvement, aesthetic appeal, perceived usability, focused attention, endurability, and novelty, all directly affect in-person tour intentions; b) environment concern of touristic travel (EC) positively moderates the relationships between user engagement and ITI; c) EC negatively moderates the relationships between imagery and ITI; d) imagery exerts the mediating effect between user engagement and ITI; e) the felt involvement and aesthetic appeal show both the linear significance impact and nonlinear importance. Finally, contributions to theories and practical implications are discussed accordingly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12223v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>D. W. Shang</dc:creator>
    </item>
    <item>
      <title>iFuzzyTL: Interpretable Fuzzy Transfer Learning for SSVEP BCI System</title>
      <link>https://arxiv.org/abs/2410.12267</link>
      <description>arXiv:2410.12267v1 Announce Type: new 
Abstract: The rapid evolution of Brain-Computer Interfaces (BCIs) has significantly influenced the domain of human-computer interaction, with Steady-State Visual Evoked Potentials (SSVEP) emerging as a notably robust paradigm. This study explores advanced classification techniques leveraging interpretable fuzzy transfer learning (iFuzzyTL) to enhance the adaptability and performance of SSVEP-based systems. Recent efforts have strengthened to reduce calibration requirements through innovative transfer learning approaches, which refine cross-subject generalizability and minimize calibration through strategic application of domain adaptation and few-shot learning strategies. Pioneering developments in deep learning also offer promising enhancements, facilitating robust domain adaptation and significantly improving system responsiveness and accuracy in SSVEP classification. However, these methods often require complex tuning and extensive data, limiting immediate applicability. iFuzzyTL introduces an adaptive framework that combines fuzzy logic principles with neural network architectures, focusing on efficient knowledge transfer and domain adaptation. iFuzzyTL refines input signal processing and classification in a human-interpretable format by integrating fuzzy inference systems and attention mechanisms. This approach bolsters the model's precision and aligns with real-world operational demands by effectively managing the inherent variability and uncertainty of EEG data. The model's efficacy is demonstrated across three datasets: 12JFPM (89.70% accuracy for 1s with an information transfer rate (ITR) of 149.58), Benchmark (85.81% accuracy for 1s with an ITR of 213.99), and eldBETA (76.50% accuracy for 1s with an ITR of 94.63), achieving state-of-the-art results and setting new benchmarks for SSVEP BCI performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12267v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiaowei Jiang, Beining Cao, Liang Ou, Yu-Cheng Chang, Thomas Do, Chin-Teng Lin</dc:creator>
    </item>
    <item>
      <title>VisAnatomy: An SVG Chart Corpus with Fine-Grained Semantic Labels</title>
      <link>https://arxiv.org/abs/2410.12268</link>
      <description>arXiv:2410.12268v1 Announce Type: new 
Abstract: Chart corpora, which comprise data visualizations and their semantic labels, are crucial for advancing visualization research. However, the labels in most existing chart corpora are high-level (e.g., chart types), hindering their utility for broader interactive applications like chart reuse, animation, and accessibility. In this paper, we contribute VisAnatomy, a chart corpus containing 942 real-world SVG charts produced by over 50 tools, encompassing 40 chart types and featuring structural and stylistic design variations. Each chart is augmented with multilevel fine-grained labels on its semantic components, including each graphical element's type, role, and position, hierarchical groupings of elements, group layouts, and visual encodings. We demonstrate the richness of the semantic labels by comparing VisAnatomy with existing corpora. We illustrate the usefulness of VisAnatomy through four applications: chart type classification, chart decomposition, animation authoring, and content navigation for accessibility. Finally, we discuss our plan to improve VisAnatomy and the research opportunities VisAnatomy presents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12268v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Chen, Hannah K. Bako, Peihong Yu, John Hooker, Jeffrey Joyal, Simon C. Wang, Samuel Kim, Jessica Wu, Aoxue Ding, Lara Sandeep, Alex Chen, Chayanika Sinha, Zhicheng Liu</dc:creator>
    </item>
    <item>
      <title>Fool Me Once? Contrasting Textual and Visual Explanations in a Clinical Decision-Support Setting</title>
      <link>https://arxiv.org/abs/2410.12284</link>
      <description>arXiv:2410.12284v1 Announce Type: new 
Abstract: The growing capabilities of AI models are leading to their wider use, including in safety-critical domains. Explainable AI (XAI) aims to make these models safer to use by making their inference process more transparent. However, current explainability methods are seldom evaluated in the way they are intended to be used: by real-world end users. To address this, we conducted a large-scale user study with 85 healthcare practitioners in the context of human-AI collaborative chest X-ray analysis. We evaluated three types of explanations: visual explanations (saliency maps), natural language explanations, and a combination of both modalities. We specifically examined how different explanation types influence users depending on whether the AI advice and explanations are factually correct. We find that text-based explanations lead to significant over-reliance, which is alleviated by combining them with saliency maps. We also observe that the quality of explanations, that is, how much factually correct information they entail, and how much this aligns with AI correctness, significantly impacts the usefulness of the different explanation types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12284v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxime Kayser, Bayar Menzat, Cornelius Emde, Bogdan Bercean, Alex Novak, Abdala Espinosa, Bartlomiej W. Papiez, Susanne Gaube, Thomas Lukasiewicz, Oana-Maria Camburu</dc:creator>
    </item>
    <item>
      <title>Towards LLM-based Cognitive Models of Students with Misconceptions</title>
      <link>https://arxiv.org/abs/2410.12294</link>
      <description>arXiv:2410.12294v1 Announce Type: new 
Abstract: Accurately modeling student cognition is crucial for developing effective AI-driven educational technologies. A key challenge is creating realistic student models that satisfy two essential properties: (1) accurately replicating specific misconceptions, and (2) correctly solving problems where these misconceptions are not applicable. This dual requirement reflects the complex nature of student understanding, where misconceptions coexist with correct knowledge. This paper investigates whether Large Language Models (LLMs) can be instruction-tuned to meet this dual requirement and effectively simulate student thinking in algebra. We introduce MalAlgoPy, a novel Python library that generates datasets reflecting authentic student solution patterns through a graph-based representation of algebraic problem-solving. Utilizing MalAlgoPy, we define and examine Cognitive Student Models (CSMs) - LLMs instruction tuned to faithfully emulate realistic student behavior. Our findings reveal that LLMs trained on misconception examples can efficiently learn to replicate errors. However, the training diminishes the model's ability to solve problems correctly, particularly for problem types where the misconceptions are not applicable, thus failing to satisfy second property of CSMs. We demonstrate that by carefully calibrating the ratio of correct to misconception examples in the training data - sometimes as low as 0.25 - it is possible to develop CSMs that satisfy both properties. Our insights enhance our understanding of AI-based student models and pave the way for effective adaptive learning systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12294v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shashank Sonkar, Xinghe Chen, Naiming Liu, Richard G. Baraniuk, Mrinmaya Sachan</dc:creator>
    </item>
    <item>
      <title>Privacy by Design: Bringing User Awareness to Privacy Risks in Internet of Things</title>
      <link>https://arxiv.org/abs/2410.12336</link>
      <description>arXiv:2410.12336v1 Announce Type: new 
Abstract: This paper aims to cover and summarize the field of IoT and related privacy concerns through the lens of privacy by design. With the ever-increasing incorporation of technology within our daily lives and an ever-growing active research into smart devices and technologies, privacy concerns are inevitable. We intend to briefly cover the broad topic of privacy in the IoT space, the inherent challenges and risks in such systems, and a few recent techniques that intend to resolve these issues on the subdomain level and a system scale level. We then proceed to approach this situation through design thinking and privacy-by-design, given that most of the prior efforts are based on resolving privacy concerns on technical grounds with system-level design. We participated in a co-design workshop for the privacy of a content creation platform and used those findings to deploy a survey-based mechanism to tackle some key concern areas for user groups and formulate design principles for privacy that promote transparent, user-centered, and awareness-provoking privacy design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12336v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Usama Younus, Rie Kamikubo</dc:creator>
    </item>
    <item>
      <title>Exploring Plural Perspectives in Self-Tracking Technologies: Trust and Reflection in Self Tracking Practices</title>
      <link>https://arxiv.org/abs/2410.12546</link>
      <description>arXiv:2410.12546v1 Announce Type: new 
Abstract: Contemporary self-tracking technologies (STTs), such as smartwatches and smartphone apps, allow people to become self-aware through the datafication of their everyday lives. However, concerns are emerging over the global north/Western portrayal of the self in the envisionment of STTs. Given the call to diversify participant samples in HCI knowledge building, we see it timely in understanding the influence of ubiquitous STTs in global south societies. We conduct a between-group analysis of 156 and 121 participants from Global North and South through two iterative surveys, respectively. We uncover significant differences in perceived trust with their STTs and reflection practices between the groups. We provide an empirical understanding on advocating for inclusive design strategies that recognize diverse interpretations of STTs and highlight the need to prioritize local values and flexibility in tracking to foster deeper reflection across cultures. Lastly, we discuss our findings in relation to the existing literature and highlight design recommendations for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12546v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sujay Shalawadi, Rosa van Koningsbruggen, Rikke Hagensby Jensen</dc:creator>
    </item>
    <item>
      <title>Do They Understand What They Are Using? -- Assessing Perception and Usage of Biometrics</title>
      <link>https://arxiv.org/abs/2410.12661</link>
      <description>arXiv:2410.12661v1 Announce Type: new 
Abstract: In this paper we assess how well users know biometric authentication methods, how they perceive them, and if they have misconceptions about them. We present the results of an online survey that we conducted in two rounds (2019, N=57; and 2023, N=47) to understand the impact of the increasing availability of biometrics on their use and perception. The survey covered participants' general understanding of physiological and behavioral biometrics and their perceived usability and security. While most participants were able to name examples and stated that they use biometrics in their daily lives, they still had difficulties explaining the concepts behind them. We shed light on participants' misconceptions, their coping strategies with authentication failures and potential attacks, as well as their perception of the usability and security of biometrics in general. As such, our results can support the design of both further studies to gain deeper insights and future biometric interfaces to foster the informed use of biometrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12661v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas Mecke, Alia Saad, Sarah Prange, Uwe Gruenefeld, Stefan Schneegass, Florian Alt</dc:creator>
    </item>
    <item>
      <title>Drillboards: Adaptive Visualization Dashboards for Dynamic Personalization of Visualization Experiences</title>
      <link>https://arxiv.org/abs/2410.12744</link>
      <description>arXiv:2410.12744v1 Announce Type: new 
Abstract: We present drillboards, a technique for adaptive visualization dashboards consisting of a hierarchy of coordinated charts that the user can drill down to reach a desired level of detail depending on their expertise, interest, and desired effort. This functionality allows different users to personalize the same dashboard to their specific needs and expertise. The technique is based on a formal vocabulary of chart representations and rules for merging multiple charts of different types and data into single composite representations. The drillboard hierarchy is created by iteratively applying these rules starting from a baseline dashboard, with each consecutive operation yielding a new dashboard with fewer charts and progressively more abstract and simplified views. We also present an authoring tool for building drillboards and show how it can be applied to an agricultural dataset with hundreds of expert users. Our evaluation asked three domain experts to author drillboards for their own datasets, which we then showed to casual end-users with favorable outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12744v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sungbok Shin, Inyoup Na, Niklas Elmqvist</dc:creator>
    </item>
    <item>
      <title>Method for Evaluating the Number of Signal Sources and Application to Non-invasive Brain-computer Interface</title>
      <link>https://arxiv.org/abs/2410.11844</link>
      <description>arXiv:2410.11844v1 Announce Type: cross 
Abstract: This paper provides a brief introduction of the mathematical theory behind the time series unfolding method.
  The algorithms presented serve as a valuable mathematical and analytical tool for analyzing data collected from brain-computer interfaces.
  In our study, we implement a mathematical model based on polyharmonic signals to interpret the data from brain-computer interface sensors.
  The analysis of data coming to the brain-computer interface sensors is based on a mathematical model of the signal in the form of a polyharmonic signal.
  Our main focus is on addressing the problem of evaluating the number of sources, or active brain oscillators.
  The efficiency of our approach is demonstrated through analysis of data recorded from a non-invasive brain-computer interface developed by the author.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11844v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandra Bernadotte, Victor Buchstaber</dc:creator>
    </item>
    <item>
      <title>Post-Userist Recommender Systems : A Manifesto</title>
      <link>https://arxiv.org/abs/2410.11870</link>
      <description>arXiv:2410.11870v1 Announce Type: cross 
Abstract: We define userist recommendation as an approach to recommender systems framed solely in terms of the relation between the user and system. Post-userist recommendation posits a larger field of relations in which stakeholders are embedded and distinguishes the recommendation function (which can potentially connect creators with audiences) from generative media. We argue that in the era of generative media, userist recommendation becomes indistinguishable from personalized media generation, and therefore post-userist recommendation is the only path forward for recommender systems research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11870v1</guid>
      <category>cs.IR</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Burke, Morgan Sylvester</dc:creator>
    </item>
    <item>
      <title>Digital Accessibility Literacy: A Conceptual Framework for Training on Digital Accessibility</title>
      <link>https://arxiv.org/abs/2410.11931</link>
      <description>arXiv:2410.11931v1 Announce Type: cross 
Abstract: Developing digital accessibility expertise is critical to breaking down barriers and ensuring digital inclusion. However, a discourse on a pedagogical culture for teaching digital literacy is still lacking. This article, therefore, takes up the current discourse on the description of literacy and uses it to develop the concept of digital accessibility literacy as a fundamental element for promoting a pedagogical culture of digital accessibility. Digital accessibility literacy encompasses both the creation (encoding) and interpretation (decoding) of accessible digital content and technologies. By integrating awareness, technical standards, inclusive design practices, and continuous feedback into curricula, future professionals will be empowered to create digital environments that are accessible to all. This comprehensive approach improves technical skills and instills ethical and social responsibility. As a first draft of a digital accessibility literacy concept, the proposal will be used as a basis for discussion and further development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11931v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bj\"orn Fisseler</dc:creator>
    </item>
    <item>
      <title>Towards Realistic Evaluation of Commit Message Generation by Matching Online and Offline Settings</title>
      <link>https://arxiv.org/abs/2410.12046</link>
      <description>arXiv:2410.12046v1 Announce Type: cross 
Abstract: Commit message generation (CMG) is a crucial task in software engineering that is challenging to evaluate correctly. When a CMG system is integrated into the IDEs and other products at JetBrains, we perform online evaluation based on user acceptance of the generated messages. However, performing online experiments with every change to a CMG system is troublesome, as each iteration affects users and requires time to collect enough statistics. On the other hand, offline evaluation, a prevalent approach in the research literature, facilitates fast experiments but employs automatic metrics that are not guaranteed to represent the preferences of real users. In this work, we describe a novel way we employed to deal with this problem at JetBrains, by leveraging an online metric - the number of edits users introduce before committing the generated messages to the VCS - to select metrics for offline experiments.
  To support this new type of evaluation, we develop a novel markup collection tool mimicking the real workflow with a CMG system, collect a dataset with 57 pairs consisting of commit messages generated by GPT-4 and their counterparts edited by human experts, and design and verify a way to synthetically extend such a dataset. Then, we use the final dataset of 656 pairs to study how the widely used similarity metrics correlate with the online metric reflecting the real users' experience.
  Our results indicate that edit distance exhibits the highest correlation, whereas commonly used similarity metrics such as BLEU and METEOR demonstrate low correlation. This contradicts the previous studies on similarity metrics for CMG, suggesting that user interactions with a CMG system in real-world settings differ significantly from the responses by human labelers operating within controlled research environments. We release all the code and the dataset for researchers: https://jb.gg/cmg-evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12046v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Petr Tsvetkov, Aleksandra Eliseeva, Danny Dig, Alexander Bezzubov, Yaroslav Golubev, Timofey Bryksin, Yaroslav Zharov</dc:creator>
    </item>
    <item>
      <title>De-jargonizing Science for Journalists with GPT-4: A Pilot Study</title>
      <link>https://arxiv.org/abs/2410.12069</link>
      <description>arXiv:2410.12069v1 Announce Type: cross 
Abstract: This study offers an initial evaluation of a human-in-the-loop system leveraging GPT-4 (a large language model or LLM), and Retrieval-Augmented Generation (RAG) to identify and define jargon terms in scientific abstracts, based on readers' self-reported knowledge. The system achieves fairly high recall in identifying jargon and preserves relative differences in readers' jargon identification, suggesting personalization as a feasible use-case for LLMs to support sense-making of complex information. Surprisingly, using only abstracts for context to generate definitions yields slightly more accurate and higher quality definitions than using RAG-based context from the fulltext of an article. The findings highlight the potential of generative AI for assisting science reporters, and can inform future work on developing tools to simplify dense documents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12069v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sachita Nishal, Eric Lee, Nicholas Diakopoulos</dc:creator>
    </item>
    <item>
      <title>On the Utility of Domain Modeling Assistance with Large Language Models</title>
      <link>https://arxiv.org/abs/2410.12577</link>
      <description>arXiv:2410.12577v1 Announce Type: cross 
Abstract: Model-driven engineering (MDE) simplifies software development through abstraction, yet challenges such as time constraints, incomplete domain understanding, and adherence to syntactic constraints hinder the design process. This paper presents a study to evaluate the usefulness of a novel approach utilizing large language models (LLMs) and few-shot prompt learning to assist in domain modeling. The aim of this approach is to overcome the need for extensive training of AI-based completion models on scarce domain-specific datasets and to offer versatile support for various modeling activities, providing valuable recommendations to software modelers. To support this approach, we developed MAGDA, a user-friendly tool, through which we conduct a user study and assess the real-world applicability of our approach in the context of domain modeling, offering valuable insights into its usability and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12577v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meriem Ben Chaaben, Lola Burgue\~no, Istvan David, Houari Sahraoui</dc:creator>
    </item>
    <item>
      <title>Decline Now: A Combinatorial Model for Algorithmic Collective Action</title>
      <link>https://arxiv.org/abs/2410.12633</link>
      <description>arXiv:2410.12633v1 Announce Type: cross 
Abstract: Drivers on food delivery platforms often run a loss on low-paying orders. In response, workers on DoorDash started a campaign, #DeclineNow, to purposefully decline orders below a certain pay threshold. For each declined order, the platform returns the request to other available drivers with slightly increased pay. While contributing to overall pay increase the implementation of the strategy comes with the risk of missing out on orders for each individual driver. In this work, we propose a first combinatorial model to study the strategic interaction between workers and the platform. Within our model, we formalize key quantities such as the average worker benefit of the strategy, the benefit of freeriding, as well as the benefit of participation. We extend our theoretical results with simulations. Our key insights show that the average worker gain of the strategy is always positive, while the benefit of participation is positive only for small degrees of labor oversupply. Beyond this point, the utility of participants decreases faster with increasing degree of oversupply, compared to the utility of non-participants. Our work highlights the significance of labor supply levels for the effectiveness of collective action on gig platforms. We suggest organizing in shifts as a means to reduce oversupply and empower collectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12633v1</guid>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dorothee Sigg, Moritz Hardt, Celestine Mendler-D\"unner</dc:creator>
    </item>
    <item>
      <title>The efficacy potential of cyber security advice as presented in news articles</title>
      <link>https://arxiv.org/abs/2304.05309</link>
      <description>arXiv:2304.05309v2 Announce Type: replace 
Abstract: Cyber security advice is a broad church: it is thematically expansive, comprising expert texts, user-generated data consumed by individual users via informal learning, and much in-between. While there is evidence that cyber security news articles play a role in disseminating cyber security advice, the nature and extent of that role are not clear. We present a corpus of cyber security advice generated from mainstream news articles. The work was driven by two research objectives. The first objective was to ascertain what kind of actionable advice is being disseminated; the second was to explore ways of determining the efficacy potential of news-mediated security advice. The results show an increase in the generation of cyber security news articles, together with increases in vocabulary complexity and reading difficulty. We argue that these could present challenges for vulnerable users. We believe that this corpus and the accompanying analysis have the potential to inform future efforts to quantify and improve the efficacy potential of security advice dissemination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.05309v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1093/iwc/iwae048</arxiv:DOI>
      <arxiv:journal_reference>Interacting with Computers, 2024</arxiv:journal_reference>
      <dc:creator>Mark Quinlan, Aaron Ceross, Andrew Simpson</dc:creator>
    </item>
    <item>
      <title>Explore, Select, Derive, and Recall: Augmenting LLM with Human-like Memory for Mobile Task Automation</title>
      <link>https://arxiv.org/abs/2312.03003</link>
      <description>arXiv:2312.03003v3 Announce Type: replace 
Abstract: The advent of large language models (LLMs) has opened up new opportunities in the field of mobile task automation. Their superior language understanding and reasoning capabilities allow users to automate complex and repetitive tasks. However, due to the inherent unreliability and high operational cost of LLMs, their practical applicability is quite limited. To address these issues, this paper introduces MobileGPT, an innovative LLM-based mobile task automator equipped with a human-like app memory. MobileGPT emulates the cognitive process of humans interacting with a mobile app -- explore, select, derive, and recall. This approach allows for a more precise and efficient learning of a task's procedure by breaking it down into smaller, modular sub-tasks that can be re-used, re-arranged, and adapted for various objectives. We implement MobileGPT using online LLMs services (GPT-3.5 and GPT-4) and evaluate its performance on a dataset of 185 tasks across 18 mobile apps. The results indicate that MobileGPT can automate and learn new tasks with 82.7% accuracy, and is able to adapt them to different contexts with near perfect (98.75%) accuracy while reducing both latency and cost by 62.5% and 68.8%, respectively, compared to the GPT-4 powered baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03003v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sunjae Lee, Junyoung Choi, Jungjae Lee, Munim Hasan Wasi, Hojun Choi, Steven Y. Ko, Sangeun Oh, Insik Shin</dc:creator>
    </item>
    <item>
      <title>PlayFutures: Imagining Civic Futures with AI and Puppets</title>
      <link>https://arxiv.org/abs/2404.01527</link>
      <description>arXiv:2404.01527v2 Announce Type: replace 
Abstract: Children are the builders of the future and crucial to how the technologies around us develop. They are not voters but are participants in how the public spaces in a city are used. Through a workshop designed around kids of age 9-12, we investigate if novel technologies like artificial intelligence can be integrated in existing ways of play and performance to 1) re-imagine the future of civic spaces, 2) reflect on these novel technologies in the process and 3) build ways of civic engagement through play. We do this using a blend AI image generation and Puppet making to ultimately build future scenarios, perform debate and discussion around the futures and reflect on AI, its role and potential in their process. We present our findings of how AI helped envision these futures, aid performances, and report some initial reflections from children about the technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01527v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Supratim Pait, Sumita Sharma, Ashley Frith, Michael Nitsche, Noura Howell</dc:creator>
    </item>
    <item>
      <title>SpreadLine: Visualizing Egocentric Dynamic Influence</title>
      <link>https://arxiv.org/abs/2408.08992</link>
      <description>arXiv:2408.08992v2 Announce Type: replace 
Abstract: Egocentric networks, often visualized as node-link diagrams, portray the complex relationship (link) dynamics between an entity (node) and others. However, common analytics tasks are multifaceted, encompassing interactions among four key aspects: strength, function, structure, and content. Current node-link visualization designs may fall short, focusing narrowly on certain aspects and neglecting the holistic, dynamic nature of egocentric networks. To bridge this gap, we introduce SpreadLine, a novel visualization framework designed to enable the visual exploration of egocentric networks from these four aspects at the microscopic level. Leveraging the intuitive appeal of storyline visualizations, SpreadLine adopts a storyline-based design to represent entities and their evolving relationships. We further encode essential topological information in the layout and condense the contextual information in a metro map metaphor, allowing for a more engaging and effective way to explore temporal and attribute-based information. To guide our work, with a thorough review of pertinent literature, we have distilled a task taxonomy that addresses the analytical needs specific to egocentric network exploration. Acknowledging the diverse analytical requirements of users, SpreadLine offers customizable encodings to enable users to tailor the framework for their tasks. We demonstrate the efficacy and general applicability of SpreadLine through three diverse real-world case studies (disease surveillance, social media trends, and academic career evolution) and a usability study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08992v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yun-Hsin Kuo, Dongyu Liu, Kwan-Liu Ma</dc:creator>
    </item>
    <item>
      <title>NoTeeline: Supporting Real-Time, Personalized Notetaking with LLM-Enhanced Micronotes</title>
      <link>https://arxiv.org/abs/2409.16493</link>
      <description>arXiv:2409.16493v2 Announce Type: replace 
Abstract: Taking notes quickly while effectively capturing key information can be challenging, especially when watching videos that present simultaneous visual and auditory streams. Manually taken notes often miss crucial details due to the fast-paced nature of the content, while automatically generated notes fail to incorporate user preferences and discourage active engagement with the content. To address this, we propose an interactive system, NoTeeline, for supporting real-time, personalized notetaking. Given 'micronotes', NoTeeline automatically expands them into full-fledged notes using Large Language Model (LLM). The generated notes build on the content of micronotes by adding relevant details while maintaining consistency with the user's writing style. In a within-subjects study (n=12), we found that NoTeeline creates high-quality notes that capture the essence of their micronotes with 93.2% factual correctness and accurately align with their writing style (8.33% improvement). Using NoTeeline, participants could capture their desired notes with significantly reduced mental effort, writing 47.0% less text and completing their note in 43.9% less time compared to a manual notetaking baseline. Our results suggest that NoTeeline enables users to integrate LLM assistance in a familiar notetaking workflow while ensuring consistency with their preference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16493v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faria Huq, Abdus Samee, David Chuan-en Lin, Xiaodi Alice Tang, Jeffrey P. Bigham</dc:creator>
    </item>
    <item>
      <title>See Where You Read with Eye Gaze Tracking and Large Language Model</title>
      <link>https://arxiv.org/abs/2409.19454</link>
      <description>arXiv:2409.19454v2 Announce Type: replace 
Abstract: Losing track of reading progress during line switching can be frustrating. Eye gaze tracking technology offers a potential solution by highlighting read paragraphs, aiding users in avoiding wrong line switches. However, the gap between gaze tracking accuracy (2-3 cm) and text line spacing (3-5 mm) makes direct application impractical. Existing methods leverage the linear reading pattern but fail during jump reading. This paper presents a reading tracking and highlighting system that supports both linear and jump reading. Based on experimental insights from the gaze nature study of 16 users, two gaze error models are designed to enable both jump reading detection and relocation. The system further leverages the large language model's contextual perception capability in aiding reading tracking. A reading tracking domain-specific line-gaze alignment opportunity is also exploited to enable dynamic and frequent calibration of the gaze results. Controlled experiments demonstrate reliable linear reading tracking, as well as 84% accuracy in tracking jump reading. Furthermore, real field tests with 18 volunteers demonstrated the system's effectiveness in tracking and highlighting read paragraphs, improving reading efficiency, and enhancing user experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19454v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sikai Yang, Gang Yan</dc:creator>
    </item>
    <item>
      <title>Generative AI and Perceptual Harms: Who's Suspected of using LLMs?</title>
      <link>https://arxiv.org/abs/2410.00906</link>
      <description>arXiv:2410.00906v2 Announce Type: replace 
Abstract: Large language models (LLMs) are increasingly integrated into a variety of writing tasks. While these tools can help people by generating ideas or producing higher quality work, like many other AI tools they may risk causing a variety of harms, disproportionately burdening historically marginalized groups. In this work, we introduce and evaluate perceptual harm, a term for the harm caused to users when others perceive or suspect them of using AI. We examined perceptual harms in three online experiments, each of which entailed human participants evaluating the profiles for fictional freelance writers. We asked participants whether they suspected the freelancers of using AI, the quality of their writing, and whether they should be hired. We found some support for perceptual harms against for certain demographic groups, but that perceptions of AI use negatively impacted writing evaluations and hiring outcomes across the board.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00906v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kowe Kadoma, Dana\"e Metaxa, Mor Naaman</dc:creator>
    </item>
    <item>
      <title>Practices and Challenges of Online Love-seeking Among Deaf or Hard of Hearing People: A Case Study in China</title>
      <link>https://arxiv.org/abs/2410.11810</link>
      <description>arXiv:2410.11810v2 Announce Type: replace 
Abstract: People who are deaf or hard of hearing (DHH) in China are increasingly exploring online platforms to connect with potential partners. This research explores the online dating experiences of DHH communities in China, an area that has not been extensively researched. We interviewed sixteen participants who have varying levels of hearing ability and love-seeking statuses to understand how they manage their identities and communicate with potential partners online. We find that DHH individuals made great efforts to navigate the rich modality features to seek love online. Participants used both algorithm-based dating apps and community-based platforms like forums and WeChat to facilitate initial encounters through text-based functions that minimized the need for auditory interaction, thus fostering a more equitable starting point. Community-based platforms were found to facilitate more in-depth communication and excelled in fostering trust and authenticity, providing a more secure environment for genuine relationships. Design recommendations are proposed to enhance the accessibility and inclusiveness of online dating platforms for DHH individuals in China. This research sheds light on the benefits and challenges of online dating for DHH individuals in China and provides guidance for platform developers and researchers to enhance user experience in this area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11810v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Beiyan Cao, Jingling Zhang, Changyang He, Yuru Huang, Muzhi Zhou, Mingming Fan</dc:creator>
    </item>
    <item>
      <title>Towards Human-centered Explainable AI: A Survey of User Studies for Model Explanations</title>
      <link>https://arxiv.org/abs/2210.11584</link>
      <description>arXiv:2210.11584v5 Announce Type: replace-cross 
Abstract: Explainable AI (XAI) is widely viewed as a sine qua non for ever-expanding AI research. A better understanding of the needs of XAI users, as well as human-centered evaluations of explainable models are both a necessity and a challenge. In this paper, we explore how HCI and AI researchers conduct user studies in XAI applications based on a systematic literature review. After identifying and thoroughly analyzing 97core papers with human-based XAI evaluations over the past five years, we categorize them along the measured characteristics of explanatory methods, namely trust, understanding, usability, and human-AI collaboration performance. Our research shows that XAI is spreading more rapidly in certain application domains, such as recommender systems than in others, but that user evaluations are still rather sparse and incorporate hardly any insights from cognitive or social sciences. Based on a comprehensive discussion of best practices, i.e., common models, design choices, and measures in user studies, we propose practical guidelines on designing and conducting user studies for XAI researchers and practitioners. Lastly, this survey also highlights several open research directions, particularly linking psychological science and human-centered XAI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11584v5</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPAMI.2023.3331846</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Pattern Analysis and Machine Intelligence (Volume: 46, Issue: 4, April 2024)</arxiv:journal_reference>
      <dc:creator>Yao Rong, Tobias Leemann, Thai-trang Nguyen, Lisa Fiedler, Peizhu Qian, Vaibhav Unhelkar, Tina Seidel, Gjergji Kasneci, Enkelejda Kasneci</dc:creator>
    </item>
    <item>
      <title>COMPASS: Computational Mapping of Patient-Therapist Alliance Strategies with Language Modeling</title>
      <link>https://arxiv.org/abs/2402.14701</link>
      <description>arXiv:2402.14701v2 Announce Type: replace-cross 
Abstract: The therapeutic working alliance is a critical factor in predicting the success of psychotherapy treatment. Traditionally, working alliance assessment relies on questionnaires completed by both therapists and patients. In this paper, we present COMPASS, a novel framework to directly infer the therapeutic working alliance from the natural language used in psychotherapy sessions. Our approach utilizes advanced large language models (LLMs) to analyze transcripts of psychotherapy sessions and compare them with distributed representations of statements in the working alliance inventory. Analyzing a dataset of over 950 sessions covering diverse psychiatric conditions including anxiety, depression, schizophrenia, and suicidal tendencies, we demonstrate the effectiveness of our method in providing fine-grained mapping of patient-therapist alignment trajectories and offering interpretability for clinical psychiatry and in identifying emerging patterns related to the condition being treated. By employing various deep learning-based topic modeling techniques in combination with prompting generative language models, we analyze the topical characteristics of different psychiatric conditions and their evolution at a turn-level resolution. This combined framework enhances the understanding of therapeutic interactions, enabling timely feedback for therapists regarding the quality of therapeutic relationships and providing interpretable insights to improve the effectiveness of psychotherapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14701v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baihan Lin, Djallel Bouneffouf, Yulia Landa, Rachel Jespersen, Cheryl Corcoran, Guillermo Cecchi</dc:creator>
    </item>
    <item>
      <title>Large Language Models Can Solve Real-World Planning Rigorously with Formal Verification Tools</title>
      <link>https://arxiv.org/abs/2404.11891</link>
      <description>arXiv:2404.11891v2 Announce Type: replace-cross 
Abstract: Despite their recent advancements, Large Language Models (LLMs) still struggle to directly generate correct plans for complex multi-constraint planning problems, even with self-verification and self-critique. For example, a U.S. domestic travel planning benchmark TravelPlanner was proposed in Xie et al. (2024), where the best LLM OpenAI o1-preview can only find travel plans that satisfy user requirements with a 10% success rate given all needed information. In this work, we tackle this difficult problem by proposing an LLM-based planning framework that formalizes and solves complex multi-constraint planning problems as constrained satisfiability problems, which are further consumed by sound and complete satisfiability solvers. We start with TravelPlanner as the primary use case and achieve a success rate of 93.9%. We demonstrate our framework's robustness by showing its effectiveness in diverse paraphrased prompts. More importantly, our framework has strong zero-shot generalizability: It can successfully handle unseen constraints in a completely unseen international travel dataset we created, and it can even generalize well to new domains such as routing and task allocation problems in a zero-shot manner. Moreover, when user input queries are infeasible, our framework can identify the unsatisfiable core, provide failure reasons, and offers personalized modification suggestions to users according to diverse human preferences. We show that our framework can modify and solve for an average of 81.6% and 91.7% unsatisfiable queries from two datasets and prove with ablations that all key components of our framework are effective and necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11891v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilun Hao, Yongchao Chen, Yang Zhang, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>AI, Pluralism, and (Social) Compensation</title>
      <link>https://arxiv.org/abs/2404.19256</link>
      <description>arXiv:2404.19256v2 Announce Type: replace-cross 
Abstract: One strategy in response to pluralistic values in a user population is to personalize an AI system: if the AI can adapt to the specific values of each individual, then we can potentially avoid many of the challenges of pluralism. Unfortunately, this approach creates a significant ethical issue: if there is an external measure of success for the human-AI team, then the adaptive AI system may develop strategies (sometimes deceptive) to compensate for its human teammate. This phenomenon can be viewed as a form of social compensation, where the AI makes decisions based not on predefined goals but on its human partner's deficiencies in relation to the team's performance objectives. We provide a practical ethical analysis of the conditions in which such compensation may nonetheless be justifiable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19256v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nandhini Swaminathan, David Danks</dc:creator>
    </item>
    <item>
      <title>Open-Source Conversational AI with SpeechBrain 1.0</title>
      <link>https://arxiv.org/abs/2407.00463</link>
      <description>arXiv:2407.00463v5 Announce Type: replace-cross 
Abstract: SpeechBrain is an open-source Conversational AI toolkit based on PyTorch, focused particularly on speech processing tasks such as speech recognition, speech enhancement, speaker recognition, text-to-speech, and much more. It promotes transparency and replicability by releasing both the pre-trained models and the complete "recipes" of code and algorithms required for training them. This paper presents SpeechBrain 1.0, a significant milestone in the evolution of the toolkit, which now has over 200 recipes for speech, audio, and language processing tasks, and more than 100 models available on Hugging Face. SpeechBrain 1.0 introduces new technologies to support diverse learning modalities, Large Language Model (LLM) integration, and advanced decoding strategies, along with novel models, tasks, and modalities. It also includes a new benchmark repository, offering researchers a unified platform for evaluating models across diverse tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00463v5</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>eess.AS</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mirco Ravanelli, Titouan Parcollet, Adel Moumen, Sylvain de Langen, Cem Subakan, Peter Plantinga, Yingzhi Wang, Pooneh Mousavi, Luca Della Libera, Artem Ploujnikov, Francesco Paissan, Davide Borra, Salah Zaiem, Zeyu Zhao, Shucong Zhang, Georgios Karakasidis, Sung-Lin Yeh, Pierre Champion, Aku Rouhe, Rudolf Braun, Florian Mai, Juan Zuluaga-Gomez, Seyed Mahed Mousavi, Andreas Nautsch, Xuechen Liu, Sangeet Sagar, Jarod Duret, Salima Mdhaffar, Gaelle Laperriere, Mickael Rouvier, Renato De Mori, Yannick Esteve</dc:creator>
    </item>
    <item>
      <title>Promoting the Culture of Qinhuai River Lantern Shadow Puppetry with a Digital Archive and Immersive Experience</title>
      <link>https://arxiv.org/abs/2410.03532</link>
      <description>arXiv:2410.03532v2 Announce Type: replace-cross 
Abstract: As an intangible cultural heritage, Chinese shadow puppetry is facing challenges in terms of its appeal and comprehension, especially among audiences from different cultural backgrounds. Additionally, the fragile materials of the puppets and obstacles to preservation pose further challenges. This study creates a digital archive of the Qinhuai River Lantern Festival shadow puppetry, utilizing digital technology to recreate scenes depicted in traditional Chinese poetry and painting. Moreover, this study employs a mixed-method approach, combining qualitative and quantitative methods, to evaluate the acceptance and audience experience of immersive shadow puppetry. An in-depth exploration was conducted from sensory, emotional, cultural dimensions and research hypotheses were tested using structural equation modeling and other methods. The results indicate that enhancing ease of use and cultural experience can improve audience appeal and comprehension, while enhancing emotional experience can increase audience participation intention. Our research holds profound significance for the preservation and transmission of shadow puppetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03532v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanfang Liu, Rua Mae Williams, Guanghong Xie, Yu Wang, Wenrui Zuo</dc:creator>
    </item>
  </channel>
</rss>
