<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Apr 2025 03:07:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient importance sampling for copula models</title>
      <link>https://arxiv.org/abs/2504.03242</link>
      <description>arXiv:2504.03242v1 Announce Type: new 
Abstract: In this paper, we propose an efficient importance sampling algorithm for rare event simulation under copula models. In the algorithm, the derived optimal probability measure is based on the criterion of minimizing the variance of the importance sampling estimator within a parametric exponential tilting family. Since the copula model is defined by its marginals and a copula function, and its moment-generating function is difficult to derive, we apply the transform likelihood ratio method to first identify an alternative exponential tilting family, after which we obtain simple and explicit expressions of equations. Then, the optimal alternative probability measure can be calculated under this transformed exponential tilting family. The proposed importance sampling framework is quite general and can be implemented for many classes of copula models, including some traditional parametric copula families and a class of semiparametric copulas called regular vine copulas, from which sampling is feasible. The theoretical results of the logarithmic efficiency and bounded relative error are proved for some commonly-used copula models under the case of simple rare events. Monte Carlo experiments are conducted, in which we study the relative efficiency of the crude Monte Carlo estimator with respect to the proposed importance-sampling-based estimators, such that substantial variance reductions are obtained in comparison to the standard Monte Carlo estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03242v1</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siang Cheng, Cheng-Der Fuh, Tianxiao Pang</dc:creator>
    </item>
    <item>
      <title>Scalable Fitting Methods for Multivariate Gaussian Additive Models with Covariate-dependent Covariance Matrices</title>
      <link>https://arxiv.org/abs/2504.03368</link>
      <description>arXiv:2504.03368v1 Announce Type: new 
Abstract: We propose efficient computational methods to fit multivariate Gaussian additive models, where the mean vector and the covariance matrix are allowed to vary with covariates, in an empirical Bayes framework. To guarantee the positive-definiteness of the covariance matrix, we model the elements of an unconstrained parametrisation matrix, focussing particularly on the modified Cholesky decomposition and the matrix logarithm. A key computational challenge arises from the fact that, for the model class considered here, the number of parameters increases quadratically with the dimension of the response vector. Hence, here we discuss how to achieve fast computation and low memory footprint in moderately high dimensions, by exploiting parsimonious model structures, sparse derivative systems and by employing block-oriented computational methods. Methods for building and fitting multivariate Gaussian additive models are provided by the SCM R package, available at https://github.com/VinGioia90/SCM, while the code for reproducing the results in this paper is available at https://github.com/VinGioia90/SACM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03368v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincenzo Gioia, Matteo Fasiolo, Ruggero Bellio, Simon N. Wood</dc:creator>
    </item>
    <item>
      <title>Comparative Analysis of Deepfake Detection Models: New Approaches and Perspectives</title>
      <link>https://arxiv.org/abs/2504.02900</link>
      <description>arXiv:2504.02900v1 Announce Type: cross 
Abstract: The growing threat posed by deepfake videos, capable of manipulating realities and disseminating misinformation, drives the urgent need for effective detection methods. This work investigates and compares different approaches for identifying deepfakes, focusing on the GenConViT model and its performance relative to other architectures present in the DeepfakeBenchmark. To contextualize the research, the social and legal impacts of deepfakes are addressed, as well as the technical fundamentals of their creation and detection, including digital image processing, machine learning, and artificial neural networks, with emphasis on Convolutional Neural Networks (CNNs), Generative Adversarial Networks (GANs), and Transformers. The performance evaluation of the models was conducted using relevant metrics and new datasets established in the literature, such as WildDeep-fake and DeepSpeak, aiming to identify the most effective tools in the battle against misinformation and media manipulation. The obtained results indicated that GenConViT, after fine-tuning, exhibited superior performance in terms of accuracy (93.82%) and generalization capacity, surpassing other architectures in the DeepfakeBenchmark on the DeepSpeak dataset. This study contributes to the advancement of deepfake detection techniques, offering contributions to the development of more robust and effective solutions against the dissemination of false information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02900v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matheus Martins Batista</dc:creator>
    </item>
    <item>
      <title>A Lanczos-Based Algorithmic Approach for Spike Detection in Large Sample Covariance Matrices</title>
      <link>https://arxiv.org/abs/2504.03066</link>
      <description>arXiv:2504.03066v1 Announce Type: cross 
Abstract: We introduce a new approach for estimating the number of spikes in a general class of spiked covariance models without directly computing the eigenvalues of the sample covariance matrix. This approach is based on the Lanczos algorithm and the asymptotic properties of the associated Jacobi matrix and its Cholesky factorization. A key aspect of the analysis is interpreting the eigenvector spectral distribution as a perturbation of its asymptotic counterpart. The specific exponential-type asymptotics of the Jacobi matrix enables an efficient approximation of the Stieltjes transform of the asymptotic spectral distribution via a finite continued fraction. As a consequence, we also obtain estimates for the density of the asymptotic distribution and the location of outliers. We provide consistency guarantees for our proposed estimators, proving their convergence in the high-dimensional regime. We demonstrate that, when applied to standard spiked covariance models, our approach outperforms existing methods in computational efficiency and runtime, while still maintaining robustness to exotic population covariances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03066v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charbel Abi Younes, Xiucai Ding, Thomas Trogdon</dc:creator>
    </item>
    <item>
      <title>Coherent Disaggregation and Uncertainty Quantification for Spatially Misaligned Data</title>
      <link>https://arxiv.org/abs/2502.10584</link>
      <description>arXiv:2502.10584v3 Announce Type: replace-cross 
Abstract: Spatial misalignment problems arise from both data aggregation and attempts to align misaligned data, leading to information loss. We propose a Bayesian disaggregation framework that links misaligned data to a continuous domain model using an iteratively linearised integration method via integrated nested Laplace approximation (INLA). The framework supports point pattern and aggregated count models under four covariate field scenarios: \textit{Raster at Full Resolution (RastFull), Raster Aggregation (RastAgg), Polygon Aggregation (PolyAgg), and Point Values (PointVal)}. The first three involve aggregation, while the latter two have incomplete fields. For PolyAgg and PointVal, we estimate the full covariate field using \textit{Value Plugin, Joint Uncertainty, and Uncertainty Plugin} methods, with the latter two accounting for uncertainty propagation. These methods demonstrate superior performance, and remain more robust even under model misspecification (i.e.\ modelling a nonlinear field as linear).
  In landslide studies, landslide occurrences are often aggregated into counts based on slope units, reducing spatial detail. The results indicate that point pattern observations and full-resolution covariate fields should be prioritized. For incomplete fields, methods incorporating uncertainty propagation are preferred. This framework supports landslide susceptibility and other spatial mapping, integrating seamlessly with INLA-extension packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10584v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Mon, 07 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Man Ho Suen, Mark Naylor, Finn Lindgren</dc:creator>
    </item>
  </channel>
</rss>
