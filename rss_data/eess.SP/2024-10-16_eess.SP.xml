<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 16 Oct 2024 04:01:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>BUPTCMCC-6G-DataAI+: A generative channel dataset for 6G AI air interface research</title>
      <link>https://arxiv.org/abs/2410.10839</link>
      <description>arXiv:2410.10839v1 Announce Type: new 
Abstract: In September 2024, Beijing University of Posts and Telecommunications and China Mobile Communications Group jointly releases a channel dataset for the sixth generation (6G) mobile communications, named BUPTCMCC-6G-DataAI+. BUPTCMCC-6G-DataAI+ is the update version of BUPTCMCC-6G-DataAI, which is already published in June 2023, aiming at extending 6G new technologies, frequency bands, and applications. BUPTCMCC-6G-DataAI+ provides deterministic data covering new mid-bands, millimeter wave (mmWave), and terahertz (THz), supports the features of XL-MIMO near-field, high mobility and provides multiple 6G scenarios such as reconfigurable intelligent surface (RIS) and industrial Internet. Configured with customized features according to different user needs, BUPTCMCC-6G-DataAI+ can adaptively generate scalable large-scale or small-scale parameters, providing data support for 6G research and development, and standardization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10839v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Yu, Jianhua Zhang, Mingjun Fu, Qixing Wang</dc:creator>
    </item>
    <item>
      <title>Optimizing Radio Access Technology Selection and Precoding in CV-Aided ISAC Systems</title>
      <link>https://arxiv.org/abs/2410.11002</link>
      <description>arXiv:2410.11002v1 Announce Type: new 
Abstract: Integrated Sensing and Communication (ISAC) systems promise to revolutionize wireless networks by concurrently supporting high-resolution sensing and high-performance communication. This paper presents a novel radio access technology (RAT) selection framework that capitalizes on vision sensing from base station (BS) cameras to optimize both communication and perception capabilities within the ISAC system. Our framework strategically employs two distinct RATs, LTE and millimeter wave (mmWave), to enhance system performance. We propose a vision-based user localization method that employs a 3D detection technique to capture the spatial distribution of users within the surrounding environment. This is followed by geometric calculations to accurately determine the state of mmWave communication links between the BS and individual users. Additionally, we integrate the SlowFast model to recognize user activities, facilitating adaptive transmission rate allocation based on observed behaviors. We develop a Deep Deterministic Policy Gradient (DDPG)-based algorithm, utilizing the joint distribution of users and their activities, designed to maximize the total transmission rate for all users through joint RAT selection and precoding optimization, while adhering to constraints on sensing mutual information and minimum transmission rates. Numerical simulation results demonstrate the effectiveness of the proposed framework in dynamically adjusting resource allocation, ensuring high-quality communication under challenging conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11002v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulan Gao, Ziqiang Ye, Ming Xiao, Yue Xiao</dc:creator>
    </item>
    <item>
      <title>6G RIS-aided Single-LEO Localization with Slow and Fast Doppler Effects</title>
      <link>https://arxiv.org/abs/2410.11010</link>
      <description>arXiv:2410.11010v1 Announce Type: new 
Abstract: 6G networks aim to enable applications like autonomous driving by providing complementary localization services through key technologies such as non-terrestrial networks (NTNs) with low Earth orbit (LEO) satellites and reconfigurable intelligent surfaces (RIS). Prior research in 6G localization using single LEO, multi-LEO, and multi-LEO multi-RIS setups has limitations: single LEO lacks the required accuracy, while multi-LEO/RIS setups demand many visible satellites and RISs, which is not always feasible in practice. This paper explores the novel problem of localization with a single LEO satellite and a single RIS, bridging these research areas. We present a comprehensive signal model accounting for user carrier frequency offset (CFO), clock bias, and fast and slow Doppler effects. Additionally, we derive a low-complexity estimator that achieves theoretical bounds at high signal-to-noise ratios (SNR). Our results demonstrate the feasibility and accuracy of RIS-aided single-LEO localization in 6G networks and highlight potential research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11010v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharief Saleh, Musa Furkan Keskin, Basuki Priyanto, Martin Beale, Pinjun Zheng, Tareq Y. Al-Naffouri, Gonzalo Seco-Granados, Henk Wymeersch</dc:creator>
    </item>
    <item>
      <title>Adaptive Power Allocation in Spaceborne Assisted NOMA Systems for Integrated Terrestrial Communications</title>
      <link>https://arxiv.org/abs/2410.11254</link>
      <description>arXiv:2410.11254v1 Announce Type: new 
Abstract: This study introduces an innovative approach for adaptive power allocation in Non-Orthogonal Multiple Access (NOMA) systems, enhanced by the integration of spaceborne and terrestrial signals through a Reconfigurable Intelligent Surface (RIS). We develop an adaptive mechanism to adjust the power distribution between spaceborne and terrestrial signals according to variations in environmental conditions and elevation angles. This mechanism employs a sophisticated transition model that combines Gaussian Mixture Models with Log-Normal distributions to adaptively counteract the detrimental impacts of atmospheric attenuation and urban shadowing. These adaptive power adjustments significantly enhance system capacity, particularly improving the Signal-to-Interference-plus-Noise Ratio under diverse operational scenarios. Simulation studies confirm the efficacy of our method within an RIS-enhanced framework, showing an approximate 20\% increase in system capacity through optimized power management between spaceborne and terrestrial signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11254v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M Khalil, Ke Wang, Jinho Choi</dc:creator>
    </item>
    <item>
      <title>EEG-based 90-Degree Turn Intention Detection for Brain-Computer Interface</title>
      <link>https://arxiv.org/abs/2410.11339</link>
      <description>arXiv:2410.11339v1 Announce Type: new 
Abstract: Electroencephalography (EEG)--based turn intention prediction for lower limb movement is important to build an efficient brain-computer interface (BCI) system. This study investigates the feasibility of intention detection of left-turn, right-turn, and straight walk by utilizing EEG signals obtained before the event occurrence. Synchronous data was collected using 31-channel EEG and IMU-based motion capture systems for nine healthy participants while performing left-turn, right-turn, and straight walk movements. EEG data was preprocessed with steps including Artifact Subspace Reconstruction (ASR), re-referencing, and Independent Component Analysis (ICA) to remove data noise. Feature extraction from the preprocessed EEG data involved computing various statistical measures (mean, median, standard deviation, skew, and kurtosis), and Hjorth parameters (activity, mobility, and complexity). Further, the feature selection was performed using the Random forest algorithm for the dimensionality reduction. The feature set obtained was utilized for 3-class classification using XG boost, gradient boosting, and support vector machine (SVM) with RBF kernel classifiers in a five-fold cross-validation scheme. Using the proposed intention detection methodology, the SVM classifier using an EEG window of 1.5 s and 0 s time-lag has the best decoding performance with mean accuracy, precision, and recall of 81.23%, 85.35%, and 83.92%, respectively, across the nine participants. The decoding analysis shows the feasibility of turn intention prediction for lower limb movement using the EEG signal before the event onset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11339v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pradyot Anand, Anant Jain, Suriya Prakash Muthukrishnan, Shubhendu Bhasin, Sitikantha Roy, Mohanavelu Kalathe, Lalan Kumar</dc:creator>
    </item>
    <item>
      <title>RSSI-Assisted CSI-Based Passenger Counting with Multiple Wi-Fi Receivers</title>
      <link>https://arxiv.org/abs/2410.11400</link>
      <description>arXiv:2410.11400v1 Announce Type: new 
Abstract: Passenger counting is crucial for public transport vehicle scheduling and traffic capacity evaluation. However, most existing methods are either costly or with low counting accuracy, leading to the recent use of Wi-Fi signals for this purpose. In this paper, we develop an efficient edge computing-based passenger counting system consists of multiple Wi-Fi receivers and an edge server. It leverages channel state information (CSI) and received signal strength indicator (RSSI) to facilitate the collaboration among multiple receivers. Specifically, we design a novel CSI feature fusion module called Adaptive RSSI-weighted CSI Feature Concatenation, which integrates locally extracted CSI and RSSI features from multiple receivers for information fusion at the edge server. Performance of our proposed system is evaluated using a real-world dataset collected from a double-decker bus in Hong Kong, with up to 20 passengers. The experimental results reveal that our system achieves an average accuracy and F1-score of over 94%, surpassing other cooperative sensing baselines by at least 2.27% in accuracy and 2.34% in F1-score.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11400v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingtao Guo, Wenhao Zhuang, Yuyi Mao, Ivan Wang-Hei Ho</dc:creator>
    </item>
    <item>
      <title>GBSense: A GHz-Bandwidth Compressed Spectrum Sensing System</title>
      <link>https://arxiv.org/abs/2410.11495</link>
      <description>arXiv:2410.11495v1 Announce Type: new 
Abstract: This paper presents GBSense, an innovative compressed spectrum sensing system designed for GHz-bandwidth signals. GBSense introduces a novel approach to realize periodic nonuniform sampling that efficiently captures wideband signals using significantly lower sampling rates compared to traditional Nyquist sampling. The system incorporates time-interleaved analog-to-digital conversion, which eliminates the need for the complex analog delays typically required in multicoset sampling architectures, and offers real-time adjustable sampling patterns. The hardware design includes a dedicated clock distribution circuit and the implementation of a standard protocol to ensure precise synchronization of nonuniform samples. GBSense can process signals with a 2 GHz radio frequency bandwidth using only a 400 MHz average sampling rate. Lab tests demonstrate 100\% accurate spectrum reconstruction when the spectrum occupancy is below 100 MHz and over 80\% accuracy for occupancy up to 200 MHz. Additionally, an integrated system built around the GBSense core and a low-power Raspberry Pi processor achieves a low processing latency of around 30 ms per frame, showcasing strong real-time performance. This work highlights the potential of GBSense as a high-efficiency solution for dynamic spectrum access in future wireless communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11495v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zihang Song, Yue Gao</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Belief Propagation Decoder for Short Block Length LDPC Codes</title>
      <link>https://arxiv.org/abs/2410.11543</link>
      <description>arXiv:2410.11543v1 Announce Type: new 
Abstract: Spiking neural networks (SNNs) are neural networks that enable energy-efficient signal processing due to their event-based nature. This paper proposes a novel decoding algorithm for low-density parity-check (LDPC) codes that integrates SNNs into belief propagation (BP) decoding by approximating the check node update equations using SNNs. For the (273,191) and (1023,781) finite-geometry LDPC code, the proposed decoder outperforms sum-product decoder at high signal-to-noise ratios (SNRs). The decoder achieves a similar bit error rate to normalized sum-product decoding with successive relaxation. Furthermore, the novel decoding operates without requiring knowledge of the SNR, making it robust to SNR mismatch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11543v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander von Bank, Eike-Manuel Edelmann, Sisi Miao, Jonathan Mandelbaum, Laurent Schmalen</dc:creator>
    </item>
    <item>
      <title>Information Importance-Aware Defense against Adversarial Attack for Automatic Modulation Classification:An XAI-Based Approach</title>
      <link>https://arxiv.org/abs/2410.11608</link>
      <description>arXiv:2410.11608v1 Announce Type: new 
Abstract: Deep learning (DL) has significantly improved automatic modulation classification (AMC) by leveraging neural networks as the feature extractor.However, as the DL-based AMC becomes increasingly widespread, it is faced with the severe secure issue from various adversarial attacks. Existing defense methods often suffer from the high computational cost, intractable parameter tuning, and insufficient robustness.This paper proposes an eXplainable artificial intelligence (XAI) defense approach, which uncovers the negative information caused by the adversarial attack through measuring the importance of input features based on the SHapley Additive exPlanations (SHAP).By properly removing the negative information in adversarial samples and then fine-tuning(FT) the model, the impact of the attacks on the classification result can be mitigated.Experimental results demonstrate that the proposed SHAP-FT improves the classification performance of the model by 15%-20% under different attack levels,which not only enhances model robustness against various attack levels but also reduces the resource consumption, validating its effectiveness in safeguarding communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11608v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingchun Wang, Peihao Dong, Fuhui Zhou, Qihui Wu</dc:creator>
    </item>
    <item>
      <title>Bistatic Information Fusion for Positioning and Tracking in Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2410.11681</link>
      <description>arXiv:2410.11681v1 Announce Type: new 
Abstract: The distributed nature of cellular networks is one of the main enablers for integrated sensing and communication (ISAC). For target positioning and tracking, making use of bistatic measurements is non-trivial due to their non-linear relationship with Cartesian coordinates. Most of the literature proposes geometric-based methods to determine the target's location by solving a well-defined set of equations stemming from the available measurements. The error covariance to be used for Bayesian tracking is then derived from local Taylor expansions. In our work we adaptively fuse any subset of bistatic measurements using a maximum likelihood (ML) framework, allowing to incorporate every possible combination of available measurements, i.e., transmitter angle, receiver angle and bistatic range. Moreover, our ML approach is intrinsically flexible, as it can be extended to fuse an arbitrary number of measurements by multistatic setups. Finally, we propose both a fixed and dynamic way to compute the covariance matrix for the position error to be fed to Bayesian tracking techniques, like a Kalman filter. Numerical evaluations with realistic cellular communications parameters at mmWave frequencies show that our proposal outperforms the considered baselines, achieving a location and velocity root mean square error of 0.25 m and 0.83 m/s, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11681v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maximilian Bauhofer, Marcus Henninger, Thorsten Wild, Stephan ten Brink, Silvio Mandelli</dc:creator>
    </item>
    <item>
      <title>Reduced Overhead Channel Estimation for OTFS With Split Pilot</title>
      <link>https://arxiv.org/abs/2410.11739</link>
      <description>arXiv:2410.11739v1 Announce Type: new 
Abstract: Orthogonal time frequency space modulation (OTFS) is currently one of the most robust modulation techniques for high Doppler channels. However, to reap the benefits of OTFS, an accurate channel estimation is crucial. To this mean, the widely used embedded pilot structures use twice the channel length size as a delay guard to avoid interference between the pilot and data symbols. Hence, incurring a large spectral efficiency loss, especially in wideband systems where the channel length is large. To reduce the pilot overhead, we propose a novel split pilot structure with two impulse pilots. With two pilots, we can use one to cancel the other, thus, capable of removing the pilot interference over data. To remove the data interference from the pilot, we also propose an iterative joint channel estimation and detection technique tailored to the proposed split pilot structure. With the interference caused by the delay spread solved, we reduce the number of delay guards in our system by half, significantly improving the spectral efficiency. To corroborate our claims, we numerically demonstrate that our proposed method can achieve performance levels comparable to that of the full-guard method while using only half the delay guard. Additionally, we show that our proposed iterative channel estimating technique has a fast convergence speed, requiring only two iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11739v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Danilo Lelin Li, Sanoopkumar P. S., Arman Farhang</dc:creator>
    </item>
    <item>
      <title>A Structural Analysis of the User Behavior Dynamics for Environmentally Sustainable ICT</title>
      <link>https://arxiv.org/abs/2410.10977</link>
      <description>arXiv:2410.10977v1 Announce Type: cross 
Abstract: The sector of information and communication technology (ICT) can contribute to the fulfillment of the Paris agreement and the sustainable development goals (SDGs) through the introduction of sustainability strategies. For environmental sustainability, such strategies should contain efficiency, sufficiency, and consistency measures. To propose such, a structural analysis of ICT is undertaken in this manuscript. Thereby, key mechanisms and dynamics behind the usage of ICT and the corresponding energy and resource use are analyzed by describing ICT as a complex system. The system contains data centers, communication networks, smartphone hardware, apps, and the behavior of the users as sub-systems, between which various Morinian interactions are present. Energy and non-energy resources can be seen as inputs of the system, while e-waste is an output. Based on the system description, we propose multiple measures for efficiency, sufficiency and consistency to reduce greenhouse gas emissions and other environmental impacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10977v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Roth, Aydin Sezgin</dc:creator>
    </item>
    <item>
      <title>Intramuscular High-Density Micro-Electrode Arrays Enable High-Precision Decoding and Mapping of Spinal Motor Neurons to Reveal Hand Control</title>
      <link>https://arxiv.org/abs/2410.11016</link>
      <description>arXiv:2410.11016v1 Announce Type: cross 
Abstract: Decoding nervous system activity is a key challenge in neuroscience and neural interfacing. In this study, we propose a novel neural decoding system that enables unprecedented large-scale sampling of muscle activity. Using micro-electrode arrays with more than 100 channels embedded within the forearm muscles, we recorded high-density signals that captured multi-unit motor neuron activity. This extensive sampling was complemented by advanced methods for neural decomposition, analysis, and classification, allowing us to accurately detect and interpret the spiking activity of spinal motor neurons that innervate hand muscles. We evaluated this system in two healthy participants, each implanted with three electromyogram (EMG) micro-electrode arrays (comprising 40 electrodes each) in the forearm. These arrays recorded muscle activity during both single- and multi-digit isometric contractions. For the first time under controlled conditions, we demonstrate that multi-digit tasks elicit unique patterns of motor neuron recruitment specific to each task, rather than employing combinations of recruitment patterns from single-digit tasks. This observation led us to hypothesize that hand tasks could be classified with high precision based on the decoded neural activity. We achieved perfect classification accuracy (100%) across 12 distinct single- and multi-digit tasks, and consistently high accuracy (&gt;96\%) across all conditions and subjects, for up to 16 task classes. These results significantly outperformed conventional EMG classification methods. The exceptional performance of this system paves the way for developing advanced neural interfaces based on invasive high-density EMG technology. This innovation could greatly enhance human-computer interaction and lead to substantial improvements in assistive technologies, offering new possibilities for restoring motor function in clinical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11016v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agnese Grison, Jaime Ibanez Pereda, Silvia Muceli, Aritra Kundu, Farah Baracat, Giacomo Indiveri, Elisa Donati, Dario Farina</dc:creator>
    </item>
    <item>
      <title>Energy Efficient Transmission Parameters Selection Method Using Reinforcement Learning in Distributed LoRa Networks</title>
      <link>https://arxiv.org/abs/2410.11270</link>
      <description>arXiv:2410.11270v1 Announce Type: cross 
Abstract: With the increase in demand for Internet of Things (IoT) applications, the number of IoT devices has drastically grown, making spectrum resources seriously insufficient. Transmission collisions and retransmissions increase power consumption. Therefore, even in long-range (LoRa) networks, selecting appropriate transmission parameters, such as channel and transmission power, is essential to improve energy efficiency. However, due to the limited computational ability and memory, traditional transmission parameter selection methods for LoRa networks are challenging to implement on LoRa devices. To solve this problem, a distributed reinforcement learning-based channel and transmission power selection method is proposed, which can be implemented on the LoRa devices to improve energy efficiency in this paper. Specifically, the channel and transmission power selection problem in LoRa networks is first mapped to the multi-armed-bandit (MAB) problem. Then, an MAB-based method is introduced to solve the formulated transmission parameter selection problem based on the acknowledgment (ACK) packet and the power consumption for data transmission of the LoRa device. The performance of the proposed method is evaluated by the constructed actual LoRa network. Experimental results show that the proposed method performs better than fixed assignment, adaptive data rate low-complexity (ADR-Lite), and $\epsilon$-greedy-based methods in terms of both transmission success rate and energy efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11270v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryotai Airiyoshi, Mikio Hasegawa, Tomoaki Ohtsuki, Aohan Li</dc:creator>
    </item>
    <item>
      <title>Communication-Control Codesign for Large-Scale Wireless Networked Control Systems</title>
      <link>https://arxiv.org/abs/2410.11316</link>
      <description>arXiv:2410.11316v1 Announce Type: cross 
Abstract: Wireless Networked Control Systems (WNCSs) are essential to Industry 4.0, enabling flexible control in applications, such as drone swarms and autonomous robots. The interdependence between communication and control requires integrated design, but traditional methods treat them separately, leading to inefficiencies. Current codesign approaches often rely on simplified models, focusing on single-loop or independent multi-loop systems. However, large-scale WNCSs face unique challenges, including coupled control loops, time-correlated wireless channels, trade-offs between sensing and control transmissions, and significant computational complexity. To address these challenges, we propose a practical WNCS model that captures correlated dynamics among multiple control loops with spatially distributed sensors and actuators sharing limited wireless resources over multi-state Markov block-fading channels. We formulate the codesign problem as a sequential decision-making task that jointly optimizes scheduling and control inputs across estimation, control, and communication domains. To solve this problem, we develop a Deep Reinforcement Learning (DRL) algorithm that efficiently handles the hybrid action space, captures communication-control correlations, and ensures robust training despite sparse cross-domain variables and floating control inputs. Extensive simulations show that the proposed DRL approach outperforms benchmarks and solves the large-scale WNCS codesign problem, providing a scalable solution for industrial automation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11316v1</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaoyang Pang, Wanchun Liu, Dusit Niyato, Branka Vucetic, Yonghui Li</dc:creator>
    </item>
    <item>
      <title>Multi-Block UAMP Detection for AFDM under Fractional Delay-Doppler Channel</title>
      <link>https://arxiv.org/abs/2410.11421</link>
      <description>arXiv:2410.11421v1 Announce Type: cross 
Abstract: Affine Frequency Division Multiplexing (AFDM) is considered as a promising solution for next-generation wireless systems due to its satisfactory performance in high-mobility scenarios. By adjusting AFDM parameters to match the multi-path delay and Doppler shift, AFDM can achieve two-dimensional time-frequency diversity gain. However, under fractional delay-Doppler channels, AFDM encounters energy dispersion in the affine domain, which poses significant challenges for signal detection. This paper first investigates the AFDM system model under fractional delay-Doppler channels. To address the energy dispersion in the affine domain, a unitary transformation based approximate message passing (UAMP) algorithm is proposed. The algorithm performs unitary transformations and message passing in the time domain to avoid the energy dispersion issue. Additionally, we implemented block-wise processing to reduce computational complexity. Finally, the empirical extrinsic information transfer (E-EXIT) chart is used to evaluate iterative detection performance. Simulation results show that UAMP significantly outperforms GAMP under fractional delay-Doppler conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11421v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jin Xu, Zijian Liang, Kai Niu</dc:creator>
    </item>
    <item>
      <title>Channel Charting-Based Channel Prediction on Real-World Distributed Massive MIMO CSI</title>
      <link>https://arxiv.org/abs/2410.11486</link>
      <description>arXiv:2410.11486v1 Announce Type: cross 
Abstract: Distributed massive MIMO is considered a key advancement for improving the performance of next-generation wireless telecommunication systems. However, its efficacy in scenarios involving user mobility is limited due to channel aging. To address this challenge, channel prediction techniques are investigated to forecast future channel state information (CSI) based on previous estimates. We propose a new channel prediction method based on channel charting, a self-supervised learning technique that reconstructs a physically meaningful latent representation of the radio environment using similarity relationships between CSI samples. The concept of inertia within a channel chart allows for predictive radio resource management tasks through the latent space. We demonstrate that channel charting can be used to predict future CSI by exploiting spatial relationships between known estimates that are embedded in the channel chart. Our method is validated on a real-world distributed massive MIMO dataset, and compared to a Wiener predictor and the outdated CSI in terms of achievable sum rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11486v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Phillip Stephan, Florian Euchner, Stephan ten Brink</dc:creator>
    </item>
    <item>
      <title>Survey on Neighbor Discovery and Beam Alignment in mmWave-Enabled UAV Swarm Networks</title>
      <link>https://arxiv.org/abs/2410.11490</link>
      <description>arXiv:2410.11490v1 Announce Type: cross 
Abstract: Millimeter wave (mmWave)-enabled unmanned aerial vehicle (UAV) swarm networks (UAVSNs) can utilize a large spectrum of resources to provide low latency and high data transmission rate. Additionally, owing to the short wavelength, UAVs equipped with large antenna arrays can form secure narrow directive beam to establish communication with less interference. However, due to the high UAV mobility, limited beam coverage, beam misalignment, and high path loss, it is very challenging to adopt the mmWave communication in UAVSNs. In this article, we present a comprehensive survey on neighbor discovery and beam alignment techniques for directional communication in mmWave-enabled UAVSNs. The existing techniques are reviewed and compared with each other. We also discuss key open issues and challenges with potential research direction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11490v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The 11th International Conference on Smart Media and Applications (SMA 2022), Saipan, USA, 2022</arxiv:journal_reference>
      <dc:creator>Muhammad Morshed Alam, Sangman Moh</dc:creator>
    </item>
    <item>
      <title>Grover Adaptive Search with Spin Variables</title>
      <link>https://arxiv.org/abs/2410.11633</link>
      <description>arXiv:2410.11633v1 Announce Type: cross 
Abstract: This paper presents a novel approach to Grover adaptive search (GAS) for a combinatorial optimization problem whose objective function involves spin variables. While the GAS algorithm with a conventional design of a quantum dictionary subroutine handles a problem associated with an objective function with binary variables $\{0,1\}$, we reformulate the problem using spin variables $\{+1,-1\}$ to simplify the algorithm. Specifically, we introduce a novel quantum dictionary subroutine that is designed for this spin-based formulation. A key benefit of this approach is the substantial reduction in the number of CNOT gates required to construct the quantum circuit. We theoretically demonstrate that, for certain problems, our proposed approach can reduce the gate complexity from an exponential order to a polynomial order, compared to the conventional binary-based approach. This improvement has the potential to enhance the scalability and efficiency of GAS, particularly in larger quantum computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11633v1</guid>
      <category>quant-ph</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shintaro Fujiwara, Naoki Ishikawa</dc:creator>
    </item>
    <item>
      <title>Near-Field Communications for Extremely Large-Scale MIMO: A Beamspace Perspective</title>
      <link>https://arxiv.org/abs/2410.11736</link>
      <description>arXiv:2410.11736v1 Announce Type: cross 
Abstract: Extremely large-scale multiple-input multiple-output (XL-MIMO) is regarded as one of the key techniques to enhance the performance of future wireless communications. Different from regular MIMO, the XL-MIMO shifts part of the communication region from the far field to the near field, where the spherical-wave channel model cannot be accurately approximated by the commonly-adopted planar-wave channel model. As a result, the well-explored far-field beamspace is unsuitable for near-field communications, thereby requiring the exploration of specialized near-field beamspace. In this article, we investigate the near-field communications for XL-MIMO from the perspective of beamspace. Given the spherical wavefront characteristics of the near-field channels, we first map the antenna space to the near-field beamspace with the fractional Fourier transform. Then, we divide the near-field beamspace into three parts, including high mainlobe, low mainlobe, and sidelobe, and provide a comprehensive analysis of these components. Based on the analysis, we demonstrate the advantages of the near-field beamspace over the existing methods. Finally, we point out several applications of the near-field beamspace and highlight some potential directions for future study in the near-field beamspace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11736v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangjian Chen, Chenhao Qi, Jingjia Huang, Octavia A. Dobre, Geoffrey Ye Li</dc:creator>
    </item>
    <item>
      <title>A Survey on Indoor Visible Light Positioning Systems: Fundamentals, Applications, and Challenges</title>
      <link>https://arxiv.org/abs/2401.13893</link>
      <description>arXiv:2401.13893v2 Announce Type: replace 
Abstract: The growing demand for location-based services in areas like virtual reality, robot control, and navigation has intensified the focus on indoor localization. Visible light positioning (VLP), leveraging visible light communications (VLC), becomes a promising indoor positioning technology due to its high accuracy and low cost. This paper provides a comprehensive survey of VLP systems. In particular, since VLC lays the foundation for VLP, we first present a detailed overview of the principles of VLC. Then, we provide an in-depth overview of VLP algorithms. The performance of each positioning algorithm is also compared in terms of various metrics such as accuracy, coverage, and orientation limitation. Beyond the physical layer studies, the network design for a VLP system is also investigated, including multi-access technologies, resource allocation, and light-emitting diode (LED) placements. Next, the applications of the VLP systems are overviewed. Finally, this paper outlines open issues, challenges, and opportunities for the research field. In a nutshell, this paper constitutes the first holistic survey on VLP from state-of-the-art studies to practical uses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13893v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyu Zhu, Yang Yang, Mingzhe Chen, Caili Guo, Julian Cheng, Shuguang Cui</dc:creator>
    </item>
    <item>
      <title>Collaborative Deep Reinforcement Learning for Resource Optimization in Non-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2402.04056</link>
      <description>arXiv:2402.04056v2 Announce Type: replace 
Abstract: Non-terrestrial networks (NTNs) with low-earth orbit (LEO) satellites have been regarded as promising remedies to support global ubiquitous wireless services. Due to the rapid mobility of LEO satellite, inter-beam/satellite handovers happen frequently for a specific user equipment (UE). To tackle this issue, earth-fixed cell scenarios have been under studied, in which the LEO satellite adjusts its beam direction towards a fixed area within its dwell duration, to maintain stable transmission performance for the UE. Therefore, it is required that the LEO satellite performs real-time resource allocation, which however is unaffordable by the LEO satellite with limited computing capability. To address this issue, in this paper, we propose a two-time-scale collaborative deep reinforcement learning (DRL) scheme for beam management and resource allocation in NTNs, in which LEO satellite and UE with different control cycles update their decision-making policies through a sequential manner. Specifically, UE updates its policy subject to improving the value functions of both the agents. Furthermore, the LEO satellite only makes decisions through finite-step rollouts with a reference decision trajectory received from the UE. Simulation results show that the proposed scheme can effectively balance the throughput performance and computational complexity over traditional greedy-searching schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04056v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cao (Sherman), Shao-Yu Lien (Sherman), Ying-Chang Liang (Sherman), Dusit Niyato (Sherman),  Xuemin (Sherman),  Shen</dc:creator>
    </item>
    <item>
      <title>Collaborative Computing in Non-Terrestrial Networks: A Multi-Time-Scale Deep Reinforcement Learning Approach</title>
      <link>https://arxiv.org/abs/2402.04865</link>
      <description>arXiv:2402.04865v2 Announce Type: replace 
Abstract: Constructing earth-fixed cells with low-earth orbit (LEO) satellites in non-terrestrial networks (NTNs) has been the most promising paradigm to enable global coverage. The limited computing capabilities on LEO satellites however render tackling resource optimization within a short duration a critical challenge. Although the sufficient computing capabilities of the ground infrastructures can be utilized to assist the LEO satellite, different time-scale control cycles and coupling decisions between the space- and ground-segments still obstruct the joint optimization design for computing agents at different segments. To address the above challenges, in this paper, a multi-time-scale deep reinforcement learning (DRL) scheme is developed for achieving the radio resource optimization in NTNs, in which the LEO satellite and user equipment (UE) collaborate with each other to perform individual decision-making tasks with different control cycles. Specifically, the UE updates its policy toward improving value functions of both the satellite and UE, while the LEO satellite only performs finite-step rollout for decision-makings based on the reference decision trajectory provided by the UE. Most importantly, rigorous analysis to guarantee the performance convergence of the proposed scheme is provided. Comprehensive simulations are conducted to justify the effectiveness of the proposed scheme in balancing the transmission performance and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04865v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Cao (Sherman), Shao-Yu Lien (Sherman), Ying-Chang Liang (Sherman), Dusit Niyato (Sherman),  Xuemin (Sherman),  Shen</dc:creator>
    </item>
    <item>
      <title>Mobile Edge Generation-Enabled Digital Twin: Architecture Design and Research Opportunities</title>
      <link>https://arxiv.org/abs/2407.02804</link>
      <description>arXiv:2407.02804v3 Announce Type: replace 
Abstract: A novel paradigm of mobile edge generation (MEG)-enabled digital twin (DT) is proposed, which enables distributed on-device generation at mobile edge networks for real-time DT applications. First, an MEG-DT architecture is put forward to decentralize generative artificial intelligence (GAI) models onto edge servers (ESs) and user equipments (UEs), which has the advantages of low latency, privacy preservation, and individual-level customization. Then, various single-user and multi-user generation mechanisms are conceived for MEG-DT, which strike trade-offs between generation latency, hardware costs, and device coordination. Furthermore, to perform efficient distributed generation, two operating protocols are explored for transmitting interpretable and latent features between ESs and UEs, namely sketch-based generation and seed-based generation, respectively. Based on the proposed protocols, the convergence between MEG and DT are highlighted. Considering the seed-based image generation scenario, numerical case studies are provided to reveal the superiority of MEG-DT over centralized generation. Finally, promising applications and research opportunities are identified. Code is available at https://github.com/xiaoxiaxusummer/MEG_DT</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02804v3</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Xu, Ruikang Zhong, Xidong Mu, Yuanwei Liu, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Development of a Digital Front-End for Electrooculography Circuits to Facilitate Digital Communication in Individuals with Communicative and Motor Disabilities</title>
      <link>https://arxiv.org/abs/2410.03013</link>
      <description>arXiv:2410.03013v2 Announce Type: replace 
Abstract: This project developed a cost-effective, digital-viable front-end for electrooculography (EOG) circuits aimed at enabling communication for individuals with Locked-in Syndrome (LIS) and Amyotrophic Lateral Sclerosis (ALS). Using the TL072 operational amplifier, the system amplifies weak EOG signals and processes them through an Arduino Uno for real-time monitoring. The circuit includes preamplification, filtering between 0.1 Hz and 30 Hz, and final amplification stages, achieving accurate eye movement tracking with a 256 Hz sampling rate. The approach to this was described in detail, with a comparison drawn between the theoretical expectations of our circuit design and its viability in contrast to the actual values measured. Our readings aimed to create an interface that optimized max-gaze angle readings by outputting a maximum reading at values above the baseline theory of our amplification circuit. From this, we measured the latency between the serial output and action, analyzing video recordings of such readings. The Latency value read reached around 20ms, which is within the tolerance for proper communication and did not seriously affect the readings. Beyond this, challenges such as noise interference (with an SNR of 1.07 dB) remain despite achieving reliable signal amplification. This was during a test of the analog functionality of this circuit. However, its limitations mean that future improvements will focus on reducing environmental interference, optimizing electrode placement, applying a novel detection algorithm to optimize communication applications, and enhancing signal clarity to make the system more effective for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03013v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andre Heid Rocha da Costa, Keiran Robert O'Keeffe</dc:creator>
    </item>
    <item>
      <title>Optimizing Energy Efficiency with RSMA: Balancing Low and High QoS Requirements</title>
      <link>https://arxiv.org/abs/2410.06061</link>
      <description>arXiv:2410.06061v2 Announce Type: replace 
Abstract: Future wireless systems are expected to deliver significantly higher quality-of-service (QoS) albeit with fewer energy resources for diverse, already existing and also novel wireless applications. The optimal resource allocation for a system in this regard could be investigated by reducing the overall power available at the expense of reduced QoS for the inefficient users. In other words, we maximize the system energy efficiency by achieving power saving through a minimal back-off in terms of QoS. In this paper, we investigate the energy efficiency vs. delivered QoS trade-off for the rate-splitting multiple access (RSMA) assisted downlink system. We first determine the user grouping with a normalised channel similarity metric so as to allow a large number of users with non-zero achievable private message rates. Through the private message removal (PMR) of these users, we aim to investigate the QoS vs. energy efficiency trade-off. Numerical results indicate a peak of ~$10\%$ increase in the network energy efficiency for the proposed normalised channel similarity metric based user grouping with scheduled PMR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06061v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srivardhan Sivadevuni, Kevin Weinberger, Aydin Sezgin</dc:creator>
    </item>
    <item>
      <title>Generative Artificial Intelligence (GAI) for Mobile Communications: A Diffusion Model Perspective</title>
      <link>https://arxiv.org/abs/2410.06389</link>
      <description>arXiv:2410.06389v2 Announce Type: replace 
Abstract: This article targets at unlocking the potentials of a class of prominent generative artificial intelligence (GAI) method, namely diffusion model (DM), for mobile communications. First, a DM-driven communication architecture is proposed, which introduces two key paradigms, i.e., conditional DM and DM-driven deep reinforcement learning (DRL), for wireless data generation and communication management, respectively. Then, we discuss the key advantages of DM-driven communication paradigms. To elaborate further, we explore DM-driven channel generation mechanisms for channel estimation, extrapolation, and feedback in multiple-input multiple-output (MIMO) systems. We showcase the numerical performance of conditional DM using the accurate DeepMIMO channel datasets, revealing its superiority in generating high-fidelity channels and mitigating unforeseen distribution shifts in sophisticated scenes. Furthermore, several DM-driven communication management designs are conceived, which is promising to deal with imperfect channels and task-oriented communications. To inspire future research developments, we highlight the potential applications and open research challenges of DM-driven communications. Code is available at https://github.com/xiaoxiaxusummer/GAI COMM/</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06389v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxia Xu, Xidong Mu, Yuanwei Liu, Hong Xing, Yue Liu, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>A Novel RFID Authentication Protocol Based on A Block-Order-Modulus Variable Matrix Encryption Algorithm</title>
      <link>https://arxiv.org/abs/2312.10593</link>
      <description>arXiv:2312.10593v4 Announce Type: replace-cross 
Abstract: In this paper, authentication for mobile radio frequency identification (RFID) systems with low-cost RFID sensor tags is studied. Firstly, an adaptive modulus (AM) encryption algorithm is proposed. Subsequently, in order to enhance the security without additional storage of new key matrices, a self-updating encryption order (SUEO) algorithm is designed. Furthermore, a diagonal block local transpose key matrix (DBLTKM) encryption algorithm is presented, which effectively expands the feasible domain of the key space. Based on the above three algorithms, a novel joint AM-SUEO-DBLTKM encryption algorithm is constructed. Making full use of the advantages of the proposed joint algorithm, a two-way RFID authentication protocol, named AM-SUEO-DBLTKM-RFID, is proposed for mobile RFID systems. In addition, the Burrows-Abadi-Needham (BAN) logic and security analysis indicate that the proposed AM-SUEO-DBLTKM-RFID protocol can effectively combat various typical attacks. Numerical results demonstrate that the proposed AM-SUEO-DBLTKM algorithm can save 99.59% of tag storage over traditional algorithms. Finally, the low computational complexity as well as the low storage cost of the proposed AM-SUEO-DBLTKM-RFID protocol facilitates deployment within low-cost RFID sensor tags.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10593v4</guid>
      <category>cs.CR</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Wang, Ruiqi Liu, Tong Gao, Feng Shu, Xuemei Lei, Yongpeng Wu, Guan Gui, Jiangzhou Wang</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network based Active and Passive Beamforming for Distributed STAR-RIS-Assisted Multi-User MISO Systems</title>
      <link>https://arxiv.org/abs/2405.01979</link>
      <description>arXiv:2405.01979v2 Announce Type: replace-cross 
Abstract: This paper investigates a joint active and passive beamforming design for distributed simultaneous transmitting and reflecting (STAR) reconfigurable intelligent surface (RIS) assisted multi-user (MU)- mutiple input single output (MISO) systems, where the energy splitting (ES) mode is considered for the STAR-RIS. We aim to design the active beamforming vectors at the base station (BS) and the passive beamforming at the STAR-RIS to maximize the user sum rate under transmitting power constraints. The formulated problem is non-convex and nontrivial to obtain the global optimum due to the coupling between active beamforming vectors and STAR-RIS phase shifts. To efficiently solve the problem, we propose a novel graph neural network (GNN)-based framework. Specifically, we first model the interactions among users and network entities are using a heterogeneous graph representation. A heterogeneous graph neural network (HGNN) implementation is then introduced to directly optimizes beamforming vectors and STAR-RIS coefficients with the system objective. Numerical results show that the proposed approach yields efficient performance compared to the previous benchmarks. Furthermore, the proposed GNN is scalable with various system configurations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01979v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ha An Le, Trinh Van Chien, Wan Choi</dc:creator>
    </item>
    <item>
      <title>OFDM Achieves the Lowest Ranging Sidelobe Under Random ISAC Signaling</title>
      <link>https://arxiv.org/abs/2407.06691</link>
      <description>arXiv:2407.06691v2 Announce Type: replace-cross 
Abstract: This paper aims to answer a fundamental question in the area of Integrated Sensing and Communications (ISAC): What is the optimal communication-centric ISAC waveform for ranging? Towards that end, we first established a generic framework to analyze the sensing performance of communication-centric ISAC waveforms built upon orthonormal signaling bases and random data symbols. Then, we evaluated their ranging performance by adopting both the periodic and aperiodic auto-correlation functions (P-ACF and A-ACF), and defined the expectation of the integrated sidelobe level (EISL) as a sensing performance metric. On top of that, we proved that among all communication waveforms with cyclic prefix (CP), the orthogonal frequency division multiplexing (OFDM) modulation is the only globally optimal waveform that achieves the lowest ranging sidelobe for quadrature amplitude modulation (QAM) and phase shift keying (PSK) constellations, in terms of both the EISL and the sidelobe level at each individual lag of the P-ACF. As a step forward, we proved that among all communication waveforms without CP, OFDM is a locally optimal waveform for QAM/PSK in the sense that it achieves a local minimum of the EISL of the A-ACF. Finally, we demonstrated by numerical results that under QAM/PSK constellations, there is no other orthogonal communication-centric waveform that achieves a lower ranging sidelobe level than that of the OFDM, in terms of both P-ACF and A-ACF cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06691v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Liu, Ying Zhang, Yifeng Xiong, Shuangyang Li, Weijie Yuan, Feifei Gao, Shi Jin, Giuseppe Caire</dc:creator>
    </item>
    <item>
      <title>Foundation Models for ECG: Leveraging Hybrid Self-Supervised Learning for Advanced Cardiac Diagnostics</title>
      <link>https://arxiv.org/abs/2407.07110</link>
      <description>arXiv:2407.07110v2 Announce Type: replace-cross 
Abstract: Using foundation models enhanced by self-supervised learning (SSL) methods presents an innovative approach to electrocardiogram (ECG) analysis, which is crucial for cardiac health monitoring and diagnosis. This study comprehensively evaluates foundation models for ECGs, leveraging SSL methods, including generative and contrastive learning, on a vast dataset comprising approximately 1.3 million ECG samples. By integrating these methods with consideration of the unique characteristics of ECGs, we developed a Hybrid Learning (HL) for foundation models that improve the precision and reliability of cardiac diagnostics. The HL-based foundation model adeptly captures the intricate details of ECGs, enhancing diagnostic capability. The results underscore the considerable potential of SSL-enhanced foundation models in clinical settings, setting the stage for future research into their scalable applications across a broader range of medical diagnostics. This work sets a new standard in the ECG field, emphasizing the transformative influence of tailored, data-driven model training on the effectiveness and accuracy of medical diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07110v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junho Song, Jong-Hwan Jang, Byeong Tak Lee, DongGyun Hong, Joon-myoung Kwon, Yong-Yeon Jo</dc:creator>
    </item>
    <item>
      <title>TADA: Temporal Adversarial Data Augmentation for Time Series Data</title>
      <link>https://arxiv.org/abs/2407.15174</link>
      <description>arXiv:2407.15174v2 Announce Type: replace-cross 
Abstract: Domain generalization aim to train models to effectively perform on samples that are unseen and outside of the distribution. Adversarial data augmentation (ADA) is a widely used technique in domain generalization. It enhances the model robustness by including synthetic samples designed to simulate potential unseen scenarios into the training datasets, which is then used to train the model. However, in time series data, traditional ADA approaches often fail to address distribution shifts related to temporal characteristics. To address this limitation, we propose Temporal Adversarial Data Augmentation (TADA) for time series data, which incorporate time warping into ADA. Although time warping is inherently non-differentiable, ADA relies on generating samples through backpropagation. We resolve this issue by leveraging the duality between phase shifts in the frequency domain and time shifts in the time domain, thereby making the process differentiable. Our evaluations across various time series datasets demonstrate that TADA outperforms existing methods for domain generalization. In addition, using distribution visualization, we confirmed that the distribution shifts induced by TADA are clearly different from those induced by ADA, and together, they effectively simulate real-world distribution shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15174v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 16 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Byeong Tak Lee, Joon-myoung Kwon, Yong-Yeon Jo</dc:creator>
    </item>
  </channel>
</rss>
