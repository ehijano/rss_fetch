<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 15 May 2025 04:02:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Agency Problems and Adversarial Bilevel Optimization under Uncertainty and Cyber Threats</title>
      <link>https://arxiv.org/abs/2505.08989</link>
      <description>arXiv:2505.08989v1 Announce Type: new 
Abstract: We study an agency problem between a holding company and its subsidiary, exposed to cyber threats that affect the overall value of the subsidiary. The holding company seeks to design an optimal incentive scheme to mitigate these losses. In response, the subsidiary selects an optimal cybersecurity investment strategy, modeled through a stochastic epidemiological SIR (Susceptible-Infected-Recovered) framework. The cyber threat landscape is captured through an L-hop risk framework with two primary sources of risk: (i) internal risk propagation via the contagion parameters in the SIR model, and (ii) external cyberattacks from a malicious external hacker. The uncertainty and adversarial nature of the hacking lead to consider a robust stochastic control approach that allows for increased volatility and ambiguity induced by cyber incidents. The agency problem is formulated as a max-min bilevel stochastic control problem with accidents. First, we derive the incentive compatibility condition by reducing the subsidiary's optimal response to the solution of a second-order backward stochastic differential equation with jumps. Next, we demonstrate that the principal's problem can be equivalently reformulated as an integro-partial Hamilton-Jacobi-Bellman-Isaacs (HJBI) equation. By extending the stochastic Perron's method to our setting, we show that the value function of the problem is the unique viscosity solution to the resulting integro-partial HJBI equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08989v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibaut Mastrolia, William Yan</dc:creator>
    </item>
    <item>
      <title>Aging-Aware Battery Control via Convex Optimization</title>
      <link>https://arxiv.org/abs/2505.09030</link>
      <description>arXiv:2505.09030v1 Announce Type: new 
Abstract: We consider the task of controlling a battery while balancing two competing objectives that evolve over different time scales. The short-term objective, such as arbitrage or load smoothing, improves with more battery cycling, while the long-term objective is to maximize battery lifetime, which discourages cycling. Using a semi-empirical aging model, we formulate this problem as a convex optimization problem. We use model predictive control (MPC) with a convex approximation of aging dynamics to optimally manage the trade-off between performance and degradation. Through simulations, we quantify this trade-off in both economic and smoothing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09030v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Obidike Nnorom Jr., Giray Ogut, Stephen Boyd, Philip Levis</dc:creator>
    </item>
    <item>
      <title>The Adaptive Complexity of Finding a Stationary Point</title>
      <link>https://arxiv.org/abs/2505.09045</link>
      <description>arXiv:2505.09045v1 Announce Type: new 
Abstract: In large-scale applications, such as machine learning, it is desirable to design non-convex optimization algorithms with a high degree of parallelization. In this work, we study the adaptive complexity of finding a stationary point, which is the minimal number of sequential rounds required to achieve stationarity given polynomially many queries executed in parallel at each round.
  For the high-dimensional case, i.e., $d = \widetilde{\Omega}(\varepsilon^{-(2 + 2p)/p})$, we show that for any (potentially randomized) algorithm, there exists a function with Lipschitz $p$-th order derivatives such that the algorithm requires at least $\varepsilon^{-(p+1)/p}$ iterations to find an $\varepsilon$-stationary point. Our lower bounds are tight and show that even with $\mathrm{poly}(d)$ queries per iteration, no algorithm has better convergence rate than those achievable with one-query-per-round algorithms. In other words, gradient descent, the cubic-regularized Newton's method, and the $p$-th order adaptive regularization method are adaptively optimal. Our proof relies upon novel analysis with the characterization of the output for the hardness potentials based on a chain-like structure with random partition.
  For the constant-dimensional case, i.e., $d = \Theta(1)$, we propose an algorithm that bridges grid search and gradient flow trapping, finding an approximate stationary point in constant iterations. Its asymptotic tightness is verified by a new lower bound on the required queries per iteration. We show there exists a smooth function such that any algorithm running with $\Theta(\log (1/\varepsilon))$ rounds requires at least $\widetilde{\Omega}((1/\varepsilon)^{(d-1)/2})$ queries per round. This lower bound is tight up to a logarithmic factor, and implies that the gradient flow trapping is adaptively optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09045v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huanjian Zhou, Andi Han, Akiko Takeda, Masashi Sugiyama</dc:creator>
    </item>
    <item>
      <title>Solving Reach- and Stabilize-Avoid Problems Using Discounted Reachability</title>
      <link>https://arxiv.org/abs/2505.09067</link>
      <description>arXiv:2505.09067v1 Announce Type: new 
Abstract: In this article, we consider the infinite-horizon reach-avoid (RA) and stabilize-avoid (SA) zero-sum game problems for general nonlinear continuous-time systems, where the goal is to find the set of states that can be controlled to reach or stabilize to a target set, without violating constraints even under the worst-case disturbance. Based on the Hamilton-Jacobi reachability method, we address the RA problem by designing a new Lipschitz continuous RA value function, whose zero sublevel set exactly characterizes the RA set. We establish that the associated Bellman backup operator is contractive and that the RA value function is the unique viscosity solution of a Hamilton-Jacobi variational inequality. Finally, we develop a two-step framework for the SA problem by integrating our RA strategies with a recently proposed Robust Control Lyapunov-Value Function, thereby ensuring both target reachability and long-term stability. We numerically verify our RA and SA frameworks on a 3D Dubins car system to demonstrate the efficacy of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09067v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boyang Li, Zheng Gong, Sylvia Herbert</dc:creator>
    </item>
    <item>
      <title>Reflected stochastic recursive control problems with jumps: dynamic programming and stochastic verification theorems</title>
      <link>https://arxiv.org/abs/2505.09070</link>
      <description>arXiv:2505.09070v1 Announce Type: new 
Abstract: This paper mainly investigates reflected stochastic recursive control problems governed by jump-diffusion dynamics. The system's state evolution is described by a stochastic differential equation driven by both Brownian motion and Poisson random measures, while the recursive cost functional is formulated via the solution process Y of a reflected backward stochastic differential equation driven by the same dual stochastic sources. By establishing the dynamic programming principle, we provide the probabilistic interpretation of an obstacle problem for partial integro-differential equations of Hamilton-Jacobi-Bellman type in the viscosity solution sense through our control problem's value function. Furthermore, the value function is proved to inherit the semi-concavity and joint Lipschitz continuity in state and time coordinates, which play key roles in deriving stochastic verification theorems of control problem within the framework of viscosity solutions. We remark that some restrictions in previous study are eliminated, such as the frozen of the reflected processes in time and state, and the independence of the driver from diffusion variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09070v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Liu, Qingmeng Wei</dc:creator>
    </item>
    <item>
      <title>An accelerated proximal PRS-SQP algorithm with dual ascent-descent procedures for smooth composite optimization</title>
      <link>https://arxiv.org/abs/2505.09078</link>
      <description>arXiv:2505.09078v1 Announce Type: new 
Abstract: Conventional wisdom in composite optimization suggests augmented Lagrangian dual ascent (ALDA) in Peaceman-Rachford splitting (PRS) methods for dual feasibility. However, ALDA may fail when the primal iterate is a local minimum, a stationary point, or a coordinatewise solution of the highly nonconvex augmented Lagrangian function. Splitting sequential quadratic programming (SQP) methods utilize augmented Lagrangian dual descent (ALDD) to directly minimize the primal residual, circumventing the limitations of ALDA and achieving faster convergence in smooth optimization. This paper aims to present a fairly accessible generalization of two contrasting dual updates, ALDA and ALDD, for smooth composite optimization. A key feature of our PRS-SQP algorithm is its dual ascent-descent procedure, which provides a free direction rule for the dual updates and a new insight to explain the counterintuitive convergence behavior. Furthermore, we incorporate a hybrid acceleration technique that combines inertial extrapolation and back substitution to improve convergence. Theoretically, we establish the feasibility for a wider range of acceleration factors than previously known and derive convergence rates within the Kurdyka- Lojasiewicz framework. Numerical experiments validate the effectiveness and stability of the proposed method in various dual-update scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09078v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Jin, Guodong Ma, Jinbao Jian</dc:creator>
    </item>
    <item>
      <title>Derivative-free optimization is competitive for aerodynamic design optimization in moderate dimensions</title>
      <link>https://arxiv.org/abs/2505.09088</link>
      <description>arXiv:2505.09088v1 Announce Type: new 
Abstract: Aerodynamic design optimization is an important problem in aircraft design that depends on the interplay between a numerical optimizer and a high-fidelity flow physics solver. Derivative-based, first and (quasi) second order, optimization techniques are the de facto choice, particularly given the availability of the adjoint method and its ability to efficiently compute gradients at the cost of just one solution of the forward problem. However, implementation of the adjoint method requires careful mathematical treatment, and its sensitivity to changes in mesh quality limits widespread applicability. Derivative-free approaches are often overlooked for large scale optimization, citing their lack of scalability in higher dimensions and/or the lack of practical interest in globally optimal solutions that they often target. However, breaking free from an adjoint solver can be paradigm-shifting in broadening the applicability of aerodynamic design optimization. We provide a systematic benchmarking of a select sample of widely used derivative-based and derivative-free optimization algorithms on the design optimization of three canonical aerodynamic bodies, namely, the NACA0012 and RAE2822 airfoils, and the ONERAM6 wing. Our results demonstrate that derivative-free methods are competitive with derivative-based methods, while outperforming them consistently in the high-dimensional setting. These findings highlight the practical competitiveness of modern derivative-free strategies, offering a scalable and robust alternative for aerodynamic design optimization when adjoint-based gradients are unavailable or unreliable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09088v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Punya Plaban, Peter Bachman, Ashwin Renganathan</dc:creator>
    </item>
    <item>
      <title>Optimization via First-Order Switching Methods: Skew-Symmetric Dynamics and Optimistic Discretization</title>
      <link>https://arxiv.org/abs/2505.09146</link>
      <description>arXiv:2505.09146v1 Announce Type: new 
Abstract: Large-scale constrained optimization problems are at the core of many tasks in control, signal processing, and machine learning. Notably, problems with functional constraints arise when, beyond a performance{\nobreakdash-}centric goal (e.g., minimizing the empirical loss), one desires to satisfy other requirements such as robustness, fairness, etc. A simple method for such problems, which remarkably achieves optimal rates for non-smooth, convex, strongly convex, and weakly convex functions under first-order oracle, is Switching Gradient Method (SGM): in each iteration depending on a predetermined constraint violation tolerance, use the gradient of objective or the constraint as the update vector. While the performance of SGM is well-understood for non-smooth functions and in fact matches its unconstrained counterpart, i.e., Gradient Descent (GD), less is formally established about its convergence properties under the smoothness of loss and constraint functions. In this work, we aim to fill this gap. First, we show that SGM may not benefit from faster rates under smoothness, in contrast to improved rates for GD under smoothness. By taking a continuous-time limit perspective, we show the issue is fundamental to SGM's dynamics and not an artifact of our analysis. Our continuous-time limit perspective further provides insights towards alleviating SGM's shortcomings. Notably, we show that leveraging the idea of optimism, a well-explored concept in variational inequalities and min-max optimization, could lead to faster methods. This perspective further enables designing a new class of ``soft'' switching methods, for which we further analyze their iteration complexity under mild assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09146v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antesh Upadhyay, Sang Bin Moon, Abolfazl Hashemi</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Optimization for Non-Smooth and Weakly Convex Problems under Heavy-Tailed Noise</title>
      <link>https://arxiv.org/abs/2505.09279</link>
      <description>arXiv:2505.09279v1 Announce Type: new 
Abstract: In existing distributed stochastic optimization studies, it is usually assumed that the gradient noise has a bounded variance. However, recent research shows that the heavy-tailed noise, which allows an unbounded variance, is closer to practical scenarios in many tasks. Under heavy-tailed noise, traditional optimization methods, such as stochastic gradient descent, may have poor performance and even diverge. Thus, it is of great importance to study distributed stochastic optimization algorithms applicable to the heavy-tailed noise scenario. However, most of the existing distributed algorithms under heavy-tailed noise are developed for convex and smooth problems, which limits their applications. This paper proposes a clipping-based distributed stochastic algorithm under heavy-tailed noise that is suitable for non-smooth and weakly convex problems. The convergence of the proposed algorithm is proven, and the conditions on the parameters are given. A numerical experiment is conducted to demonstrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09279v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jun Hu, Chao Sun, Bo Chen, Jianzheng Wang, Zheming Wang</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimal Control for Systems with Drifts of Bounded Variation: A Maximum Principle Approach</title>
      <link>https://arxiv.org/abs/2505.09309</link>
      <description>arXiv:2505.09309v1 Announce Type: new 
Abstract: In this paper, we study the problem of stochastic optimal control for systems governed by stochastic differential equations (SDEs) with drift coefficients of bounded variation. We establish both necessary and sufficient stochastic maximum principle. To achieve this, we prove the existence and uniqueness of solutions to SDEs with random drifts of bounded variation. We then show that these solutions are Sobolev differentiable with respect to their initial conditions and provide an explicit representation involving integrals with respect to the local time of the state process. We handle the irregular drift, by constructing a sequence of approximating control problems with smooth coefficients. By applying Ekeland's variational principle, we obtain a sequence of adjoint processes, which we then use to derive the maximum principle by taking the limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09309v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Antoine Marie Bogso, Rhoss Likibi Pellat, Donatien Kuissi Kamdem, Olivier Menoukeu Pamen</dc:creator>
    </item>
    <item>
      <title>Safe Primal-Dual Optimization with a Single Smooth Constraint</title>
      <link>https://arxiv.org/abs/2505.09349</link>
      <description>arXiv:2505.09349v1 Announce Type: new 
Abstract: This paper addresses the problem of safe optimization under a single smooth constraint, a scenario that arises in diverse real-world applications such as robotics and autonomous navigation. The objective of safe optimization is to solve a black-box minimization problem while strictly adhering to a safety constraint throughout the learning process. Existing methods often suffer from high sample complexity due to their noise sensitivity or poor scalability with number of dimensions, limiting their applicability. We propose a novel primal-dual optimization method that, by carefully adjusting dual step-sizes and constraining primal updates, ensures the safety of both primal and dual sequences throughout the optimization. Our algorithm achieves a convergence rate that significantly surpasses current state-of-the-art techniques. Furthermore, to the best of our knowledge, it is the first primal-dual approach to guarantee safe updates. Simulations corroborate our theoretical findings, demonstrating the practical benefits of our method. We also show how the method can be extended to multiple constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09349v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ilnura Usmanova, Kfir Yehuda Levy</dc:creator>
    </item>
    <item>
      <title>A Learning-Based Inexact ADMM for Solving Quadratic Programs</title>
      <link>https://arxiv.org/abs/2505.09391</link>
      <description>arXiv:2505.09391v1 Announce Type: new 
Abstract: Convex quadratic programs (QPs) constitute a fundamental computational primitive across diverse domains including financial optimization, control systems, and machine learning. The alternating direction method of multipliers (ADMM) has emerged as a preferred first-order approach due to its iteration efficiency - exemplified by the state-of-the-art OSQP solver. Machine learning-enhanced optimization algorithms have recently demonstrated significant success in speeding up the solving process. This work introduces a neural-accelerated ADMM variant that replaces exact subproblem solutions with learned approximations through a parameter-efficient Long Short-Term Memory (LSTM) network. We derive convergence guarantees within the inexact ADMM formalism, establishing that our learning-augmented method maintains primal-dual convergence while satisfying residual thresholds. Extensive experimental results demonstrate that our approach achieves superior solution accuracy compared to existing learning-based methods while delivering significant computational speedups of up to $7\times$, $28\times$, and $22\times$ over Gurobi, SCS, and OSQP, respectively. Furthermore, the proposed method outperforms other learning-to-optimize methods in terms of solution quality. Detailed performance analysis confirms near-perfect compliance with the theoretical assumptions, consequently ensuring algorithm convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09391v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Gao, Jinxin Xiong, Linxin Yang, Akang Wang, Weiwei Xu, Jiang Xue</dc:creator>
    </item>
    <item>
      <title>On some applications of the Boundary Control method to spectral estimation and inverse problems</title>
      <link>https://arxiv.org/abs/2505.09410</link>
      <description>arXiv:2505.09410v1 Announce Type: new 
Abstract: We consider applications of the Boundary Control (BC) method to generalized spectral estimation problems and to inverse source problems. We derive the equations of the BC method for this problems and show that solvability of this equations crucially depends on the controllability properties of the corresponding dynamical system and properties of corresponding families of exponentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09410v1</guid>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.17586/2220-8054-2015-6-1-63-78</arxiv:DOI>
      <dc:creator>S. A. Avdonin, A. S. Mikhaylov, A. S. Mikhaylov</dc:creator>
    </item>
    <item>
      <title>Single-loop $\mathcal{O}(\epsilon^{-3})$ stochastic smoothing algorithms for nonsmooth Riemannian optimization</title>
      <link>https://arxiv.org/abs/2505.09485</link>
      <description>arXiv:2505.09485v1 Announce Type: new 
Abstract: In this paper, we develop two Riemannian stochastic smoothing algorithms for nonsmooth optimization problems on Riemannian manifolds, addressing distinct forms of the nonsmooth term \( h \). Both methods combine dynamic smoothing with a momentum-based variance reduction scheme in a fully online manner. When \( h \) is Lipschitz continuous, we propose an stochastic algorithm under adaptive parameter that achieves the optimal iteration complexity of \( \mathcal{O}(\epsilon^{-3}) \), improving upon the best-known rates for exist algorithms. When \( h \) is the indicator function of a convex set, we design a new algorithm using truncated momentum, and under a mild error bound condition with parameter \( \theta \geq 1 \), we establish a complexity of \( \tilde{\mathcal{O}}(\epsilon^{-\max\{\theta+2, 2\theta\}}) \), in line with the best-known results in the Euclidean setting. Both algorithms feature a single-loop design with low per-iteration cost and require only \( \mathcal{O}(1) \) samples per iteration, ensuring that sample and iteration complexities coincide. Our framework encompasses a broad class of problems and recovers or matches optimal complexity guarantees in several important settings, including smooth stochastic Riemannian optimization, composite problems in Euclidean space, and constrained optimization via indicator functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09485v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kangkang Deng, Zheng Peng, Weihe Wu</dc:creator>
    </item>
    <item>
      <title>RDA-PSO: A computational method to quantify the diffusive dispersal of insects</title>
      <link>https://arxiv.org/abs/2505.08848</link>
      <description>arXiv:2505.08848v1 Announce Type: cross 
Abstract: This article introduces a computational method, called "Recapture of Diffusive Agents &amp; Particle Swarm Optimization" (RDA-PSO), designed to estimate the dispersal parameter of diffusive insects in mark-release-recapture (MRR) field experiments. In addition to describing the method, its properties are discussed, with particular focus on robustness in estimating the observed diffusion coefficient. It is shown that RDA-PSO provides a simple and reliable approach to quantify mosquito dispersal that outperforms other techniques based on the solution of the diffusion equation, three of which are also introduced in this work. Examples of application to both synthetic and real field data for the yellow fever mosquito are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08848v1</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lidia Mrad, Joceline Lega</dc:creator>
    </item>
    <item>
      <title>Learning Cocoercive Conservative Denoisers via Helmholtz Decomposition for Poisson Inverse Problems</title>
      <link>https://arxiv.org/abs/2505.08909</link>
      <description>arXiv:2505.08909v1 Announce Type: cross 
Abstract: Plug-and-play (PnP) methods with deep denoisers have shown impressive results in imaging problems. They typically require strong convexity or smoothness of the fidelity term and a (residual) non-expansive denoiser for convergence. These assumptions, however, are violated in Poisson inverse problems, and non-expansiveness can hinder denoising performance. To address these challenges, we propose a cocoercive conservative (CoCo) denoiser, which may be (residual) expansive, leading to improved denoising. By leveraging the generalized Helmholtz decomposition, we introduce a novel training strategy that combines Hamiltonian regularization to promote conservativeness and spectral regularization to ensure cocoerciveness. We prove that CoCo denoiser is a proximal operator of a weakly convex function, enabling a restoration model with an implicit weakly convex prior. The global convergence of PnP methods to a stationary point of this restoration model is established. Extensive experimental results demonstrate that our approach outperforms closely related methods in both visual quality and quantitative metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08909v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deliang Wei, Peng Chen, Haobo Xu, Jiale Yao, Fang Li, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>Birch SGD: A Tree Graph Framework for Local and Asynchronous SGD Methods</title>
      <link>https://arxiv.org/abs/2505.09218</link>
      <description>arXiv:2505.09218v1 Announce Type: cross 
Abstract: We propose a new unifying framework, Birch SGD, for analyzing and designing distributed SGD methods. The central idea is to represent each method as a weighted directed tree, referred to as a computation tree. Leveraging this representation, we introduce a general theoretical result that reduces convergence analysis to studying the geometry of these trees. This perspective yields a purely graph-based interpretation of optimization dynamics, offering a new and intuitive foundation for method development. Using Birch SGD, we design eight new methods and analyze them alongside previously known ones, with at least six of the new methods shown to have optimal computational time complexity. Our research leads to two key insights: (i) all methods share the same "iteration rate" of $O\left(\frac{(R + 1) L \Delta}{\varepsilon} + \frac{\sigma^2 L \Delta}{\varepsilon^2}\right)$, where $R$ the maximum "tree distance" along the main branch of a tree; and (ii) different methods exhibit different trade-offs-for example, some update iterates more frequently, improving practical performance, while others are more communication-efficient or focus on other aspects. Birch SGD serves as a unifying framework for navigating these trade-offs. We believe these results provide a unified foundation for understanding, analyzing, and designing efficient asynchronous and parallel optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09218v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin, Danil Sivtsov</dc:creator>
    </item>
    <item>
      <title>Absense of loops for the Wasserstein-$\mathcal{H}^1$ problem: the localization/blow-up argument</title>
      <link>https://arxiv.org/abs/2505.09232</link>
      <description>arXiv:2505.09232v1 Announce Type: cross 
Abstract: In the present work we prove that minimizers of the Wasserstein-$\mathscr{H}^1$ problem, introduced recently by Chambolle et. al., are trees in two cases: when the target measure is a sum of finitely many Dirac masses or when it has a bounded density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09232v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Miguel Machado (LMCRC)</dc:creator>
    </item>
    <item>
      <title>Primal-dual splitting methods for phase-field surfactant model with moving contact lines</title>
      <link>https://arxiv.org/abs/2505.09469</link>
      <description>arXiv:2505.09469v1 Announce Type: cross 
Abstract: Surfactants have important effects on the dynamics of droplets on solid surfaces, which has inspired many industrial applications. Phase-field surfactant model with moving contact lines (PFS-MCL) has been employed to investigate the complex droplet dynamics with surfactants, while its numerical simulation remains challenging due to the coupling of gradient flows with respect to transport distances involving nonlinear and degenerate mobilities. We propose a novel structure-preserving variational scheme for PFS-MCL model with the dynamic boundary condition based on the minimizing movement scheme and optimal transport theory for Wasserstein gradient flows. The proposed scheme consists of a series of convex minimization problems and can be efficiently solved by our proposed primal-dual splitting method and its accelerated versions. By respecting the underlying PDE's variational structure with respect to the transport distance, the proposed scheme is proved to inherits the desirable properties including original energy dissipation, bound-preserving, and mass conservation. Through a suite of numerical simulations, we validate the performance of the proposed scheme and investigate the effects of surfactants on the droplet dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09469v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Wu, Zhen Zhang, Chaozhen Wei</dc:creator>
    </item>
    <item>
      <title>SAD Neural Networks: Divergent Gradient Flows and Asymptotic Optimality via o-minimal Structures</title>
      <link>https://arxiv.org/abs/2505.09572</link>
      <description>arXiv:2505.09572v1 Announce Type: cross 
Abstract: We study gradient flows for loss landscapes of fully connected feed forward neural networks with commonly used continuously differentiable activation functions such as the logistic, hyperbolic tangent, softplus or GELU function. We prove that the gradient flow either converges to a critical point or diverges to infinity while the loss converges to an asymptotic critical value. Moreover, we prove the existence of a threshold $\varepsilon&gt;0$ such that the loss value of any gradient flow initialized at most $\varepsilon$ above the optimal level converges to it. For polynomial target functions and sufficiently big architecture and data set, we prove that the optimal loss value is zero and can only be realized asymptotically. From this setting, we deduce our main result that any gradient flow with sufficiently good initialization diverges to infinity. Our proof heavily relies on the geometry of o-minimal structures. We confirm these theoretical findings with numerical experiments and extend our investigation to real-world scenarios, where we observe an analogous behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09572v1</guid>
      <category>cs.LG</category>
      <category>math.LO</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian Kranz, Davide Gallon, Steffen Dereich, Arnulf Jentzen</dc:creator>
    </item>
    <item>
      <title>Solving Cutting Stock Problems via an Extended Ryan-Foster Branching Scheme and Fast Column Generation</title>
      <link>https://arxiv.org/abs/2308.03595</link>
      <description>arXiv:2308.03595v3 Announce Type: replace 
Abstract: We present a branch-cut-and-price framework to solve Cutting Stock Problems with strong relaxations using Set Covering (Packing) Formulations, which are solved by column generation. The main contributions of this paper include an extended Ryan-Foster scheme, which allows us to use this powerful branching scheme even in non-binary problems by using a conflict propagation lemma; a fast column generation process based on a diversification strategy; custom primal heuristics, enabling us to find optimal solutions for several open instances; and a technique to use a smaller feasibility tolerance in floating-point linear programming solvers, combined with numerically safe methods to produce stronger and safer lower bounds. Additional performance-improving strategies include a technique that controls the height of the branch-and-bound tree; a variable selection algorithm based on branching history; a new set of dual inequalities; insights to obtain a lean model; and the subset-row inequalities. By employing this comprehensive framework, we overcame the current state-of-the-art concerning the following problems: Cutting Stock, Skiving Stock, Ordered Open-End Bin Packing, Class-Constrained Bin Packing, and Identical Parallel Machines Scheduling with Minimum Makespan. Additionally, a new challenging benchmark for Cutting Stock is introduced.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03595v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renan F. F. da Silva, Rafael C. S. Schouery</dc:creator>
    </item>
    <item>
      <title>Verification theorem related to a zero sum stochastic differential game, based on a chain rule for non-smooth functions</title>
      <link>https://arxiv.org/abs/2407.06243</link>
      <description>arXiv:2407.06243v2 Announce Type: replace 
Abstract: We establish a verification theorem, inspired by those existing in stochastic control, to demonstrate how a pair of feedback controls can form a Nash equilibrium in a stochastic zero-sum differential game. Suppose for instance that the diffusion coefficient of the state equation is non-degenerate and the classical Isaacs condition is satisfied and the existence of a (what is termed) quasi-strong solution to the Bellman-Isaacs (BI) equations. In that case we are able to show that there exists a saddle point constituted by a couple of feedback controls that achieve the value of the game. Moreover, the latter is equal to the unique solution of the BI equations. A suitable generalization is available when diffusion is possibly degenerate. Similarly we have also improved a well-known verification theorem in stochastic control theory. The techniques of stochastic calculus via regularizations we use, in particular specific chain rules, are borrowed from a companion paper of the authors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06243v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlo Ciccarella (OC, ENSTA Paris), Francesco Russo (OC, ENSTA Paris)</dc:creator>
    </item>
    <item>
      <title>Approximate D-optimal design and equilibrium measure</title>
      <link>https://arxiv.org/abs/2409.04058</link>
      <description>arXiv:2409.04058v3 Announce Type: replace 
Abstract: We introduce a minor variant of the approximate D-optimal design of experiments with a more general information matrix that takes into account the representation of the design space S. The main motivation (and result) is that if S in R^d is the unit ball, the unit box or the canonical simplex, then remarkably, for every dimension d and every degree n, one obtains an optimal solution in closed form, namely the equilibrium measure of S (in pluripotential theory). Equivalently, for each degree n, the unique optimal solution is the vector of moments (up to degree 2n) of the equilibrium measure of S. Hence finding an optimal design reduces to finding a cubature for the equilibrium measure, with atoms in S, positive weights, and exact up to degree 2n. In addition, any resulting sequence of atomic D-optimal measures converges to the equilibrium measure of S for the weak-star topology, as n increases. Links with Fekete sets of points are also discussed. More general compact basic semi-algebraic sets are also considered, and a previously developed two-step design algorithm is easily adapted to this new variant of D-optimal design problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.04058v3</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Didier Henrion (LAAS-POP), Jean Bernard Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>A robust optimization approach to flow decomposition</title>
      <link>https://arxiv.org/abs/2410.21140</link>
      <description>arXiv:2410.21140v2 Announce Type: replace 
Abstract: In this paper, we generalize the minimum flow decomposition problem (MFD) and incorporate uncertain edge capacities from the perspective of robust optimization. In the classical flow decomposition problem, a network flow is decomposed into a set of weighted paths from a fixed source node to a fixed sink node that precisely represents the flow distribution across all edges. While MFDs are often used in bioinformatics applications, they are also applicable in other fields, representing the flow of goods or passengers in distribution networks, where the decomposition represents the vehicles and corresponding capacities needed to cover these flows. Motivated by these applications, we generalize the MFD to the weighted inexact case with lower and upper bounds on the flow values, provide a detailed analysis, and explore different variants that are solvable in polynomial time. Moreover, we introduce the concept of robust flow decomposition by incorporating uncertain bounds and applying different robustness concepts to handle the uncertainty. Finally, we present two different adjustably robust problem formulations and perform computational experiments illustrating the benefit of adjustability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21140v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Moritz Stinzend\"orfer, Philine Schiewe, Fabricio Oliveira</dc:creator>
    </item>
    <item>
      <title>A new fractional differential quasi-variational inequality with Mittag-Leffler kernel in Hilbert spaces and its applications</title>
      <link>https://arxiv.org/abs/2503.02669</link>
      <description>arXiv:2503.02669v2 Announce Type: replace 
Abstract: This paper considers a new fractional differential quasi-variational inequality with Mittag-Leffler kernel comprising a fractional differential equation with Mittag-Leffler kernel and a quasi-variational inequality in Hilbert spaces. Qualitative properties of the solution for the parameterized quasi-variational inequality are investigated, which improve some known results in the literature. Moreover, the unique existence of the solution and Hyers-Ulam stability are obtained for such a novel system under mild conditions. Finally, the obtained abstract results are applied to analyze the unique solvability and stability for a multi-agent optimization problem and a price control problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02669v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeng-bao Wu, Quan-guo Zhang, Tao Chen, Yue Zeng, Nan-jing Huang, Yi-bin Xiao</dc:creator>
    </item>
    <item>
      <title>Fast Frank--Wolfe Algorithms with Adaptive Bregman Step-Size for Weakly Convex Functions</title>
      <link>https://arxiv.org/abs/2504.04330</link>
      <description>arXiv:2504.04330v2 Announce Type: replace 
Abstract: We propose a Frank--Wolfe (FW) algorithm with an adaptive Bregman step-size strategy for smooth adaptable (also called: relatively smooth) (weakly-) convex functions. This means that the gradient of the objective function is not necessarily Lipschitz continuous, and we only require the smooth adaptable property. Compared to existing FW algorithms, our assumptions are less restrictive. We establish convergence guarantees in various settings, such as sublinear to linear convergence rates, depending on the assumptions for convex and nonconvex objective functions. Assuming that the objective function is weakly convex and satisfies the local quadratic growth condition, we provide both local sublinear and local linear convergence regarding the primal gap. We also propose a variant of the away-step FW algorithm using Bregman distances over polytopes. We establish global faster (up to linear) convergence for convex optimization under the H\"{o}lder error bound condition and its local linear convergence for nonconvex optimization under the local quadratic growth condition. Numerical experiments demonstrate that our proposed FW algorithms outperform existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04330v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shota Takahashi, Sebastian Pokutta, Akiko Takeda</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Distributed Online Nonconvex Optimization with Time-Varying Constraints</title>
      <link>https://arxiv.org/abs/2505.08592</link>
      <description>arXiv:2505.08592v2 Announce Type: replace 
Abstract: This paper considers distributed online nonconvex optimization with time-varying inequality constraints over a network of agents, where the nonconvex local loss and convex local constraint functions can vary arbitrarily across iterations, and the information of them is privately revealed to each agent at each iteration. For a uniformly jointly strongly connected time-varying directed graph, we propose two distributed bandit online primal--dual algorithm with compressed communication to efficiently utilize communication resources in the one-point and two-point bandit feedback settings, respectively. In nonconvex optimization, finding a globally optimal decision is often NP-hard. As a result, the standard regret metric used in online convex optimization becomes inapplicable. To measure the performance of the proposed algorithms, we use a network regret metric grounded in the first-order optimality condition associated with the variational inequality. We show that the compressed algorithms establish sublinear network regret and cumulative constraint violation bounds. Finally, a simulation example is presented to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08592v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunpeng Zhang, Lei Xu, Xinlei Yi, Guanghui Wen, Ming Cao, Karl H. Johansson, Tianyou Chai, Tao Yang</dc:creator>
    </item>
    <item>
      <title>Accelerated Stochastic Min-Max Optimization Based on Bias-corrected Momentum</title>
      <link>https://arxiv.org/abs/2406.13041</link>
      <description>arXiv:2406.13041v2 Announce Type: replace-cross 
Abstract: Lower-bound analyses for nonconvex strongly-concave minimax optimization problems have shown that stochastic first-order algorithms require at least $\mathcal{O}(\varepsilon^{-4})$ oracle complexity to find an $\varepsilon$-stationary point. Some works indicate that this complexity can be improved to $\mathcal{O}(\varepsilon^{-3})$ when the loss gradient is Lipschitz continuous. The question of achieving enhanced convergence rates under distinct conditions, remains unresolved. In this work, we address this question for optimization problems that are nonconvex in the minimization variable and strongly concave or Polyak-Lojasiewicz (PL) in the maximization variable. We introduce novel bias-corrected momentum algorithms utilizing efficient Hessian-vector products. We establish convergence conditions and demonstrate a lower iteration complexity of $\mathcal{O}(\varepsilon^{-3})$ for the proposed algorithms. The effectiveness of the method is validated through applications to robust logistic regression using real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13041v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyuan Cai, Sulaiman A. Alghunaim, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Efficient Local and Tabu Search Strategies for Large-Scale Quadratic Integer Programming</title>
      <link>https://arxiv.org/abs/2409.14176</link>
      <description>arXiv:2409.14176v2 Announce Type: replace-cross 
Abstract: This study investigates the area of general quadratic integer programming (QIP), encompassing both unconstrained (UQIP) and constrained (CQIP) variants. These NP-hard problems have far-reaching applications, yet the non-convex cases have received limited attention in the literature. To address this gap, we introduce a closed-form formula for single-variable changes, establishing novel necessary and sufficient conditions for 1-Opt local improvement in UQIP and CQIP. We develop a simple local and sophisticated tabu search with an oscillation strategy tailored for large-scale problems. Experimental results on instances with up to 8000 variables demonstrate the efficiency of these strategies, producing high-quality solutions within a short time. Our approaches significantly outperform the Gurobi 11.0.2 solver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14176v2</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Wang, Bahram Alidaee</dc:creator>
    </item>
    <item>
      <title>Distributing Intelligence in 6G Programmable Data Planes for Effective In-Network Intrusion Prevention</title>
      <link>https://arxiv.org/abs/2410.24013</link>
      <description>arXiv:2410.24013v3 Announce Type: replace-cross 
Abstract: The problem of attacks on new generation network infrastructures is becoming increasingly relevant, given the widening of the attack surface of these networks resulting from the greater number of devices that will access them in the future (sensors, actuators, vehicles, household appliances, etc.). Approaches to the design of intrusion detection systems must evolve and go beyond the traditional concept of perimeter control to build on new paradigms that exploit the typical characteristics of future 5G and 6G networks, such as in-network computing and intelligent programmable data planes. The aim of this research is to propose a disruptive paradigm in which devices in a typical data plane of a future programmable network have anomaly detection capabilities and cooperate in a fully distributed fashion to act as an ML-enabled Intrusion Prevention System ``embedded" into the network. The reported proof-of-concept experiments demonstrate that the proposed paradigm allows working effectively and with a good level of precision while occupying overall less CPU and RAM resources of the devices involved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24013v3</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MNET.2025.3544828</arxiv:DOI>
      <arxiv:journal_reference>IEEE Network, vol. 39, no. 3, 26 Feb. 2025, pp. 319-25</arxiv:journal_reference>
      <dc:creator>Mattia G. Spina, Floriano De Rango, Edoardo Scalzo, Francesca Guerriero, Antonio Iera</dc:creator>
    </item>
    <item>
      <title>Degree Matrix Comparison for Graph Alignment</title>
      <link>https://arxiv.org/abs/2411.07475</link>
      <description>arXiv:2411.07475v3 Announce Type: replace-cross 
Abstract: The graph alignment problem, which considers the optimal node correspondence across networks, has recently gained significant attention due to its wide applications. There are graph alignment methods suited for various network types, but we focus on the unsupervised geometric alignment algorithms. We propose Degree Matrix Comparison (DMC), a very simple degree-based method that has shown to be effective for heterogeneous networks. Through extensive experiments and mathematical proofs, we demonstrate the potential of this method. Remarkably, DMC achieves up to 99% correct node alignment for 90%-overlap networks and 100% accuracy for isomorphic graphs. Additionally, we propose a reduced Greedy DMC with lower time complexity and Weighted DMC that has demonstrated potential for aligning weighted graphs. Positive results from applying Greedy DMC and the Weighted DMC furthermore speaks to the validity and potential of the DMC. The sequence of DMC methods could significantly impact graph alignment, offering reliable solutions for the task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07475v3</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Wang, Peter Chin</dc:creator>
    </item>
    <item>
      <title>Reduction from the partition problem: Dynamic lot sizing problem with polynomial complexity</title>
      <link>https://arxiv.org/abs/2412.05017</link>
      <description>arXiv:2412.05017v4 Announce Type: replace-cross 
Abstract: In this note, we polynomially reduce an instance of the partition problem to a dynamic lot sizing problem, and show that solving the latter problem solves the former problem. By solving the dynamic program formulation of the dynamic lot sizing problem, we show that the instance of the partition problem can be solved with pseudo-polynomial time complexity. Numerical results on solving instances of the partition problem are also provided using an implementation of the algorithm that solves the dynamic program. We conclude by discussing polynomial time solvability of the partition problem through further observation on the dynamic program formulation of the dynamic lot sizing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05017v4</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chee-Khian Sim</dc:creator>
    </item>
    <item>
      <title>Kernel-based error bounds of bilinear Koopman surrogate models for nonlinear data-driven control</title>
      <link>https://arxiv.org/abs/2503.13407</link>
      <description>arXiv:2503.13407v2 Announce Type: replace-cross 
Abstract: We derive novel deterministic bounds on the approximation error of data-based bilinear surrogate models for unknown nonlinear systems. The surrogate models are constructed using kernel-based extended dynamic mode decomposition to approximate the Koopman operator in a reproducing kernel Hilbert space. Unlike previous methods that require restrictive assumptions on the invariance of the dictionary, our approach leverages kernel-based dictionaries that allow us to control the projection error via pointwise error bounds, overcoming a significant limitation of existing theoretical guarantees. The derived state- and input-dependent error bounds allow for direct integration into Koopman-based robust controller designs with closed-loop guarantees for the unknown nonlinear system. Numerical examples illustrate the effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13407v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Str\"asser, Manuel Schaller, Julian Berberich, Karl Worthmann, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>A Spectrum-based Filter Design for Periodic Control of Systems with Time Delay</title>
      <link>https://arxiv.org/abs/2503.19863</link>
      <description>arXiv:2503.19863v2 Announce Type: replace-cross 
Abstract: A fully analytical controller design is proposed to tackle a periodic control problem for stable linear systems with an input delay. Applying the internal model control scheme, the controller design reduces to designing a filter, which is done through the placement of poles and zeros. The zeros are placed to compensate for the harmonics and to achieve the desired degree of properness for the filter. For placing the poles, a quasi-optimal procedure is proposed utilizing the standard LQR method. Given the high-dimensionality of the filter due to targeting a large number of harmonics, the design, as well as controller implementation, is performed over a state-space representation. A thorough experimental case study is included to demonstrate both the practical feasibility and effectiveness of the proposed control design. The experimental validation is performed on a physical system, the goal of which is to reject periodic vibrations acting on a mass-spring-damper setup where the sensor and the actuator are non-collocated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19863v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 15 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jsv.2025.118959</arxiv:DOI>
      <arxiv:journal_reference>Journal of Sound and Vibration, Volume 604, 2025, 118959</arxiv:journal_reference>
      <dc:creator>Can Kutlu Y\"uksel, Tom\'a\v{s} Vyhl\'idal, Jaroslav Bu\v{s}ek, Martin Hrom\v{c}\'ik, Silviu-Iulian Niculescu</dc:creator>
    </item>
  </channel>
</rss>
