<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Jul 2025 04:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Finding One Local Optimum Is Easy -- But What about Two?</title>
      <link>https://arxiv.org/abs/2507.07524</link>
      <description>arXiv:2507.07524v1 Announce Type: new 
Abstract: The class PLS (Polynomial Local Search) captures the complexity of finding a solution that is locally optimal and has proven to be an important concept in the theory of local search. It has been shown that local search versions of various combinatorial optimization problems, such as Maximum Independent Set and Max Cut, are complete for this class. Such computational intractability typically arises in local search problems allowing arbitrary weights; in contrast, for unweighted problems, locally optimal solutions can be found in polynomial time under standard settings. In this paper, we pursue the complexity of local search problems from a different angle: We show that computing two locally optimal solutions is NP-hard for various natural unweighted local search problems, including Maximum Independent Set, Minimum Dominating Set, Max SAT, and Max Cut. We also discuss several tractable cases for finding two (or more) local optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07524v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuaki Kobayashi, Kazuhiro Kurita, Yutaro Yamaguchi</dc:creator>
    </item>
    <item>
      <title>On the Complexity of Hyperpath and Minimal Separator Enumeration in Directed Hypergraphs</title>
      <link>https://arxiv.org/abs/2507.07528</link>
      <description>arXiv:2507.07528v1 Announce Type: new 
Abstract: In this paper, we address the enumeration of (induced) $s$-$t$ paths and minimal $s$-$t$ separators. These problems are some of the most famous classical enumeration problems that can be solved in polynomial delay by simple backtracking for a (un)directed graph. As a generalization of these problems, we consider the (induced) $s$-$t$ hyperpath and minimal $s$-$t$ separator enumeration in a \emph{directed hypergraph}. We show that extending these classical enumeration problems to directed hypergraphs drastically changes their complexity. More precisely, there are no output-polynomial time algorithms for the enumeration of induced $s$-$t$ hyperpaths and minimal $s$-$t$ separators unless $P = NP$, and if there is an output-polynomial time algorithm for the $s$-$t$ hyperpath enumeration, then the minimal transversal enumeration can be solved in output polynomial time even if a directed hypergraph is $BF$-hypergraph. Since the existence of an output-polynomial time algorithm for the minimal transversal enumeration has remained an open problem for over 45 years, it indicates that the $s$-$t$ hyperpath enumeration for a $BF$-hypergraph is not an easy problem. As a positive result, the $s$-$t$ hyperpath enumeration for a $B$-hypergraph can be solved in polynomial delay by backtracking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07528v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kazuhiro Kurita, Kevin Mann</dc:creator>
    </item>
    <item>
      <title>Efficient and Adaptive Estimation of Local Triadic Coefficients</title>
      <link>https://arxiv.org/abs/2507.07536</link>
      <description>arXiv:2507.07536v1 Announce Type: new 
Abstract: Characterizing graph properties is fundamental to the analysis and to our understanding of real-world networked systems. The local clustering coefficient, and the more recently introduced, local closure coefficient, capture powerful properties that are essential in a large number of applications, ranging from graph embeddings to graph partitioning. Such coefficients capture the local density of the neighborhood of each node, considering incident triadic structures and paths of length two. For this reason, we refer to these coefficients collectively as local triadic coefficients.
  In this work, we consider the novel problem of computing efficiently the average of local triadic coefficients, over a given partition of the nodes of the input graph into a set of disjoint buckets. The average local triadic coefficients of the nodes in each bucket provide a better insight into the interplay of graph structure and the properties of the nodes associated to each bucket. Unfortunately, exact computation, which requires listing all triangles in a graph, is infeasible for large networks. Hence, we focus on obtaining highly-accurate probabilistic estimates.
  We develop Triad, an adaptive algorithm based on sampling, which can be used to estimate the average local triadic coefficients for a partition of the nodes into buckets. Triad is based on a new class of unbiased estimators, and non-trivial bounds on its sample complexity, enabling the efficient computation of highly accurate estimates. Finally, we show how Triad can be efficiently used in practice on large networks, and we present a case study showing that average local triadic coefficients can capture high-order patterns over collaboration networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07536v1</guid>
      <category>cs.DS</category>
      <category>cs.SI</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.14778/3742728.3742748</arxiv:DOI>
      <dc:creator>Ilie Sarpe, Aristides Gionis</dc:creator>
    </item>
    <item>
      <title>A Randomized Rounding Approach for DAG Edge Deletion</title>
      <link>https://arxiv.org/abs/2507.07943</link>
      <description>arXiv:2507.07943v1 Announce Type: new 
Abstract: In the DAG Edge Deletion problem, we are given an edge-weighted directed acyclic graph and a parameter $k$, and the goal is to delete the minimum weight set of edges so that the resulting graph has no paths of length $k$. This problem, which has applications to scheduling, was introduced in 2015 by Kenkre, Pandit, Purohit, and Saket. They gave a $k$-approximation and showed that it is UGC-Hard to approximate better than $\lfloor 0.5k \rfloor$ for any constant $k \ge 4$ using a work of Svensson from 2012. The approximation ratio was improved to $\frac{2}{3}(k+1)$ by Klein and Wexler in 2016.
  In this work, we introduce a randomized rounding framework based on distributions over vertex labels in $[0,1]$. The most natural distribution is to sample labels independently from the uniform distribution over $[0,1]$. We show this leads to a $(2-\sqrt{2})(k+1) \approx 0.585(k+1)$-approximation. By using a modified (but still independent) label distribution, we obtain a $0.549(k+1)$-approximation for the problem, as well as show that no independent distribution over labels can improve our analysis to below $0.542(k+1)$. Finally, we show a $0.5(k+1)$-approximation for bipartite graphs and for instances with structured LP solutions. Whether this ratio can be obtained in general is open.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07943v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Kalantarzadeh, Nathan Klein, Victor Reis</dc:creator>
    </item>
    <item>
      <title>Finding sparse induced subgraphs on graphs of bounded induced matching treewidth</title>
      <link>https://arxiv.org/abs/2507.07975</link>
      <description>arXiv:2507.07975v1 Announce Type: new 
Abstract: The induced matching width of a tree decomposition of a graph $G$ is the cardinality of a largest induced matching $M$ of $G$, such that there exists a bag that intersects every edge in $M$. The induced matching treewidth of a graph $G$, denoted by $\mathsf{tree-}\mu(G)$, is the minimum induced matching width of a tree decomposition of $G$. The parameter $\mathsf{tree-}\mu$ was introduced by Yolov [SODA '18], who showed that, for example, Maximum-Weight Independent Set can be solved in polynomial-time on graphs of bounded $\mathsf{tree-}\mu$. Lima, Milani\v{c}, Mur\v{s}i\v{c}, Okrasa, Rz\k{a}\.zewski, and \v{S}torgel [ESA '24] conjectured that this algorithm can be generalized to a meta-problem called Maximum-Weight Induced Subgraph of Bounded Treewidth, where we are given a vertex-weighted graph $G$, an integer $w$, and a $\mathsf{CMSO}_2$-sentence $\Phi$, and are asked to find a maximum-weight set $X \subseteq V(G)$ so that $G[X]$ has treewidth at most $w$ and satisfies $\Phi$. They proved the conjecture for some special cases, such as for the problem Maximum-Weight Induced Forest.
  In this paper, we prove the general case of the conjecture. In particular, we show that Maximum-Weight Induced Subgraph of Bounded Treewidth is polynomial-time solvable when $\mathsf{tree-}\mu(G)$, $w$, and $|\Phi|$ are bounded. The running time of our algorithm for $n$-vertex graphs $G$ with $\mathsf{tree} - \mu(G) \le k$ is $f(k, w, |\Phi|) \cdot n^{O(k w^2)}$ for a computable function $f$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07975v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans L. Bodlaender, Fedor V. Fomin, Tuukka Korhonen</dc:creator>
    </item>
    <item>
      <title>A Graph Isomorphism-based Decentralized Algorithm for Modular Robot Configuration Formation</title>
      <link>https://arxiv.org/abs/1602.03104</link>
      <description>arXiv:1602.03104v1 Announce Type: cross 
Abstract: We consider the problem of configuration formation in modular robot systems where a set of modules that are initially in different configurations and located at different locations are required to assume appropriate positions so that they can get into a new, user-specified, target configuration. We propose a novel algorithm based on graph isomorphism, where the modules select locations or spots in the target configuration using a utility-based framework, while retaining their original configuration to the greatest extent possible, to reduce the time and energy required by the modules to assume the target configuration. We have shown analytically that our proposed algorithm is complete and guarantees a Pareto-optimal allocation. Experimental simulations of our algorithm with different number of modules in different initial configurations and located initially at different locations, show that the planning time of our algorithm is nominal (order of msec. for 100 modules). We have also compared our algorithm against a market-based allocation algorithm and shown that our proposed algorithm performs better in terms of time and number of messages exchanged.</description>
      <guid isPermaLink="false">oai:arXiv.org:1602.03104v1</guid>
      <category>cs.RO</category>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10514-018-9759-9</arxiv:DOI>
      <arxiv:journal_reference>Autonomous Robots, 2019</arxiv:journal_reference>
      <dc:creator>Ayan Dutta, Prithviraj Dasgupta, Carl Nelson</dc:creator>
    </item>
    <item>
      <title>A simpler and parallelizable $O(\sqrt{\log n})$-approximation algorithm for Sparsest Cut</title>
      <link>https://arxiv.org/abs/2307.00115</link>
      <description>arXiv:2307.00115v5 Announce Type: replace 
Abstract: Currently, the best known tradeoff between approximation ratio and complexity for the Sparsest Cut problem is achieved by the algorithm in [Sherman, FOCS 2009]: it computes $O(\sqrt{(\log n)/\varepsilon})$-approximation using $O(n^\varepsilon\log^{O(1)}n)$ maxflows for any $\varepsilon\in[\Theta(1/\log n),\Theta(1)]$. It works by solving the SDP relaxation of [Arora-Rao-Vazirani, STOC 2004] using the Multiplicative Weights Update algorithm (MW) of [Arora-Kale, JACM 2016]. To implement one MW step, Sherman approximately solves a multicommodity flow problem using another application of MW. Nested MW steps are solved via a certain ``chaining'' algorithm that combines results of multiple calls to the maxflow algorithm. We present an alternative approach that avoids solving the multicommodity flow problem and instead computes ``violating paths''. This simplifies Sherman's algorithm by removing a need for a nested application of MW, and also allows parallelization: we show how to compute $O(\sqrt{(\log n)/\varepsilon})$-approximation via $O(\log^{O(1)}n)$ maxflows using $O(n^\varepsilon)$ processors. We also revisit Sherman's chaining algorithm, and present a simpler version together with a new analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00115v5</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Kolmogorov</dc:creator>
    </item>
    <item>
      <title>Directed Temporal Tree Realization for Periodic Public Transport: Easy and Hard Cases</title>
      <link>https://arxiv.org/abs/2504.07920</link>
      <description>arXiv:2504.07920v2 Announce Type: replace 
Abstract: We study the complexity of the directed periodic temporal graph realization problem. This work is motivated by the design of periodic schedules in public transport with constraints on the quality of service. Namely, we require that the fastest path between (important) pairs of vertices is upper bounded by a specified maximum duration, encoded in an upper distance matrix $D$. While previous work has considered the undirected version of the problem, the application in public transport schedule design requires the flexibility to assign different departure times to the two directions of an edge. A problem instance can only be feasible if all values of the distance matrix are at least shortest path distances. However, the task of realizing exact fastest path distances in a periodic temporal graph is often too restrictive. Therefore, we introduce a minimum slack parameter $k$ that describes a lower bound on the maximum allowed waiting time on each path. We concentrate on tree topologies and provide a full characterization of the complexity landscape with respect to the period $\Delta$ and the minimum slack parameter~$k$, showing a sharp threshold between NP-complete cases and cases which are always realizable. We also provide hardness results for the special case of period $\Delta = 2$ for general directed and undirected graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07920v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Meusel, Matthias M\"uller-Hannemann, Klaus Reinhardt</dc:creator>
    </item>
    <item>
      <title>Prediction-Augmented Mechanism Design for Weighted Facility Location</title>
      <link>https://arxiv.org/abs/2507.06509</link>
      <description>arXiv:2507.06509v2 Announce Type: replace 
Abstract: Facility location is fundamental in operations research, mechanism design, and algorithmic game theory, with applications ranging from urban infrastructure planning to distributed systems. Recent research in this area has focused on augmenting classic strategyproof mechanisms with predictions to achieve an improved performance guarantee against the uncertainty under the strategic environment. Previous work has been devoted to address the trade-off obstacle of balancing the consistency (near-optimality under accurate predictions) and robustness (bounded inefficiency under poor predictions) primarily in the unweighted setting, assuming that all agents have the same importance. However, this assumption may not be true in some practical scenarios, leading to research of weighted facility location problems.
  The major contribution of the current work is to provide a prediction augmented algorithmic framework for balancing the consistency and robustness over strategic agents with non-uniform weights. In particular, through a reduction technique that identifies a subset of \emph{representative} instances and maps the other given locations to the representative ones, we prove that there exists a \emph{strategyproof} mechanism achieving a bounded consistency guarantee of $\frac{\sqrt{(1+c)^2W^2_{\min}+(1-c)^2W^2_{\max}}}{(1+c)W_{\min}}$ and a bounded robustness guarantee of $\frac{\sqrt{(1-c)^2W^2_{\min}+(1+c)^2W^2_{\max}}}{(1-c)W_{\min}}$ in weighted settings, where $c$ can be viewed as a parameter to make a trade-off between the consistency and robustness and $W_{\min}$ and $W_{\max}$ denote the minimum and maximum agents' weight. We also proved that there is no strategyproof deterministic mechanism that reach $1$-consistency and $O\left( n \cdot \frac{W_{\max}}{W_{\min}} \right)$-robustness in weighted FLP, even with fully predictions of all agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06509v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangguang Shi, Zhenyu Xue</dc:creator>
    </item>
    <item>
      <title>An Algorithm for Learning Smaller Representations of Models With Scarce Data</title>
      <link>https://arxiv.org/abs/2010.07990</link>
      <description>arXiv:2010.07990v2 Announce Type: replace-cross 
Abstract: We present an algorithm for solving binary classification problems when the dataset is not fully representative of the problem being solved, and obtaining more data is not possible. It relies on a trained model with loose accuracy constraints, an iterative hyperparameter searching-and-pruning procedure over a search space $\Theta$, and a data-generating function. Our algorithm works by reconstructing up to homology the manifold on which lies the support of the underlying distribution. We provide an analysis on correctness and runtime complexity under ideal conditions and an extension to deep neural networks. In the former case, if $\size{\Theta}$ is the number of hyperparameter sets in the search space, this algorithm returns a solution that is up to $2(1 - {2^{-\size{\Theta}}})$ times better than simply training with an enumeration of $\Theta$ and picking the best model. As part of our analysis we also prove that an open cover of a dataset has the same homology as the manifold on which lies the support of the underlying probability distribution, if and only said dataset is learnable. This latter result acts as a formal argument to explain the effectiveness of data expansion techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.07990v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s41884-024-00153-0</arxiv:DOI>
      <arxiv:journal_reference>Information Geometry (2024)</arxiv:journal_reference>
      <dc:creator>Adrian de Wynter</dc:creator>
    </item>
    <item>
      <title>Learning Algorithms in the Limit</title>
      <link>https://arxiv.org/abs/2506.15543</link>
      <description>arXiv:2506.15543v2 Announce Type: replace-cross 
Abstract: This paper studies the problem of learning computable functions in the limit by extending Gold's inductive inference framework to incorporate \textit{computational observations} and \textit{restricted input sources}. Complimentary to the traditional Input-Output Observations, we introduce Time-Bound Observations, and Policy-Trajectory Observations to study the learnability of general recursive functions under more realistic constraints. While input-output observations do not suffice for learning the class of general recursive functions in the limit, we overcome this learning barrier by imposing computational complexity constraints or supplementing with approximate time-bound observations. Further, we build a formal framework around observations of \textit{computational agents} and show that learning computable functions from policy trajectories reduces to learning rational functions from input and output, thereby revealing interesting connections to finite-state transducer inference. On the negative side, we show that computable or polynomial-mass characteristic sets cannot exist for the class of linear-time computable functions even for policy-trajectory observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15543v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Fri, 11 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hristo Papazov, Nicolas Flammarion</dc:creator>
    </item>
  </channel>
</rss>
