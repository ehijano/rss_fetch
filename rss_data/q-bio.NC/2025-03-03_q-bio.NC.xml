<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 03 Mar 2025 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Brain-Inspired Exploration of Functional Networks and Key Neurons in Large Language Models</title>
      <link>https://arxiv.org/abs/2502.20408</link>
      <description>arXiv:2502.20408v1 Announce Type: new 
Abstract: In recent years, the rapid advancement of large language models (LLMs) in natural language processing has sparked significant interest among researchers to understand their mechanisms and functional characteristics. Although existing studies have attempted to explain LLM functionalities by identifying and interpreting specific neurons, these efforts mostly focus on individual neuron contributions, neglecting the fact that human brain functions are realized through intricate interaction networks. Inspired by cognitive neuroscience research on functional brain networks (FBNs), this study introduces a novel approach to investigate whether similar functional networks exist within LLMs. We use methods similar to those in the field of functional neuroimaging analysis to locate and identify functional networks in LLM. Experimental results show that, similar to the human brain, LLMs contain functional networks that frequently recur during operation. Further analysis shows that these functional networks are crucial for LLM performance. Masking key functional networks significantly impairs the model's performance, while retaining just a subset of these networks is adequate to maintain effective operation. This research provides novel insights into the interpretation of LLMs and the lightweighting of LLMs for certain downstream tasks. Code is available at https://github.com/WhatAboutMyStar/LLM_ACTIVATION.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20408v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiheng Liu, Xiaohui Gao, Haiyang Sun, Bao Ge, Tianming Liu, Junwei Han, Xintao Hu</dc:creator>
    </item>
    <item>
      <title>Deviance Detection and Regularity Sensitivity in Dissociated Neuronal Cultures</title>
      <link>https://arxiv.org/abs/2502.20753</link>
      <description>arXiv:2502.20753v1 Announce Type: new 
Abstract: Understanding how neural networks process complex patterns of information is crucial for advancing both neuroscience and artificial intelligence. To investigate fundamental principles of neural computation, we studied dissociated neuronal cultures, one of the most primitive living neural networks, on high-resolution CMOS microelectrode arrays and tested whether the dissociated culture exhibits regularity sensitivity beyond mere stimulus-specific adaptation and deviance detection. In oddball electrical stimulation paradigms, we confirmed that the neuronal culture produced mismatch responses (MMRs) with true deviance detection beyond mere adaptation. These MMRs were dependent on the N-methyl-D-aspartate (NMDA) receptors, similar to mismatch negativity (MMN) in humans, which is known to have true deviance detection properties. Crucially, we also showed sensitivity to the statistical regularity of stimuli, a phenomenon previously observed only in intact brains: the MMRs in a predictable, periodic sequence were smaller than those in a commonly used sequence in which the appearance of the deviant stimulus was random and unpredictable. These results challenge the traditional view that a hierarchically structured neural network is required to process complex temporal patterns, suggesting instead that deviant detection and regularity sensitivity are inherent properties arising from the primitive neural network. They also suggest new directions for the development of neuro-inspired artificial intelligence systems, emphasizing the importance of incorporating adaptive mechanisms and temporal dynamics in the design of neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20753v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuo Zhang, Amit Yaron, Dai Akita, Tomoyo Isoguchi Shiramatsu, Zenas C. Chao, Hirokazu Takahashi</dc:creator>
    </item>
    <item>
      <title>Analysis of Evolving Cortical Neuronal Networks Using Visual Informatics</title>
      <link>https://arxiv.org/abs/2502.20862</link>
      <description>arXiv:2502.20862v1 Announce Type: new 
Abstract: Understanding the nature of the changes exhibited by evolving neuronal dynamics from high-dimensional activity data is essential for advancing neuroscience, particularly in the study of neuronal network development and the pathophysiology of neurological disorders. This work examines how advanced dimensionality reduction techniques can efficiently summarize and enhance our understanding of the development of neuronal networks over time and in response to stimulation. We develop a framework based on the Minimum-Distortion Embedding (MDE) methods and demonstrate how MDE outperforms better known benchmarks based on Principal Component Analysis (PCA) and t-distributed Stochastic Neighbor Embedding (t-SNE) by effectively preserving both global structures and local relationships within complex neuronal datasets. Our \emph{in silico} experiments reveal MDE's capability to capture the evolving connectivity patterns of simulated neuronal networks, illustrating a clear trajectory tracking the simulated network development. Complementary \emph{in vitro} experiments further validate MDE's advantages, highlighting its ability to identify behavioral differences and connectivity changes in neuronal cultures over a 35-day observation period. Additionally, we explore the effects of stimulation on neuronal activity, providing valuable insights into the plasticity and learning mechanisms of neuronal networks. Our findings underscore the importance of metric selection in dimensionality reduction, showing that correlation metrics yield more meaningful embeddings compared to Euclidean distance. The implications of this research extend to various areas, including the potential development of therapeutic intervention strategies for neurological disorders, and the identification of distinct phases of neuronal activity for advancing cortical-based computing devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20862v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ho Fai Po, Akke Mats Houben, Anna-Christina Haeb, Yordan P. Raykov, Daniel Tornero, Jordi Soriano, David Saad</dc:creator>
    </item>
    <item>
      <title>Microscopic Propagator Imaging (MPI) with Diffusion MRI</title>
      <link>https://arxiv.org/abs/2502.21129</link>
      <description>arXiv:2502.21129v1 Announce Type: new 
Abstract: We propose Microscopic Propagator Imaging (MPI) as a novel method to retrieve the indices of the microscopic propagator which is the probability density function of water displacements due to diffusion within the nervous tissue microstructures. Unlike the Ensemble Average Propagator indices or the Diffusion Tensor Imaging metrics, MPI indices are independent from the mesoscopic organization of the tissue such as the presence of multiple axonal bundle directions and orientation dispersion. As a consequence, MPI indices are more specific to the volumes, sizes, and types of microstructures, like axons and cells, that are present in the tissue. Thus, changes in MPI indices can be more directly linked to alterations in the presence and integrity of microstructures themselves. The methodology behind MPI is rooted on zonal modeling of spherical harmonics, signal simulation, and machine learning regression, and is demonstrated on both synthetic and Human Diffusion MRI data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21129v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <category>physics.bio-ph</category>
      <category>physics.med-ph</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tommaso Zajac, Gloria Menegaz, Marco Pizzolato</dc:creator>
    </item>
    <item>
      <title>Dynamic Markov Blanket Detection for Macroscopic Physics Discovery</title>
      <link>https://arxiv.org/abs/2502.21217</link>
      <description>arXiv:2502.21217v1 Announce Type: new 
Abstract: The free energy principle (FEP), along with the associated constructs of Markov blankets and ontological potentials, have recently been presented as the core components of a generalized modeling method capable of mathematically describing arbitrary objects that persist in random dynamical systems; that is, a mathematical theory of ``every'' ``thing''. Here, we leverage the FEP to develop a mathematical physics approach to the identification of objects, object types, and the macroscopic, object-type-specific rules that govern their behavior. We take a generative modeling approach and use variational Bayesian expectation maximization to develop a dynamic Markov blanket detection algorithm that is capable of identifying and classifying macroscopic objects, given partial observation of microscopic dynamics. This unsupervised algorithm uses Bayesian attention to explicitly label observable microscopic elements according to their current role in a given system, as either the internal or boundary elements of a given macroscopic object; and it identifies macroscopic physical laws that govern how the object interacts with its environment. Because these labels are dynamic or evolve over time, the algorithm is capable of identifying complex objects that travel through fixed media or exchange matter with their environment. This approach leads directly to a flexible class of structured, unsupervised algorithms that sensibly partition complex many-particle or many-component systems into collections of interacting macroscopic subsystems, namely, ``objects'' or ``things''. We derive a few examples of this kind of macroscopic physics discovery algorithm and demonstrate its utility with simple numerical experiments, in which the algorithm correctly labels the components of Newton's cradle, a burning fuse, the Lorenz attractor, and a simulated cell.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21217v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeff Beck, Maxwell J. D. Ramstead</dc:creator>
    </item>
    <item>
      <title>Noise induced extreme events in single Fitzhugh-Nagumo oscillator</title>
      <link>https://arxiv.org/abs/2502.20404</link>
      <description>arXiv:2502.20404v1 Announce Type: cross 
Abstract: The FitzHugh-Nagumo (FHN) model serves as a fundamental neuronal model which is extensively studied across various dynamical scenarios, we explore the dynamics of a scalar FHN oscillator under the influence of white noise. Unlike previous studies, in which extreme events (EE) were observed solely in coupled FHN oscillators, we demonstrate that a single system can exhibit EE induced by noise. Perturbation of the deterministic model in its steady state by random fluctuations reveals the emergence of subthreshold/small-amplitude oscillations (SAO), eventually leading to rare and extreme large-amplitude oscillations (LAO), which become particularly evident at minimal noise intensities. We elucidate the route by which these EE emerge, confirming their occurrence through probability calculations of trajectories in phase space. Additionally, our investigation reveals bursting phenomena in the system, which are characterized by specific levels of noise amplitude and elucidated using inter-spike interval statistics. At higher noise amplitudes, frequent LAO production is observed and attributed to self-induced stochastic resonance. The emergence of EE is explained through the theory of large fluctuations, with the escape rates of trajectories estimated via both analytical and numerical approaches. This study is significant because it reveals EE and bursting phenomena in a single FHN oscillator, offering potential new insights into the dynamics of neuronal populations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20404v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>nlin.CD</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>S. Hariharan, R. Suresh, V. K. Chandrasekar</dc:creator>
    </item>
    <item>
      <title>Training Large Neural Networks With Low-Dimensional Error Feedback</title>
      <link>https://arxiv.org/abs/2502.20580</link>
      <description>arXiv:2502.20580v1 Announce Type: cross 
Abstract: Training deep neural networks typically relies on backpropagating high dimensional error signals a computationally intensive process with little evidence supporting its implementation in the brain. However, since most tasks involve low-dimensional outputs, we propose that low-dimensional error signals may suffice for effective learning. To test this hypothesis, we introduce a novel local learning rule based on Feedback Alignment that leverages indirect, low-dimensional error feedback to train large networks. Our method decouples the backward pass from the forward pass, enabling precise control over error signal dimensionality while maintaining high-dimensional representations. We begin with a detailed theoretical derivation for linear networks, which forms the foundation of our learning framework, and extend our approach to nonlinear, convolutional, and transformer architectures. Remarkably, we demonstrate that even minimal error dimensionality on the order of the task dimensionality can achieve performance matching that of traditional backpropagation. Furthermore, our rule enables efficient training of convolutional networks, which have previously been resistant to Feedback Alignment methods, with minimal error. This breakthrough not only paves the way toward more biologically accurate models of learning but also challenges the conventional reliance on high-dimensional gradient signals in neural network training. Our findings suggest that low-dimensional error signals can be as effective as high-dimensional ones, prompting a reevaluation of gradient-based learning in high-dimensional systems. Ultimately, our work offers a fresh perspective on neural network optimization and contributes to understanding learning mechanisms in both artificial and biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20580v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maher Hanut, Jonathan Kadmon</dc:creator>
    </item>
    <item>
      <title>Triple Phase Transitions: Understanding the Learning Dynamics of Large Language Models from a Neuroscience Perspective</title>
      <link>https://arxiv.org/abs/2502.20779</link>
      <description>arXiv:2502.20779v1 Announce Type: cross 
Abstract: Large language models (LLMs) often exhibit abrupt emergent behavior, whereby new abilities arise at certain points during their training. This phenomenon, commonly referred to as a ''phase transition'', remains poorly understood. In this study, we conduct an integrative analysis of such phase transitions by examining three interconnected perspectives: the similarity between LLMs and the human brain, the internal states of LLMs, and downstream task performance. We propose a novel interpretation for the learning dynamics of LLMs that vary in both training data and architecture, revealing that three phase transitions commonly emerge across these models during training: (1) alignment with the entire brain surges as LLMs begin adhering to task instructions Brain Alignment and Instruction Following, (2) unexpectedly, LLMs diverge from the brain during a period in which downstream task accuracy temporarily stagnates Brain Detachment and Stagnation, and (3) alignment with the brain reoccurs as LLMs become capable of solving the downstream tasks Brain Realignment and Consolidation. These findings illuminate the underlying mechanisms of phase transitions in LLMs, while opening new avenues for interdisciplinary research bridging AI and neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20779v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuko Nakagi, Keigo Tada, Sota Yoshino, Shinji Nishimoto, Yu Takagi</dc:creator>
    </item>
    <item>
      <title>Enhancing deep neural networks through complex-valued representations and Kuramoto synchronization dynamics</title>
      <link>https://arxiv.org/abs/2502.21077</link>
      <description>arXiv:2502.21077v1 Announce Type: cross 
Abstract: Neural synchrony is hypothesized to play a crucial role in how the brain organizes visual scenes into structured representations, enabling the robust encoding of multiple objects within a scene. However, current deep learning models often struggle with object binding, limiting their ability to represent multiple objects effectively. Inspired by neuroscience, we investigate whether synchrony-based mechanisms can enhance object encoding in artificial models trained for visual categorization. Specifically, we combine complex-valued representations with Kuramoto dynamics to promote phase alignment, facilitating the grouping of features belonging to the same object. We evaluate two architectures employing synchrony: a feedforward model and a recurrent model with feedback connections to refine phase synchronization using top-down information. Both models outperform their real-valued counterparts and complex-valued models without Kuramoto synchronization on tasks involving multi-object images, such as overlapping handwritten digits, noisy inputs, and out-of-distribution transformations. Our findings highlight the potential of synchrony-driven mechanisms to enhance deep learning models, improving their performance, robustness, and generalization in complex visual categorization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21077v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sabine Muzellec, Andrea Alamia, Thomas Serre, Rufin VanRullen</dc:creator>
    </item>
    <item>
      <title>Multimodal Dreaming: A Global Workspace Approach to World Model-Based Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2502.21142</link>
      <description>arXiv:2502.21142v1 Announce Type: cross 
Abstract: Humans leverage rich internal models of the world to reason about the future, imagine counterfactuals, and adapt flexibly to new situations. In Reinforcement Learning (RL), world models aim to capture how the environment evolves in response to the agent's actions, facilitating planning and generalization. However, typical world models directly operate on the environment variables (e.g. pixels, physical attributes), which can make their training slow and cumbersome; instead, it may be advantageous to rely on high-level latent dimensions that capture relevant multimodal variables. Global Workspace (GW) Theory offers a cognitive framework for multimodal integration and information broadcasting in the brain, and recent studies have begun to introduce efficient deep learning implementations of GW. Here, we evaluate the capabilities of an RL system combining GW with a world model. We compare our GW-Dreamer with various versions of the standard PPO and the original Dreamer algorithms. We show that performing the dreaming process (i.e., mental simulation) inside the GW latent space allows for training with fewer environment steps. As an additional emergent property, the resulting model (but not its comparison baselines) displays strong robustness to the absence of one of its observation modalities (images or simulation attributes). We conclude that the combination of GW with World Models holds great potential for improving decision-making in RL agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21142v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eopold Mayti\'e, Roland Bertin Johannet, Rufin VanRullen</dc:creator>
    </item>
    <item>
      <title>ALVI Interface: Towards Full Hand Motion Decoding for Amputees Using sEMG</title>
      <link>https://arxiv.org/abs/2502.21256</link>
      <description>arXiv:2502.21256v1 Announce Type: cross 
Abstract: We present a system for decoding hand movements using surface EMG signals. The interface provides real-time (25 Hz) reconstruction of finger joint angles across 20 degrees of freedom, designed for upper limb amputees. Our offline analysis shows 0.8 correlation between predicted and actual hand movements. The system functions as an integrated pipeline with three key components: (1) a VR-based data collection platform, (2) a transformer-based model for EMG-to-motion transformation, and (3) a real-time calibration and feedback module called ALVI Interface. Using eight sEMG sensors and a VR training environment, users can control their virtual hand down to finger joint movement precision, as demonstrated in our video: youtube link.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21256v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aleksandr Kovalev, Anna Makarova, Petr Chizhov, Matvey Antonov, Gleb Duplin, Vladislav Lomtev, Viacheslav Gostevskii, Vladimir Bessonov, Andrey Tsurkan, Mikhail Korobok, Aleksejs Tim\v{c}enko</dc:creator>
    </item>
    <item>
      <title>Deciphering Functions of Neurons in Vision-Language Models</title>
      <link>https://arxiv.org/abs/2502.18485</link>
      <description>arXiv:2502.18485v2 Announce Type: replace 
Abstract: The burgeoning growth of open-sourced vision-language models (VLMs) has catalyzed a plethora of applications across diverse domains. Ensuring the transparency and interpretability of these models is critical for fostering trustworthy and responsible AI systems. In this study, our objective is to delve into the internals of VLMs to interpret the functions of individual neurons. We observe the activations of neurons with respects to the input visual tokens and text tokens, and reveal some interesting findings. Particularly, we found that there are neurons responsible for only visual or text information, or both, respectively, which we refer to them as visual neurons, text neurons, and multi-modal neurons, respectively. We build a framework that automates the explanation of neurons with the assistant of GPT-4o. Meanwhile, for visual neurons, we propose an activation simulator to assess the reliability of the explanations for visual neurons. System statistical analyses on top of one representative VLM of LLaVA, uncover the behaviors/characteristics of different categories of neurons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18485v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqi Xu, Cuiling Lan, Xuejin Chen, Yan Lu</dc:creator>
    </item>
    <item>
      <title>Self-Attention-Based Contextual Modulation Improves Neural System Identification</title>
      <link>https://arxiv.org/abs/2406.07843</link>
      <description>arXiv:2406.07843v3 Announce Type: replace-cross 
Abstract: Convolutional neural networks (CNNs) have been shown to be state-of-the-art models for visual cortical neurons. Cortical neurons in the primary visual cortex are sensitive to contextual information mediated by extensive horizontal and feedback connections. Standard CNNs integrate global contextual information to model contextual modulation via two mechanisms: successive convolutions and a fully connected readout layer. In this paper, we find that self-attention (SA), an implementation of non-local network mechanisms, can improve neural response predictions over parameter-matched CNNs in two key metrics: tuning curve correlation and peak tuning. We introduce peak tuning as a metric to evaluate a model's ability to capture a neuron's top feature preference. We factorize networks to assess each context mechanism, revealing that information in the local receptive field is most important for modeling overall tuning, but surround information is critically necessary for characterizing the tuning peak. We find that self-attention can replace posterior spatial-integration convolutions when learned incrementally, and is further enhanced in the presence of a fully connected readout layer, suggesting that the two context mechanisms are complementary. Finally, we find that decomposing receptive field learning and contextual modulation learning in an incremental manner may be an effective and robust mechanism for learning surround-center interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07843v3</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 03 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isaac Lin, Tianye Wang, Shang Gao, Shiming Tang, Tai Sing Lee</dc:creator>
    </item>
  </channel>
</rss>
