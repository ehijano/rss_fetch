<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 09 Jul 2025 04:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Maximum likelihood estimation of mean functions for Gaussian processes under small noise asymptotics</title>
      <link>https://arxiv.org/abs/2507.05628</link>
      <description>arXiv:2507.05628v1 Announce Type: new 
Abstract: Maximum likelihood estimators for time-dependent mean functions within Gaussian processes are provided in the context of continuous observations. We find the widest possible class of mean functions for which the likelihood function can be written explicitly. When it is subjected to a small noise asymptotic condition leading to the vanishing of the primary Gaussian noise, we attain local asymptotic normality results, accompanied by insights into the asymptotic efficiency of these estimators. In addition, we introduce M-estimators based on discrete samples, which also leads us to the asymptotic efficiency. Furthermore, we provide quasi-information criteria for model selection analogous to Akaike Information Criteria in discretely observed cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05628v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mitsuki Kobayashi, Yuto Nishiwaki, Yasutaka Shimizu, Nobutoki Takaoka</dc:creator>
    </item>
    <item>
      <title>A Note on Inferential Decisions, Errors and Path-Dependency</title>
      <link>https://arxiv.org/abs/2507.05634</link>
      <description>arXiv:2507.05634v1 Announce Type: new 
Abstract: Consider the standard sequential testing of a binary outcome. The associated belief process and its objectively true conditional-probability counterpart generally differ, but they converge to the same target in well-defined tests. We show that unless the two processes are 'essentially identical', differing at most by an a priori factor, time-homogeneous continuous sequential decisions based on the former must be path-dependent with respect to state-variables based on the latter or other non-essentially-identical belief processes. Further, total inferential errors decompose into two components with distinct and independent characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05634v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kangda K. Wren</dc:creator>
    </item>
    <item>
      <title>Optimal structure learning and conditional independence testing</title>
      <link>https://arxiv.org/abs/2507.05689</link>
      <description>arXiv:2507.05689v1 Announce Type: new 
Abstract: We establish a fundamental connection between optimal structure learning and optimal conditional independence testing by showing that the minimax optimal rate for structure learning problems is determined by the minimax rate for conditional independence testing in these problems. This is accomplished by establishing a general reduction between these two problems in the case of poly-forests, and demonstrated by deriving optimal rates for several examples, including Bernoulli, Gaussian and nonparametric models. Furthermore, we show that the optimal algorithm in these settings is a suitable modification of the PC algorithm. This theoretical finding provides a unified framework for analyzing the statistical complexity of structure learning through the lens of minimax testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05689v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Gao, Yuhao Wang, Bryon Aragam</dc:creator>
    </item>
    <item>
      <title>Importance sampling for Sobol' indices estimation</title>
      <link>https://arxiv.org/abs/2507.05958</link>
      <description>arXiv:2507.05958v1 Announce Type: new 
Abstract: We propose a new importance sampling framework for the estimation and analysis of Sobol' indices. We show that a Sobol' index defined under a reference input distribution can be consistently estimated from samples drawn from other sampling distributions by reweighting the estimator appropriately to account for the distribution change. We derive the optimal sampling distribution that minimizes the asymptotic variance and demonstrate its strong impact on estimation accuracy. Beyond variance reduction, the framework supports distributional sensitivity analysis via reverse importance sampling, enabling robust exploration of input distribution uncertainty with negligible additional computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05958v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haythem Boucharif, J\'er\^ome Morio, Paul Rochet</dc:creator>
    </item>
    <item>
      <title>Nonparametric Estimation in SDE Models Involving an Explanatory Process</title>
      <link>https://arxiv.org/abs/2507.06098</link>
      <description>arXiv:2507.06098v1 Announce Type: new 
Abstract: This paper deals with the process $X = (X_t)_{t\in [0,T]}$ defined by the stochastic differential equation (SDE) $dX_t = (a(X_t) + b(Y_t))dt +\sigma(X_t)dW_1(t)$, where $W_1$ is a Brownian motion and $Y$ is an exogenous process. The first task - of probabilistic nature - is to properly define the model, to prove the existence and uniqueness of the solution of such an equation, and then to establish the existence and a suitable control of a density with respect to the Lebesgue measure of the distribution of $(X_t,Y_t)$ ($t &gt; 0$). In the second part of the paper, a risk bound and a rate of convergence in specific Sobolev spaces are established for a copies-based projection least squares estimator of the $\mathbb R^2$-valued function $(a,b)$. Moreover, a model selection procedure making the adequate bias-variance compromise both in theory and practice is investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06098v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabienne Comte, Nicolas Marie</dc:creator>
    </item>
    <item>
      <title>On the Estimation of Gaussian Moment Tensors</title>
      <link>https://arxiv.org/abs/2507.06166</link>
      <description>arXiv:2507.06166v1 Announce Type: new 
Abstract: This paper studies two estimators for Gaussian moment tensors: the standard sample moment estimator and a plug-in estimator based on Isserlis's theorem. We establish dimension-free, non-asymptotic error bounds that demonstrate and quantify the advantage of Isserlis's estimator for tensors of even order $p&gt;2$. Our bounds hold in operator and entrywise maximum norms, and apply to symmetric and asymmetric tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06166v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omar Al-Ghattas, Jiaheng Chen, Daniel Sanz-Alonso</dc:creator>
    </item>
    <item>
      <title>Consistency and Inconsistency in $K$-Means Clustering</title>
      <link>https://arxiv.org/abs/2507.06226</link>
      <description>arXiv:2507.06226v1 Announce Type: new 
Abstract: A celebrated result of Pollard proves asymptotic consistency for $k$-means clustering when the population distribution has finite variance. In this work, we point out that the population-level $k$-means clustering problem is, in fact, well-posed under the weaker assumption of a finite expectation, and we investigate whether some form of asymptotic consistency holds in this setting. As we illustrate in a variety of negative results, the complete story is quite subtle; for example, the empirical $k$-means cluster centers may fail to converge even if there exists a unique set of population $k$-means cluster centers. A detailed analysis of our negative results reveals that inconsistency arises because of an extreme form of cluster imbalance, whereby the presence of outlying samples leads to some empirical $k$-means clusters possessing very few points. We then give a collection of positive results which show that some forms of asymptotic consistency, under only the assumption of finite expectation, may be recovered by imposing some a priori degree of balance among the empirical $k$-means clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06226v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo\"ise Blanchard, Adam Quinn Jaffe, Nikita Zhivotovskiy</dc:creator>
    </item>
    <item>
      <title>Enjoying Non-linearity in Multinomial Logistic Bandits</title>
      <link>https://arxiv.org/abs/2507.05306</link>
      <description>arXiv:2507.05306v1 Announce Type: cross 
Abstract: We consider the multinomial logistic bandit problem, a variant of generalized linear bandits where a learner interacts with an environment by selecting actions to maximize expected rewards based on probabilistic feedback from multiple possible outcomes. In the binary setting, recent work has focused on understanding the impact of the non-linearity of the logistic model (Faury et al., 2020; Abeille et al., 2021). They introduced a problem-dependent constant $\kappa_*$, that may be exponentially large in some problem parameters and which is captured by the derivative of the sigmoid function. It encapsulates the non-linearity and improves existing regret guarantees over $T$ rounds from $\smash{O(d\sqrt{T})}$ to $\smash{O(d\sqrt{T/\kappa_*})}$, where $d$ is the dimension of the parameter space. We extend their analysis to the multinomial logistic bandit framework, making it suitable for complex applications with more than two choices, such as reinforcement learning or recommender systems. To achieve this, we extend the definition of $\kappa_*$ to the multinomial setting and propose an efficient algorithm that leverages the problem's non-linearity. Our method yields a problem-dependent regret bound of order $ \smash{\widetilde{\mathcal{O}}( Kd \sqrt{{T}/{\kappa_*}})} $, where $K$ is the number of actions and $\kappa_* \ge 1$. This improves upon the best existing guarantees of order $ \smash{\widetilde{\mathcal{O}}( Kd \sqrt{T} )} $. Moreover, we provide a $\smash{ \Omega(d\sqrt{T/\kappa_*})}$ lower-bound, showing that our dependence on $\kappa_*$ is optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05306v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Boudart (PSL, DI-ENS, Inria), Pierre Gaillard (PSL, DI-ENS, Inria), Alessandro Rudi (PSL, DI-ENS, Inria)</dc:creator>
    </item>
    <item>
      <title>Property Elicitation on Imprecise Probabilities</title>
      <link>https://arxiv.org/abs/2507.05857</link>
      <description>arXiv:2507.05857v1 Announce Type: cross 
Abstract: Property elicitation studies which attributes of a probability distribution can be determined by minimising a risk. We investigate a generalisation of property elicitation to imprecise probabilities (IP). This investigation is motivated by multi-distribution learning, which takes the classical machine learning paradigm of minimising a single risk over a (precise) probability and replaces it with $\Gamma$-maximin risk minimization over an IP. We provide necessary conditions for elicitability of a IP-property. Furthermore, we explain what an elicitable IP-property actually elicits through Bayes pairs -- the elicited IP-property is the corresponding standard property of the maximum Bayes risk distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05857v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>James Bailie, Rabanus Derr</dc:creator>
    </item>
    <item>
      <title>Sharp constants relating the sub-Gaussian norm and the sub-Gaussian parameter</title>
      <link>https://arxiv.org/abs/2507.05928</link>
      <description>arXiv:2507.05928v1 Announce Type: cross 
Abstract: We determine the optimal constants in the classical inequalities relating the sub-Gaussian norm \(\|X\|_{\psi_2}\) and the sub-Gaussian parameter \(\sigma_X\) for centered real-valued random variables. We show that \(\sqrt{3/8} \cdot \|X\|_{\psi_2} \le \sigma_X \le \sqrt{\log 2} \cdot \|X\|_{\psi_2}\), and that both bounds are sharp, attained by the standard Gaussian and Rademacher distributions, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05928v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lasse Leskel\"a, Matvei Zhukov</dc:creator>
    </item>
    <item>
      <title>seMCD: Sequentially implemented Monte Carlo depth computation with statistical guarantees</title>
      <link>https://arxiv.org/abs/2507.06227</link>
      <description>arXiv:2507.06227v1 Announce Type: cross 
Abstract: Statistical depth functions provide center-outward orderings in spaces of dimension larger than one, where a natural ordering does not exist. The numerical evaluation of such depth functions can be computationally prohibitive, even for relatively low dimensions. We present a novel sequentially implemented Monte Carlo methodology for the computation of, theoretical and empirical, depth functions and related quantities (seMCD), that outputs an interval, a so-called seMCD-bucket, to which the quantity of interest belongs with a high probability prespecified by the user. For specific classes of depth functions, we adapt algorithms from sequential testing, providing finite-sample guarantees. For depth functions dependent on unknown distributions, we offer asymptotic guarantees using non-parametric statistical methods. In contrast to plain-vanilla Monte Carlo methodology the number of samples required in the algorithm is random but typically much smaller than standard choices suggested in the literature. The seMCD method can be applied to various depth functions, covering multivariate and functional spaces. We demonstrate the efficiency and reliability of our approach through empirical studies, highlighting its applicability in outlier or anomaly detection, classification, and depth region computation. In conclusion, the seMCD-algorithm can achieve accurate depth approximations with few Monte Carlo samples while maintaining rigorous statistical guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06227v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Gnettner, Claudia Kirch, Alicia Nieto-Reyes</dc:creator>
    </item>
    <item>
      <title>Convex relaxation for the generalized maximum-entropy sampling problem</title>
      <link>https://arxiv.org/abs/2404.01390</link>
      <description>arXiv:2404.01390v3 Announce Type: replace 
Abstract: The generalized maximum-entropy sampling problem (GMESP) is to select an order-$s$ principal submatrix from an order-$n$ covariance matrix, to maximize the product of its $t$ greatest eigenvalues, $0&lt;t\leq s &lt;n$. Introduced more than 25 years ago, GMESP is a natural generalization of two fundamental problems in statistical design theory: (i) maximum-entropy sampling problem (MESP); (ii) binary D-optimality (D-Opt). In the general case, it can be motivated by a selection problem in the context of principal component analysis (PCA).
  We introduce the first convex-optimization based relaxation for GMESP, study its behavior, compare it to an earlier spectral bound, and demonstrate its use in a branch-and-bound scheme. We find that such an approach is practical when $s-t$ is very small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01390v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel Ponte, Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Causal Inference in Longitudinal Data under Unknown Interference</title>
      <link>https://arxiv.org/abs/2106.15074</link>
      <description>arXiv:2106.15074v4 Announce Type: replace-cross 
Abstract: In longitudinal studies where units are embedded in space or a social network, interference may arise, meaning that a unit's outcome can depend on treatment histories of others. The presence of interference poses significant challenges for causal inference, particularly when the interference structure -- how a unit's outcome responds to others' influences -- is complex, heterogeneous, and unknown to researchers. This paper develops a general framework for identifying and estimating both direct and spillover effects of treatment histories under minimal assumptions about the interference structure. We define a class of policy-relevant causal estimands and show that they can be represented by a modified marginal structural model (MSM). Under the standard assumption of sequential exchangeability, these estimands are identifiable and can be estimated using inverse probability weighting (IPW). We derive conditions for consistency and asymptotic normality of the estimators and provide procedures for constructing Wald-type confidence intervals with valid coverage in large samples. The method's utility is demonstrated through applications in both social science and biomedical settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.15074v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ye Wang, Michael Jetsupphasuk</dc:creator>
    </item>
    <item>
      <title>Static and Dynamic BART for Rank-Order Data</title>
      <link>https://arxiv.org/abs/2308.10231</link>
      <description>arXiv:2308.10231v4 Announce Type: replace-cross 
Abstract: Ranking lists are often provided at regular time intervals in a range of applications, including economics, sports, marketing, and politics. Most popular methods for rank-order data postulate a linear specification for the latent scores, which determine the observed ranks, and ignore the temporal dependence of the ranking lists. To address these issues, novel nonparametric static (ROBART) and autoregressive (ARROBART) models are developed, with latent scores defined as nonlinear Bayesian additive regression tree functions of covariates. To make inferences in the dynamic ARROBART model, closed-form filtering, predictive, and smoothing distributions for the latent time-varying scores are derived. These results are applied in a Gibbs sampler with data augmentation for posterior inference. The proposed methods are shown to outperform existing competitors in simulation studies, static data applications to electoral data, stated preferences for sushi and movies, and dynamic data applications to economic complexity rankings of countries and weekly pollster rankings of NCAA football teams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10231v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Matteo Iacopini, Eoghan O'Neill, Luca Rossini</dc:creator>
    </item>
    <item>
      <title>Bounding adapted Wasserstein metrics</title>
      <link>https://arxiv.org/abs/2407.21492</link>
      <description>arXiv:2407.21492v2 Announce Type: replace-cross 
Abstract: The Wasserstein distance $\mathcal{W}_p$ is an important instance of an optimal transport cost. Its numerous mathematical properties as well as applications to various fields such as mathematical finance and statistics have been well studied in recent years. The adapted Wasserstein distance $\mathcal{A}\mathcal{W}_p$ extends this theory to laws of discrete time stochastic processes in their natural filtrations, making it particularly well suited for analyzing time-dependent stochastic optimization problems.
  While the topological differences between $\mathcal{A}\mathcal{W}_p$ and $\mathcal{W}_p$ are well understood, their differences as metrics remain largely unexplored beyond the trivial bound $\mathcal{W}_p\lesssim \mathcal{A}\mathcal{W}_p$. This paper closes this gap by providing upper bounds of $\mathcal{A}\mathcal{W}_p$ in terms of $\mathcal{W}_p$ through investigation of the smooth adapted Wasserstein distance. Our upper bounds are explicit and are given by a sum of $\mathcal{W}_p$, Eder's modulus of continuity and a term characterizing the tail behavior of measures. As a consequence, upper bounds on $\mathcal{W}_p$ automatically hold for $\mathcal{AW}_p$ under mild regularity assumptions on the measures considered. A particular instance of our findings is the inequality $\mathcal{A}\mathcal{W}_1\le C\sqrt{\mathcal{W}_1}$ on the set of measures that have Lipschitz kernels.
  Our work also reveals how smoothing of measures affects the adapted weak topology. In fact, we find that the topology induced by the smooth adapted Wasserstein distance exhibits a non-trivial interpolation property, which we characterize explicitly: it lies in between the adapted weak topology and the weak topology, and the inclusion is governed by the decay of the smoothing parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21492v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jose Blanchet, Martin Larsson, Jonghwa Park, Johannes Wiesel</dc:creator>
    </item>
    <item>
      <title>The Zeta Tail Distribution: A Novel Event-Count Model</title>
      <link>https://arxiv.org/abs/2506.17496</link>
      <description>arXiv:2506.17496v2 Announce Type: replace-cross 
Abstract: We introduce the Zeta Tail(a) probability distribution as a new model for random damage-event counts in risk analysis. Although readily motivated as an analogue of the Geometric(p) distribution, Zeta Tail(a) has received little attention in the scholarly literature. In the present work, we begin by deriving various fundamental properties of this novel distribution. We then assess its usefulness as an alternative to Geometric(p), both theoretically and through application to a set of meteorological data. Lastly, we discuss conceptual differences between employing the Zeta Tail(a) model conditionally (i.e., given observed data with certain known characteristics) and unconditionally (i.e., for arbitrary, as yet unobserved data).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17496v2</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Wed, 09 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael R. Powers</dc:creator>
    </item>
  </channel>
</rss>
