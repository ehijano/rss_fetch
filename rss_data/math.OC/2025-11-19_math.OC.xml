<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Nov 2025 05:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Geometry of the Reformulation-Linearization-Technique: Domination of Disjunctions</title>
      <link>https://arxiv.org/abs/2511.13805</link>
      <description>arXiv:2511.13805v1 Announce Type: new 
Abstract: The reformulation-linearization-technique (RLT) is a well-known strengthening technique for binary mixed-integer optimization. It is well known to dominate lift-and-project strengthening, which is based on disjunctive programming (DP) for single-variable disjunctions. In contrast to the latter, the geometry of RLT is not understood completely. We provide some insights by characterizing the points in the corresponding RLT closure geometrically. We exploit this insight to show that RLT even dominates DP approaches based on cardinality equations with right-hand side 1. This is in contrast to cardinality inequalities with right-hand side 1, whose DPs are not dominated. Our results have applications in the strength comparison for the quadratic assignment problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13805v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugo A. Hof, Matthias Walter</dc:creator>
    </item>
    <item>
      <title>Optimal Sequential Flows</title>
      <link>https://arxiv.org/abs/2511.13806</link>
      <description>arXiv:2511.13806v1 Announce Type: new 
Abstract: We provide a new algebraic technique to solve the sequential flow problem in polynomial space. The task is to maximize the flow through a graph where edge capacities can be changed over time by choosing a sequence of capacity labelings from a given finite set. Our method is based on a novel factorization theorem for finite semigroups that, applied to a suitable flow semigroup, allows to derive small witnesses. This generalizes to multiple in/output vertices, as well as regular constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13806v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hugo Gimbert, Corto Mascle, Patrick Totzke</dc:creator>
    </item>
    <item>
      <title>QUASAR: An Evolutionary Algorithm to Accelerate High-Dimensional Optimization</title>
      <link>https://arxiv.org/abs/2511.13843</link>
      <description>arXiv:2511.13843v1 Announce Type: new 
Abstract: High-dimensional numerical optimization presents a persistent challenge. This paper introduces Quasi-Adaptive Search with Asymptotic Reinitialization (QUASAR), an evolutionary algorithm to accelerate convergence in complex, non-differentiable problems afflicted by the curse of dimensionality.
  Evaluated on the notoriously difficult CEC2017 benchmark suite of 29 functions, QUASAR achieved the lowest overall rank sum (150) using the Friedman test, significantly outperforming L-SHADE (229) and standard DE (305) in the dimension-variant trials. QUASAR also proves computationally efficient, with run times averaging $1.4 \text{x}$ faster than DE and $7.8 \text{x}$ faster than L-SHADE ($p \ll 0.001$) in the population-variant trials.
  Building upon Differential Evolution (DE), QUASAR introduces a highly stochastic architecture to dynamically balance exploration and exploitation. Inspired by the probabilistic behavior of quantum particles in a stellar core, the algorithm implements three primary components that augment standard DE mechanisms: 1) probabilistically selected mutation strategies and scaling factors; 2) rank-based crossover rates; 3) asymptotically decaying reinitialization that leverages a covariance matrix of the best solutions to introduce high-quality genetic diversity.
  QUASAR's performance establishes it as an effective, user-friendly optimizer for complex high-dimensional problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13843v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Soltes</dc:creator>
    </item>
    <item>
      <title>Convex relaxation approaches for high dimensional optimal transport</title>
      <link>https://arxiv.org/abs/2511.13847</link>
      <description>arXiv:2511.13847v1 Announce Type: new 
Abstract: Optimal transport (OT) is a powerful tool in mathematics and data science but faces severe computational and statistical challenges in high dimensions. We propose convex relaxation approaches based on marginal and cluster moment relaxations that exploit locality and correlative sparsity in the distributions. These methods approximate high-dimensional couplings using low-order marginals and sparse moment statistics, yielding semidefinite programs that provide lower bounds on the OT cost with greatly reduced complexity. For Gaussian distributions with sparse correlations, we prove reductions in both computational and sample complexity, and experiments show the approach also works well for non-Gaussian cases. In addition, we demonstrate how to extract transport maps from our relaxations, offering a simpler and interpretable alternative to neural networks in generative modeling. Our results suggest that convex relaxations can provide a promising path for dimension reduction in high-dimensional OT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13847v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuehaw Khoo, Tianyun Tang</dc:creator>
    </item>
    <item>
      <title>Backing PDHG into a Corner</title>
      <link>https://arxiv.org/abs/2511.13894</link>
      <description>arXiv:2511.13894v1 Announce Type: new 
Abstract: Recent enhancements to the Primal-Dual Hybrid Gradient (PDHG)
  algorithm have enabled GPUs to efficiently solve large linear
  programming problems, often faster than the long-dominant simplex
  and interior-point methods. The solutions found by PDHG are
  typically of much lower quality than those found by the
  alternatives, which can be remedied by following the PDHG iterations
  with a crossover step to obtain an accurate optimal basic solution.
  However, the cost of this highly sequential crossover step can be
  quite significant. This paper examines whether PDHG iterations can
  be enhanced to push the solution into a corner of the optimal LP
  face, thereby providing crossover a better starting point and
  hopefully reducing its runtime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13894v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Rothberg</dc:creator>
    </item>
    <item>
      <title>Hessians in Birkhoff-Theoretic Trajectory Optimization</title>
      <link>https://arxiv.org/abs/2511.13963</link>
      <description>arXiv:2511.13963v1 Announce Type: new 
Abstract: This paper derives various Hessians associated with Birkhoff-theoretic methods for trajectory optimization. According to a theorem proved in this paper, approximately 80% of the eigenvalues are contained in the narrow interval [-2, 4] for all Birkhoff-discretized optimal control problems. A preliminary analysis of computational complexity is also presented with further discussions on the grand challenge of solving a million point trajectory optimization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13963v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.RO</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2514/1.G008778</arxiv:DOI>
      <arxiv:journal_reference>Journal of Guidance Control and Dynamics, Vol. 48, No. 9, September 2025, 2105--2112</arxiv:journal_reference>
      <dc:creator>I. M. Ross</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Nash Equilibrium Seeking with Heterogeneous Data: A Lagrangian Approach</title>
      <link>https://arxiv.org/abs/2511.14048</link>
      <description>arXiv:2511.14048v1 Announce Type: new 
Abstract: We study a class of distributionally robust games where agents are allowed to heterogeneously choose their risk aversion with respect to distributional shifts of the uncertainty. In our formulation, heterogeneous Wasserstein ball constraints on each distribution are enforced through a penalty function leveraging a Lagrangian formulation. We then formulate the distributionally robust Nash equilibrium problem and show that under certain assumptions it is equivalent to a finite-dimensional variational inequality problem with a strongly monotone mapping. We then design an approximate Nash equilibrium seeking algorithm and prove convergence of the average regret to a quantity that diminishes with the number of iterations, thus learning the desired equilibrium up to an a priori specified accuracy. Numerical simulations corroborate our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14048v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zifan Wang, Georgios Pantazis, Sergio Grammatico, Michael M. Zavlanos, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Nonlinear three-operator splitting algorithms with momentum for monotone inclusions</title>
      <link>https://arxiv.org/abs/2511.14050</link>
      <description>arXiv:2511.14050v1 Announce Type: new 
Abstract: In this paper, we introduce three novel splitting algorithms for solving structured monotone inclusion problems involving the sum of a maximally monotone operator, a monotone and Lipschitz continuous operator and a cocoercive operator. Each proposed method extends one of the classical schemes: the semi-forward-reflected-backward splitting algorithm, the semi-reflected-forward-backward splitting algorithm, and the outer reflected forward-backward splitting algorithm by incorporating a nonlinear momentum term. Under appropriate step-size conditions, we establish the weak convergence of all three algorithms, and further prove their $R$-linear convergence rates under strong monotonicity assumptions. Preliminary numerical experiments on both synthetic datasets and real-world quadratic programming problems in portfolio optimization demonstrate the effectiveness and superiority of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14050v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liqian Qin, Aviv Gibali, Cuijie Zhang, Yuchao Tang</dc:creator>
    </item>
    <item>
      <title>Primal-Dual Bundle Methods for Linear Equality-Constrained Problems</title>
      <link>https://arxiv.org/abs/2511.14069</link>
      <description>arXiv:2511.14069v1 Announce Type: new 
Abstract: Dual ascent (DA) and the method of multipliers (MM) are fundamental methods for solving linear equality-constrained convex optimization problems, and their dual updates can be viewed as the minimization of a proximal linear surrogate function of the negative Lagrange dual and augmented Lagrange dual function, respectively. However, the proximal linear surrogate function may suffer from low approximation accuracy, which leads to slow convergence of DA and MM. To accelerate their convergence, we adapt the proximal bundle surrogate framework that can incorporate a list of more accurate surrogate functions, to both the primal and the dual updates of DA and MM, leading to a family of novel primal-dual bundle methods. Our methods generalize the primal-dual gradient method, DA, the linearized MM, and MM. Under standard assumptions that allow for a broad range of surrogate functions, we prove theoretical convergence guarantees for the proposed methods. Numerical experiments demonstrate that our methods converge not only faster, but also significantly more robust with respect to the parameters compared to the primal-dual gradient method, DA, the linearized MM, and MM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14069v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhuoqing Zheng, Tao Liu, Xuyang Wu</dc:creator>
    </item>
    <item>
      <title>Two-dimensional Spatial Optimization for Electric Motorcycle Powertrain Elements using Mixed-integer Programming</title>
      <link>https://arxiv.org/abs/2511.14236</link>
      <description>arXiv:2511.14236v1 Announce Type: new 
Abstract: This study presents a framework for optimizing the two-dimensional (2D) placement of electric motorcycle powertrain elements, accounting for the position, the orientation and geometric irregularities. Specifically, we construct a 2D placement model at the component level in which we include near-continuous rotation of components and allow for irregular subsystem geometries to make optimal use of the limited design space. Second, we introduce linearization techniques for the trigonometric constraints and formulate the placement problem as a mixed-integer quadratic program (MIQP). Finally, we demonstrate our framework on two electric motorcycle powertrain topologies and study the influence of the geometry complexity on the placement solutions. The results show that gradually increasing complexity leads to more manageable computation times and higher the complexity solution improves handling performance by 2.5% compared to the benchmark placement found in existing electric motorcycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14236v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jorn van Kampen, Chun-Cheng Huang, Mauro Salazar</dc:creator>
    </item>
    <item>
      <title>Optimizing Urban Electric Vehicle Charging and Battery Swapping Infrastructure: A Location-Inventory-Grid Model</title>
      <link>https://arxiv.org/abs/2511.14308</link>
      <description>arXiv:2511.14308v1 Announce Type: new 
Abstract: The rapid rise of electric vehicles (EVs) places unprecedented stress on both urban mobility systems and low-voltage power grids. Designing battery swapping and charging networks that are cost-efficient, grid-compatible, and sustainable is therefore a pressing yet complex challenge: service providers must jointly optimize station locations, battery inventory, and grid interaction under high-dimensional uncertainty. We develop an integrated location-inventory-grid model and employ a continuous approximation approach to overcome the intractability of discrete formulations. Our analysis compares centralized versus decentralized charging, with and without participation in frequency regulation. The results reveal that centralized charging, when combined with frequency regulation, not only reduces cost but also strengthens grid stability. However, it may constrain operational flexibility near the optimum, potentially challenging efforts to mitigate environmental impacts by lowering battery inventories. These results offer actionable guidance for cost-efficient, environmentally sustainable, and grid-compatible scaling of urban EV infrastructure to meet the demands of large-scale EV adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14308v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenqing Ai, Hanyu Cheng, Wei Qi</dc:creator>
    </item>
    <item>
      <title>A PDE-constrained Optimization Approach to Optimal Trajectory Planning under Uncertainty via Reflected Schr\"odinger Bridges</title>
      <link>https://arxiv.org/abs/2511.14355</link>
      <description>arXiv:2511.14355v1 Announce Type: new 
Abstract: A computational PDE-constrained optimization approach is proposed for optimal trajectory planning under uncertainty by means of an associated Schroedinger Bridge Problem (SBP). The proposed SBP formulation is interpreted as the mean-field limit associated to the energy-optimal evolution of a particle governed by a stochastic differential equation (SDE) with nonlinear drift and reflecting boundary conditions, constrained to initial and terminal densities for its state. The resulting mean-field system consists of a nonlinear Fokker-Planck equation coupled with a Hamilton-Jacobi-Bellman equation, subject to two-point boundary conditions in time and Neumann boundary conditions in space. Through the Hopf-Cole transformation, this nonlinear system is recast as a pair of forward-backward advection-diffusion equations, which are amenable to efficient numerical solution via standard finite element discretization. The weak formulation naturally enforces reflecting boundary conditions without requiring explicit particle-boundary collision detection, thus circumventing the computational difficulties inherent to particle-based methods in complex geometries. Numerical experiments on challenging 3D maze configurations demonstrate fast convergence, mass conservation, and validate the optimal controls computed through reflected SDE simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14355v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Kalise, Wenxin Liu</dc:creator>
    </item>
    <item>
      <title>H\"older regularity in bang-bang type affine optimal control problems</title>
      <link>https://arxiv.org/abs/2511.14459</link>
      <description>arXiv:2511.14459v1 Announce Type: new 
Abstract: This paper revisits the issue of H\"older Strong Metric sub-Regularity (HSMs-R) of the optimality system associated with ODE optimal control problems that are affine with respect to the control. The main contributions are as follows. First, the metric in the control space, introduced in this paper, differs from the ones used so far in the literature in that it allows to take into consideration the bang-bang structure of the optimal control functions. This is especially important in the analysis of Model Predictive Control algorithms. Second, the obtained sufficient conditions for HSMs-R extend the known ones in a way which makes them applicable to some problems which are non-linear in the state variable and the H\"older exponent is smaller than one (that is, the regularity is not Lipschitz).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14459v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-030-97549-4_35</arxiv:DOI>
      <arxiv:journal_reference>Large-Scale Scientific Computing, Lecture Notes in Comput. Sci. 13127 (2022), 306-313</arxiv:journal_reference>
      <dc:creator>Alberto Dom\'inguez Corella, Vladimir Veliov</dc:creator>
    </item>
    <item>
      <title>Dynamic Carbon Intensity Indicator (CII) Management in Stochastic Tramp Shipping Market</title>
      <link>https://arxiv.org/abs/2511.14471</link>
      <description>arXiv:2511.14471v1 Announce Type: new 
Abstract: In the maritime sector, tramp shipping companies manage fleets to maximize profit while navigating market uncertainties. The International Maritime Organization (IMO) recently introduced the Carbon Intensity Indicator (CII) to reduce greenhouse gas emissions, further complicating deployment decisions. This paper introduces a novel two-stage stochastic programming model for long-term fleet deployment under market uncertainty and CII regulation. It is the first to integrate key operational uncertainties such as fuel prices, freight rates, and cargo demand into a unified tactical planning framework under CII regulation, simultaneously optimizing routing, cargo allocation, and speed. Furthermore, we develop an novel efficient heuristic algorithm that reliably converges to solutions within a 5\% optimality gap, enabling practical decision-support under uncertainty. Numerical analysis highlights two key findings based on our model: (1) It uncovers the ``CII paradox,'' a critical counterintuitive phenomenon where the present Supply-based CII regulation may increase total emissions significantly and drastically reduce profits. This challenges the conventional wisdom that stricter carbon-intensity rules invariably reduce emissions. (2) It demonstrates the advantage of stochastic modeling, showing that accounting for future uncertainties significantly narrows the revenue gap with perfect-foresight solutions, thereby offering superior economic performance over deterministic approaches. Collectively, these results deepen the understanding of environmental regulation's operational impacts and pave the way for more effective and sustainable fleet management strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14471v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanyu Cheng, Liangqi Cheng, Xiwen Bai</dc:creator>
    </item>
    <item>
      <title>Strong bi-metric regularity in affine optimal control problems</title>
      <link>https://arxiv.org/abs/2511.14475</link>
      <description>arXiv:2511.14475v1 Announce Type: new 
Abstract: The paper presents new sufficient conditions for the property of strong bi-metric regularity of the optimality map associated with an optimal control problem which is affine with respect to the control variable ({\em affine problem}). The optimality map represents the system of first order optimality conditions (Pontryagin maximum principle), and its regularity is of key importance for the qualitative and numerical analysis of optimal control problems. The case of affine problems is especially challenging due to the typical discontinuity of the optimal control functions. A remarkable feature of the obtained sufficient conditions is that they do not require convexity of the objective functional. As an application, the result is used for proving uniform convergence of the Euler discretization method for a family of affine optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14475v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Pure Appl. Funct. Anal. 6 (2021), no. 6, 1119-1137</arxiv:journal_reference>
      <dc:creator>Alberto Dom\'inguez Corella, Marc Quincampoix, Vladimir Veliov</dc:creator>
    </item>
    <item>
      <title>Improved Convergence in Parameter-Agnostic Error Feedback through Momentum</title>
      <link>https://arxiv.org/abs/2511.14501</link>
      <description>arXiv:2511.14501v1 Announce Type: new 
Abstract: Communication compression is essential for scalable distributed training of modern machine learning models, but it often degrades convergence due to the noise it introduces. Error Feedback (EF) mechanisms are widely adopted to mitigate this issue of distributed compression algorithms. Despite their popularity and training efficiency, existing distributed EF algorithms often require prior knowledge of problem parameters (e.g., smoothness constants) to fine-tune stepsizes. This limits their practical applicability especially in large-scale neural network training. In this paper, we study normalized error feedback algorithms that combine EF with normalized updates, various momentum variants, and parameter-agnostic, time-varying stepsizes, thus eliminating the need for problem-dependent tuning. We analyze the convergence of these algorithms for minimizing smooth functions, and establish parameter-agnostic complexity bounds that are close to the best-known bounds with carefully-tuned problem-dependent stepsizes. Specifically, we show that normalized EF21 achieve the convergence rate of near ${O}(1/T^{1/4})$ for Polyak's heavy-ball momentum, ${O}(1/T^{2/7})$ for Iterative Gradient Transport (IGT), and ${O}(1/T^{1/3})$ for STORM and Hessian-corrected momentum. Our results hold with decreasing stepsizes and small mini-batches. Finally, our empirical experiments confirm our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14501v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdurakhmon Sadiev, Yury Demidovich, Igor Sokolov, Grigory Malinovsky, Sarit Khirirat, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>A General Framework for Physician Rostering Using Mixed-Integer Programming and a Web-Based Graphical User Interface</title>
      <link>https://arxiv.org/abs/2511.14536</link>
      <description>arXiv:2511.14536v1 Announce Type: new 
Abstract: Physician rostering in hospitals is complex due to varying shift structures, qualifications, and department- or hospital-specific regulations. Most existing optimization models are highly tailored to a single hospital or department and rarely see practical use. We present a general framework and a corresponding mixed-integer programming (MIP) model for physician rostering that accommodates a wide variety of roster structures and constraints. The model is integrated into a web application with an advanced graphical user interface (GUI), allowing physicians to specify preferences and hospital staff to configure the MIP model to their roster requirements without any mathematical or technical background. This approach enables easy adaptation to different hospitals or departments and straightforward updates in response to structural changes, such as new duties or modified qualifications. The applicability and effectiveness of the framework are demonstrated using real-world data from three departments in different hospitals specializing in internal medicine, cardiology, and orthopedics/trauma surgery. In one department, the system is already in everyday use, while in the other two, our model achieves comparable or improved roster quality relative to existing department-specific models, highlighting its potential as a versatile and practical tool for physician rostering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14536v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Meier, Jan Boeckmann, Clemens Thielen</dc:creator>
    </item>
    <item>
      <title>A Unified Phase-Field Fourier Neural Network Framework for Topology Optimization</title>
      <link>https://arxiv.org/abs/2511.14623</link>
      <description>arXiv:2511.14623v1 Announce Type: new 
Abstract: This paper presents a unified and physics-driven framework of alternating phase-field Fourier neural networks (APF-FNNs) for topology optimization. At its core, an alternating architecture decouples the optimization by parameterizing the state, adjoint and topology fields with three distinct Fourier Neural Networks (FNNs). These networks are trained through a collaborative and stable alternating optimization scheme applicable to both self-adjoint and non-self-adjoint systems. The Ginzburg-Landau energy functional is incorporated into the topology network's loss function, acting as an intrinsic regularizer that promotes well-defined designs with smooth and distinct interfaces. By employing physics-informed losses derived from either variational principles or strong-form PDE residuals, the broad applicability of the APF-FNNs is demonstrated across a spectrum of 2D and 3D multi-physics benchmarks, including compliance minimization, eigenvalue maximization, and Stokes/Navier-Stokes flow optimization. The proposed APF-FNNs consistently yield high-performance and high-resolution topologies, establishing a powerful and versatile foundation for physics-driven computational design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14623v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Li, Xindi Hu, Helin Gong, Wei Gong, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>Concave Comparison Functions for Accelerating Constrained Lyapunov Decay</title>
      <link>https://arxiv.org/abs/2511.14626</link>
      <description>arXiv:2511.14626v1 Announce Type: new 
Abstract: What limits how fast a Lyapunov function can decay under input bounds? We address this question by showing how the shape of Lyapunov comparison functions governs guaranteed decay for control affine systems. Using a windowed nominal exponential rate together with the endpoint cap induced by actuator limits, we establish a strict ordering: concave comparison functions strictly outperform linear and convex ones, and strict concavity is necessary to improve the best achievable global exponential rate under a fixed endpoint cap. We derive a computable lower bound on the required actuation level for a target nominal rate and show that only concave shaping can reduce this level under the endpoint cap. We then establish a feasibility-preserving acceleration result: whenever a margin exists on a sublevel set, a feasible linear comparison can be replaced by a concave one that preserves feasibility while strictly increasing the guaranteed windowed decay. Finally, we give a tunable rational concave factor with controlled slope that yields a constructive design and integrates with CLF QP, as illustrated by examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14626v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuyuan Fan, Guanru Pan, Herbert Werner</dc:creator>
    </item>
    <item>
      <title>An Adaptive Proximal Point Method for Nonsmooth and Nonconvex Optimization on Hadamard Manifolds</title>
      <link>https://arxiv.org/abs/2511.14724</link>
      <description>arXiv:2511.14724v1 Announce Type: new 
Abstract: This paper addresses a class of nonsmooth and nonconvex optimization problems defined on complete Riemannian manifolds. The objective function has a composite structure, combining convex, differentiable, and lower semicontinuous terms, thereby generalizing the classical framework of difference-of-convex programming. Motivated by recent advances in proximal point methods in Euclidean and Riemannian settings, we propose two variants: one that uses the Lipschitz constant of the gradient of the smooth part, suitable when this parameter is accessible, and another that dispenses with such knowledge, expanding its applicability. We analyze the complexity of both approaches, establish their convergence, and illustrate their effectiveness through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14724v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vitaliano S. Amaral, Marcio Ant\^onio de A. Bortoloti, Jurandir O. Lopes, Gilson N. Silva</dc:creator>
    </item>
    <item>
      <title>A Sequential Operator-Splitting Framework for Exploration of Nonconvex Trajectory Optimization Solution Spaces</title>
      <link>https://arxiv.org/abs/2511.14752</link>
      <description>arXiv:2511.14752v1 Announce Type: new 
Abstract: Trajectory optimization methods provide an efficient and reliable means of computing feasible trajectories in nonconvex solution spaces. However, a well-known limitation of these algorithms is that they are inherently local in nature, and typically converge to a solution in the neighborhood of their initial guess. This paper presents a sequential operator-splitting framework, based on the alternating direction method of multipliers (ADMM), aimed at promoting exploration within the sequential convex programming (SCP) framework. In particular, diverse initial solutions are modeled as agents within the consensus ADMM framework. Driving these agents toward consensus facilitates exploration of the nonconvex optimization landscape. Numerical simulations demonstrate that the proposed method consistently yields equivalent or lower-cost solutions compared to the standard SCP approach, with the same number of or fewer agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14752v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Ganiban, Natalia Pavlasek, Behcet Acikmese</dc:creator>
    </item>
    <item>
      <title>Game-theoretic Decentralized Coordination for Airspace Sector Overload Mitigation</title>
      <link>https://arxiv.org/abs/2511.13770</link>
      <description>arXiv:2511.13770v1 Announce Type: cross 
Abstract: Decentralized air traffic management systems offer a scalable alternative to centralized control, but often assume high levels of cooperation. In practice, such assumptions frequently break down since airspace sectors operate independently and prioritize local objectives. We address the problem of sector overload in decentralized air traffic management by proposing a mechanism that models self-interested behaviors based on best response dynamics. Each sector adjusts the departure times of flights under its control to reduce its own congestion, without any shared decision making. A tunable cooperativeness factor models the degree to which each sector is willing to reduce overload in other sectors. We prove that the proposed mechanism satisfies a potential game structure, ensuring that best response dynamics converge to a pure Nash equilibrium, under a mild restriction. In addition, we identify a sufficient condition under which an overload-free solution corresponds to a global minimizer of the potential function. Numerical experiments using 24 hours of European flight data demonstrate that the proposed algorithm substantially reduces overload even with only minimal cooperation between sectors, while maintaining scalability and matching the solution quality of centralized solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13770v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaehan Im, Daniel Delahaye, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Hashpower allocation in Pay-per-Share blockchain mining pools</title>
      <link>https://arxiv.org/abs/2511.13777</link>
      <description>arXiv:2511.13777v1 Announce Type: cross 
Abstract: Mining blocks in a blockchain using the \textit{Proof-of-Work} consensus protocol involves significant risk, as network participants face continuous operational costs while earning infrequent capital gains upon successfully mining a block. A common risk mitigation strategy is to join a mining pool, which combines the computing resources of multiple miners to provide a more stable income. This article examines a Pay-per-Share (PPS) reward system, where the pool manager can adjust both the share difficulty and the management fee. Using a simplified wealth model for miners, we explore how miners should allocate their computing resources among different mining pools, considering the trade-off between risk transfer to the manager and management fees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13777v1</guid>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre-Olivier Goffard, Hansjoerg Albrecher, Jean-Pierre Fouque</dc:creator>
    </item>
    <item>
      <title>Dissipativity-Based Distributed Stability Analysis for Networks with Heterogeneous Nonlinear Agents</title>
      <link>https://arxiv.org/abs/2511.13925</link>
      <description>arXiv:2511.13925v1 Announce Type: cross 
Abstract: Stabilizing large networks of nonlinear agents is challenging; decomposition and distributed analysis of these networks are crucial for computational tractability and information security. Vidyasagar's Network Dissipativity Theorem enables both properties concurrently in distributed network analysis. This paper explored combining it with the alternating direction methods of multipliers to develop distributed stability analysis for networks of inhomogeneous, nonlinear agents. One algorithm enhances information security by requiring agents to share only a dissipativity characterization, not a dynamical model, for stability analysis. A second algorithm further restricts this information sharing to their clique, thereby enhancing security, and can also reduce the computational burden of stability analysis if the network allows chordal decomposition. The convergence of the proposed algorithms is demonstrated, and criteria are identified for decomposable networks facilitating chordal decomposition. The effectiveness of the proposed methods is demonstrated through numerical examples involving a swarm of linearized unmanned aerial vehicles and networks beyond linear time-invariant agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13925v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ingyu Jang, Ethan J. LoCicero, Leila Bridgeman</dc:creator>
    </item>
    <item>
      <title>Consensus-Based Stability Analysis of Multi-Agent Networks</title>
      <link>https://arxiv.org/abs/2511.13926</link>
      <description>arXiv:2511.13926v1 Announce Type: cross 
Abstract: The emergence of large-scale multi-agent systems has led to controller synthesis methods for sparse communication between agents. However, most sparse controller synthesis algorithms remain centralized, requiring information exchange and high computational costs. This underscores the need for distributed algorithms that design controllers using only local dynamics information from each agent. This paper presents a consensus-based distributed stability analysis. The proposed stability analysis algorithms leverage Vidyasagar's Network Dissipativity Theorem and the alternating direction methods of multipliers to perform general stability analysis. Numerical examples involving a 2D swarm of unmanned aerial vehicles demonstrate the convergence of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13926v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ingyu Jang, Ethan J. LoCicero, Leila Bridgeman</dc:creator>
    </item>
    <item>
      <title>On the Gradient Complexity of Private Optimization with Private Oracles</title>
      <link>https://arxiv.org/abs/2511.13999</link>
      <description>arXiv:2511.13999v1 Announce Type: cross 
Abstract: We study the running time, in terms of first order oracle queries, of differentially private empirical/population risk minimization of Lipschitz convex losses. We first consider the setting where the loss is non-smooth and the optimizer interacts with a private proxy oracle, which sends only private messages about a minibatch of gradients. In this setting, we show that expected running time $\Omega(\min\{\frac{\sqrt{d}}{\alpha^2}, \frac{d}{\log(1/\alpha)}\})$ is necessary to achieve $\alpha$ excess risk on problems of dimension $d$ when $d \geq 1/\alpha^2$. Upper bounds via DP-SGD show these results are tight when $d&gt;\tilde{\Omega}(1/\alpha^4)$. We further show our lower bound can be strengthened to $\Omega(\min\{\frac{d}{\bar{m}\alpha^2}, \frac{d}{\log(1/\alpha)} \})$ for algorithms which use minibatches of size at most $\bar{m} &lt; \sqrt{d}$. We next consider smooth losses, where we relax the private oracle assumption and give lower bounds under only the condition that the optimizer is private. Here, we lower bound the expected number of first order oracle calls by $\tilde{\Omega}\big(\frac{\sqrt{d}}{\alpha} + \min\{\frac{1}{\alpha^2}, n\}\big)$, where $n$ is the size of the dataset. Modifications to existing algorithms show this bound is nearly tight. Compared to non-private lower bounds, our results show that differentially private optimizers pay a dimension dependent runtime penalty. Finally, as a natural extension of our proof technique, we show lower bounds in the non-smooth setting for optimizers interacting with information limited oracles. Specifically, if the proxy oracle transmits at most $\Gamma$-bits of information about the gradients in the minibatch, then $\Omega\big(\min\{\frac{d}{\alpha^2\Gamma}, \frac{d}{\log(1/\alpha)}\}\big)$ oracle calls are needed. This result shows fundamental limitations of gradient quantization techniques in optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13999v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Menart, Aleksandar Nikolov</dc:creator>
    </item>
    <item>
      <title>Splat Regression Models</title>
      <link>https://arxiv.org/abs/2511.14042</link>
      <description>arXiv:2511.14042v1 Announce Type: cross 
Abstract: We introduce a highly expressive class of function approximators called Splat Regression Models. Model outputs are mixtures of heterogeneous and anisotropic bump functions, termed splats, each weighted by an output vector. The power of splat modeling lies in its ability to locally adjust the scale and direction of each splat, achieving both high interpretability and accuracy. Fitting splat models reduces to optimization over the space of mixing measures, which can be implemented using Wasserstein-Fisher-Rao gradient flows. As a byproduct, we recover the popular Gaussian Splatting methodology as a special case, providing a unified theoretical framework for this state-of-the-art technique that clearly disambiguates the inverse problem, the model, and the optimization algorithm. Through numerical experiments, we demonstrate that the resulting models and algorithms constitute a flexible and promising approach for solving diverse approximation, estimation, and inverse problems involving low-dimensional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14042v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mara Daniels, Philippe Rigollet</dc:creator>
    </item>
    <item>
      <title>SCOPE: Spectral Concentration by Distributionally Robust Joint Covariance-Precision Estimation</title>
      <link>https://arxiv.org/abs/2511.14146</link>
      <description>arXiv:2511.14146v1 Announce Type: cross 
Abstract: We propose a distributionally robust formulation for simultaneously estimating the covariance matrix and the precision matrix of a random vector.The proposed model minimizes the worst-case weighted sum of the Frobenius loss of the covariance estimator and Stein's loss of the precision matrix estimator against all distributions from an ambiguity set centered at the nominal distribution. The radius of the ambiguity set is measured via convex spectral divergence. We demonstrate that the proposed distributionally robust estimation model can be reduced to a convex optimization problem, thereby yielding quasi-analytical estimators. The joint estimators are shown to be nonlinear shrinkage estimators. The eigenvalues of the estimators are shrunk nonlinearly towards a positive scalar, where the scalar is determined by the weight coefficient of the loss terms. By tuning the coefficient carefully, the shrinkage corrects the spectral bias of the empirical covariance/precision matrix estimator. By this property, we call the proposed joint estimator the Spectral concentrated COvariance and Precision matrix Estimator (SCOPE). We demonstrate that the shrinkage effect improves the condition number of the estimator. We provide a parameter-tuning scheme that adjusts the shrinkage target and intensity that is asymptotically optimal. Numerical experiments on synthetic and real data show that our shrinkage estimators perform competitively against state-of-the-art estimators in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14146v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renjie Chen, Viet Anh Nguyen, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Gradient Flows of Potential Energies in the Geometry of Sinkhorn Divergences</title>
      <link>https://arxiv.org/abs/2511.14278</link>
      <description>arXiv:2511.14278v1 Announce Type: cross 
Abstract: We analyze the gradient flow of a potential energy in the space of probability measures when we substitute the optimal transport geometry with a geometry based on Sinkhorn divergences, a debiased version of entropic optimal transport. This gradient flow appears formally as the limit of the minimizing movement scheme, a.k.a. JKO scheme, when the squared Wasserstein distance is substituted by the Sinkhorn divergence. We prove well-posedness and stability of the flow, and that, in the long term, the energy always converges to its minimal value. The analysis is based on a change of variable to study the flow in a Reproducing Kernel Hilbert Space, in which the evolution is no longer a gradient flow but described by a monotone operator. Under a restrictive assumption we prove the convergence of our modified JKO scheme towards this flow as the time step vanishes. We also provide numerical illustrations of the intriguing properties of this newly defined gradient flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14278v1</guid>
      <category>math.AP</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathis Hardion (LIGM), Hugo Lavenant (BIDSA)</dc:creator>
    </item>
    <item>
      <title>A graph-informed regret metric for optimal distributed control</title>
      <link>https://arxiv.org/abs/2511.14280</link>
      <description>arXiv:2511.14280v1 Announce Type: cross 
Abstract: We consider the optimal control of large-scale systems using distributed controllers with a network topology that mirrors the coupling graph between subsystems. In this work, we introduce spatial regret, a graph-informed metric that measures the worst-case performance gap between a distributed controller and an oracle which is assumed to have access to additional sensor information. The oracle's graph is a user-specified augmentation of the available information graph, resulting in a benchmark policy that highlights disturbances for which additional sensor information would significantly improve performance. Minimizing spatial regret yields distributed controllers-respecting the nominal information graph-that emulate the oracle's response to disturbances that are characteristic of large-scale networks, such as localized perturbations. We show that minimizing spatial regret admits a convex reformulation as an infinite program with a finite-dimensional approximation. To scale to large networks, we derive a computable upper bound on the spatial regret metric whose minimization problem can be solved in a distributed way. Numerical experiments on power-system models demonstrate that the resulting controllers mitigate localized disturbances more effectively than controllers optimized using classical metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14280v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Martinelli, Andrea Martin, Giancarlo Ferrari-Trecate, Luca Furieri</dc:creator>
    </item>
    <item>
      <title>An adaptive extension to robust data-driven predictive control under parametric uncertainty</title>
      <link>https://arxiv.org/abs/2511.14319</link>
      <description>arXiv:2511.14319v1 Announce Type: cross 
Abstract: Robust data-driven controllers typically rely on datasets from previous experiments, which embed information on the variability of the system parameters across past operational conditions. Complementarily, data collected online can contribute to improving the feedback performance relative to the current system's conditions, but are unable to account for the overall -- possibly time-varying -- system operation.
  With this in mind, we consider the problem of stabilizing a time-varying linear system, whose parameters are only known to lie within a bounded polytopic set. Taking a robust data-driven approach, we synthesize the control law by simultaneously leveraging two sets of historical state and input measures: an offline dataset -- which covers the extreme variations of the system parameters -- and an online dataset consisting of a rolling window of the latest state and input samples.
  Our approach relies on the data informativity framework: we thus relax persistent excitation requirements (i.e., the collected samples need not be sufficient for system identification), while still allowing for the design of a stabilizing controller. The state feedback law is obtained from standard Lyapunov arguments, implemented via semi-definite optimization: this also yields an upper bound on the cost-to-go for the class of systems that are consistent with the online data, while guaranteeing a decreasing cost for all systems compatible with the offline data. Numerical experiments are presented to illustrate the effectiveness of the proposed controller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14319v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ignacio Sanchez, Filiberto Fele, Daniel Limon</dc:creator>
    </item>
    <item>
      <title>Quantum speed-ups for solving semidefinite relaxations of polynomial optimization</title>
      <link>https://arxiv.org/abs/2511.14389</link>
      <description>arXiv:2511.14389v1 Announce Type: cross 
Abstract: We study quantum algorithms for approximating Lasserre's hierarchy values for polynomial optimization. Let $f,g_1,\ldots,g_m$ be real polynomials in $n$ variables and $f^\star$ the infimum of $f$ over the semialgebraic set $S(g)=\{x: g_i(x)\ge 0\}$. Let $\lambda_k$ be the value of the order-$k$ Lasserre relaxation. Assume either (i) $f^\star=\lambda_k$ and the optimum is attained in the $\ell_1$-ball of radius $1/2$, or (ii) $S(g)$ lies in the simplex $\{x\ge 0: \sum_j x_j\le 1/2\}$, and the constraints define this simplex. After an appropriate coefficient rescaling, we give a quantum algorithm based on matrix multiplicative weights that approximates $\lambda_k$ to accuracy $\varepsilon&gt;0$ with runtime, for fixed $k$, \[ O(n^k\varepsilon^{-4}+n^{k/2}\varepsilon^{-5}),\qquad O\!\left(s_g\!\left[n^k\varepsilon^{-4}+\!\left(n^{k}+\!\sum_{i=1}^m n^{k-d_i}\right)^{1/2}\!\varepsilon^{-5}\right]\right), \] where $s_g$ bounds the sparsity of the coefficient-matching matrices associated with the constraints. Classical matrix multiplicative-weights methods scale as $O(n^{3k}\mathrm{poly}(1/\varepsilon))$ even in the unconstrained case. As an example, we obtain an $O(n\varepsilon^{-4}+\sqrt{n}\varepsilon^{-5})$ quantum algorithm for portfolio optimization, improving over the classical $O(n^{\omega+1}\log(1/\varepsilon))$ bound with $\omega\approx2.373$.
  Our approach builds on and sharpens the analysis of Apeldoorn and Gily\'en for the SDPs arising in polynomial optimization. We also show how to implement the required block encodings without QRAM. Under the stated assumptions, our method achieves a super-quadratic speedup in the problem dimension for computing Lasserre relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14389v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Stilck Fran\c{c}a, Ngoc Hoang Anh Mai</dc:creator>
    </item>
    <item>
      <title>AdamHD: Decoupled Huber Decay Regularization for Language Model Pre-Training</title>
      <link>https://arxiv.org/abs/2511.14721</link>
      <description>arXiv:2511.14721v1 Announce Type: cross 
Abstract: Adaptive optimizers with decoupled weight decay, such as AdamW, are the de facto standard for pre-training large transformer-based generative models. Yet the quadratic nature of the $\ell_2$ penalty embedded in weight decay drives all parameters toward the origin at the same rate, making the update vulnerable to rare but extreme gradient directions and often over-penalizing well-conditioned coordinates. We propose AdamHuberDecay, a drop-in replacement for AdamW that substitutes the $\ell_2$ penalty with a decoupled smooth Huber regularizer. The resulting update decays parameters quadratically while their magnitude remains below a threshold $\delta$, and linearly ($\ell_1$-like) once they exceed $\delta$, yielding (i) bounded regularization gradients, (ii) invariance to per-coordinate second-moment rescaling, and (iii) stronger sparsity pressure on overgrown weights.
  We derive the closed-form decoupled Huber decay step and show how to integrate it with any Adam-family optimizer at $O(1)$ extra cost. Extensive experiments on GPT-2 and GPT-3 pre-training demonstrate that AdamHuberDecay (a) converges 10-15% faster in wall-clock time, (b) reduces validation perplexity by up to 4 points, (c) delivers performance improvements of 2.5-4.7% across downstream tasks, and (d) yields visibly sparser weight histograms that translate into 20-30% memory savings after magnitude pruning, without tuning the decay coefficient beyond the default grid used for AdamW. Ablations confirm robustness to outlier gradients and large-batch regimes, together with theoretical analyses that bound the expected parameter norm under noisy updates. AdamHuberDecay therefore provides a simple, principled path toward more efficient and resilient training of next-generation foundational generative transformers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14721v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:journal_reference>39th Conference on Neural Information Processing Systems (NeurIPS 2025) Workshop: GPU-Accelerated and Scalable Optimization (ScaleOpt)</arxiv:journal_reference>
      <dc:creator>Fu-Ming Guo, Yingfang Fan</dc:creator>
    </item>
    <item>
      <title>Convex Reformulation of LMI-Based Distributed Controller Design with a Class of Non-Block-Diagonal Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2404.04576</link>
      <description>arXiv:2404.04576v4 Announce Type: replace 
Abstract: This study addresses a distributed state feedback controller design problem for continuous-time linear time-invariant systems by means of linear matrix inequalities (LMIs). As structural constraints on a control gain result in non-convexity in general, the block-diagonal relaxation of Lyapunov functions has been prevalent despite its conservatism. In this work, we target a class of non-block-diagonal Lyapunov functions with the same sparsity pattern as distributed controllers. By leveraging a block-diagonal factorization of sparse matrices and Finsler's lemma, we first present a nonlinear matrix inequality for stabilizing distributed controllers with such Lyapunov functions, which boils down to a necessary and sufficient condition for such controllers if the sparsity pattern is chordal. As its relaxation, we derive novel LMIs, one of which strictly covers the conventional relaxation, and then provide analogous results for $H_\infty$ control. Lastly, numerical examples underscore the efficacy of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04576v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuto Watanabe, Sotaro Fushimi, Kazunori Sakurama</dc:creator>
    </item>
    <item>
      <title>Finite-Agent Stochastic Differential Games on Large Graphs: I. The Linear-Quadratic Case</title>
      <link>https://arxiv.org/abs/2406.09523</link>
      <description>arXiv:2406.09523v3 Announce Type: replace 
Abstract: In this paper, we study finite-agent linear-quadratic games on graphs. Specifically, we propose a comprehensive framework that extends the existing literature by incorporating heterogeneous and interpretable player interactions. Compared to previous works, our model offers a more realistic depiction of strategic decision-making processes. For general graphs, we establish the convergence of fictitious play, a widely-used iterative solution method for determining the Nash equilibrium of our proposed game model. Notably, under appropriate conditions, this convergence holds true irrespective of the number of players involved. For vertex-transitive graphs, we develop a semi-explicit characterization of the Nash equilibrium. Through rigorous analysis, we demonstrate the well-posedness of this characterization under certain conditions. We present numerical experiments that validate our theoretical results and provide insights into the intricate relationship between various game dynamics and the underlying graph structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09523v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Applied Mathematics &amp; Optimization 92(2), 1--50, 2025</arxiv:journal_reference>
      <dc:creator>Ruimeng Hu, Jihao Long, Haosheng Zhou</dc:creator>
    </item>
    <item>
      <title>On the Hardness of the $L_1-L_2$ Regularization Problem</title>
      <link>https://arxiv.org/abs/2411.03216</link>
      <description>arXiv:2411.03216v2 Announce Type: replace 
Abstract: The sparse linear reconstruction problem is a core problem in signal processing which aims to recover sparse solutions to linear systems. The original problem regularized by the total number of nonzero components (also known as $L_0$ regularization) is well-known to be NP-hard. The relaxation of the $L_0$ regularization by using the $L_1$ norm offers a convex reformulation, but is only exact under certain conditions (e.g., restricted isometry property) which might be NP-hard to verify. To overcome the computational hardness of the $L_0$ regularization problem while providing tighter results than the $L_1$ relaxation, several alternate optimization problems have been proposed to find sparse solutions. One such problem is the $L_1-L_2$ minimization problem, which is to minimize the difference of the $L_1$ and $L_2$ norms subject to linear constraints. This paper proves that solving the $L_1-L_2$ minimization problem is NP-hard. Specifically, we prove that it is NP-hard to minimize the $L_1-L_2$ regularization function subject to linear constraints. Moreover, it is also NP-hard to solve the unconstrained formulation that minimizes the sum of a least squares term and the $L_1-L_2$ regularization function. Furthermore, restricting the feasible set to a smaller one by adding nonnegative constraints does not change the NP-hardness nature of the problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03216v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyuan Ouyang, Kyle Yates</dc:creator>
    </item>
    <item>
      <title>A Bregman ADMM for Bethe variational problem</title>
      <link>https://arxiv.org/abs/2502.04613</link>
      <description>arXiv:2502.04613v3 Announce Type: replace 
Abstract: In this work, we propose a novel Bregman ADMM with nonlinear dual update to solve the Bethe variational problem (BVP), a key optimization formulation in graphical models and statistical physics. Our algorithm provides rigorous convergence guarantees, even if the objective function of BVP is non-convex and non-Lipschitz continuous on the boundary. A central result of our analysis is proving that the entries in local minima of BVP are strictly positive, effectively resolving non-smoothness issues caused by zero entries. Beyond theoretical guarantees, the algorithm possesses high level of separability and parallelizability to achieve highly efficient subproblem computation. Our Bregman ADMM can be easily extended to solve the quantum Bethe variational problem. Numerical experiments are conducted to validate the effectiveness and robustness of the proposed method. Based on this research, we have released an open-source package of the proposed method at https://github.com/TTYmath/BADMM-BVP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04613v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuehaw Khoo, Tianyun Tang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>A microscopic traffic flow model on network with destination-aware V2V communications and rational decision-making</title>
      <link>https://arxiv.org/abs/2504.01480</link>
      <description>arXiv:2504.01480v2 Announce Type: replace 
Abstract: In this paper we carry out a computational study of a novel microscopic follow-the-leader model for traffic flow on road networks. We assume that each driver has its own origin and destination, and wants to complete its journey in minimal time. We also assume that each driver is able to take rational decisions at junctions and can change route while moving depending on the traffic conditions. The main novelty of the model is that vehicles can automatically and anonymously share information about their position, destination, and planned path when they are close to each other within a certain distance. The pieces of information acquired during the journey are used to optimize the route itself. In the limit case of an infinite communication range, we recover the classical Reactive User Equilibrium and Dynamic User Equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01480v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emiliano Cristiani, Francesca L. Ignoto</dc:creator>
    </item>
    <item>
      <title>Communication-Efficient Distributed Online Nonconvex Optimization with Time-Varying Constraints</title>
      <link>https://arxiv.org/abs/2505.08592</link>
      <description>arXiv:2505.08592v3 Announce Type: replace 
Abstract: This paper considers distributed online nonconvex optimization with time-varying inequality constraints over a network of agents, where the nonconvex local loss and convex local constraint functions can vary arbitrarily across iterations. For a time-varying directed graph, we propose two distributed bandit online primal--dual algorithm with compressed communication to efficiently utilize communication resources in the one-point and two-point bandit feedback settings, respectively. To measure the performance of the proposed algorithms, we use a network regret metric grounded in the first-order optimality condition associated with the variational inequality. We show that the compressed algorithms establish sublinear network regret and cumulative constraint violation bounds. Moreover, the network cumulative constraint violation bounds are reduced under Slater's condition. Finally, a simulation example is presented to validate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08592v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunpeng Zhang, Lei Xu, Xinlei Yi, Guanghui Wen, Ming Cao, Karl H. Johansson, Tianyou Chai, Tao Yang</dc:creator>
    </item>
    <item>
      <title>Sample complexity of optimal transport barycenters with discrete support</title>
      <link>https://arxiv.org/abs/2505.21274</link>
      <description>arXiv:2505.21274v3 Announce Type: replace 
Abstract: Computational implementation of optimal transport barycenters for a set of target probability measures requires a form of approximation, a widespread solution being empirical approximation of measures. We provide an $O(\sqrt{N/n})$ statistical generalization bounds for the empirical sparse optimal transport barycenters problem, where $N$ is the maximum cardinality of the barycenter (sparse support) and $n$ is the sample size of the target measures empirical approximation. Our analysis includes various optimal transport divergences including Wasserstein, Sinkhorn and Sliced-Wasserstein. We discuss the application of our result to specific settings including K-means, constrained K-means, free and fixed support Wasserstein barycenters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21274v3</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>L\'eo Portales, Edouard Pauwels, Elsa Cazelles</dc:creator>
    </item>
    <item>
      <title>Deep Equilibrium models for Poisson Imaging Inverse problems via Mirror Descent</title>
      <link>https://arxiv.org/abs/2507.11461</link>
      <description>arXiv:2507.11461v2 Announce Type: replace 
Abstract: Deep Equilibrium Models (DEQs) are implicit neural networks with fixed points, which have recently gained attention for learning image regularization functionals, particularly in settings involving Gaussian fidelities, where assumptions on the forward operator ensure contractiveness of standard (proximal) Gradient Descent operators. In this work, we extend the application of DEQs to Poisson inverse problems, where the data fidelity term is more appropriately modeled by the Kullback--Leibler divergence. To this end, we introduce a novel DEQ formulation based on Mirror Descent defined in terms of a tailored non-Euclidean geometry that naturally adapts with the structure of the data term. This enables the learning of neural regularizers within a principled training framework. We derive sufficient conditions and establish refined convergence results based on the Kurdyka--Lojasiewicz framework for subanalytic functions with non-closed domains to guarantee the convergence of the learned reconstruction scheme and propose computational strategies that enable both efficient training and parameter-free inference. Numerical experiments show that our method outperforms traditional model-based approaches and it is comparable to the performance of Bregman Plug-and-Play methods, while mitigating their typical drawbacks, such as time-consuming tuning of hyper-parameters. The code is publicly available at https://github.com/christiandaniele/DEQ-MD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11461v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Daniele, Silvia Villa, Samuel Vaiter, Luca Calatroni</dc:creator>
    </item>
    <item>
      <title>On the Time Derivative of the KL Divergence for a Generalized Langevin Annealing Scheme</title>
      <link>https://arxiv.org/abs/2511.11956</link>
      <description>arXiv:2511.11956v2 Announce Type: replace 
Abstract: Consider the Langevin diffusion process $\mathrm{d} X_t = \nabla \log p_t(X_t) + \sqrt{2}\mathrm{d} W_t$ guided by the time-dependent probability density $p_t(x)$. Let $q_t$ be the density of $X_t$. Recently, in order to analyze convergence in the Kullback-Leibler divergence, the time derivative of $t\mapsto \mathrm{KL}(q_t|p_t)$ has been used in several works without investigating in detail when such a derivative exists. In this short manuscript we provide a rigorous derivation of the quantity $\frac{\mathrm{d}}{\mathrm{d} t}\mathrm{KL}(q_t|p_t)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11956v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Habring</dc:creator>
    </item>
    <item>
      <title>A New Perspective on Double-S Curve Motions of Higher Order and Optimal Motion Planning</title>
      <link>https://arxiv.org/abs/2511.12615</link>
      <description>arXiv:2511.12615v2 Announce Type: replace 
Abstract: This paper presents and proves an equation for the time horizon of symmetric trajectories with zero boundary conditions and bounded derivatives of arbitrary order. This equation holds regardless of the number of phases comprising the associated motion. This avoids case distinctions in calculations. Application examples of motions with minimum time, minimum velocity, and minimum acceleration are discussed. Furthermore, an algorithm is derived that reduces the time minimization problem to solving a system of equations. This algorithm avoids nested case distinctions and complex optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12615v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rico Z\"ollner</dc:creator>
    </item>
    <item>
      <title>Infinite-Horizon Optimal Control of Jump-Diffusion Models for Pollution-Dependent Disasters</title>
      <link>https://arxiv.org/abs/2511.13568</link>
      <description>arXiv:2511.13568v2 Announce Type: replace 
Abstract: The paper develops a unified framework for stochastic growth models with environmental risk, in which rare but catastrophic shocks interact with capital accumulation and pollution. The analysis begins with a Poisson process formulation, leading to a Hamilton-Jacobi-Bellman (HJB) equation with jump terms that admits closed-form candidate solutions and yields a composite state variable capturing exposure to rare shocks. The framework is then extended by endogenizing disaster intensity via a nonhomogeneous Poisson process, showing how environmental degradation amplifies macroeconomic risk and strengthens incentives for abatement. A further extension introduces pollution diffusion alongside state-dependent jump intensity, yielding a tractable jump-diffusion HJB that decomposes naturally into capital and pollution components under power-type value functions. Finally, a formulation in terms of Poisson random measures unifies the dynamics, makes arrivals and compensators explicit, and accommodates state-dependent magnitudes. Together, these results establish rigorous verification theorems and viscosity-solution characterizations for the associated integro-differential HJB equations, highlight how vulnerability emerges endogenously from the joint evolution of capital and pollution, and show that the prospect of rare, state-dependent disasters fundamentally reshapes optimal intertemporal trade-offs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13568v2</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daria Sakhanda, Joshu\'e Hel\'i Ricalde-Guerrero</dc:creator>
    </item>
    <item>
      <title>Achieving Instance-dependent Sample Complexity for Constrained Markov Decision Process</title>
      <link>https://arxiv.org/abs/2402.16324</link>
      <description>arXiv:2402.16324v4 Announce Type: replace-cross 
Abstract: We consider the reinforcement learning problem for the constrained Markov decision process (CMDP), which plays a central role in satisfying safety or resource constraints in sequential learning and decision-making. In this problem, we are given finite resources and a MDP with unknown transition probabilities. At each stage, we take an action, collecting a reward and consuming some resources, all assumed to be unknown and need to be learned over time. In this work, we take the first step towards deriving optimal problem-dependent guarantees for the CMDP problems. We derive a logarithmic regret bound, which translates into a $O(\frac{1}{\Delta\cdot\epsilon}\cdot\log^2(1/\epsilon))$ sample complexity bound, with $\Delta$ being a problem-dependent parameter, yet independent of $\epsilon$. Our sample complexity bound improves upon the state-of-art $O(1/\epsilon^2)$ sample complexity for CMDP problems established in the previous literature, in terms of the dependency on $\epsilon$. To achieve this advance, we develop a new framework for analyzing CMDP problems. To be specific, our algorithm operates in the primal space and we resolve the primal LP for the CMDP problem at each period in an online manner, with adaptive remaining resource capacities. The key elements of our algorithm are: i) a characterization of the instance hardness via LP basis, ii) an eliminating procedure that identifies one optimal basis of the primal LP, and; iii) a resolving procedure that is adaptive to the remaining resources and sticks to the characterized optimal basis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16324v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiashuo Jiang, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Sample-Efficient Quantum State Tomography for Structured Quantum States in One Dimension</title>
      <link>https://arxiv.org/abs/2410.02583</link>
      <description>arXiv:2410.02583v4 Announce Type: replace-cross 
Abstract: While quantum state tomography (QST) remains the gold standard for benchmarking and verifying quantum devices, it requires an exponentially large number of measurements and classical computational resources for generic quantum many-body systems, making it impractical even for intermediate-size quantum devices. Fortunately, many physical quantum states often exhibit certain low-dimensional structures that enable the development of efficient QST. A notable example is the class of states represented by matrix product operators (MPOs) with a finite matrix/bond dimension, which include most physical states in one dimension and where the number of independent parameters describing the states only grows linearly with the number of qubits. Whether a sample efficient quantum state tomography protocol, where the number of required state copies scales only linearly as the number of parameters describing the state, exists for a generic MPO state still remains an important open question.
  In this paper, we answer this fundamental question affirmatively by using a class of informationally complete positive operator-valued measures (IC-POVMs) -- including symmetric IC-POVMs (SIC-POVMs) and spherical $t$-designs -- focusing on sample complexity while not accounting for the implementation complexity of the measurement settings. For SIC-POVMs and (approximate) spherical 2-designs, we show that the number of state copies to guarantee bounded recovery error of an MPO state with a constrained least-squares estimator depends on the probability distribution of the MPO under the POVM but scales only linearly with $n$ when the distribution is approximately uniform. For spherical $t$-designs with $t\geq 3$, we prove that only a number of state copies proportional to the number of independent parameters in the MPO is sufficient for a guaranteed recovery of any state represented by an MPO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02583v4</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Qin, Casey Jameson, Alireza Goldar, Michael B. Wakin, Zhexuan Gong, Zhihui Zhu</dc:creator>
    </item>
    <item>
      <title>Gradient descent inference in empirical risk minimization</title>
      <link>https://arxiv.org/abs/2412.09498</link>
      <description>arXiv:2412.09498v3 Announce Type: replace-cross 
Abstract: Gradient descent is one of the most widely used iterative algorithms in modern statistical learning. However, its precise algorithmic dynamics in high-dimensional settings remain only partially understood, which has limited its broader potential for statistical inference applications.
  This paper provides a precise, non-asymptotic joint distributional characterization of gradient descent iterates and their debiased statistics in a broad class of empirical risk minimization problems, in the so-called mean-field regime where the sample size is proportional to the signal dimension. Our non-asymptotic state evolution theory holds for both general non-convex loss functions and non-Gaussian data, and reveals the central role of two Onsager correction matrices that precisely characterize the non-trivial dependence among all gradient descent iterates in the mean-field regime.
  Leveraging the joint state evolution characterization, we show that the gradient descent iterate retrieves approximate normality after a debiasing correction via a linear combination of all past iterates, where the debiasing coefficients can be estimated by the proposed gradient descent inference algorithm. This leads to a new algorithmic statistical inference framework based on debiased gradient descent, which (i) applies to a broad class of models with both convex and non-convex losses, (ii) remains valid at each iteration without requiring algorithmic convergence, and (iii) exhibits a certain robustness to possible model misspecification. As a by-product, our framework also provides algorithmic estimates of the generalization error at each iteration. As canonical examples, we demonstrate our theory and inference methods in the single-index regression model and a generalized logistic regression model, where the natural loss functions may exhibit arbitrarily non-convex landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.09498v3</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiyang Han, Xiaocong Xu</dc:creator>
    </item>
    <item>
      <title>Concentration inequalities for semidefinite least squares based on data</title>
      <link>https://arxiv.org/abs/2509.13166</link>
      <description>arXiv:2509.13166v2 Announce Type: replace-cross 
Abstract: We study data-driven least squares (LS) problems with semidefinite (SD) constraints and derive finite-sample guarantees on the spectrum of their optimal solutions when these constraints are relaxed. In particular, we provide a high confidence bound allowing one to solve a simpler program in place of the full SDLS problem, while ensuring that the eigenvalues of the resulting solution are $\varepsilon$-close of those enforced by the SD constraints. The developed certificate, which consistently shrinks as the number of data increases, turns out to be easy-to-compute, distribution-free, and only requires independent and identically distributed samples. Moreover, when the SDLS is used to learn an unknown quadratic function, we establish bounds on the error between a gradient descent iterate minimizing the surrogate cost obtained with no SD constraints and the true minimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13166v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Fabiani, Andrea Simonetto</dc:creator>
    </item>
    <item>
      <title>Zeroes and Extrema of Functions via Random Measures</title>
      <link>https://arxiv.org/abs/2511.10293</link>
      <description>arXiv:2511.10293v2 Announce Type: replace-cross 
Abstract: We present methods that provide all zeroes and extrema of a function that do not require differentiation. Using point process theory, we are able to describe the locations of zeroes or maxima, their number, as well as their distribution over a given window of observation. The algorithms in order to accomplish the theoretical development are also provided, and they are exemplified using many illustrative examples, for real and complex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10293v2</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Athanasios Christou Micheas</dc:creator>
    </item>
    <item>
      <title>On topological properties of closed attractors</title>
      <link>https://arxiv.org/abs/2511.10429</link>
      <description>arXiv:2511.10429v2 Announce Type: replace-cross 
Abstract: The notion of an attractor has various definitions in the theory of dynamical systems. Under compactness assumptions, several of those definitions coincide and the theory is rather complete. However, without compactness, the picture becomes blurry. To improve our understanding, we characterize in this work when a closed, not necessarily compact, asymptotically stable attractor on a locally compact metric space is homotopy equivalent to its domain of attraction. This enables a further structural study of the corresponding feedback stabilization problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10429v2</guid>
      <category>math.DS</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter Jongeneel</dc:creator>
    </item>
    <item>
      <title>Dynamical Sampling: A Survey</title>
      <link>https://arxiv.org/abs/2511.10769</link>
      <description>arXiv:2511.10769v2 Announce Type: replace-cross 
Abstract: Dynamical sampling refers to a class of problems in which space-time samples are taken from a signal evolving under an underlying dynamical system. The goal is to use these samples to recover relevant information about the system, such as the initial state, the evolution operator, or the sources and sinks driving the dynamics. These problems are tightly connected to frame theory, operator theory, functional analysis, and other foundational areas of mathematics; they also give rise to new theoretical questions and have applications across engineering and the sciences. This survey provides an overview of the theoretical underpinnings of dynamical sampling, summarizes recent results, and outlines directions for future work, including open problems and conjectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10769v2</guid>
      <category>math.FA</category>
      <category>math.DS</category>
      <category>math.OA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akram Aldroubi, Carlos Cabrelli, Ilya Krishtal, Ursula Molter</dc:creator>
    </item>
  </channel>
</rss>
