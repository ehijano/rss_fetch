<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 01:39:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Accelerating Graph Neural Networks with a Novel Matrix Compression Format</title>
      <link>https://arxiv.org/abs/2409.02208</link>
      <description>arXiv:2409.02208v1 Announce Type: new 
Abstract: The inference and training stages of Graph Neural Networks (GNNs) are often dominated by the time required to compute a long sequence of matrix multiplications between the sparse graph adjacency matrix and its embedding. To accelerate these stages, we first propose the Compressed Binary Matrix (CBM) storage format to succinctly represent the binary adjacency matrix of an unweighted graph. Then, we show how to generalize this representation to normalized adjacency matrices of unweighted graphs which arise in the context of GNNs. Finally, we develop efficient matrix multiplication kernels based on this compressed representation. The matrix multiplication kernels proposed in this work never require more scalar operations than classic sparse matrix multiplication algorithms. Experimental evaluation shows that the matrix multiplication strategies proposed outperform the current state-of-the-art implementations provided by Intel MKL, achieving speedups close to 5$\times$. Furthermore, our optimized matrix-multiplication strategies accelerated the inference time of a GNN by up to $3\times$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02208v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao N. F. Alves, Samir Moustafa, Siegfried Benkner, Alexandre P. Francisco, Wilfried N. Gansterer, Lu\'is M. S. Russo</dc:creator>
    </item>
    <item>
      <title>Hadamard Row-Wise Generation Algorithm</title>
      <link>https://arxiv.org/abs/2409.02406</link>
      <description>arXiv:2409.02406v1 Announce Type: new 
Abstract: In this paper, we introduce an efficient algorithm for generating specific Hadamard rows, addressing the memory demands of pre-computing the entire matrix. Leveraging Sylvester's recursive construction, our method generates the required $i$-th row on demand, significantly reducing computational resources. The algorithm uses the Kronecker product to construct the desired row from the binary representation of the index, without creating the full matrix. This approach is particularly useful for single-pixel imaging systems that need only one row at a time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02406v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.CV</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brayan Monroy, Jorge Bacca</dc:creator>
    </item>
    <item>
      <title>An Effective Tag Assignment Approach for Billboard Advertisement</title>
      <link>https://arxiv.org/abs/2409.02455</link>
      <description>arXiv:2409.02455v1 Announce Type: new 
Abstract: Billboard Advertisement has gained popularity due to its significant outrage in return on investment. To make this advertisement approach more effective, the relevant information about the product needs to be reached to the relevant set of people. This can be achieved if the relevant set of tags can be mapped to the correct slots. Formally, we call this problem the Tag Assignment Problem in Billboard Advertisement. Given trajectory, billboard database, and a set of selected billboard slots and tags, this problem asks to output a mapping of selected tags to the selected slots so that the influence is maximized. We model this as a variant of traditional bipartite matching called One-To-Many Bipartite Matching (OMBM). Unlike traditional bipartite matching, a tag can be assigned to only one slot; in the OMBM, a tag can be assigned to multiple slots while the vice versa can not happen. We propose an iterative solution approach that incrementally allocates the tags to the slots. The proposed methodology has been explained with an illustrated example. A complexity analysis of the proposed solution approach has also been conducted. The experimental results on real-world trajectory and billboard datasets prove our claim on the effectiveness and efficiency of the proposed solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02455v1</guid>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Harishchandra Kumar, Suman Banerjee, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>V-Words, Lyndon Words and Galois Words</title>
      <link>https://arxiv.org/abs/2409.02757</link>
      <description>arXiv:2409.02757v1 Announce Type: new 
Abstract: We say that a family $\mathcal{W}$ of strings over $\Sigma^+$ forms a Unique Maximal Factorization Family (UMFF) if and only if every $w \in \mathcal{W}$ has a unique maximal factorization. Further, an UMFF $\mathcal{W}$ is called a circ-UMFF whenever it contains exactly one rotation of every primitive string $x \in \Sigma^+$. $V$-order is a non-lexicographical total ordering on strings that determines a circ-UMFF. In this paper we propose a generalization of circ-UMFF called the substring circ-UMFF and extend combinatorial research on $V$-order by investigating connections to Lyndon words. Then we extend these concepts to any total order. Applications of this research arise in efficient text indexing, compression, and search problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02757v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jacqueline W. Daykin, Neerja Mhaskar, W. F. Smyth</dc:creator>
    </item>
    <item>
      <title>Key Compression Limits for $k$-Minimum Value Sketches</title>
      <link>https://arxiv.org/abs/2409.02852</link>
      <description>arXiv:2409.02852v1 Announce Type: new 
Abstract: The $k$-Minimum Values (\kmv) data sketch algorithm stores the $k$ least hash keys generated by hashing the items in a dataset. We show that compression based on ordering the keys and encoding successive differences can offer $O(\log n)$ bits per key in expected storage savings, where $n$ is the number of unique values in the data set. We also show that $O(\log n)$ expected bits saved per key is optimal for any form of compression for the $k$ least of $n$ random values -- that the encoding method is near-optimal among all methods to encode a \kmv sketch. We present a practical method to perform that compression, show that it is computationally efficient, and demonstrate that its average savings in practice is within about five percent of the theoretical minimum based on entropy. We verify that our method outperforms off-the-shelf compression methods, and we demonstrate that it is practical, using real and synthetic data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02852v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charlie Dickens, Eric Bax, Alexander Saydakov</dc:creator>
    </item>
    <item>
      <title>Revisiting ILP Models for Exact Crossing Minimization in Storyline Drawings</title>
      <link>https://arxiv.org/abs/2409.02858</link>
      <description>arXiv:2409.02858v1 Announce Type: new 
Abstract: Storyline drawings are a popular visualization of interactions of a set of characters over time, e.g., to show participants of scenes in a book or movie. Characters are represented as $x$-monotone curves that converge vertically for interactions and diverge otherwise. Combinatorially, the task of computing storyline drawings reduces to finding a sequence of permutations of the character curves for the different time points, with the primary objective being crossing minimization of the induced character trajectories. In this paper, we revisit exact integer linear programming (ILP) approaches for this NP-hard problem. By enriching previous formulations with additional problem-specific insights and new heuristics, we obtain exact solutions for an extended new benchmark set of larger and more complex instances than had been used before. Our experiments show that our enriched formulations lead to better performing algorithms when compared to state-of-the-art modelling techniques. In particular, our best algorithms are on average 2.6-3.2 times faster than the state-of-the-art and succeed in solving complex instances that could not be solved before within the given time limit. Further, we show in an ablation study that our enrichment components contribute considerably to the performance of the new ILP formulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02858v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Dobler, Michael J\"unger, Paul J. J\"unger, Julian Meffert, Petra Mutzel, Martin N\"ollenburg</dc:creator>
    </item>
    <item>
      <title>Directed Hypercube Routing, a Generalized Lehman-Ron Theorem, and Monotonicity Testing</title>
      <link>https://arxiv.org/abs/2409.02206</link>
      <description>arXiv:2409.02206v1 Announce Type: cross 
Abstract: Motivated by applications to monotonicity testing, Lehman and Ron (JCTA, 2001) proved the existence of a collection of vertex disjoint paths between comparable sub-level sets in the directed hypercube. The main technical contribution of this paper is a new proof method that yields a generalization to their theorem: we prove the existence of two edge-disjoint collections of vertex disjoint paths. Our main conceptual contribution are conjectures on directed hypercube flows with simultaneous vertex and edge capacities of which our generalized Lehman-Ron theorem is a special case. We show that these conjectures imply directed isoperimetric theorems, and in particular, the robust directed Talagrand inequality due to Khot, Minzer, and Safra (SIAM J. on Comp, 2018). These isoperimetric inequalities, that relate the directed surface area (of a set in the hypercube) to its distance to monotonicity, have been crucial in obtaining the best monotonicity testers for Boolean functions. We believe our conjectures pave the way towards combinatorial proofs of these directed isoperimetry theorems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02206v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deeparnab Chakrabarty, C. Seshadhri</dc:creator>
    </item>
    <item>
      <title>Optimal L-Systems for Stochastic L-system Inference Problems</title>
      <link>https://arxiv.org/abs/2409.02259</link>
      <description>arXiv:2409.02259v1 Announce Type: cross 
Abstract: This paper presents two novel theorems that address two open problems in stochastic Lindenmayer-system (L-system) inference, specifically focusing on the construction of an optimal stochastic L-system capable of generating a given sequence of strings. The first theorem delineates a method for crafting a stochastic L-system that maximizes the likelihood of producing a given sequence of words through a singular derivation. Furthermore, the second theorem determines the stochastic L-systems with the highest probability of producing a given sequence of words with multiple possible derivations. From these, we introduce an algorithm to infer an optimal stochastic L-system from a given sequence. This algorithm incorporates sophisticated optimization techniques, such as interior point methods, ensuring production of a stochastically optimal stochastic L-system suitable for generating the given sequence. This allows for the use of using stochastic L-systems as model for machine learning using only positive data for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02259v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.DS</category>
      <category>cs.FL</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Lotfi, Ian McQuillan</dc:creator>
    </item>
    <item>
      <title>iRangeGraph: Improvising Range-dedicated Graphs for Range-filtering Nearest Neighbor Search</title>
      <link>https://arxiv.org/abs/2409.02571</link>
      <description>arXiv:2409.02571v1 Announce Type: cross 
Abstract: Range-filtering approximate nearest neighbor (RFANN) search is attracting increasing attention in academia and industry. Given a set of data objects, each being a pair of a high-dimensional vector and a numeric value, an RFANN query with a vector and a numeric range as parameters returns the data object whose numeric value is in the query range and whose vector is nearest to the query vector. To process this query, a recent study proposes to build $O(n^2)$ dedicated graph-based indexes for all possible query ranges to enable efficient processing on a database of $n$ objects. As storing all these indexes is prohibitively expensive, the study constructs compressed indexes instead, which reduces the memory consumption considerably. However, this incurs suboptimal performance because the compression is lossy. In this study, instead of materializing a compressed index for every possible query range in preparation for querying, we materialize graph-based indexes, called elemental graphs, for a moderate number of ranges. We then provide an effective and efficient algorithm that during querying can construct an index for any query range using the elemental graphs. We prove that the time needed to construct such an index is low. We also cover an experimental study on real-world datasets that provides evidence that the materialized elemental graphs only consume moderate space and that the proposed method is capable of superior and stable query performance across different query workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02571v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuexuan Xu, Jianyang Gao, Yutong Gou, Cheng Long, Christian S. Jensen</dc:creator>
    </item>
    <item>
      <title>The Parameterized Complexity of Extending Stack Layouts</title>
      <link>https://arxiv.org/abs/2409.02833</link>
      <description>arXiv:2409.02833v1 Announce Type: cross 
Abstract: An $\ell$-page stack layout (also known as an $\ell$-page book embedding) of a graph is a linear order of the vertex set together with a partition of the edge set into $\ell$ stacks (or pages), such that the endpoints of no two edges on the same stack alternate. We study the problem of extending a given partial $\ell$-page stack layout into a complete one, which can be seen as a natural generalization of the classical NP-hard problem of computing a stack layout of an input graph from scratch. Given the inherent intractability of the problem, we focus on identifying tractable fragments through the refined lens of parameterized complexity analysis. Our results paint a detailed and surprisingly rich complexity-theoretic landscape of the problem which includes the identification of paraNP-hard, W[1]-hard and XP-tractable, as well as fixed-parameter tractable fragments of stack layout extension via a natural sequence of parameterizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02833v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Depian, Simon D. Fink, Robert Ganian, Martin N\"ollenburg</dc:creator>
    </item>
    <item>
      <title>Beyond matroids: Secretary Problem and Prophet Inequality with general constraints</title>
      <link>https://arxiv.org/abs/1604.00357</link>
      <description>arXiv:1604.00357v2 Announce Type: replace 
Abstract: We study generalizations of the "Prophet Inequality" and "Secretary Problem", where the algorithm is restricted to an arbitrary downward-closed set system. For {0,1}-values, we give O(log n)-competitive algorithms for both problems. This is close to the \Omega(log n / loglog n) lower bound due to Babaioff, Immorlica, and Kleinberg. For general values, our results translate to O(log n log r)-competitive algorithms, where r is the cardinality of the largest feasible set. This resolves (up to the O(log r loglog n) factors) an open question posed to us by Bobby Kleinberg.</description>
      <guid isPermaLink="false">oai:arXiv.org:1604.00357v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aviad Rubinstein</dc:creator>
    </item>
    <item>
      <title>Fast Practical Compression of Deterministic Finite Automata</title>
      <link>https://arxiv.org/abs/2306.12771</link>
      <description>arXiv:2306.12771v3 Announce Type: replace 
Abstract: We revisit the popular \emph{delayed deterministic finite automaton} (\ddfa{}) compression algorithm introduced by Kumar~et~al.~[SIGCOMM 2006] for compressing deterministic finite automata (DFAs) used in intrusion detection systems. This compression scheme exploits similarities in the outgoing sets of transitions among states to achieve strong compression while maintaining high throughput for matching.
  The \ddfa{} algorithm and later variants of it, unfortunately, require at least quadratic compression time since they compare all pairs of states to compute an optimal compression. This is too slow and, in some cases, even infeasible for collections of regular expression in modern intrusion detection systems that produce DFAs of millions of states.
  Our main result is a simple, general framework for constructing \ddfa{} based on locality-sensitive hashing that constructs an approximation of the optimal \ddfa{} in near-linear time. We apply our approach to the original \ddfa{} compression algorithm and two important variants, and we experimentally evaluate our algorithms on DFAs from widely used modern intrusion detection systems. Overall, our new algorithms compress up to an order of magnitude faster than existing solutions with either no or little loss of compression size. Consequently, our algorithms are significantly more scalable and can handle larger collections of regular expressions than previous solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.12771v3</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Bille, Inge Li G{\o}rtz, Max Rish{\o}j Pedersen</dc:creator>
    </item>
    <item>
      <title>Parameterized Algorithms for Balanced Cluster Edge Modification Problems</title>
      <link>https://arxiv.org/abs/2403.03830</link>
      <description>arXiv:2403.03830v2 Announce Type: replace 
Abstract: We study {\sc Cluster Edge Modification} problems with constraints on the size of the clusters. A graph $G$ is a cluster graph if every connected component of $G$ is a clique. In a typical {\sc Cluster Edge Modification} problem such as the widely studied {\sc Cluster Editing}, we are given a graph $G$ and a non-negative integer $k$ as input, and we have to decide if we can turn $G$ into a cluster graph by way of at most $k$ edge modifications -- that is, by adding or deleting edges. In this paper, we study the parameterized complexity of such problems, but with an additional constraint: The size difference between any two connected components of the resulting cluster graph should not exceed a given threshold. Depending on which modifications are permissible -- only adding edges, only deleting edges, both adding and deleting edges -- we have three different computational problems. We show that all three problems, when parameterized by $k$, admit single-exponential time FPT algorithms and polynomial kernels. Our problems may be thought of as the size-constrained or balanced counterparts of the typical {\sc Cluster Edge Modification} problems, similar to the well-studied size-constrained or balanced counterparts of other clustering problems such as {\sc $k$-Means Clustering}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03830v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayakrishnan Madathil, Kitty Meeks</dc:creator>
    </item>
    <item>
      <title>Algorithms for Generating Small Random Samples</title>
      <link>https://arxiv.org/abs/2405.12371</link>
      <description>arXiv:2405.12371v3 Announce Type: replace 
Abstract: We present algorithms for generating small random samples without replacement. We consider two cases. We present an algorithm for sampling a pair of distinct integers, and an algorithm for sampling a triple of distinct integers. The worst-case runtime of both algorithms is constant, while the worst-case runtimes of common algorithms for the general case of sampling $k$ elements from a set of $n$ increase with $n$. Java implementations of both algorithms are included in the open source library $\rho\mu$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12371v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.PR</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent A. Cicirello</dc:creator>
    </item>
    <item>
      <title>Locally Private Histograms in All Privacy Regimes</title>
      <link>https://arxiv.org/abs/2408.04888</link>
      <description>arXiv:2408.04888v2 Announce Type: replace 
Abstract: Frequency estimation, a.k.a. histograms, is a workhorse of data analysis, and as such has been thoroughly studied under differentially privacy. In particular, computing histograms in the \emph{local} model of privacy has been the focus of a fruitful recent line of work, and various algorithms have been proposed, achieving the order-optimal $\ell_\infty$ error in the high-privacy (small $\varepsilon$) regime while balancing other considerations such as time- and communication-efficiency. However, to the best of our knowledge, the picture is much less clear when it comes to the medium- or low-privacy regime (large $\varepsilon$), despite its increased relevance in practice. In this paper, we investigate locally private histograms, and the very related distribution learning task, in this medium-to-low privacy regime, and establish near-tight (and somewhat unexpected) bounds on the $\ell_\infty$ error achievable. As a direct corollary of our results, we obtain a protocol for histograms in the \emph{shuffle} model of differential privacy, with accuracy matching previous algorithms but significantly better message and communication complexity.
  Our theoretical findings emerge from a novel analysis, which appears to improve bounds across the board for the locally private histogram problem. We back our theoretical findings by an empirical comparison of existing algorithms in all privacy regimes, to assess their typical performance and behaviour beyond the worst-case setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04888v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.DM</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement L. Canonne, Abigail Gentle</dc:creator>
    </item>
    <item>
      <title>ExpoSort: Breaking the quasi-polynomial-time barrier for reluctant sorting</title>
      <link>https://arxiv.org/abs/2409.00794</link>
      <description>arXiv:2409.00794v2 Announce Type: replace 
Abstract: We introduce the algorithm ExpoSort, a groundbreaking method that sorts an array of $n$ numbers in a spectacularly inefficient $\Theta(2^n)$ time. ExpoSort proudly claims the title of the first reluctant algorithm to decisively surpass the quasi-polynomial running time $\Omega(n^{\log n/(2+\varepsilon)})$ of the notoriously sluggish SlowSort algorithm by Broder and Stolfi [ACM SIGACT News, 1984]. In the ongoing quest for the slowest possible sort, ExpoSort redefines what it means to take one's time.
  Remarkably, ExpoSort achieves this feat with one of the simplest pseudocodes among all known sorting algorithms. However, a slight modification -- merely moving one recursive call inside an if statement -- transforms ExpoSort into an astonishingly well-camouflaged variant of the classic InsertionSort with best- and worst-case running times of $\Theta(n)$ and $\Theta(n^3)$, respectively. This dual nature of ExpoSort serves as a reminder of the utmost care required when crafting pessimal algorithms, where a slight lapse in judgment could result in accidentally producing an embarrassingly practical algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00794v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikkel Abrahamsen</dc:creator>
    </item>
    <item>
      <title>Quantum Backtracking in Qrisp Applied to Sudoku Problems</title>
      <link>https://arxiv.org/abs/2402.10060</link>
      <description>arXiv:2402.10060v3 Announce Type: replace-cross 
Abstract: The quantum backtracking algorithm proposed by Ashley Montanaro raised considerable interest, as it provides a quantum speed-up for a large class of classical optimization algorithms. It does not suffer from Barren-Plateaus and transfers well into the fault-tolerant era, as it requires only a limited number of arbitrary angle gates. Despite its potential, the algorithm has seen limited implementation efforts, presumably due to its abstract formulation. In this work, we provide a detailed instruction on implementing the quantum step operator for arbitrary backtracking instances. For a single controlled diffuser of a binary backtracking tree with depth n, our implementation requires only $6n+14$ CX gates. We detail the process of constructing accept and reject oracles for Sudoku problems using our interface to quantum backtracking. The presented code is written using Qrisp, a high-level quantum programming language, making it executable on most current physical backends and simulators. Subsequently, we perform several simulator based experiments and demonstrate solving 4x4 Sudoku instances with up to 9 empty fields. This is, to the best of our knowledge, the first instance of a compilable implementation of this generality, marking a significant and exciting step forward in quantum software engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10060v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raphael Seidel, Ren\'e Zander, Matic Petri\v{c}, Niklas Steinmann, David Q. Liu, Nikolay Tcholtchev, Manfred Hauswirth</dc:creator>
    </item>
    <item>
      <title>Potential Hessian Ascent: The Sherrington-Kirkpatrick Model</title>
      <link>https://arxiv.org/abs/2408.02360</link>
      <description>arXiv:2408.02360v2 Announce Type: replace-cross 
Abstract: We present the first iterative spectral algorithm to find near-optimal solutions for a random quadratic objective over the discrete hypercube, resolving a conjecture of Subag [Subag, Communications on Pure and Applied Mathematics, 74(5), 2021].
  The algorithm is a randomized Hessian ascent in the solid cube, with the objective modified by subtracting an instance-independent potential function [Chen et al., Communications on Pure and Applied Mathematics, 76(7), 2023].
  Using tools from free probability theory, we construct an approximate projector into the top eigenspaces of the Hessian, which serves as the covariance matrix for the random increments. With high probability, the iterates' empirical distribution approximates the solution to the primal version of the Auffinger-Chen SDE [Auffinger et al., Communications in Mathematical Physics, 335, 2015]. The per-iterate change in the modified objective is bounded via a Taylor expansion, where the derivatives are controlled through Gaussian concentration bounds and smoothness properties of a semiconcave regularization of the Fenchel-Legendre dual to the Parisi PDE.
  These results lay the groundwork for (possibly) demonstrating low-degree sum-of-squares certificates over high-entropy step distributions for a relaxed version of the Parisi formula [Open Question 1.8, arXiv:2401.14383].</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02360v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Jekel, Juspreet Singh Sandhu, Jonathan Shi</dc:creator>
    </item>
  </channel>
</rss>
