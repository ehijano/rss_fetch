<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Nov 2025 05:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Analysis of the TAIGA-HiSCORE Data Using the Latent Space of Autoencoders</title>
      <link>https://arxiv.org/abs/2511.09655</link>
      <description>arXiv:2511.09655v1 Announce Type: new 
Abstract: The aim of extensive air shower (EAS) analysis is to reconstruct the physical parameters of the primary particle that initiated the shower. The TAIGA experiment is a hybrid detector system that combines several imaging atmospheric Cherenkov telescopes (IACTs) and an array of non-imaging Cherenkov detectors (TAIGA-HiSCORE) for EAS detection. Because the signals recorded by different detector types differ in physical nature, the direct merging of data is unfeasible, which complicates multimodal analysis. Currently, to analyze data from the IACTs and TAIGA-HiSCORE, a set of auxiliary parameters specific to each detector type is calculated from the recorded signals. These parameters are chosen empirically, so there is no certainty that they retain all important information and are the best suited for the respective problems. We propose to use autoencoders (AE) for the analysis of TAIGA experimental data and replace the conventionally used auxiliary parameters with the parameters of the AE latent space. The advantage of the AE latent space parameters is that they preserve essential physics from experimental data without prior assumptions. This approach also holds potential for enabling seamless integration of heterogeneous IACT and HiSCORE data through a joint latent space. To reconstruct the parameters of the primary particle of the EAS from the latent space of the AE, a separate artificial neural network is used. In this paper, the proposed approach is used to reconstruct the energy of the EAS primary particles based on Monte Carlo simulation data for TAIGA-HiSCORE. The dependence of the energy determination accuracy on the dimensionality of the latent space is analyzed, and these results are also compared with the results obtained by the conventional technique. It is shown that when using the AE latent space, the energy of the primary particle is reconstructed with satisfactory accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09655v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yu. Yu. Dubenskaya, S. P. Polyakov, A. P. Kryukov, A. P. Demichev, E. O. Gres, E. B. Postnikov, A. Yu. Razumov, P. A. Volchugov, D. P. Zhurov</dc:creator>
    </item>
    <item>
      <title>Analyzing Exoplanet Transits Observed with the WFC3/UVIS G280 Grism</title>
      <link>https://arxiv.org/abs/2511.09694</link>
      <description>arXiv:2511.09694v1 Announce Type: new 
Abstract: Here we describe a Jupyter notebook demonstrating methods for the reduction and analysis of exoplanet transit observations taken with the WFC3/UVIS G280 grism. Released on Space Telescope's hst_notebooks GitHub repository, this notebook presents an example workflow for processing time-series observations taken with the G280 grism - from the calibrated flat-fielded spectra to transit light curves ready for fitting. The specific routines presented in the notebook are explained here, and are meant to highlight data reduction steps that users will typically apply to extract transit light curves. The steps include background subtraction, spatial and temporal cosmic ray correction, spectral trace fitting, spectral extraction, and light curve generation. The end products of the routines in the Jupyter notebook are the raw broadband and spectroscopic light curves, which can be ingested into publicly available light curve fitting tools to extract planetary transmission spectra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09694v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Munazza K. Alam, Frederick Dauphin, Amanda Pagul</dc:creator>
    </item>
    <item>
      <title>Mock Observations for the CSST Mission: CPI-C -- Targets for High Contrast Imaging</title>
      <link>https://arxiv.org/abs/2511.09862</link>
      <description>arXiv:2511.09862v1 Announce Type: new 
Abstract: We introduce CPISM, a simulation program developed for the Cool Planet Imaging Coronagraph (CPI-C) on the China Space Station Telescope (CSST). CPISM supports high-contrast exoplanet imaging by simulating observational conditions and instrumental effects to optimize target selection and observation strategies. The modular design includes target modeling, imaging simulation, observational effects, detector response, and data product generation modules, enabling flexible and realistic synthetic observations. Validation through simulations of a bright star shows strong agreement with theoretical expectations, confirming the program's accuracy. CPISM's modular design allows flexibility, accommodating different stellar and planetary models, and can simulate instrumental noise, cosmic rays, and other observational effects. This tool aids in data processing, signal-to-noise ratio analysis, and high-contrast photometry, contributing to future exoplanet discovery and characterization efforts. The program's outputs will enhance observation planning and scientific return for the CPI-C mission, providing critical insights into exoplanetary systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09862v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi-Ming Zhu, Gang Zhao, Jiang-Pei Dou, Zhong-Hua Lv, Yi-Li Chen, Bo Ma, Zhao-Jun Yan, Jing Tang, Ran Li</dc:creator>
    </item>
    <item>
      <title>Topmetal-L: A Low Noise Charge-Sensitive Pixel Sensor for POLAR2/LPD</title>
      <link>https://arxiv.org/abs/2511.09863</link>
      <description>arXiv:2511.09863v1 Announce Type: new 
Abstract: POLAR-2 is a next-generation space astronomy platform led by China, with its core scientific objective focused on high-precision polarization measurements of gamma-ray bursts. As one of its key payloads, the Low-energy Polarization Detector (LPD) is designed to perform wide-field surveys to capture X-ray polarization information from gamma-ray bursts in the 2-10 keV energy range. This paper presents Topmetal-L, a dedicated charge-sensitive pixel sensor developed for the LPD prototype upgrade. Fabricated in a 130 nm CMOS process in 2024, the chip integrates a 356 $\times$ 512 pixel array with a pixel pitch of 45 $\mu$m. Each pixel incorporates a 26 $\times$ 26 $\mu$m^2 charge-collecting electrode window and is capable of simultaneously outputting both energy and position information of deposited charges. Topmetal-L has been systematically optimized for power consumption, noise performance, and readout efficiency. It exhibits an input dynamic range of 0-4 ke-, a typical charge-to-voltage conversion gain of 76.04 $\mu$V/e-, an average equivalent noise charge of approximately 22.8 e-, a sensitive area exceeding 3.6 cm^2, and a total power consumption of 720 mW per chip. To meet the requirements of large-area, high-frame-rate readout for gas-based polarization detectors, a sentinel-scanning readout scheme is proposed, reducing the full-frame readout time to 730 $\mu$s. A prototype Topmetal-L-based gas polarization detection system was evaluated across key energies: it exhibited a residual modulation of 0.26% $\pm$ 0.45% at 5.90 keV, a modulation factor of 66.67% $\pm$ 0.45% for a linearly polarized 8.0 keV source, and a counting rate saturated at 15 k counts/(cm^2$\cdot$s) when tested at 5.4 keV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09863v1</guid>
      <category>astro-ph.IM</category>
      <category>nucl-ex</category>
      <category>physics.ins-det</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Li-rong Xie, Shi-Qiang Zhou, Di-Fan Yi, Huan-Bo Feng, Zhu-Ke Feng, Dong Wang, Chao-song Gao, En-Wei Liang, Xiang-Ming Sun, Hong-Bang Liu</dc:creator>
    </item>
    <item>
      <title>fiDrizzle-MU: A Fast Iterative Drizzle with Multiplicative Updates</title>
      <link>https://arxiv.org/abs/2511.09881</link>
      <description>arXiv:2511.09881v1 Announce Type: new 
Abstract: We propose fiDrizzleMU, an algorithm for co-adding exposures via iterative multiplicative updates, replacing the additive correction framework. This method achieves superior anti-aliasing and noise reduction in stacked images. When applied to James Webb Space Telescope data, the fiDrizzleMU algorithm reconstructs a gravitational lensing candidate that was significantly blurred by the pipeline's resampling process. This enables the accurate recovery of faint and extended structures in high-resolution astronomical imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09881v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1088/1674-4527/ade351</arxiv:DOI>
      <dc:creator>Shen Zhang, Lei Wang, Huanyuan Shan, Ran Li, Xiaoyue Cao, Yunhao Gao</dc:creator>
    </item>
    <item>
      <title>Ginnungagap -- a massively parallel cosmological initial conditions generator</title>
      <link>https://arxiv.org/abs/2511.10353</link>
      <description>arXiv:2511.10353v1 Announce Type: new 
Abstract: Ginnungagap is a fully parallel (MPI+OpenMP) code designed to generate cosmological initial conditions for simulations involving very large numbers of particles. It operates in several modes, including the creation of initial conditions with either uniform or spatially varying resolution (for "zoom-in" simulations). The initial conditions can be fully random or derived by extending the resolution of existing ones while preserving the large-scale structures. Ginnungagap is open source and modular, consisting of a collection of independent tools that can be used for a variety of tasks. In this paper, we describe the main features of Ginnungagap and present test results for different types of simulations prepared with it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10353v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.CO</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergey Pilipenko, Gustavo Yepes, Stefan Gottl\"ober, Steffen Knollmann</dc:creator>
    </item>
    <item>
      <title>A scalable and accurate framework for self-calibrating null depth retrieval using neural posterior estimation</title>
      <link>https://arxiv.org/abs/2511.10455</link>
      <description>arXiv:2511.10455v1 Announce Type: new 
Abstract: Accurate null depth retrieval is critical in nulling interferometry. However, achieving accurate null depth calibration is challenging due to various noise sources, instrumental imperfections, and the complexity of real observational environments. These challenges necessitate advanced calibration techniques that can efficiently handle such uncertainties while maintaining a high accuracy. This paper aims to incorporate machine-learning techniques with a Bayesian inference to improve the accuracy and efficiency of null depth retrieval in nulling interferometry. Specifically, it explores the use of neural posterior estimation (NPE) to develop models that overcome the computational limitations of conventional methods, such as numerical self-calibration (NSC), providing a more robust solution for accurate null depth calibration. An NPE-based model was developed, with a simulator that incorporates real data to better represent specific conditions. The model was tested on both synthetic and observational data from the LBTI nuller for evaluation. The NPE model successfully demonstrated improved efficiency, achieving results comparable to current methods in use. It achieved a null depth retrieval accuracy down to a few $10^{-4}$ on real observational data, matching the performance of conventional approaches while offering significant computational advantages, reducing the data retrieval time to one-quarter of the time required by self-calibration methods. The NPE model presents a practical and scalable solution for null depth calibration in nulling interferometry, offering substantial improvements in efficiency over existing methods with a better precision and application to other interferometric techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10455v1</guid>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baoyi Zeng, Marc-Antoine Martinod, Denis Defr\`ere</dc:creator>
    </item>
    <item>
      <title>statmorph-lsst: Quantifying and correcting morphological biases in galaxy surveys</title>
      <link>https://arxiv.org/abs/2511.09644</link>
      <description>arXiv:2511.09644v1 Announce Type: cross 
Abstract: Quantitative morphology provides a key probe of galaxy evolution across cosmic time and environments. However, these metrics can be biased by changes in imaging quality - resolution and depth - either across the survey area or the sample. To prepare for the upcoming Rubin LSST data, we investigate this bias for all metrics measured by statmorph and single-component S\'ersic fitting with Galfit. We find that geometrical measurements (ellipticity, axis ratio, Petrosian radius, and effective radius) are fairly robust at most depths and resolutions. Light concentration measurements ($C$, Gini, $M_{20}$) systematically decrease with resolution, leading low-mass or high-redshift bulge-dominated sources to appear indistinguishable from disks. S\'ersic index $n$, while unbiased, suffers from a 20-40% uncertainty due to degeneracies in the S\'ersic fit. Disturbance measurements ($A$, $A_S$, $D$) depend on signal-to-noise and are thus affected by noise and surface-brightness dimming. We quantify this dependence for each parameter, offer empirical correction functions, and show that the evolution in $C$ observed in JWST galaxies can be explained purely by observational biases. We propose two new measurements - isophotal asymmetry $A_X$ and substructure $St$ - that aim to resolve some of these biases. Finally, we provide a Python package statmorph-lsst implementing these changes and a full dataset that enables tests of custom functions (see text for links).</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09644v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elizaveta Sazonova, Cameron R. Morgan, Michael Balogh, Mat\'ias Bla\~na, Carlos G. Bornancini, Darko Donevski, Alister Graham, Hector M. Hernandez Toledo, Benne W. Holwerda, Jeyhan S. Kartaltepe, Garreth Martin, William J. Pearson, Rossella Ragusa, Vicente Rodriguez-Gomez, Michael J. Rutkowski, Jose Antonio V\'azquez-Mata, Rogier A. Windhorst</dc:creator>
    </item>
    <item>
      <title>Photon counting readout for detection and inference of gravitational waves from neutron star merger remnants</title>
      <link>https://arxiv.org/abs/2511.09656</link>
      <description>arXiv:2511.09656v1 Announce Type: cross 
Abstract: Gravitational waves emitted after neutron star binary coalescences and the information they carry about dense matter are a high-priority target for next-generation detectors. Even though such detectors are expected to observe millions of signals, detectable post-merger emission will remain rare. In this work, we explore post-merger detectability and inference through an alternative detector readout scheme for data dominated by quantum-noise, which is the case above $1$\,kHz: photon-counting. In such a readout, signals and noise become quantized into discrete distributions corresponding to the detection of single photons measured in a chosen basis of modes. Through simulated data, we demonstrate that photon counting can be efficient even for weak signals. We find ${\sim}1$ in 100 signals with a post-merger signal-to-noise ratio of 0.2 can result in a single photon and thus be detected. Furthermore, after $2\times10^4$ signals -- equivalent to $10^{-2}$ to $1.5$ years of observation -- photon counting results in a twofold improvement in the measurement of the radius of a $1.6\,M_\odot$ neutron star. Constraints can be further tightened if the detector classical noise is reduced. Photon counting offers a promising alternative to traditional homodyne readout techniques for extracting information from low signal-to-noise ratio post-merger signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09656v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Payne, Lee McCuller, Katerina Chatziioannou</dc:creator>
    </item>
    <item>
      <title>Planetary architectures under the influence of a stellar binary</title>
      <link>https://arxiv.org/abs/2511.09676</link>
      <description>arXiv:2511.09676v1 Announce Type: cross 
Abstract: Context. The presence of a stellar companion can strongly influence the architecture and long-term stability of planetary systems. Motivated by the discovery of exoplanets exhibiting extremely high eccentricities (e &gt;= 0.8) in systems with a binary companion, we investigate how planetary orbits around one star (S-type configuration) evolve under the gravitational perturbations of the companion. Aims. We aim to assess the role of a stellar companion in shaping the orbital evolution of S-type planets and to explore whether dynamical interactions in such environments can account for the formation of highly eccentric planets. Methods. We performed a suite of N-body simulations, modeling systems initially composed of three Jupiter-mass planets on nearly circular, coplanar orbits around the primary star. We systematically varied the semi-major axis, eccentricity, and inclination of the stellar companion, to characterize the conditions under which extreme eccentricities can be excited. Results. Our results show that dynamical processes such as planet-planet scattering and secular mechanisms--including the von Zeipel-Kozai-Lidov effect induced by the binary--often act together to produce abrupt and significant changes in planetary orbital evolution, with the outcome strongly dependent on the binary separation. The binary's eccentricity primarily dictates the number of surviving planets, while its inclination not only governs the final eccentricities of those survivors but also drives their orbits to align with the binary plane. Our simulations successfully reproduce the high eccentricities and compact orbits observed in four observed systems, showing close agreement between the modeled configurations and the actual systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09676v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Milenne \'Avila-Bravo, Carolina Charalambous, Claudia Aguilera-G\'omez</dc:creator>
    </item>
    <item>
      <title>Simulated Real-Time Testing of the Prototype Implementation of the SOFIE Model: The 2025 Space Weather Prediction Testbed Exercise</title>
      <link>https://arxiv.org/abs/2511.09716</link>
      <description>arXiv:2511.09716v1 Announce Type: cross 
Abstract: The CLEAR Space Weather Center of Excellence's solar energetic particle (SEP) prediction model, SOlar wind with FIeld lines and Energetic particles (SOFIE), was run and evaluated on-site during the Space Weather Prediction Testbed (SWPT) exercise at NOAA's Space Weather Prediction Center (SWPC) in May 2025. As a physics-based SEP simulation and prediction model, SOFIE simulates the acceleration and transport of energetic particles in the coronal mass ejection (CME) driven shock in the solar corona and inner heliosphere. It has been validated against historical events. However, questions remain regarding whether a physics-based model, traditionally considered computationally expensive, could meet operational needs. The SWPT exercise offered a valuable opportunity to evaluate SOFIE's performance under simulated real-time conditions. Interactive feedback during the exercise from SWPC forecasters, SRAG console operators, CCMC personnel, and M2M SWAO analysts led to significant strategic improvements in the model setup to meet operational requirements. The resolution of the simulation domain was optimized by combining a coarser background grid with higher-resolution regions along the CME path and facing toward Earth, reducing computational cost without compromising accuracy. In this work, we present the operational performance of SOFIE and its capability to predict SEP fluxes significantly faster than real time. SOFIE was able to complete a 4-day SEP simulation within 5 hours on a supercomputer with 1,000 CPU cores during the SWPT exercise. This marks a critical milestone in demonstrating both the robustness and operational usefulness of SOFIE to support future human space exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09716v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <category>physics.space-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Weihao Liu, Lulu Zhao, Igor V. Sokolov, Kathryn Whitman, Tamas I. Gombosi, Nishtha Sachdeva, Eric T. Adamson, Hazel M. Bain, Claudio Corti, M. Leila Mays, Michelangelo Romano, Carina R. Alden, Madeleine M. Anastopulos, Mary E. Aronne, Janet E. Barzilla, Wesley T. Cook, Shawn D. Dahl, Hannah Hermann, Anthony J. Iampietro, A. Steve Johnson, Elizabeth A. Juelfs, Melissa R. Kane, Jonathan D. Lash, Kimberly Moreland, Briana K. Muhlestein, Teresa Nieves-Chinchilla, Edward Semones, James F. Spann, Earl M. Spencer, Luke A. Stegeman, Christopher J. Stubenrauch, Kenneth L. Tegnell</dc:creator>
    </item>
    <item>
      <title>Towards model-free stellar chemical abundances. Potential applications in the search for chemically peculiar stars in large spectroscopic surveys</title>
      <link>https://arxiv.org/abs/2511.09733</link>
      <description>arXiv:2511.09733v1 Announce Type: cross 
Abstract: Chemical abundance determinations from stellar spectra are challenged by observational noise, limitations in stellar models, and departures from simplifying assumptions. While traditional and supervised machine learning methods have made remarkable progress in estimating atmospheric parameters and chemical compositions within existing physical models, these factors still constrain our ability to fully exploit the vast data sets provided by modern spectroscopic surveys. We aim to develop a self-supervised, disentangled representation learning framework that extracts chemically meaningful features directly from spectra, without relying on externally imposed label catalogs. We build a variational autoencoder-based representation learning model with physics-inspired structure: multiple decoders each focus on spectral regions dominated by a particular element, enforcing that each latent dimension maps to a single abundance. To evaluate the potential application of our framework, we trained and validated the model on low-resolution, low signal-to-noise synthetic spectra focusing on $\rm [Fe/H]$, $\rm [C/Fe]$, and $\rm [\alpha/Fe]$. We then demonstrate how the trained model can be used to flag stars as chemically enhanced or depleted in these abundances based on their position within the latent distribution. Our model successfully learns a representation of spectra whose axes correlate tightly with the target abundances ($r=0.92\pm0.01$ for $\rm [Fe/H]$, $r=0.92\pm0.01$ for $\rm [C/Fe]$, $r=0.82\pm0.02$ for $\rm [\alpha/Fe]$). The disentangled representations provide a robust means to distinguish stars based on their chemical properties, offering an efficient and scalable solution for large spectroscopic surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09733v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theosamuele Signor, Paula Jofr\'e, Hernan Lira, Sara Vitali, Luis Mart\'i, Nayat S\'anchez-Pi</dc:creator>
    </item>
    <item>
      <title>Mitigating numerical dissipation in simulations of subsonic turbulent flows</title>
      <link>https://arxiv.org/abs/2511.09806</link>
      <description>arXiv:2511.09806v1 Announce Type: cross 
Abstract: Magnetohydrodynamic (MHD) simulations of subsonic (Mach number~$&lt;1$) turbulence are crucial to our understanding of several processes including oceanic and atmospheric flows, the amplification of magnetic fields in the early universe, accretion discs, and stratified flows in stars. In this work, we demonstrate that conventional numerical schemes are excessively dissipative in this low-Mach regime. We demonstrate that a new numerical scheme (termed `USM-BK' and implemented in the FLASH MHD code) reduces the dissipation of kinetic and magnetic energy, constrains the divergence of magnetic field to zero close to machine precision, and resolves smaller-scale structure than other, more conventional schemes, and hence, is the most accurate for simulations of low-Mach turbulent flows among the schemes compared in this work. We first compare several numerical schemes/solvers, including Split-Roe, Split-Bouchut, USM-Roe, USM-HLLC, USM-HLLD, and the new USM-BK, on a simple vortex problem. We then compare the schemes/solvers in simulations of the turbulent dynamo and show that the choice of scheme affects the growth rate, saturation level, and viscous and resistive dissipation scale of the dynamo. We also measure the numerical kinematic Reynolds number (Re) and magnetic Reynolds number (Rm) of our otherwise ideal MHD flows, and show that the new USM-BK scheme provides the highest Re and comparable Rm amongst all the schemes compared.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09806v1</guid>
      <category>physics.flu-dyn</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Watt, Christoph Federrath, Claudius Birke, Christian Klingenberg</dc:creator>
    </item>
    <item>
      <title>CORONA-Fields: Leveraging Foundation Models for Classification of Solar Wind Phenomena</title>
      <link>https://arxiv.org/abs/2511.09843</link>
      <description>arXiv:2511.09843v1 Announce Type: cross 
Abstract: Space weather at Earth, driven by the solar activity, poses growing risks to satellites around our planet as well as to critical ground-based technological infrastructure. Major space weather contributors are the solar wind and coronal mass ejections whose variable density, speed, temperature, and magnetic field make the automated classification of those structures challenging. In this work, we adapt a foundation model for solar physics, originally trained on Solar Dynamics Observatory imagery, to create embeddings suitable for solar wind structure analysis. These embeddings are concatenated with the spacecraft position and solar magnetic connectivity encoded using Fourier features which generates a neural field-based model. The full deep learning architecture is fine-tuned bridging the gap between remote sensing and in situ observations. Labels are derived from Parker Solar Probe measurements, forming a downstream classification task that maps plasma properties to solar wind structures. Although overall classification performance is modest, likely due to coarse labeling, class imbalance, and limited transferability of the pretrained model, this study demonstrates the feasibility of leveraging foundation model embeddings for in situ solar wind tasks. As a first proof-of-concept, it lays the groundwork for future improvements toward more reliable space weather predictions. The code and configuration files used in this study are publicly available to support reproducibility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09843v1</guid>
      <category>cs.CV</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Martin, Jinsu Hong, Connor O'Brien, Valmir P Moraes Filho, Jasmine R. Kobayashi, Evangelia Samara, Joseph Gallego</dc:creator>
    </item>
    <item>
      <title>Rediscovering the Lunar Equation of the Centre with AI Feynman via Embedded Physical Biases</title>
      <link>https://arxiv.org/abs/2511.09979</link>
      <description>arXiv:2511.09979v1 Announce Type: cross 
Abstract: This work explores using the physics-inspired AI Feynman symbolic regression algorithm to automatically rediscover a fundamental equation in astronomy -- the Equation of the Centre. Through the introduction of observational and inductive biases corresponding to the physical nature of the system through data preprocessing and search space restriction, AI Feynman was successful in recovering the first-order analytical form of this equation from lunar ephemerides data. However, this manual approach highlights a key limitation in its reliance on expert-driven coordinate system selection. We therefore propose an automated preprocessing extension to find the canonical coordinate system. Results demonstrate that targeted domain knowledge embedding enables symbolic regression to rediscover physical laws, but also highlight further challenges in constraining symbolic regression to derive physics equations when leveraging domain knowledge through tailored biases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09979v1</guid>
      <category>cs.LG</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saumya Shah, Zi-Yu Khoo, Abel Yang, St\'ephane Bressan</dc:creator>
    </item>
    <item>
      <title>A predictive framework for realistic star planet radio emission in compact systems</title>
      <link>https://arxiv.org/abs/2511.10350</link>
      <description>arXiv:2511.10350v1 Announce Type: cross 
Abstract: Radio emission from star planet interactions (SPI) beyond our solar system has yet to be firmly detected, primarily due to challenges such as weak signals, directional beaming effects, and low frequency emissions that are blocked by the ionosphere of Earth. Addressing these obstacles calls for strategic target selection. This proof of concept study aims to improve SPI target prioritization by simulating SPI induced radio emission frequencies and estimating associated radio power to identify systems most likely to produce detectable signals. We combine Zeeman Doppler Imaging (ZDI) maps with 3D magnetohydrodynamic (MHD) stellar wind simulations and use the ExPRES code to model SPI driven radio emissions. We also estimate the intensity of these emissions using the Radio Magnetic Scaling Law, based on the magnetic field and plasma density parameters from the 3D wind models. This approach is applied to systems such as Tau Boo, HD 179949, and HD 189733 to assess their detectability with current and future radio telescopes. This framework, tested on benchmark systems, is applicable to any star planet system with available ZDI maps and wind models. As magnetic field reconstructions and wind simulations improve, the method will become more robust. It provides a data driven approach to prioritize targets and optimize telescope scheduling. This shall enable systematic exploration of magnetic SPI radio emissions across a wide range of exoplanetary systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10350v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. J. Chebly, C. K. Louis, A. Strugarek, J. D. Alvarado G, P. Zarka</dc:creator>
    </item>
    <item>
      <title>Generating optimal Gravitational-Wave template banks with metric-preserving autoencoders</title>
      <link>https://arxiv.org/abs/2511.10466</link>
      <description>arXiv:2511.10466v1 Announce Type: cross 
Abstract: We present a geometric placement algorithm for constructing template banks. We specialize in the case of Gravitational Wave searches, and use autoencoders for non-linear compression of the space of waveforms after these have been represented by a finite number of basis functions using an SVD decomposition. To ensure that the autoencoder is suitable for geometric placement we try to find a coordinate system describing the manifold of SVD coefficients such that distances in the latent and embedding space are equal. We show that the curvature of the banks is negligible and that such a system can be found. We then show that a geometric placement algorithm via a uniform grid in the latent space combined with rejection of unphysical points using a normalizing flow results in templates that, while slightly less in number than the similar construction using random forests of Ref.~\cite{Wadekar:2023kym}, perform slightly better in the effectualness tests, especially for high-mass binary systems. We discuss briefly how these dimensionality reduction techniques might be used in the context of cosmology, and a simple toy example where the periodicity of a flat manifold slightly complicates finding a distance-preserving coordinate system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10466v1</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Cabass, Digvijay Wadekar, Matias Zaldarriaga, Zihan Zhou</dc:creator>
    </item>
    <item>
      <title>Bayesian model comparison and validation with Gaussian Process Regression for interferometric 21-cm signal recovery</title>
      <link>https://arxiv.org/abs/2511.10499</link>
      <description>arXiv:2511.10499v1 Announce Type: cross 
Abstract: The 21-cm signal from neutral hydrogen is anticipated to reveal critical insights into the formation of early cosmic structures during the Cosmic Dawn and the subsequent Epoch of Reionization. However, the intrinsic faintness of the signal, as opposed to astrophysical foregrounds, poses a formidable challenge for its detection. Motivated by the recent success of machine learning based Gaussian Process Regression (GPR) methods in LOFAR and NenuFAR observations, we perform a Bayesian comparison among five GPR models to account for the simulated 4-hour tracking observations with the SKA-Low telescope. The simulated sky is convolved with the instrumental beam response and includes realistic radio sources and thermal noise from 122 to 134 MHz. A Bayesian model evaluation framework is applied to five GPR models to discern the most effective modelling strategy and determine the optimal model parameters. The GPR model with wedge parametrization ($\textit{Wedge}$) and its extension ($\alpha\textit{Noise}$) with noise scaling achieve the highest Bayesian evidence of the observed data and the least biased 21-cm power spectrum recovery. The $\alpha\textit{Noise}$ and $\textit{Wedge}$ models also forecast the best local power-spectrum recovery, demonstrating fractional differences of $-0.14\%$ and $0.47\%$ respectively, compared to the injected 21-cm power at $k = 0.32\ \mathrm{h\ cMpc}^{-1}$. We additionally perform Bayesian null tests to validate the five models, finding that the two optimal models also pass with the remaining three models yielding spurious detections in data containing no 21-cm signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10499v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Liu, Eloy de Lera Acedo, Peter Sims</dc:creator>
    </item>
    <item>
      <title>Carbox: an end-to-end differentiable astrochemical simulation framework</title>
      <link>https://arxiv.org/abs/2511.10558</link>
      <description>arXiv:2511.10558v1 Announce Type: cross 
Abstract: Since the first observations of interstellar molecules, astrochemical simulations have been employed to model and understand its formation and destruction path- ways. With the advent of high-resolution telescopes such as JWST and ALMA, the number of detected molecules has increased significantly, thereby creating a need for increasingly complex chemical reaction networks. To model such complex systems, we have developed Carbox, a new astrochemical simulation code that leverages the modern high-performance transformation framework Jax. With Jax enabling computational efficiency and differentiability, Carbox can easily utilize GPU acceleration, be used to study sensitivity and uncertainty, and interface with advances in Scientific Machine Learning. All of these features are crucial for modeling the molecules observed by current and next-generation telescopes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10558v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gijs Vermari\"en, Tommaso Grassi, Marie Van de Sande, Serena Viti, Stefano Bovino, Alessandro Lupi, Alexander Ruf, Lorenzo Branca, Catherine Walsh</dc:creator>
    </item>
    <item>
      <title>A Bayesian Perspective on Evidence for Evolving Dark Energy</title>
      <link>https://arxiv.org/abs/2511.10631</link>
      <description>arXiv:2511.10631v1 Announce Type: cross 
Abstract: The DESI collaboration reports a significant preference for a dynamic dark energy model ($w_0w_a$CDM) over the cosmological constant ($\Lambda$CDM) when their data are combined with other frontier cosmological probes. We present a direct Bayesian model comparison using nested sampling to compute the Bayesian evidence, revealing a contrasting conclusion: for the key combination of the DESI DR2 BAO and the Planck CMB data, we find the Bayesian evidence modestly favours $\Lambda$CDM (log-Bayes factor $\ln B = -0.57{\scriptstyle\pm0.26}$), in contrast to the collaboration's 3.1$\sigma$ frequentist significance in favoring $w_0w_a$CDM. Extending this analysis to also combine with the DES-Y5 supernova catalogue, our Bayesian analysis reaches a significance of $3.07{\scriptstyle\pm0.10}\,\sigma$ in favour of $w_0w_a$CDM. By performing a comprehensive tension analysis, employing five complementary metrics, we pinpoint the origin: a significant ($\approx 2.95\sigma$), low-dimensional tension between DESI DR2 and DES-Y5 that is present only within the $\Lambda$CDM framework. The $w_0w_a$CDM model is preferred precisely because its additional parameters act to resolve this specific dataset conflict. The convergence of our findings with independent geometric analyses suggests that the preference for dynamic dark energy is primarily driven by the resolution of inter-dataset tensions, warranting a cautious interpretation of its statistical significance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10631v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dily Duan Yi Ong, David Yallup, Will Handley</dc:creator>
    </item>
    <item>
      <title>Flexible Simulation Based Inference for Galaxy Photometric Fitting with Synthesizer</title>
      <link>https://arxiv.org/abs/2511.10640</link>
      <description>arXiv:2511.10640v1 Announce Type: cross 
Abstract: We introduce Synference, a new, flexible Python framework for galaxy SED fitting using simulation-based inference (SBI). Synference leverages the Synthesizer package for flexible forward-modelling of galaxy SEDs and integrates the LtU-ILI package to ensure best practices in model training and validation. In this work we demonstrate Synference by training a neural posterior estimator on $10^6$ simulated galaxies, based on a flexible 8-parameter physical model, to infer galaxy properties from 14-band HST and JWST photometry. We validate this model, demonstrating excellent parameter recovery (e.g. R$^2&gt;$0.99 for M$_\star$) and accurate posterior calibration against nested sampling results. We apply our trained model to 3,088 spectroscopically-confirmed galaxies in the JADES GOODS-South field. The amortized inference is exceptionally fast, having nearly fixed cost per posterior evaluation and processing the entire sample in $\sim$3 minutes on a single CPU (18 galaxies/CPU/sec), a $\sim$1700$\times$ speedup over traditional nested sampling or MCMC techniques. We demonstrate Synference's ability to simultaneously infer photometric redshifts and physical parameters, and highlight its utility for rapid Bayesian model comparison by demonstrating systematic stellar mass differences between two commonly used stellar population synthesis models. Synference is a powerful, scalable tool poised to maximise the scientific return of next-generation galaxy surveys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10640v1</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas Harvey, Christopher C. Lovell, Sophie Newman, Christopher J. Conselice, Duncan Austin, Aswin P. Vijayan, Stephen M. Wilkins, Vadim Rusakov, Qiong Li, Nathan Adams, Kai Magdwick, Matthew Ho</dc:creator>
    </item>
    <item>
      <title>Enhancing the development of Cherenkov Telescope Array control software with Large Language Models</title>
      <link>https://arxiv.org/abs/2510.01299</link>
      <description>arXiv:2510.01299v2 Announce Type: replace 
Abstract: We develop AI agents based on instruction-finetuned large language models (LLMs) to assist in the engineering and operation of the Cherenkov Telescope Array Observatory (CTAO) Control and Data Acquisition Software (ACADA). These agents align with project-specific documentation and codebases, understand contextual information, interact with external APIs, and communicate with users in natural language. We present our progress in integrating these features into CTAO pipelines for operations and offline data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01299v2</guid>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitriy Kostunin, Elisa Jones, Vladimir Sotnikov, Valery Sotnikov, Sergo Golovachev, Alexandre Strube</dc:creator>
    </item>
    <item>
      <title>Mock Observations for the CSST Mission: CPI-C -- Instrument Simulation</title>
      <link>https://arxiv.org/abs/2511.08886</link>
      <description>arXiv:2511.08886v2 Announce Type: replace 
Abstract: To support the development of the data processing pipeline and the scientific performance assessment for the Cool Planet Imaging Coronagraph (CPI-C) on the Chinese Space Station Survey Telescope (CSST), we have developed the end-to-end instrument simulation program, CPISM. This paper details the core modules of CPISM that simulate the CPI-C instrument, focusing on the simulation of the high-contrast imaging optical system and the visible-band science camera. We modeled key optical components, such as the transmission apodizing filter, the wavefront corrector, and the focal plane mask using the HCIPy package. A $10^{-8}$ contrast dark hole region, consistent with design specifications, was simulated using the Electric Field Conjugation (EFC) optimization method, and broadband observation effects were considered. For the science camera, which is an electron multiplying charge-coupled device (EMCCD), we established a detailed model encompassing photon collection, charge transfer, electron multiplication (EM), and readout processes, based on test data. This model simulates complex instrumental features including dark current, charge transfer efficiency, clock-induced charge, multiplication noise factor, and various readout effects like striping and drift. We also proposed and validated an improved statistical model for the EM process to enhance simulation efficiency. CPISM can generate simulated images containing rich instrumental details, closely similar to the expected real observational data, thus laying the foundation for the development and verification of CPI-C data processing algorithms and preparations for future scientific research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08886v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.EP</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gang Zhao, Yiming Zhu, Jiangpei Dou, Yili Chen, Zhonghua Lv, Bingli Niu, Zhaojun Yan, Bo Ma, Ran Li</dc:creator>
    </item>
    <item>
      <title>Mock Observations for the CSST Mission: HSTDM--Synthetic Data Generation</title>
      <link>https://arxiv.org/abs/2511.09074</link>
      <description>arXiv:2511.09074v2 Announce Type: replace 
Abstract: The High Sensitivity Terahertz Detection Module (HSTDM), a key component of the backend modules on board the China Space Station Telescope (CSST), will offer great opportunities for the discovery of Terahertz Astronomy, with implications that extend well beyond China to the global astronomical community. It is imperative that the raw data collected by HSTDM undergoes meticulous calibration and processing through the HSTDM data processing pipeline (HSTDM pipeline for short) to ensure the accuracy and effectiveness of the final science data to be archived for further research. This process necessitates that the HSTDM pipeline address instrumental artifacts and effects as well as the coordination of data flow of the scheduled observing sequences under all observing modes of HSTDM within the CSST automated processing environment. As the understanding of CSST HSTDM data processing develops during the pipeline development stage, it becomes essential to assess the accuracy, the robustness and the performance of the HSTDM pipeline under all observing modes of HSTDM so that components of the HSTDM pipeline be rationally added, removed, amended or extended within the modular framework. In this paper, we develop practical simulation methods to facilitate this need. The contribution of synthetic data generation of HSTDM observation includes two parts: 1. HSTDM instrumental effect simulation based on both real testing profiles and simulated models; 2. Observing data flow generation based on HSTDM observing mode scenario. The simulation methods have been implemented and shown to be practical in testing the HSTDM pipeline during the development stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09074v2</guid>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>SiYuan Tan, WenYin Duan, YiLong Zhang, YiPing Ao, Yan Gong, ZhenHui Lin, Xuan Zhang, Yong Shi, Jing Tang, Jing Li, RuiQing Mao, Sheng-Cai Shi</dc:creator>
    </item>
    <item>
      <title>MOA-2010-BLG-328: Keck and HST Expose the Limits of Occams Razor in Microlensing</title>
      <link>https://arxiv.org/abs/2504.06347</link>
      <description>arXiv:2504.06347v2 Announce Type: replace-cross 
Abstract: We present high resolution follow-up data of the planetary microlensing event MOA-2010-BLG-328, using Keck and the Hubble. Keck data, taken 8 years after the event, reveal a strong lens detection enabling a direct measurement of lens flux and source-lens relative proper motion. We find the relative source-lens proper motion to be $\mu_{\rm rel, Hel} = 4.07 \pm 0.34\ \rm mas\ yr^{-1}$, with the lens being $\sim10$ times fainter than the source. The lens was very faint in the Hubble passbands, and the small lens-source separation of $\sim$35 mas made its detection difficult. However, we obtained estimates of the lens magnitudes in Hubble bands by constraining its location to match the Keck K-band detection. The original analysis by \citet{Furusawa2013} reports a degenerate light curve, with several viable models depending on higher-order effects. We attempt to break the degeneracy by remodeling the event using constraints from follow-up data. Our best fit model includes parallax, orbital motion, xallarap and the magnification of a source companion. Models omitting any of these are excluded. However, even with a lens detection the solution remains unclear, as the degeneracy between a nearby late M dwarf and a distant early M dwarf in the disk persists, and cannot be broken with NIR data alone. We conclude the lens is either a $\sim0.2\ M_{\odot}$ star at $2-3$kpc, or a $\sim0.5\ M_{\odot}$ star at $4-5$kpc. This study highlights the importance of multi-band data and comprehensive modeling to resolve microlensing degeneracies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06347v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-3881/ae0d82</arxiv:DOI>
      <arxiv:journal_reference>Vandorou et al. (2025), AJ, 170, 6, 310</arxiv:journal_reference>
      <dc:creator>Aikaterini Vandorou, David P. Bennett, Jean-Philippe Beaulieu, Aparna Bhattacharya, Joshua W. Blackman, Andrew A. Cole, Naoki Koshimoto, Cl\'ement Ranc, Natalia E. Rektsini, Sean K. Terry</dc:creator>
    </item>
    <item>
      <title>Broadband Optical Modulation and Control at Millikelvin Temperatures</title>
      <link>https://arxiv.org/abs/2504.06995</link>
      <description>arXiv:2504.06995v2 Announce Type: replace-cross 
Abstract: A universal experimental challenge when studying radiation effects on cryogenic devices is to precisely and accurately characterize the position-dependent device response very near the energy detection threshold. We have developed a compact cryogenic optical beam steering system that can be used to generate O({\mu}s) pulses of small numbers of photons over the energy range of 1.2 - 4.5eV at room temperature, and deliver those photons via fiber optic to any specified location on the surface of a detector operating at cryogenic temperatures. This new system will allow for robust calibration of any photon-sensitive detector, including supercondcting devices. The system can be used efficiently to explore the physics of target materials, quantify the position sensitivity of different sensor designs, measure phonon transport, and study the effects of quasiparticle poisoning on detector operation. We describe the design of this pulsed calibration method and present first results obtained with a second-generation system operated at room temperature and sub-Kelvin temperatures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06995v2</guid>
      <category>physics.ins-det</category>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <category>nucl-ex</category>
      <category>physics.app-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>N. Tabassum, T. Aralis, J. Anczarski, D. Baxter, B. Cabrera, R. Chapla, N. Entin, L. Hsu, H. W. Magoon, A. Nunez, J. L. Ryan, M. Salatino, A. Simchony, Z. J. Smith, S. Stevens, G. P\'erez, H. Stueber, B. A. Young, N. A. Kurinsky, K. Stifter</dc:creator>
    </item>
    <item>
      <title>How gravitational waves change photon orbital angular momentum quantum states</title>
      <link>https://arxiv.org/abs/2504.16452</link>
      <description>arXiv:2504.16452v2 Announce Type: replace-cross 
Abstract: We explore the evolution of vortex light in the presence of gravitational waves (GWs) and demonstrate that the quantized orbital angular momentum (OAM) states can make transitions to other states due to the GWs. The interaction is calculated based on the framework of the wave propagation in linearized gravity theory and canonical quantization of the light field in curved spacetime. It is found that when a photon possessing OAM of $l$ interacts with GWs, the OAM modes of $l\pm1$ and $l\pm2$ may be excited with probabilities of $P_{l\pm1}\sim 10^{-17}$ and $P_{l\pm2}\sim 10^{-20}$, respectively. Higher probabilities of the transitions can be achieved when the photon radial wave vector or the propagation distance is increased, or when the photons encounter GWs with stronger amplitudes or smaller frequencies. Thus, a new GW detection technique is proposed, which may exhibit good performance in a wide range of GW frequencies. Furthermore, the detector is insensitive to seismic noise and is more advantageous for determining the distance of the source compared to current interferometer detectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16452v2</guid>
      <category>gr-qc</category>
      <category>astro-ph.IM</category>
      <category>quant-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haorong Wu, Xilong Fan, Lixiang Chen</dc:creator>
    </item>
    <item>
      <title>Fast and accurate parameter estimation of high-redshift sources with the Einstein Telescope</title>
      <link>https://arxiv.org/abs/2504.21087</link>
      <description>arXiv:2504.21087v2 Announce Type: replace-cross 
Abstract: The Einstein Telescope (ET), along with other third-generation gravitational wave (GW) detectors, will be a key instrument for detecting GWs in the coming decades. However, analyzing the data and estimating source parameters will be challenging, especially given the large number of expected detections-on the order of $10^5$ per year-which makes current methods based on stochastic sampling impractical. In this work, we use Dingo-IS to perform neural posterior estimation (NPE) of high-redshift events detectable with ET in its triangular configuration. NPE is a likelihood-free inference technique that leverages normalizing flows to approximate posterior distributions. After training, inference is fast, requiring only a few minutes per source, and accurate, as corrected through importance sampling and validated against standard Bayesian inference methods. To confirm previous findings on the ability to estimate parameters for high-redshift sources with ET, we compare NPE results with predictions from the Fisher information matrix (FIM) approximation. We find that NPE correctly recovers the eight degenerate sky modes induced by the triangular detector geometry, missed by the FIM analysis, resulting in an underestimation of sky localization uncertainties for most sources. FIM also overestimates the uncertainty in luminosity distance by a factor of $\sim 3$ on average when the injected luminosity distance is $d^{\mathrm{inj}}_{\mathrm{L}} &gt; 10^5~$Mpc, further confirming that ET will be particularly well suited for studying the early Universe.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21087v2</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/wf1k-p5cl</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. D 112 (2025) 103015</arxiv:journal_reference>
      <dc:creator>Filippo Santoliquido, Jacopo Tissino, Ulyana Dupletsa, Marica Branchesi, Jan Harms, Manuel Arca Sedda, Maximilian Dax, Annalena Kofler, Stephen R. Green, Nihar Gupte, Isobel M. Romero-Shaw, Emanuele Berti</dc:creator>
    </item>
    <item>
      <title>Neural-Network Chemical Emulator for First-Star Formation: Robust Iterative Predictions over a Wide Density Range</title>
      <link>https://arxiv.org/abs/2508.16114</link>
      <description>arXiv:2508.16114v2 Announce Type: replace-cross 
Abstract: We present a neural-network emulator for the thermal and chemical evolution in Population III star formation. The emulator accurately reproduces the thermochemical evolution over a wide density range spanning 21 orders of magnitude (10$^{-3}$-10$^{18}$ cm$^{-3}$), tracking six primordial species: H, H$_2$, e$^{-}$, H$^{+}$, H$^{-}$, and H$_2^{+}$. To handle the broad dynamic range, we partition the density range into five subregions and train separate deep operator networks (DeepONets) in each region. When applied to randomly sampled thermochemical states, the emulator achieves relative errors below 10% in over 90% of cases for both temperature and chemical abundances (except for the rare species H$_2^{+}$). The emulator is roughly ten times faster on a CPU and more than 1000 times faster for batched predictions on a GPU, compared with conventional numerical integration. Furthermore, to ensure robust predictions under many iterations, we introduce a novel timescale-based update method, where a short-timestep update of each variable is computed by rescaling the predicted change over a longer timestep equal to its characteristic variation timescale. In one-zone collapse calculations, the results from the timescale-based method agree well with traditional numerical integration even with many iterations at a timestep as short as 10$^{-4}$ of the free-fall time. This proof-of-concept study suggests the potential for neural network-based chemical emulators to accelerate hydrodynamic simulations of star formation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16114v2</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sojun Ono, Kazuyuki Sugimura</dc:creator>
    </item>
    <item>
      <title>Witnessing downsizing in the making: quiescent and breathing galaxies at the dawn of the Universe</title>
      <link>https://arxiv.org/abs/2509.09764</link>
      <description>arXiv:2509.09764v3 Announce Type: replace-cross 
Abstract: [Shortened for arXiv] We conduct a systematic search for $\log(M_\ast/M_\odot) \geq 9.5$ quiescent galaxies at $z &gt; 3$ in six extragalactic deep fields observed with NIRCam, with the goal of extracting their physical and statistical features in a uniform and self-consistent manner. We exploit the ASTRODEEP-JWST photometric catalogs to single out robust candidates, including sources quenched only a few tens of Myr before the observation. We apply a SED-fitting procedure which explores three functional forms of star formation history and the $\chi^2$ probabilities of the solutions, with additional checks to minimise the contamination from interlopers, tuning our selection criteria against available spectroscopic data from the DAWN archive and simulated catalogs. We select 633 candidates, which we rank by a reliability parameter based on the probabilities of the quiescent and alternative star-forming solutions, with 291 candidates tagged as "gold". According to the best-fit models, 79\% of the massive ($\log(M_\ast/M_\odot) \geq 10.5$) quiescent galaxies at $3 &lt; z &lt; 5$ stopped forming stars at least 150 Myr before the time of observation, while 89\% of low-mass sources have been quenched for less than 150 Myr. The abundance of low-mass old quiescent systems does not increase significantly with time from $z = 5$ to 3: low-mass objects seem to be experiencing a short episode of quenching followed by rejuvenation (``breathing''), consistent with a downsizing scenario of galaxy formation. We also find an abrupt drop in the density of massive quiescent candidates at $z &gt; 5$. We derive estimates for the number density of early passive galaxies up to $z = 10$ and compare them against various models: tensions with data remain in the modeling of the observed bimodality of time passed since quenching as a function of mass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09764v3</guid>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emiliano Merlin, Flaminia Fortuni, Antonello Calabr\`o, Marco Castellano, Paola Santini, Adriano Fontana, Lucas C. Kimmig, Francesco Shankar, Lorenzo Napolitano, Anton M. Koekemoer, Ray A. Lucas, Fabio Pacucci, Michael C. Cooper, Michaela Hirschmann, Pablo G. P\'erez-Gonz\'alez, Guillermo Barro, Mark Dickinson, Giovanni Gandolfi, Diego Paris, Norman A. Grogin, Xin Wang</dc:creator>
    </item>
  </channel>
</rss>
