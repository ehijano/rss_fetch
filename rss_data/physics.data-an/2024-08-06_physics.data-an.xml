<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 07 Aug 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On marginals and profiled posteriors for cosmological parameter estimation</title>
      <link>https://arxiv.org/abs/2408.02063</link>
      <description>arXiv:2408.02063v1 Announce Type: cross 
Abstract: With several examples and in an analysis of the Pantheon+ supernova sample we discuss the properties of the marginal posterior distribution versus the profiled posterior distribution -- the profile likelihood in a Bayesian disguise. We investigate whether maximisation, as used for the profiling, or integration, as used for the marginalisation, is more appropriate. To report results we recommend the marginal posterior distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02063v1</guid>
      <category>astro-ph.CO</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Kerscher, Jochen Weller</dc:creator>
    </item>
    <item>
      <title>KAN we improve on HEP classification tasks? Kolmogorov-Arnold Networks applied to an LHC physics example</title>
      <link>https://arxiv.org/abs/2408.02743</link>
      <description>arXiv:2408.02743v1 Announce Type: cross 
Abstract: Recently, Kolmogorov-Arnold Networks (KANs) have been proposed as an alternative to multilayer perceptrons, suggesting advantages in performance and interpretability. We study a typical binary event classification task in high-energy physics including high-level features and comment on the performance and interpretability of KANs in this context. We find that the learned activation functions of a one-layer KAN resemble the log-likelihood ratio of the input features. In deeper KANs, the activations in the first KAN layer differ from those in the one-layer KAN, which indicates that the deeper KANs learn more complex representations of the data. We study KANs with different depths and widths and we compare them to multilayer perceptrons in terms of performance and number of trainable parameters. For the chosen classification task, we do not find that KANs are more parameter efficient. However, small KANs may offer advantages in terms of interpretability that come at the cost of only a moderate loss in performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02743v1</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Erdmann, Florian Mausolf, Jan Lukas Sp\"ah</dc:creator>
    </item>
  </channel>
</rss>
