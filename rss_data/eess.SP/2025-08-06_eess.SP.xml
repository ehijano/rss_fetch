<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 01:31:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An AI-driven EDA Algorithm-Empowered VCO and LDO Co-Design Method</title>
      <link>https://arxiv.org/abs/2508.02687</link>
      <description>arXiv:2508.02687v1 Announce Type: new 
Abstract: Traditionally, the output noise and power supply rejection of low-dropout regulators (LDOs) are optimized to minimize power supply fluctuations, reducing their impact on the low-frequency noise of target voltage-controlled oscillators (VCOs). However, this sequential design approach does not fully address the trade-offs between high-frequency and LDO-induced low-frequency phase noise. To overcome this limitation, this paper presents a co-design method for low phase-noise LC-tank VCOs powered by LDOs. It is difficult to carry out the co-design using traditional manual design techniques. Hence, an efficient AI-driven EDA algorithm is used. To validate the proposed method, a 5.6 GHz LC-tank VCO with an integrated LDO is designed using a 65 nm CMOS process. Simulations show that the co-design method improves phase noise by 1.2 dB at a 1 MHz offset and reduces dynamic power consumption by 28.8%, with FoM increased by 2.4 dBc/Hz compared to the conventional sequential design method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02687v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijia Hao, Maarten Strackx, Miguel Gandara, Sandy Cochran, Bo Liu</dc:creator>
    </item>
    <item>
      <title>On Improving PPG-Based Sleep Staging: A Pilot Study</title>
      <link>https://arxiv.org/abs/2508.02689</link>
      <description>arXiv:2508.02689v1 Announce Type: new 
Abstract: Sleep monitoring through accessible wearable technology is crucial to improving well-being in ubiquitous computing. Although photoplethysmography(PPG) sensors are widely adopted in consumer devices, achieving consistently reliable sleep staging using PPG alone remains a non-trivial challenge. In this work, we explore multiple strategies to enhance the performance of PPG-based sleep staging. Specifically, we compare conventional single-stream model with dual-stream cross-attention strategies, based on which complementary information can be learned via PPG and PPG-derived modalities such as augmented PPG or synthetic ECG. To study the effectiveness of the aforementioned approaches in four-stage sleep monitoring task, we conducted experiments on the world's largest sleep staging dataset, i.e., the Multi-Ethnic Study of Atherosclerosis(MESA). We found that substantial performance gain can be achieved by combining PPG and its auxiliary information under the dual-stream cross-attention architecture. Source code of this project can be found at https://github.com/DavyWJW/sleep-staging-models</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02689v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Wang, Yu Guan, Chen Chen, Ligang Zhou, Laurence T. Yang, Sai Gu</dc:creator>
    </item>
    <item>
      <title>Federated Learning in Active STARS-Aided Uplink Networks</title>
      <link>https://arxiv.org/abs/2508.02693</link>
      <description>arXiv:2508.02693v1 Announce Type: new 
Abstract: Active simultaneously transmitting and reflecting surfaces (ASTARS) have attracted growing research interest due to its ability to alleviate multiplicative fading and reshape the electromagnetic environment across the entire space. In this paper, we utilise ASTARS to assist the federated learning (FL) uplink model transfer and further reduce the number of uploaded parameter counts through over-the-air (OTA) computing techniques. The impact of model aggregation errors on ASTARS-aided FL uplink networks is characterized. We derive an upper bound on the aggregation error of the OTA-FL model and quantify the training loss due to communication errors. Then, we define the performance of OTA-FL as a joint optimization problem that encompasses both the assignment of received beams and the phase shifting of ASTARS, aiming to achieve the maximum learning efficiency and high-quality signal transmission. Numerical results demonstrate that: i) The FL accuracy in ASTARS uplink networks are enhanced compared to that in state-of-the-art networks; ii) The ASTARS enabled FL system achieves the better learning accuracy using fewer active units than other baseline, especially when the dataset is more discrete; and iii) FL accuracy improves with higher amplification power, but excessive amplification makes thermal noise the dominant source of error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02693v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2025.3590980</arxiv:DOI>
      <dc:creator>Xinwei Yue, Xinning Guo, Xidong Mu, Jingjing Zhao, Peng Yang, Junsheng Mu, Zhiping Lu</dc:creator>
    </item>
    <item>
      <title>A Completely Blind Channel Estimation Technique for OFDM Using Constellation Splitting</title>
      <link>https://arxiv.org/abs/2508.02698</link>
      <description>arXiv:2508.02698v1 Announce Type: new 
Abstract: The problem of second-order statistics (SOS)-based blind channel estimation in OFDM systems is addressed in this paper. Almost all SOS-based methods proposed so far suffer from a complex-scalar estimation ambiguity, which is resolved by using pilots or reference symbols. We propose an algorithm to resolve this ambiguity in blind manner using frequency-domain linear non-redundant precoding and constellation-splitting among the alternate subcarriers. The performance of the proposed scheme is evaluated via numerical simulations in MATLAB environment. Simulation results show that the proposed approach performs as good as its semi-blind counterpart for M-ary PAM systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02698v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>In Proceedings of National Conference on Advances in Wireless Cellular Telecommunications: Technologies and Services, ICEIT, New Delhi, India, 14-15 April 2011</arxiv:journal_reference>
      <dc:creator>Sameera Bharadwaja H., D. K. Mehra</dc:creator>
    </item>
    <item>
      <title>Measuring Dependencies between Biological Signals with Temporal Self-supervision, and its Limitations</title>
      <link>https://arxiv.org/abs/2508.02703</link>
      <description>arXiv:2508.02703v1 Announce Type: new 
Abstract: Measuring the statistical dependence between observed signals is a primary tool for scientific discovery. However, biological systems often exhibit complex non-linear interactions that currently cannot be captured without a priori knowledge regarding the nature of dependence. We introduce a self-supervised approach, concurrence, which is inspired by the observation that if two signals are dependent, then one should be able to distinguish between temporally aligned vs. misaligned segments extracted from them. Experiments with fMRI, physiological and behavioral signals show that, to our knowledge, concurrence is the first approach that can expose relationships across such a wide spectrum of signals and extract scientifically relevant differences without ad-hoc parameter tuning or reliance on a priori information, providing a potent tool for scientific discoveries across fields. However, depencencies caused by extraneous factors remain an open problem, thus researchers should validate that exposed relationships truely pertain to the question(s) of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02703v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Evangelos Sariyanidi, John D. Herrington, Lisa Yankowitz, Pratik Chaudhari, Theodore D. Satterthwaite, Casey J. Zampella, Robert T. Schultz, Russell T. Shinohara, Birkan Tunc</dc:creator>
    </item>
    <item>
      <title>Evaluation of Deep Learning Models for LBBB Classification in ECG Signals</title>
      <link>https://arxiv.org/abs/2508.02710</link>
      <description>arXiv:2508.02710v1 Announce Type: new 
Abstract: This study explores different neural network architectures to evaluate their ability to extract spatial and temporal patterns from electrocardiographic (ECG) signals and classify them into three groups: healthy subjects, Left Bundle Branch Block (LBBB), and Strict Left Bundle Branch Block (sLBBB).
  Clinical Relevance, Innovative technologies enable the selection of candidates for Cardiac Resynchronization Therapy (CRT) by optimizing the classification of subjects with Left Bundle Branch Block (LBBB).</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02710v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Beatriz Macas Ord\'o\~nez, Diego Vinicio Orellana Villavicencio, Jos\'e Manuel Ferr\'andez, Paula Bonomini</dc:creator>
    </item>
    <item>
      <title>Physics-guided denoiser network for enhanced additive manufacturing data quality</title>
      <link>https://arxiv.org/abs/2508.02712</link>
      <description>arXiv:2508.02712v1 Announce Type: new 
Abstract: Modern engineering systems are increasingly equipped with sensors for real-time monitoring and decision-making. However, the data collected by these sensors is often noisy and difficult to interpret, limiting its utility for control and diagnostics. In this work, we propose a physics-informed denoising framework that integrates energy-based model and Fisher score regularization to jointly reduce data noise and enforce physical consistency with a physics-based model. The approach is first validated on benchmark problems, including the simple harmonic oscillator, Burgers' equation, and Laplace's equation, across varying noise levels. We then apply the denoising framework to real thermal emission data from laser powder bed fusion (LPBF) additive manufacturing experiments, using a trained Physics-Informed Neural Network (PINN) surrogate model of the LPBF process to guide denoising. Results show that the proposed method outperforms baseline neural network denoisers, effectively reducing noise under a range of LPBF processing conditions. This physics-guided denoising strategy enables robust, real-time interpretation of low-cost sensor data, facilitating predictive control and improved defect mitigation in additive manufacturing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02712v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pallock Halder, Satyajit Mojumder</dc:creator>
    </item>
    <item>
      <title>Precoder Design for User-Centric Network Massive MIMO: A Symplectic Optimization Approach</title>
      <link>https://arxiv.org/abs/2508.02713</link>
      <description>arXiv:2508.02713v1 Announce Type: new 
Abstract: In this paper, we utilize symplectic optimization to design a precoder for user-centric network (UCN) massive multiple-input multiple-output (MIMO) systems, where a subset of base stations (BSs) serves each user terminal (UT) instead of using all BSs. In UCN massive MIMO systems, the dimension of the precoders is reduced compared to conventional network massive MIMO. It simplifies the implementation of precoders in practical systems. However, the matrix inversion in traditional linear precoders still requires high computational complexity. To avoid the matrix inversion, we employ the symplectic optimization framework, where optimization problems are solved based on dissipative Hamiltonian dynamical systems. To better fit symplectic optimization, we transform the received model into the real field and reformulate the weighted sum-rate (WSR) maximization problem. The objective function of the optimization problem is viewed as the potential energy of the dynamical system. Due to energy dissipation, the continuous dynamical system always converges to a state with minimal potential energy. By discretizing the continuous system while preserving the symplectic structure, we obtain an iterative method for the precoder design. The complexity analysis of the proposed symplectic method is also provided to show its high computational efficiency. Simulation results demonstrate that the proposed precoder design based on symplectic optimization outperforms the weighted minimum mean-square error (WMMSE) precoder in the UCN massive MIMO system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02713v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengxu Lin, An-An Lu, Xiqi Gao</dc:creator>
    </item>
    <item>
      <title>SleepLiteCNN: Energy-Efficient Sleep Apnea Subtype Classification with 1-Second Resolution Using Single-Lead ECG</title>
      <link>https://arxiv.org/abs/2508.02718</link>
      <description>arXiv:2508.02718v1 Announce Type: new 
Abstract: Apnea is a common sleep disorder characterized by breathing interruptions lasting at least ten seconds and occurring more than five times per hour. Accurate, high-temporal-resolution detection of sleep apnea subtypes - Obstructive, Central, and Mixed - is crucial for effective treatment and management. This paper presents an energy-efficient method for classifying these subtypes using a single-lead electrocardiogram (ECG) with high temporal resolution to address the real-time needs of wearable devices. We evaluate a wide range of classical machine learning algorithms and deep learning architectures on 1-second ECG windows, comparing their accuracy, complexity, and energy consumption. Based on this analysis, we introduce SleepLiteCNN, a compact and energy-efficient convolutional neural network specifically designed for wearable platforms. SleepLiteCNN achieves over 95% accuracy and a 92% macro-F1 score, while requiring just 1.8 microjoules per inference after 8-bit quantization. Field Programmable Gate Array (FPGA) synthesis further demonstrates significant reductions in hardware resource usage, confirming its suitability for continuous, real-time monitoring in energy-constrained environments. These results establish SleepLiteCNN as a practical and effective solution for wearable device sleep apnea subtype detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02718v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zahra Mohammadi, Siamak Mohammadi</dc:creator>
    </item>
    <item>
      <title>Veli: Unsupervised Method and Unified Benchmark for Low-Cost Air Quality Sensor Correction</title>
      <link>https://arxiv.org/abs/2508.02724</link>
      <description>arXiv:2508.02724v1 Announce Type: new 
Abstract: Urban air pollution is a major health crisis causing millions of premature deaths annually, underscoring the urgent need for accurate and scalable monitoring of air quality (AQ). While low-cost sensors (LCS) offer a scalable alternative to expensive reference-grade stations, their readings are affected by drift, calibration errors, and environmental interference. To address these challenges, we introduce Veli (Reference-free Variational Estimation via Latent Inference), an unsupervised Bayesian model that leverages variational inference to correct LCS readings without requiring co-location with reference stations, eliminating a major deployment barrier. Specifically, Veli constructs a disentangled representation of the LCS readings, effectively separating the true pollutant reading from the sensor noise. To build our model and address the lack of standardized benchmarks in AQ monitoring, we also introduce the Air Quality Sensor Data Repository (AQ-SDR). AQ-SDR is the largest AQ sensor benchmark to date, with readings from 23,737 LCS and reference stations across multiple regions. Veli demonstrates strong generalization across both in-distribution and out-of-distribution settings, effectively handling sensor drift and erratic sensor behavior. Code for model and dataset will be made public when this paper is published.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02724v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yahia Dalbah, Marcel Worring, Yen-Chia Hsu</dc:creator>
    </item>
    <item>
      <title>SpectrumFM: A New Paradigm for Spectrum Cognition</title>
      <link>https://arxiv.org/abs/2508.02742</link>
      <description>arXiv:2508.02742v1 Announce Type: new 
Abstract: The enhancement of spectrum efficiency and the realization of secure spectrum utilization are critically dependent on spectrum cognition. However, existing spectrum cognition methods often exhibit limited generalization and suboptimal accuracy when deployed across diverse spectrum environments and tasks. To overcome these challenges, we propose a spectrum foundation model, termed SpectrumFM, which provides a new paradigm for spectrum cognition. An innovative spectrum encoder that exploits the convolutional neural networks and the multi-head self attention mechanisms is proposed to effectively capture both fine-grained local signal structures and high-level global dependencies in the spectrum data. To enhance its adaptability, two novel self-supervised learning tasks, namely masked reconstruction and next-slot signal prediction, are developed for pre-training SpectrumFM, enabling the model to learn rich and transferable representations. Furthermore, low-rank adaptation (LoRA) parameter-efficient fine-tuning is exploited to enable SpectrumFM to seamlessly adapt to various downstream spectrum cognition tasks, including spectrum sensing (SS), anomaly detection (AD), and wireless technology classification (WTC). Extensive experiments demonstrate the superiority of SpectrumFM over state-of-the-art methods. Specifically, it improves detection probability in the SS task by 30% at -4 dB signal-to-noise ratio (SNR), boosts the area under the curve (AUC) in the AD task by over 10%, and enhances WTC accuracy by 9.6%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02742v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chunyu Liu, Hao Zhang, Wei Wu, Fuhui Zhou, Qihui Wu, Derrick Wing Kwan Ng, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Extracting Range-Doppler Information of Moving Targets from Wi-Fi Channel State Information</title>
      <link>https://arxiv.org/abs/2508.02799</link>
      <description>arXiv:2508.02799v1 Announce Type: new 
Abstract: This paper presents, for the first time, a method to extract both range and Doppler information from commercial Wi-Fi Channel State Information (CSI) using a monostatic (single transceiver) setup. Utilizing the CSI phase in Wi-Fi sensing from a Network Interface Card (NIC) not designed for full-duplex operation is challenging due to (1) Hardware asynchronization, which introduces significant phase errors, and (2) Proximity of transmit (Tx) and receive (Rx) antennas, which creates strong coupling that overwhelms the motion signal of interest. We propose a new signal processing approach that addresses both challenges via three key innovations: Time offset cancellation, Phase alignment correction, and Tx/Rx coupling mitigation. Our method achieves cm-level accuracy in range and Doppler estimation for moving targets, validated using a commercial Intel Wi-Fi AX211 NIC. Our results show successful detection and tracking of moving objects in realistic environments, establishing the feasibility of high-precision sensing using standard Wi-Fi packet communications and off-the-shelf hardware without requiring any modification or specialized full-duplex capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02799v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jessica Sanson, Rahul C. Shah, Maximilian Pinaroc, Valerio Frascolla</dc:creator>
    </item>
    <item>
      <title>Integrating Machine Learning with Multimodal Monitoring System Utilizing Acoustic and Vision Sensing to Evaluate Geometric Variations in Laser Directed Energy Deposition</title>
      <link>https://arxiv.org/abs/2508.02847</link>
      <description>arXiv:2508.02847v1 Announce Type: new 
Abstract: Laser directed energy deposition (DED) additive manufacturing struggles with consistent part quality due to complex melt pool dynamics and process variations. While much research targets defect detection, little work has validated process monitoring systems for evaluating melt pool dynamics and process quality. This study presents a novel multimodal monitoring framework, synergistically integrating contact-based acoustic emission (AE) sensing with coaxial camera vision to enable layer-wise identification and evaluation of geometric variations in DED parts. The experimental study used three part configurations: a baseline part without holes, a part with a 3mm diameter through-hole, and one with a 5mm through-hole to test the system's discerning capabilities. Raw sensor data was preprocessed: acoustic signals were filtered for time-domain and frequency-domain feature extraction, while camera data underwent melt pool segmentation and morphological feature extraction. Multiple machine learning algorithms (including SVM, random forest, and XGBoost) were evaluated to find the optimal model for classifying layer-wise geometric variations. The integrated multimodal strategy achieved a superior classification performance of 94.4%, compared to 87.8% for AE only and 86.7% for the camera only. Validation confirmed the integrated system effectively captures both structural vibration signatures and surface morphological changes tied to the geometric variations. While this study focuses on specific geometries, the demonstrated capability to discriminate between features establishes a technical foundation for future applications in characterizing part variations like geometric inaccuracies and manufacturing-induced defects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02847v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.IV</category>
      <category>eess.SY</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Xu, Chaitanya Krishna Prasad Vallabh, Souran Manoochehri</dc:creator>
    </item>
    <item>
      <title>Secure mmWave Beamforming with Proactive-ISAC Defense Against Beam-Stealing Attacks</title>
      <link>https://arxiv.org/abs/2508.02856</link>
      <description>arXiv:2508.02856v1 Announce Type: new 
Abstract: Millimeter-wave (mmWave) communication systems face increasing susceptibility to advanced beam-stealing attacks, posing a significant physical layer security threat. This paper introduces a novel framework employing an advanced Deep Reinforcement Learning (DRL) agent for proactive and adaptive defense against these sophisticated attacks. A key innovation is leveraging Integrated Sensing and Communications (ISAC) capabilities for active, intelligent threat assessment. The DRL agent, built on a Proximal Policy Optimization (PPO) algorithm, dynamically controls ISAC probing actions to investigate suspicious activities. We introduce an intensive curriculum learning strategy that guarantees the agent experiences successful detection during training to overcome the complex exploration challenges inherent to such a security-critical task. Consequently, the agent learns a robust and adaptive policy that intelligently balances security and communication performance. Numerical results demonstrate that our framework achieves a mean attacker detection rate of 92.8% while maintaining an average user SINR of over 13 dB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02856v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seyed Bagher Hashemi Natanzi, Hossein Mohammadi, Bo Tang, Vuk Marojevic</dc:creator>
    </item>
    <item>
      <title>Zak-OTFS for Faster-Than-Nyquist Signaling in the Presence of Mobility &amp; Delay Spread</title>
      <link>https://arxiv.org/abs/2508.02950</link>
      <description>arXiv:2508.02950v1 Announce Type: new 
Abstract: Orthogonal signaling limits the number of information symbols transmitted in bandwidth $B$ and time $T$ to be $BT$. This corresponds to the Nyquist signaling and is achieved by mounting information symbols on $BT$-dimensional basis spanning the $BT$-dimensional space spaced $\frac{1}{B}$ and $\frac{1}{T}$ apart. Faster-than-Nyquist signaling involves transmitting more than $BT$ informational symbols in a $BT$-dimensional space. This leads to loss of orthogonality. This is achieved by time and/or bandwidth expansion resulting from packing more information symbols in the same $BT$-dimensional space (spacing less than $\frac{1}{B}$ and/or $\frac{1}{T}$). In this paper, we take a different approach to faster-than-Nyquist signaling. We propose to superimpose the information symbols on one another maintaining the original spacing in the Nyquist signaling. We carry this out in the delay-Doppler (DD) domain using Zak-transform based orthogonal time frequency space (Zak-OTFS) modulation. In Zak-OTFS, the channel varies slowly. Further Zak-OTFS also allows construction of mutually unbiased bases the interference between which appear like Gaussian noise. The proposed scheme leverages the slow variation in the DD channel to construct a precoder that mitigates the effect of the doubly-spread channel. Further, in the proposed scheme we mount information symbols on two mutually unbiased bases which allows superposition of information symbols. This simplifies receiver processing to detection in Gaussian noise since each basis appears to the other as Gaussian noise. This reduction makes it possible to use trellis coded modulation to enhance bit-error performance. Numerical results demonstrate that the faster-than-Nyquist signaling scheme achieves similar uncoded performance as that of Nyquist signaling and with coding the performance is better than Nyquist signaling at high signal-to-noise ratios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02950v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandesh Rao Mattu, Nishant Mehrotra, Robert Calderbank</dc:creator>
    </item>
    <item>
      <title>Generating Light-based Fingerprints for Indoor Localization</title>
      <link>https://arxiv.org/abs/2508.03011</link>
      <description>arXiv:2508.03011v1 Announce Type: new 
Abstract: Accurate indoor localization underpins applications ranging from wayfinding and emergency response to asset tracking and smart-building services. Radio-frequency solutions (e.g. Wi-Fi, RFID, UWB) are widely adopted but remain vulnerable to multipath fading, interference, and uncontrollable coverage variation. We explore an orthogonal modality -- visible light communication (VLC) -- and demonstrate that the spectral signatures captured by a low-cost AS7341 sensor can serve as robust location fingerprints.
  We introduce a two-stage framework that (i) trains a multi-layer perceptron (MLP) on real spectral measurements and (ii) enlarges the training corpus with synthetic samples produced by TabGAN. The augmented dataset reduces the mean localization error from 62.9cm to 49.3cm -- a 20% improvement -- while requiring only 5% additional data-collection effort. Experimental results obtained on 42 reference points in a U-shaped laboratory confirm that GAN-based augmentation mitigates data-scarcity issues and enhances generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03011v1</guid>
      <category>eess.SP</category>
      <category>cs.RO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hsun-Yu Lee, Jie Lin, Fang-Jing Wu</dc:creator>
    </item>
    <item>
      <title>Metasurface-Enabled Extremely Large-Scale Antenna Systems: Transceiver Architecture, Physical Modeling, and Channel Estimation</title>
      <link>https://arxiv.org/abs/2508.03021</link>
      <description>arXiv:2508.03021v1 Announce Type: new 
Abstract: Extremely large-scale antenna arrays (ELAAs) have emerged as a pivotal technology for addressing the unprecedented performance demands of next-generation wireless communication systems. To enhance their practicality, we propose metasurface-enabled extremely large-scale antenna (MELA) systems -- novel transceiver architectures that employ reconfigurable transmissive metasurfaces to facilitate efficient over-the-air RF-to-antenna coupling and phase control. This architecture eliminates the need for bulky switch matrices and costly phase-shifter networks typically required in conventional solutions. Physically grounded models are developed to characterize electromagnetic field propagation through individual transmissive unit cells, capturing the fundamental physics of wave transformation and transmission. Additionally, distance-dependent approximate models are introduced, exhibiting structural properties conducive to efficient parameter estimation and signal processing. Based on the channel model, a two stage channel estimation framework is proposed for the scenarios comprising users in the hybrid near- and far-fields. In the first stage, a dictionary-driven beamspace filtering technique enables rapid angular-domain scanning. In the refinement stage, the rotational symmetry of subarrays is exploited to design super-resolution estimators that jointly recover angular and range parameters. An analytical expression for the half-power beamwidth of MELA is derived, revealing its near-optimal spatial resolution relative to conventional ELAA architectures. Numerical experiments further validate the high-resolution of the proposed channel estimation algorithm and the fidelity of the electromagnetic model, positioning the MELA architecture as a highly competitive and forward-looking solution for practical ELAA deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03021v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengyu Wang, Tiebin Mi, Gui Zhou, Robert C. Qiu</dc:creator>
    </item>
    <item>
      <title>Scenario-Agnostic Deep-Learning-Based Localization with Contrastive Self-Supervised Pre-training</title>
      <link>https://arxiv.org/abs/2508.03084</link>
      <description>arXiv:2508.03084v1 Announce Type: new 
Abstract: Wireless localization has become a promising technology for offering intelligent location-based services. Although its localization accuracy is improved under specific scenarios, the short of environmental dynamic vulnerability still hinders this approach from being fully practical applications. In this paper, we propose CSSLoc, a novel framework on contrastive self-supervised pre-training to learn generic representations for accurate localization in various scenarios. Without the location information supervision, CSSLoc attempts to learn an insightful metric on the similarity discrimination of radio data, in such a scenario-agnostic manner that the similar samples are closely clustered together and different samples are separated in the representation space. Furthermore, the trained feature encoder can be directly transferred for downstream localization tasks, and the location predictor is trained to estimate accurate locations with the robustness of environmental dynamics. With extensive experimental results, CSSLoc can outperform classical and state-of-the-art DNN-based localization schemes in typical indoor scenarios, pushing deep-learning-based localization from specificity to generality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03084v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lingyan Zhang, Yuanfeng Qiu, Dachuan Li, Shaohua Wu, Tingting Zhang, Qinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Can Large Language Models Identify Materials from Radar Signals?</title>
      <link>https://arxiv.org/abs/2508.03120</link>
      <description>arXiv:2508.03120v1 Announce Type: new 
Abstract: Accurately identifying the material composition of objects is a critical capability for AI robots powered by large language models (LLMs) to perform context-aware manipulation. Radar technologies offer a promising sensing modality for material recognition task. When combined with deep learning, radar technologies have demonstrated strong potential in identifying the material of various objects. However, existing radar-based solutions are often constrained to closed-set object categories and typically require task-specific data collection to train deep learning models, largely limiting their practical applicability. This raises an important question: Can we leverage the powerful reasoning capabilities of pre-trained LLMs to directly infer material composition from raw radar signals? Answering this question is non-trivial due to the inherent redundancy of radar signals and the fact that pre-trained LLMs have no prior exposure to raw radar data during training. To address this, we introduce LLMaterial, the first study to investigate the feasibility of using LLM to identify materials directly from radar signals. First, we introduce a physics-informed signal processing pipeline that distills high-redundancy radar raw data into a set of compact intermediate parameters that encapsulate the material's intrinsic characteristics. Second, we adopt a retrieval-augmented generation (RAG) strategy to provide the LLM with domain-specific knowledge, enabling it to interpret and reason over the extracted intermediate parameters. Leveraging this integration, the LLM is empowered to perform step-by-step reasoning on the condensed radar features, achieving open-set material recognition directly from raw radar signals. Preliminary results show that LLMaterial can effectively distinguish among a variety of common materials, highlighting its strong potential for real-world material identification applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03120v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3714394.3756289</arxiv:DOI>
      <dc:creator>Jiangyou Zhu, Hongyu Deng, He Chen</dc:creator>
    </item>
    <item>
      <title>Model Order Reduction for Large-scale Circuits Using Higher Order Dynamic Mode Decomposition</title>
      <link>https://arxiv.org/abs/2508.03131</link>
      <description>arXiv:2508.03131v1 Announce Type: new 
Abstract: Model order reduction (MOR) has long been a mainstream strategy to accelerate large-scale transient circuit simulation. Dynamic Mode Decomposition (DMD) represents a novel data-driven characterization method, extracting dominant dynamical modes directly from time-domain simulation data without requiring explicit system equations. This paper first deduces the DMD algorithm and then proposes high order dynamic mode decomposition (HODMD) incorporating delayed embedding technique, specifically targeting computational efficiency in large-scale circuit simulations. Compared with the DMD method, the HODMD method overcomes the problem that the output signal cannot be reconstructed when the spatial resolution is insufficient. The proposed HODMD algorithm is applicable to general circuits and does not impose any constraints on the topology of the pertinent circuit or type of the components. Three representative numerical test cases are presented to systematically validate both the computational efficiency and accuracy of the proposed HODMD method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03131v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Na Liu, Chengliang Dai, Qiuyue Wu, Qiuqi Li, Guoxiong Cai</dc:creator>
    </item>
    <item>
      <title>Federated Learning with Feature Reconstruction for Vector Quantization based Semantic Communication</title>
      <link>https://arxiv.org/abs/2508.03248</link>
      <description>arXiv:2508.03248v1 Announce Type: new 
Abstract: Recent advancements in semantic communication have primarily focused on image transmission, where neural network (NN)-based joint source-channel coding (JSCC) modules play a central role. However, such systems often experience semantic communication errors due to mismatched knowledge bases between users and performance degradation from outdated models, necessitating regular model updates. To address these challenges in vector quantization (VQ)-based image semantic communication systems, we propose FedSFR, a novel federated learning (FL) framework that incorporates semantic feature reconstruction (FR). FedSFR introduces an FR step at the parameter server (PS) and allows a subset of clients to transmit compact feature vectors in lieu of sending full local model updates, thereby improving training stability and communication efficiency. To enable effective FR learning, we design a loss function tailored for VQ-based image semantic communication and demonstrate its validity as a surrogate for image reconstruction error. Additionally, we provide a rigorous convergence analysis and present a differentially private variant of FedSFR, along with formal privacy analysis. Experimental results on two benchmark datasets validate the superiority of FedSFR over existing baselines, especially in capacity-constrained settings, confirming both its effectiveness and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03248v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoon Huh, Bumjun Kim, Wan Choi</dc:creator>
    </item>
    <item>
      <title>Investigating the Cognitive Response of Brake Lights in Initiating Braking Action Using EEG</title>
      <link>https://arxiv.org/abs/2508.03274</link>
      <description>arXiv:2508.03274v1 Announce Type: new 
Abstract: Half of all road accidents result from either lack of driver attention or from maintaining insufficient separation between vehicles. Collision from the rear, in particular, has been identified as the most common class of accident in the UK, and its influencing factors have been widely studied for many years. Rear-mounted stop lamps, illuminated when braking, are the primary mechanism to alert following drivers to the need to reduce speed or brake. This paper develops a novel brain response approach to measuring subject reaction to different brake light designs. A variety of off-the-shelf brake light assemblies are tested in a physical simulated driving environment to assess the cognitive reaction times of 22 subjects. Eight pairs of LED-based and two pairs of incandescent bulb-based brake light assemblies are used and electroencephalogram (EEG) data recorded. Channel Pz is utilised to extract the P3 component evoked during the decision making process that occurs in the brain when a participant decides to lift their foot from the accelerator and depress the brake. EEG analysis shows that both incandescent bulb-based lights are statistically slower to evoke cognitive responses than all tested LED-based lights. Between the LED designs, differences are evident, but not statistically significant, attributed to the significant amount of movement artifact in the EEG signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03274v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TITS.2021.3091291</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Intelligent Transportation Systems Aug 2022</arxiv:journal_reference>
      <dc:creator>Ramaswamy Palaniappan, Surej Mouli, Howard Bowman, Ian McLoughlin</dc:creator>
    </item>
    <item>
      <title>Spiking Neural Networks for Resource Allocation in UAV-Enabled Wireless Networks</title>
      <link>https://arxiv.org/abs/2508.03279</link>
      <description>arXiv:2508.03279v1 Announce Type: new 
Abstract: This work presents a new spiking neural network (SNN)-based approach for user equipment-base station (UE-BS) association in non-terrestrial networks (NTNs). With the introduction of UAV's in wireless networks, the system architecture becomes heterogeneous, resulting in the need for dynamic and efficient management to avoid congestion and sustain overall performance. The presented framework compares two SNN-based optimization strategies. Specifically, a top-down centralized approach with complete network visibility and a bottom-up distributed approach for individual network nodes. The SNN is based on leak integrate-and-fire neurons with temporal components, which can perform fast and efficient event-driven inference. Realistic ray-tracing simulations are conducted, which showcase that the bottom-up model attains over 90\% accuracy, while the top-down model maintains 80-100\% accuracy. Both approaches reveal a trade-off between individually optimal solutions and UE-BS association feasibility, thus revealing the effectiveness of both approaches depending on deployment scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03279v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasileios Kouvakis, Stylianos E. Trevlakis, Ioannis Arapakis, Alexandros-Apostolos A. Boulogeorgos</dc:creator>
    </item>
    <item>
      <title>Quantum Deep Learning for Massive MIMO User Scheduling</title>
      <link>https://arxiv.org/abs/2508.03327</link>
      <description>arXiv:2508.03327v1 Announce Type: new 
Abstract: We introduce a hybrid Quantum Neural Networks (QNN) architecture for the efficient user scheduling in 5G/Beyond 5G (B5G) massive Multiple Input Multiple Output (MIMO) systems, addressing the scalability issues of traditional methods. By leveraging statistical Channel State Information (CSI), our model reduces computational overhead and enhances spectral efficiency. It integrates classical neural networks with a variational quantum circuit kernel, outperforming classical Convolutional Neural Networks (CNNs) and maintaining robust performance in noisy channels. This demonstrates the potential of quantum-enhanced Machine Learning (ML) for wireless scheduling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03327v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingyu Huang, Ruining Fan, Mouli Chakraborty, Avishek Nag, Anshu Mukherjee</dc:creator>
    </item>
    <item>
      <title>Beam-Hopping Pattern Design for Grant-Free Random Access in LEO Satellite Communications</title>
      <link>https://arxiv.org/abs/2508.03391</link>
      <description>arXiv:2508.03391v1 Announce Type: new 
Abstract: Increasing demand for massive device connectivity in underserved regions drives the development of advanced low Earth orbit (LEO) satellite communication systems. Beam-hopping LEO systems without connection establishment provide a promising solution for achieving both demand-aware resource allocation and low access latency. This paper investigates beam-hopping pattern design for the grant-free random access systems to dynamically allocate satellite resources according to traffic demands across serving cells. We formulate a binary optimization problem that aims to maximize the minimum successful transmission probability across cells, given limited satellite beam generation capacity. To solve this problem, we propose novel beam-hopping design algorithms that alternately enhance the collision avoidance rate and decoding success probability within an alternating optimization framework. Specifically, the algorithms employ a bisection method to optimize illumination allocation for each cell based on demand, while using the alternating direction method of multipliers (ADMM) to optimize beam-hopping patterns for maximizing decoding success probability. Furthermore, we enhance the ADMM by replacing the strict binary constraint with two equivalent continuous-valued constraints. Simulation results demonstrate the superiority of the proposed algorithms compared to other beam-hopping methods and verify robustness in managing traffic demand imbalance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03391v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seunghyeon Jeon, Seonjung Kim, Gyeongrae Im, Yo-Seb Jeon</dc:creator>
    </item>
    <item>
      <title>How to Proactively Monitor Untrusted Communications with Cell-Free Massive MIMO?</title>
      <link>https://arxiv.org/abs/2508.03423</link>
      <description>arXiv:2508.03423v1 Announce Type: new 
Abstract: This paper studies a cell-free massive multiple-input multiple-output (CF-mMIMO) proactive monitoring system in which multiple multi-antenna monitoring nodes (MNs) are assigned to either observe the transmissions from an untrusted transmitter (UT) or to jam the reception at the untrusted receiver (UR). We propose an effective channel state information (CSI) acquisition scheme for the monitoring system. In our approach, the MNs leverage the pilot signals transmitted during the uplink and downlink phases of the untrusted link and estimate the effective channels corresponding to the UT and UR via a minimum mean-squared error (MMSE) estimation scheme. We derive new spectral efficiency (SE) expressions for the untrusted link and the monitoring system. For the latter, the SE is derived for two CSI availability cases at the central processing unit (CPU); namely case-1: imperfect CSI knowledge at both MNs and CPU, case-2: imperfect CSI knowledge at the MNs and no CSI knowledge at the CPU. To improve the monitoring performance, we propose a novel joint mode assignment and jamming power control optimization method to maximize the monitoring success probability (MSP) based on the Bayesian optimization framework. Numerical results show that (a) our CF-mMIMO proactive monitoring system relying on the proposed CSI acquisition and optimization approach significantly outperforms the considered benchmarks; (b) the MSP performance of our CF-mMIMO proactive monitoring system is greater than 0.8, regardless of the number of antennas at the untrusted nodes or the precoding scheme for the untrusted transmission link.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03423v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2025.3596456</arxiv:DOI>
      <dc:creator>Isabella W. G. da Silva, Zahra Mobini, Hien Q. Ngo, Hyundong Shin, Michail Matthaiou</dc:creator>
    </item>
    <item>
      <title>Joint Sensing and Bi-Directional Communication with Dynamic TDD Enabled Cell-Free MIMO</title>
      <link>https://arxiv.org/abs/2508.03460</link>
      <description>arXiv:2508.03460v1 Announce Type: new 
Abstract: This paper studies integrated sensing and communication (ISAC) with dynamic time division duplex (DTDD) cell-free (CF) massive multiple-input multiple-output~(mMIMO) systems. DTDD enables the CF mMIMO system to concurrently serve both uplink~(UL) and downlink~(DL) users with spatially separated \emph{half-duplex~(HD)} access points~(APs) using the same time-frequency resources. Further, to facilitate ISAC, the UL APs are utilized for both UL data and target echo reception, while the DL APs jointly transmit the precoded DL data streams and target signal. In this context, we present centralized and distributed generalized likelihood-ratio tests~(GLRTs) for target detection treating UL users' signals as sensing interference. We then quantify the optimality and complexity trade-off between distributed and centralized GLRTs and benchmark the respective estimators with the Bayesian Cram\'er-Rao lower bound for target radar-cross section~(RCS). Then, we present a unified framework for joint UL users' data detection and RCS estimation. Next, for communication, we derive the signal-to-noise-plus-interference~(SINR) optimal combiner accounting for the cross-link and radar interference for UL data processing. In DL, we use regularized zero-forcing for the users and propose two types of precoders for the target: one ``user-centric" that nullifies the interference caused by the target signal to the DL users and one ``target-centric" based on the dominant eigenvector of the composite channel between the target and the APs. Finally, numerical studies corroborate with our theoretical findings and reveal that the \emph{GLRT is robust to inter-AP interference, and DTDD doubles the $90\%$-likely sum UL-DL SE compared to traditional TDD-based CF-mMIMO ISAC systems}; while using HD hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03460v1</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anubhab Chowdhury, Sai Subramanyam Thoota, Erik G. Larsson</dc:creator>
    </item>
    <item>
      <title>Decoding and Engineering the Phytobiome Communication for Smart Agriculture</title>
      <link>https://arxiv.org/abs/2508.03584</link>
      <description>arXiv:2508.03584v1 Announce Type: new 
Abstract: Smart agriculture applications, integrating technologies like the Internet of Things and machine learning/artificial intelligence (ML/AI) into agriculture, hold promise to address modern challenges of rising food demand, environmental pollution, and water scarcity. Alongside the concept of the phytobiome, which defines the area including the plant, its environment, and associated organisms, and the recent emergence of molecular communication (MC), there exists an important opportunity to advance agricultural science and practice using communication theory. In this article, we motivate to use the communication engineering perspective for developing a holistic understanding of the phytobiome communication and bridge the gap between the phytobiome communication and smart agriculture. Firstly, an overview of phytobiome communication via molecular and electrophysiological signals is presented and a multi-scale framework modeling the phytobiome as a communication network is conceptualized. Then, how this framework is used to model electrophysiological signals is demonstrated with plant experiments. Furthermore, possible smart agriculture applications, such as smart irrigation and targeted delivery of agrochemicals, through engineering the phytobiome communication are proposed. These applications merge ML/AI methods with the Internet of Bio-Nano-Things enabled by MC and pave the way towards more efficient, sustainable, and eco-friendly agricultural production. Finally, the implementation challenges, open research issues, and industrial outlook for these applications are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03584v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>q-bio.MN</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatih Gulec, Hamdan Awan, Nigel Wallbridge, Andrew W. Eckford</dc:creator>
    </item>
    <item>
      <title>MPCA-based Domain Adaptation for Transfer Learning in Ultrasonic Guided Waves</title>
      <link>https://arxiv.org/abs/2508.02726</link>
      <description>arXiv:2508.02726v1 Announce Type: cross 
Abstract: Ultrasonic Guided Waves (UGWs) represent a promising diagnostic tool for Structural Health Monitoring (SHM) in thin-walled structures, and their integration with machine learning (ML) algorithms is increasingly being adopted to enable real-time monitoring capabilities. However, the large-scale deployment of UGW-based ML methods is constrained by data scarcity and limited generalisation across different materials and sensor configurations. To address these limitations, this work proposes a novel transfer learning (TL) framework based on Multilinear Principal Component Analysis (MPCA). First, a Convolutional Neural Network (CNN) for regression is trained to perform damage localisation for a plated structure. Then, MPCA and fine-tuning are combined to have the CNN work for a different plate. By jointly applying MPCA to the source and target domains, the method extracts shared latent features, enabling effective domain adaptation without requiring prior assumptions about dimensionality. Following MPCA, fine-tuning enables adapting the pre-trained CNN to a new domain without the need for a large training dataset. The proposed MPCA-based TL method was tested against 12 case studies involving different composite materials and sensor arrays. Statistical metrics were used to assess domains alignment both before and after MPCA, and the results demonstrate a substantial reduction in localisation error compared to standard TL techniques. Hence, the proposed approach emerges as a robust, data-efficient, and statistically based TL framework for UGW-based SHM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02726v1</guid>
      <category>eess.IV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucio Pinello, Francesco Cadini, Luca Lomazzi</dc:creator>
    </item>
    <item>
      <title>Real-World Receptivity to Adaptive Mental Health Interventions: Findings from an In-the-Wild Study</title>
      <link>https://arxiv.org/abs/2508.02817</link>
      <description>arXiv:2508.02817v1 Announce Type: cross 
Abstract: The rise of mobile health (mHealth) technologies has enabled real-time monitoring and intervention for mental health conditions using passively sensed smartphone data. Building on these capabilities, Just-in-Time Adaptive Interventions (JITAIs) seek to deliver personalized support at opportune moments, adapting to users' evolving contexts and needs. Although prior research has examined how context affects user responses to generic notifications and general mHealth messages, relatively little work has explored its influence on engagement with actual mental health interventions. Furthermore, while much of the existing research has focused on detecting when users might benefit from an intervention, less attention has been paid to understanding receptivity, i.e., users' willingness and ability to engage with and act upon the intervention.
  In this study, we investigate user receptivity through two components: acceptance(acknowledging or engaging with a prompt) and feasibility (ability to act given situational constraints). We conducted a two-week in-the-wild study with 70 students using a custom Android app, LogMe, which collected passive sensor data and active context reports to prompt mental health interventions. The adaptive intervention module was built using Thompson Sampling, a reinforcement learning algorithm. We address four research questions relating smartphone features and self-reported contexts to acceptance and feasibility, and examine whether an adaptive reinforcement learning approach can optimize intervention delivery by maximizing a combined receptivity reward. Our results show that several types of passively sensed data significantly influenced user receptivity to interventions. Our findings contribute insights into the design of context-aware, adaptive interventions that are not only timely but also actionable in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02817v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nilesh Kumar Sahu, Aditya Sneh, Snehil Gupta, Haroon R Lone</dc:creator>
    </item>
    <item>
      <title>Spatial-Temporal-Spectral Mamba with Sparse Deformable Token Sequence for Enhanced MODIS Time Series Classification</title>
      <link>https://arxiv.org/abs/2508.02839</link>
      <description>arXiv:2508.02839v1 Announce Type: cross 
Abstract: Although MODIS time series data are critical for supporting dynamic, large-scale land cover land use classification, it is a challenging task to capture the subtle class signature information due to key MODIS difficulties, e.g., high temporal dimensionality, mixed pixels, and spatial-temporal-spectral coupling effect. This paper presents a novel spatial-temporal-spectral Mamba (STSMamba) with deformable token sequence for enhanced MODIS time series classification, with the following key contributions. First, to disentangle temporal-spectral feature coupling, a temporal grouped stem (TGS) module is designed for initial feature learning. Second, to improve Mamba modeling efficiency and accuracy, a sparse, deformable Mamba sequencing (SDMS) approach is designed, which can reduce the potential information redundancy in Mamba sequence and improve the adaptability and learnability of the Mamba sequencing. Third, based on SDMS, to improve feature learning, a novel spatial-temporal-spectral Mamba architecture is designed, leading to three modules, i.e., a sparse deformable spatial Mamba module (SDSpaM), a sparse deformable spectral Mamba module (SDSpeM), and a sparse deformable temporal Mamba module (SDTM) to explicitly learn key information sources in MODIS. The proposed approach is tested on MODIS time series data in comparison with many state-of-the-art approaches, and the results demonstrate that the proposed approach can achieve higher classification accuracy with reduced computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02839v1</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zack Dewis, Zhengsen Xu, Yimin Zhu, Motasem Alkayid, Mabel Heffring, Lincoln Linlin Xu</dc:creator>
    </item>
    <item>
      <title>Channel Coding for Unequal Error Protection in Digital Semantic Communication</title>
      <link>https://arxiv.org/abs/2508.03381</link>
      <description>arXiv:2508.03381v1 Announce Type: cross 
Abstract: Semantic communication is an emerging paradigm that prioritizes transmitting task-relevant information over accurately delivering raw data bits. In this paper, we address an unequal error protection (UEP) problem in digital semantic communication, where bits of higher semantic importance require stronger protection. To quantify bit-level importance, we leverage bit-flip probabilities of semantic bits as target error protection levels, which are jointly learned with semantic encoder and decoder. We propose two novel channel coding frameworks aimed at minimizing the total blocklength while satisfying UEP constraints. First, we develop a bit-level UEP framework based on repetition coding, in which the repetition number for each bit is optimized to precisely meet its target bit-flip probability. Second, we introduce a block-level UEP framework utilizing modern channel codes, where semantic bits with similar target bit-flip probabilities are grouped to exploit coding gains. Within this framework, we propose a bit-grouping algorithm guided by finite blocklength capacity analysis. Simulation results conducted on image transmission tasks confirm that the proposed frameworks significantly outperform conventional approaches, yielding substantial improvements in both task performance and transmission efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03381v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonjung Kim, Yongjeong Oh, Yongjune Kim, Namyoon Lee, Yo-Seb Jeon</dc:creator>
    </item>
    <item>
      <title>What If, But Privately: Private Counterfactual Retrieval</title>
      <link>https://arxiv.org/abs/2508.03681</link>
      <description>arXiv:2508.03681v1 Announce Type: cross 
Abstract: Transparency and explainability are two important aspects to be considered when employing black-box machine learning models in high-stake applications. Providing counterfactual explanations is one way of catering this requirement. However, this also poses a threat to the privacy of the institution that is providing the explanation, as well as the user who is requesting it. In this work, we are primarily concerned with the user's privacy who wants to retrieve a counterfactual instance, without revealing their feature vector to the institution. Our framework retrieves the exact nearest neighbor counterfactual explanation from a database of accepted points while achieving perfect, information-theoretic, privacy for the user. First, we introduce the problem of private counterfactual retrieval (PCR) and propose a baseline PCR scheme that keeps the user's feature vector information-theoretically private from the institution. Building on this, we propose two other schemes that reduce the amount of information leaked about the institution database to the user, compared to the baseline scheme. Second, we relax the assumption of mutability of all features, and consider the setting of immutable PCR (I-PCR). Here, the user retrieves the nearest counterfactual without altering a private subset of their features, which constitutes the immutable set, while keeping their feature vector and immutable set private from the institution. For this, we propose two schemes that preserve the user's privacy information-theoretically, but ensure varying degrees of database privacy. Third, we extend our PCR and I-PCR schemes to incorporate user's preference on transforming their attributes, so that a more actionable explanation can be received. Finally, we present numerical results to support our theoretical findings, and compare the database leakage of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03681v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreya Meel, Mohamed Nomeir, Pasan Dissanayake, Sanghamitra Dutta, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>AI-driven Wireless Positioning: Fundamentals, Standards, State-of-the-art, and Challenges</title>
      <link>https://arxiv.org/abs/2501.14970</link>
      <description>arXiv:2501.14970v2 Announce Type: replace 
Abstract: Wireless positioning technologies hold significant value for applications in autonomous driving, extended reality (XR), unmanned aerial vehicles (UAVs), and more. With the advancement of artificial intelligence (AI), leveraging AI to enhance positioning accuracy and robustness has emerged as a field full of potential. Driven by the requirements and functionalities defined in the 3rd Generation Partnership Project (3GPP) standards, AI/machine learning (ML)-based cellular positioning is becoming a key technology to overcome the limitations of traditional methods. This paper presents a comprehensive survey of AI-driven cellular positioning. We begin by reviewing the fundamentals of wireless positioning and AI models, analyzing their respective challenges and synergies. We provide a comprehensive review of the evolution of 3GPP positioning standards, with a focus on the integration of AI/ML in current and upcoming standard releases. Guided by the 3GPP-defined taxonomy, we categorize and summarize state-of-the-art (SOTA) research into two major classes: AI/ML-assisted positioning and direct AI/ML-based positioning. The former includes line-of-sight (LOS)/non-line-of-sight (NLOS) detection, time of arrival (TOA)/time difference of arrival (TDOA) estimation, and angle prediction; the latter encompasses fingerprinting, knowledge-assisted learning, and channel charting. Furthermore, we review representative public datasets and conduct performance evaluations of AI-based positioning algorithms using these datasets. Finally, we conclude by summarizing the challenges and opportunities of AI-driven wireless positioning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14970v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangjin Pan, Yuan Gao, Yilin Gao, Wenjun Yu, Zhiyong Zhong, Xiaoyu Yang, Xinyu Guo, Shugong Xu</dc:creator>
    </item>
    <item>
      <title>Millimeter-Wave Communication Testbed Using Digital Coding Dynamic Metasurface Antenna: Practical Design and Implementation</title>
      <link>https://arxiv.org/abs/2502.13705</link>
      <description>arXiv:2502.13705v2 Announce Type: replace 
Abstract: Dynamic Metasurface Antennas (DMAs) are transforming reconfigurable antenna technology by enabling energy-efficient, cost-effective beamforming through programmable meta-elements, eliminating the need for traditional phase shifters and delay lines. This breakthrough technology is emerging to revolutionize beamforming for next-generation wireless communication and sensing networks. In this paper, we present the design and real-world implementation of a DMA-assisted wireless communication platform operating in the license-free 60 GHz millimeter-wave (mmWave) band. Our system employs high-speed binary-coded sequences generated via a field-programmable gate array (FPGA), enabling real-time beam steering for spatial multiplexing and independent data transmission. A proof-of-concept experiment successfully demonstrates high-definition quadrature phase-shift keying (QPSK) modulated video transmission at 62 GHz. Furthermore, leveraging the DMA's multi-beam capability, we simultaneously transmit video to two spatially separated receivers, achieving accurate demodulation. We envision the proposed mmWave testbed as a platform for enabling the seamless integration of sensing and communication by allowing video transmission to be replaced with sensing data or utilizing an auxiliary wireless channel to transmit sensing information to multiple receivers. This synergy paves the way for advancing integrated sensing and communication (ISAC) in beyond-5G and 6G networks. Additionally, our testbed demonstrates potential for real-world use cases, including mmWave backhaul links and massive multiple-input multiple-output (MIMO) mmWave base stations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13705v2</guid>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul Jabbar, Mostafa Elsayed, Jalil Ur-Rehman Kazim, Zhibo Pang, Julien Le Kernec, Muhammad Imran, Hadi Larijani, Masood Ur-Rehman, Qammer Abbasi, Muhammad Usman</dc:creator>
    </item>
    <item>
      <title>Detection of Intelligent Tampering in Wireless Electrocardiogram Signals Using Hybrid Machine Learning</title>
      <link>https://arxiv.org/abs/2507.06402</link>
      <description>arXiv:2507.06402v2 Announce Type: replace-cross 
Abstract: With the proliferation of wireless electrocardiogram (ECG) systems for health monitoring and authentication, protecting signal integrity against tampering is becoming increasingly important. This paper analyzes the performance of CNN, ResNet, and hybrid Transformer-CNN models for tamper detection. It also evaluates the performance of a Siamese network for ECG based identity verification. Six tampering strategies, including structured segment substitutions and random insertions, are emulated to mimic real world attacks. The one-dimensional ECG signals are transformed into a two dimensional representation in the time frequency domain using the continuous wavelet transform (CWT). The models are trained and evaluated using ECG data from 54 subjects recorded in four sessions 2019 to 2025 outside of clinical settings while the subjects performed seven different daily activities. Experimental results show that in highly fragmented manipulation scenarios, CNN, FeatCNN-TranCNN, FeatCNN-Tran and ResNet models achieved an accuracy exceeding 99.5 percent . Similarly, for subtle manipulations (for example, 50 percent from A and 50 percent from B and, 75 percent from A and 25 percent from B substitutions) our FeatCNN-TranCNN model demonstrated consistently reliable performance, achieving an average accuracy of 98 percent . For identity verification, the pure Transformer-Siamese network achieved an average accuracy of 98.30 percent . In contrast, the hybrid CNN-Transformer Siamese model delivered perfect verification performance with 100 percent accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06402v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhant Deshpande, Yalemzerf Getnet, Waltenegus Dargie</dc:creator>
    </item>
    <item>
      <title>SemiSegECG: A Multi-Dataset Benchmark for Semi-Supervised Semantic Segmentation in ECG Delineation</title>
      <link>https://arxiv.org/abs/2507.18323</link>
      <description>arXiv:2507.18323v2 Announce Type: replace-cross 
Abstract: Electrocardiogram (ECG) delineation, the segmentation of meaningful waveform features, is critical for clinical diagnosis. Despite recent advances using deep learning, progress has been limited by the scarcity of publicly available annotated datasets. Semi-supervised learning presents a promising solution by leveraging abundant unlabeled ECG data. In this study, we present SemiSegECG, the first systematic benchmark for semi-supervised semantic segmentation (SemiSeg) in ECG delineation. We curated and unified multiple public datasets, including previously underused sources, to support robust and diverse evaluation. We adopted five representative SemiSeg algorithms from computer vision, implemented them on two different architectures: the convolutional network and the transformer, and evaluated them in two different settings: in-domain and cross-domain. Additionally, we propose ECG-specific training configurations and augmentation strategies and introduce a standardized evaluation framework. Our results show that the transformer outperforms the convolutional network in semi-supervised ECG delineation. We anticipate that SemiSegECG will serve as a foundation for advancing semi-supervised ECG delineation methods and will facilitate further research in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18323v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minje Park, Jeonghwa Lim, Taehyung Yu, Sunghoon Joo</dc:creator>
    </item>
  </channel>
</rss>
