<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Feb 2026 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable Fair Influence Blocking Maximization via Approximately Monotonic Submodular Optimization</title>
      <link>https://arxiv.org/abs/2601.22584</link>
      <description>arXiv:2601.22584v1 Announce Type: new 
Abstract: Influence Blocking Maximization (IBM) aims to select a positive seed set to suppress the spread of negative influence. However, existing IBM methods focus solely on maximizing blocking effectiveness, overlooking fairness across communities. To address this issue, we formalize fairness in IBM and justify Demographic Parity (DP) as a notion that is particularly well aligned with its semantics. Yet enforcing DP is computationally challenging: prior work typically formulates DP as a Linear Programming (LP) problem and relies on costly solvers, rendering them impractical for large-scale networks. In this paper, we propose a DP-aware objective while maintaining an approximately monotonic submodular structure, enabling efficient optimization with theoretical guarantees. We integrate this objective with blocking effectiveness through a tunable scalarization, yielding a principled fairness-effectiveness trade-offs. Building on this structure, we develop CELF-R, an accelerated seed selection algorithm that exploits approximate submodularity to eliminate redundant evaluations and naturally supports Pareto front construction. Extensive experiments demonstrate that CELF-R consistently outperforms state-of-the-art baselines, achieving a $(1-1/e-\psi)$-approximate solution while maintaining high efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22584v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiangpeng Fang, Jilong Shi, Xiaobin Rui, Jian Zhang, Zhixiao Wang</dc:creator>
    </item>
    <item>
      <title>Competitive Non-Clairvoyant KV-Cache Scheduling for LLM Inference</title>
      <link>https://arxiv.org/abs/2601.22996</link>
      <description>arXiv:2601.22996v1 Announce Type: new 
Abstract: Large Language Model (LLM) inference presents a unique scheduling challenge due to the Key-Value (KV) cache, where a job's memory footprint grows linearly with the number of decoded tokens. This growth couples scheduling decisions with feasibility: a scheduler must minimize latency under a hard memory budget, yet the response lengths of requests are inherently unknown. While recent works have explored this problem either assuming clairvoyance -- exact knowledge of response lengths -- or relying on machine-learned predictions, obtaining robust performance guarantees without any prior knowledge of job sizes remains a theoretically fundamental and practically important open problem.
  In this work, we propose the Geometric Slicing Algorithm (GSA), the non-clairvoyant policy to achieve the first constant competitive ratio for this problem in the offline batch setting. GSA manages uncertainty through a geometric phase structure that periodically restarts jobs to bound memory exposure, combined with a staggered pipeline mechanism that enables high concurrency by smoothing aggregate memory consumption. We prove that GSA achieves a competitive ratio of at most 61.92 for general instances, improving to 32 in the large-memory regime. Our algorithmic framework also yields a clairvoyant counterpart, the Geometric Batching Algorithm (GBA), which achieves an approximation ratio of 10.67 for general instances and 6.75 in the large-memory regime -- significantly improving upon the best previously known bound of over 9000. Numerical experiments on real request traces demonstrate that our algorithms perform robustly while preserving these worst-case guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22996v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiding Feng, Zonghan Yang, Yuhao Zhang</dc:creator>
    </item>
    <item>
      <title>Compressed Set Representations based on Set Difference</title>
      <link>https://arxiv.org/abs/2601.23240</link>
      <description>arXiv:2601.23240v1 Announce Type: new 
Abstract: We introduce a compressed representation of sets of sets that exploits how much they differ from each other. Our representation supports access, membership, predecessor and successor queries on the sets within logarithmic time. In addition, we give a new MST-based construction algorithm for the representation that outperforms standard ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.23240v1</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie, Meng He, Gonzalo Navarro</dc:creator>
    </item>
    <item>
      <title>COL-Trees: Efficient Hierarchical Object Search in Road Networks</title>
      <link>https://arxiv.org/abs/2601.22183</link>
      <description>arXiv:2601.22183v1 Announce Type: cross 
Abstract: Location-based services rely heavily on efficient methods that search for relevant points-of-interest (POIs) near a given location. A k Nearest Neighbor (kNN) query is one such example that finds the k closest POIs from an agent's location. While most existing techniques focus on retrieving nearby POIs for a single agent, these search heuristics do not translate to many other applications. For example, Aggregate k Nearest Neighbor (AkNN) queries require POIs that are close to multiple agents. k Farthest Neighbor (kFN) queries require POIs that are the antithesis of nearest. Such problems naturally benefit from a hierarchical approach, but existing methods rely on Euclidean-based heuristics, which have diminished effectiveness in graphs such as road networks. We propose a novel data structure, COL-Tree (Compacted Object-Landmark Tree), to address this gap by enabling efficient hierarchical graph traversal using a more accurate landmark-based heuristic. We then present query algorithms that utilize COL-Trees to efficiently answer AkNN, kFN, and other queries. In our experiments on real-world and synthetic datasets, we demonstrate that our techniques significantly outperform existing approaches, achieving up to 4 orders of magnitude improvement. Moreover, this comes at a small pre-processing overhead in both theory and practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22183v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tenindra Abeywickrama, Muhammad Aamir Cheema, Sabine Storandt</dc:creator>
    </item>
    <item>
      <title>Computing Dominating Sets in Disk Graphs with Centers in Convex Position</title>
      <link>https://arxiv.org/abs/2601.22609</link>
      <description>arXiv:2601.22609v1 Announce Type: cross 
Abstract: Given a set $P$ of $n$ points in the plane and a collection of disks centered at these points, the disk graph $G(P)$ has vertex set $P$, with an edge between two vertices if their corresponding disks intersect. We study the dominating set problem in $G(P)$ under the special case where the points of $P$ are in convex position. The problem is NP-hard in general disk graphs. Under the convex position assumption, however, we present the first polynomial-time algorithm for the problem. Specifically, we design an $O(k^2 n \log^2 n)$-time algorithm, where $k$ denotes the size of a minimum dominating set. For the weighted version, in which each disk has an associated weight and the goal is to compute a dominating set of minimum total weight, we obtain an $O(n^5 \log^2 n)$-time algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22609v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasiia Tkachenko, Haitao Wang</dc:creator>
    </item>
    <item>
      <title>Complexity Classes for Online Problems with and without Predictions</title>
      <link>https://arxiv.org/abs/2406.18265</link>
      <description>arXiv:2406.18265v3 Announce Type: replace 
Abstract: With the developments in machine learning, there has been a surge in interest and results focused on algorithms utilizing predictions, not least in online algorithms where most new results incorporate the prediction aspect for concrete online problems. While the structural computational hardness of problems with regards to time and space is quite well developed, not much is known about online problems where time and space resources are typically not in focus. Some information-theoretical insights were gained when researchers considered online algorithms with oracle advice, but predictions of uncertain quality is a very different matter.
  We initiate the development of a complexity theory for online problems with predictions, focusing on binary predictions for minimization problems. Based on the most generic hard online problem type, string guessing, we define a family of hierarchies of complexity classes (indexed by pairs of error measures) and develop notions of reductions, class membership, hardness, and completeness. Our framework contains all the tools one expects to find when working with complexity, and we illustrate our tools by analyzing problems with different characteristics. In addition, we show that known lower bounds for paging with discard predictions apply directly to all hard problems for each class in the hierarchy based on the canonical pair of error measures. This paging problem is not complete for these classes.
  Our work also implies corresponding complexity classes for classic online problems without predictions, with the corresponding complete problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18265v3</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Magnus Berg, Joan Boyar, Lene M. Favrholdt, Kim S. Larsen</dc:creator>
    </item>
    <item>
      <title>Spirals and Beyond: Competitive Plane Search with Multi-Speed Agents</title>
      <link>https://arxiv.org/abs/2508.10793</link>
      <description>arXiv:2508.10793v2 Announce Type: replace 
Abstract: We consider the problem of minimizing the worst-case search time for a hidden point target in the plane using multiple mobile agents of differing speeds, all starting from a common origin. The search time is normalized by the target's distance to the origin, following the standard convention in competitive analysis. The goal is to minimize the maximum such normalized time over all target locations, the search cost. As a base case, we extend the known result for a single unit-speed agent, which achieves an optimal cost of about $\mathcal{U}_1 = 17.28935$ via a logarithmic spiral, to $n$ unit-speed agents. We give a symmetric spiral-based algorithm where each agent follows a logarithmic spiral offset by equal angular phases. This yields a search cost independent of which agent finds the target. We provide a closed-form upper bound $\mathcal{U}_n$ for this setting, which we use in our general result. Our main contribution is an upper bound on the worst-case normalized search time for $n$ agents with arbitrary speeds. We give a framework that selects a subset of agents and assigns spiral-type trajectories with speed-dependent angular offsets, again making the search cost independent of which agent reaches the target. A corollary shows that $n$ multi-speed agents (fastest speed 1) can beat $k$ unit-speed agents (cost below $\mathcal{U}_k$) if the geometric mean of their speeds exceeds $\mathcal{U}_n / \mathcal{U}_k$. This means slow agents may be excluded if they lower the mean too much, motivating non-spiral algorithms. We also give new upper bounds for point search in cones and conic complements using a single unit-speed agent. These are then used to design hybrid spiral-directional strategies, which outperform the spiral-based algorithms when some agents are slow. This suggests that spiral-type trajectories may not be optimal in the general multi-speed setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10793v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Georgiou, Caleb Jones, Matthew Madej</dc:creator>
    </item>
    <item>
      <title>Efficient Approximation Algorithms for Fair Influence Maximization under Maximin Constraint</title>
      <link>https://arxiv.org/abs/2509.26579</link>
      <description>arXiv:2509.26579v2 Announce Type: replace 
Abstract: Fair Influence Maximization (FIM) seeks to mitigate disparities in influence across different groups and has recently garnered increasing attention. A widely adopted notion of fairness in FIM is the maximin constraint, which directly requires maximizing the utility (influenced ratio within a group) of the worst-off group. Despite its intuitive formulation, designing efficient algorithms with strong theoretical guarantees remains challenging, as the maximin objective does not satisfy submodularity, a key property for designing approximate algorithms in traditional influence maximization settings. In this paper, we address this challenge by proposing a two-step optimization framework consisting of Inner-group Maximization (IGM) and Across-group Maximization (AGM). We first prove that the influence spread within any individual group remains submodular, enabling effective optimization within groups. Based on this, IGM applies a greedy approach to pick high-quality seeds for each group. In the second step, AGM coordinates seed selection across groups by introducing two strategies: Uniform Selection (US) and Greedy Selection (GS). We prove that AGM-GS holds a $(1-1/e-\varepsilon)$ approximation to the optimal solution when groups are completely disconnected, while AGM-US guarantees a roughly $\frac{1}{m}(1-1/e-\varepsilon)$ lower bound regardless of the group structure, with $m$ denoting the number of groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26579v2</guid>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaobin Rui, Qiangpeng Fang, Chen Peng, Jilong Shi, Zhixiao Wang, Wei Chen</dc:creator>
    </item>
    <item>
      <title>Quantum speedups for linear programming via interior point methods</title>
      <link>https://arxiv.org/abs/2311.03215</link>
      <description>arXiv:2311.03215v3 Announce Type: replace-cross 
Abstract: We describe a quantum algorithm based on an interior point method for solving a linear program with $n$ inequality constraints on $d$ variables. The algorithm explicitly returns a feasible solution that is $\varepsilon$-close to optimal, and runs in time $\sqrt{n} \cdot \mathrm{poly}(d,\log(n),\log(1/\varepsilon))$ which is sublinear for tall linear programs (i.e., $n \gg d$). Our algorithm speeds up the Newton step in the state-of-the-art interior point method of Lee and Sidford [FOCS '14]. This requires us to efficiently approximate the Hessian and gradient of the barrier function, and these are our main contributions.
  To approximate the Hessian, we describe a quantum algorithm for the \emph{spectral approximation} of $A^T A$ for a tall matrix $A \in \mathbb R^{n \times d}$. The algorithm uses leverage score sampling in combination with Grover search, and returns a $\delta$-approximation by making $O(\sqrt{nd}/\delta)$ row queries to $A$. This generalizes an earlier quantum speedup for graph sparsification by Apers and de Wolf [FOCS '20]. To approximate the gradient, we use a recent quantum algorithm for multivariate mean estimation by Cornelissen, Hamoudi and Jerbi [STOC '22]. While a naive implementation introduces a dependence on the condition number of the Hessian, we avoid this by pre-conditioning our random variable using our quantum algorithm for spectral approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03215v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Sander Gribling</dc:creator>
    </item>
    <item>
      <title>Enumeration of minimal transversals of hypergraphs of bounded VC-dimension</title>
      <link>https://arxiv.org/abs/2407.00694</link>
      <description>arXiv:2407.00694v4 Announce Type: replace-cross 
Abstract: We consider the problem of enumerating all minimal transversals (also called minimal hitting sets) of a hypergraph $\mathcal{H}$. An equivalent formulation of this problem known as the \emph{transversal hypergraph} problem (or \emph{hypergraph dualization} problem) is to decide, given two hypergraphs, whether one corresponds to the set of minimal transversals of the other. The existence of a polynomial time algorithm to solve this problem is a long standing open question. In \cite{fredman_complexity_1996}, the authors present the first sub-exponential algorithm to solve the transversal hypergraph problem which runs in quasi-polynomial time, making it unlikely that the problem is (co)NP-complete.
  In this paper, we show that when one of the two hypergraphs is of bounded VC-dimension, the transversal hypergraph problem can be solved in polynomial time, or equivalently that if $\mathcal{H}$ is a hypergraph of bounded VC-dimension, then there exists an incremental polynomial time algorithm to enumerate its minimal transversals. This result generalizes most of the previously known polynomial cases in the literature since they almost all consider classes of hypergraphs of bounded VC-dimension. As a consequence, the hypergraph transversal problem is solvable in polynomial time for any class of hypergraphs closed under partial subhypergraphs. We also show that the proposed algorithm runs in quasi-polynomial time in general hypergraphs and runs in polynomial time if the conformality of the hypergraph is bounded, which is one of the few known polynomial cases where the VC-dimension is unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00694v4</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Mon, 02 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arnaud Mary</dc:creator>
    </item>
  </channel>
</rss>
