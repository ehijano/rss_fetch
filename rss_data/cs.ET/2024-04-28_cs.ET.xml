<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Apr 2024 04:00:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>QuERLoc: Towards Next-Generation Localization with Quantum-Enhanced Ranging</title>
      <link>https://arxiv.org/abs/2404.16895</link>
      <description>arXiv:2404.16895v1 Announce Type: new 
Abstract: Remarkable advances have been achieved in localization techniques in past decades, rendering it one of the most important technologies indispensable to our daily lives. In this paper, we investigate a novel localization approach for future computing by presenting QuERLoc, the first study on localization using quantum-enhanced ranging. By fine-tuning the evolution of an entangled quantum probe, quantum ranging can output the information integrated in the probe as a specific mapping of distance-related parameters. QuERLoc is inspired by this unique property to measure a special combination of distances between a target sensor and multiple anchors within one single physical measurement. Leveraging this capability, QuERLoc settles two drawbacks of classical localization approaches: (i) the target-anchor distances must be measured individually and sequentially, and (ii) the resulting optimization problems are non-convex and are sensitive to noise. We first present the theoretical formulation of preparing the probing quantum state and controlling its dynamic to induce a convexified localization problem, and then solve it efficiently via optimization. We conduct extensive numerical analysis of QuERLoc under various settings. The results show that QuERLoc consistently outperforms classical approaches in accuracy and closely follows the theoretical lowerbound, while maintaining low time complexity. It achieves a minimum reduction of 73% in RMSE and 97.6% in time consumption compared to baselines. By introducing range-based quantum localization to the mobile computing community and showing its superior performance, QuERLoc sheds light on next-generation localization technologies and opens up new directions for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16895v1</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Entong He, Yuxiang Yang, Chenshu Wu</dc:creator>
    </item>
    <item>
      <title>Transductive Spiking Graph Neural Networks for Loihi</title>
      <link>https://arxiv.org/abs/2404.17048</link>
      <description>arXiv:2404.17048v1 Announce Type: new 
Abstract: Graph neural networks have emerged as a specialized branch of deep learning, designed to address problems where pairwise relations between objects are crucial. Recent advancements utilize graph convolutional neural networks to extract features within graph structures. Despite promising results, these methods face challenges in real-world applications due to sparse features, resulting in inefficient resource utilization. Recent studies draw inspiration from the mammalian brain and employ spiking neural networks to model and learn graph structures. However, these approaches are limited to traditional Von Neumann-based computing systems, which still face hardware inefficiencies. In this study, we present a fully neuromorphic implementation of spiking graph neural networks designed for Loihi 2. We optimize network parameters using Lava Bayesian Optimization, a novel hyperparameter optimization system compatible with neuromorphic computing architectures. We showcase the performance benefits of combining neuromorphic Bayesian optimization with our approach for citation graph classification using fixed-precision spiking neurons. Our results demonstrate the capability of integer-precision, Loihi 2 compatible spiking neural networks in performing citation graph classification with comparable accuracy to existing floating point implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17048v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shay Snyder (George Mason University), Victoria Clerico (George Mason University), Guojing Cong (Oak Ridge National Laboratory), Shruti Kulkarni (Oak Ridge National Laboratory), Catherine Schuman (University of Tennessee - Knoxville), Sumedh R. Risbud (Intel Labs), Maryam Parsa (George Mason University)</dc:creator>
    </item>
    <item>
      <title>Asynchronous Neuromorphic Optimization with Lava</title>
      <link>https://arxiv.org/abs/2404.17052</link>
      <description>arXiv:2404.17052v1 Announce Type: new 
Abstract: Performing optimization with event-based asynchronous neuromorphic systems presents significant challenges. Intel's neuromorphic computing framework, Lava, offers an abstract application programming interface designed for constructing event-based computational graphs. In this study, we introduce a novel framework tailored for asynchronous Bayesian optimization that is also compatible with Loihi 2. We showcase the capability of our asynchronous optimization framework by connecting it with a graph-based satellite scheduling problem running on physical Loihi 2 hardware.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17052v1</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shay Snyder (George Mason University), Sumedh R. Risbud (Intel Labs), Maryam Parsa (George Mason University)</dc:creator>
    </item>
    <item>
      <title>Complete Boolean Algebra for Memristive and Spintronic Asymmetric Basis Logic Functions</title>
      <link>https://arxiv.org/abs/2404.17068</link>
      <description>arXiv:2404.17068v1 Announce Type: new 
Abstract: The increasing advancement of emerging device technologies that provide alternative basis logic sets necessitates the exploration of innovative logic design automation methodologies. Specifically, emerging computing architectures based on the memristor and the bilayer avalanche spin-diode offer non-commutative or `asymmetric' operations, namely the inverted-input AND (IAND) and implication as basis logic gates. Existing logic design techniques inadequately leverage the unique characteristics of asymmetric logic functions resulting in insufficiently optimized logic circuits. This paper presents a complete Boolean algebraic framework specifically tailored to asymmetric logic functions, introducing fundamental identities, theorems and canonical normal forms that lay the groundwork for efficient synthesis and minimization of such logic circuits without relying on conventional Boolean algebra. Further, this paper establishes a logical relationship between implication and IAND operations. A previously proposed modified Karnaugh map method based on a subset of the presented algebraic principles demonstrated a 28% reduction in computational steps for an algorithmically designed memristive full adder; the presently-proposed algebraic framework lays the foundation for much greater future improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17068v1</guid>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaibhav Vyas, Joseph S. Friedman</dc:creator>
    </item>
    <item>
      <title>Scrutinizing Data from Sky: An Examination of Its Veracity in Area Based Traffic Contexts</title>
      <link>https://arxiv.org/abs/2404.17212</link>
      <description>arXiv:2404.17212v1 Announce Type: new 
Abstract: Traffic data collection has been an overwhelming task for researchers as well as authorities over the years. With the advancement in technology and introduction of various tools for processing and extracting traffic data the task has been made significantly convenient. Data from Sky (DFS) is one such tool, based on image processing and artificial intelligence (AI), that provides output for macroscopic as well as microscopic variables of the traffic streams. The company claims to provide 98 to 100 percent accuracy on the data exported using DFS tool. The tool is widely used in developed countries where the traffic is homogenous and has lane-based movements. In this study, authors have checked the veracity of DFS tool in heterogenous and area-based traffic movement that is prevailing in most developing countries. The validation is done using various methods using Classified Volume Count (CVC), Space Mean Speeds (SMS) of individual vehicle classes and microscopic trajectory of probe vehicle to verify DFS claim. The error for CVCs for each vehicle class present in the traffic stream is estimated. Mean Absolute Percentage Error (MAPE) values are calculated for average speeds of each vehicle class between manually and DFS extracted space mean speeds (SMSs), and the microscopic trajectories are validated using a GPS based tracker put on probe vehicles. The results are fairly accurate in the case of data taken from a bird eye view with least errors. The other configurations of data collection have some significant errors, that are majorly caused by the varied traffic composition, the view of camera angle, and the direction of traffic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17212v1</guid>
      <category>cs.ET</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yawar Ali (Indian Institute of Technology Delhi, New Delhi, India), Krishnan K N (Indian Institute of Technology Delhi, New Delhi, India), Debashis Ray Sarkar (Indian Institute of Technology Delhi, New Delhi, India), K. Ramachandra Rao (Indian Institute of Technology Delhi, New Delhi, India), Niladri Chatterjee (Indian Institute of Technology Delhi, New Delhi, India), Ashish Bhaskar (Queensland University of Technology, Brisbane, Australia)</dc:creator>
    </item>
    <item>
      <title>Towards Scalable Multi-Chip Wireless Networks with Near-Field Time Reversal</title>
      <link>https://arxiv.org/abs/2404.17325</link>
      <description>arXiv:2404.17325v1 Announce Type: new 
Abstract: The concept of Wireless Network-on-Chip (WNoC) has emerged as a potential solution to address the escalating communication demands of modern computing systems due to their low-latency, versatility, and reconfigurability. However, for WNoC to fulfill its potential, it is essential to establish multiple high-speed wireless links across chips. Unfortunately, the compact and enclosed nature of computing packages introduces significant challenges in the form of Co-Channel Interference (CCI) and Inter-Symbol Interference (ISI), which not only hinder the deployment of multiple spatial channels but also severely restrict the symbol rate of each individual channel. In this paper, we posit that Time Reversal (TR) could be effective in addressing both impairments in this static scenario thanks to its spatiotemporal focusing capabilities even in the near field. Through comprehensive full-wave simulations and bit error rate analysis in multiple scenarios and at multiple frequency bands, we provide evidence that TR can increase the symbol rate by an order of magnitude, enabling the deployment of multiple concurrent links and achieving aggregate speeds exceeding 100 Gb/s. Finally, we evaluate the impact of reducing the sampling rate of the TR filter on the achievable speeds, paving the way to practical TR-based wireless communications at the chip scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17325v1</guid>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ama Bandara, F\'atima Rodr\'iguez-Gal\'an, Pau Talarn, Elana Pereira de Santana, Peter Haring Bol\'ivar, Eduard Alarc\'on, Sergi Abadal</dc:creator>
    </item>
    <item>
      <title>"ChatGPT Is Here to Help, Not to Replace Anybody" -- An Evaluation of Students' Opinions On Integrating ChatGPT In CS Courses</title>
      <link>https://arxiv.org/abs/2404.17443</link>
      <description>arXiv:2404.17443v1 Announce Type: new 
Abstract: Large Language Models (LLMs) like GPT and Bard are capable of producing code based on textual descriptions, with remarkable efficacy. Such technology will have profound implications for computing education, raising concerns about cheating, excessive dependence, and a decline in computational thinking skills, among others. There has been extensive research on how teachers should handle this challenge but it is also important to understand how students feel about this paradigm shift. In this research, 52 first-year CS students were surveyed in order to assess their views on technologies with code-generation capabilities, both from academic and professional perspectives. Our findings indicate that while students generally favor the academic use of GPT, they don't over rely on it, only mildly asking for its help. Although most students benefit from GPT, some struggle to use it effectively, urging the need for specific GPT training. Opinions on GPT's impact on their professional lives vary, but there is a consensus on its importance in academic practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17443v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruno Pereira Cipriano, Pedro Alves</dc:creator>
    </item>
    <item>
      <title>Meta-Object: Interactive and Multisensory Virtual Object Learned from the Real World for the Post-Metaverse</title>
      <link>https://arxiv.org/abs/2404.17179</link>
      <description>arXiv:2404.17179v1 Announce Type: cross 
Abstract: With the proliferation of wearable Augmented Reality/Virtual Reality (AR/VR) devices, ubiquitous virtual experiences seamlessly integrate into daily life through metaverse platforms. To support immersive metaverse experiences akin to reality, we propose a next-generation virtual object, a meta-object, a property-embedded virtual object that contains interactive and multisensory characteristics learned from the real world. Current virtual objects differ significantly from real-world objects due to restricted sensory feedback based on limited physical properties. To leverage meta-objects in the metaverse, three key components are needed: meta-object modeling and property embedding, interaction-adaptive multisensory feedback, and an intelligence simulation-based post-metaverse platform. Utilizing meta-objects that enable both on-site and remote users to interact as if they were engaging with real objects could contribute to the advent of the post-metaverse era through wearable AR/VR devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17179v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dooyoung Kim, Taewook Ha, Jinseok Hong, Seonji Kim, Selin Choi, Heejeong Ko, Woontack Woo</dc:creator>
    </item>
    <item>
      <title>Dynamic Optimization on Quantum Hardware: Feasibility for a Process Industry Use Case</title>
      <link>https://arxiv.org/abs/2311.07310</link>
      <description>arXiv:2311.07310v3 Announce Type: replace-cross 
Abstract: The quest for real-time dynamic optimization solutions in the process industry represents a formidable computational challenge, particularly within the realm of applications like model-predictive control, where rapid and reliable computations are critical. Conventional methods can struggle to surmount the complexities of such tasks. Quantum computing and quantum annealing emerge as \textit{avant-garde} contenders to transcend conventional computational constraints. We convert a dynamic optimization problem, {characterized by an optimization problem with a system of differential-algebraic equations embedded}, into a Quadratic Unconstrained Binary Optimization problem, enabling quantum computational approaches. The empirical findings synthesized from classical methods, simulated annealing, quantum annealing via D-Wave's quantum annealer, and hybrid solver methodologies, illuminate the intricate landscape of computational prowess essential for tackling complex and high-dimensional dynamic optimization problems. Our findings suggest that while quantum annealing is a maturing technology that currently does not outperform state-of-the-art classical solvers, continuous improvements could eventually aid in increasing efficiency within the chemical process industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07310v3</guid>
      <category>math.OC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.compchemeng.2024.108704</arxiv:DOI>
      <arxiv:journal_reference>Computers and Chemical Engineering, 2024, 108704, ISSN 0098-1354</arxiv:journal_reference>
      <dc:creator>Dennis Michael Nenno, Adrian Caspari</dc:creator>
    </item>
    <item>
      <title>Half-Space Modeling with Reflecting Surface in Molecular Communication</title>
      <link>https://arxiv.org/abs/2401.07282</link>
      <description>arXiv:2401.07282v2 Announce Type: replace-cross 
Abstract: In Molecular Communications via Diffusion (MCvD), messenger molecules are emitted by a transmitter and propagate randomly through the fluidic environment. In biological systems, the environment can be considered a bounded space, surrounded by various structures such as tissues and organs. The propagation of molecules is affected by these structures, which reflect the molecules upon collision. Deriving the channel response of MCvD systems with an absorbing spherical receiver requires solving the 3-D diffusion equation in the presence of reflecting and absorbing boundary conditions, which is extremely challenging. In this paper, the method of images is brought to molecular communication (MC) realm to find a closed-form solution to the channel response of a single-input single-output (SISO) system near an infinite reflecting surface. We showed that a molecular SISO system in a 3-D half-space with an infinite reflecting surface could be approximated as a molecular single-input multiple-output (SIMO) system in a 3-D space, which consists of two symmetrically located, with respect to the reflecting surface, identical absorbing spherical receivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07282v2</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anil Kamber, H. Birkan Yilmaz, Ali Emre Pusane, Tuna Tugcu</dc:creator>
    </item>
  </channel>
</rss>
