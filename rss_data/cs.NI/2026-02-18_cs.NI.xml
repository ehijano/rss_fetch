<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Feb 2026 02:32:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Exploring Performance Tradeoffs in Age-Aware Remote Monitoring with Satellites</title>
      <link>https://arxiv.org/abs/2602.15145</link>
      <description>arXiv:2602.15145v1 Announce Type: new 
Abstract: We investigate a remote monitoring framework with multiple sensing modalities including IoT sensors on the ground, mobile UAVs in the air, and a periodically available satellite constellation. While the IoT sensors cover small areas and remain fixed, the UAVs can move between locations and cover larger areas, and the satellites can observe the entire region but have high latency and low reliability. We divide the deployment region into cells and model it as a graph, with the nodes representing individual cells and edges representing possible UAV mobility patterns. To evaluate the freshness of collected information from this graph, we adopt the Age of Information (AoI) metric, measured separately for each cell. Under a given deployment of IoT nodes and UAV mobility patterns, our objective is to ascertain whether the system should actually utilize monitoring updates from satellites - a seemingly simple yet surprisingly elusive question. For stationary randomized scheduling policies, we develop closed-form expressions and lower bounds for the weighted-sum AoI and utilize this analysis to explore performance tradeoffs as system parameters vary. We also provide a Lyapunov style max-weight policy and detailed simulations that provide crucial insights for deploying such systems in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15145v1</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sunjung Kang, Vishrant Tripathi, Christopher G. Brinton</dc:creator>
    </item>
    <item>
      <title>High-Fidelity Network Management for Federated AI-as-a-Service: Cross-Domain Orchestration</title>
      <link>https://arxiv.org/abs/2602.15281</link>
      <description>arXiv:2602.15281v2 Announce Type: new 
Abstract: To support the emergence of AI-as-a-Service (AIaaS), communication service providers (CSPs) are on the verge of a radical transformation-from pure connectivity providers to AIaaS a managed network service (control-and-orchestration plane that exposes AI models). In this model, the CSP is responsible not only for transport/communications, but also for intent-to-model resolution and joint network-compute orchestration, i.e., reliable and timely end-to-end delivery. The resulting end-to-end AIaaS service thus becomes governed by communications impairments (delay, loss) and inference impairments (latency, error). A central open problem is an operational AIaaS control-and-orchestration framework that enforces high fidelity, particularly under multi-domain federation. This paper introduces an assurance-oriented AIaaS management plane based on Tail-Risk Envelopes (TREs): signed, composable per-domain descriptors that combine deterministic guardrails with stochastic rate-latency-impairment models. Using stochastic network calculus, we derive bounds on end-to-end delay violation probabilities across tandem domains and obtain an optimization-ready risk-budget decomposition. We show that tenant-level reservations prevent bursty traffic from inflating tail latency under TRE contracts. An auditing layer then uses runtime telemetry to estimate extreme-percentile performance, quantify uncertainty, and attribute tail-risk to each domain for accountability. Packet-level Monte-Carlo simulations demonstrate improved p99.9 compliance under overload via admission control and robust tenant isolation under correlated burstiness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15281v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohaned Chraiti, Ozgur Ercetin, Merve Saimler</dc:creator>
    </item>
    <item>
      <title>AI-Paging: Lease-Based Execution Anchoring for Network-Exposed AI-as-a-Service</title>
      <link>https://arxiv.org/abs/2602.15286</link>
      <description>arXiv:2602.15286v2 Announce Type: new 
Abstract: With AI-as-a-Service (AIaaS) now deployed across multiple providers and model tiers, selecting the appropriate model instance at run time is increasingly outside the end user's knowledge and operational control. Accordingly, the 6G service providers are envisioned to play a crucial role in exposing AIaaS in a setting where users submit only an intent while the network helps in the intent-to-model matching (resolution) and execution placement under policy, trust, and Quality of Service (QoS) constraints. The network role becomes to discover candidate execution endpoints and selects a suitable model/anchor under policy and QoS constraints in a process referred here to as AI-paging (by analogy to cellular call paging). In the proposed architecture, AI-paging is a control-plane transaction that resolves an intent into an AI service identity (AISI), a scoped session token (AIST), and an expiring admission lease (COMMIT) that authorizes user-plane steering to a selected AI execution anchor (AEXF) under a QoS binding. AI-Paging enforces two invariants: (i) lease-gated steering (without COMMIT, no steering state is installed) and (ii) make-before-break anchoring to support continuity and reliability of AIaaS services under dynamic network conditions. We prototype AI-Paging using existing control- and user-plane mechanisms (service-based control, QoS flows, and policy-based steering) with no new packet headers, ensuring compatibility with existing 3GPP-based exposure and management architectures, and evaluate transaction latency, relocation interruption, enforcement correctness under lease expiry, and audit-evidence overhead under mobility and failures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15286v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohaned Chraiti, Merve Saimler</dc:creator>
    </item>
    <item>
      <title>AI Sessions for Network-Exposed AI-as-a-Service</title>
      <link>https://arxiv.org/abs/2602.15288</link>
      <description>arXiv:2602.15288v2 Announce Type: new 
Abstract: Cloud-based Artificial Intelligence (AI) inference is increasingly latency- and context-sensitive, yet today's AI-as-a-Service is typically consumed as an application-chosen endpoint, leaving the network to provide only best-effort transport. This decoupling prevents enforceable tail-latency guarantees, compute-aware admission control, and continuity under mobility. This paper proposes Network-Exposed AI-as-a-Service (NE-AIaaS) built around a new service primitive: the AI Session (AIS)-a contractual object that binds model identity, execution placement, transport Quality-of-Service (QoS), and consent/charging scope into a single lifecycle with explicit failure semantics. We introduce the AI Service Profile (ASP), a compact contract that expresses task modality and measurable service objectives (e.g., time-to-first-response/token, p99 latency, success probability) alongside privacy and mobility constraints. On this basis, we specify protocol-grade procedures for (i) DISCOVER (model/site discovery), (ii) AI PAGING (context-aware selection of execution anchor), (iii) two-phase PREPARE/COMMIT that atomically co-reserves compute and QoS resources, and (iv) make-before-break MIGRATION for session continuity. The design is standard-mappable to Common API Framework (CAPIF) style northbound exposure, ETSI Multi-access Edge Computing (MEC) execution substrates, 5G QoS flows for transport enforcement, and Network Data Analytics Function (NWDAF) style analytics for closed-loop paging/migration triggers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15288v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohaned Chraiti, Merve Saimler</dc:creator>
    </item>
    <item>
      <title>A Scan-Based Analysis of Internet-Exposed IoT Devices Using Shodan Data</title>
      <link>https://arxiv.org/abs/2602.15263</link>
      <description>arXiv:2602.15263v1 Announce Type: cross 
Abstract: An open measurement problem in IoT security is whether scan-observable network configurations encode population-level exposure risk beyond individual devices. An analysis of internet-exposed IoT endpoints using a controlled multi-country sample from Shodan Search and Shodan InternetDB, selecting 100 hosts identified via TCP port 7547 (TR-069/CWMP) and evenly distributed across the ten most represented countries. Hosts are enriched with scan-derived metadata and analyzed using feature-relevance assessment, cross-country comparisons of open and risky port exposure, and supervised classification of higher-risk exposure profiles. The analysis reveals consistent cross-country differences in exposure structure, with mean risky-port counts ranging from 0.4 to 1.0 per host, and achieves balanced accuracy of approximately 0.61 when classifying higher-risk exposure profiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15263v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Richelle Williams, Fernando Koch</dc:creator>
    </item>
    <item>
      <title>On the Geometric Coherence of Global Aggregation in Federated GNN</title>
      <link>https://arxiv.org/abs/2602.15510</link>
      <description>arXiv:2602.15510v1 Announce Type: cross 
Abstract: Federated Learning (FL) enables distributed training across multiple clients without centralized data sharing, while Graph Neural Networks (GNNs) model relational data through message passing. In federated GNN settings, client graphs often exhibit heterogeneous structural and propagation characteristics. When standard aggregation mechanisms are applied to such heterogeneous updates, the global model may converge numerically while exhibiting degraded relational behavior.Our work identifies a geometric failure mode of global aggregation in Cross- Domain Federated GNNs. Although GNN parameters are numerically represented as vectors, they encode relational transformations that govern the direction, strength, and sensitivity of information flow across graph neighborhoods. Aggregating updates originating from incompatible propagation regimes can therefore introduce destructive interference in this transformation space.This leads to loss of coherence in global message passing. Importantly, this degradation is not necessarily reflected in conventional metrics such as loss or accuracy.To address this issue, we propose GGRS (Global Geometric Reference Structure), a server-side framework that regulates client updates prior to aggregation based on geometric admissibility criteria. GGRS preserves directional consistency of relational transformations as well as maintains diversity of admissible propagation subspaces. It also stabilizes sensitivity to neighborhood interactions, without accessing client data or graph topology. Experiments on heterogeneous GNN-native, Amazon Co-purchase datasets demonstrate that GGRS preserves global message-passing coherence across training rounds by highlighting the necessity of geometry-aware regulation in federated graph learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15510v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chethana Prasad Kabgere, Shylaja SS</dc:creator>
    </item>
    <item>
      <title>DNN-Enabled Multi-User Beamforming for Throughput Maximization under Adjustable Fairness</title>
      <link>https://arxiv.org/abs/2602.15617</link>
      <description>arXiv:2602.15617v1 Announce Type: cross 
Abstract: Ensuring user fairness in wireless communications is a fundamental challenge, as balancing the trade-off between fairness and sum rate leads to a non-convex, multi-objective optimization whose complexity grows with network scale. To alleviate this conflict, we propose an optimization-based unsupervised learning approach based on the wireless transformer (WiT) architecture that learns from channel state information (CSI) features. We reformulate the trade-off by combining the sum rate and fairness objectives through a Lagrangian multiplier, which is updated automatically via a dual-ascent algorithm. This mechanism allows for a controllable fairness constraint while simultaneously maximizing the sum rate, effectively realizing a trace on the Pareto front between two conflicting objectives. Our findings show that the proposed approach offers a flexible solution for managing the trade-off optimization under prescribed fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.15617v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kaifeng Lu, Markus Rupp, Stefan Schwarz</dc:creator>
    </item>
    <item>
      <title>Time-Series Foundation Models for ISP Traffic Forecasting</title>
      <link>https://arxiv.org/abs/2511.17529</link>
      <description>arXiv:2511.17529v2 Announce Type: replace 
Abstract: Accurate network-traffic forecasting enables proactive capacity planning and anomaly detection in Internet Service Provider (ISP) networks. Recent advances in time-series foundation models (TSFMs) have demonstrated strong zero-shot and few-shot generalization across diverse domains, yet their effectiveness for computer networking remains unexplored. This paper presents a systematic evaluation of a TSFM, IBM's Tiny Time Mixer (TTM), on the CESNET-TimeSeries24 dataset, a 40-week real-world ISP telemetry corpus. We assess TTM under zero-shot and few-shot settings across multiple forecasting horizons (hours to days), aggregation hierarchies (institutions, subnets, IPs), and temporal resolutions (10-minute and hourly). Results show that TTM achieves consistent accuracy (RMSE 0.026-0.057) and stable $R^2$ scores across horizons and context lengths, outperforming or matching fully trained deep learning baselines such as GRU and LSTM. Inference latency remains under 0.05s per 100 points on a single MacBook Pro using CPU-only computation, confirming deployability without dedicated GPU or MPS acceleration. These findings highlight the potential of pretrained TSFMs to enable scalable, efficient, and training-free forecasting for modern network monitoring and management systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17529v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Liu, Behrooz Farkiani, Patrick Crowley</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Routing Protocol in Vehicular Opportunistic Networks: A Dynamic Cluster-based Routing Using Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2511.19026</link>
      <description>arXiv:2511.19026v4 Announce Type: replace 
Abstract: Opportunistic Networks (OppNets) employ the Store-Carry-Forward (SCF) paradigm to maintain communication during intermittent connectivity. However, routing performance suffers due to dynamic topology changes, unpredictable contact patterns, and resource constraints including limited energy and buffer capacity. These challenges compromise delivery reliability, increase latency, and reduce node longevity in highly dynamic environments. This paper proposes Cluster-based Routing using Deep Reinforcement Learning (CR-DRL), an adaptive routing approach that integrates an Actor-Critic learning framework with a heuristic function. CR-DRL enables real-time optimal relay selection and dynamic cluster overlap adjustment to maintain connectivity while minimizing redundant transmissions and enhancing routing efficiency. Simulation results demonstrate significant improvements over state-of-the-art baselines. CR-DRL extends node lifetimes by up to 21%, overall energy use is reduced by 17%, and nodes remain active for 15% longer. Communication performance also improves, with up to 10% higher delivery ratio, 28.5% lower delay, 7% higher throughput, and data requiring 30% fewer transmission steps across the network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19026v4</guid>
      <category>cs.NI</category>
      <category>stat.ME</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TITS.2026.3661465</arxiv:DOI>
      <dc:creator>Meisam Sharifi Sani, Saeid Iranmanesh, Raad Raad, Faisel Tubbal</dc:creator>
    </item>
    <item>
      <title>Multi-Generator Continual Learning for Robust Delay Prediction in 6G</title>
      <link>https://arxiv.org/abs/2512.07726</link>
      <description>arXiv:2512.07726v2 Announce Type: replace 
Abstract: In future 6G networks, dependable networks will enable telecommunication services such as remote control of robots or vehicles with strict requirements on end-to-end network performance in terms of delay, delay variation, tail distributions, and throughput. With respect to such networks, it is paramount to be able to determine what performance level the network segment can guarantee at a given point in time. One promising approach is to use predictive models trained using machine learning (ML). Predicting performance metrics such as one-way delay (OWD), in a timely manner, provides valuable insights for the network, user equipments (UEs), and applications to address performance trends, deviations, and violations. Over the course of time, a dynamic network environment results in distributional shifts, which causes catastrophic forgetting and drop of ML model performance. In continual learning (CL), the model aims to achieve a balance between stability and plasticity, enabling new information to be learned while preserving previously learned knowledge. In this paper, we target on the challenges of catastrophic forgetting of OWD prediction model. We propose a novel approach which introducing the concept of multi-generator for the state-of-the-art CL generative replay framework, along with tabular variational autoencoders (TVAE) as generators. The domain knowledge of UE capabilities is incorporated into the learning process for determining generator setup and relevance. The proposed approach is evaluated across a diverse set of scenarios with data that is collected in a realistic 5G testbed, demonstrating its outstanding performance in comparison to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07726v2</guid>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TMLCN.2026.3663092</arxiv:DOI>
      <dc:creator>Xiaoyu Lan, Jalil Taghia, Hannes Larsson, Andreas Johnsson</dc:creator>
    </item>
    <item>
      <title>Constitutional Consensus for Democratic Governance</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v5 Announce Type: replace-cross 
Abstract: Permissionless-consensus-based Decentralised Autonomous Organisations (DAOs) are the prevailing paradigm for participant-governed digital organisations. As participants have verified resources but no trusted identities, this ecosystem is necessarily plutocratic (one coin -- one vote). Here we offer, for the first time, a democratic (one person -- one vote) paradigm for the governance of digital communities and organisations, based on permissioned consensus and egalitarian decision processes.
  In line with Lamport's vision of consensus as a self-governing parliament, in the democratic paradigm a constitution specifies both a decision making protocol as well as a consensus protocol, combined to let participants amend the constitution through constitutionally-valid decisions that are ratified by consensus. To meaningfully instantiate this paradigm we integrate the disciplines of distributed computing and computational social choice, with the goal of providing a practical and efficient smartphone-based solution for the democratic self-governance of grassroots sovereign digital communities and organisations.
  The resulting Constitutional Consensus protocol employs (1) state-of-the-art Sybil-resilient democratic decision processes for amending the set of participants, supermajority threshold, and timeout; and (2) a novel Byzantine-fault tolerant consensus protocol that is DAG-based (following Cordial Miners) thus eschewing reliable broadcast, with dual-mode operation (following Morpheus) that is quiescent when idle, has spontaneous leaders for isolated transactions, and formal round-robin leadership during high throughput.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v5</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro, Nimrod Talmon</dc:creator>
    </item>
    <item>
      <title>Software Testing at the Network Layer: Automated HTTP API Quality Assessment and Security Analysis of Production Web Applications</title>
      <link>https://arxiv.org/abs/2602.08242</link>
      <description>arXiv:2602.08242v4 Announce Type: replace-cross 
Abstract: Modern web applications rely heavily on client-side API calls to fetch data, render content, and communicate with backend services. However, the quality of these network interactions (redundant requests, missing cache headers, oversized payloads, and excessive third-party dependencies) is rarely tested in a systematic way. Moreover, many of these quality deficiencies carry security implications: missing cache headers enable cache poisoning, excessive third-party dependencies expand the supply-chain attack surface, and error responses risk leaking server internals. In this study, we present an automated software testing framework that captures and analyzes the complete HTTP traffic of 18 production websites spanning 11 categories (e-commerce, news, government, developer tools, travel, and more). Using automated browser instrumentation via Playwright, we record 108 HAR (HTTP Archive) files across 3 independent runs per page, then apply 8 heuristic-based anti-pattern detectors to produce a composite quality score (0-100) for each site. Our results reveal a wide quality spectrum: minimalist server-rendered sites achieve perfect scores of 100, while content-heavy commercial sites score as low as 56.8. We identify redundant API calls and missing cache headers as the two most pervasive anti-patterns, each affecting 67% of sites, while third-party overhead exceeds 20% on 72% of sites. One utility site makes 2,684 requests per page load, which is 447x more than the most minimal site. To protect site reputations, all identities are anonymized using category-based pseudonyms. We provide all analysis scripts, anonymized results, and reproducibility instructions as an open artifact. This work establishes an empirical baseline for HTTP API call quality across the modern web and offers a reproducible testing framework that researchers and practitioners can apply to their own applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.08242v4</guid>
      <category>cs.SE</category>
      <category>cs.NI</category>
      <pubDate>Wed, 18 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Hassaan Mughal, Muhammad Bilal, Noor Fatima</dc:creator>
    </item>
  </channel>
</rss>
