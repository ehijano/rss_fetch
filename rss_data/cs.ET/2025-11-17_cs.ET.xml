<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Nov 2025 04:08:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>StochEP: Stochastic Equilibrium Propagation for Spiking Convergent Recurrent Neural Networks</title>
      <link>https://arxiv.org/abs/2511.11320</link>
      <description>arXiv:2511.11320v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs) promise energy-efficient, sparse, biologically inspired computation. Training them with Backpropagation Through Time (BPTT) and surrogate gradients achieves strong performance but remains biologically implausible. Equilibrium Propagation (EP) provides a more local and biologically grounded alternative. However, existing EP frameworks, primarily based on deterministic neurons, either require complex mechanisms to handle discontinuities in spiking dynamics or fail to scale beyond simple visual tasks. Inspired by the stochastic nature of biological spiking mechanism and recent hardware trends, we propose a stochastic EP framework that integrates probabilistic spiking neurons into the EP paradigm. This formulation smoothens the optimization landscape, stabilizes training, and enables scalable learning in deep convolutional spiking convergent recurrent neural networks (CRNNs). We provide theoretical guarantees showing that the proposed stochastic EP dynamics approximate deterministic EP under mean-field theory, thereby inheriting its underlying theoretical guarantees. The proposed framework narrows the gap to both BPTT-trained SNNs and EP-trained non-spiking CRNNs in vision benchmarks while preserving locality, highlighting stochastic EP as a promising direction for neuromorphic and on-chip learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11320v1</guid>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiaqi Lin, Yi Jiang, Abhronil Sengupta</dc:creator>
    </item>
    <item>
      <title>Towards Efficient and Reliable AI Through Neuromorphic Principles</title>
      <link>https://arxiv.org/abs/2309.15942</link>
      <description>arXiv:2309.15942v2 Announce Type: replace-cross 
Abstract: Artificial intelligence (AI) research today is largely driven by ever-larger neural network models trained on graphics processing units (GPUs). This paradigm has yielded remarkable progress, but it also risks entrenching a hardware lottery in which algorithmic choices succeed primarily because they align with current hardware, rather than because they are inherently superior. In particular, the dominance of Transformer architectures running on GPU clusters has led to an arms race of scaling up models, resulting in exorbitant computational costs and energy usage. At the same time, today's AI models often remain unreliable in the sense that they cannot properly quantify uncertainty in their decisions -- for example, large language models tend to hallucinate incorrect outputs with high confidence.
  This article argues that achieving more efficient and reliable AI will require embracing a set of principles that are well-aligned with the goals of neuromorphic engineering, which are in turn inspired by how the brain processes information. Specifically, we outline six key neuromorphic principles, spanning algorithms, architectures, and hardware, that can inform the design of future AI systems: (i) the use of stateful, recurrent models; (ii) extreme dynamic sparsity, possibly down to spike-based processing; (iii) backpropagation-free on-device learning and fine-tuning; (iv) probabilistic decision-making; (v) in-memory computing; and (vi) hardware-software co-design via stochastic computing. We discuss each of these principles in turn, surveying relevant prior work and pointing to directions for research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15942v2</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bipin Rajendran, Osvaldo Simeone, Bashir M. Al-Hashimi</dc:creator>
    </item>
    <item>
      <title>When Federated Learning Meets Quantum Computing: Survey and Research Opportunities</title>
      <link>https://arxiv.org/abs/2504.08814</link>
      <description>arXiv:2504.08814v4 Announce Type: replace-cross 
Abstract: Quantum Federated Learning (QFL) is an emerging field that harnesses advances in Quantum Computing (QC) to improve the scalability and efficiency of decentralized Federated Learning (FL) models. This paper provides a systematic and comprehensive survey of the emerging problems and solutions when FL meets QC, from research protocol to a novel taxonomy, particularly focusing on both quantum and federated limitations, such as their architectures, Noisy Intermediate Scale Quantum (NISQ) devices, and privacy preservation, so on. With the introduction of two novel metrics, qubit utilization efficiency and quantum model training strategy, we present a thorough analysis of the current status of the QFL research. This work explores key developments and integration strategies, along with the impact of QC on FL, keeping a sharp focus on hybrid quantum-classical approaches. The paper offers an in-depth understanding of how the strengths of QC, such as gradient hiding, state entanglement, quantum key distribution, quantum security, and quantum-enhanced differential privacy, have been integrated into FL to ensure the privacy of participants in an enhanced, fast, and secure framework. Finally, this study proposes potential future directions to address the identified research gaps and challenges, aiming to inspire faster and more secure QFL models for practical use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08814v4</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakar Mathur, Ashish Gupta, Sajal K. Das</dc:creator>
    </item>
    <item>
      <title>Quantum resources in resource management systems</title>
      <link>https://arxiv.org/abs/2506.10052</link>
      <description>arXiv:2506.10052v2 Announce Type: replace-cross 
Abstract: Quantum computing resources are increasingly being incorporated into high-performance computing (HPC) environments as co-processors for hybrid workloads. To support this paradigm, quantum devices must be treated as schedulable first-class resources within existing HPC infrastructure. This enables consistent workload management, unified resource visibility, and support for hybrid quantum-classical job execution models.
  This paper presents a reference architecture and implementation for the integration of quantum computing resources, both on-premises and cloud-hosted into HPC centers via standard workload managers. We introduce a Slurm plugin designed to abstract and control quantum backends, enabling seamless resource scheduling, minimizing queue duplication, and supporting job co-scheduling with classical compute nodes. The architecture supports heterogeneous quantum resources and can be extended to any workload (and container) management systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10052v2</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Utz Bacher, Mark Birmingham, Christopher D. Carothers, Andrew Damin, Carlos D. Gonzalez Calaza, Ashwin Kumar Karnad, Stefano Mensa, Matthieu Moreau, Aurelien Nober, Munetaka Ohtani, Max Rossmannek, Philippa Rubin, M. Emre Sahin, Oscar Wallis, Amir Shehata, Iskandar Sitdikov, Aleksander Wennersteen</dc:creator>
    </item>
  </channel>
</rss>
