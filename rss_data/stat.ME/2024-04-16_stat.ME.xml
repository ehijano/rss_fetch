<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.ME updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.ME</link>
    <description>stat.ME updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.ME" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Apr 2024 04:00:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Adjusting for bias due to measurement error in functional quantile regression models with error-prone functional and scalar covariates</title>
      <link>https://arxiv.org/abs/2404.10063</link>
      <description>arXiv:2404.10063v1 Announce Type: new 
Abstract: Wearable devices enable the continuous monitoring of physical activity (PA) but generate complex functional data with poorly characterized errors. Most work on functional data views the data as smooth, latent curves obtained at discrete time intervals with some random noise with mean zero and constant variance. Viewing this noise as homoscedastic and independent ignores potential serial correlations. Our preliminary studies indicate that failing to account for these serial correlations can bias estimations. In dietary assessments, epidemiologists often use self-reported measures based on food frequency questionnaires that are prone to recall bias. With the increased availability of complex, high-dimensional functional, and scalar biomedical data potentially prone to measurement errors, it is necessary to adjust for biases induced by these errors to permit accurate analyses in various regression settings. However, there has been limited work to address measurement errors in functional and scalar covariates in the context of quantile regression. Therefore, we developed new statistical methods based on simulation extrapolation (SIMEX) and mixed effects regression with repeated measures to correct for measurement error biases in this context. We conducted simulation studies to establish the finite sample properties of our new methods. The methods are illustrated through application to a real data set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10063v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiwei Chen, Yuanyuan Luan, Roger S. Zoh, Lan Xue, Sneha Jadhav, Carmen D. Tekwe</dc:creator>
    </item>
    <item>
      <title>Perturbations of Markov Chains</title>
      <link>https://arxiv.org/abs/2404.10251</link>
      <description>arXiv:2404.10251v1 Announce Type: new 
Abstract: This chapter surveys progress on three related topics in perturbations of Markov chains: the motivating question of when and how "perturbed" MCMC chains are developed, the theoretical problem of how perturbation theory can be used to analyze such chains, and finally the question of how the theoretical analyses can lead to practical advice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10251v1</guid>
      <category>stat.ME</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Rudolf, Aaron Smith, Matias Quiroz</dc:creator>
    </item>
    <item>
      <title>Semi-parametric profile pseudolikelihood via local summary statistics for spatial point pattern intensity estimation</title>
      <link>https://arxiv.org/abs/2404.10344</link>
      <description>arXiv:2404.10344v1 Announce Type: new 
Abstract: Second-order statistics play a crucial role in analysing point processes. Previous research has specifically explored locally weighted second-order statistics for point processes, offering diagnostic tests in various spatial domains. However, there remains a need to improve inference for complex intensity functions, especially when the point process likelihood is intractable and in the presence of interactions among points. This paper addresses this gap by proposing a method that exploits local second-order characteristics to account for local dependencies in the fitting procedure. Our approach utilises the Papangelou conditional intensity function for general Gibbs processes, avoiding explicit assumptions about the degree of interaction and homogeneity. We provide simulation results and an application to real data to assess the proposed method's goodness-of-fit. Overall, this work contributes to advancing statistical techniques for point process analysis in the presence of spatial interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10344v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Nicoletta D'Angelo, Giada Adelfio, Jorge Mateu, Ottmar Cronie</dc:creator>
    </item>
    <item>
      <title>Covariate Ordered Systematic Sampling as an Improvement to Randomized Controlled Trials</title>
      <link>https://arxiv.org/abs/2404.10381</link>
      <description>arXiv:2404.10381v1 Announce Type: new 
Abstract: The Randomized Controlled Trial (RCT) or A/B testing is considered the gold standard method for estimating causal effects. Fisher famously advocated randomly allocating experiment units into treatment and control groups to preclude systematic biases. We propose a variant of systematic sampling called Covariate Ordered Systematic Sampling (COSS). In COSS, we order experimental units using a pre-experiment covariate and allocate them alternately into treatment and control groups. Using theoretical proofs, experiments on simulated data, and hundreds of A/B tests conducted within 3 real-world marketing campaigns, we show how our method achieves better sensitivity gains than commonly used variance reduction techniques like CUPED while retaining the simplicity of RCTs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10381v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deddy Jobson, Li Yilin, Naoki Nishimura, Yang Jie, Koya Ohashi, Takeshi Matsumoto</dc:creator>
    </item>
    <item>
      <title>Assumption-Lean Quantile Regression</title>
      <link>https://arxiv.org/abs/2404.10495</link>
      <description>arXiv:2404.10495v1 Announce Type: new 
Abstract: Quantile regression is a powerful tool for detecting exposure-outcome associations given covariates across different parts of the outcome's distribution, but has two major limitations when the aim is to infer the effect of an exposure. Firstly, the exposure coefficient estimator may not converge to a meaningful quantity when the model is misspecified, and secondly, variable selection methods may induce bias and excess uncertainty, rendering inferences biased and overly optimistic. In this paper, we address these issues via partially linear quantile regression models which parametrize the conditional association of interest, but do not restrict the association with other covariates in the model. We propose consistent estimators for the unknown model parameter by mapping it onto a nonparametric main effect estimand that captures the (conditional) association of interest even when the quantile model is misspecified. This estimand is estimated using the efficient influence function under the nonparametric model, allowing for the incorporation of data-adaptive procedures such as variable selection and machine learning. Our approach provides a flexible and reliable method for detecting associations that is robust to model misspecification and excess uncertainty induced by variable selection methods. The proposal is illustrated using simulation studies and data on annual health care costs associated with excess body weight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10495v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgi Baklicharov, Christophe Ley, Vanessa Gorasso, Brecht Devleesschauwer, Stijn Vansteelandt</dc:creator>
    </item>
    <item>
      <title>Nonparametric Isotropy Test for Spatial Point Processes using Random Rotations</title>
      <link>https://arxiv.org/abs/2404.10594</link>
      <description>arXiv:2404.10594v1 Announce Type: new 
Abstract: In spatial statistics, point processes are often assumed to be isotropic meaning that their distribution is invariant under rotations. Statistical tests for the null hypothesis of isotropy found in the literature are based either on asymptotics or on Monte Carlo simulation of a parametric null model. Here, we present a nonparametric test based on resampling the Fry points of the observed point pattern. Empirical levels and powers of the test are investigated in a simulation study for four point process models with anisotropy induced by different mechanisms. Finally, a real data set is tested for isotropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10594v1</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chiara Fend, Claudia Redenbach</dc:creator>
    </item>
    <item>
      <title>Weighting methods for truncation by death in cluster-randomized trials</title>
      <link>https://arxiv.org/abs/2404.10629</link>
      <description>arXiv:2404.10629v1 Announce Type: new 
Abstract: Patient-centered outcomes, such as quality of life and length of hospital stay, are the focus in a wide array of clinical studies. However, participants in randomized trials for elderly or critically and severely ill patient populations may have truncated or undefined non-mortality outcomes if they do not survive through the measurement time point. To address truncation by death, the survivor average causal effect (SACE) has been proposed as a causally interpretable subgroup treatment effect defined under the principal stratification framework. However, the majority of methods for estimating SACE have been developed in the context of individually-randomized trials. Only limited discussions have been centered around cluster-randomized trials (CRTs), where methods typically involve strong distributional assumptions for outcome modeling. In this paper, we propose two weighting methods to estimate SACE in CRTs that obviate the need for potentially complicated outcome distribution modeling. We establish the requisite assumptions that address latent clustering effects to enable point identification of SACE, and we provide computationally-efficient asymptotic variance estimators for each weighting estimator. In simulations, we evaluate our weighting estimators, demonstrating their finite-sample operating characteristics and robustness to certain departures from the identification assumptions. We illustrate our methods using data from a CRT to assess the impact of a sedation protocol on mechanical ventilation among children with acute respiratory failure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10629v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dane Isenberg, Michael Harhay, Nandita Mitra, Fan Li</dc:creator>
    </item>
    <item>
      <title>Effect of Systematic Uncertainties on Density and Temperature Estimates in Coronae of Capella</title>
      <link>https://arxiv.org/abs/2404.10427</link>
      <description>arXiv:2404.10427v1 Announce Type: cross 
Abstract: We estimate the coronal density of Capella using the O VII and Fe XVII line systems in the soft X-ray regime that have been observed over the course of the Chandra mission. Our analysis combines measures of error due to uncertainty in the underlying atomic data with statistical errors in the Chandra data to derive meaningful overall uncertainties on the plasma density of the coronae of Capella. We consider two Bayesian frameworks. First, the so-called pragmatic-Bayesian approach considers the atomic data and their uncertainties as fully specified and uncorrectable. The fully-Bayesian approach, on the other hand, allows the observed spectral data to update the atomic data and their uncertainties, thereby reducing the overall errors on the inferred parameters. To incorporate atomic data uncertainties, we obtain a set of atomic data replicates, the distribution of which captures their uncertainty. A principal component analysis of these replicates allows us to represent the atomic uncertainty with a lower-dimensional multivariate Gaussian distribution. A $t$-distribution approximation of the uncertainties of a subset of plasma parameters including a priori temperature information, obtained from the temperature-sensitive-only Fe XVII spectral line analysis, is carried forward into the density- and temperature-sensitive O VII spectral line analysis. Markov Chain Monte Carlo based model fitting is implemented including Multi-step Monte Carlo Gibbs Sampler and Hamiltonian Monte Carlo. Our analysis recovers an isothermally approximated coronal plasma temperature of $\approx$5 MK and a coronal plasma density of $\approx$10$^{10}$ cm$^{-3}$, with uncertainties of 0.1 and 0.2 dex respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10427v1</guid>
      <category>astro-ph.SR</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xixi Yu, Vinay L. Kashyap, Giulio Del Zanna, David A. van Dyk, David C. Stenning, Connor P. Ballance, Harry P. Warren</dc:creator>
    </item>
    <item>
      <title>Tree Bandits for Generative Bayes</title>
      <link>https://arxiv.org/abs/2404.10436</link>
      <description>arXiv:2404.10436v1 Announce Type: cross 
Abstract: In generative models with obscured likelihood, Approximate Bayesian Computation (ABC) is often the tool of last resort for inference. However, ABC demands many prior parameter trials to keep only a small fraction that passes an acceptance test. To accelerate ABC rejection sampling, this paper develops a self-aware framework that learns from past trials and errors. We apply recursive partitioning classifiers on the ABC lookup table to sequentially refine high-likelihood regions into boxes. Each box is regarded as an arm in a binary bandit problem treating ABC acceptance as a reward. Each arm has a proclivity for being chosen for the next ABC evaluation, depending on the prior distribution and past rejections. The method places more splits in those areas where the likelihood resides, shying away from low-probability regions destined for ABC rejections. We provide two versions: (1) ABC-Tree for posterior sampling, and (2) ABC-MAP for maximum a posteriori estimation. We demonstrate accurate ABC approximability at much lower simulation cost. We justify the use of our tree-based bandit algorithms with nearly optimal regret bounds. Finally, we successfully apply our approach to the problem of masked image classification using deep generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10436v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sean O'Hagan, Jungeum Kim, Veronika Rockova</dc:creator>
    </item>
    <item>
      <title>Capturing the Macroscopic Behaviour of Molecular Dynamics with Membership Functions</title>
      <link>https://arxiv.org/abs/2404.10523</link>
      <description>arXiv:2404.10523v1 Announce Type: cross 
Abstract: Markov processes serve as foundational models in many scientific disciplines, such as molecular dynamics, and their simulation forms a common basis for analysis. While simulations produce useful trajectories, obtaining macroscopic information directly from microstate data presents significant challenges. This paper addresses this gap by introducing the concept of membership functions being the macrostates themselves. We derive equations for the holding times of these macrostates and demonstrate their consistency with the classical definition. Furthermore, we discuss the application of the ISOKANN method for learning these quantities from simulation data. In addition, we present a novel method for extracting transition paths based on the ISOKANN results and demonstrate its efficacy by applying it to simulations of the mu-opioid receptor. With this approach we provide a new perspective on analyzing the macroscopic behaviour of Markov systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10523v1</guid>
      <category>physics.chem-ph</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Sikorski, Robert Julian Rabben, Surahit Chewle, Marcus Weber</dc:creator>
    </item>
    <item>
      <title>JCGM 101-compliant uncertainty evaluation using virtual experiments</title>
      <link>https://arxiv.org/abs/2404.10530</link>
      <description>arXiv:2404.10530v1 Announce Type: cross 
Abstract: Virtual experiments (VEs), a modern tool in metrology, can be used to help perform an uncertainty evaluation for the measurand. Current guidelines in metrology do not cover the many possibilities to incorporate VEs into an uncertainty evaluation, and it is often difficult to assess if the intended use of a VE complies with said guidelines. In recent work, it was shown that a VE can be used in conjunction with real measurement data and a Monte Carlo procedure to produce equal results to a supplement of the Guide to the Expression of Uncertainty in Measurement. However, this was shown only for linear measurement models. In this work, we extend this Monte Carlo approach to a common class of non-linear measurement models and more complex VEs, providing a reference approach for suitable uncertainty evaluations involving VEs. Numerical examples are given to show that the theoretical derivations hold in a practical scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10530v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Finn Hughes, Manuel Marschall, Gerd W\"ubbeler, Gertjan Kok, Marcel van Dijk, Clemens Elster</dc:creator>
    </item>
    <item>
      <title>Data-driven subgrouping of patient trajectories with chronic diseases: Evidence from low back pain</title>
      <link>https://arxiv.org/abs/2404.10580</link>
      <description>arXiv:2404.10580v1 Announce Type: cross 
Abstract: Clinical data informs the personalization of health care with a potential for more effective disease management. In practice, this is achieved by subgrouping, whereby clusters with similar patient characteristics are identified and then receive customized treatment plans with the goal of targeting subgroup-specific disease dynamics. In this paper, we propose a novel mixture hidden Markov model for subgrouping patient trajectories from chronic diseases. Our model is probabilistic and carefully designed to capture different trajectory phases of chronic diseases (i.e., "severe", "moderate", and "mild") through tailored latent states. We demonstrate our subgrouping framework based on a longitudinal study across 847 patients with non-specific low back pain. Here, our subgrouping framework identifies 8 subgroups. Further, we show that our subgrouping framework outperforms common baselines in terms of cluster validity indices. Finally, we discuss the applicability of the model to other chronic and long-lasting diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10580v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christof Naumzik, Alice Kongsted, Werner Vach, Stefan Feuerriegel</dc:creator>
    </item>
    <item>
      <title>Optimal Instrument Selection using Bayesian Model Averaging for Model Implied Instrumental Variable Two Stage Least Squares Estimators</title>
      <link>https://arxiv.org/abs/1808.10522</link>
      <description>arXiv:1808.10522v2 Announce Type: replace 
Abstract: Model-Implied Instrumental Variable Two-Stage Least Squares (MIIV-2SLS) is a limited information, equation-by-equation, non-iterative estimator for latent variable models. Associated with this estimator are equation specific tests of model misspecification. One issue with equation specific tests is that they lack specificity, in that they indicate that some instruments are problematic without revealing which specific ones. Instruments that are poor predictors of their target variables (weak instruments) is a second potential problem. We propose a novel extension to detect instrument specific tests of misspecification and weak instruments. We term this the Model-Implied Instrumental Variable Two-Stage Bayesian Model Averaging (MIIV-2SBMA) estimator. We evaluate the performance of MIIV-2SBMA against MIIV-2SLS in a simulation study and show that it has comparable performance in terms of parameter estimation. Additionally, our instrument specific overidentification tests developed within the MIIV-2SBMA framework show increased power to detect specific problematic and weak instruments. Finally, we demonstrate MIIV-2SBMA using an empirical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:1808.10522v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Teague R. Henry, Zachary F. Fisher, Kenneth A. Bollen</dc:creator>
    </item>
    <item>
      <title>Adaptive functional principal components analysis</title>
      <link>https://arxiv.org/abs/2306.16091</link>
      <description>arXiv:2306.16091v3 Announce Type: replace 
Abstract: Functional data analysis almost always involves smoothing discrete observations into curves, because they are never observed in continuous time and rarely without error. Although smoothing parameters affect the subsequent inference, data-driven methods for selecting these parameters are not well-developed, frustrated by the difficulty of using all the information shared by curves while being computationally efficient. On the one hand, smoothing individual curves in an isolated, albeit sophisticated way, ignores useful signals present in other curves. On the other hand, bandwidth selection by automatic procedures such as cross-validation after pooling all the curves together quickly become computationally unfeasible due to the large number of data points. In this paper we propose a new data-driven, adaptive kernel smoothing, specifically tailored for functional principal components analysis through the derivation of sharp, explicit risk bounds for the eigen-elements. The minimization of these quadratic risk bounds provide refined, yet computationally efficient bandwidth rules for each eigen-element separately. Both common and independent design cases are allowed. Rates of convergence for the estimators are derived. An extensive simulation study, designed in a versatile manner to closely mimic the characteristics of real data sets supports our methodological contribution. An illustration on a real data application is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16091v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sunny G. W. Wang, Valentin Patilea, Nicolas Klutchnikoff</dc:creator>
    </item>
    <item>
      <title>Model Selection over Partially Ordered Sets</title>
      <link>https://arxiv.org/abs/2308.10375</link>
      <description>arXiv:2308.10375v3 Announce Type: replace 
Abstract: In problems such as variable selection and graph estimation, models are characterized by Boolean logical structure such as presence or absence of a variable or an edge. Consequently, false positive error or false negative error can be specified as the number of variables/edges that are incorrectly included or excluded in an estimated model. However, there are several other problems such as ranking, clustering, and causal inference in which the associated model classes do not admit transparent notions of false positive and false negative errors due to the lack of an underlying Boolean logical structure. In this paper, we present a generic approach to endow a collection of models with partial order structure, which leads to a hierarchical organization of model classes as well as natural analogs of false positive and false negative errors. We describe model selection procedures that provide false positive error control in our general setting and we illustrate their utility with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10375v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of National Academy of Sciences, 2024</arxiv:journal_reference>
      <dc:creator>Armeen Taeb, Peter B\"uhlmann, Venkat Chandrasekaran</dc:creator>
    </item>
    <item>
      <title>A robust and powerful replicability analysis for high dimensional data</title>
      <link>https://arxiv.org/abs/2310.09701</link>
      <description>arXiv:2310.09701v2 Announce Type: replace 
Abstract: Identifying replicable signals across different studies provides stronger scientific evidence and more powerful inference. Existing literature on high dimensional applicability analysis either imposes strong modeling assumptions or has low power. We develop a powerful and robust empirical Bayes approach for high dimensional replicability analysis. Our method effectively borrows information from different features and studies while accounting for heterogeneity. We show that the proposed method has better power than competing methods while controlling the false discovery rate, both empirically and theoretically. Analyzing datasets from the genome-wide association studies reveals new biological insights that otherwise cannot be obtained by using existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09701v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haochen Lei, Yan Li, Hongyuan Cao</dc:creator>
    </item>
    <item>
      <title>Precise FWER Control for Gaussian Related Fields: Riding the SuRF to continuous land -- Part 1</title>
      <link>https://arxiv.org/abs/2312.13450</link>
      <description>arXiv:2312.13450v2 Announce Type: replace 
Abstract: The Gaussian Kinematic Formula (GKF) is a powerful and computationally efficient tool to perform statistical inference on random fields and became a well-established tool in the analysis of neuroimaging data. Using realistic error models, recent articles show that GKF based methods for \emph{voxelwise inference} lead to conservative control of the familywise error rate (FWER) and for cluster-size inference lead to inflated false positive rates. In this series of articles we identify and resolve the main causes of these shortcomings in the traditional usage of the GKF for voxelwise inference. This first part removes the \textit{good lattice assumption} and allows the data to be non-stationary, yet still assumes the data to be Gaussian. The latter assumption is resolved in part 2, where we also demonstrate that our GKF based methodology is non-conservative under realistic error models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13450v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian JE Telschow, Samuel Davenport</dc:creator>
    </item>
    <item>
      <title>Measurement and comparison of distributional shift with applications to ecology, economics, and image analysis</title>
      <link>https://arxiv.org/abs/2401.11119</link>
      <description>arXiv:2401.11119v4 Announce Type: replace 
Abstract: The concept of shift is often invoked to describe directional differences in statistical moments but has not yet been established as a property of individual distributions. In the present study, we define distributional shift (DS) as the concentration of frequencies towards the lowest discrete class and derive its measurement from the sum of cumulative frequencies. We use empirical datasets to demonstrate DS as an advantageous measure of ecological rarity and as a generalisable measure of poverty and scarcity. We then define relative distributional shift (RDS) as the difference in DS between distributions, yielding a uniquely signed (i.e., directional) measure. Using simulated random sampling, we show that RDS is closely related to measures of distance, divergence, intersection, and probabilistic scoring. We apply RDS to image analysis by demonstrating its performance in the detection of light events, changes in complex patterns, patterns within visual noise, and colour shifts. Altogether, DS is an intuitive statistical property that underpins a uniquely useful comparative measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11119v4</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenneth J. Locey, Brian D. Stein</dc:creator>
    </item>
    <item>
      <title>Multiply Robust Difference-in-Differences Estimation of Causal Effect Curves for Continuous Exposures</title>
      <link>https://arxiv.org/abs/2401.14355</link>
      <description>arXiv:2401.14355v2 Announce Type: replace 
Abstract: Researchers commonly use difference-in-differences (DiD) designs to evaluate public policy interventions. While methods exist for estimating effects in the context of binary interventions, policies often result in varied exposures across regions implementing the policy. Yet, existing approaches for incorporating continuous exposures face substantial limitations in addressing confounding variables associated with intervention status, exposure levels, and outcome trends. These limitations significantly constrain policymakers' ability to fully comprehend policy impacts and design future interventions. In this work, we propose new estimators for causal effect curves within the DiD framework, accounting for multiple sources of confounding. Our approach accommodates misspecification of a subset of treatment, exposure, and outcome models while avoiding any parametric assumptions on the effect curve. We present the statistical properties of the proposed methods and illustrate their application through simulations and a study investigating the heterogeneous effects of a nutritional excise tax under different levels of accessibility to cross-border shopping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14355v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gary Hettinger, Youjin Lee, Nandita Mitra</dc:creator>
    </item>
    <item>
      <title>Bayesian Penalized Transformation Models: Structured Additive Location-Scale Regression for Arbitrary Conditional Distributions</title>
      <link>https://arxiv.org/abs/2404.07440</link>
      <description>arXiv:2404.07440v2 Announce Type: replace 
Abstract: Penalized transformation models (PTMs) are a novel form of location-scale regression. In PTMs, the shape of the response's conditional distribution is estimated directly from the data, and structured additive predictors are placed on its location and scale. The core of the model is a monotonically increasing transformation function that relates the response distribution to a reference distribution. The transformation function is equipped with a smoothness prior that regularizes how much the estimated distribution diverges from the reference distribution. These models can be seen as a bridge between conditional transformation models and generalized additive models for location, scale and shape. Markov chain Monte Carlo inference for PTMs can be conducted with the No-U-Turn sampler and offers straightforward uncertainty quantification for the conditional distribution as well as for the covariate effects. A simulation study demonstrates the effectiveness of the approach. We apply the model to data from the Fourth Dutch Growth Study and the Framingham Heart Study. A full-featured implementation is available as a Python library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07440v2</guid>
      <category>stat.ME</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Brachem, Paul F. V. Wiemann, Thomas Kneib</dc:creator>
    </item>
    <item>
      <title>Lorenz map, inequality ordering and curves based on multidimensional rearrangements</title>
      <link>https://arxiv.org/abs/2203.09000</link>
      <description>arXiv:2203.09000v4 Announce Type: replace-cross 
Abstract: We propose a multivariate extension of the Lorenz curve based on multivariate rearrangements of optimal transport theory. We define a vector Lorenz map as the integral of the vector quantile map associated with a multivariate resource allocation. Each component of the Lorenz map is the cumulative share of each resource, as in the traditional univariate case. The pointwise ordering of such Lorenz maps defines a new multivariate majorization order, which is equivalent to preference by any social planner with inequality averse multivariate rank dependent social evaluation functional. We define a family of multi-attribute Gini index and complete ordering based on the Lorenz map. We propose the level sets of an Inverse Lorenz Function as a practical tool to visualize and compare inequality in two dimensions, and apply it to income-wealth inequality in the United States between 1989 and 2022.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.09000v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanqin Fan, Marc Henry, Brendan Pass, Jorge A. Rivero</dc:creator>
    </item>
    <item>
      <title>Sharp adaptive and pathwise stable similarity testing for scalar ergodic diffusions</title>
      <link>https://arxiv.org/abs/2203.13776</link>
      <description>arXiv:2203.13776v3 Announce Type: replace-cross 
Abstract: Within the nonparametric diffusion model, we develop a multiple test to infer about similarity of an unknown drift $b$ to some reference drift $b_0$: At prescribed significance, we simultaneously identify those regions where violation from similiarity occurs, without a priori knowledge of their number, size and location. This test is shown to be minimax-optimal and adaptive. At the same time, the procedure is robust under small deviation from Brownian motion as the driving noise process. A detailed investigation for fractional driving noise, which is neither a semimartingale nor a Markov process, is provided for Hurst indices close to the Brownian motion case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.13776v3</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Brutsche, Angelika Rohde</dc:creator>
    </item>
    <item>
      <title>Principal-Agent Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2205.06812</link>
      <description>arXiv:2205.06812v3 Announce Type: replace-cross 
Abstract: Consider the relationship between a regulator (the principal) and an experimenter (the agent) such as a pharmaceutical company. The pharmaceutical company wishes to sell a drug for profit, whereas the regulator wishes to allow only efficacious drugs to be marketed. The efficacy of the drug is not known to the regulator, so the pharmaceutical company must run a costly trial to prove efficacy to the regulator. Critically, the statistical protocol used to establish efficacy affects the behavior of a strategic, self-interested agent; a lower standard of statistical evidence incentivizes the agent to run more trials that are less likely to be effective. The interaction between the statistical protocol and the incentives of the pharmaceutical company is crucial for understanding this system and designing protocols with high social utility. In this work, we discuss how the regulator can set up a protocol with payoffs based on statistical evidence. We show how to design protocols that are robust to an agent's strategic actions, and derive the optimal protocol in the presence of strategic entrants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.06812v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stephen Bates, Michael I. Jordan, Michael Sklar, Jake A. Soloff</dc:creator>
    </item>
    <item>
      <title>Robust Multivariate Functional Control Chart</title>
      <link>https://arxiv.org/abs/2207.07978</link>
      <description>arXiv:2207.07978v3 Announce Type: replace-cross 
Abstract: In modern Industry 4.0 applications, a huge amount of data is acquired during manufacturing processes that are often contaminated with anomalous observations in the form of both casewise and cellwise outliers. These can seriously reduce the performance of control charting procedures, especially in complex and high-dimensional settings. To mitigate this issue in the context of profile monitoring, we propose a new framework, referred to as robust multivariate functional control chart (RoMFCC), that is able to monitor multivariate functional data while being robust to both functional casewise and cellwise outliers. The RoMFCC relies on four main elements: (I) a functional univariate filter to identify functional cellwise outliers to be replaced by missing components; (II) a robust multivariate functional data imputation method of missing values; (III) a casewise robust dimensionality reduction; (IV) a monitoring strategy for the multivariate functional quality characteristic. An extensive Monte Carlo simulation study is performed to compare the RoMFCC with competing monitoring schemes already appeared in the literature. Finally, a motivating real-case study is presented where the proposed framework is used to monitor a resistance spot welding process in the automotive industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.07978v3</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00401706.2024.2327346</arxiv:DOI>
      <dc:creator>Christian Capezza, Fabio Centofanti, Antonio Lepore, Biagio Palumbo</dc:creator>
    </item>
    <item>
      <title>The extended Ville's inequality for nonintegrable nonnegative supermartingales</title>
      <link>https://arxiv.org/abs/2304.01163</link>
      <description>arXiv:2304.01163v2 Announce Type: replace-cross 
Abstract: Following the initial work by Robbins, we rigorously present an extended theory of nonnegative supermartingales, requiring neither integrability nor finiteness. In particular, we derive a key maximal inequality foreshadowed by Robbins, which we call the extended Ville's inequality, that strengthens the classical Ville's inequality (for integrable nonnegative supermartingales), and also applies to our nonintegrable setting. We derive an extension of the method of mixtures, which applies to $\sigma$-finite mixtures of our extended nonnegative supermartingales. We present some implications of our theory for sequential statistics, such as the use of improper mixtures (priors) in deriving nonparametric confidence sequences and (extended) e-processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01163v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongjian Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Scalable Bayesian inference for the generalized linear mixed model</title>
      <link>https://arxiv.org/abs/2403.03007</link>
      <description>arXiv:2403.03007v2 Announce Type: replace-cross 
Abstract: The generalized linear mixed model (GLMM) is a popular statistical approach for handling correlated data, and is used extensively in applications areas where big data is common, including biomedical data settings. The focus of this paper is scalable statistical inference for the GLMM, where we define statistical inference as: (i) estimation of population parameters, and (ii) evaluation of scientific hypotheses in the presence of uncertainty. Artificial intelligence (AI) learning algorithms excel at scalable statistical estimation, but rarely include uncertainty quantification. In contrast, Bayesian inference provides full statistical inference, since uncertainty quantification results automatically from the posterior distribution. Unfortunately, Bayesian inference algorithms, including Markov Chain Monte Carlo (MCMC), become computationally intractable in big data settings. In this paper, we introduce a statistical inference algorithm at the intersection of AI and Bayesian inference, that leverages the scalability of modern AI algorithms with guaranteed uncertainty quantification that accompanies Bayesian inference. Our algorithm is an extension of stochastic gradient MCMC with novel contributions that address the treatment of correlated data (i.e., intractable marginal likelihood) and proper posterior variance estimation. Through theoretical and empirical results we establish our algorithm's statistical inference properties, and apply the method in a large electronic health records database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03007v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel I. Berchuck, Felipe A. Medeiros, Sayan Mukherjee, Andrea Agazzi</dc:creator>
    </item>
    <item>
      <title>Partial Identification of Individual-Level Parameters Using Aggregate Data in a Nonparametric Binary Outcome Model</title>
      <link>https://arxiv.org/abs/2403.07236</link>
      <description>arXiv:2403.07236v4 Announce Type: replace-cross 
Abstract: It is well known that the relationship between variables at the individual level can be different from the relationship between those same variables aggregated over individuals. This problem of aggregation becomes relevant when the researcher wants to learn individual-level relationships but only has access to data that has been aggregated. In this paper, I develop a methodology to partially identify linear combinations of conditional average outcomes from aggregate data when the outcome of interest is binary while imposing very few restrictions on the underlying data generating process. I construct identified sets using an optimization program that allows for researchers to impose additional shape and data restrictions. I also provide consistency results and construct an inference procedure that is valid with aggregate data, which only provides marginal information about each variable. I apply the methodology to simulated and real-world data sets and find that the estimated identified sets are too wide to be useful, but become narrower as more assumptions are imposed and data aggregated at a finer level is available. This suggests that to obtain useful information from aggregate data sets about individual-level relationships, researchers must impose further assumptions that are carefully justified or seek out data aggregated at the finest level possible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07236v4</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarah Moon</dc:creator>
    </item>
  </channel>
</rss>
