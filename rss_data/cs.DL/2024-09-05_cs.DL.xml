<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 01:41:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exploring the applicability of Large Language Models to citation context analysis</title>
      <link>https://arxiv.org/abs/2409.02443</link>
      <description>arXiv:2409.02443v1 Announce Type: new 
Abstract: Unlike traditional citation analysis -- which assumes that all citations in a paper are equivalent -- citation context analysis considers the contextual information of individual citations. However, citation context analysis requires creating large amounts of data through annotation, which hinders the widespread use of this methodology. This study explored the applicability of Large Language Models (LLMs) -- particularly ChatGPT -- to citation context analysis by comparing LLMs and human annotation results. The results show that the LLMs annotation is as good as or better than the human annotation in terms of consistency but poor in terms of predictive performance. Thus, having LLMs immediately replace human annotators in citation context analysis is inappropriate. However, the annotation results obtained by LLMs can be used as reference information when narrowing the annotation results obtained by multiple human annotators to one, or LLMs can be used as one of the annotators when it is difficult to prepare sufficient human annotators. This study provides basic findings important for the future development of citation context analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02443v1</guid>
      <category>cs.DL</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11192-024-05142-9</arxiv:DOI>
      <dc:creator>Kai Nishikawa, Hitoshi Koshiba</dc:creator>
    </item>
    <item>
      <title>Exploring Citation Diversity in Scholarly Literature: An Entropy-Based Approach</title>
      <link>https://arxiv.org/abs/2409.02592</link>
      <description>arXiv:2409.02592v1 Announce Type: cross 
Abstract: This study explores global citation diversity,examining its various patterns across countries and academic disciplines.We analyzed citation distributions in top institutes worldwide,revealing that the higher citation end of the distribution follow Power law or Pareto law pattern and the Pareto law's scaling exponent changes with the number of institutes considered.An entropy based novel citation inequality measure has been introduced, enhancing the precision of our analysis. Our findings show that countries with small and large economies often group similarly based on citation diversity, with shifting the groupings as the number of institutes considered changes.Moreover,we analyzed citation diversity among award-winning scientists across six scientific disciplines,finding significant variations.We also explored the evolution of citation diversity over the past century across multiple fields.A gender-based study in various disciplines highlights citation inequalities among male and female scientists.Our innovative citation diversity measure stands out as a vital tool for evaluating citation inequality,providing insights beyond what traditional citation counts can offer.This thorough analysis deepens our understanding of global scientific contributions and promotes a more equitable view of academic accomplishments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02592v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.DL</category>
      <pubDate>Thu, 05 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>suchismita Banerjee, Abhik Ghosh, Banasri Basu</dc:creator>
    </item>
  </channel>
</rss>
