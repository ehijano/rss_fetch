<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 12 Mar 2024 04:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 12 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Compositional Framework for First-Order Optimization</title>
      <link>https://arxiv.org/abs/2403.05711</link>
      <description>arXiv:2403.05711v1 Announce Type: new 
Abstract: Optimization decomposition methods are a fundamental tool to develop distributed solution algorithms for large scale optimization problems arising in fields such as machine learning and optimal control. In this paper, we present an algebraic framework for hierarchically composing optimization problems defined on hypergraphs and automatically generating distributed solution algorithms that respect the given hierarchical structure. The central abstractions of our framework are operads, operad algebras, and algebra morphisms, which formalize notions of syntax, semantics, and structure preserving semantic transformations respectively. These abstractions allow us to formally relate composite optimization problems to the distributed algorithms that solve them. Specifically, we show that certain classes of optimization problems form operad algebras, and a collection of first-order solution methods, namely gradient descent, Uzawa's algorithm (also called gradient ascent-descent), and their subgradient variants, yield algebra morphisms from these problem algebras to algebras of dynamical systems. Primal and dual decomposition methods are then recovered by applying these morphisms to certain classes of composite problems. Using this framework, we also derive a novel sufficient condition for when a problem defined by compositional data is solvable by a decomposition method. We show that the minimum cost network flow problem satisfies this condition, thereby allowing us to automatically derive a hierarchical dual decomposition algorithm for finding minimum cost flows on composite flow networks. We implement our operads, algebras, and algebra morphisms in a Julia package called AlgebraicOptimization.jl and use our implementation to empirically demonstrate that hierarchical dual decomposition outperforms standard dual decomposition on classes of flow networks with hierarchical structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05711v1</guid>
      <category>math.OC</category>
      <category>math.CT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tyler Hanks, Matthew Klawonn, Evan Patterson, Matthew Hale, James Fairbanks</dc:creator>
    </item>
    <item>
      <title>Do Identifiability Results for Continuous-Space Extend to Discrete-Space Systems?</title>
      <link>https://arxiv.org/abs/2403.05736</link>
      <description>arXiv:2403.05736v1 Announce Type: new 
Abstract: Researchers develop new models to explain the unknowns. The developed models typically involve parameters that capture tangible quantities, the estimation of which is desired. However, prior to parameter estimation, the identifiability of the parameters should be investigated. Parameter identifiability investigates the recoverability of the unknown parameters given the error-free outputs, inputs, and the developed equations of the model. Different notions of and methods to test identifiability exist for dynamical systems defined in the continuous state space. Yet little attention was paid to identifiability of discrete-space systems, where variables and parameters are defined in a discrete space. We develop the identifiability framework for discrete space systems and highlight that this is not an immediate extension of the continuous space framework. Unlike the continuous case, a ``neighborhood'' is not uniquely defined in the discrete space, and hence, neither are local identifiability concepts. Moreover, results on algebraic identifiability that proved useful in the continuous space are much less so in their discrete form as the notion of differentiability disappears.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05736v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuththara Sarathchandra, Azadeh Aghaeeyan, Pouria Ramazi</dc:creator>
    </item>
    <item>
      <title>A Feasibility Analysis at Signal-Free Intersections</title>
      <link>https://arxiv.org/abs/2403.05739</link>
      <description>arXiv:2403.05739v1 Announce Type: new 
Abstract: In this letter, we address the problem of improving the feasible domain of the solution of a decentralized control framework for coordinating connected and automated vehicles (CAVs) at signal-free intersections as the traffic volume increases. The framework provides the optimal trajectories of CAVs to cross the intersection safely without stop-and-go driving. However, as the traffic volume increases, the domain of the feasible trajectories decreases. We use concepts of numerical interpolation to identify appropriate polynomials that can serve as alternative trajectories of the CAVs, expanding the domain of the feasible CAV trajectories. We provide the conditions under which such polynomials exist. Finally, we demonstrate the efficacy of our approach through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05739v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippos N. Tzortzoglou, Logan E. Beaver, Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>Specialized effective Positivstellens\"atze for improved convergence rates of the moment-SOS hierarchy</title>
      <link>https://arxiv.org/abs/2403.05934</link>
      <description>arXiv:2403.05934v1 Announce Type: new 
Abstract: Recently a moment-sum-of-squares hierarchy for exit location estimation of stochastic processes has been presented. When restricting to the special case of the unit ball, we show that the solutions approach the optimal value by a super-polynomial rate. To show this result we state a new effective Positivstellensatz on the sphere with quadratic degree bound based on a recent Positivstellensatz for trigonometric polynomials on the hypercube and pair it with a recent effective Positivstellensatz on the unit ball. At the present example, we aim to highlight the effectiveness of specialized Positivstellens\"atze for the moment-SoS hierarchy and their interplay with problem intrinsic properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05934v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Corbinian Schlosser, Matteo Tacchi</dc:creator>
    </item>
    <item>
      <title>Estimates of the Kolmogorov n-width for nonlinear transformations with application to distributed-parameter control systems</title>
      <link>https://arxiv.org/abs/2403.06029</link>
      <description>arXiv:2403.06029v1 Announce Type: new 
Abstract: This paper aims at characterizing the approximability of bounded sets in the range of nonlinear operators in Banach spaces by finite-dimensional linear varieties. In particular, the class of operators we consider includes the endpoint maps of nonlinear distributed-parameter control systems. The concept of Kolmogorov widths is developed to describe the relation between the n-width of a bounded subset and the width of its image by applying essentially nonlinear transformation. We propose explicit estimates of the n-width in the space of images in terms of the affine part of the corresponding operator and the width of its nonlinear perturbation. These n-width estimates enable us to describe the reachable sets for infinite-dimensional bilinear control systems, with applications to controlling the Euler-Bernoulli beam using a contraction force and to a single-input Schr\"odinger equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06029v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zuyev, Lihong Feng, Peter Benner</dc:creator>
    </item>
    <item>
      <title>Absence of spurious solutions far from ground truth: A low-rank analysis with high-order losses</title>
      <link>https://arxiv.org/abs/2403.06056</link>
      <description>arXiv:2403.06056v1 Announce Type: new 
Abstract: Matrix sensing problems exhibit pervasive non-convexity, plaguing optimization with a proliferation of suboptimal spurious solutions. Avoiding convergence to these critical points poses a major challenge. This work provides new theoretical insights that help demystify the intricacies of the non-convex landscape. In this work, we prove that under certain conditions, critical points sufficiently distant from the ground truth matrix exhibit favorable geometry by being strict saddle points rather than troublesome local minima. Moreover, we introduce the notion of higher-order losses for the matrix sensing problem and show that the incorporation of such losses into the objective function amplifies the negative curvature around those distant critical points. This implies that increasing the complexity of the objective function via high-order losses accelerates the escape from such critical points and acts as a desirable alternative to increasing the complexity of the optimization problem via over-parametrization. By elucidating key characteristics of the non-convex optimization landscape, this work makes progress towards a comprehensive framework for tackling broader machine learning objectives plagued by non-convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06056v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziye Ma, Ying Chen, Javad Lavaei, Somayeh Sojoudi</dc:creator>
    </item>
    <item>
      <title>Monotone Mean-Variance Portfolio Selection in Semimartingale Markets: Martingale Method</title>
      <link>https://arxiv.org/abs/2403.06190</link>
      <description>arXiv:2403.06190v1 Announce Type: new 
Abstract: We use the martingale method to discuss the relationship between mean-variance (MV) and monotone mean-variance (MMV) portfolio selections. We propose a unified framework to discuss the relationship in general financial markets without any specific setting or completeness requirement. We apply this framework to a semimartingale market and find that MV and MMV are consistent if and only if the variance-optimal signed martingale measure keeps non-negative. Further, we provide an example to show the application of our result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06190v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Li, Zongxia Liang, Shunzhi Pang</dc:creator>
    </item>
    <item>
      <title>Fine-tuning of diffusion models via stochastic control: entropy regularization and beyond</title>
      <link>https://arxiv.org/abs/2403.06279</link>
      <description>arXiv:2403.06279v1 Announce Type: new 
Abstract: This paper aims to develop and provide a rigorous treatment to the problem of entropy regularized fine-tuning in the context of continuous-time diffusion models, which was recently proposed by Uehara et al. ( arXiv:2402.15194, 2024). We also show how the analysis can be extended to fine-tuning involving a general $f$-divergence regularizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06279v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenpin Tang</dc:creator>
    </item>
    <item>
      <title>Almost Optimal Agnostic Control of Unknown Linear Dynamics</title>
      <link>https://arxiv.org/abs/2403.06320</link>
      <description>arXiv:2403.06320v1 Announce Type: new 
Abstract: We consider a simple control problem in which the underlying dynamics depend on a parameter $a$ that is unknown and must be learned. We study three variants of the control problem: Bayesian control, in which we have a prior belief about $a$; bounded agnostic control, in which we have no prior belief about $a$ but we assume that $a$ belongs to a bounded set; and fully agnostic control, in which $a$ is allowed to be an arbitrary real number about which we have no prior belief. In the Bayesian variant, a control strategy is optimal if it minimizes a certain expected cost. In the agnostic variants, a control strategy is optimal if it minimizes a quantity called the worst-case regret. For the Bayesian and bounded agnostic variants above, we produce optimal control strategies. For the fully agnostic variant, we produce almost optimal control strategies, i.e., for any $\varepsilon&gt;0$ we produce a strategy that minimizes the worst-case regret to within a multiplicative factor of $(1+\varepsilon)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06320v1</guid>
      <category>math.OC</category>
      <category>math.CA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jacob Carruth, Maximilian F. Eggl, Charles Fefferman, Clarence W. Rowley</dc:creator>
    </item>
    <item>
      <title>Forward completeness implies bounded reachable sets for time-delay systems on the state space of essentially bounded measurable functions</title>
      <link>https://arxiv.org/abs/2403.06543</link>
      <description>arXiv:2403.06543v1 Announce Type: new 
Abstract: We consider time-delay systems with a finite number of delays in the state space $L^\infty\times\R^n$. In this framework, we show that forward completeness implies the bounded reachability sets property, while this implication was recently shown by J.L. Mancilla-Aguilar and H. Haimovich to fail in the state space of continuous functions. As a consequence, we show that global asymptotic stability is always uniform in the state space $L^\infty\times\R^n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06543v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas BrivadisL2S, Antoine ChailletIUF, L2S, Andrii Mironchenko, Fabian Wirth</dc:creator>
    </item>
    <item>
      <title>Non-convex relaxation and 1/2-approximation algorithm for the chance-constrained binary knapsack problem</title>
      <link>https://arxiv.org/abs/2403.06686</link>
      <description>arXiv:2403.06686v1 Announce Type: new 
Abstract: We consider the chance-constrained binary knapsack problem (CKP), where the item weights are independent and normally distributed. We introduce a continuous relaxation for the CKP, represented as a non-convex optimization problem, which we call the non-convex relaxation. A comparative study shows that the non-convex relaxation provides an upper bound for the CKP, at least as tight as those obtained from other continuous relaxations for the CKP. Furthermore, the quality of the obtained upper bound is guaranteed to be at most twice the optimal objective value of the CKP. Despite its non-convex nature, we show that the non-convex relaxation can be solved in polynomial time. Subsequently, we proposed a polynomial-time 1/2-approximation algorithm for the CKP based on this relaxation, providing a lower bound for the CKP. Computational test results demonstrate that the non-convex relaxation and the proposed approximation algorithm yields tight lower and upper bounds for the CKP within a short computation time, ensuring the quality of the obtained bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06686v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junyoung Kim, Kyungsik Lee</dc:creator>
    </item>
    <item>
      <title>Tikhonov Regularization for Stochastic Non-Smooth Convex Optimization in Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2403.06708</link>
      <description>arXiv:2403.06708v1 Announce Type: new 
Abstract: To solve non-smooth convex optimization problems with a noisy gradient input, we analyze the global behavior of subgradient-like flows under stochastic errors. The objective function is composite, being equal to the sum of two convex functions, one being differentiable and the other potentially non-smooth. We then use stochastic differential inclusions where the drift term is minus the subgradient of the objective function, and the diffusion term is either bounded or square-integrable. In this context, under Lipschitz's continuity of the differentiable term and a growth condition of the non-smooth term, our first main result shows almost sure weak convergence of the trajectory process towards a minimizer of the objective function. Then, using Tikhonov regularization with a properly tuned vanishing parameter, we can obtain almost sure strong convergence of the trajectory towards the minimum norm solution. We find an explicit tuning of this parameter when our objective function satisfies a local error-bound inequality. We also provide a comprehensive complexity analysis by establishing several new pointwise and ergodic convergence rates in expectation for the convex and strongly convex case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06708v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodrigo Maulen-Soto, Jalal Fadili, Hedy Attouch</dc:creator>
    </item>
    <item>
      <title>Domain-Independent Dynamic Programming and Constraint Programming Approaches for Assembly Line Balancing Problems with Setups</title>
      <link>https://arxiv.org/abs/2403.06780</link>
      <description>arXiv:2403.06780v1 Announce Type: new 
Abstract: We propose domain-independent dynamic programming (DIDP) and constraint programming (CP) models to exactly solve type-1 and type-2 assembly line balancing problem with sequence-dependent setup times (SUALBP). The goal is to assign tasks to assembly stations and to sequence these tasks within each station, while satisfying precedence relations specified between a subset of task pairs. Each task has a given processing time and a setup time dependent on the previous task on the station to which the task is assigned. The sum of the processing and setup times of tasks assigned to each station constitute the station time and the maximum station time is called the cycle time. For type-1 SUALBP, the objective is to minimize the number of stations, given a maximum cycle time. For type-2 SUALBP, the objective is to minimize the cycle time, given the number of stations. On a set of diverse SUALBP instances, experimental results show that our approaches significantly outperform the state-of-the-art mixed integer programming models for SUALBP-1. For SUALBP-2, the DIDP model outperforms the state-of-the-art exact approach based on logic-based Benders decomposition. By closing 76 open instances for SUALBP-2, our results demonstrate the promise of DIDP for solving complex planning and scheduling problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06780v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Zhang, J. Christopher Beck</dc:creator>
    </item>
    <item>
      <title>Hybrid optimal control with mixed-integer Lagrangian methods</title>
      <link>https://arxiv.org/abs/2403.06842</link>
      <description>arXiv:2403.06842v1 Announce Type: new 
Abstract: Models involving hybrid systems are versatile in their application, but difficult to handle and optimize efficiently due to their combinatorial nature. This work presents a method to cope with hybrid optimal control problems which, in contrast to decomposition techniques, does not require relaxing the integrality constraints. Based on the discretize-then-optimize approach, our scheme addresses mixed-integer nonlinear problems under mild assumptions. The proposed numerical algorithm builds upon the augmented Lagrangian framework, whose subproblems are handled using successive mixed-integer linearizations with trust regions. We validate the performance of the numerical routine with extensive investigations using several hybrid optimal control problems from different fields of application. Promising preliminary results are presented for a motion planning task with hysteresis and drag, a Lotka-Volterra fishing problem, and a facility location design problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06842v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktoriya Nikitina, Alberto De Marchi, Matthias Gerdts</dc:creator>
    </item>
    <item>
      <title>Last Iterate Convergence of Incremental Methods and Applications in Continual Learning</title>
      <link>https://arxiv.org/abs/2403.06873</link>
      <description>arXiv:2403.06873v1 Announce Type: new 
Abstract: Incremental gradient methods and incremental proximal methods are a fundamental class of optimization algorithms used for solving finite sum problems, broadly studied in the literature. Yet, when it comes to their convergence guarantees, nonasymptotic (first-order or proximal) oracle complexity bounds have been obtained fairly recently, almost exclusively applying to the average iterate. Motivated by applications in continual learning, we obtain the first convergence guarantees for the last iterate of both incremental gradient and incremental proximal methods, in general convex smooth (for both) and convex Lipschitz (for the proximal variants) settings. Our oracle complexity bounds for the last iterate nearly match (i.e., match up to a square-root-log or a log factor) the best known oracle complexity bounds for the average iterate, for both classes of methods. We further obtain generalizations of our results to weighted averaging of the iterates with increasing weights, which can be seen as interpolating between the last iterate and the average iterate guarantees. Additionally, we discuss how our results can be generalized to variants of studied incremental methods with permuted ordering of updates. Our results generalize last iterate guarantees for incremental methods compared to state of the art, as such results were previously known only for overparameterized linear models, which correspond to convex quadratic problems with infinitely many solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06873v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xufeng Cai, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>Heavy Ball Momentum for Non-Strongly Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.06930</link>
      <description>arXiv:2403.06930v1 Announce Type: new 
Abstract: When considering the minimization of a quadratic or strongly convex function, it is well known that first-order methods involving an inertial term weighted by a constant-in-time parameter are particularly efficient (see Polyak [32], Nesterov [28], and references therein). By setting the inertial parameter according to the condition number of the objective function, these methods guarantee a fast exponential decay of the error. We prove that this type of schemes (which are later called Heavy Ball schemes) is relevant in a relaxed setting, i.e. for composite functions satisfying a quadratic growth condition. In particular, we adapt V-FISTA, introduced by Beck in [10] for strongly convex functions, to this broader class of functions. To the authors' knowledge, the resulting worst-case convergence rates are faster than any other in the literature, including those of FISTA restart schemes. No assumption on the set of minimizers is required and guarantees are also given in the non-optimal case, i.e. when the condition number is not exactly known. This analysis follows the study of the corresponding continuous-time dynamical system (Heavy Ball with friction system), for which new convergence results of the trajectory are shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06930v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Fran\c{c}ois Aujol, Charles Dossal, Hippolyte Labarri\`ere, Aude Rondepierre</dc:creator>
    </item>
    <item>
      <title>Economic Capacity Withholding Bounds of Competitive Energy Storage Bidders</title>
      <link>https://arxiv.org/abs/2403.05705</link>
      <description>arXiv:2403.05705v1 Announce Type: cross 
Abstract: Economic withholding in electricity markets refers to generators bidding higher than their true marginal fuel cost, and is a typical approach to exercising market power. However, existing market designs require storage to design bids strategically based on their own future price predictions, motivating storage to conduct economic withholding without assuming market power. As energy storage takes up more significant roles in wholesale electricity markets, understanding its motivations for economic withholding and the consequent effects on social welfare becomes increasingly vital. This paper derives a theoretical framework to study the economic capacity withholding behavior of storage participating in competitive electricity markets and validate our results in simulations based on the ISO New England system. We demonstrate that storage bids can reach unbounded high levels under conditions where future price predictions show bounded expectations but unbounded deviations. Conversely, in scenarios with peak price limitations, we show the upper bounds of storage bids are grounded in bounded price expectations. Most importantly, we show that storage capacity withholding can potentially lower the overall system cost when price models account for system uncertainties. Our paper reveals energy storage is not a market manipulator but an honest player contributing to the social welfare. It helps electricity market researchers and operators better understand the economic withholding behavior of storage and reform market policies to maximize storage contributing to a cost-efficient decolonization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05705v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Qin, Ioannis Lestas, Bolun Xu</dc:creator>
    </item>
    <item>
      <title>Optimistic Safety for Linearly-Constrained Online Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.05786</link>
      <description>arXiv:2403.05786v1 Announce Type: cross 
Abstract: The setting of online convex optimization (OCO) under unknown constraints has garnered significant attention in recent years. In this work, we consider a version of this problem with static linear constraints that the player receives noisy feedback of and must always satisfy. By leveraging our novel design paradigm of optimistic safety, we give an algorithm for this problem that enjoys $\tilde{\mathcal{O}}(\sqrt{T})$ regret. This improves on the previous best regret bound of $\tilde{\mathcal{O}}(T^{2/3})$ while using only slightly stronger assumptions of independent noise and an oblivious adversary. Then, by recasting this problem as OCO under time-varying stochastic linear constraints, we show that our algorithm enjoys the same regret guarantees in such a setting and never violates the constraints in expectation. This contributes to the literature on OCO under time-varying stochastic constraints, where the state-of-the-art algorithms enjoy $\tilde{\mathcal{O}}(\sqrt{T})$ regret and $\tilde{\mathcal{O}}(\sqrt{T})$ violation when the constraints are convex and the player receives full feedback. Additionally, we provide a version of our algorithm that is more computationally efficient and give numerical experiments comparing it with benchmark algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05786v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Spencer Hutchinson, Tianyi Chen, Mahnoosh Alizadeh</dc:creator>
    </item>
    <item>
      <title>Another look at Residual Dynamic Mode Decomposition in the regime of fewer Snapshots than Dictionary Size</title>
      <link>https://arxiv.org/abs/2403.05891</link>
      <description>arXiv:2403.05891v1 Announce Type: cross 
Abstract: Residual Dynamic Mode Decomposition (ResDMD) offers a method for accurately computing the spectral properties of Koopman operators. It achieves this by calculating an infinite-dimensional residual from snapshot data, thus overcoming issues associated with finite truncations of Koopman operators, such as spurious eigenvalues. These spectral properties include spectra and pseudospectra, spectral measures, Koopman mode decompositions, and dictionary verification. In scenarios where there are fewer snapshots than dictionary size, particularly for exact DMD and kernelized EDMD, ResDMD has traditionally been applied by dividing snapshot data into a training set and a quadrature set. Through a novel computational approach of solving a dual least-squares problem, we demonstrate how to eliminate the need for two datasets. We provide an analysis of these new residuals for exact DMD and kernelized EDMD, demonstrating ResDMD's versatility and broad applicability across various dynamical systems, including those modeled by high-dimensional and nonlinear observables. The utility of these new residuals is showcased through three diverse examples: the analysis of cylinder wake, the study of aerofoil cascades, and the compression of transient shockwave experimental data. This approach not only simplifies the application of ResDMD but also extends its potential for deeper insights into the dynamics of complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05891v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <category>nlin.CD</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew J. Colbrook</dc:creator>
    </item>
    <item>
      <title>Unique reconstruction for discretized inverse problems: a random sketching approach</title>
      <link>https://arxiv.org/abs/2403.05935</link>
      <description>arXiv:2403.05935v1 Announce Type: cross 
Abstract: Inverse problem theory is often studied in the ideal infinite-dimensional setting. Through the lens of the PDE-constrained optimization, the well-posedness PDE theory suggests unique reconstruction of the parameter function that attain the zero-loss property of the mismatch function, when infinite amount of data is provided. Unfortunately, this is not the case in practice, when we are limited to finite amount of measurements due to experimental or economical reasons. Consequently, one must compromise the inference goal to a discrete approximation of the unknown smooth function.
  What is the reconstruction power of a fixed number of data observations? How many parameters can one reconstruct? Here we describe a probabilistic approach, and spell out the interplay of the observation size $(r)$ and the number of parameters to be uniquely identified $(m)$. The technical pillar is the random sketching strategy, in which the matrix concentration inequality and sampling theory are largely employed. By analyzing randomly sub-sampled Hessian matrix, we attain well-conditioned reconstruction problem with high probability. Our main theory is finally validated in numerical experiments. We set tests on both synthetic and the data from an elliptic inverse problem. The empirical performance shows that given suitable sampling quality, the well-conditioning of the sketched Hessian is certified with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05935v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruhui Jin, Qin Li, Anjali Nair, Samuel Stechmann</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning Paycheck Optimization for Multivariate Financial Goals</title>
      <link>https://arxiv.org/abs/2403.06011</link>
      <description>arXiv:2403.06011v1 Announce Type: cross 
Abstract: We study paycheck optimization, which examines how to allocate income in order to achieve several competing financial goals. For paycheck optimization, a quantitative methodology is missing, due to a lack of a suitable problem formulation. To deal with this issue, we formulate the problem as a utility maximization problem. The proposed formulation is able to (i) unify different financial goals; (ii) incorporate user preferences regarding the goals; (iii) handle stochastic interest rates. The proposed formulation also facilitates an end-to-end reinforcement learning solution, which is implemented on a variety of problem settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06011v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Risk and Decision Analysis, Volume 9, 2023</arxiv:journal_reference>
      <dc:creator>Melda Alaluf, Giulia Crippa, Sinong Geng, Zijian Jing, Nikhil Krishnan, Sanjeev Kulkarni, Wyatt Navarro, Ronnie Sircar, Jonathan Tang</dc:creator>
    </item>
    <item>
      <title>Fully discretized Sobolev gradient flow for the Gross-Pitaevskii eigenvalue problem</title>
      <link>https://arxiv.org/abs/2403.06028</link>
      <description>arXiv:2403.06028v1 Announce Type: cross 
Abstract: For the ground state of the Gross-Pitaevskii (GP) eigenvalue problem, we consider a fully discretized Sobolev gradient flow, which can be regarded as the Riemannian gradient descent on the sphere under a metric induced by a modified $H^1$-norm. We prove its global convergence to a critical point of the discrete GP energy and its local exponential convergence to the ground state of the discrete GP energy. The local exponential convergence rate depends on the eigengap of the discrete GP energy. When the discretization is the classical second-order finite difference in two dimensions, such an eigengap can be further proven to be mesh independent, i.e., it has a uniform positive lower bound, thus the local exponential convergence rate is mesh independent. Numerical experiments with discretization by high order $Q^k$ spectral element methods in two and three dimensions are provided to validate the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06028v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziang Chen, Jianfeng Lu, Yulong Lu, Xiangxiong Zhang</dc:creator>
    </item>
    <item>
      <title>An Improved Analysis of Langevin Algorithms with Prior Diffusion for Non-Log-Concave Sampling</title>
      <link>https://arxiv.org/abs/2403.06183</link>
      <description>arXiv:2403.06183v1 Announce Type: cross 
Abstract: Understanding the dimension dependency of computational complexity in high-dimensional sampling problem is a fundamental problem, both from a practical and theoretical perspective. Compared with samplers with unbiased stationary distribution, e.g., Metropolis-adjusted Langevin algorithm (MALA), biased samplers, e.g., Underdamped Langevin Dynamics (ULD), perform better in low-accuracy cases just because a lower dimension dependency in their complexities. Along this line, Freund et al. (2022) suggest that the modified Langevin algorithm with prior diffusion is able to converge dimension independently for strongly log-concave target distributions. Nonetheless, it remains open whether such property establishes for more general cases. In this paper, we investigate the prior diffusion technique for the target distributions satisfying log-Sobolev inequality (LSI), which covers a much broader class of distributions compared to the strongly log-concave ones. In particular, we prove that the modified Langevin algorithm can also obtain the dimension-independent convergence of KL divergence with different step size schedules. The core of our proof technique is a novel construction of an interpolating SDE, which significantly helps to conduct a more accurate characterization of the discrete updates of the overdamped Langevin dynamics. Our theoretical analysis demonstrates the benefits of prior diffusion for a broader class of target distributions and provides new insights into developing faster sampling algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06183v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xunpeng Huang, Hanze Dong, Difan Zou, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>Quantized Constant-Envelope Waveform Design for Massive MIMO DFRC Systems</title>
      <link>https://arxiv.org/abs/2403.06185</link>
      <description>arXiv:2403.06185v1 Announce Type: cross 
Abstract: Both dual-functional radar-communication (DFRC) and massive multiple-input multiple-output (MIMO) have been recognized as enabling technologies for 6G wireless networks. This paper considers the advanced waveform design for hardware-efficient massive MIMO DFRC systems. Specifically, the transmit waveform is imposed with the quantized constant-envelope (QCE) constraint, which facilitates the employment of low-resolution digital-to-analog converters (DACs) and power-efficient amplifiers. The waveform design problem is formulated as the minimization of the mean square error (MSE) between the designed and desired beampatterns subject to the constructive interference (CI)-based communication quality of service (QoS) constraints and the QCE constraint. To solve the formulated problem, we first utilize the penalty technique to transform the discrete problem into an equivalent continuous penalty model. Then, we propose an inexact augmented Lagrangian method (ALM) algorithm for solving the penalty model. In particular, the ALM subproblem at each iteration is solved by a custom-built block successive upper-bound minimization (BSUM) algorithm, which admits closed-form updates, making the proposed inexact ALM algorithm computationally efficient. Simulation results demonstrate the superiority of the proposed approach over existing state-of-the-art ones. In addition, extensive simulations are conducted to examine the impact of various system parameters on the trade-off between communication and radar performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06185v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheyu Wu, Ya-Feng Liu, Wei-Kun Chen, Christos Masouros</dc:creator>
    </item>
    <item>
      <title>Control of flow behavior in complex fluids using automatic differentiation</title>
      <link>https://arxiv.org/abs/2403.06257</link>
      <description>arXiv:2403.06257v1 Announce Type: cross 
Abstract: Inverse design of complex flows is notoriously challenging because of the high cost of high dimensional optimization. Usually, optimization problems are either restricted to few control parameters, or adjoint-based approaches are used to convert the optimization problem into a boundary value problem. Here, we show that the recent advances in automatic differentiation (AD) provide a generic platform for solving inverse problems in complex fluids. To demonstrate the versatility of the approach, we solve an array of optimization problems related to active matter motion in Newtonian fluids, dispersion in structured porous media, and mixing in journal bearing. Each of these problems highlights the advantages of AD in ease of implementation and computational efficiency to solve high-dimensional optimization problems involving particle-laden flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06257v1</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Alhashim, Kaylie Hausknecht, Michael Brenner</dc:creator>
    </item>
    <item>
      <title>A Tunable Universal Formula for Safety-Critical Control</title>
      <link>https://arxiv.org/abs/2403.06285</link>
      <description>arXiv:2403.06285v1 Announce Type: cross 
Abstract: Sontag's universal formula is a widely-used technique for stabilizing control through control Lyapunov functions, and it has been extended to address safety-critical control in recent years by incorporating control barrier functions (CBFs). However, how to derive a universal formula that satisfies requirements on essential properties, including safety, robustness, and smoothness, is still an open problem. To address this challenge, this paper introduces a novel solution - a tunable universal formula - incorporating a (state-dependent) tunable scaling term into Sontag's universal formula. This tunable scaling term enables the regulation of safety control performances, allowing the attainment of desired properties through a proper selection. Furthermore, we extend this tunable universal formula to address safety-critical control problems with norm-bounded input constraints, showcasing its applicability across diverse control scenarios. Finally, we demonstrate the efficacy of our method through a collision avoidance example, investigating the essential properties including safety, robustness, and smoothness under various tunable scaling terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06285v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Li, Zhiyong Sun, Patrick J. W. Koelewijn, Siep Weiland</dc:creator>
    </item>
    <item>
      <title>Disentangling Resilience from Robustness: Contextual Dualism, Interactionism, and Game-Theoretic Paradigms</title>
      <link>https://arxiv.org/abs/2403.06299</link>
      <description>arXiv:2403.06299v1 Announce Type: cross 
Abstract: This article explains the distinctions between robustness and resilience in control systems. Resilience confronts a distinct set of challenges, posing new ones for designing controllers for feedback systems, networks, and machines that prioritize resilience over robustness. The concept of resilience is explored through a three-stage model, emphasizing the need for a proactive preparation and automated response to elastic events. A toy model is first used to illustrate the tradeoffs between resilience and robustness. Then, it delves into contextual dualism and interactionism, and introduces game-theoretic paradigms as a unifying framework to consolidate resilience and robustness. The article concludes by discussing the interplay between robustness and resilience, suggesting that a comprehensive theory of resilience and quantification metrics, and formalization through game-theoretic frameworks are necessary. The exploration extends to system-of-systems resilience and various mechanisms, including the integration of AI techniques and non-technical solutions, like cyber insurance, to achieve comprehensive resilience in control systems. As we approach 2030, the systems and control community is at the opportune moment to lay scientific foundations of resilience by bridging feedback control theory, game theory, and learning theory. Resilient control systems will enhance overall quality of life, enable the development of a resilient society, and create a societal-scale impact amid global challenges such as climate change, conflicts, and cyber insecurity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06299v1</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Quanyan Zhu, Tamer Basar</dc:creator>
    </item>
    <item>
      <title>Designing a K-state P-bit Engine</title>
      <link>https://arxiv.org/abs/2403.06436</link>
      <description>arXiv:2403.06436v1 Announce Type: cross 
Abstract: Probabilistic bit (p-bit)-based compute engines utilize the unique capability of a p-bit to probabilistically switch between two states to solve computationally challenging problems. However, when solving problems that require more than two states (e.g., problems such as Max-3-Cut, verifying if a graph is K-partite (K&gt;2) etc.), additional pre-processing steps such as graph reduction are required to make the problem compatible with a two-state p-bit platform. Moreover, this not only increases the problem size by entailing the use of auxiliary variables but can also degrade the solution quality. In this work, we develop a unique framework for implementing a K-state (K&gt;2) p-bit engine. Furthermore, from an implementation standpoint, we show that such a K-state p-bit engine can be implemented using N traditional (2-state) p-bits, and one multi-state p-bit -- a novel concept proposed here. Augmenting traditional p-bit platforms, our approach enables us to solve an archetypal combinatoric problem class requiring multiple states, namely Max-K-Cut (K=3, 4 shown here), without using any additional auxiliary variables. Thus, our work fundamentally advances the functional capability of p-bit engines, enabling them to solve a broader class of computationally challenging problems more efficiently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06436v1</guid>
      <category>cs.ET</category>
      <category>math.OC</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Khairul Bashar, Abir Hasan, Nikhil Shukla</dc:creator>
    </item>
    <item>
      <title>Revisiting Cross-Diffusion for Overcrowding Dispersal in Interacting Species System</title>
      <link>https://arxiv.org/abs/2403.06464</link>
      <description>arXiv:2403.06464v1 Announce Type: cross 
Abstract: This work introduces and study a novel class of reaction-diffusion systems to model the evolution of two interacting species that disperse to avoid overcrowding. Our approach employs the principle of proximal minimization energy, implemented through a minimum flow proximal algorithm. This framework offers a potential generalization of existing systems commonly used in the theory of segregation for interacting species dynamics. Beyond existence and uniqueness, this approach allows us to capture the dynamic interplay between diffusion rates and concentration gradients of each species, and has the potential to significantly advance our understanding of how cross-diffusion shapes the spatial distribution, coexistence, and pattern formation of multiple species within a system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06464v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noureddine Igbida</dc:creator>
    </item>
    <item>
      <title>Scalable Distributed Optimization Despite Byzantine Adversaries</title>
      <link>https://arxiv.org/abs/2403.06502</link>
      <description>arXiv:2403.06502v1 Announce Type: cross 
Abstract: The problem of distributed optimization requires a group of networked agents to compute a parameter that minimizes the average of their local cost functions. While there are a variety of distributed optimization algorithms that can solve this problem, they are typically vulnerable to ``Byzantine'' agents that do not follow the algorithm. Recent attempts to address this issue focus on single dimensional functions, or assume certain statistical properties of the functions at the agents. In this paper, we provide two resilient, scalable, distributed optimization algorithms for multi-dimensional functions. Our schemes involve two filters, (1) a distance-based filter and (2) a min-max filter, which each remove neighborhood states that are extreme (defined precisely in our algorithms) at each iteration. We show that these algorithms can mitigate the impact of up to $F$ (unknown) Byzantine agents in the neighborhood of each regular agent. In particular, we show that if the network topology satisfies certain conditions, all of the regular agents' states are guaranteed to converge to a bounded region that contains the minimizer of the average of the regular agents' functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06502v1</guid>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kananart Kuwaranancharoen, Lei Xin, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>Extreme Point Pursuit -- Part I: A Framework for Constant Modulus Optimization</title>
      <link>https://arxiv.org/abs/2403.06506</link>
      <description>arXiv:2403.06506v1 Announce Type: cross 
Abstract: This study develops a framework for a class of constant modulus (CM) optimization problems, which covers binary constraints, discrete phase constraints, semi-orthogonal matrix constraints, non-negative semi-orthogonal matrix constraints, and several types of binary assignment constraints. Capitalizing on the basic principles of concave minimization and error bounds, we study a convex-constrained penalized formulation for general CM problems. The advantage of such formulation is that it allows us to leverage non-convex optimization techniques, such as the simple projected gradient method, to build algorithms. As the first part of this study, we explore the theory of this framework. We study conditions under which the formulation provides exact penalization results. We also examine computational aspects relating to the use of the projected gradient method for each type of CM constraint. Our study suggests that the proposed framework has a broad scope of applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06506v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junbin Liu, Ya Liu, Wing-Kin Ma, Mingjie Shao, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Extreme Point Pursuit -- Part II: Further Error Bound Analysis and Applications</title>
      <link>https://arxiv.org/abs/2403.06513</link>
      <description>arXiv:2403.06513v1 Announce Type: cross 
Abstract: In the first part of this study, a convex-constrained penalized formulation was studied for a class of constant modulus (CM) problems. In particular, the error bound techniques were shown to play a vital role in providing exact penalization results. In this second part of the study, we continue our error bound analysis for the cases of partial permutation matrices, size-constrained assignment matrices and non-negative semi-orthogonal matrices. We develop new error bounds and penalized formulations for these three cases, and the new formulations possess good structures for building computationally efficient algorithms. Moreover, we provide numerical results to demonstrate our framework in a variety of applications such as the densest k-subgraph problem, graph matching, size-constrained clustering, non-negative orthogonal matrix factorization and sparse fair principal component analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06513v1</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junbin Liu, Ya Liu, Wing-Kin Ma, Mingjie Shao, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Ride-pooling Electric Autonomous Mobility-on-Demand: Joint Optimization of Operations and Fleet and Infrastructure Design</title>
      <link>https://arxiv.org/abs/2403.06566</link>
      <description>arXiv:2403.06566v1 Announce Type: cross 
Abstract: This paper presents a modeling and design optimization framework for an Electric Autonomous Mobility-on-Demand system that allows for ride-pooling, i.e., multiple users can be transported at the same time towards a similar direction to decrease vehicle hours traveled by the fleet at the cost of additional waiting time and delays caused by detours. In particular, we first devise a multi-layer time-invariant network flow model that jointly captures the position and state of charge of the vehicles. Second, we frame the time-optimal operational problem of the fleet, including charging and ride-pooling decisions as a mixed-integer linear program, whereby we jointly optimize the placement of the charging infrastructure. Finally, we perform a case-study using Manhattan taxi-data. Our results indicate that jointly optimizing the charging infrastructure placement allows to decrease overall energy consumption of the fleet and vehicle hours traveled by approximately 1% compared to an heuristic placement. Most significantly, ride-pooling can decrease such costs considerably more, and up to 45%. Finally, we investigate the impact of the vehicle choice on the energy consumption of the fleet, comparing a lightweight two-seater with a heavier four-seater, whereby our results show that the former and latter designs are most convenient for low- and high-demand areas, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06566v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Paparella, Karni Chauhan, Luc Koenders, Theo Hofman, Mauro Salazar</dc:creator>
    </item>
    <item>
      <title>Scalable Online Exploration via Coverability</title>
      <link>https://arxiv.org/abs/2403.06571</link>
      <description>arXiv:2403.06571v1 Announce Type: cross 
Abstract: Exploration is a major challenge in reinforcement learning, especially for high-dimensional domains that require function approximation. We propose exploration objectives -- policy optimization objectives that enable downstream maximization of any reward function -- as a conceptual framework to systematize the study of exploration. Within this framework, we introduce a new objective, $L_1$-Coverage, which generalizes previous exploration schemes and supports three fundamental desiderata:
  1. Intrinsic complexity control. $L_1$-Coverage is associated with a structural parameter, $L_1$-Coverability, which reflects the intrinsic statistical difficulty of the underlying MDP, subsuming Block and Low-Rank MDPs.
  2. Efficient planning. For a known MDP, optimizing $L_1$-Coverage efficiently reduces to standard policy optimization, allowing flexible integration with off-the-shelf methods such as policy gradient and Q-learning approaches.
  3. Efficient exploration. $L_1$-Coverage enables the first computationally efficient model-based and model-free algorithms for online (reward-free or reward-driven) reinforcement learning in MDPs with low coverability.
  Empirically, we find that $L_1$-Coverage effectively drives off-the-shelf policy optimization algorithms to explore the state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06571v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Amortila, Dylan J. Foster, Akshay Krishnamurthy</dc:creator>
    </item>
    <item>
      <title>Passive iFIR filters for data-driven control</title>
      <link>https://arxiv.org/abs/2403.06640</link>
      <description>arXiv:2403.06640v1 Announce Type: cross 
Abstract: We consider the design of a new class of passive iFIR controllers given by the parallel action of an integrator and a finite impulse response filter. iFIRs are more expressive than PID controllers but retain their features and simplicity. The paper provides a model-free data-driven design for passive iFIR controllers based on virtual reference feedback tuning. Passivity is enforced through constrained optimization (three different formulations are discussed). The proposed design does not rely on large datasets or accurate plant models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06640v1</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixing Wang, Yongkang Huo, Fulvio Forni</dc:creator>
    </item>
    <item>
      <title>Efficient first-order algorithms for large-scale, non-smooth maximum entropy models with application to wildfire science</title>
      <link>https://arxiv.org/abs/2403.06816</link>
      <description>arXiv:2403.06816v1 Announce Type: cross 
Abstract: Maximum entropy (Maxent) models are a class of statistical models that use the maximum entropy principle to estimate probability distributions from data. Due to the size of modern data sets, Maxent models need efficient optimization algorithms to scale well for big data applications. State-of-the-art algorithms for Maxent models, however, were not originally designed to handle big data sets; these algorithms either rely on technical devices that may yield unreliable numerical results, scale poorly, or require smoothness assumptions that many practical Maxent models lack. In this paper, we present novel optimization algorithms that overcome the shortcomings of state-of-the-art algorithms for training large-scale, non-smooth Maxent models. Our proposed first-order algorithms leverage the Kullback-Leibler divergence to train large-scale and non-smooth Maxent models efficiently. For Maxent models with discrete probability distribution of $n$ elements built from samples, each containing $m$ features, the stepsize parameters estimation and iterations in our algorithms scale on the order of $O(mn)$ operations and can be trivially parallelized. Moreover, the strong $\ell_{1}$ convexity of the Kullback--Leibler divergence allows for larger stepsize parameters, thereby speeding up the convergence rate of our algorithms. To illustrate the efficiency of our novel algorithms, we consider the problem of estimating probabilities of fire occurrences as a function of ecological features in the Western US MTBS-Interagency wildfire data set. Our numerical results show that our algorithms outperform the state of the arts by one order of magnitude and yield results that agree with physical models of wildfire occurrence and previous statistical analyses of wildfire drivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06816v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel P. Langlois, Jatan Buch, J\'er\^ome Darbon</dc:creator>
    </item>
    <item>
      <title>Robust optimality and duality for composite uncertain multiobjective optimization in Asplund spaces with its applications</title>
      <link>https://arxiv.org/abs/2211.07611</link>
      <description>arXiv:2211.07611v3 Announce Type: replace 
Abstract: This article is devoted to investigate a nonsmooth/nonconvex uncertain multiobjective optimization problem with composition fields (CUP) for brevity) over arbitrary Asplund spaces. Employing some advanced techniques of variational analysis and generalized differentiation, we establish necessary optimality conditions for weakly robust efficient solutions of (CUP) in terms of the limiting subdifferential. Sufficient conditions for the existence of (weakly) robust efficient solutions to such a problem are also driven under the new concept of pseudo-quasi convexity for composite functions. We formulate a Mond-Weir-type robust dual problem to the primal problem (CUP), and explore weak, strong, and converse duality properties. In addition, the obtained results are applied to an approximate uncertain multiobjective problem and a composite uncertain multiobjective problem with linear operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07611v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11117-024-01032-9</arxiv:DOI>
      <dc:creator>Maryam Saadati, Morteza Oveisiha</dc:creator>
    </item>
    <item>
      <title>Handbook of Convergence Theorems for (Stochastic) Gradient Methods</title>
      <link>https://arxiv.org/abs/2301.11235</link>
      <description>arXiv:2301.11235v3 Announce Type: replace 
Abstract: This is a handbook of simple proofs of the convergence of gradient and stochastic gradient descent type methods. We consider functions that are Lipschitz, smooth, convex, strongly convex, and/or Polyak-{\L}ojasiewicz functions. Our focus is on ``good proofs'' that are also simple. Each section can be consulted separately. We start with proofs of gradient descent, then on stochastic variants, including minibatching and momentum. Then move on to nonsmooth problems with the subgradient method, the proximal gradient descent and their stochastic variants. Our focus is on global convergence rates and complexity rates. Some slightly less common proofs found here include that of SGD (Stochastic gradient descent) with a proximal step, with momentum, and with mini-batching without replacement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.11235v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Garrigos, Robert M. Gower</dc:creator>
    </item>
    <item>
      <title>Recent Developments in Machine Learning Methods for Stochastic Control and Games</title>
      <link>https://arxiv.org/abs/2303.10257</link>
      <description>arXiv:2303.10257v3 Announce Type: replace 
Abstract: Stochastic optimal control and games have a wide range of applications, from finance and economics to social sciences, robotics, and energy management. Many real-world applications involve complex models that have driven the development of sophisticated numerical methods. Recently, computational methods based on machine learning have been developed for solving stochastic control problems and games. In this review, we focus on deep learning methods that have unlocked the possibility of solving such problems, even in high dimensions or when the structure is very complex, beyond what traditional numerical methods can achieve. We consider mostly the continuous time and continuous space setting. Many of the new approaches build on recent neural-network-based methods for solving high-dimensional partial differential equations or backward stochastic differential equations, or on model-free reinforcement learning for Markov decision processes that have led to breakthrough results. This paper provides an introduction to these methods and summarizes the state-of-the-art works at the crossroad of machine learning and stochastic control and games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.10257v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruimeng Hu, Mathieu Lauri\`ere</dc:creator>
    </item>
    <item>
      <title>Convergence Rate of Learning a Strongly Variationally Stable Equilibrium</title>
      <link>https://arxiv.org/abs/2304.02355</link>
      <description>arXiv:2304.02355v2 Announce Type: replace 
Abstract: We derive the rate of convergence to the strongly variationally stable Nash equilibrium in a convex game, for a zeroth-order learning algorithm. Though we do not assume strong monotonicity of the game, our rates for the one-point feedback and for the two-point feedback match the best known rates for strongly monotone games under zeroth-order information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02355v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tatiana Tatarenko, Maryam Kamgarpour</dc:creator>
    </item>
    <item>
      <title>A Mixing-Accelerated Primal-Dual Proximal Algorithm for Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2304.02830</link>
      <description>arXiv:2304.02830v2 Announce Type: replace 
Abstract: In this paper, we develop a distributed mixing-accelerated primal-dual proximal algorithm, referred to as MAP-Pro, which enables nodes in multi-agent networks to cooperatively minimize the sum of their nonconvex, smooth local cost functions in a decentralized fashion. The proposed algorithm is constructed upon minimizing a computationally inexpensive augmented-Lagrangian-like function and incorporating a time-varying mixing polynomial to expedite information fusion across the network. The convergence results derived for MAP-Pro include a sublinear rate of convergence to a stationary solution and, under the Polyak-{\L}ojasiewics (P-{\L}) condition, a linear rate of convergence to the global optimal solution. Additionally, we may embed the well-noted Chebyshev acceleration scheme in MAP-Pro, which generates a specific sequence of mixing polynomials with given degrees and enhances the convergence performance based on MAP-Pro. Finally, we illustrate the competitive convergence speed and communication efficiency of MAP-Pro via a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.02830v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zichong Ou, Chenyang Qiu, Dandan Wang, Jie Lu</dc:creator>
    </item>
    <item>
      <title>A Stochastic-Gradient-based Interior-Point Algorithm for Solving Smooth Bound-Constrained Optimization Problems</title>
      <link>https://arxiv.org/abs/2304.14907</link>
      <description>arXiv:2304.14907v2 Announce Type: replace 
Abstract: A stochastic-gradient-based interior-point algorithm for minimizing a continuously differentiable objective function (that may be nonconvex) subject to bound constraints is presented, analyzed, and demonstrated through experimental results. The algorithm is unique from other interior-point methods for solving smooth \edit{nonconvex} optimization problems since the search directions are computed using stochastic gradient estimates. It is also unique in its use of inner neighborhoods of the feasible region -- defined by a positive and vanishing neighborhood-parameter sequence -- in which the iterates are forced to remain. It is shown that with a careful balance between the barrier, step-size, and neighborhood sequences, the proposed algorithm satisfies convergence guarantees in both deterministic and stochastic settings. The results of numerical experiments show that in both settings the algorithm can outperform \edit{projection-based} methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14907v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank E. Curtis, Vyacheslav Kungurtsev, Daniel P. Robinson, Qi Wang</dc:creator>
    </item>
    <item>
      <title>Modeling Model Predictive Control: A Category Theoretic Framework for Multistage Control Problems</title>
      <link>https://arxiv.org/abs/2305.03820</link>
      <description>arXiv:2305.03820v2 Announce Type: replace 
Abstract: Model predictive control (MPC) is an optimal control technique which involves solving a sequence of constrained optimization problems across a given time horizon. In this paper, we introduce a category theoretic framework for constructing complex MPC problem formulations by composing subproblems. Specifically, we construct a monoidal category - called Para(Conv) - whose objects are Euclidean spaces and whose morphisms represent constrained convex optimization problems. We then show that the multistage structure of typical MPC problems arises from sequential composition in Para(Conv), while parallel composition can be used to model constraints across multiple stages of the prediction horizon. This framework comes equipped with a rigorous, diagrammatic syntax, allowing for easy visualization and modification of complex problems. Finally, we show how this framework allows a simple software realization in the Julia programming language by integrating with existing mathematical programming libraries to provide high-level, graphical abstractions for MPC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03820v2</guid>
      <category>math.OC</category>
      <category>math.CT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tyler Hanks, Baike She, Matthew Hale, Evan Patterson, Matthew Klawonn, James Fairbanks</dc:creator>
    </item>
    <item>
      <title>Differential-Equation Constrained Optimization With Stochasticity</title>
      <link>https://arxiv.org/abs/2305.04024</link>
      <description>arXiv:2305.04024v2 Announce Type: replace 
Abstract: Most inverse problems from physical sciences are formulated as PDE-constrained optimization problems. This involves identifying unknown parameters in equations by optimizing the model to generate PDE solutions that closely match measured data. The formulation is powerful and widely used in many sciences and engineering fields. However, one crucial assumption is that the unknown parameter must be deterministic. In reality, however, many problems are stochastic in nature, and the unknown parameter is random. The challenge then becomes recovering the full distribution of this unknown random parameter. It is a much more complex task. In this paper, we examine this problem in a general setting. In particular, we conceptualize the PDE solver as a push-forward map that pushes the parameter distribution to the generated data distribution. This way, the SDE-constrained optimization translates to minimizing the distance between the generated distribution and the measurement distribution. We then formulate a gradient-flow equation to seek the ground-truth parameter probability distribution. This opens up a new paradigm for extending many techniques in PDE-constrained optimization to that for systems with stochasticity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04024v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qin Li, Li Wang, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Sharpened Lazy Incremental Quasi-Newton Method</title>
      <link>https://arxiv.org/abs/2305.17283</link>
      <description>arXiv:2305.17283v2 Announce Type: replace 
Abstract: The problem of minimizing the sum of $n$ functions in $d$ dimensions is ubiquitous in machine learning and statistics. In many applications where the number of observations $n$ is large, it is necessary to use incremental or stochastic methods, as their per-iteration cost is independent of $n$. Of these, Quasi-Newton (QN) methods strike a balance between the per-iteration cost and the convergence rate. Specifically, they exhibit a superlinear rate with $O(d^2)$ cost in contrast to the linear rate of first-order methods with $O(d)$ cost and the quadratic rate of second-order methods with $O(d^3)$ cost. However, existing incremental methods have notable shortcomings: Incremental Quasi-Newton (IQN) only exhibits asymptotic superlinear convergence. In contrast, Incremental Greedy BFGS (IGS) offers explicit superlinear convergence but suffers from poor empirical performance and has a per-iteration cost of $O(d^3)$. To address these issues, we introduce the Sharpened Lazy Incremental Quasi-Newton Method (SLIQN) that achieves the best of both worlds: an explicit superlinear convergence rate, and superior empirical performance at a per-iteration $O(d^2)$ cost. SLIQN features two key changes: first, it incorporates a hybrid strategy of using both classic and greedy BFGS updates, allowing it to empirically outperform both IQN and IGS. Second, it employs a clever constant multiplicative factor along with a lazy propagation strategy, which enables it to have a cost of $O(d^2)$. Additionally, our experiments demonstrate the superiority of SLIQN over other incremental and stochastic Quasi-Newton variants and establish its competitiveness with second-order incremental methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17283v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aakash Lahoti, Spandan Senapati, Ketan Rajawat, Alec Koppel</dc:creator>
    </item>
    <item>
      <title>A Distributed Optimization Framework to Regulate the Electricity Consumption of a Residential Neighborhood</title>
      <link>https://arxiv.org/abs/2306.09954</link>
      <description>arXiv:2306.09954v2 Announce Type: replace 
Abstract: Increased variability of electricity generation due to renewable sources requires either large amounts of stand-by production capacity or some form of demand response. For residential loads, space heating and cooling, water heating, electric vehicle charging, and routine appliances make up the bulk of the electricity consumption. Controlling these loads can reduce the peak load of a residential neighborhood and facilitate matching supply with demand. However, maintaining user comfort is important for ensuring user participation to such a program. This paper formulates a novel mixed integer linear programming problem to control the overall electricity consumption of a residential neighborhood by considering the users' comfort. To efficiently solve the problem for communities involving a large number of homes, a distributed optimization framework based on the Dantzig-Wolfe decomposition technique is developed. We demonstrate the load shaping capacity and the computational performance of the proposed optimization framework in a simulated environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09954v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erhan Can Ozcan, Ioannis Ch. Paschalidis</dc:creator>
    </item>
    <item>
      <title>Theory and applications of the Sum-Of-Squares technique</title>
      <link>https://arxiv.org/abs/2306.16255</link>
      <description>arXiv:2306.16255v3 Announce Type: replace 
Abstract: The Sum-of-Squares (SOS) approximation method is a technique used in optimization problems to derive lower bounds on the optimal value of an objective function. By representing the objective function as a sum of squares in a feature space, the SOS method transforms non-convex global optimization problems into solvable semidefinite programs. This note presents an overview of the SOS method. We start with its application in finite-dimensional feature spaces and, subsequently, we extend it to infinite-dimensional feature spaces using reproducing kernels (k-SOS). Additionally, we highlight the utilization of SOS for estimating some relevant quantities in information theory, including the log-partition function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16255v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francis Bach, Elisabetta Cornacchia, Luca Pesce, Giovanni Piccioli</dc:creator>
    </item>
    <item>
      <title>Data-driven MPC with stability guarantees using extended dynamic mode decomposition</title>
      <link>https://arxiv.org/abs/2308.00296</link>
      <description>arXiv:2308.00296v4 Announce Type: replace 
Abstract: For nonlinear (control) systems, extended dynamic mode decomposition (EDMD) is a popular method to obtain data-driven surrogate models. Its theoretical foundation is the Koopman framework, in which one propagates observable functions of the state to obtain a linear representation in an infinite-dimensional space. In this work, we prove practical asymptotic stability of a (controlled) equilibrium for EDMD-based model predictive control, in which the optimization step is conducted using the data-based surrogate model. To this end, we derive novel bounds on the estimation error that are proportional to the norm of state and control. This enables us to show that, if the underlying system is cost controllable, this stabilizablility property is preserved. We conduct numerical simulations illustrating the proven practical asymptotic stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00296v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lea Bold, Lars Gr\"une, Manuel Schaller, Karl Worthmann</dc:creator>
    </item>
    <item>
      <title>Funnel MPC for nonlinear systems with arbitrary relative degree</title>
      <link>https://arxiv.org/abs/2308.12217</link>
      <description>arXiv:2308.12217v2 Announce Type: replace 
Abstract: The Model Predictive Control (MPC) scheme Funnel MPC enables output tracking of smooth reference signals with prescribed error bounds for nonlinear multi-input multi-output systems with stable internal dynamics. Earlier works achieved the control objective for system with relative degree restricted to one or incorporated additional feasibility constraints in the optimal control problem. Here we resolve these limitations by introducing a modified stage cost function relying on a weighted sum of the tracking error derivatives. The weights need to be sufficiently large and we state explicit lower bounds. Under these assumptions we are able to prove initial and recursive feasibility of the novel Funnel MPC scheme for systems with arbitrary relative degree - without requiring any terminal conditions, a sufficiently long prediction horizon or additional output constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.12217v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Berger, Dario Dennst\"adt</dc:creator>
    </item>
    <item>
      <title>Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates</title>
      <link>https://arxiv.org/abs/2310.09804</link>
      <description>arXiv:2310.09804v2 Announce Type: replace 
Abstract: Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression - Byz-DASHA-PAGE - and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the first Byzantine-robust method with communication compression and error feedback - Byz-EF21 - along with its bidirectional compression version - Byz-EF21-BC - and derive the convergence rates for these methods for non-convex and Polyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our theoretical findings in the numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09804v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Ahmad Rammal, Kaja Gruntkowska, Nikita Fedin, Eduard Gorbunov, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Mixed-integer linearity in nonlinear optimization: a trust region approach</title>
      <link>https://arxiv.org/abs/2310.17285</link>
      <description>arXiv:2310.17285v2 Announce Type: replace 
Abstract: Bringing together nonlinear optimization with polyhedral and integrality constraints enables versatile modeling, but poses significant computational challenges. We investigate a method to address these problems based on sequential mixed-integer linearization with trust region safeguard, computing feasible iterates via calls to a generic mixed-integer linear solver. Convergence to critical, possibly suboptimal, feasible points is established for arbitrary starting points. Finally, we present numerical applications in nonsmooth optimal control and optimal network design and operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17285v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto De Marchi</dc:creator>
    </item>
    <item>
      <title>Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging</title>
      <link>https://arxiv.org/abs/2311.02557</link>
      <description>arXiv:2311.02557v2 Announce Type: replace 
Abstract: Consider the problem of minimizing an expected logarithmic loss over either the probability simplex or the set of quantum density matrices. This problem includes tasks such as solving the Poisson inverse problem, computing the maximum-likelihood estimate for quantum state tomography, and approximating positive semi-definite matrix permanents with the currently tightest approximation ratio. Although the optimization problem is convex, standard iteration complexity guarantees for first-order methods do not directly apply due to the absence of Lipschitz continuity and smoothness in the loss function.
  In this work, we propose a stochastic first-order algorithm named $B$-sample stochastic dual averaging with the logarithmic barrier. For the Poisson inverse problem, our algorithm attains an $\varepsilon$-optimal solution in $\smash{\tilde{O}}(d^2/\varepsilon^2)$ time, matching the state of the art, where $d$ denotes the dimension. When computing the maximum-likelihood estimate for quantum state tomography, our algorithm yields an $\varepsilon$-optimal solution in $\smash{\tilde{O}}(d^3/\varepsilon^2)$ time. This improves on the time complexities of existing stochastic first-order methods by a factor of $d^{\omega-2}$ and those of batch methods by a factor of $d^2$, where $\omega$ denotes the matrix multiplication exponent. Numerical experiments demonstrate that empirically, our algorithm outperforms existing methods with explicit complexity guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02557v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-En Tsai, Hao-Chung Cheng, Yen-Huan Li</dc:creator>
    </item>
    <item>
      <title>On the tractability of Nash equilibrium</title>
      <link>https://arxiv.org/abs/2311.05644</link>
      <description>arXiv:2311.05644v3 Announce Type: replace 
Abstract: In this paper, we propose a method for solving a PPAD-complete problem [Papadimitriou, 1994]. Given is the payoff matrix $C$ of a symmetric bimatrix game $(C, C^T)$ and our goal is to compute a Nash equilibrium of $(C, C^T)$. In this paper, we devise a nonlinear replicator dynamic (whose right-hand-side can be obtained by solving a pair of convex optimization problems) with the following property: Under any invertible $0 &lt; C \leq 1$, every orbit of our dynamic starting at an interior strategy of the standard simplex approaches a set of strategies of $(C, C^T)$ such that, for each strategy in this set, a symmetric Nash equilibrium strategy can be computed by solving the aforementioned convex mathematical programs. We prove convergence using results in analysis (the analytic implicit function theorem), nonlinear optimization theory (duality theory, Berge's maximum principle, and a theorem of Robinson [1980] on the Lipschitz continuity of parametric nonlinear programs), and dynamical systems theory (such as the LaSalle invariance principle).</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05644v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioannis Avramopoulos</dc:creator>
    </item>
    <item>
      <title>Optimality conditions for bilevel programs via Moreau envelope reformulation</title>
      <link>https://arxiv.org/abs/2311.14857</link>
      <description>arXiv:2311.14857v2 Announce Type: replace 
Abstract: For bilevel programs with a convex lower level program, the classical approach replaces the lower level program with its Karush-Kuhn-Tucker condition and solve the resulting mathematical program with complementarity constraint (MPCC). It is known that when the set of lower level multipliers is not unique, MPCC may not be equivalent to the original bilevel problem, and many MPCC-tailored constraint qualifications do not hold. In this paper, we study bilevel programs where the lower level is generalized convex. Applying the equivalent reformulation via Moreau envelope, we derive new directional optimality conditions. Even in the nondirectional case, the new optimality condition is stronger than the strong stationarity for the corresponding MPCC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14857v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kuang Bai, Jane Ye, Shangzhi Zeng</dc:creator>
    </item>
    <item>
      <title>Continuous Approximations of Projected Dynamical Systems via Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2403.00447</link>
      <description>arXiv:2403.00447v2 Announce Type: replace 
Abstract: Projected Dynamical Systems (PDSs) form a class of discontinuous constrained dynamical systems, and have been used widely to solve optimization problems and variational inequalities. Recently, they have also gained significant attention for control purposes, such as high-performance integrators, saturated control and feedback optimization. In this work, we establish that locally Lipschitz continuous dynamics, involving Control Barrier Functions (CBFs), namely CBF-based dynamics, approximate PDSs. Specifically, we prove that trajectories of CBF-based dynamics uniformly converge to trajectories of PDSs, as a CBF-parameter is taken to infinity. Towards this, we also prove that CBF-based dynamics are perturbations of PDSs, with quantitative bounds on the perturbation. Our results pave the way to implement discontinuous PDS-based controllers in a continuous fashion, employing CBFs. Moreover, they can be employed to numerically simulate PDSs, overcoming disadvantages of existing discretization schemes, such as computing projections to possibly non-convex sets. Finally, this bridge between CBFs and PDSs may yield other potential benefits, including novel insights on stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00447v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giannis Delimpaltadakis, Jorge Cort\'es, W. P. M. H. Heemels</dc:creator>
    </item>
    <item>
      <title>Shape optimization in the space of piecewise-smooth shapes for the Bingham flow variational inequality</title>
      <link>https://arxiv.org/abs/2403.02106</link>
      <description>arXiv:2403.02106v2 Announce Type: replace 
Abstract: This paper sets up an approach for shape optimization problems constrained by variational inequalities (VI) in an appropriate shape space. In contrast to classical VI, where no explicit dependence on the domain is given, VI constrained shape optimization problems are in particular highly challenging because of two main reasons: Firstly, one needs to operate in inherently non-linear, non-convex and infinite-dimensional shape spaces. Secondly, the problem cannot be solved directly without any regularization techniques in general because, e.g., one cannot expect the existence of the shape derivative for an arbitrary shape functional depending on solutions to VI. This paper introduces a specific shape manifold and presents an optimization technique to handle the non-differentiabilities on this shape manifold. In particular, we formulate an optimization system based on G\^ateaux semiderivatives and Eulerian derivatives for a shape optimization problem constrained by the Bingham flow variational inequality. Numerical results show the applicability and efficiency of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02106v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim SuchanHelmut-Schmidt-Universit\"at/Universit\"at der Bundeswehr Hamburg, Germany, Volker SchulzUniversit\"at Trier, Germany, Kathrin WelkerTU Bergakademie Freiberg, Germany</dc:creator>
    </item>
    <item>
      <title>Chance-Constrained Control for Safe Spacecraft Autonomy: Convex Programming Approach</title>
      <link>https://arxiv.org/abs/2403.04062</link>
      <description>arXiv:2403.04062v2 Announce Type: replace 
Abstract: This paper presents a robust path-planning framework for safe spacecraft autonomy under uncertainty and develops a computationally tractable formulation based on convex programming. We utilize chance-constrained control to formulate the problem. It provides a mathematical framework to solve for a sequence of control policies that minimizes a probabilistic cost under probabilistic constraints with a user-defined confidence level (e.g., safety with 99.9% confidence). The framework enables the planner to directly control state distributions under operational uncertainties while ensuring the vehicle safety. This paper rigorously formulates the safe autonomy problem, gathers and extends techniques in literature to accommodate key cost/constraint functions that often arise in spacecraft path planning, and develops a tractable solution method. The presented framework is demonstrated via two representative numerical examples: safe autonomous rendezvous and orbit maintenance in cislunar space, both under uncertainties due to navigation error from Kalman filter, execution error via Gates model, and imperfect force models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04062v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kenshiro Oguri</dc:creator>
    </item>
    <item>
      <title>Online Reinforcement Learning in Markov Decision Process Using Linear Programming</title>
      <link>https://arxiv.org/abs/2304.00155</link>
      <description>arXiv:2304.00155v3 Announce Type: replace-cross 
Abstract: We consider online reinforcement learning in episodic Markov decision process (MDP) with unknown transition function and stochastic rewards drawn from some fixed but unknown distribution. The learner aims to learn the optimal policy and minimize their regret over a finite time horizon through interacting with the environment. We devise a simple and efficient model-based algorithm that achieves $\widetilde{O}(LX\sqrt{TA})$ regret with high probability, where $L$ is the episode length, $T$ is the number of episodes, and $X$ and $A$ are the cardinalities of the state space and the action space, respectively. The proposed algorithm, which is based on the concept of ``optimism in the face of uncertainty", maintains confidence sets of transition and reward functions and uses occupancy measures to connect the online MDP with linear programming. It achieves a tighter regret bound compared to the existing works that use a similar confidence set framework and improves computational effort compared to those that use a different framework but with a slightly tighter regret bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00155v3</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC49753.2023.10383839</arxiv:DOI>
      <arxiv:journal_reference>2023 62nd IEEE Conference on Decision and Control (CDC)</arxiv:journal_reference>
      <dc:creator>Vincent Leon, S. Rasoul Etesami</dc:creator>
    </item>
    <item>
      <title>Sparse Cholesky Factorization for Solving Nonlinear PDEs via Gaussian Processes</title>
      <link>https://arxiv.org/abs/2304.01294</link>
      <description>arXiv:2304.01294v3 Announce Type: replace-cross 
Abstract: In recent years, there has been widespread adoption of machine learning-based approaches to automate the solving of partial differential equations (PDEs). Among these approaches, Gaussian processes (GPs) and kernel methods have garnered considerable interest due to their flexibility, robust theoretical guarantees, and close ties to traditional methods. They can transform the solving of general nonlinear PDEs into solving quadratic optimization problems with nonlinear, PDE-induced constraints. However, the complexity bottleneck lies in computing with dense kernel matrices obtained from pointwise evaluations of the covariance kernel, and its \textit{partial derivatives}, a result of the PDE constraint and for which fast algorithms are scarce.
  The primary goal of this paper is to provide a near-linear complexity algorithm for working with such kernel matrices. We present a sparse Cholesky factorization algorithm for these matrices based on the near-sparsity of the Cholesky factor under a novel ordering of pointwise and derivative measurements. The near-sparsity is rigorously justified by directly connecting the factor to GP regression and exponential decay of basis functions in numerical homogenization. We then employ the Vecchia approximation of GPs, which is optimal in the Kullback-Leibler divergence, to compute the approximate factor. This enables us to compute $\epsilon$-approximate inverse Cholesky factors of the kernel matrices with complexity $O(N\log^d(N/\epsilon))$ in space and $O(N\log^{2d}(N/\epsilon))$ in time. We integrate sparse Cholesky factorizations into optimization algorithms to obtain fast solvers of the nonlinear PDE. We numerically illustrate our algorithm's near-linear space/time complexity for a broad class of nonlinear PDEs such as the nonlinear elliptic, Burgers, and Monge-Amp\`ere equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01294v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Chen, Houman Owhadi, Florian Sch\"afer</dc:creator>
    </item>
    <item>
      <title>Dyadic partition-based training schemes for TV/TGV denoising</title>
      <link>https://arxiv.org/abs/2305.07150</link>
      <description>arXiv:2305.07150v2 Announce Type: replace-cross 
Abstract: Due to their ability to handle discontinuous images while having a well-understood behavior, regularizations with total variation (TV) and total generalized variation (TGV) are some of the best-known methods in image denoising. However, like other variational models including a fidelity term, they crucially depend on the choice of their tuning parameters. A remedy is to choose these automatically through multilevel approaches, for example by optimizing performance on noisy/clean image pairs. In this work, we consider such methods with space-dependent parameters which are piecewise constant on dyadic grids, with the grid itself being part of the minimization. We prove existence of minimizers for fixed discontinuous parameters under mild assumptions on the data, which lead to existence of finite optimal partitions. We further establish that these assumptions are equivalent to the commonly used box constraints on the parameters. On the numerical side, we consider a simple subdivision scheme for optimal partitions built on top of any other bilevel optimization method for scalar parameters, and demonstrate its improved performance on some representative test images when compared with constant optimized parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.07150v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elisa Davoli, Rita Ferreira, Irene Fonseca, Jos\'e A. Iglesias</dc:creator>
    </item>
    <item>
      <title>Contextual Bandits with Budgeted Information Reveal</title>
      <link>https://arxiv.org/abs/2305.18511</link>
      <description>arXiv:2305.18511v2 Announce Type: replace-cross 
Abstract: Contextual bandit algorithms are commonly used in digital health to recommend personalized treatments. However, to ensure the effectiveness of the treatments, patients are often requested to take actions that have no immediate benefit to them, which we refer to as pro-treatment actions. In practice, clinicians have a limited budget to encourage patients to take these actions and collect additional information. We introduce a novel optimization and learning algorithm to address this problem. This algorithm effectively combines the strengths of two algorithmic approaches in a seamless manner, including 1) an online primal-dual algorithm for deciding the optimal timing to reach out to patients, and 2) a contextual bandit learning algorithm to deliver personalized treatment to the patient. We prove that this algorithm admits a sub-linear regret bound. We illustrate the usefulness of this algorithm on both synthetic and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.18511v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kyra Gan, Esmaeil Keyvanshokooh, Xueqing Liu, Susan Murphy</dc:creator>
    </item>
    <item>
      <title>Automated Importance Sampling via Optimal Control for Stochastic Reaction Networks: A Markovian Projection-based Approach</title>
      <link>https://arxiv.org/abs/2306.02660</link>
      <description>arXiv:2306.02660v2 Announce Type: replace-cross 
Abstract: We propose a novel alternative approach to our previous work (Ben Hammouda et al., 2023) to improve the efficiency of Monte Carlo (MC) estimators for rare event probabilities for stochastic reaction networks (SRNs). In the same spirit of (Ben Hammouda et al., 2023), an efficient path-dependent measure change is derived based on a connection between determining optimal importance sampling (IS) parameters within a class of probability measures and a stochastic optimal control formulation, corresponding to solving a variance minimization problem. In this work, we propose a novel approach to address the encountered curse of dimensionality by mapping the problem to a significantly lower-dimensional space via a Markovian projection (MP) idea. The output of this model reduction technique is a low-dimensional SRN (potentially even one dimensional) that preserves the marginal distribution of the original high-dimensional SRN system. The dynamics of the projected process are obtained by solving a related optimization problem via a discrete $L^2$ regression. By solving the resulting projected Hamilton-Jacobi-Bellman (HJB) equations for the reduced-dimensional SRN, we obtain projected IS parameters, which are then mapped back to the original full-dimensional SRN system, resulting in an efficient IS-MC estimator for rare events probabilities of the full-dimensional SRN. Our analysis and numerical experiments reveal that the proposed MP-HJB-IS approach substantially reduces the MC estimator variance, resulting in a lower computational complexity in the rare event regime than standard MC estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02660v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cam.2024.115853</arxiv:DOI>
      <dc:creator>Chiheb Ben Hammouda, Nadhir Ben Rached, Ra\'ul Tempone, Sophia Wiechert</dc:creator>
    </item>
    <item>
      <title>Error Feedback Can Accurately Compress Preconditioners</title>
      <link>https://arxiv.org/abs/2306.06098</link>
      <description>arXiv:2306.06098v4 Announce Type: replace-cross 
Abstract: Leveraging second-order information about the loss at the scale of deep networks is one of the main lines of approach for improving the performance of current optimizers for deep learning. Yet, existing approaches for accurate full-matrix preconditioning, such as Full-Matrix Adagrad (GGT) or Matrix-Free Approximate Curvature (M-FAC) suffer from massive storage costs when applied even to small-scale models, as they must store a sliding window of gradients, whose memory requirements are multiplicative in the model dimension. In this paper, we address this issue via a novel and efficient error-feedback technique that can be applied to compress preconditioners by up to two orders of magnitude in practice, without loss of convergence. Specifically, our approach compresses the gradient information via sparsification or low-rank compression \emph{before} it is fed into the preconditioner, feeding the compression error back into future iterations. Experiments on deep neural networks show that this approach can compress full-matrix preconditioners to up to 99\% sparsity without accuracy loss, effectively removing the memory overhead of full-matrix preconditioners such as GGT and M-FAC. Our code is available at \url{https://github.com/IST-DASLab/EFCP}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06098v4</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ionut-Vlad Modoranu, Aleksei Kalinov, Eldar Kurtic, Elias Frantar, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>Data-Driven Adversarial Online Control for Unknown Linear Systems</title>
      <link>https://arxiv.org/abs/2308.08138</link>
      <description>arXiv:2308.08138v2 Announce Type: replace-cross 
Abstract: We consider the online control problem with an unknown linear dynamical system in the presence of adversarial perturbations and adversarial convex loss functions. Although the problem is widely studied in model-based control, it remains unclear whether data-driven approaches, which bypass the system identification step, can solve the problem. In this work, we present a novel data-driven online adaptive control algorithm to address this online control problem. Our algorithm leverages the behavioral systems theory to learn a non-parametric system representation and then adopts a perturbation-based controller updated by online gradient descent. We prove that our algorithm guarantees an $\tmO(T^{2/3})$ regret bound with high probability, which matches the best-known regret bound for this problem. Furthermore, we extend our algorithm and performance guarantee to the cases with output feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08138v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zishun Liu, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Optimal transport for types and convex analysis for definable predicates in tracial $\mathrm{W}^*$-algebras</title>
      <link>https://arxiv.org/abs/2308.11058</link>
      <description>arXiv:2308.11058v3 Announce Type: replace-cross 
Abstract: We investigate the connections between continuous model theory, free probability, and optimal transport/convex analysis in the context of tracial von Neumann algebras. In particular, we give an analog of Monge-Kantorovich duality for optimal couplings where the role of probability distributions on $\mathbb{C}^n$ is played by model-theoretic types, the role of real-valued continuous functions is played by definable predicates, and the role of continuous function $\mathbb{C}^n \to \mathbb{C}^n$ is played by definable functions. In the process, we also advance the understanding of definable predicates and definable functions by showing that all definable predicates can be approximated by "$C^1$ definable predicates" whose gradients are definable functions. As a consequence, we show that every element in the definable closure of $\mathrm{W}^*(x_1,\dots,x_n)$ can be expressed as a definable function of $(x_1,\dots,x_n)$. We give several classes of examples showing that the definable closure can be much larger than $\mathrm{W}^*(x_1,\dots,x_n)$ in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.11058v3</guid>
      <category>math.OA</category>
      <category>math.LO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Jekel</dc:creator>
    </item>
    <item>
      <title>Quantum-Informed Recursive Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2308.13607</link>
      <description>arXiv:2308.13607v3 Announce Type: replace-cross 
Abstract: We propose and implement a family of quantum-informed recursive optimization (QIRO) algorithms for combinatorial optimization problems. Our approach leverages quantum resources to obtain information that is used in problem-specific classical reduction steps that recursively simplify the problem. These reduction steps address the limitations of the quantum component and ensure solution feasibility in constrained optimization problems. Additionally, we use backtracking techniques to further improve the performance of the algorithm without increasing the requirements on the quantum hardware. We demonstrate the capabilities of our approach by informing QIRO with correlations from classical simulations of shallow (depth $p=1$) circuits of the quantum approximate optimization algorithm (QAOA), solving instances of maximum independent set and maximum satisfiability problems with hundreds of variables. We also demonstrate how QIRO can be deployed on a neutral atom quantum processor available online on Amazon Braket to find large independent sets of graphs. In summary, our scheme achieves results comparable to classical heuristics, such as simulated annealing and greedy algorithms, even with relatively weak quantum resources. Furthermore, enhancing the quality of these quantum resources improves the performance of the algorithms, highlighting the potential of QIRO. Notably, the modular nature of QIRO offers various avenues for modifications, positioning our work as a blueprint for designing a broader class of hybrid quantum-classical algorithms for combinatorial optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13607v3</guid>
      <category>quant-ph</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jernej Rudi Fin\v{z}gar, Aron Kerschbaumer, Martin J. A. Schuetz, Christian B. Mendl, Helmut G. Katzgraber</dc:creator>
    </item>
    <item>
      <title>Model-Free Source Seeking by a Novel Single-Integrator with Attenuating Oscillations and Better Convergence Rate: Robotic Experiments</title>
      <link>https://arxiv.org/abs/2311.04330</link>
      <description>arXiv:2311.04330v2 Announce Type: replace-cross 
Abstract: In this paper we validate, including experimentally, the effectiveness of a recent theoretical developments made by our group on control-affine Extremum Seeking Control (ESC) systems. In particular, our validation is concerned with the problem of source seeking by a mobile robot to the unknown source of a scalar signal (e.g., light). Our recent theoretical results made it possible to estimate the gradient of the unknown objective function (i.e., the scalar signal) incorporated in the ESC and use such information to apply an adaptation law which attenuates the oscillations of the ESC system while converging to the extremum (i.e., source). Based on our previous results, we propose here an amended design of the simple single-integrator control-affine structure known in ESC literature and show that it can functions effectively to achieve a model-free, real-time source seeking of light with attenuated oscillations using only local measurements of the light intensity. Results imply that the proposed design has significant potential as it also demonstrated much better convergence rate. We hope this paper encourages expansion of the proposed design in other fields, problems and experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04330v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivam Bajpai, Ahmed A. Elgohary, Sameh A. Eisa</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of Interior-Point Methods for Quantum Relative Entropy</title>
      <link>https://arxiv.org/abs/2312.07438</link>
      <description>arXiv:2312.07438v2 Announce Type: replace-cross 
Abstract: Quantum Relative Entropy (QRE) programming is a recently popular and challenging class of convex optimization problems with significant applications in quantum computing and quantum information theory. We are interested in modern interior point (IP) methods based on optimal self-concordant barriers for the QRE cone. A range of theoretical and numerical challenges associated with such barrier functions and the QRE cones have hindered the scalability of IP methods. To address these challenges, we propose a series of numerical and linear algebraic techniques and heuristics aimed at enhancing the efficiency of gradient and Hessian computations for the self-concordant barrier function, solving linear systems, and performing matrix-vector products. We also introduce and deliberate about some interesting concepts related to QRE such as symmetric quantum relative entropy (SQRE). We also introduce a two-phase method for performing facial reduction that can significantly improve the performance of QRE programming. Our new techniques have been implemented in the latest version (DDS 2.2) of the software package DDS. In addition to handling QRE constraints, DDS accepts any combination of several other conic and non-conic convex constraints. Our comprehensive numerical experiments encompass several parts including 1) a comparison of DDS 2.2 with Hypatia for the nearest correlation matrix problem, 2) using DDS for combining QRE constraints with various other constraint types, and 3) calculating the key rate for quantum key distribution (QKD) channels and presenting results for several QKD protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07438v2</guid>
      <category>quant-ph</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehdi Karimi, Levent Tuncel</dc:creator>
    </item>
    <item>
      <title>Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2402.04613</link>
      <description>arXiv:2402.04613v2 Announce Type: replace-cross 
Abstract: Most commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy consists of regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. In this paper, we use the so-called kernel mean embedding to show that the corresponding regularization can be rewritten as the Moreau envelope of some function in the reproducing kernel Hilbert space associated with $K$. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to prove properties of the MMD-regularized $f$-divergences and, in particular, their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. Finally, we consider Wasserstein gradient flows starting from empirical measures. We provide proof-of-the-concept numerical examples for $f$-divergences with both infinite and finite recession constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04613v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Neumayer, Viktor Stein, Gabriele Steidl, Nicolaj Rux</dc:creator>
    </item>
  </channel>
</rss>
