<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Unifying equivalences across unsupervised learning, network science, and imaging/network neuroscience</title>
      <link>https://arxiv.org/abs/2508.10045</link>
      <description>arXiv:2508.10045v1 Announce Type: new 
Abstract: Modern scientific fields face the challenge of integrating a wealth of data, analyses, and results. We recently showed that a neglect of this integration can lead to circular analyses and redundant explanations. Here, we help advance scientific integration by describing equivalences that unify diverse analyses of datasets and networks. We describe equivalences across analyses of clustering and dimensionality reduction, network centrality and dynamics, and popular models in imaging and network neuroscience. First, we equate foundational objectives across unsupervised learning and network science (from k means to modularity to UMAP), fuse classic algorithms for optimizing these objectives, and extend these objectives to simplify interpretations of popular dimensionality reduction methods. Second, we equate basic measures of connectional magnitude and dispersion with six measures of communication, control, and diversity in network science and network neuroscience. Third, we describe three semi-analytical vignettes that clarify and simplify the interpretation of structural and dynamical analyses in imaging and network neuroscience. We illustrate our results on example brain-imaging data and provide abct, an open multi-language toolbox that implements our analyses. Together, our study unifies diverse analyses across unsupervised learning, network science, imaging neuroscience, and network neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10045v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mika Rubinov</dc:creator>
    </item>
    <item>
      <title>An Intelligent Infrastructure as a Foundation for Modern Science</title>
      <link>https://arxiv.org/abs/2508.10051</link>
      <description>arXiv:2508.10051v1 Announce Type: new 
Abstract: Infrastructure shapes societies and scientific discovery. Traditional scientific infrastructure, often static and fragmented, leads to issues like data silos, lack of interoperability and reproducibility, and unsustainable short-lived solutions. Our current technical inability and social reticence to connect and coordinate scientific research and engineering leads to inefficiencies and impedes progress. With AI technologies changing how we interact with the world around us, there is an opportunity to transform scientific processes. Neuroscience's exponential growth of multimodal and multiscale data, and urgent clinical relevance demand an infrastructure itself learns, coordinates, and improves. Using neuroscience as a stress test, this perspective argues for a paradigm shift: infrastructure must evolve into a dynamic, AI-aligned ecosystem to accelerate science. Building on several existing principles for data, collective benefit, and digital repositories, I recommend operational guidelines for implementing them to create this dynamic ecosystem, aiming to foster a decentralized, self-learning, and self-correcting system where humans and AI can collaborate seamlessly. Addressing the chronic underfunding of scientific infrastructure, acknowledging diverse contributions beyond publications, and coordinating global efforts are critical steps for this transformation. By prioritizing an intelligent infrastructure as a central scientific instrument for knowledge generation, we can overcome current limitations, accelerate discovery, ensure reproducibility and ethical practices, and ultimately translate neuroscientific understanding into tangible societal benefits, setting a blueprint for other scientific domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10051v1</guid>
      <category>q-bio.NC</category>
      <category>cs.ET</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Satrajit S. Ghosh</dc:creator>
    </item>
    <item>
      <title>Large Language Models Show Signs of Alignment with Human Neurocognition During Abstract Reasoning</title>
      <link>https://arxiv.org/abs/2508.10057</link>
      <description>arXiv:2508.10057v1 Announce Type: new 
Abstract: This study investigates whether large language models (LLMs) mirror human neurocognition during abstract reasoning. We compared the performance and neural representations of human participants with those of eight open-source LLMs on an abstract-pattern-completion task. We leveraged pattern type differences in task performance and in fixation-related potentials (FRPs) as recorded by electroencephalography (EEG) during the task. Our findings indicate that only the largest tested LLMs (~70 billion parameters) achieve human-comparable accuracy, with Qwen-2.5-72B and DeepSeek-R1-70B also showing similarities with the human pattern-specific difficulty profile. Critically, every LLM tested forms representations that distinctly cluster the abstract pattern categories within their intermediate layers, although the strength of this clustering scales with their performance on the task. Moderate positive correlations were observed between the representational geometries of task-optimal LLM layers and human frontal FRPs. These results consistently diverged from comparisons with other EEG measures (response-locked ERPs and resting EEG), suggesting a potential shared representational space for abstract patterns. This indicates that LLMs might mirror human brain mechanisms in abstract reasoning, offering preliminary evidence of shared principles between biological and artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10057v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher Pinier, Sonia Acu\~na Vargas, Mariia Steeghs-Turchina, Dora Matzke, Claire E. Stevenson, Michael D. Nunez</dc:creator>
    </item>
    <item>
      <title>Excessive Screen Time is Associated with Mental Health Problems and ADHD in US Children and Adolescents: Physical Activity and Sleep as Parallel Mediators</title>
      <link>https://arxiv.org/abs/2508.10062</link>
      <description>arXiv:2508.10062v1 Announce Type: new 
Abstract: To examine associations between screen time and anxiety, depression, behavior or conduct problems, and ADHD among children and adolescents during the pandemic, and to assess whether physical activity, sleep duration, and bedtime regularity mediate these associations. Data from 50231 US children and adolescents aged 6 to 17 years in the 2020 to 2021 National Survey of Childrens Health were analyzed. Exact natural effect models and structural equation modeling assessed mediation by physical activity, short sleep duration, and irregular bedtime. We found that daily screen time equal or more than 4 hours was linked to higher risks of anxiety (aOR = 1.45, 95% CI 1.32, 1.58), depression (aOR = 1.65, 95% CI 1.41, 1.93), behavior or conduct problems (aOR = 1.17, 95% CI 1.05, 1.30), and ADHD (aOR = 1.21, 95% CI 1.11, 1.33). Physical activity accounted for 30.2% to 39.3% of the association, irregular bedtime for 18.2% to 25.7%, and short sleep duration for 2.77% to 7.34%. Excessive screen time was associated with poorer mental health and ADHD, partly explained by reduced physical activity, irregular bedtime, and insufficient sleep. Interventions should promote physical activity, regular sleep routines, and adequate sleep duration to effectively mitigate mental health issues and ADHD among children and adolescents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10062v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ying Dai, Na Ouyang</dc:creator>
    </item>
    <item>
      <title>Dynamical Alignment: A Principle for Adaptive Neural Computation</title>
      <link>https://arxiv.org/abs/2508.10064</link>
      <description>arXiv:2508.10064v1 Announce Type: new 
Abstract: The computational capabilities of a neural network are widely assumed to be determined by its static architecture. Here we challenge this view by establishing that a fixed neural structure can operate in fundamentally different computational modes, driven not by its structure but by the temporal dynamics of its input signals. We term this principle 'Dynamical Alignment'.
  Applying this principle offers a novel resolution to the long-standing paradox of why brain-inspired spiking neural networks (SNNs) underperform. By encoding static input into controllable dynamical trajectories, we uncover a bimodal optimization landscape with a critical phase transition governed by phase space volume dynamics. A 'dissipative' mode, driven by contracting dynamics, achieves superior energy efficiency through sparse temporal codes. In contrast, an 'expansive' mode, driven by expanding dynamics, unlocks the representational power required for SNNs to match or even exceed their artificial neural network counterparts on diverse tasks, including classification, reinforcement learning, and cognitive integration.
  We find this computational advantage emerges from a timescale alignment between input dynamics and neuronal integration. This principle, in turn, offers a unified, computable perspective on long-observed dualities in neuroscience, from stability-plasticity dilemma to segregation-integration dynamic. It demonstrates that computation in both biological and artificial systems can be dynamically sculpted by 'software' on fixed 'hardware', pointing toward a potential paradigm shift for AI research: away from designing complex static architectures and toward mastering adaptive, dynamic computation principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10064v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xia Chen</dc:creator>
    </item>
    <item>
      <title>Linking GFAP Levels to Speech Anomalies in Acute Brain Injury: A Simulation Based Study</title>
      <link>https://arxiv.org/abs/2508.10130</link>
      <description>arXiv:2508.10130v1 Announce Type: new 
Abstract: Background: Glial fibrillary acidic protein (GFAP) is a biomarker for intracerebral hemorrhage and traumatic brain injury, but its link to acute speech disruption is untested. Speech anomalies often emerge early after injury, enabling rapid triage.
  Methods: We simulated a cohort of 200 virtual patients stratified by lesion location, onset time, and severity. GFAP kinetics followed published trajectories; speech anomalies were generated from lesion-specific neurophysiological mappings. Ensemble machine-learning models used GFAP, speech, and lesion features; robustness was tested under noise, delays, and label dropout. Causal inference (inverse probability of treatment weighting and targeted maximum likelihood estimation) estimated directional associations between GFAP elevation and speech severity.
  Findings: GFAP correlated with simulated speech anomaly severity (Spearman rho = 0.48), strongest for cortical lesions (rho = 0.55). Voice anomalies preceded detectable GFAP rise by a median of 42 minutes in cortical injury. Classifier area under the curve values were 0.74 (GFAP only), 0.78 (voice only), and 0.86 for the fused multimodal model, which showed higher sensitivity in mild or ambiguous cases. Causal estimates indicated higher GFAP increased the modeled probability of moderate-to-severe speech anomalies by 32 to 35 percent, independent of lesion site and onset time.
  Conclusion: These results support a link between GFAP elevation and speech anomalies in acute brain injury and suggest integrated biochemical-voice diagnostics could improve early triage, especially for cortical injury. Findings are simulation-based and require validation in prospective clinical studies with synchronized GFAP assays and speech recordings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10130v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shamaley Aravinthan, Bin Hu</dc:creator>
    </item>
    <item>
      <title>Insights from the Algonauts 2025 Winners</title>
      <link>https://arxiv.org/abs/2508.10784</link>
      <description>arXiv:2508.10784v1 Announce Type: new 
Abstract: The Algonauts 2025 Challenge just wrapped up a few weeks ago. It is a biennial challenge in computational neuroscience in which teams attempt to build models that predict human brain activity from carefully curated stimuli. Previous editions (2019, 2021, 2023) focused on still images and short videos; the 2025 edition, which concluded last month (late July), pushed the field further by using long, multimodal movies. Teams were tasked with predicting fMRI responses across 1,000 whole-brain parcels across four participants in the dataset who were scanned while watching nearly 80 hours of naturalistic movie stimuli. These recordings came from the CNeuroMod project and included 65 hours of training data, about 55 hours of Friends (seasons 1-6) plus four feature films (The Bourne Supremacy, Hidden Figures, Life, and The Wolf of Wall Street). The remaining data were used for validation: Season 7 of Friends for in-distribution tests, and the final winners for the Challenge were those who could best predict brain activity for six films in their held-out out-of-distribution (OOD) set. The winners were just announced and the top team reports are now publicly available. As members of the MedARC team which placed 4th in the competition, we reflect on the approaches that worked, what they reveal about the current state of brain encoding, and what might come next.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10784v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul S. Scotti, Mihir Tripathy</dc:creator>
    </item>
    <item>
      <title>Scalable Modeling of Nonlinear Network Dynamics in Neurodegenerative Disease</title>
      <link>https://arxiv.org/abs/2508.10343</link>
      <description>arXiv:2508.10343v1 Announce Type: cross 
Abstract: Mechanistic models of progressive neurodegeneration offer great potential utility for clinical use and novel treatment development. Toward this end, several connectome-informed models of neuroimaging biomarkers have been proposed. However, these models typically do not scale well beyond a small number of biomarkers due to heterogeneity in individual disease trajectories and a large number of parameters. To address this, we introduce the Connectome-based Monotonic Inference of Neurodegenerative Dynamics (COMIND). The model combines concepts from diffusion and logistic models with structural brain connectivity. This guarantees monotonic disease trajectories while maintaining a limited number of parameters to improve scalability. We evaluate our model on simulated data as well as on the Parkinson's Progressive Markers Initiative (PPMI) data. Our model generalizes to anatomical imaging representations from a standard brain atlas without the need to reduce biomarker number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10343v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Semchin, Emile d'Angremont, Marco Lorenzi, Boris Gutman</dc:creator>
    </item>
    <item>
      <title>EDAPT: Towards Calibration-Free BCIs with Continual Online Adaptation</title>
      <link>https://arxiv.org/abs/2508.10474</link>
      <description>arXiv:2508.10474v1 Announce Type: cross 
Abstract: Brain-computer interfaces (BCIs) suffer from accuracy degradation as neural signals drift over time and vary across users, requiring frequent recalibration that limits practical deployment. We introduce EDAPT, a task- and model-agnostic framework that eliminates calibration through continual model adaptation. EDAPT first trains a baseline decoder using data from multiple users, then continually personalizes this model via supervised finetuning as the neural patterns evolve during use. We tested EDAPT across nine datasets covering three BCI tasks, and found that it consistently improved accuracy over conventional, static methods. These improvements primarily stem from combining population-level pretraining and online continual finetuning, with unsupervised domain adaptation providing further gains on some datasets. EDAPT runs efficiently, updating models within 200 milliseconds on consumer-grade hardware. Finally, decoding accuracy scales with total data budget rather than its allocation between subjects and trials. EDAPT provides a practical pathway toward calibration-free BCIs, reducing a major barrier to BCI deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10474v1</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lisa Haxel, Jaivardhan Kapoor, Ulf Ziemann, Jakob H. Macke</dc:creator>
    </item>
    <item>
      <title>Differential Physiological Responses to Proxemic and Facial Threats in Virtual Avatar Interactions</title>
      <link>https://arxiv.org/abs/2508.10586</link>
      <description>arXiv:2508.10586v1 Announce Type: cross 
Abstract: Proxemics, the study of spatial behavior, is fundamental to social interaction and increasingly relevant for virtual reality (VR) applications. While previous research has established that users respond to personal space violations in VR similarly as in real-world settings, phase-specific physiological responses and the modulating effects of facial expressions remain understudied. We investigated physiological and subjective responses to personal space violations by virtual avatars, to understand how threatening facial expressions and interaction phases (approach vs. standing) influence these responses. Sixteen participants experienced a 2x2 factorial design manipulating Personal Space (intrusion vs. respect) and Facial Expression (neutral vs. angry) while we recorded skin conductance response (SCR), heart rate variability (HRV), and discomfort ratings. Personal space boundaries were individually calibrated using a stop-distance procedure. Results show that SCR responses are significantly higher during the standing phase compared to the approach phase when personal space was violated, indicating that prolonged proximity within personal space boundaries is more physiologically arousing than the approach itself. Angry facial expressions significantly reduced HRV, reflecting decreased parasympathetic activity, and increased discomfort ratings, but did not amplify SCR responses. These findings demonstrate that different physiological modalities capture distinct aspects of proxemic responses: SCR primarily reflects spatial boundary violations, while HRV responds to facial threat cues. Our results provide insights for developing comprehensive multi-modal assessments of social behavior in virtual environments and inform the design of more realistic avatar interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10586v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Birgit Nierula, Mustafa Tevfik Lafci, Anna Melnik, Mert Akg\"ul, Farelle Toumaleu Siewe, Sebastian Bosse</dc:creator>
    </item>
    <item>
      <title>Neuronal correlations shape the scaling behavior of memory capacity and nonlinear computational capability of reservoir recurrent neural networks</title>
      <link>https://arxiv.org/abs/2504.19657</link>
      <description>arXiv:2504.19657v3 Announce Type: replace-cross 
Abstract: Reservoir computing is a powerful framework for real-time information processing, characterized by its high computational ability and quick learning, with applications ranging from machine learning to biological systems. In this paper, we investigate how the computational ability of reservoir recurrent neural networks (RNNs) scales with an increasing number of readout neurons. First, we demonstrate that the memory capacity of a reservoir RNN scales sublinearly with the number of readout neurons. To elucidate this observation, we develop a theoretical framework for analytically deriving memory capacity that incorporates the effect of neuronal correlations, which have been ignored in prior theoretical work for analytical simplicity. Our theory successfully relates the sublinear scaling of memory capacity to the strength of neuronal correlations. Furthermore, we show this principle holds across diverse types of RNNs, even those beyond the direct applicability of our theory. Next, we numerically investigate the scaling behavior of nonlinear computational ability, which, alongside memory capacity, is crucial for overall computational performance. Our numerical simulations reveal that as memory capacity growth becomes sublinear, increasing the number of readout neurons successively enables nonlinear processing at progressively higher polynomial orders. Our theoretical framework suggests that neuronal correlations govern not only memory capacity but also the sequential growth of nonlinear computational capabilities. Our findings establish a foundation for designing scalable and cost-effective reservoir computing, providing novel insights into the interplay among neuronal correlations, linear memory, and nonlinear processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19657v3</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shotaro Takasu, Toshio Aoyagi</dc:creator>
    </item>
  </channel>
</rss>
