<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 May 2025 04:01:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Modeling the 2022 Mpox Outbreak with a Mechanistic Network Model</title>
      <link>https://arxiv.org/abs/2505.05534</link>
      <description>arXiv:2505.05534v1 Announce Type: new 
Abstract: We implemented a dynamic agent-based network model to simulate the spread of mpox in a United States-based MSM population. This model allowed us to implement data-informed dynamic network evolution to simulate realistic disease spreading and behavioral adaptations. We found that behavior change, the reduction in one-time partnerships, and widespread vaccination are effective in preventing the transmission of mpox and that earlier intervention has a greater effect, even when only a high-risk portion of the population participates. With no intervention, 16% of the population was infected (25th percentile, 75th percentiles of simulations: 15.3%, 16.6%). With vaccination and behavior change in only the 25% of individuals most likely to have a one-time partner, cumulative infections were reduced by 30%, or a total reduction in nearly 500 infections. Earlier intervention further reduces cumulative infections; beginning vaccination a year before the outbreak results in only 5.5% of men being infected, averting 950 infections or nearly 10% of the total population in our model. We also show that sustained partnerships drive the early outbreak, while one-time partnerships drive transmission after the first initial weeks. The median effective reproductive number, Rt, at t = 0 days is 1.30 for casual partnerships, 1.00 for main, and 0.6 for one-time. By t = 28, the median Rt for one-time partnerships has more than doubled to 1.48, while it decreased for casual and main partnerships: 0.46 and 0.29, respectively. With the ability to model individuals' behavior, mechanistic networks are particularly well suited to studying sexually transmitted infections, the spread and control of which are often governed by individual-level action. Our results contribute valuable insights into the role of different interventions and relationship types in mpox transmission dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05534v1</guid>
      <category>stat.AP</category>
      <category>physics.soc-ph</category>
      <category>q-bio.PE</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emma G. Crenshaw, Jukka-Pekka Onnela</dc:creator>
    </item>
    <item>
      <title>Bayesian shape-constrained regression for quantifying Alzheimer's disease biomarker progression</title>
      <link>https://arxiv.org/abs/2505.05700</link>
      <description>arXiv:2505.05700v1 Announce Type: new 
Abstract: Several biomarkers are hypothesized to indicate early stages of Alzheimer's disease, well before the cognitive symptoms manifest. Their precise relations to the disease progression, however, is poorly understood. This lack of understanding limits our ability to diagnose the disease and intervene effectively at early stages. To provide better understanding of the relation between the disease and biomarker progressions, we propose a novel modeling approach to quantify the biomarkers' trajectories as functions of age. Building on monotone regression splines, we introduce two additional shape constraints to incorporate structures informed by the current medical literature. First, we impose the regression curves to satisfy a vanishing derivative condition, reflecting the observation that changes in biomarkers generally plateau at early and late stages of the disease. Second, we enforce the regression curves to have a unique inflection point, which enhances interpretability of the estimated disease progression and facilitates assessment of temporal ordering among the biomarkers. We fit our shape-constrained regression model under Bayesian framework to take advantage of its ability to account for the heterogeneity in disease progression among individuals. When applied to the BIOCARD data, the model is able to capture asymmetry in the biomarkers' progressions while maintaining interpretability, yielding estimates of the curves with temporal ordering consistent with the existing scientific hypotheses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05700v1</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingyuan Li, Zheyu Wang, Akihiko Nishimura</dc:creator>
    </item>
    <item>
      <title>HiBayES: A Hierarchical Bayesian Modeling Framework for AI Evaluation Statistics</title>
      <link>https://arxiv.org/abs/2505.05602</link>
      <description>arXiv:2505.05602v1 Announce Type: cross 
Abstract: As Large Language Models (LLMs) and other AI systems evolve, robustly estimating their capabilities from inherently stochastic outputs while systematically quantifying uncertainty in these estimates becomes increasingly important. Further, advanced AI evaluations often have a nested hierarchical structure, exhibit high levels of complexity, and come with high costs in testing the most advanced AI systems. To address these challenges, we introduce HiBayES, a generalizable Hierarchical Bayesian modeling framework for AI Evaluation Statistics. HiBayES supports robust inferences in classical question-answer benchmarks and advanced agentic evaluations, particularly in low-data scenarios (e.g., &lt; 20 data points per evaluation). Built on Generalized Linear Models (GLMs), Bayesian data analysis, and formal model comparison, HiBayES provides principled uncertainty quantification and robust parameter estimation. This paper offers a comprehensive introduction to HiBayES, including illustrative examples, comparisons to conventional statistical methods, and practical guidance for implementing multilevel Bayesian GLMs. Additionally, we provide a HiBayES software package [4] (Beta version) for out-of-the-box implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05602v1</guid>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lennart Luettgau, Harry Coppock, Magda Dubois, Christopher Summerfield, Cozmin Ududec</dc:creator>
    </item>
    <item>
      <title>The Evolution of Embedding Table Optimization and Multi-Epoch Training in Pinterest Ads Conversion</title>
      <link>https://arxiv.org/abs/2505.05605</link>
      <description>arXiv:2505.05605v1 Announce Type: cross 
Abstract: Deep learning for conversion prediction has found widespread applications in online advertising. These models have become more complex as they are trained to jointly predict multiple objectives such as click, add-to-cart, checkout and other conversion types. Additionally, the capacity and performance of these models can often be increased with the use of embedding tables that encode high cardinality categorical features such as advertiser, user, campaign, and product identifiers (IDs). These embedding tables can be pre-trained, but also learned end-to-end jointly with the model to directly optimize the model objectives. Training these large tables is challenging due to: gradient sparsity, the high cardinality of the categorical features, the non-uniform distribution of IDs and the very high label sparsity. These issues make training prone to both slow convergence and overfitting after the first epoch. Previous works addressed the multi-epoch overfitting issue by using: stronger feature hashing to reduce cardinality, filtering of low frequency IDs, regularization of the embedding tables, re-initialization of the embedding tables after each epoch, etc. Some of these techniques reduce overfitting at the expense of reduced model performance if used too aggressively. In this paper, we share key learnings from the development of embedding table optimization and multi-epoch training in Pinterest Ads Conversion models. We showcase how our Sparse Optimizer speeds up convergence, and how multi-epoch overfitting varies in severity between different objectives in a multi-task model depending on label sparsity. We propose a new approach to deal with multi-epoch overfitting: the use of a frequency-adaptive learning rate on the embedding tables and compare it to embedding re-initialization. We evaluate both methods offline using an industrial large-scale production dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05605v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>stat.AP</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Qiu, Shubham Barhate, Hin Wai Lui, Runze Su, Rafael Rios M\"uller, Kungang Li, Ling Leng, Han Sun, Shayan Ehsani, Zhifang Liu</dc:creator>
    </item>
    <item>
      <title>Estimation and Inference in Boundary Discontinuity Designs</title>
      <link>https://arxiv.org/abs/2505.05670</link>
      <description>arXiv:2505.05670v1 Announce Type: cross 
Abstract: Boundary Discontinuity Designs are used to learn about treatment effects along a continuous boundary that splits units into control and treatment groups according to a bivariate score variable. These research designs are also called Multi-Score Regression Discontinuity Designs, a leading special case being Geographic Regression Discontinuity Designs. We study the statistical properties of commonly used local polynomial treatment effects estimators along the continuous treatment assignment boundary. We consider two distinct approaches: one based explicitly on the bivariate score variable for each unit, and the other based on their univariate distance to the boundary. For each approach, we present pointwise and uniform estimation and inference methods for the treatment effect function over the assignment boundary. Notably, we show that methods based on univariate distance to the boundary exhibit an irreducible large misspecification bias when the assignment boundary has kinks or other irregularities, making the distance-based approach unsuitable for empirical work in those settings. In contrast, methods based on the bivariate score variable do not suffer from that drawback. We illustrate our methods with an empirical application. Companion general-purpose software is provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05670v1</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Rocio Titiunik, Ruiqi Rae Yu</dc:creator>
    </item>
    <item>
      <title>Who's at Risk? Effects of Inflation on Unemployment Risk</title>
      <link>https://arxiv.org/abs/2505.05757</link>
      <description>arXiv:2505.05757v1 Announce Type: cross 
Abstract: We empirically investigate the distributional effects of inflation on workers' unemployment tail risks using instrumental variable quantile regression. We find that supply-driven inflation disproportionately raises unemployment tail risks for cyclically vulnerable workers in both the short and medium term, while demand-driven inflation has differential effects -- limited to race and reason for unemployment -- only in the medium term. Demand-boosting policies, including monetary policy, can inadvertently widen those disparities through the inflation channel, underscoring the importance of inflation stabilization in promoting equitable growth in the labor market. Our findings could be explained structurally by heterogeneity in experienced inflation and wage inflation expectations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05757v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hie Joo Ahn, Lam Nguyen</dc:creator>
    </item>
    <item>
      <title>Diffusion piecewise exponential models for survival extrapolation using Piecewise Deterministic Monte Carlo</title>
      <link>https://arxiv.org/abs/2505.05932</link>
      <description>arXiv:2505.05932v1 Announce Type: cross 
Abstract: The piecewise exponential model is a flexible non-parametric approach for time-to-event data, but extrapolation beyond final observation times typically relies on random walk priors and deterministic knot locations, resulting in unrealistic long-term hazards. We introduce the diffusion piecewise exponential model, a prior framework consisting of a discretised diffusion for the hazard, that can encode a wide variety of information about the long-term behaviour of the hazard, time changed by a Poisson process prior for knot locations. This allows the behaviour of the hazard in the observation period to be combined with prior information to inform extrapolations. Efficient posterior sampling is achieved using Piecewise Deterministic Markov Processes, whereby we extend existing approaches using sticky dynamics from sampling spike-and-slab distributions to more general transdimensional posteriors. We focus on applications in Health Technology Assessment, where the need to compute mean survival requires hazard functions to be extrapolated beyond the observation period, showcasing performance on datasets for Colon cancer and Leukaemia patients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05932v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke Hardcastle, Samuel Livingstone, Gianluca Baio</dc:creator>
    </item>
    <item>
      <title>Using iterated local alignment to aggregate trajectory data into a traffic flow map</title>
      <link>https://arxiv.org/abs/2406.17500</link>
      <description>arXiv:2406.17500v4 Announce Type: replace 
Abstract: Vehicle trajectories, with their detailed geolocations, are a promising data source to compute traffic flow maps at scales ranging from the city/regional level to the road level. The main obstacle is that trajectory data are prone to measurement noise. While this is negligible for city level large-scale flow aggregation, it poses substantial difficulties for road level small-scale aggregation. To overcome these difficulties, we introduce innovative local alignment algorithms, where we infer road segments to serve as local reference segments, and proceed to align nearby road segments to them. We deploy these algorithms in an iterative workflow to compute locally aligned flow maps. By applying this workflow to synthetic and empirical trajectories, we verify that our locally aligned flow maps provide high levels of accuracy and spatial resolution of flow aggregation at multiple scales for static and interactive maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.17500v4</guid>
      <category>stat.AP</category>
      <category>cs.CE</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tarn Duong</dc:creator>
    </item>
    <item>
      <title>Thinning-Stable Point Processes as a Model for Spatial Burstiness</title>
      <link>https://arxiv.org/abs/2505.00717</link>
      <description>arXiv:2505.00717v3 Announce Type: replace 
Abstract: In modern telecommunications, spatial burstiness of data traffic
  poses challenges to traditional Poisson-based models. This paper
  describes application of thinning-stable point processes,
  which provide a more appropriate framework for modeling bursty
  spatial data. We discuss their properties, representation, inference
  methods, and applications, demonstrating the advantages over
  classical approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00717v3</guid>
      <category>stat.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>WiOpt-2025 Conference paper, 26-29th of May, 2025, Link\"oping, Sweden</arxiv:journal_reference>
      <dc:creator>Sergei Zuyev</dc:creator>
    </item>
    <item>
      <title>Optimization perspective on raking</title>
      <link>https://arxiv.org/abs/2407.20520</link>
      <description>arXiv:2407.20520v3 Announce Type: replace-cross 
Abstract: Raking is widely used in survey inference and global health models to adjust the observations in contingency tables to given marginals, in the latter case reconciling estimates between models with different granularities. We review the convex optimization foundation of raking and focus on a dual perspective that simplifies and streamlines prior raking extensions and provides new functionality, enabling a unified approach to n-dimensional raking, raking with differential weights, ensuring bounds on estimates are respected, raking to margins either as hard constraints or as aggregate observations, handling missing data, and allowing efficient uncertainty propagation. The dual perspective also enables a uniform fast and scalable matrix-free optimization approach for all of these extensions. All of the methods are implemented in an open source Python package with an intuitive user interface, installable from PyPi (https://pypi.org/project/raking/), and we illustrate the capabilities using synthetic data and real mortality estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20520v3</guid>
      <category>stat.ME</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ariane Ducellier (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA), Alexander Hsu (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA, Department of Applied Mathematics, University of Washington, Seattle, WA), Parkes Kendrick (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA), Bill Gustafson (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA), Laura Dwyer-Lindgren (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA), Christopher Murray (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA), Peng Zheng (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA), Aleksandr Aravkin (Institute for Health Metrics and Evaluation, University of Washington, Seattle, WA, Department of Applied Mathematics, University of Washington, Seattle, WA)</dc:creator>
    </item>
    <item>
      <title>Crash Severity Risk Modeling Strategies under Data Imbalance</title>
      <link>https://arxiv.org/abs/2412.02094</link>
      <description>arXiv:2412.02094v2 Announce Type: replace-cross 
Abstract: This study investigates crash severity risk modeling strategies for work zones involving large vehicles (i.e., trucks, buses, and vans) under crash data imbalance between low-severity (LS) and high-severity (HS) crashes. We utilized crash data involving large vehicles in South Carolina work zones from 2014 to 2018, which included four times more LS crashes than HS crashes. The objective of this study is to evaluate the crash severity prediction performance of various statistical, machine learning, and deep learning models under different feature selection and data balancing techniques. Findings highlight a disparity in LS and HS predictions, with lower accuracy for HS crashes due to class imbalance and feature overlap. Discriminative Mutual Information (DMI) yields the most effective feature set for predicting HS crashes without requiring data balancing, particularly when paired with gradient boosting models and deep neural networks such as CatBoost, NeuralNetTorch, XGBoost, and LightGBM. Data balancing techniques such as NearMiss-1 maximize HS recall when combined with DMI-selected features and certain models such as LightGBM, making them well-suited for HS crash prediction. Conversely, RandomUnderSampler, HS Class Weighting, and RandomOverSampler achieve more balanced performance, which is defined as an equitable trade-off between LS and HS metrics, especially when applied to NeuralNetTorch, NeuralNetFastAI, CatBoost, LightGBM, and Bayesian Mixed Logit (BML) using merged feature sets or models without feature selection. The insights from this study offer safety analysts guidance on selecting models, feature selection, and data balancing techniques aligned with specific safety goals, providing a robust foundation for enhancing work-zone crash severity prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02094v2</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>stat.AP</category>
      <pubDate>Mon, 12 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Abdullah Al Mamun (Graduate Student, Glenn Department of Civil Engineering, Clemson University), Abyad Enan (Graduate Student, Glenn Department of Civil Engineering, Clemson University), Debbie A. Indah (Graduate Student, Department of Engineering, South Carolina State University), Judith Mwakalonge (Professor, Department of Engineering, South Carolina State University), Gurcan Comert (Associate Professor, Computational Data Science and Engineering Department, North Carolina A&amp;T State University), Mashrur Chowdhury (Professor, Glenn Department of Civil Engineering, Clemson University)</dc:creator>
    </item>
  </channel>
</rss>
