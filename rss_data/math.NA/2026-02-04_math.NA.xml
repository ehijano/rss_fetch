<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 05:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Error Analysis of Matrix Multiplication Emulation Using Ozaki-II Scheme</title>
      <link>https://arxiv.org/abs/2602.02549</link>
      <description>arXiv:2602.02549v1 Announce Type: new 
Abstract: The Ozaki-II scheme is an emulation method that leverages the Chinese Remainder Theorem to compute high-precision matrix multiplication via a sequence of low-precision matrix multiplications. In this scheme, the attainable numerical accuracy improves as the number of low-precision matrix multiplications increases. Previous numerical studies have shown that single- and double-precision matrix multiplication using the Ozaki-II scheme achieves higher throughput than that of standard BLAS routines on modern AI hardware equipped with fast INT8 matrix multiply-accumulate units with INT8 inputs and INT32 accumulation. However, the accuracy of the Ozaki-II scheme can degrade when the exponent distribution of the input matrices is wide, in which case a large number of low-precision matrix multiplications is required to obtain high-precision results. In this paper, we present a rigorous deterministic error analysis of the Ozaki-II scheme. The proposed analysis not only clarifies the accuracy behavior of the method but also enables the estimation of the number of low-precision matrix multiplications required to achieve a desired level of numerical accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02549v1</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuki Uchino, Katsuhisa Ozaki, Toshiyuki Imamura</dc:creator>
    </item>
    <item>
      <title>A space-time LATIN-PGD strategy for solving Newtonian compressible flows</title>
      <link>https://arxiv.org/abs/2602.02616</link>
      <description>arXiv:2602.02616v1 Announce Type: new 
Abstract: Simulating flow problems is at the core of many engineering applications but often requires high computational effort, especially when dealing with complex models. This work presents a novel approach for resolving flow problems using the LATIN-PGD solver. In this contribution, we place ourselves within the framework of Newtonian compressible and laminar flows. This specific and relatively simple case enables focusing on flows for which a state equation provides a direct relation between pressure and density. It is then possible to use the LATIN solver to set up a pressure-velocity decoupling algorithm. Moreover, Proper Generalised Decomposition (PGD) is natively included in the solver and yields two independent space-time decompositions for the velocity and the pressure fields. As a first step, the solver is validated on a problem for which an analytical solution is available. It is then applied to slightly more complex problems. The results show good agreement with the literature, and we expect that the solver could be used to compute more complicated material laws in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02616v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <category>physics.med-ph</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>\'Elise Foulatier (LMPS), Pierre-Alain Boucard (LMPS), Fran\c{c}ois Louf (LMPS), David N\'eron (LMPS), Philipp Junker</dc:creator>
    </item>
    <item>
      <title>Comparison of Trefftz-Based PINNs and Standard PINNs Focusing on Structure Preservation</title>
      <link>https://arxiv.org/abs/2602.02779</link>
      <description>arXiv:2602.02779v1 Announce Type: new 
Abstract: In this study, we investigate the capability of physics-informed neural networks (PINNs) to preserve global physical structures by comparing standard PINNs with a Trefftz-based PINN (Trefftz-PINN). The target problem is the reproduction of mag-netic field-line structures in a helical fusion reactor configuration. Using identical training data sampled from exact solutions, we perform comparisons under matched mean squared error (MSE) levels. Visualization of magnetic field lines reveals that standard PINNs may exhibit structural collapse across magnetic surfaces even when the MSE is sufficiently small, whereas Trefftz-PINNs successfully preserve the global topology of magnetic field lines. Furthermore, the proposed framework is extended to computational fluid dynamics (CFD) problems, where streamline structures of veloc-ity fields are analyzed. Similar tendencies are observed, demonstrating that Trefftz-PINNs provide superior structure preservation compared to standard PINNs. These results indicate that minimizing numerical error alone does not guarantee physical consistency, and that constraining the solution space prior to learning is an effective strategy for physics-consistent surrogate modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02779v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Koji Koyamada</dc:creator>
    </item>
    <item>
      <title>Scaling Optimized Spectral Approximations on Unbounded Domains: The Generalized Hermite and Laguerre Methods</title>
      <link>https://arxiv.org/abs/2602.03083</link>
      <description>arXiv:2602.03083v1 Announce Type: new 
Abstract: We propose a novel error analysis framework for scaled generalized Laguerre and generalized Hermite approximations.This framework can be regarded as an analogue of the Nyquist-Shannon sampling theorem: It characterizes the spatial and frequency bandwidths that can be effectively captured by Laguerre or Hermite sampling points. Provided a function satisfies the corresponding bandwidth constraints, it can be accurately approximated within this framework. The proposed framework is notably more powerful than classical theory -- it not only provides systematic guidance for choosing the optimal scaling factor, but also predicts root-exponential and other intricate convergence behaviors that classical approaches fail to capture. Leveraging this framework, we conducted a detailed comparative study of Hermite and Laguerre approximations. We find that functions with similar decay and oscillation characteristics may nonetheless display markedly different convergence rates. Furthermore, approximations based on two concatenated sets of Laguerre functions may offer significant advantages over those using a single set of Hermite functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03083v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Hu, Haijun Yu</dc:creator>
    </item>
    <item>
      <title>The High Cost of Data Augmentation for Learning Equivariant Models</title>
      <link>https://arxiv.org/abs/2602.03118</link>
      <description>arXiv:2602.03118v1 Announce Type: new 
Abstract: According to Noether's theorem the presence of a continuous symmetry in a Hamiltonian systems is equivalent to the existence of a conserved quantity, yet these symmetries are not always explicitly enforced in data-driven models. There remains a debate whether or not encoding of symmetry into a model architecture is the optimal approach. A competing approach is to target approximate symmetry through data augmentation. In this work, we study two approaches aimed at improving the symmetry properties of such an approximation scheme: one based on a quadrature rule for the Haar measure on the compact Lie group encoding the continuous symmetry of interest and one based on a random sampling of that Haar measure. We demonstrate both theoretically and empirically that the quadrature augmentation leads to exact symmetry preservation in polynomial models, while the random augmentation has only square-root convergence of the symmetrization error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03118v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Klinteb\"ack, Christoph Ortner, Lior Silberman</dc:creator>
    </item>
    <item>
      <title>Event-Level Probabilistic Prediction of Extreme Rainfall over India Using Physics-Gated Latent Dynamics</title>
      <link>https://arxiv.org/abs/2602.03166</link>
      <description>arXiv:2602.03166v1 Announce Type: new 
Abstract: Extreme rainfall over the Indian monsoon region poses severe societal and infrastructural risks but remains difficult to predict at daily time scales due to stochastic convective triggering and multiscale atmospheric interactions. While large-scale atmospheric fields provide important environmental context, their ability to localize extreme rainfall events is fundamentally limited. In this study, we examine how large-scale atmospheric information from ERA5 reanalysis can be leveraged for event-level probabilistic prediction of daily rainfall extremes over India. We compare an adaptive ConvLSTM baseline with a proposed Physics-Gated Latent Ordinary Differential Equation (PG-LODE) framework, which models atmospheric evolution as a continuous-time latent process whose dynamics are explicitly modulated by a physics-based gating mechanism under convectively unstable conditions. Extreme events are defined using the local 95th percentile of the India Meteorological Department gridded rainfall dataset during the June to September monsoon season. Pixel-wise evaluation shows limited skill for both models due to spatial displacement errors, whereas event-level tile-based verification reveals a clear performance contrast. The ConvLSTM remains highly conservative, detecting only 27 percent of extreme events, while PG-LODE achieves near-complete detection with a substantially higher critical success index and a moderate false alarm rate. These results demonstrate that physics-gated continuous-time latent dynamics offer a robust pathway for translating large-scale atmospheric predictability into reliable assessments of extreme rainfall risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03166v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arun Govind Neelan</dc:creator>
    </item>
    <item>
      <title>Fully Automated Adaptive Parameter Selection for 3-D High-order Nystr\"om Boundary Integral Equation Methods</title>
      <link>https://arxiv.org/abs/2602.03178</link>
      <description>arXiv:2602.03178v1 Announce Type: new 
Abstract: We present an adaptive Chebyshev-based Boundary Integral Equation (CBIE) solver for electromagnetic scattering from smooth perfect electric conductor (PEC) objects. The proposed approach eliminates manual parameter tuning by introducing (i) a unified adaptive quadrature strategy for automatic selection of the near-singular interaction distance and (ii) an adaptive computation of all self- and near-singular precomputation integrals to a prescribed accuracy using Gauss-Kronrod (h-adaptive) or Clenshaw-Curtis (p-adaptive) rules and singularity-resolving changes of variables. Both h-adaptive and p-adaptive schemes are explored within this framework, ensuring high-order accuracy and robustness across a broad range of geometries without loss of efficiency. Numerical results for canonical and complex CAD geometries demonstrate that the adaptive solver achieves accuracy and convergence rates comparable to optimally tuned fixed-grid CBIE implementations, while offering automation and scalability to electrically large, geometrically complex problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03178v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Davit Aslanyan, Constantine Sideris</dc:creator>
    </item>
    <item>
      <title>Deterministic and randomized Kaczmarz methods for $AXB=C$ with applications to color image restoration</title>
      <link>https://arxiv.org/abs/2602.03239</link>
      <description>arXiv:2602.03239v1 Announce Type: new 
Abstract: We study Kaczmarz type methods to solve consistent linear matrix equations. We first present a block Kaczmarz (BK) method that employs a deterministic cyclic row selection strategy. Assuming that the associated coefficient matrix has full column or row rank, we derive matrix formulas for a cycle of this BK method. Moreover, we propose a greedy randomized block Kaczmarz (GRBK) method and further extend it to a relaxed variant (RGRBK) and a deterministic counterpart (MWRBK). We establish the convergence properties of the proposed methods. Numerical tests verify the theoretical findings, and we apply the proposed methods to color image restoration problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03239v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenli Wang, Duo Liu, Gangrong Qu, Michiel E. Hochstenbach</dc:creator>
    </item>
    <item>
      <title>Physics informed learning of orthogonal features with applications in solving partial differential equations</title>
      <link>https://arxiv.org/abs/2602.03247</link>
      <description>arXiv:2602.03247v1 Announce Type: new 
Abstract: The random feature method (RFM) constructs approximation spaces by initializing features from generic distributions, which provides universal approximation properties to solve general partial differential equations. However, such standard initializations lack awareness of the underlying physical laws and geometry, which limits approximation. In this work, we propose the Physics-Driven Orthogonal Feature Method (PD-OFM), a framework for constructing feature representations that are explicitly tailored to both the differential operator and the computational domain by pretraining features using physics-informed objectives together with orthogonality regularization. This pretraining strategy yields nearly orthogonal feature bases. We provide both theoretical and empirical evidence that physics-informed pretraining improves the approximation capability of the learned feature space. When employed to solve Helmholtz, Poisson, wave, and Navier-Stokes equations, the proposed method achieves residual errors 2-3 orders of magnitude lower than those of comparable methods. Furthermore, the orthogonality regularization improves transferability, enabling pretrained features to generalize effectively across different source terms and domain geometries for the same PDE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03247v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianxing Jia, Dong Wang</dc:creator>
    </item>
    <item>
      <title>Weighted finite difference methods for a nonlinear Klein--Gordon equation with high oscillations in space and time</title>
      <link>https://arxiv.org/abs/2602.03322</link>
      <description>arXiv:2602.03322v1 Announce Type: new 
Abstract: We consider a nonlinear Klein--Gordon equation in the nonrelativistic limit regime with initial data in the form of a modulated highly oscillatory exponential. In this regime of a small scaling parameter $\varepsilon$, the solution exhibits rapid oscillations in both time and space, posing challenges for numerical approximation. We propose an explicit and an implicit exponentially weighted finite difference method. While the explicit weighted leapfrog method needs to satisfy a CFL-type stability condition, the implicit weighted Crank--Nicolson method is unconditionally stable. Both methods achieve second-order accuracy with time steps and mesh sizes that are not restricted in magnitude by $\varepsilon$. The methods are uniformly convergent in the range from arbitrarily small to moderately bounded $\varepsilon$. Numerical experiments illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03322v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanyan Shi, Christian Lubich</dc:creator>
    </item>
    <item>
      <title>A Comparative Study of Low-Dissipation Numerical Schemes for Hyperbolic Conservation Laws</title>
      <link>https://arxiv.org/abs/2602.03348</link>
      <description>arXiv:2602.03348v1 Announce Type: new 
Abstract: This work provides a comparative assessment of several low-dissipation numerical schemes for hyperbolic conservation laws, highlighting their performance relative to the classical Harten-Lax-van Leer (HLL) schemes. The schemes under consideration include the classical Harten-Lax-van Leer-Contact (HLLC), the recently proposed TV flux splitting, the low-dissipation Central-Upwind (LDCU), and the local characteristic decomposition-based Central-Upwind (LCDCU) schemes. These methods are extended to higher orders of accuracy, up to the fifth order, within both finite-volume and finite-difference frameworks. A series of numerical experiments for the one- and two-dimensional Euler equations of gas dynamics are performed to evaluate the accuracy, robustness, and computational efficiency of the studied schemes. The comparison highlights the trade-offs between resolution of contact and shear waves, robustness in the presence of shocks, and computational cost. The investigated low-dissipation schemes show comparable levels of numerical dissipation, with only subtle differences appearing in selected benchmark problems. The results provide practical guidance for selecting efficient low-dissipation solvers for the simulation of complex compressible flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03348v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaoshuai Chu, Michael Herty</dc:creator>
    </item>
    <item>
      <title>On singular Galerkin discretizations for three models in high-frequency scattering</title>
      <link>https://arxiv.org/abs/2602.03428</link>
      <description>arXiv:2602.03428v1 Announce Type: new 
Abstract: We consider three common mathematical models for time-harmonic high frequency scattering: the Helmholtz equation in two and three spatial dimensions, a transverse magnetic problem in two dimensions, and Maxwell's equation in three dimensions with dissipative boundary conditions such that the continuous problem is well posed. In this paper, we construct meshes for popular (low order) Galerkin finite element discretizations such that the discrete system matrix becomes singular and the discrete problem is not well posed. This implies that a condition "the finite element space has to be sufficiently rich" in the form of a resolution condition - typically imposed for discrete well-posedness - is not an artifact from the proof by a compact perturbation argument but necessary for discrete stability of the Galerkin discretization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03428v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Chaumont-Frelet, S. Sauter</dc:creator>
    </item>
    <item>
      <title>UNSO: Unified Newton Schulz Orthogonalization</title>
      <link>https://arxiv.org/abs/2602.02500</link>
      <description>arXiv:2602.02500v1 Announce Type: cross 
Abstract: The Newton-Schulz (NS) iteration has gained increasing interest for its role in the Muon optimizer and the Stiefel manifold. However, the conventional NS iteration suffers from inefficiency and instability. Although various improvements have been introduced to NS iteration, they fail to deviate from the conventional iterative paradigm, which could increase computation burden largely due to the matrix products along the long dimension repeatedly. To address this, we consolidate the iterative structure into a unified framework, named Unified Newton-Schulz Orthogonalization (UNSO). To do so, we could avoid a polynomial expansion. Instead, we evaluate the role of each matrix power, remove the insignificant terms, and provide a recommended polynomial with learnable coefficients. These learnable coefficients are then optimized, and achieve an outstanding performance with stable convergence. The code of our method is available: https://github.com/greekinRoma/Unified_Newton_Schulz_Orthogonalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02500v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Hu, Qianxi Zhao, Yuming Li, Mingyu Zhou, Xiyin Li</dc:creator>
    </item>
    <item>
      <title>Bayesian Methods for the Navier-Stokes Equations</title>
      <link>https://arxiv.org/abs/2602.02945</link>
      <description>arXiv:2602.02945v1 Announce Type: cross 
Abstract: We develop a Bayesian methodology for numerical solution of the incompressible Navier--Stokes equations with quantified uncertainty. The central idea is to treat discretized Navier--Stokes dynamics as a state-space model and to view numerical solution as posterior computation: priors encode physical structure and modeling error, and the solver outputs a distribution over states and quantities of interest rather than a single trajectory. In two dimensions, stochastic representations (Feynman--Kac and stochastic characteristics for linear advection--diffusion with prescribed drift) motivate Monte Carlo solvers and provide intuition for uncertainty propagation. In three dimensions, we formulate stochastic Navier--Stokes models and describe particle-based and ensemble-based Bayesian workflows for uncertainty propagation in spectral discretizations. A key computational advantage is that parameter learning can be performed stably via particle learning: marginalization and resample--propagate (one-step smoothing) constructions avoid the weight-collapse that plagues naive sequential importance sampling on static parameters. When partial observations are available, the same machinery supports sequential observational updating as an additional capability. We also discuss non-Gaussian (heavy-tailed) error models based on normal variance-mean mixtures, which yield conditionally Gaussian updates via latent scale augmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02945v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicholas Polson, Vadim Sokolov</dc:creator>
    </item>
    <item>
      <title>Variational Sparse Paired Autoencoders (vsPAIR) for Inverse Problems and Uncertainty Quantification</title>
      <link>https://arxiv.org/abs/2602.02948</link>
      <description>arXiv:2602.02948v1 Announce Type: cross 
Abstract: Inverse problems are fundamental to many scientific and engineering disciplines; they arise when one seeks to reconstruct hidden, underlying quantities from noisy measurements. Many applications demand not just point estimates but interpretable uncertainty. Providing fast inference alongside uncertainty estimates remains challenging yet desirable in numerous applications.
  We propose the Variational Sparse Paired Autoencoder (vsPAIR) to address this challenge. The architecture pairs a standard VAE encoding observations with a sparse VAE encoding quantities of interest, connected through a learned latent mapping. The variational structure enables uncertainty estimation, the paired architecture encourages interpretability by anchoring QoI representations to clean data, and sparse encodings provide structure by concentrating information into identifiable factors rather than diffusing across all dimensions. We also propose modifications to existing sparse VAE methods: a hard-concrete spike-and-slab relaxation for differentiable training and a beta hyperprior for adaptive sparsity levels. To validate the effectiveness of our proposed architecture, we conduct experiments on blind inpainting and computed tomography, demonstrating that vsPAIR is a capable inverse problem solver that can provide interpretable and structured uncertainty estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02948v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Michael Solomon, Rishi Leburu, Matthias Chung</dc:creator>
    </item>
    <item>
      <title>Fisher-Information-Based Sensor Placement for Structural Digital Twins: Analytic Results and Benchmarks</title>
      <link>https://arxiv.org/abs/2602.02981</link>
      <description>arXiv:2602.02981v1 Announce Type: cross 
Abstract: High-fidelity digital twins rely on the accurate assimilation of sensor data into physics-based computational models. In structural applications, such twins aim to identify spatially distributed quantities--such as elementwise weakening fields, material parameters, or effective thermal loads--by minimizing discrepancies between measured and simulated responses subject to the governing equations of structural mechanics. While adjoint-based methods enable efficient gradient computation for these inverse problems, the quality and stability of the resulting estimates depend critically on the choice of sensor locations, measurement types, and directions.
  This paper develops a rigorous and implementation-ready framework for Fisher-information-based sensor placement in adjoint-based finite-element digital twins. Sensor configurations are evaluated using a D-optimal design criterion derived from a linearization of the measurement map, yielding a statistically meaningful measure of information content. We present matrix-free operator formulas for applying the Jacobian and its adjoint, and hence for computing Fisher-information products $Fv = J^\top R^{-1} Jv$ using only forward and adjoint solves. Building on these operator evaluations, we derive explicit sensitivity expressions for D-optimal sensor design with respect to measurement parameters and discuss practical strategies for evaluating the associated log-determinant objectives. To complement the general framework, we provide analytically tractable sensor placement results for a canonical one-dimensional structural model, clarifying the distinction between detectability and localizability and proving that D-optimal placement of multiple displacement sensors yields approximately uniform spacing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02981v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil, Animesh Jain, Rainald L\"ohner</dc:creator>
    </item>
    <item>
      <title>FlashSinkhorn: IO-Aware Entropic Optimal Transport</title>
      <link>https://arxiv.org/abs/2602.03067</link>
      <description>arXiv:2602.03067v1 Announce Type: cross 
Abstract: Entropic optimal transport (EOT) via Sinkhorn iterations is widely used in modern machine learning, yet GPU solvers remain inefficient at scale. Tensorized implementations suffer quadratic HBM traffic from dense $n\times m$ interactions, while existing online backends avoid storing dense matrices but still rely on generic tiled map-reduce reduction kernels with limited fusion. We present \textbf{FlashSinkhorn}, an IO-aware EOT solver for squared Euclidean cost that rewrites stabilized log-domain Sinkhorn updates as row-wise LogSumExp reductions of biased dot-product scores, the same normalization as transformer attention. This enables FlashAttention-style fusion and tiling: fused Triton kernels stream tiles through on-chip SRAM and update dual potentials in a single pass, substantially reducing HBM IO per iteration while retaining linear-memory operations. We further provide streaming kernels for transport application, enabling scalable first- and second-order optimization. On A100 GPUs, FlashSinkhorn achieves up to $32\times$ forward-pass and $161\times$ end-to-end speedups over state-of-the-art online baselines on point-cloud OT, improves scalability on OT-based downstream tasks. For reproducibility, we release an open-source implementation at https://github.com/ot-triton-lab/ot_triton.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03067v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix X. -F. Ye, Xingjie Li, An Yu, Ming-Ching Chang, Linsong Chu, Davis Wertheimer</dc:creator>
    </item>
    <item>
      <title>Sparse Training of Neural Networks based on Multilevel Mirror Descent</title>
      <link>https://arxiv.org/abs/2602.03535</link>
      <description>arXiv:2602.03535v1 Announce Type: cross 
Abstract: We introduce a dynamic sparse training algorithm based on linearized Bregman iterations / mirror descent that exploits the naturally incurred sparsity by alternating between periods of static and dynamic sparsity pattern updates. The key idea is to combine sparsity-inducing Bregman iterations with adaptive freezing of the network structure to enable efficient exploration of the sparse parameter space while maintaining sparsity. We provide convergence guaranties by embedding our method in a multilevel optimization framework. Furthermore, we empirically show that our algorithm can produce highly sparse and accurate models on standard benchmarks. We also show that the theoretical number of FLOPs compared to SGD training can be reduced from 38% for standard Bregman iterations to 6% for our method while maintaining test accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03535v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yannick Lunk, Sebastian J. Scott, Leon Bungert</dc:creator>
    </item>
    <item>
      <title>Noisy nonlocal aggregation model with gradient flow structures</title>
      <link>https://arxiv.org/abs/2602.03654</link>
      <description>arXiv:2602.03654v1 Announce Type: cross 
Abstract: Interacting particle systems provide a fundamental framework for modeling collective behavior in biological, social, and physical systems. In many applications, stochastic perturbations are essential for capturing environmental variability and individual uncertainty, yet their impact on long-term dynamics and equilibrium structure remains incompletely understood, particularly in the presence of nonlocal interactions. We investigate a stochastic interacting particle system governed by potential-driven interactions and its continuum density formulation in the large-population limit. We introduce an energy functional and show that the macroscopic density evolution has a gradient-flow structure in the Wasserstein-2 space. The associated variational framework yields equilibrium states through constrained energy minimization and illustrates how noise regulates the density and mitigates singular concentration. We demonstrate the connection between microscopic and macroscopic descriptions through numerical examples in one and two dimensions. Within the variational framework, we compute energy minimizers and perform a linear stability analysis. The numerical results show that the stable minimizers agree with the long-time dynamics of the macroscopic density model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03654v1</guid>
      <category>nlin.AO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Su Yang, Weiqi Chu, Panayotis G. Kevrekidis</dc:creator>
    </item>
    <item>
      <title>Improved Analysis of the Accelerated Noisy Power Method with Applications to Decentralized PCA</title>
      <link>https://arxiv.org/abs/2602.03682</link>
      <description>arXiv:2602.03682v1 Announce Type: cross 
Abstract: We analyze the Accelerated Noisy Power Method, an algorithm for Principal Component Analysis in the setting where only inexact matrix-vector products are available, which can arise for instance in decentralized PCA. While previous works have established that acceleration can improve convergence rates compared to the standard Noisy Power Method, these guarantees require overly restrictive upper bounds on the magnitude of the perturbations, limiting their practical applicability. We provide an improved analysis of this algorithm, which preserves the accelerated convergence rate under much milder conditions on the perturbations. We show that our new analysis is worst-case optimal, in the sense that the convergence rate cannot be improved, and that the noise conditions we derive cannot be relaxed without sacrificing convergence guarantees. We demonstrate the practical relevance of our results by deriving an accelerated algorithm for decentralized PCA, which has similar communication costs to non-accelerated methods. To our knowledge, this is the first decentralized algorithm for PCA with provably accelerated convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03682v1</guid>
      <category>stat.ML</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Agui\'e, Mathieu Even, Laurent Massouli\'e</dc:creator>
    </item>
    <item>
      <title>Reducing acquisition time and radiation damage: data-driven subsampling for spectro-microscopy</title>
      <link>https://arxiv.org/abs/2602.03744</link>
      <description>arXiv:2602.03744v1 Announce Type: cross 
Abstract: Spectro-microscopy is an experimental technique which can be used to observe spatial variations in chemical state and changes in chemical state over time or under experimental conditions. As a result it has broad applications across areas such as energy materials, catalysis, environmental science and biological samples. However, the technique is often limited by factors such as long acquisition times and radiation damage. We present two measurement strategies that allow for significantly shorter experiment times and total doses applied. The strategies are based on taking only a small subset of all the measurements (e.g. sparse acquisition or subsampling), and then computationally reconstructing all unobserved measurements using mathematical techniques. The methods are data-driven, using spectral and spatial importance subsampling distributions to identify important measurements. As a result, taking as little as 4-6\% of the measurements is sufficient to capture the same information as in a conventional scan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03744v1</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.optics</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maike Meier, Lorenzo Lazzarino, Boris Shustin, Hussam Al Daas, Paul Quinn</dc:creator>
    </item>
    <item>
      <title>Do We Need Asynchronous SGD? On the Near-Optimality of Synchronous Methods</title>
      <link>https://arxiv.org/abs/2602.03802</link>
      <description>arXiv:2602.03802v1 Announce Type: cross 
Abstract: Modern distributed optimization methods mostly rely on traditional synchronous approaches, despite substantial recent progress in asynchronous optimization. We revisit Synchronous SGD and its robust variant, called $m$-Synchronous SGD, and theoretically show that they are nearly optimal in many heterogeneous computation scenarios, which is somewhat unexpected. We analyze the synchronous methods under random computation times and adversarial partial participation of workers, and prove that their time complexities are optimal in many practical regimes, up to logarithmic factors. While synchronous methods are not universal solutions and there exist tasks where asynchronous methods may be necessary, we show that they are sufficient for many modern heterogeneous computation scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03802v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Grigory Begunov, Alexander Tyurin</dc:creator>
    </item>
    <item>
      <title>Quasi-Trefftz spaces for a first-order formulation of the Helmholtz equation</title>
      <link>https://arxiv.org/abs/2509.08936</link>
      <description>arXiv:2509.08936v2 Announce Type: replace 
Abstract: This work is concerned with the development of quasi-Trefftz methods for first-order differential systems. It focuses on discrete quasi-Trefftz spaces, starting from their definition and including the construction of corresponding bases together with their computational aspect.
  This is the first attempt at constructing quasi-Trefftz bases for a problem governed by a first-order system without relying on an auxiliary scalar equation. A decoupling approach, with a second order scalar equation for the one unknown, is proposed here simply as a point of comparison to this new approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08936v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lise-Marie Imbert-G\'erard, Andr\'ea Lagard\`ere, Guillaume Sylvand, S\'ebastien Tordeux</dc:creator>
    </item>
    <item>
      <title>Numerical Verification of PolyDG Algebraic Solvers for the Pseudo-Stress Stokes Problem</title>
      <link>https://arxiv.org/abs/2512.02537</link>
      <description>arXiv:2512.02537v2 Announce Type: replace 
Abstract: This work focuses on the development of efficient solvers for the pseudo-stress formulation of the unsteady Stokes problem, discretised by means of a discontinuous Galerkin method on polytopal grids (PolyDG). The introduction of the pseudo-stress variable is motivated by the growing interest in non-Newtonian flow models and coupled interface problems, where the stress field plays a fundamental role in the physical description. The space-time discretisation of the problem is obtained by combining the PolyDG approach in space with the implicit Euler method for time integration. The resulting linear system, characterised by a symmetric, positive, definite matrix, exhibits deteriorating convergence with standard solvers as the time step decreases. To address this issue, we investigate two tailored strategies: deflated Conjugate Gradient, which mitigates the effect of the most problematic eigenmodes, and collective Block-Jacobi, which exploits the block structure of the system matrix. Numerical experiments show that both approaches yield iteration counts effectively independent of $\Delta t$, ensuring robust performance with respect to the time step. Future work will focus on extending this robustness to the spatial discretisation parameter $h$ by integrating multigrid strategies with the time-robust solvers developed in this study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.02537v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paola F. Antonietti, Alessandra Cancrini, Gabriele Ciaramella</dc:creator>
    </item>
    <item>
      <title>Multi-Level Monte Carlo Training of Neural Operators</title>
      <link>https://arxiv.org/abs/2505.12940</link>
      <description>arXiv:2505.12940v2 Announce Type: replace-cross 
Abstract: Operator learning is a rapidly growing field that aims to approximate nonlinear operators related to partial differential equations (PDEs) using neural operators. These rely on discretization of input and output functions and are, usually, expensive to train for large-scale problems at high-resolution. Motivated by this, we present a Multi-Level Monte Carlo (MLMC) approach to train neural operators by leveraging a hierarchy of resolutions of function discretization. Our framework relies on using gradient corrections from fewer samples of fine-resolution data to decrease the computational cost of training while maintaining a high level accuracy. The proposed MLMC training procedure can be applied to any architecture accepting multi-resolution data. Our numerical experiments on a range of state-of-the-art models and test-cases demonstrate improved computational efficiency compared to traditional single-resolution training approaches, and highlight the existence of a Pareto curve between accuracy and computational time, related to the number of samples per resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12940v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Rowbottom, Stefania Fresca, Pietro Lio, Carola-Bibiane Sch\"onlieb, Nicolas Boull\'e</dc:creator>
    </item>
    <item>
      <title>On Modeling and Solving the Boltzmann Equation</title>
      <link>https://arxiv.org/abs/2508.13232</link>
      <description>arXiv:2508.13232v2 Announce Type: replace-cross 
Abstract: The Boltzmann equation has been a driving force behind significant mathematical research over the years. Its challenging theoretical complexity, combined with a wide variety of current scientific and technological problems that require numerical simulations based on this model, justifies such interest. This work provides a brief overview of studies and advances on the solution of the linear Boltzmann equation in one- and two-dimensional spatial dimensions. In particular, relevant aspects of the discrete ordinates approximation of the model are highlighted for neutron and photon transport applications, including nuclear safeguards, nuclear reactor shielding problems, and optical tomography. In addition, a short discussion of rarefied gas dynamics problems, relevant, for instance, to the study of micro-electro-mechanical systems, and their connection with the Linearized Boltzmann Equation, is presented. A primary goal of the work is to establish as much as possible the connections between the different phenomena described by the model and the versatility of the analytical methodology, the ADO method, in providing concise and accurate solutions, which are fundamental for numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13232v2</guid>
      <category>math-ph</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liliane Basso Barichello</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators</title>
      <link>https://arxiv.org/abs/2509.15069</link>
      <description>arXiv:2509.15069v2 Announce Type: replace-cross 
Abstract: This letter presents a novel approach for \mbox{efficiently} computing time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$ using cascaded accumulators. Traditional direct computation requires $K{\times}N$ general multiplications, which become prohibitive for large $N$, while alternative strategies based on lookup tables or signal reversal require storing entire data blocks. By exploiting accumulator properties, the proposed method eliminates the need for such storage and reduces the multiplicative cost to only $K{+}1$ constant multiplications, enabling efficient real-time implementation. The approach is particularly useful when such sums need to be efficiently computed in sample-by-sample processing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15069v2</guid>
      <category>eess.SP</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deijany Rodriguez Linares, Oksana Moryakova, H{\aa}kan Johansson</dc:creator>
    </item>
    <item>
      <title>Power Transform Revisited: Numerically Stable, and Federated</title>
      <link>https://arxiv.org/abs/2510.04995</link>
      <description>arXiv:2510.04995v2 Announce Type: replace-cross 
Abstract: Power transforms are popular parametric methods for making data more Gaussian-like, and are widely used as preprocessing steps in statistical analysis and machine learning. However, we find that direct implementations of power transforms suffer from severe numerical instabilities, which can lead to incorrect results or even crashes. In this paper, we provide a comprehensive analysis of the sources of these instabilities and propose effective remedies. We further extend power transforms to the federated learning setting, addressing both numerical and distributional challenges that arise in this context. Experiments on real-world datasets demonstrate that our methods are both effective and robust, substantially improving stability compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.04995v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuefeng Xu, Graham Cormode</dc:creator>
    </item>
    <item>
      <title>A Fast Relax-and-Round Approach to Unit Commitment for Data Center Own Generation</title>
      <link>https://arxiv.org/abs/2511.16420</link>
      <description>arXiv:2511.16420v3 Announce Type: replace-cross 
Abstract: The rapid growth of data centers increasingly requires data center operators to "bring own generation" to complement the available utility power plants to supply all or part of data center load. This practice sharply increases the number of generators on the bulk power system and shifts operational focus toward fuel costs rather than traditional startup and runtime constraints. Conventional mixed-integer unit commitment formulations are not well suited for systems with thousands of flexible, fast-cycling units. We propose a unit commitment formulation that relaxes binary commitment decisions by allowing generators to be fractionally on, enabling the use of algorithms for continuous solvers. We then use a rounding approach to get a feasible unit commitment. For a 276-unit system, solution time decreases from 10 hours to less than a second, with no accuracy degradation. Our approach scales with no issues to tens of thousands of generators, which allows solving problems on the scale of the major North America interconnections. The bulk of computation is parallel and GPU compatible, enabling further acceleration in future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16420v3</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaked Regev, Eve Tsybina, Slaven Peles</dc:creator>
    </item>
  </channel>
</rss>
