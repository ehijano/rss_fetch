<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 01:32:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Physics-informed graph neural networks for flow field estimation in carotid arteries</title>
      <link>https://arxiv.org/abs/2408.07110</link>
      <description>arXiv:2408.07110v1 Announce Type: new 
Abstract: Hemodynamic quantities are valuable biomedical risk factors for cardiovascular pathology such as atherosclerosis. Non-invasive, in-vivo measurement of these quantities can only be performed using a select number of modalities that are not widely available, such as 4D flow magnetic resonance imaging (MRI). In this work, we create a surrogate model for hemodynamic flow field estimation, powered by machine learning. We train graph neural networks that include priors about the underlying symmetries and physics, limiting the amount of data required for training. This allows us to train the model using moderately-sized, in-vivo 4D flow MRI datasets, instead of large in-silico datasets obtained by computational fluid dynamics (CFD), as is the current standard. We create an efficient, equivariant neural network by combining the popular PointNet++ architecture with group-steerable layers. To incorporate the physics-informed priors, we derive an efficient discretisation scheme for the involved differential operators. We perform extensive experiments in carotid arteries and show that our model can accurately estimate low-noise hemodynamic flow fields in the carotid artery. Moreover, we show how the learned relation between geometry and hemodynamic quantities transfers to 3D vascular models obtained using a different imaging modality than the training data. This shows that physics-informed graph neural networks can be trained using 4D flow MRI data to estimate blood flow in unseen carotid artery geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07110v1</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Suk, Dieuwertje Alblas, Barbara A. Hutten, Albert Wiegman, Christoph Brune, Pim van Ooij, Jelmer M. Wolterink</dc:creator>
    </item>
    <item>
      <title>Spatial Dynamics Behavioral Analysis of Motivational Operations Using Weighted Voronoi Diagrams</title>
      <link>https://arxiv.org/abs/2408.07250</link>
      <description>arXiv:2408.07250v1 Announce Type: new 
Abstract: This paper presents a novel approach to the analysis of spatial behavior distribution, utilizing weighted Voronoi diagrams. The objective is to map and understand how an experimental subject moves and spends time in various areas of a given space, thus identifying the areas of greatest behavioral interest. The technique entails the partitioning of the space into a grid, the designation of generator points, and the assignment of weights based on the time the subject spends in each region. The data analyzed were derived from multiple experimental sessions in which subjects were exposed to various conditions, including food deprivation, water deprivation, and combined deprivation and no deprivation. The aforementioned conditions resulted in the formation of clearly delineated spatial patterns. Weighted Voronoi diagrams provided a comprehensive and precise representation of these areas of interest, facilitating an in-depth examination of the evolution of behavioral patterns in diverse contexts, such as under different Motivational Operations. This tool offers a valuable perspective for the dynamic study of spatial behaviors in variable experimental settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07250v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Alberto Hern\'andez-Linares, Porfirio Toledo, Brenda Zarah\'i Medina-P\'erez, Varsovia Hern\'andez, Martha Lorena Avenda\~no Garrido, V\'ictor Quintero, Alejandro Le\'on</dc:creator>
    </item>
    <item>
      <title>Accounting for the geometry of the lung in respiratory viral infections</title>
      <link>https://arxiv.org/abs/2408.07618</link>
      <description>arXiv:2408.07618v1 Announce Type: new 
Abstract: Increasingly, mathematical models of viral infections have come to recognise the important role of spatial structure in infection dynamics. Almost invariably, spatial models of viral infections make use of a wide, flat computational domain which is assumed to be representative of the entire affected tissue. Implicit in this assumption is that either the tissue being modelled is largely wide and homogeneous, or that the topology of the tissue has little influence on the dynamics of the system. This assumption fails to take into account the distinctive geometry of the lung. The lung is characterised by a tubular, highly branching structure, and moreover is spatially heterogeneous: deeper regions of the lung are composed of far narrower airways and are associated with more severe infection. Here, we extend a typical multicellular model of viral dynamics to account for two essential features of the geometry of the lung: the tubular structure of airways, and the branching process between airway generations. We show that, with this more realistic tissue geometry, the dynamics of infection are substantially changed compared to the standard approach, and that the resulting model is equipped to tackle important biological phenomena that are not well-addressed with existing models, including viral lineage dynamics in the lung, and heterogeneity in immune responses to infection in different regions of the respiratory tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07618v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Williams, James M. McCaw, James M. Osborne</dc:creator>
    </item>
    <item>
      <title>Drug Discovery SMILES-to-Pharmacokinetics Diffusion Models with Deep Molecular Understanding</title>
      <link>https://arxiv.org/abs/2408.07636</link>
      <description>arXiv:2408.07636v1 Announce Type: new 
Abstract: Artificial intelligence (AI) is increasingly used in every stage of drug development. One challenge facing drug discovery AI is that drug pharmacokinetic (PK) datasets are often collected independently from each other, often with limited overlap, creating data overlap sparsity. Data sparsity makes data curation difficult for researchers looking to answer research questions in poly-pharmacy, drug combination research, and high-throughput screening. We propose Imagand, a novel SMILES-to-Pharmacokinetic (S2PK) diffusion model capable of generating an array of PK target properties conditioned on SMILES inputs. We show that Imagand-generated synthetic PK data closely resembles real data univariate and bivariate distributions, and improves performance for downstream tasks. Imagand is a promising solution for data overlap sparsity and allows researchers to efficiently generate ligand PK data for drug discovery research. Code is available at \url{https://github.com/bing1100/Imagand}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07636v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bing Hu, Anita Layton, Helen Chen</dc:creator>
    </item>
    <item>
      <title>Quantification of total uncertainty in the physics-informed reconstruction of CVSim-6 physiology</title>
      <link>https://arxiv.org/abs/2408.07201</link>
      <description>arXiv:2408.07201v1 Announce Type: cross 
Abstract: When predicting physical phenomena through simulation, quantification of the total uncertainty due to multiple sources is as crucial as making sure the underlying numerical model is accurate. Possible sources include irreducible aleatoric uncertainty due to noise in the data, epistemic uncertainty induced by insufficient data or inadequate parameterization, and model-form uncertainty related to the use of misspecified model equations. Physics-based regularization interacts in nontrivial ways with aleatoric, epistemic and model-form uncertainty and their combination, and a better understanding of this interaction is needed to improve the predictive performance of physics-informed digital twins that operate under real conditions. With a specific focus on biological and physiological models, this study investigates the decomposition of total uncertainty in the estimation of states and parameters of a differential system simulated with MC X-TFC, a new physics-informed approach for uncertainty quantification based on random projections and Monte-Carlo sampling. MC X-TFC is applied to a six-compartment stiff ODE system, the CVSim-6 model, developed in the context of human physiology. The system is analyzed by progressively removing data while estimating an increasing number of parameters and by investigating total uncertainty under model-form misspecification of non-linear resistance in the pulmonary compartment. In particular, we focus on the interaction between the formulation of the discrepancy term and quantification of model-form uncertainty, and show how additional physics can help in the estimation process. The method demonstrates robustness and efficiency in estimating unknown states and parameters, even with limited, sparse, and noisy data. It also offers great flexibility in integrating data with physics for improved estimation, even in cases of model misspecification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07201v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mario De Florio, Zongren Zou, Daniele E. Schiavazzi, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Deep Learning: a Heuristic Three-stage Mechanism for Grid Searches to Optimize the Future Risk Prediction of Breast Cancer Metastasis Using EHR-based Clinical Data</title>
      <link>https://arxiv.org/abs/2408.07673</link>
      <description>arXiv:2408.07673v2 Announce Type: cross 
Abstract: A grid search, at the cost of training and testing a large number of models, is an effective way to optimize the prediction performance of deep learning models. A challenging task concerning grid search is the time management. Without a good time management scheme, a grid search can easily be set off as a mission that will not finish in our lifetime. In this study, we introduce a heuristic three-stage mechanism for managing the running time of low-budget grid searches, and the sweet-spot grid search (SSGS) and randomized grid search (RGS) strategies for improving model prediction performance, in predicting the 5-year, 10-year, and 15-year risk of breast cancer metastasis. We develop deep feedforward neural network (DFNN) models and optimize them through grid searches. We conduct eight cycles of grid searches by applying our three-stage mechanism and SSGS and RGS strategies. We conduct various SHAP analyses including unique ones that interpret the importance of the DFNN-model hyperparameters. Our results show that grid search can greatly improve model prediction. The grid searches we conducted improved the risk prediction of 5-year, 10-year, and 15-year breast cancer metastasis by 18.6%, 16.3%, and 17.3% respectively, over the average performance of all corresponding models we trained using the RGS strategy. We not only demonstrate best model performance but also characterize grid searches from various aspects such as their capabilities of discovering decent models and the unit grid search time. The three-stage mechanism worked effectively. It made our low-budget grid searches feasible and manageable, and in the meantime helped improve model prediction performance. Our SHAP analyses identified both clinical risk factors important for the prediction of future risk of breast cancer metastasis, and DFNN-model hyperparameters important to the prediction of performance scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07673v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xia Jiang, Yijun Zhou, Chuhan Xu, Adam Brufsky, Alan Wells</dc:creator>
    </item>
    <item>
      <title>Harnessing Big Data and Artificial Intelligence to Study Plant Stress</title>
      <link>https://arxiv.org/abs/2404.15776</link>
      <description>arXiv:2404.15776v2 Announce Type: replace 
Abstract: Life finds a way. For sessile organisms like plants, the need to adapt to changes in the environment is even more poignant. For humanity, the need to develop crops that can grow in diverse environments and feed our growing population is an existential one. The advent of the genomics era enabled the generation of high-throughput data and computational methods that serve as powerful hypothesis-generating tools to understand the genomic and gene functional basis of stress resilience. Today, the proliferation of artificial intelligence (AI) allows scientists to rapidly screen through high-throughput datasets to uncover elusive patterns and correlations, enabling us to create more performant models for prediction and hypothesis generation in plant biology. This review aims to provide an overview of the availability of large-scale data in plant stress research and discuss the application of AI tools on these large-scale datasets in a bid to develop more stress-resilient plants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15776v2</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eugene Koh, Rohan Shawn Sunil, Hilbert Yuen In Lam, Marek Mutwil</dc:creator>
    </item>
    <item>
      <title>Information Theory for Complex Systems Scientists</title>
      <link>https://arxiv.org/abs/2304.12482</link>
      <description>arXiv:2304.12482v3 Announce Type: replace-cross 
Abstract: In the 21st century, many of the crucial scientific and technical issues facing humanity can be understood as problems associated with understanding, modelling, and ultimately controlling complex systems: systems comprised of a large number of non-trivially interacting components whose collective behaviour can be difficult to predict. Information theory, a branch of mathematics historically associated with questions about encoding and decoding messages, has emerged as something of a lingua franca for those studying complex systems, far exceeding its original narrow domain of communication systems engineering. In the context of complexity science, information theory provides a set of tools which allow researchers to uncover the statistical and effective dependencies between interacting components; relationships between systems and their environment; mereological whole-part relationships; and is sensitive to non-linearities missed by commonly parametric statistical models.
  In this review, we aim to provide an accessible introduction to the core of modern information theory, aimed specifically at aspiring (and established) complex systems scientists. This includes standard measures, such as Shannon entropy, relative entropy, and mutual information, before building to more advanced topics, including: information dynamics, measures of statistical complexity, information decomposition, and effective network inference. In addition to detailing the formal definitions, in this review we make an effort to discuss how information theory can be interpreted and develop the intuition behind abstract concepts like "entropy," in the hope that this will enable interested readers to understand what information is, and how it is used, at a more fundamental level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.12482v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <category>stat.OT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Thomas F. Varley</dc:creator>
    </item>
    <item>
      <title>A distribution-guided Mapper algorithm</title>
      <link>https://arxiv.org/abs/2401.12237</link>
      <description>arXiv:2401.12237v2 Announce Type: replace-cross 
Abstract: Motivation: The Mapper algorithm is an essential tool to explore shape of data in topology data analysis. With a dataset as an input, the Mapper algorithm outputs a graph representing the topological features of the whole dataset. This graph is often regarded as an approximation of a reeb graph of data. The classic Mapper algorithm uses fixed interval lengths and overlapping ratios, which might fail to reveal subtle features of data, especially when the underlying structure is complex.
  Results: In this work, we introduce a distribution guided Mapper algorithm named D-Mapper, that utilizes the property of the probability model and data intrinsic characteristics to generate density guided covers and provides enhanced topological features. Our proposed algorithm is a probabilistic model-based approach, which could serve as an alternative to non-prababilistic ones. Moreover, we introduce a metric accounting for both the quality of overlap clustering and extended persistence homology to measure the performance of Mapper type algorithm. Our numerical experiments indicate that the D-Mapper outperforms the classical Mapper algorithm in various scenarios. We also apply the D-Mapper to a SARS-COV-2 coronavirus RNA sequences dataset to explore the topological structure of different virus variants. The results indicate that the D-Mapper algorithm can reveal both vertical and horizontal evolution processes of the viruses.
  Availability: Our package is available at https://github.com/ShufeiGe/D-Mapper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12237v2</guid>
      <category>math.AT</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyang Tao, Shufei Ge</dc:creator>
    </item>
  </channel>
</rss>
