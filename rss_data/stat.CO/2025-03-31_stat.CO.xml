<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 31 Mar 2025 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Bayesian inference of numerical modeling-based morphodynamics: Application to a dam-break over a mobile bed experiment</title>
      <link>https://arxiv.org/abs/2503.21789</link>
      <description>arXiv:2503.21789v1 Announce Type: new 
Abstract: Numerical modeling of morphodynamics presents significant challenges in engineering due to uncertainties arising from inaccurate inputs, model errors, and limited computing resources. Accurate results are essential for optimizing strategies and reducing costs. This paper presents a step-by-step Bayesian methodology to conduct an uncertainty analysis of 2D numerical modeling-based morphodynamics, exemplified by a dam-break over a sand bed experiment. Initially, uncertainties from prior knowledge are propagated through the dynamical model using the Monte Carlo technique. This approach estimates the relative influence of each input parameter on results, identifying the most relevant parameters and observations for Bayesian inference and creating a numerical database for emulator construction. Given the computationally intensive simulations of Markov chain Monte Carlo (MCMC) sampling, a neural network emulator is used to approximate the complex 2D numerical model efficiently. Subsequently, a Bayesian framework is employed to characterize input parameter uncertainty variability and produce probability-based predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21789v1</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Goeury, Fabien Souill\'e</dc:creator>
    </item>
    <item>
      <title>Binary AddiVortes: (Bayesian) Additive Voronoi Tessellations for Binary Classification with an application to Predicting Home Mortgage Application Outcomes</title>
      <link>https://arxiv.org/abs/2503.21792</link>
      <description>arXiv:2503.21792v1 Announce Type: cross 
Abstract: The Additive Voronoi Tessellations (AddiVortes) model is a multivariate regression model that uses multiple Voronoi tessellations to partition the covariate space for an additive ensemble model. In this paper, the AddiVortes framework is extended to binary classification by incorporating a probit model with a latent variable formulation. Specifically, we utilise a data augmentation technique, where a latent variable is introduced and the binary response is determined via thresholding. In most cases, the AddiVortes model outperforms random forests, BART and other leading black-box regression models when compared using a range of metrics. A comprehensive analysis is conducted using AddiVortes to predict an individual's likelihood of being approved for a home mortgage, based on a range of covariates. This evaluation highlights the model's effectiveness in capturing complex relationships within the data and its potential for improving decision-making in mortgage approval processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21792v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam J. Stone, Emmanuel Ogundimu, John Paul Gosling</dc:creator>
    </item>
    <item>
      <title>tempdisagg: A Python Framework for Temporal Disaggregation of Time Series Data</title>
      <link>https://arxiv.org/abs/2503.22054</link>
      <description>arXiv:2503.22054v1 Announce Type: cross 
Abstract: tempdisagg is a modern, extensible, and production-ready Python framework for temporal disaggregation of time series data. It transforms low-frequency aggregates into consistent, high-frequency estimates using a wide array of econometric techniques-including Chow-Lin, Denton, Litterman, Fernandez, and uniform interpolation-as well as enhanced variants with automated estimation of key parameters such as the autocorrelation coefficient rho. The package introduces features beyond classical methods, including robust ensemble modeling via non-negative least squares optimization, post-estimation correction of negative values under multiple aggregation rules, and optional regression-based imputation of missing values through a dedicated Retropolarizer module. Architecturally, it follows a modular design inspired by scikit-learn, offering a clean API for validation, modeling, visualization, and result interpretation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22054v1</guid>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jaime Vera-Jaramillo</dc:creator>
    </item>
    <item>
      <title>An integrated method for clustering and association network inference</title>
      <link>https://arxiv.org/abs/2503.22467</link>
      <description>arXiv:2503.22467v1 Announce Type: cross 
Abstract: We consider high dimensional Gaussian graphical models inference. These models provide a rigorous framework to describe a network of statistical dependencies between entities, such as genes in genomic regulation studies or species in ecology. Penalized methods, including the standard Graphical-Lasso, are well-known approaches to infer the parameters of these models. As the number of variables in the model (of entities in the network) grow, the network inference and interpretation become more complex. We propose Normal-Block, a new model that clusters variables and consider a network at the cluster level. Normal-Block both adds structure to the network and reduces its size. We build on Graphical-Lasso to add a penalty on the network's edges and limit the detection of spurious dependencies, we also propose a zero-inflated version of the model to account for real-world data properties. For the inference procedure, we propose a direct heuristic method and another more rigorous one that simultaneously infers the clustering of variables and the association network between clusters, using a penalized variational Expectation-Maximization approach. An implementation of the model in R, in a package called normalblockr, is available on github (https://github.com/jeannetous/normalblockr). We present the results in terms of clustering and network inference using both simulated data and various types of real-world data (proteomics, words occurrences on webpages, and microbiota distribution).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22467v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeanne Tous, Julien Chiquet</dc:creator>
    </item>
    <item>
      <title>Gaussian process modelling of infectious diseases using the Greta software package and GPUs</title>
      <link>https://arxiv.org/abs/2411.05556</link>
      <description>arXiv:2411.05556v3 Announce Type: replace 
Abstract: Gaussian process are a widely-used statistical tool for conducting non-parametric inference in applied sciences, with many computational packages available to fit to data and predict future observations. We study the use of the Greta software for Bayesian inference to apply Gaussian process regression to spatio-temporal data of infectious disease outbreaks and predict future disease spread. Greta builds on Tensorflow, making it comparatively easy to take advantage of the significant gain in speed offered by GPUs. In these complex spatio-temporal models, we show a reduction of up to 70\% in computational time relative to fitting the same models on CPUs. We show how the choice of covariance kernel impacts the ability to infer spread and extrapolate to unobserved spatial and temporal units. The inference pipeline is applied to weekly incidence data on tuberculosis in the East and West Midlands regions of England over a period of two years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05556v3</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eva Gunn, Nikhil Sengupta, Ben Swallow</dc:creator>
    </item>
    <item>
      <title>Gridding and Parameter Expansion for Scalable Latent Gaussian Models of Spatial Multivariate Data</title>
      <link>https://arxiv.org/abs/2101.03579</link>
      <description>arXiv:2101.03579v2 Announce Type: replace-cross 
Abstract: Scalable spatial GPs for massive datasets can be built via sparse Directed Acyclic Graphs (DAGs) where a small number of directed edges is sufficient to flexibly characterize spatial dependence. The DAG can be used to devise fast algorithms for posterior sampling of the latent process, but these may exhibit pathological behavior in estimating covariance parameters. In this article, we introduce gridding and parameter expansion methods to improve the practical performance of MCMC algorithms in terms of effective sample size per unit time (ESS/s). Gridding is a model-based strategy that reduces the number of expensive operations necessary during MCMC on irregularly spaced data. Parameter expansion reduces dependence in posterior samples in spatial regression for high resolution data. These two strategies lead to computational gains in the big data settings on which we focus. We consider popular constructions of univariate spatial processes based on Mat\'ern covariance functions and multivariate coregionalization models for Gaussian outcomes in extensive analyses of synthetic datasets comparing with alternative methods. We demonstrate effectiveness of our proposed methods in a forestry application using remotely sensed data from NASA's Goddard LiDAR, Hyper-Spectral, and Thermal imager (G-LiHT).</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.03579v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Mon, 31 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1214/25-BA1515</arxiv:DOI>
      <dc:creator>Michele Peruzzi, Sudipto Banerjee, David B. Dunson, Andrew O. Finley</dc:creator>
    </item>
  </channel>
</rss>
