<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Dec 2025 02:39:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>BISTRO - A Bi-Fidelity Stochastic Gradient Framework using Trust-Regions for Optimization Under Uncertainty</title>
      <link>https://arxiv.org/abs/2512.09055</link>
      <description>arXiv:2512.09055v1 Announce Type: new 
Abstract: Stochastic optimization of engineering systems is often infeasible due to repeated evaluations of a computationally expensive, high-fidelity simulation. Bi-fidelity methods mitigate this challenge by leveraging a cheaper, approximate model to accelerate convergence. Most existing bi-fidelity approaches, however, exploit either design-space curvature or random-space correlation, not both. We present BISTRO - a BI-fidelity Stochastic Trust-Region Optimizer for unconstrained optimization under uncertainty through a stochastic approximation procedure. This approach exploits the curvature information of a low-fidelity objective function to converge within a basin of a local minimum of the high-fidelity model where low-fidelity curvature information is no longer valuable. The method then switches to a variance-reduced stochastic gradient descent procedure. We provide convergence guarantees in expectation under certain regularity assumptions and ensure the best-case $\mathcal{O}(1/n)$ convergence rate for stochastic optimization. On benchmark problems and a 20-dimensional space shuttle reentry case, BISTRO converges faster than adaptive sampling and variance reduction procedures and cuts computational expense by up to 29x.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09055v1</guid>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas O. Dixon, Geoffrey F. Bomarito, James E. Warner, Alex A. Gorodetsky</dc:creator>
    </item>
    <item>
      <title>Cyqlone: A Parallel, High-Performance Linear Solver for Optimal Control</title>
      <link>https://arxiv.org/abs/2512.09058</link>
      <description>arXiv:2512.09058v1 Announce Type: new 
Abstract: We present Cyqlone, a solver for linear systems with a stage-wise optimal control structure that fully exploits the various levels of parallelism available in modern hardware. Cyqlone unifies algorithms based on the sequential Riccati recursion, parallel Schur complement methods, and cyclic reduction methods, thereby minimizing the required number of floating-point operations, while allowing parallelization across a user-configurable number of processors. Given sufficient parallelism, the solver run time scales with the logarithm of the horizon length (in contrast to the linear scaling of sequential Riccati-based methods), enabling real-time solution of long-horizon problems. Beyond multithreading on multi-core processors, implementations of Cyqlone can also leverage vectorization using batched linear algebra routines. Such batched routines exploit data parallelism using single instruction, multiple data (SIMD) operations, and expose a higher degree of instruction-level parallelism than their non-batched counterparts. This enables them to significantly outperform BLAS and BLASFEO for the small matrices that arise in optimal control. Building on this high-performance linear solver, we develop CyQPALM, a parallel and optimal-control-specific variant of the QPALM quadratic programming solver. It combines the parallel and vectorized linear algebra operations from Cyqlone with a parallel line search and parallel factorization updates, resulting in order-of-magnitude speedups compared to the state-of-the-art HPIPM solver. Open-source C++ implementations of Cyqlone and CyQPALM are available at https://github.com/kul-optec/cyqlone</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09058v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pieter Pas, Panagiotis Patrinos</dc:creator>
    </item>
    <item>
      <title>Reactive Vehicle Guidance using Dynamic Maneuvering Cue</title>
      <link>https://arxiv.org/abs/2512.09083</link>
      <description>arXiv:2512.09083v1 Announce Type: new 
Abstract: Recent approaches for navigating among dynamic threat regions (i.e., weapon engagement zones) have focused on planning entire trajectories. Moreover, the allowance for penetration into these threat regions was based on heuristic measurements of risk. This paper offers an approach for a more reactive (i.e., feedback-based) guidance that is based on closed-form analytical expressions and thereby suitable for onboard, real-time execution. In addition, a risk measurement is formulated based upon the concept of Dynamic Maneuvering Cue (DMC) which measures the amount of turn a vehicle would need to take in its current state in order to put itself outside the threat region. This approach is then extended to handle multiple threat regions simultaneously (with minimal additional computational complexity). Finally, the DMC constraint is applied to a simple feedback controller as well as a model predictive controller (MPC). The MPC shows better performance but at the cost of having to solve an optimization problem online versus the meager computational burden associated with the simple controller. This approach, which is based on assuming the threats are adversarial, may be used as a conservative method for collision avoidance and deconfliction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09083v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Von Moll, Isaac Weintraub</dc:creator>
    </item>
    <item>
      <title>On Event-Triggered Extremum Seeking via Standard and Lie-Bracket Averaging: A Hybrid Dynamical Systems Approach</title>
      <link>https://arxiv.org/abs/2512.09113</link>
      <description>arXiv:2512.09113v1 Announce Type: new 
Abstract: We introduce and analyze the stability of a class of event-triggered extremum-seeking algorithms designed to solve resource-aware, model-free, optimization problems. Leveraging recent advances in Lie-Bracket Averaging for hybrid systems, we demonstrate that the proposed controllers can be formulated as well-posed multi-time-scale hybrid systems that satisfy key regularity, stability, and robustness properties. In extremum-seeking systems, exploration and exploitation are inherently coupled. This coupling necessitates careful consideration in the design of the event-triggered controller. To address this challenge, we incorporate a low-pass filter into the algorithm and carefully design the flow and jump sets of the resulting hybrid system. The resulting controller renders the optimal point semi-globally practically asymptotically stable with solutions exhibiting a uniform semi-global dwell time. We also demonstrate how the proposed event-triggered scheme can be modified to allow analysis using traditional averaging tools for hybrid systems by introducing two independent tunable parameters in the controller. Numerical simulations are presented to validate and illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09113v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Abdelgalil, Jorge I. Poveda</dc:creator>
    </item>
    <item>
      <title>Second-Order $\Lambda$-Sets and Extensions to Non-Smooth, Hybrid, and Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2512.09126</link>
      <description>arXiv:2512.09126v1 Announce Type: new 
Abstract: This paper develops a comprehensive extension of the $\Lambda$-set framework for optimal control, introducing second-order $\Lambda$-sets and generalizing the theory to non-smooth, hybrid, and stochastic hybrid systems. We first establish second-order necessary conditions that incorporate curvature information of the reachable set, providing refined optimality criteria that bridge classical second-variation methods with the geometric $\Lambda$-set approach. The framework is then extended to Filippov systems with discontinuous dynamics and to hybrid dynamical systems with state-dependent switching, yielding new necessary conditions for optimality in these settings. Furthermore, we introduce stochastic $\Lambda$-sets for systems subject to both continuous diffusion and discrete random switching, connecting the framework to Peng's stochastic maximum principle. Throughout the paper, detailed examples -- including nonholonomic systems, mechanical systems with friction, and stochastic temperature control -- illustrate the theoretical developments and demonstrate the practical applicability of the extended $\Lambda$-set theory. The results unify and generalize existing maximum principles, offering a powerful geometric tool for analyzing optimal control problems across a broad spectrum of system classes, from classical smooth systems to modern stochastic hybrid systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09126v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mohammad H. M Rashid</dc:creator>
    </item>
    <item>
      <title>A Benamou-Brenier Proximal Splitting Method for Constrained Unbalanced Optimal Transport</title>
      <link>https://arxiv.org/abs/2512.09250</link>
      <description>arXiv:2512.09250v1 Announce Type: new 
Abstract: The dynamic formulation of optimal transport, also known as the Benamou-Brenier formulation, has been extended to the unbalanced case by introducing a source term in the continuity equation. When this source term is penalized based on the Fisher-Rao metric, the resulting model is referred to as the Wasserstein-Fisher-Rao (WFR) setting, and allows for the comparison between any two positive measures without the need for equalized total mass. In recent work, we introduced a constrained variant of this model, in which affine integral equality constraints are imposed along the measure path. In the present paper, we propose a further generalization of this framework, which allows for constraints that apply not just to the density path but also to the momentum and source terms, and incorporates affine inequalities in addition to equality constraints. We prove, under suitable assumptions on the constraints, the well-posedness of the resulting class of convex variational problems. The paper is then primarily devoted to developing an effective numerical pipeline that tackles the corresponding constrained optimization problem based on finite difference discretizations and parallel proximal schemes. Our proposed framework encompasses standard balanced and unbalanced optimal transport, as well as a multitude of natural and practically relevant constraints, and we highlight its versatility via several synthetic and real data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09250v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mao Nishino, Martin Bauer, Tom Needham, Nicolas Charon</dc:creator>
    </item>
    <item>
      <title>Parameter-Free Accelerated Quasi-Newton Method for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2512.09439</link>
      <description>arXiv:2512.09439v1 Announce Type: new 
Abstract: We propose a quasi-Newton-type method for nonconvex optimization with Lipschitz continuous gradients and Hessians. The algorithm finds an $\varepsilon$-stationary point within $\tilde{\mathrm{O}}(d^{1/4} \varepsilon^{-13/8})$ gradient evaluations, where $d$ is the problem dimension. Although this bound includes an additional logarithmic factor compared with the best known complexity, our method is parameter-free in the sense that it requires no prior knowledge of problem-dependent parameters such as Lipschitz constants or the optimal value. Moreover, it does not need the target accuracy $\varepsilon$ or the total number of iterations to be specified in advance. The result is achieved by combining several key ideas: momentum-based acceleration, quartic regularization for subproblems, and a scaled variant of the Powell-symmetric-Broyden (PSB) update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09439v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naoki Marumo</dc:creator>
    </item>
    <item>
      <title>Some Remarks on Positive/Negative Feedback</title>
      <link>https://arxiv.org/abs/2512.09474</link>
      <description>arXiv:2512.09474v1 Announce Type: new 
Abstract: In the context of unstable systems with control, a commonly-held precept is that negative and positive feedback cannot both be stabilizing. The canonical linear prototype is the scalar system $\dot x=u$ which, under negative linear feedback $u=-kx$ ($k &gt;0$) is exponentially stable for all $k &gt;0 $, whereas the inherent lack of exponential instability of the uncontrolled system is amplified by positive feedback $u=kx$ ($k &gt;0)$. By contrast, for nonlinear systems it is shown that this intuitively-appealing dichotomy may fail to hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09474v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Berger, Achim Ilchmann, Eugene P. Ryan</dc:creator>
    </item>
    <item>
      <title>Suboptimal open-loop solution of a Stackelberg linear-quadratic differential game with cheap control of a follower: analytical/numerical study</title>
      <link>https://arxiv.org/abs/2512.09476</link>
      <description>arXiv:2512.09476v1 Announce Type: new 
Abstract: A two-player finite horizon linear-quadratic Stackelberg differential game is considered. The feature of this game is that the control cost of a follower in the cost functionals of both players is small, which means that the game under consideration is a cheap control game. The open-loop solution of this game is studied. Using the game's solvability conditions, obtaining such a game's solution is reduced to the solution of a proper boundary-value problem. Due to the smallness of the follower's control cost, this boundary-value problem is singularly perturbed. The asymptotic behaviour of the solution to this problem is analysed. Based on this analysis, the asymptotic behaviour of the open-loop optimal players' controls and the optimal values of the cost functionals is studied. Using these results, asymptotically suboptimal players' controls are designed. An illustrative example of a supply chain problem with a small control cost of a retailer is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09476v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valery Y. Glizer, Vladimir Turetsky</dc:creator>
    </item>
    <item>
      <title>Trajectory Optimization by Successive Pseudospectral Convexification on Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2512.09551</link>
      <description>arXiv:2512.09551v1 Announce Type: new 
Abstract: This paper proposes an intrinsic pseudospectral convexification framework for optimal control problems with manifold constraints. While successive pseudospectral convexification combines spectral collocation with successive convexification, classical pseudospectral methods are not geometry-consistent on manifolds. This is because interpolation and differentiation are performed in Euclidean coordinates. We introduce a geometry-consistent transcription that enables pseudospectral collocation without imposing manifold constraints extrinsically. The resulting method solves nonconvex manifold-constrained problems through a sequence of convex subproblems. A six-degree-of-freedom landing guidance example with unit quaternions and unit thrust-direction vectors demonstrates the practicality of the approach and preserves manifold feasibility to machine precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09551v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tatsuya Narumi, Shin-ichiro Sakai</dc:creator>
    </item>
    <item>
      <title>A tensor phase theory with applications in multilinear control</title>
      <link>https://arxiv.org/abs/2512.09559</link>
      <description>arXiv:2512.09559v1 Announce Type: new 
Abstract: The purpose of this paper is to initiate a phase theory for tensors under the Einstein product, and explore its applications in multilinear control systems. Firstly, the sectorial tensor decomposition for sectorial tensors is derived, which allows us to define phases for sectorial tensors. A numerical procedure for computing phases of a sectorial tensor is also proposed. Secondly, the maximin and minimax expressions for tensor phases are given, which are used to quantify how close the phases of a sectorial tensor are to those of its compressions. Thirdly, the compound spectrum, compound numerical ranges and compound angular numerical ranges of two sectorial tensors $A,B$ are defined and characterized in terms of the compound numerical ranges and compound angular numerical ranges of the sectorial tensors $A,B$. Fourthly, it is shown that the angles of eigenvalues of the product of two sectorial tensors are upper bounded by the sum of their individual phases. Finally, based on the tensor phase theory developed above, a tensor version of the small phase theorem is presented, which can be regarded as a natural generalization of the matrix case, recently proposed in Ref. [10]. The results offer powerful new tools for the stability and robustness analysis of multilinear feedback control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09559v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengdong Liu, Yimin Wei, Guofeng Zhang</dc:creator>
    </item>
    <item>
      <title>The Ky Fan Norms and Beyond: Dual Norms and Combinations for Matrix Optimization</title>
      <link>https://arxiv.org/abs/2512.09678</link>
      <description>arXiv:2512.09678v1 Announce Type: new 
Abstract: In this article, we explore the use of various matrix norms for optimizing functions of weight matrices, a crucial problem in training large language models. Moving beyond the spectral norm underlying the Muon update, we leverage duals of the Ky Fan $k$-norms to introduce a family of Muon-like algorithms we name Fanions, which are closely related to Dion. By working with duals of convex combinations of the Ky Fan $k$-norms with either the Frobenius norm or the $l_\infty$ norm, we construct the families of F-Fanions and S-Fanions, respectively. Their most prominent members are F-Muon and S-Muon. We complement our theoretical analysis with an extensive empirical study of these algorithms across a wide range of tasks and settings, demonstrating that F-Muon and S-Muon consistently match Muon's performance, while outperforming vanilla Muon on a synthetic linear least squares problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09678v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Kravatskiy, Ivan Kozyrev, Nikolai Kozlov, Alexander Vinogradov, Daniil Merkulov, Ivan Oseledets</dc:creator>
    </item>
    <item>
      <title>Computer-Assisted Search for Differential Equations Corresponding to Optimization Methods and Their Convergence Rates</title>
      <link>https://arxiv.org/abs/2512.09712</link>
      <description>arXiv:2512.09712v1 Announce Type: new 
Abstract: Let $f:\mathbb{R}^n \to \mathbb{R}$ be a continuously differentiable convex function with its minimizer denoted by $x_*$ and optimal value $f_* = f(x_*)$. Optimization algorithms such as the gradient descent method can often be interpreted in the continuous-time limit as differential equations known as continuous dynamical systems. Analyzing the convergence rate of $f(x) - f_*$ in such systems often relies on constructing appropriate Lyapunov functions. However, these Lyapunov functions have been designed through heuristic reasoning rather than a systematic framework. Several studies have addressed this issue. In particular, Suh, Roh, and Ryu (2022) proposed a constructive approach that involves introducing dilated coordinates and applying integration by parts. Although this method significantly improves the process of designing Lyapunov functions, it still involves arbitrary choices among many possible options, and thus retains a heuristic nature in identifying Lyapunov functions that yield the best convergence rates. In this study, we propose a systematic framework for exploring these choices computationally. More precisely, we propose a brute-force approach using symbolic computation by computer algebra systems to explore every possibility. By formulating the design of Lyapunov functions for continuous dynamical systems as an optimization problem, we aim to optimize the Lyapunov function itself. As a result, our framework successfully reproduces many previously reported results and, in several cases, discovers new convergence rates that have not been shown in the existing studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09712v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.CA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atsushi Tabei, Ken'ichiro Tanaka</dc:creator>
    </item>
    <item>
      <title>A Smooth Approximation Framework for Weakly Convex Optimization</title>
      <link>https://arxiv.org/abs/2512.09720</link>
      <description>arXiv:2512.09720v2 Announce Type: new 
Abstract: Standard complexity analyses for weakly convex optimization rely on the Moreau envelope technique proposed by Davis and Drusvyatskiy (2019). The main insight is that nonsmooth algorithms, such as proximal subgradient, proximal point, and their stochastic variants, implicitly minimize a smooth surrogate function induced by the Moreau envelope. Meanwhile, explicit smoothing, which directly minimizes a smooth approximation of the objective, has long been recognized as an efficient strategy for nonsmooth optimization. In this paper, we generalize the notion of smoothable functions, which was proposed by Beck and Teboulle (2012) for nonsmooth convex optimization. This generalization provides a unified viewpoint on several important smoothing techniques for weakly convex optimization, including Nesterov-type smoothing and Moreau envelope smoothing. Our theory yields a framework for designing smooth approximation algorithms for both deterministic and stochastic weakly convex problems with provable complexity guarantees. Furthermore, our theory extends to the smooth approximation of non-Lipschitz functions, allowing for complexity analysis even when global Lipschitz continuity does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09720v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Deng, Wenzhi Gao</dc:creator>
    </item>
    <item>
      <title>On Parameter Identification in Three-Dimensional Elasticity and Discretisation with Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2512.09754</link>
      <description>arXiv:2512.09754v1 Announce Type: new 
Abstract: Physics-informed neural networks have emerged as a powerful tool in the scientific machine learning community, with applications to both forward and inverse problems. While they have shown considerable empirical success, significant challenges remain -- particularly regarding training stability and the lack of rigorous theoretical guarantees, especially when compared to classical mesh-based methods. In this work, we focus on the inverse problem of identifying a spatially varying parameter in a constitutive model of three-dimensional elasticity, using measurements of the system's state. This setting is especially relevant for non-invasive diagnosis in cardiac biomechanics, where one must also carefully account for the type of boundary data available. To address this inverse problem, we adopt an all-at-once optimisation framework, simultaneously estimating the state and parameter through a least-squares loss that encodes both available data and the governing physics. For this formulation, we prove stability estimates ensuring that our approach yields a stable approximation of the underlying ground-truth parameter of the physical system independent of a specific discretisation. We then proceed with a neural network-based discretisation and compare it to traditional mesh-based approaches. Our theoretical findings are complemented by illustrative numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09754v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federica Caforio, Martin Holler, Matthias H\"ofler</dc:creator>
    </item>
    <item>
      <title>Stochastic Fleet Size and Mix Consistent Vehicle Routing Problem for Last Mile Delivery</title>
      <link>https://arxiv.org/abs/2512.09764</link>
      <description>arXiv:2512.09764v1 Announce Type: new 
Abstract: In this paper, we address the joint optimization of fleet size and mix, along with vehicle routing, under uncertain customer demand. We propose a two-stage stochastic mixed-integer programming model, where first-stage decisions concern the composition of the delivery fleet and the design of consistent baseline routes. In the second stage, approximate recourse actions are introduced to adapt the initial routes in response to realized customer demands. The objective is to minimize the total delivery cost, including vehicle acquisition, travel distance, and penalty costs for unserved demand. To tackle the computational challenges arising in realistic problem instances, we develop a path-based reformulation of the model and design a Kernel Search-based heuristic to enhance scalability. Computational experiments on small synthetic instances, generated through a population-density-based sampling approach, are conducted to validate the formulation and assess the effects of demand stochasticity through standard stochastic measures, after applying a scenario reduction technique. Additional tests on large-scale real-world instances, based on data from the Italian postal company, demonstrate the effectiveness of the proposed approach and provide managerial and practical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09764v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paolo Beatrici, Sebastian Birolini, Francesca Maggioni, Paolo Malighetti</dc:creator>
    </item>
    <item>
      <title>Optimal strategy against straightforward bidding in clock auctions</title>
      <link>https://arxiv.org/abs/2512.09788</link>
      <description>arXiv:2512.09788v1 Announce Type: new 
Abstract: We study a model of auction representative of the 5G auction in France. We determine the optimal strategy of a bidder, assuming that the valuations of competitors are unknown to this bidder and that competitors adopt the straightforward bidding strategy. Our model is based on a Partially Observable Markov Decision Process (POMDP). This POMDP admits a concise statistics, avoiding the solution of a dynamic programming equation in the space of beliefs. In addition, under this optimal strategy, the expected gain of the bidder does not decrease if competitors deviate from straightforward bidding. We illustrate our results by numerical experiments, comparing the value of the bidder with the value of a perfectly informed one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09788v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Performance Evaluation, 2025, 169, pp.102502</arxiv:journal_reference>
      <dc:creator>Jad Zeroual (TROPICAL), Marianne Akian (TROPICAL), Aur\'elien Bechler (TROPICAL), Matthieu Chardy (TROPICAL), St\'ephane Gaubert (TROPICAL)</dc:creator>
    </item>
    <item>
      <title>Stabilization of a chain of 3 hyperbolic PDEs with 2 inputs in arbitrary position</title>
      <link>https://arxiv.org/abs/2512.09799</link>
      <description>arXiv:2512.09799v1 Announce Type: new 
Abstract: This paper addresses the stabilization of a chain of three coupled hyperbolic partial differential equations actuated by two control inputs applied at arbitrary nodes of the network. With the exception of configurations where one input is located at an endpoint, cases already well studied in the literature, all admissible two-inputs configurations are treated in this paper within a unified framework. The proposed approach relies on a backstepping transformation combined with a reformulation of the closed-loop dynamics as an Integral Difference Equation (IDE). This IDE representation reveals a common structural pattern across configurations and clarifies the role played by delayed dynamics in the stability analysis. Within this formulation, the stabilization problem can be handled using existing IDE control techniques. For most configurations, the stabilization of the PDE system requires an approximate spectral controllability assumption. Remarkably, one specific configuration can be stabilized without imposing any additional spectral condition. In contrast, we also provide an explicit example of a configuration for which the required spectral controllability property fails to hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09799v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Braun (L2S), Jean Auriol (L2S), Lucas Brivadis (L2S)</dc:creator>
    </item>
    <item>
      <title>Online Inference of Constrained Optimization: Primal-Dual Optimality and Sequential Quadratic Programming</title>
      <link>https://arxiv.org/abs/2512.08948</link>
      <description>arXiv:2512.08948v1 Announce Type: cross 
Abstract: We study online statistical inference for the solutions of stochastic optimization problems with equality and inequality constraints. Such problems are prevalent in statistics and machine learning, encompassing constrained $M$-estimation, physics-informed models, safe reinforcement learning, and algorithmic fairness. We develop a stochastic sequential quadratic programming (SSQP) method to solve these problems, where the step direction is computed by sequentially performing a quadratic approximation of the objective and a linear approximation of the constraints. Despite having access to unbiased estimates of population gradients, a key challenge in constrained stochastic problems lies in dealing with the bias in the step direction. As such, we apply a momentum-style gradient moving-average technique within SSQP to debias the step. We show that our method achieves global almost-sure convergence and exhibits local asymptotic normality with an optimal primal-dual limiting covariance matrix in the sense of H\'ajek and Le Cam. In addition, we provide a plug-in covariance matrix estimator for practical inference. To our knowledge, the proposed SSQP method is the first fully online method that attains primal-dual asymptotic minimax optimality without relying on projection operators onto the constraint set, which are generally intractable for nonlinear problems. Through extensive experiments on benchmark nonlinear problems, as well as on constrained generalized linear models and portfolio allocation problems using both synthetic and real data, we demonstrate superior performance of our method, showing that the method and its asymptotic behavior not only solve constrained stochastic problems efficiently but also provide valid and practical online inference in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.08948v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yihang Gao, Michael K. Ng, Michael W. Mahoney, Sen Na</dc:creator>
    </item>
    <item>
      <title>Natural Geometry of Robust Data Attribution: From Convex Models to Deep Networks</title>
      <link>https://arxiv.org/abs/2512.09103</link>
      <description>arXiv:2512.09103v1 Announce Type: cross 
Abstract: Data attribution methods identify which training examples are responsible for a model's predictions, but their sensitivity to distributional perturbations undermines practical reliability. We present a unified framework for certified robust attribution that extends from convex models to deep networks. For convex settings, we derive Wasserstein-Robust Influence Functions (W-RIF) with provable coverage guarantees. For deep networks, we demonstrate that Euclidean certification is rendered vacuous by spectral amplification -- a mechanism where the inherent ill-conditioning of deep representations inflates Lipschitz bounds by over $10{,}000\times$. This explains why standard TRAK scores, while accurate point estimates, are geometrically fragile: naive Euclidean robustness analysis yields 0\% certification. Our key contribution is the Natural Wasserstein metric, which measures perturbations in the geometry induced by the model's own feature covariance. This eliminates spectral amplification, reducing worst-case sensitivity by $76\times$ and stabilizing attribution estimates. On CIFAR-10 with ResNet-18, Natural W-TRAK certifies 68.7\% of ranking pairs compared to 0\% for Euclidean baselines -- to our knowledge, the first non-vacuous certified bounds for neural network attribution. Furthermore, we prove that the Self-Influence term arising from our analysis equals the Lipschitz constant governing attribution stability, providing theoretical grounding for leverage-based anomaly detection. Empirically, Self-Influence achieves 0.970 AUROC for label noise detection, identifying 94.1\% of corrupted labels by examining just the top 20\% of training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09103v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shihao Li, Jiachen Li, Dongmei Chen</dc:creator>
    </item>
    <item>
      <title>Semantic Trajectory Generation for Goal-Oriented Spacecraft Rendezvous</title>
      <link>https://arxiv.org/abs/2512.09111</link>
      <description>arXiv:2512.09111v2 Announce Type: cross 
Abstract: Reliable real-time trajectory generation is essential for future autonomous spacecraft. While recent progress in nonconvex guidance and control is paving the way for onboard autonomous trajectory optimization, these methods still rely on extensive expert input (e.g., waypoints, constraints, mission timelines, etc.), which limits the operational scalability in real rendezvous missions. This paper introduces SAGES (Semantic Autonomous Guidance Engine for Space), a trajectory-generation framework that translates natural-language commands into spacecraft trajectories that reflect high-level intent while respecting nonconvex constraints. Experiments in two settings -- fault-tolerant proximity operations with continuous-time constraint enforcement and a free-flying robotic platform -- demonstrate that SAGES reliably produces trajectories aligned with human commands, achieving over 90% semantic-behavioral consistency across diverse behavior modes. Ultimately, this work marks an initial step toward language-conditioned, constraint-aware spacecraft trajectory generation, enabling operators to interactively guide both safety and behavior through intuitive natural-language commands with reduced expert burden.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09111v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuji Takubo, Arpit Dwivedi, Sukeerth Ramkumar, Luis A. Pabon, Daniele Gammelli, Marco Pavone, Simone D'Amico</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimization of Laser-Wakefield Acceleration via Spectral Pulse Shaping</title>
      <link>https://arxiv.org/abs/2512.09125</link>
      <description>arXiv:2512.09125v1 Announce Type: cross 
Abstract: In this paper, we investigate the effect of spectral pulse shaping of the laser driver on the performance of channel-guided, laser-plasma accelerators. The study was carried out with the assistance of Bayesian optimization using particle-in-cell simulations. We used a realistic plasma profile based on a novel optical-field-ionized channel technique with ionization injection and low on-axis plasma densities to maximize the energy gain of the electron bunch trailing the laser. Spectral shaping allows us to modify the temporal profile of the laser driver while keeping the laser energy constant, affecting the acceleration and injection processes. Given the complexity and breadth of the parameter space in question, we used numerical optimization to identify high performers. In particular, we found laser profiles with additional spectral content that, when used with optimal plasma channel parameters, result in charge content an order of magnitude higher than the baseline Gaussian case while also increasing the mean energy of the electron bunch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09125v1</guid>
      <category>physics.plasm-ph</category>
      <category>math.OC</category>
      <category>physics.acc-ph</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. Z. Djordjevi\'c, C. Benedetti, A. D. McNaughton, C. B. Schroeder, R. Lehe, H. -E. Tsai, S. C. Wilks, B. A. Reagan, G. J. Williams, J. van Tilborg</dc:creator>
    </item>
    <item>
      <title>Geometric properties of optimizers for the maximum gradient of the torsion function</title>
      <link>https://arxiv.org/abs/2512.09400</link>
      <description>arXiv:2512.09400v1 Announce Type: cross 
Abstract: Consider $J(\Omega):= \|\nabla u_\Omega\|_\infty/\sqrt{|\Omega|} $ and $J_P(\Omega):= \|\nabla u_\Omega\|_\infty/P(\Omega) $, where $\Omega$ is a planar convex domain, $u_\Omega$ is the torsion function, $P(\Omega)$ is the perimeter of $\Omega$ and $|\Omega|$ its area. We prove that there exist planar convex domains that maximize the functionals $J$ and $J_P$, and any maximizer has a $C^1$ boundary that contains a line segment on which $|\nabla u_\Omega|$ attains its maximum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09400v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Burdzy, Ilias Ftouhi, Xuefeng Liu, Phanuel Mariano</dc:creator>
    </item>
    <item>
      <title>Time-Discretized Simulation of Vehicle Platoons for Safety Analysis with Guaranteed Error Bounds</title>
      <link>https://arxiv.org/abs/2512.09416</link>
      <description>arXiv:2512.09416v1 Announce Type: cross 
Abstract: Wireless communication is essential to achieve coordinated control in vehicle platoons. However, packet losses in wireless communication can cause critical safety issues when they occur in conjunction with sudden brakes. In this paper, we propose simulation-based methods that allow the study of such safety issues by determining the absolute minimum distance between vehicles over time for various control parameters that guarantee string stability. For our proposed time-discretized simulations, we provide two methods for selecting different time-step intervals to ensure that the error in distance approximation remains within specified bounds at all times. Through numerical examples we demonstrate that among control parameters that guarantee string stability some perform better than others under simultaneously occurring packet losses and sudden brakes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09416v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhao Chen, Ahmet Cetinkaya</dc:creator>
    </item>
    <item>
      <title>Advancing Mathematical Research via Human-AI Interactive Theorem Proving</title>
      <link>https://arxiv.org/abs/2512.09443</link>
      <description>arXiv:2512.09443v2 Announce Type: cross 
Abstract: We investigate how large language models can be used as research tools in scientific computing while preserving mathematical rigor. We propose a human-in-the-loop workflow for interactive theorem proving and discovery with LLMs. Human experts retain control over problem formulation and admissible assumptions, while the model searches for proofs or contradictions, proposes candidate properties and theorems, and helps construct structures and parameters that satisfy explicit constraints, supported by numerical experiments and simple verification checks. Experts treat these outputs as raw material, further refine them, and organize the results into precise statements and rigorous proofs. We instantiate this workflow in a case study on the connection between manifold optimization and Grover's quantum search algorithm, where the pipeline helps identify invariant subspaces, explore Grover-compatible retractions, and obtain convergence guarantees for the retraction-based gradient method. The framework provides a practical template for integrating large language models into frontier mathematical research, enabling faster exploration of proof space and algorithm design while maintaining transparent reasoning responsibilities. Although illustrated on manifold optimization problems in quantum computing, the principles extend to other core areas of scientific computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09443v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Li, Zhijian Lai, Dong An, Jiang Hu, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>Adaptive Optimal Control for Avatar-Guided Motor Rehabilitation in Virtual Reality</title>
      <link>https://arxiv.org/abs/2512.09667</link>
      <description>arXiv:2512.09667v1 Announce Type: cross 
Abstract: A control-theoretic framework for autonomous avatar-guided rehabilitation in virtual reality, based on interpretable, adaptive motor guidance through optimal control, is presented. The framework faces critical challenges in motor rehabilitation due to accessibility, cost, and continuity of care, with over 50% of patients inability to attend regular clinic sessions. The system enables post-stroke patients to undergo personalized therapy in immersive virtual reality at home, while being monitored by clinicians. The core is a nonlinear, human-in-the-loop control strategy, where the avatar adapts in real time to the patient's performance. Balance between following the patient's movements and guiding them to ideal kinematic profiles based on the Hogan minimum-jerk model is achieved through multi-objective optimal control. A data-driven "ability index" uses smoothness metrics to dynamically adjust control gains according to the patient's progress. The system was validated through simulations and preliminary trials, and shows potential for delivering adaptive, engaging and scalable remote physiotherapy guided by interpretable control-theoretic principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09667v1</guid>
      <category>eess.SY</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesco De Lellis, Maria Lombardi, Egidio De Benedetto, Pasquale Arpaia, Mario di Bernardo</dc:creator>
    </item>
    <item>
      <title>The tangent space to the Wasserstein space: parallel transport and other applications</title>
      <link>https://arxiv.org/abs/2512.09763</link>
      <description>arXiv:2512.09763v1 Announce Type: cross 
Abstract: We propose a new notion of the formal tangent space to the Wasserstein space $\mathcal{P}(X)$ at a given measure. Modulo an integrability condition, we say that this tangent space is made of functions over $X$ which are valued in the probability measures over the tangent bundle to $X$. This generalization of previous concepts of tangent spaces allows us to define appropriate notions of parallel transport, $\mathcal{C}^{1,\alpha}$ regularity over $\mathcal{P}(X)$ and translation of a curve over $\mathcal{P}(X)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09763v1</guid>
      <category>math.AP</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Bertucci (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>Certificates for nonnegativity of multivariate integer polynomials under perturbations</title>
      <link>https://arxiv.org/abs/2512.09808</link>
      <description>arXiv:2512.09808v1 Announce Type: cross 
Abstract: We develop a general and unconditional framework for certifying the global nonnegativity of multivariate integer polynomials; based on rewriting them as sum of squares modulo their gradient ideals. We remove the two structural assumptions typically required by other approaches, namely that the polynomial attains its infimum and zero-dimensionality of the gradient ideal. Our approach combines a denominator-free stereographic transformation with a refined variant of the Hanzon--Jibetean perturbation scheme. The stereographic transformation preserves nonnegativity while making the polynomial coercive, with explicit bounds on the radius of positivity and on the nonzero critical values. Subsequently, we apply carefully constructed explicit perturbations that enforce zero-dimensionality of the gradient ideal without altering nonnegativity, allowing us to invoke recent algorithms to derive algebraic certificates or rational witness points. We present three algorithms implementing our framework and analyze their bit complexity in detail, which is single exponential with respect to the number of variables. A second contribution is a new explicit SOS perturbation scheme, which allows us to perturb any nonnegative polynomial in such a way that it can be written as a sum of squares (SOS). In contrast to Lasserre's classical SOS approximation, which guaranties density but currently does not provide an effective control over the perturbation size, we only derive concrete perturbation bounds ensuring that a nonnegative polynomial enters the SOS cone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09808v1</guid>
      <category>cs.SC</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mat\'ias R Bender (TROPICAL), Kozhasov Khazhgali (UniCA), Tsigaridas Elias (OURAGAN), Zhu Chaoping (OURAGAN)</dc:creator>
    </item>
    <item>
      <title>Optimal Transportation by Orthogonal Coupling Dynamics</title>
      <link>https://arxiv.org/abs/2410.08060</link>
      <description>arXiv:2410.08060v2 Announce Type: replace 
Abstract: Many numerical and learning algorithms rely on the solution of the Monge-Kantorovich problem and Wasserstein distances, which provide appropriate distributional metrics. While the natural approach is to treat the problem as an infinite-dimensional linear programming, such a methodology limits the computational performance due to the polynomial scaling with respect to the sample size along with intensive memory requirements. We propose a novel alternative framework to address the Monge-Kantorovich problem based on a projection type gradient descent scheme. The dynamics builds on the notion of the conditional expectation, where the connection with the opinion dynamics is leveraged to devise efficient numerical schemes. We demonstrate that the resulting dynamics recovers random maps with favourable computational performance. Along with the theoretical insight, the proposed dynamics paves the way for innovative approaches to construct numerical schemes for computing optimal transport maps as well as Wasserstein distances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08060v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Sadr, Peyman Mohajerin Esfahani, Hossein Gorji</dc:creator>
    </item>
    <item>
      <title>Local controllability of a free-boundary problem for a class of one-dimensional degenerate parabolic equations</title>
      <link>https://arxiv.org/abs/2503.11929</link>
      <description>arXiv:2503.11929v3 Announce Type: replace 
Abstract: This paper is devoted to a study of the controllability of a free-boundary problem for a class of one-dimensional degenerate parabolic equations with distributed controls, locally supported in space. We prove that for any $T&gt;0$, if the initial state is sufficiently small, there exists a control that drives the state exactly to rest at time $t = T$. The proof is based on Schauder's fixed point theorem, combined with appropriate estimates for solutions to degenerate parabolic equations and for control functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11929v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lingyang Liu</dc:creator>
    </item>
    <item>
      <title>Inexact Zeroth-Order Nonsmooth and Nonconvex Stochastic Composite Optimization and Applications</title>
      <link>https://arxiv.org/abs/2508.11519</link>
      <description>arXiv:2508.11519v2 Announce Type: replace 
Abstract: In this paper we present an inexact zeroth-order method suitable for the solution nonsmooth and nonconvex stochastic composite optimization problems, in which the objective is split into a real-valued Lipschitz continuous stochastic function and an extended-valued (deterministic) proper, closed, and convex one. The algorithm operates under inexact oracles providing noisy (and biased) stochastic evaluations of the underlying finite-valued part of the objective function. We show that the proposed method converges (non-asymptotically), under very mild assumptions, close to a stationary point of an appropriate surrogate problem which is related (in a precise mathematical sense) to the original one. This, in turn, provides a new notion of approximate stationarity suitable nonsmooth and nonconvex stochastic composite optimization, generalizing conditions used in the available literature.
  In light of the generic oracle properties under which the algorithm operates, we showcase the applicability of the approach in a wide range of problems including large classes of two-stage nonconvex stochastic optimization and nonconvex-nonconcave minimax stochastic optimization instances, without requiring convexity of the lower level problems, or even uniqueness of the associated lower level solution maps. We showcase how the developed theory can be applied in each of these cases under general assumptions, providing algorithmic methodologies that go beyond the current state-of-the-art appearing in each respective literature, enabling the solution of problems that are out of reach of currently available methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11519v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spyridon Pougkakiotis, Dionysis Kalogerias</dc:creator>
    </item>
    <item>
      <title>On Complexity of Model-Based Derivative-Free Methods</title>
      <link>https://arxiv.org/abs/2510.14935</link>
      <description>arXiv:2510.14935v2 Announce Type: replace 
Abstract: In many applications of mathematical optimization, one may wish to optimize an objective function without access to its derivatives. These situations call for derivative-free optimization (DFO) methods. Among the most successful approaches in practice are model-based trust-region methods, such as those pioneered by M.J.D Powell. While relatively complex to implement, these methods are now available in standard scientific computing platforms, including MATLAB and SciPy. However, theoretical analysis of their computational complexity lags behind practice. In particular, it is important to bound the number of function evaluations required to achieve a desired level of accuracy. In this paper we systematically derive complexity bounds for classical model-based trust-region methods and their modern variations. We establish, for the first time, that these methods can have the same worst case complexity than any other known DFO method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14935v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abraar Chaudhry, Katya Scheinberg</dc:creator>
    </item>
    <item>
      <title>A New Perspective on Double-S Curve Motions of Higher Order and Optimal Motion Planning</title>
      <link>https://arxiv.org/abs/2511.12615</link>
      <description>arXiv:2511.12615v3 Announce Type: replace 
Abstract: This paper presents and proves an equation for the time horizon of symmetric trajectories with zero boundary conditions and bounded derivatives of arbitrary order. This equation holds regardless of the number of phases comprising the associated motion. This avoids case distinctions in calculations. Application examples of motions with minimum time, minimum velocity, and minimum acceleration are discussed. Furthermore, an algorithm is derived that reduces the time minimization problem to solving a system of equations. This algorithm avoids nested case distinctions and complex optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12615v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rico Z\"ollner</dc:creator>
    </item>
    <item>
      <title>Data-driven Analysis of First-Order Methods via Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2511.17834</link>
      <description>arXiv:2511.17834v2 Announce Type: replace 
Abstract: We consider the problem of analyzing the probabilistic performance of first-order methods when solving convex optimization problems drawn from an unknown distribution only accessible through samples. By combining performance estimation (PEP) and Wasserstein distributionally robust optimization (DRO), we formulate the analysis as a tractable semidefinite program. Our approach unifies worst-case and average-case analyses by incorporating data-driven information from the observed convergence of first-order methods on a limited number of problem instances. This yields probabilistic, data-driven performance guarantees in terms of the expectation or conditional value-at-risk of the selected performance metric. Experiments on smooth convex minimization, logistics regression, and Lasso show that our method significantly reduces the conservatism of classical worst-case bounds and narrows the gap between theoretical and empirical performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.17834v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jisun Park, Vinit Ranjan, Bartolomeo Stellato</dc:creator>
    </item>
    <item>
      <title>New Results on the Polyak Stepsize: Tight Convergence Analysis and Universal Function Classes</title>
      <link>https://arxiv.org/abs/2512.06231</link>
      <description>arXiv:2512.06231v2 Announce Type: replace 
Abstract: In this paper, we revisit a classical adaptive stepsize strategy for gradient descent: the Polyak stepsize (PolyakGD), originally proposed in Polyak (1969). We study the convergence behavior of PolyakGD from two perspectives: tight worst-case analysis and universality across function classes. As our first main result, we establish the tightness of the known convergence rates of PolyakGD by explicitly constructing worst-case functions. In particular, we show that the $O((1-\frac{1}{\kappa})^K)$ rate for smooth strongly convex functions and the $O(1/K)$ rate for smooth convex functions are both tight. Moreover, we theoretically show that PolyakGD automatically exploits floating-point errors to escape the worst-case behavior. Our second main result provides new convergence guarantees for PolyakGD under both H\"older smoothness and H\"older growth conditions. These findings show that the Polyak stepsize is universal, automatically adapting to various function classes without requiring prior knowledge of problem parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06231v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang He, Wenzhi Gao, Bo Jiang, Madeleine Udell, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>A Minimalist Optimizer Design for LLM Pretraining</title>
      <link>https://arxiv.org/abs/2506.16659</link>
      <description>arXiv:2506.16659v2 Announce Type: replace-cross 
Abstract: Training large language models (LLMs) typically relies on adaptive optimizers such as Adam, which introduce extra operations and require significant more memory to maintain first- and second-order moments than SGD. While recent works such as GaLore, Fira and APOLLO have proposed state-compressed variants to reduce memory consumption, a fundamental question remains: What are the minimum modifications to plain SGD needed to match state-of-the-art pretraining performance? We systematically investigate this question using a bottom-up approach, and identify two simple yet highly (memory- and compute-) efficient techniques: (1) column-wise gradient normalization (normalizing the gradient along the output dimension), which boosts SGD performance without momentum; and (2) applying first-order momentum only to the output layer, where gradient variance is highest. Combining these two techniques lead to SCALE (Stochastic Column-normAlized Last-layer momEntum), a simple optimizer for memory efficient pretraining. Across multiple LLaMA models (60M-1B), SCALE matches or exceeds the performance of Adam while using only 35-45% of the total memory. It also consistently outperforms memory-efficient optimizers such as GaLore, Fira and APOLLO, making it a strong candidate for large-scale pretraining under memory constraints. For LLaMA 7B model, SCALE outperforms the state-of-the-art memory-efficient methods APOLLO and Muon, in terms of both perplexity and memory consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16659v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Athanasios Glentis, Jiaxiang Li, Andi Han, Mingyi Hong</dc:creator>
    </item>
    <item>
      <title>A Continuous Energy Ising Machine Leveraging Difference-of-Convex Programming</title>
      <link>https://arxiv.org/abs/2509.01928</link>
      <description>arXiv:2509.01928v2 Announce Type: replace-cross 
Abstract: Many combinatorial optimization problems can be reformulated as finding the ground state of the Ising model. Existing Ising solvers are mostly inspired by simulated annealing. Although annealing techniques offer scalability, they lack convergence guarantees and are sensitive to the cooling schedule. We propose solving the Ising problem by relaxing the binary spins to continuous variables and introducing an attraction potential that steers the solution toward binary spin configurations. A key property of this potential is that its combination with the Ising energy produces a Hamiltonian that can be written as a difference of convex polynomials. This enables us to design efficient iterative algorithms that require a single matrix-vector multiplication per iteration and provide convergence guarantees. We implement our Ising solver on a wide range of GPU platforms, from edge devices to high-performance computing clusters, and demonstrate that it consistently outperforms existing solvers across problem sizes ranging from small ($10^3$ spins) to ultra-large ($10^8$ spins).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.01928v2</guid>
      <category>cs.DC</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Debraj Banerjee, Santanu Mahapatra, Kunal Narayan Chaudhury</dc:creator>
    </item>
    <item>
      <title>Anderson-type acceleration method for Deep Neural Network optimization</title>
      <link>https://arxiv.org/abs/2510.20254</link>
      <description>arXiv:2510.20254v2 Announce Type: replace-cross 
Abstract: In this paper we consider the neural network optimization. We develop Anderson-type acceleration method for the stochastic gradient decent method and it improves the network permanence very much. We demonstrate the applicability of the method for Deep Neural Network (DNN) and Convolution Neural Network (CNN).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.20254v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kazufumi Ito, Tiancheng Xue</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Kalman Filter</title>
      <link>https://arxiv.org/abs/2512.06286</link>
      <description>arXiv:2512.06286v2 Announce Type: replace-cross 
Abstract: In this work, we propose a noise-centric formulation of the distributionally robust Kalman filter (DRKF) for discrete-time linear stochastic systems with uncertain noise statistics. By placing Wasserstein ambiguity sets directly on the process and measurement noise distributions, the proposed DRKF preserves the analytical structure of the classical Kalman filter while providing a priori spectral bounds on all feasible covariances. In the time-invariant setting, we derive a steady-state DRKF from a single stationary semidefinite program, yielding a constant-gain estimator with the same per-step computational complexity as the standard Kalman filter. We establish conditions guaranteeing the existence, uniqueness, and convergence of this steady-state solution, and we prove its asymptotic minimax optimality with respect to the worst-case mean-square error. Numerical experiments validate the theory and demonstrate that the proposed DRKF improves estimation accuracy under unknown or uncertain noise models while offering computational advantages over existing robust and distributionally robust filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06286v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 11 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Minhyuk Jang, Astghik Hakobyan, Insoon Yang</dc:creator>
    </item>
  </channel>
</rss>
