<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Jan 2026 05:01:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Structure-Preserving Numerical Scheme for Optimal Control and Design of Mixing in Incompressible Flows</title>
      <link>https://arxiv.org/abs/2601.06294</link>
      <description>arXiv:2601.06294v1 Announce Type: new 
Abstract: We develop a structure-preserving computational framework for optimal mixing control in incompressible flows. Our approach exactly conserves the continuous system's key invariants (mass and $L^2$-energy), while also maintaining discrete state-adjoint duality at every time step. These properties are achieved by integrating a centered finite-volume discretization in space with a time-symmetric Crank-Nicolson integrator for both the forward advection and its adjoint, all inside a gradient-based optimization loop. The result is a numerical solver that is faithful to the continuous optimality conditions and efficiently computes mixing-enhancing controls. In our numerical tests, the optimized time-dependent stirring produces a nearly exponential decay of a chosen mix-norm, achieving orders-of-magnitude faster mixing than any single steady flow. To our knowledge, this work provides the first evidence that enforcing physical structure at the discrete level can lead to both exact conservation and highly effective mixing outcomes in optimal flow design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06294v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weiwei Hu, Ziqian Li, Yubiao Zhang, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Supervised and Unsupervised Neural Network Solver for First Order Hyperbolic Nonlinear PDEs</title>
      <link>https://arxiv.org/abs/2601.06388</link>
      <description>arXiv:2601.06388v1 Announce Type: new 
Abstract: We present a neural network-based method for learning scalar hyperbolic conservation laws. Our method replaces the traditional numerical flux in finite volume schemes with a trainable neural network while preserving the conservative structure of the scheme. The model can be trained both in a supervised setting with efficiently generated synthetic data or in an unsupervised manner, leveraging the weak formulation of the partial differential equation. We provide theoretical results that our model can perform arbitrarily well, and provide associated upper bounds on neural network size. Extensive experiments demonstrate that our method often outperforms efficient schemes such as Godunov's scheme, WENO, and Discontinuous Galerkin for comparable computational budgets. Finally, we demonstrate the effectiveness of our method on a traffic prediction task, leveraging field experimental highway data from the Berkeley DeepDrive drone dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06388v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zakaria Baba, Alexandre M. Bayen, Alexi Canesse, Maria Laura Delle Monache, Martin Drieux, Zhe Fu, Nathan Lichtl\'e, Zihe Liu, Hossein Nick Zinat Matin, Benedetto Piccoli</dc:creator>
    </item>
    <item>
      <title>An NPDo Approach for Principal Joint Block Diagonalization</title>
      <link>https://arxiv.org/abs/2601.06410</link>
      <description>arXiv:2601.06410v1 Announce Type: new 
Abstract: Matrix joint block-diagonalization (JBD) frequently arises from diverse applications such as independent component analysis, blind source separation, and common principal component analysis (CPCA), among others. Particularly, CPCA aims at joint diagonalization, i.e., each block size being $1$-by-$1$. This paper is concerned with {\em principal joint block-diagonalization\/} (\pjbd), which aim to achieve two goals: 1)~partial joint block-diagonalization, and 2)~identification of dominant common block-diagonal parts for all involved matrices. This is in contrast to most existing methods, especially the popular ones based on Givens rotation, which focus on full joint diagonalization and quickly become impractical for matrices of even moderate size ($300$-by-$300$ or larger). An NPDo approach is proposed and it is built on a {\em nonlinear polar decomposition with orthogonal polar factor dependency} that characterizes the solutions of the optimization problem designed to achieve \pjbd, and it is shown the associated SCF iteration is globally convergent to a stationary point while the objective function increases monotonically during the iterative process. Numerical experiments are presented to illustrate the effectiveness of the NPDo approach and its superiority to Givens rotation-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06410v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ren-Cang Li, Ding Lu, Li Wang, Lei-Hong Zhang</dc:creator>
    </item>
    <item>
      <title>On traces of the derivatives of the $L^2$-projection error</title>
      <link>https://arxiv.org/abs/2601.06625</link>
      <description>arXiv:2601.06625v1 Announce Type: new 
Abstract: We provide derivative estimates for the $L^2$ projection of an $H^{k}$ function onto the space of polynomials of degree $\leq p$. The bounds are explicit in the order of differentiation and the polynomial degree $p$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06625v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Torsten Lin{\ss}, Christos Xenophontos</dc:creator>
    </item>
    <item>
      <title>The optimal error analysis of nonuniform L1 method for the variable-exponent subdiffusion model</title>
      <link>https://arxiv.org/abs/2601.06773</link>
      <description>arXiv:2601.06773v1 Announce Type: new 
Abstract: This work investigates the optimal error estimate of the fully discrete scheme for the variable-exponent subdiffusion model under the nonuniform temporal mesh. We apply the perturbation method to reformulate the original model into its equivalent form, and apply the L1 scheme as well as the interpolation quadrature rule to discretize the Caputo derivative term and the convolution term in the reformulated model, respectively. We then prove the temporal convergence rates $O(N^{-\min\{2-\alpha(0), r\alpha(0)\}})$ under the nonuniform mesh, which improves the existing convergence results in [Zheng, CSIAM T. Appl. Math. 2025] for $r\geq \frac{2-\alpha(0)}{\alpha(0)}$. Numerical results are presented to substantiate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06773v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenlin Qiu, Kexin Li, Yiqun Li, Hao Zhang</dc:creator>
    </item>
    <item>
      <title>Analysis and Efficient Sylvester-Based Implementation of a Dimension-Split ETD2RK Scheme for Multidimensional Reaction-Diffusion Equations</title>
      <link>https://arxiv.org/abs/2601.06849</link>
      <description>arXiv:2601.06849v1 Announce Type: new 
Abstract: We propose and analyze a second-order, dimension-split exponential time differencing Runge--Kutta scheme (ETD2RK-DS) for multidimensional reaction--diffusion equations in two and three spatial dimensions. Under mild assumptions on the nonlinear source term, we establish uniform stability bounds and prove second-order temporal convergence for the underlying dimension-split scheme.
  To enable efficient implementation, we employ Pad\'e approximations of the matrix exponential, converting each required matrix-exponential--vector product into the solution of a shifted linear system. A convergence analysis of the resulting Pad\'e-based ETD2RK-DS formulation is provided. We derive explicit and reproducible tensor-slicing and reshaping algorithms that realize the dimension-splitting strategy, decomposing multidimensional systems into collections of independent one-dimensional problems. This leads to a reduction of the dominant per-time-step computational cost from $\mathcal{O}(m^3)$ to $\mathcal{O}(m^2)$ in two dimensions and from $\mathcal{O}(m^5)$ to $\mathcal{O}(m^3)$ in three dimensions when compared with banded LU solvers for the unsplit problem, where $m$ denotes the number of grid points per spatial direction.
  Furthermore, we develop a Sylvester-equation reformulation of the resulting one-dimensional systems, enabling a highly efficient spectral implementation based on reusable eigendecompositions, matrix--vector multiplications, and Hadamard divisions. Numerical experiments in two and three dimensions, including a coupled FitzHugh--Nagumo system, confirm the second-order temporal accuracy, stability of the underlying scheme, and scalability of the proposed ETD2RK-DS framework, as well as the substantial computational advantages of the Sylvester-based implementation over classical LU-based solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06849v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim O. Sarumi</dc:creator>
    </item>
    <item>
      <title>The Ill-Posed Foundations of Physics-Informed Neural Networks and Their Finite-Difference Variants</title>
      <link>https://arxiv.org/abs/2601.07017</link>
      <description>arXiv:2601.07017v1 Announce Type: new 
Abstract: Physics-informed neural networks based on automatic differentiation (AD-PINNs) and their finite-difference counterparts (FD-PINNs) are widely used for solving partial differential equations (PDEs), yet their analytical properties remain poorly understood. This work provides a unified mathematical foundation for both formulations. Under mild regularity assumptions on the activation function and for sufficiently wide neural networks of depth at least two, we prove that both the AD- and FD-PINN optimization problems are ill-posed: whenever a minimizer exists, there are in fact infinitely many, and uniqueness fails regardless of the choice of collocation points or finite-difference stencil. Nevertheless, we establish two structural properties. First, whenever the underlying PDE or its finite-difference discretization admits a solution, the corresponding AD-PINN or FD-PINN loss also admits a minimizer, realizable by a neural network of finite width. Second, FD-PINNs are tightly coupled to the underlying finite-difference scheme: every FD-PINN minimizer agrees with a finite-difference minimizer on the grid, and in regimes where the discrete PDE solution is unique, all zero-loss FD-PINN minimizers coincide with the discrete PDE solution on the stencil. Numerical experiments illustrate these theoretical insights: FD-PINNs remain stable in representative forward and inverse problems, including settings where AD-PINNs may fail to converge. We also include an inverse problem with noisy data, demonstrating that FD-PINNs retain robustness in this setting as well. Taken together, our results clarify the analytical limitations of AD-PINNs and explain the structural reasons for the more stable behavior observed in FD-PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07017v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Andreas Langer</dc:creator>
    </item>
    <item>
      <title>A Relaxed Direct-insertion Downscaling Method For Discrete-in-time Data Assimilation</title>
      <link>https://arxiv.org/abs/2601.07025</link>
      <description>arXiv:2601.07025v1 Announce Type: new 
Abstract: This paper improves the spectrally-filtered direct-insertion downscaling method for discrete-in-time data assimilation by introducing a relaxation parameter that overcomes a constraint on the observation frequency. Numerical simulations demonstrate that taking the relaxation parameter proportional to the time between observations allows one to vary the observation frequency over a wide range while maintaining convergence of the approximating solution to the reference solution. Under the same assumptions we analytically prove that taking the observation frequency to infinity results in the continuous-in-time nudging method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07025v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emine Celik, Eric Olson</dc:creator>
    </item>
    <item>
      <title>An efficient hyper reduced-order model for segregated solvers for geometrical parametrization problems</title>
      <link>https://arxiv.org/abs/2601.07082</link>
      <description>arXiv:2601.07082v1 Announce Type: new 
Abstract: We propose an efficient hyper-reduced order model (HROM) designed for segregated finite-volume solvers in geometrically parametrized problems. The method follows a discretize-then-project strategy: the full-order operators are first assembled using finite volume or finite element discretizations and then projected onto low-dimensional spaces using a small set of spatial sampling points, selected through hyper-reduction techniques such as DEIM. This approach removes the dependence of the online computational cost on the full mesh size. The method is assessed on three benchmark problems: a linear transport equation, a nonlinear Burgers equation, and the incompressible Navier--Stokes equations. The results show that the hyper-reduced models closely match full-order solutions while achieving substantial reductions in computational time. Since only a sparse subset of mesh cells is evaluated during the online phase, the method is naturally parallelizable and scalable to very large meshes. These findings demonstrate that hyper-reduction can be effectively combined with segregated solvers and geometric parametrization to enable fast and accurate CFD simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07082v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Valentin Nkana Ngan, Giovanni Stabile, Andrea Mola, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>The MAC scheme for linear elasticity in displacement-stress formulation on non-uniform staggered grids</title>
      <link>https://arxiv.org/abs/2601.07174</link>
      <description>arXiv:2601.07174v1 Announce Type: new 
Abstract: A marker-and-cell finite difference method is developed for solving the two dimensional and three dimensional linear elasticity in the displacement-stress formulation on staggered grids. The method employs a staggered grid arrangement, where the displacement components are approximated on the midpoints of cell edges, the normal stresses are defined at the cell centers, and the shear stresses are defined at the grid points. This structure ensures local conservation properties and avoids spurious oscillations in stress approximation. A rigorous mathematical analysis is presented, establishing the stability of the scheme and proving the second-order L2-error super-convergence for both displacement and stress. The proposed method is locking-free with respect to the Lame constant, making it suitable for both compressible and nearly incompressible elastic materials. Numerical experiments demonstrate the efficiency and robustness of the finite difference scheme, and the computed results show excellent agreement with the theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07174v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongxing Rui, Weijie Wang</dc:creator>
    </item>
    <item>
      <title>Parametric Probabilistic Manifold Decomposition for Nonlinear Model Reduction</title>
      <link>https://arxiv.org/abs/2601.07278</link>
      <description>arXiv:2601.07278v1 Announce Type: new 
Abstract: Probabilistic Manifold Decomposition (PMD)\cite{doi:10.1137/25M1738863}, developed in our earlier work, provides a nonlinear model reduction by embedding high-dimensional dynamics onto low-dimensional probabilistic manifolds. The PMD has demonstrated strong performance for time-dependent systems. However, its formulation is for temporal dynamics and does not directly accommodate parametric variability, which limits its applicability to tasks such as design optimization, control, and uncertainty quantification. In order to address the limitations, a \emph{Parametric Probabilistic Manifold Decomposition} (PPMD) is presented to deal with parametric problems. The central advantage of PPMD is its ability to construct continuous, high-fidelity parametric surrogates while retaining the transparency and non-intrusive workflow of PMD. By integrating probabilistic-manifold embeddings with parameter-aware latent learning, PPMD enables smooth predictions across unseen parameter values (such as different boundary or initial conditions). To validate the proposed method, a comprehensive convergence analysis is established for PPMD, covering the approximation of the linear principal subspace, the geometric recovery of the nonlinear solution manifold, and the statistical consistency of the kernel ridge regression used for latent learning. The framework is then numerically demonstrated on two classic flow configurations: flow past a cylinder and backward-facing step flow. Results confirm that PPMD achieves superior accuracy and generalization beyond the training parameter range compared to the conventional proper orthogonal decomposition with Gaussian process regression (POD+GPR) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07278v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaming Guo, Dunhui Xiao</dc:creator>
    </item>
    <item>
      <title>TriCG with deflated restarting for symmetric quasi-definite linear systems</title>
      <link>https://arxiv.org/abs/2601.07455</link>
      <description>arXiv:2601.07455v1 Announce Type: new 
Abstract: TriCG is a short-recurrence iterative method recently introduced by Montoison and Orban [SIAM J. Sci. Comput., 43 (2021), pp. A2502--A2525] for solving symmetric quasi-definite (SQD) linear systems. TriCG takes advantage of the inherent block structure of SQD linear systems and performs substantially better than SYMMLQ. However, numerical experiments have revealed that the convergence of TriCG can be notably slow when the off-diagonal block contains a substantial number of large elliptic singular values. To address this limitation, we introduce a deflation strategy tailored for TriCG to improve its convergence behavior. Specifically, we develop a generalized Saunders--Simon--Yip process with deflated restarting to construct the deflation subspaces. Building upon this process, we propose a novel method termed TriCG with deflated restarting. The deflation subspaces can also be utilized to solve SQD linear systems with multiple right-hand sides. Numerical experiments are provided to illustrate the superior performance of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07455v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Du, Jia-Jun Fan</dc:creator>
    </item>
    <item>
      <title>Derivative-free discrete gradient methods</title>
      <link>https://arxiv.org/abs/2601.07479</link>
      <description>arXiv:2601.07479v1 Announce Type: new 
Abstract: Discrete gradient methods are a class of numerical integrators producing solutions with exact preservation of first integrals of ordinary differential equations. In this paper, we apply order theory combined with the symmetrized Itoh--Abe discrete gradient and finite differences to construct an integral-preserving fourth-order method that is derivative-free. The numerical scheme is implicit and a convergence result for Newton's iterations is provided, taking into account how the error due to the finite difference approximations affects the convergence rate. Numerical experiments verify the order and show that the derivative-free method is significantly faster than obtaining derivatives by automatic differentiation. Finally, an experiment using topographic data as the potential function of a Hamiltonian oscillator demonstrates how this method allows the simulation of discrete-time dynamics from a Hamiltonian that is a combination of data and analytical expressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07479v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3934/jcd.2024004</arxiv:DOI>
      <arxiv:journal_reference>Myhr, H{\aa}kon Noren, and S{\o}lve Eidnes. "Derivative-free discrete gradient methods." Journal of Computational Dynamics 11.3 (2024): 256-273</arxiv:journal_reference>
      <dc:creator>H{\aa}kon Noren Myhr, S{\o}lve Eidnes</dc:creator>
    </item>
    <item>
      <title>On spectral properties and fast initial convergence of the Kaczmarz method</title>
      <link>https://arxiv.org/abs/2601.07498</link>
      <description>arXiv:2601.07498v1 Announce Type: new 
Abstract: The Kaczmarz method is successfully used for solving discretizations of linear inverse problems, especially in computed tomography where it is known as ART. Practitioners often observe and appreciate its fast convergence in the first few iterations, leading to the same favorable semi-convergence that we observe for simultaneous iterative reconstruction methods. While the latter methods have symmetric and positive definite iteration operators that facilitate their analysis, the operator in Kaczmarz's method is nonsymmetric and it has been an open question so far to understand this fast initial convergence. We perform a spectral analysis of Kaczmarz's method that gives new insight into its (often fast) initial behavior. We also carry out a statistical analysis of how the data noise enters the iteration vectors, which sheds new light on the semi-convergence. Our results are illustrated with several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07498v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Per Christian Hansen, Michiel E. Hochstenbach</dc:creator>
    </item>
    <item>
      <title>Multiword matrix multiplication over large finite fields in floating-point arithmetic</title>
      <link>https://arxiv.org/abs/2601.07508</link>
      <description>arXiv:2601.07508v1 Announce Type: new 
Abstract: This article is concerned with the efficient computation of modular matrix multiplication C=AB mod p, a key kernel in computer algebra. We focus on floating-point arithmetic, which allows for using efficient matrix multiplication libraries. However, the existing approach is limited to primes p with bitsize at most half the mantissa size (e.g., 26 bits with double precision arithmetic), and becomes quite inefficient when p approaches this limit. We present a new approach that overcomes this limitation and can efficiently handle primes with larger bitsizes. The key idea is to use multiword decompositions, which represent A and B as scaled sums of u and v matrices (words) with smaller coefficients. We provide a rigorous analysis that proves the correctness of this approach for suitably chosen scaling parameters. Our analysis determines the maximum bitsize of p that can be handled for a given number of words; in particular, we show that decomposing in two words each input suffices to handle bitsizes almost equal to the full mantissa size (e.g., the 26 bits limit is raised to 52 bits in double precision arithmetic). Moreover, we show that (1,v) decompositions with v&gt;1 are also of interest to handle intermediate bitsizes. We perform an extensive experimental analysis for various matrix shapes and prime bitsizes. Our performance benchmarks on both CPU and GPU architectures confirm the efficiency of the proposed approach, which can outperform the existing single word approach for bitsizes as low as 23, and can handle bitsizes as high as 52 while retaining high performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07508v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J\'er\'emy Berthomieu (PolSys), Stef Graillat (PEQUAN), Dimitri Lesnoff (PEQUAN, PolSys), Theo Mary (PEQUAN)</dc:creator>
    </item>
    <item>
      <title>A higher order polytopal method for contact mechanics with Tresca friction</title>
      <link>https://arxiv.org/abs/2601.07586</link>
      <description>arXiv:2601.07586v1 Announce Type: new 
Abstract: In this work, we design and analyze a Discrete de Rham (DDR) scheme for a contact mechanics problem involving fractures along which a model of Tresca friction is considered. Our approach is based on a mixed formulation involving a displacement field and a Lagrange multiplier, enforcing the contact conditions, representing tractions at fractures. The approximation space for the displacement is made of vectors values attached to each vertex, edge, face, and element, while the Lagrange multiplier space is approximated by piecewise constant vectors on each fracture face. The displacement degrees of freedom allow reconstruct piecewise quadratic approximations of this field. We prove a discrete Korn inequality that account for the fractures, as well as an inf-sup condition (in a non-standard $H^{-1/2}$-norm) between the discrete Lagrange multiplier space and the discrete displacement space. We provide an in-depth error analysis of the scheme and show that, contrary to usual low-order nodal-based schemes, our method is robust in the quasi-incompressible limit for the primal variable~(displacement). An extensive set of numerical experiments confirms the theoretical analysis and demonstrate the practical accuracy and robustness of the scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07586v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jerome Droniou, Raman Kumar, Roland Masson, Ritesh Singla</dc:creator>
    </item>
    <item>
      <title>TMATDG: applying TDG methods to multiple scattering via T-matrix approximation</title>
      <link>https://arxiv.org/abs/2601.07704</link>
      <description>arXiv:2601.07704v1 Announce Type: new 
Abstract: We present a MATLAB package for the solution of multiple scattering problems, coupling Trefftz Discontinuos Galerkin methods for Helmholtz scattering with the T-matrix method. We rely on the TMATROM package to numerically approximate the T-matrices and deal with multiple scattering problem, providing a framework to handle scattering by polygonal obstacles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07704v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Armando Maria Monforte</dc:creator>
    </item>
    <item>
      <title>Explicit complex time integrators for stiff problems</title>
      <link>https://arxiv.org/abs/2601.07730</link>
      <description>arXiv:2601.07730v1 Announce Type: new 
Abstract: Most numerical methods for time integration use real-valued time steps. Complex time steps, however, can provide an additional degree of freedom, as we can select the magnitude of the time step in both the real and imaginary directions. We show that specific paths in the complex time plane lead to expanded stability regions, providing clear computational advantages for complex-valued systems. In particular, we highlight the Schr\"odinger equation, for which complex time integrators can be uniquely optimal. Furthermore, we demonstrate that these benefits extend to certain classes of real-valued stiff systems by coupling complex time steps with the Projective Integration method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07730v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.CV</category>
      <category>math.MP</category>
      <category>quant-ph</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jithin D. George, Julian Koellermeier, Samuel Y. Jung, Niall M. Mangan</dc:creator>
    </item>
    <item>
      <title>On the Compact Discontinuous Galerkin method for polytopal meshes</title>
      <link>https://arxiv.org/abs/2601.07757</link>
      <description>arXiv:2601.07757v1 Announce Type: new 
Abstract: The Compact Discontinuous Galerkin method was introduced by Peraire and Persson in (SIAM J. Sci. Comput., 30, 1806--1824, 2008). In this work, we present the stability and convergence analysis for the $hp$-version of this method applied to elliptic problems on polytopal meshes. Moreover, we introduce fast and practical algorithms that allow the CDG, LDG, and BR2 methods to be implemented within a unified framework. Our numerical experiments show that the CDG method yields a compact stencil for the stiffness matrix, with faster assembly and solving times compared to the LDG and BR2 methods. We numerically study how coercivity depends on the method parameters for various mesh types, with particular focus on the number of facets per mesh element. Finally, we demonstrate the importance of choosing the correct directions for the numerical fluxes when using variable polynomial degrees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07757v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mattia Corti, Sergio G\'omez</dc:creator>
    </item>
    <item>
      <title>Necessary and Sufficient Conditions for the Existence of an LU Factorization for General Rank Deficient Matrices</title>
      <link>https://arxiv.org/abs/2601.07791</link>
      <description>arXiv:2601.07791v1 Announce Type: new 
Abstract: We establish necessary and sufficient conditions for the existence of an LU factorization $A=LU$ for an arbitrary square matrix $A$, including singular and rank-deficient cases, without the use of row or column permutations. We prove that such a factorization exists if and only if the nullity of every leading principal submatrix is bounded by the sum of the nullities of the corresponding leading column and row blocks. While building upon the work of Okunev and Johnson, we present simpler, constructive proofs. Furthermore, we extend these results to characterize rank-revealing factorizations, providing explicit sparsity bounds for the factors $L$ and $U$. Finally, we derive analogous necessary and sufficient conditions for the existence of factorizations constrained to have unit lower or unit upper triangular factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07791v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5281/zenodo.18224816</arxiv:DOI>
      <dc:creator>Eric Darve</dc:creator>
    </item>
    <item>
      <title>Certificate for Orthogonal Equivalence of Real Polynomials by Polynomial-Weighted Principal Component Analysis</title>
      <link>https://arxiv.org/abs/2601.06148</link>
      <description>arXiv:2601.06148v1 Announce Type: cross 
Abstract: Suppose that $f(x) \in \mathbb{R}[x_1,\dots, x_n]$ and $g(x) \in \mathbb{R}[x_1,\dots, x_n]$ are two real polynomials of degree $d$ in $n$ variables. If the polynomials $f$ and $g$ are the same up to orthogonal symmetry a natural question is then what element of the orthogonal group induces the orthogonal symmetry; i.e. to find the element $R\in O(n)$ such that $f(Rx)=g(x)$. One may directly solve this problem by constructing a nonlinear system of equations induced by the relation $f(Rx)=g(x)$ along with the identities of the orthogonal group however this approach becomes quite computationally expensive for larger values of $n$ and $d$. To give an alternative and significantly more scalable solution to this problem, we introduce the concept of Polynomial-Weighted Principal Component Analysis (PW-PCA). We in particular show how PW-PCA can be effectively computed and how these techniques can be used to obtain a certificate of orthogonal equivalence, that is we find the $R\in O(n)$ such that $f(Rx)=g(x)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06148v1</guid>
      <category>math.RA</category>
      <category>cs.NA</category>
      <category>math.AC</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Helmer, David Hong, Hoon Hong</dc:creator>
    </item>
    <item>
      <title>A First Course in Sparse Optimization</title>
      <link>https://arxiv.org/abs/2601.06173</link>
      <description>arXiv:2601.06173v1 Announce Type: cross 
Abstract: This article aims to provide a comprehensive overview of sparse optimization, with a focus on both sparse signal recovery and sparse regularization techniques. We will begin by exploring the foundations of sparse optimization, delving into the mathematical tools and models that underpin sparse signal recovery and LASSO. We will then discuss key algorithms for both sparse recovery (e.g., basis pursuit, matching pursuit) and sparse regularization (e.g., LASSO, elastic net), along with their applications in real-world problems. Throughout the text, we balance intuitive explanations with rigorous mathematical formulations to provide a comprehensive resource for both newcomers and experts in the field. Our aim is twofold: to provide a self-contained entry point for students and researchers new to the field, and to offer a rigorous reference for practitioners seeking to apply sparse optimization in science and engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06173v1</guid>
      <category>math.HO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Lu</dc:creator>
    </item>
    <item>
      <title>A Linear Combination of Unitaries Decomposition for the Laplace Operator</title>
      <link>https://arxiv.org/abs/2601.06370</link>
      <description>arXiv:2601.06370v1 Announce Type: cross 
Abstract: We provide novel linear combination of unitaries decompositions for a class of discrete elliptic differential operators. Specifically, Poisson problems augmented with periodic, Dirichlet, Neumann, Robin, and mixed boundary conditions are considered on the unit interval and on higher-dimensional rectangular domains. The number of unitary terms required for our decomposition is independent of the number of grid points used in the discretization and scales linearly with the spatial dimension. Explicit circuit constructions for each unitary are given and their complexities analyzed. The worst case depth and elementary gate cost of any such circuit is shown to scale at most logarithmically with respect to number of grid points in the underlying discrete system. We also investigate the cost of using our method within the Variational Quantum Linear Solver algorithm and show favorable scaling. Finally, we extend the proposed decomposition technique to treat problems that include first-order derivative terms with variable coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06370v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Hogancamp, Reuben Demirdjian, Daniel Gunlycke</dc:creator>
    </item>
    <item>
      <title>Inference-Time Alignment for Diffusion Models via Doob's Matching</title>
      <link>https://arxiv.org/abs/2601.06514</link>
      <description>arXiv:2601.06514v1 Announce Type: cross 
Abstract: Inference-time alignment for diffusion models aims to adapt a pre-trained diffusion model toward a target distribution without retraining the base score network, thereby preserving the generative capacity of the base model while enforcing desired properties at the inference time. A central mechanism for achieving such alignment is guidance, which modifies the sampling dynamics through an additional drift term. In this work, we introduce Doob's matching, a novel framework for guidance estimation grounded in Doob's $h$-transform. Our approach formulates guidance as the gradient of logarithm of an underlying Doob's $h$-function and employs gradient-penalized regression to simultaneously estimate both the $h$-function and its gradient, resulting in a consistent estimator of the guidance. Theoretically, we establish non-asymptotic convergence rates for the estimated guidance. Moreover, we analyze the resulting controllable diffusion processes and prove non-asymptotic convergence guarantees for the generated distributions in the 2-Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06514v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyuan Chang, Chenguang Duan, Yuling Jiao, Yi Xu, Jerry Zhijian Yang</dc:creator>
    </item>
    <item>
      <title>Automated dimensional analysis for PDEs</title>
      <link>https://arxiv.org/abs/2601.06535</link>
      <description>arXiv:2601.06535v1 Announce Type: cross 
Abstract: Physical units are fundamental to scientific computing. However, many finite element frameworks lack built-in support for dimensional analysis. In this work, we present a systematic framework for integrating physical units into the Unified Form Language (UFL). We implement a symbolic Quantity class to track units within variational forms. The implementation exploits the abelian group structure of physical dimensions. We represent them as vectors in $\mathbb{Q}^n$ to simplify operations and improve performance. A graph-based visitor pattern traverses the expression tree to automate consistency checks and factorization. We demonstrate that this automated nondimensionalization functions as the simplest form of Full Operator Preconditioning. It acts as a physics-aware diagonal preconditioner that equilibrates linear systems prior to assembly. Numerical experiments with the Navier--Stokes equations show that this improves the condition number of the saddle-point matrix. Analysis of Neo-Hooke hyperelasticity highlights the detection of floating-point cancellation errors in small deformation regimes. Finally, the Poisson--Nernst--Planck system example illustrates the handling of coupled multiphysics problems with derived scaling parameters. Although the implementation targets the FEniCSx framework, the concepts are general and easily adaptable to other finite element libraries using UFL, such as Firedrake or DUNE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06535v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michal Habera, Andreas Zilian</dc:creator>
    </item>
    <item>
      <title>Constrained Density Estimation via Optimal Transport</title>
      <link>https://arxiv.org/abs/2601.06830</link>
      <description>arXiv:2601.06830v1 Announce Type: cross 
Abstract: A novel framework for density estimation under expectation constraints is proposed. The framework minimizes the Wasserstein distance between the estimated density and a prior, subject to the constraints that the expected value of a set of functions adopts or exceeds given values. The framework is generalized to include regularization inequalities to mitigate the artifacts in the target measure. An annealing-like algorithm is developed to address non-smooth constraints, with its effectiveness demonstrated through both synthetic and proof-of-concept real world examples in finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06830v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinan Hu, Estaban Tabak</dc:creator>
    </item>
    <item>
      <title>Surface Dean--Kawasaki equations</title>
      <link>https://arxiv.org/abs/2601.06863</link>
      <description>arXiv:2601.06863v1 Announce Type: cross 
Abstract: We consider stochastic particle dynamics on hypersurfaces represented in Monge gauge parametrization. Starting from the underlying Langevin system, we derive the surface Dean-Kawasaki (DK) equation and formulate it in the martingale sense. The resulting SPDE explicitly reflects the geometry of the hypersurface through the induced metric and its differential operators. Our framework accommodates both pairwise interactions and environmental potentials, and we extend the analysis to evolving hypersurfaces driven by an SDE that interacts with the particles, yielding the corresponding surface DK equation for the coupled surface-particle system. We establish a weak uniqueness result in the non-interacting case, and we develop a finite-volume discretization preserving the fluctuation-dissipation relation. Numerical experiments illustrate equilibrium properties and dynamical behavior influenced by surface geometry and external potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.06863v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Bell, Ana Djurdjevac, Nicolas Perkowski</dc:creator>
    </item>
    <item>
      <title>Primal-Dual algorithms for Abstract convex functions with respect to quadratic functions</title>
      <link>https://arxiv.org/abs/2601.07076</link>
      <description>arXiv:2601.07076v1 Announce Type: cross 
Abstract: We consider the saddle point problem where the objective functions are abstract convex with respect to the class of quadratic functions. We propose primal-dual algorithms using the corresponding abstract proximal operator and investigate the convergence under certain restrictions. We test our algorithms by several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07076v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ewa Bednarczuk, The Hung Tran</dc:creator>
    </item>
    <item>
      <title>Robust maximum hands-off optimal control: existence, maximum principle, and $L^{0}$-$L^1$ equivalence</title>
      <link>https://arxiv.org/abs/2601.07256</link>
      <description>arXiv:2601.07256v1 Announce Type: cross 
Abstract: This work advances the maximum hands-off sparse control framework by developing a robust counterpart for constrained linear systems with parametric uncertainties. The resulting optimal control problem minimizes an $L^{0}$ objective subject to an uncountable, compact family of constraints, and is therefore a nonconvex, nonsmooth robust optimization problem. To address this, we replace the $L^{0}$ objective with its convex $L^{1}$ surrogate and, using a nonsmooth variant of the robust Pontryagin maximum principle, show that the $L^{0}$ and $L^{1}$ formulations have identical sets of optimal solutions -- we call this the robust hands-off principle. Building on this equivalence, we propose an algorithmic framework -- drawing on numerically viable techniques from the semi-infinite robust optimization literature -- to solve the resulting problems. An illustrative example is provided to demonstrate the effectiveness of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07256v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddhartha Ganguly, Kenji Kashima</dc:creator>
    </item>
    <item>
      <title>An adjoint method for training data-driven reduced-order models</title>
      <link>https://arxiv.org/abs/2601.07579</link>
      <description>arXiv:2601.07579v1 Announce Type: cross 
Abstract: Reduced-order modeling lies at the interface of numerical analysis and data-driven scientific computing, providing principled ways to compress high-fidelity simulations in science and engineering. We propose a training framework that couples a continuous-time form of operator inference with the adjoint-state method to obtain robust data-driven reduced-order models. This method minimizes a trajectory-based loss between reduced-order solutions and projected snapshot data, which removes the need to estimate time derivatives from noisy measurements and provides intrinsic temporal regularization through time integration. We derive the corresponding continuous adjoint equations to compute gradients efficiently and implement a gradient based optimizer to update the reduced model parameters. Each iteration only requires one forward reduced order solve and one adjoint solve, followed by inexpensive gradient assembly, making the method attractive for large-scale simulations. We validate the proposed method on three partial differential equations: viscous Burgers' equation, the two-dimensional Fisher-KPP equation, and an advection-diffusion equation. We perform systematic comparisons against standard operator inference under two perturbation regimes, namely reduced temporal snapshot density and additive Gaussian noise. For clean data, both approaches deliver similar accuracy, but in situations with sparse sampling and noise, the proposed adjoint-based training provides better accuracy and enhanced roll-out stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07579v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Donglin Liu, Francisco Garc\'ia Atienza, Mengwu Guo</dc:creator>
    </item>
    <item>
      <title>Free-RBF-KAN: Kolmogorov-Arnold Networks with Adaptive Radial Basis Functions for Efficient Function Learning</title>
      <link>https://arxiv.org/abs/2601.07760</link>
      <description>arXiv:2601.07760v1 Announce Type: cross 
Abstract: Kolmogorov-Arnold Networks (KANs) have shown strong potential for efficiently approximating complex nonlinear functions. However, the original KAN formulation relies on B-spline basis functions, which incur substantial computational overhead due to De Boor's algorithm. To address this limitation, recent work has explored alternative basis functions such as radial basis functions (RBFs) that can improve computational efficiency and flexibility. Yet, standard RBF-KANs often sacrifice accuracy relative to the original KAN design. In this work, we propose Free-RBF-KAN, a RBF-based KAN architecture that incorporates adaptive learning grids and trainable smoothness to close this performance gap. Our method employs freely learnable RBF shapes that dynamically align grid representations with activation patterns, enabling expressive and adaptive function approximation. Additionally, we treat smoothness as a kernel parameter optimized jointly with network weights, without increasing computational complexity. We provide a general universality proof for RBF-KANs, which encompasses our Free-RBF-KAN formulation. Through a broad set of experiments, including multiscale function approximation, physics-informed machine learning, and PDE solution operator learning, Free-RBF-KAN achieves accuracy comparable to the original B-spline-based KAN while delivering faster training and inference. These results highlight Free-RBF-KAN as a compelling balance between computational efficiency and adaptive resolution, particularly for high-dimensional structured modeling tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07760v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shao-Ting Chiu, Siu Wun Cheung, Ulisses Braga-Neto, Chak Shing Lee, Rui Peng Li</dc:creator>
    </item>
    <item>
      <title>Generative Modeling via Hierarchical Tensor Sketching</title>
      <link>https://arxiv.org/abs/2304.05305</link>
      <description>arXiv:2304.05305v2 Announce Type: replace 
Abstract: We propose a hierarchical tensor-network approach for approximating high-dimensional probability density via empirical distribution. This leverages randomized singular value decomposition (SVD) techniques and involves solving linear equations for tensor cores in this tensor network. The complexity of the resulting algorithm scales linearly in the dimension of the high-dimensional density. An analysis of estimation error demonstrates the effectiveness of this method through several numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.05305v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.ML</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Peng, Yian Chen, E. Miles Stoudenmire, Yuehaw Khoo</dc:creator>
    </item>
    <item>
      <title>Fast Numerical Approximation of Linear, Second-Order Hyperbolic Problems Using Model Order Reduction and the Laplace Transform</title>
      <link>https://arxiv.org/abs/2405.19896</link>
      <description>arXiv:2405.19896v2 Announce Type: replace 
Abstract: We extend our previous work [F. Henr'iquez and J. S. Hesthaven, arXiv:2403.02847 (2024)] to the linear, second-order wave equation in bounded domains. This technique uses two widely known mathematical tools to construct a fast and efficient method for the solution of linear, time-dependent problems: the Laplace transform (LT) and the model-order reduction (MOR) techniques, hence the name LT-MOR method.
  The application of the Laplace transform yields a time-independent problem parametrically depending on the Laplace variable. Following the two-phase paradigm of the reduced basis method, first in an offline stage we sample the Laplace parameter, compute the high-fidelity solution, and then resort to a Proper Orthogonal Decomposition (POD) to extract a basis of reduced dimension. Then, in an online phase, we project the time-dependent problem onto this basis and proceed to solve the evolution problem using any suitable time-stepping method. We prove exponential convergence of the reduced solution computed by the proposed method toward the high-fidelity one as the dimension of the reduced space increases.
  Finally, we present numerical experiments illustrating the performance of the method in terms of accuracy and, in particular, speed-up when compared to the full-order model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19896v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Henriquez, Jan S. Hesthaven</dc:creator>
    </item>
    <item>
      <title>Universal Approximation of Dynamical Systems by Semi-Autonomous Neural ODEs and Applications</title>
      <link>https://arxiv.org/abs/2407.17092</link>
      <description>arXiv:2407.17092v3 Announce Type: replace 
Abstract: In this paper, we introduce semi-autonomous neural ordinary differential equations (SA-NODEs), a variation of the vanilla NODEs, employing fewer parameters. We investigate the universal approximation properties of SA-NODEs for dynamical systems from both a theoretical and a numerical perspective. Within the assumption of a finite-time horizon, under general hypotheses we establish an asymptotic approximation result, demonstrating that the error vanishes as the number of parameters goes to infinity. Under additional regularity assumptions, we further specify this convergence rate in relation to the number of parameters, utilizing quantitative approximation results in the Barron space. Based on the previous result, we prove an approximation rate for transport equations by their neural counterparts. Our numerical experiments validate the effectiveness of SA-NODEs in capturing the dynamics of various ODE systems and transport equations. Additionally, we compare SA-NODEs with vanilla NODEs, highlighting the superior performance and reduced complexity of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17092v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqian Li, Kang Liu, Lorenzo Liverani, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Fourier Extension Based on Weighted Generalized Inverse</title>
      <link>https://arxiv.org/abs/2501.16096</link>
      <description>arXiv:2501.16096v4 Announce Type: replace 
Abstract: This paper introduces a weighted generalized inverse framework for Fourier extensions, designed to suppress spurious oscillations in the extended region while maintaining high approximation accuracy on the original interval. By formulating the Fourier extension problem as a compact operator equation, we propose a weighted best-approximation solution that incorporates a priori smoothness information through suitable weight operators on the Fourier coefficients. This leads to a regularization scheme based on the generalized truncated singular value decomposition (GTSVD). Under algebraic and exponential smoothness assumptions, convergence analysis demonstrates optimal $L^2$ accuracy and improved stability for derivatives. Compared with classical Fourier extension using standard TSVD, the proposed method effectively controls high-frequency components and yields smoother extensions. A practical discretization using uniform sampling is developed, along with an adaptive design of weight functions. Numerical experiments confirm that the method significantly improves derivative approximations and reduces oscillations in the extended domain without compromising accuracy on the original interval.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16096v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenyu Zhao, Yanfei Wang, Anatoly G. Yagola, Xusheng Li</dc:creator>
    </item>
    <item>
      <title>High-dimensional stochastic finite volumes using the tensor train format</title>
      <link>https://arxiv.org/abs/2502.04868</link>
      <description>arXiv:2502.04868v3 Announce Type: replace 
Abstract: A method for the uncertainty quantification of nonlinear hyperbolic conservation laws with many uncertain parameters is presented. The method combines stochastic finite volume methods and tensor trains in a novel way: the dimensions of physical space and time are kept as full tensors, while all stochastic dimensions are compressed together into a tensor train. The resulting hybrid format has one tensor train for each spatial cell and each time step. The MUSCL scheme is adapted to the proposed hybrid format, and its feasibility is demonstrated through several test cases. For the scalar Burgers' equation, we conduct a convergence study and compare the results with those obtained using the full tensor train format with three stochastic parameters. The equation is then solved for an increasing number of stochastic dimensions.For systems of conservation laws, we focus on the Euler equations. A parameter study and a comparison with the full tensor train format are carried out for the Sod shock tube problem. As a more complex application, we investigate the Shu-Osher problem, which involves intricate wave interactions. The presented method opens new avenues for integrating uncertainty quantification with established numerical schemes for hyperbolic conservation laws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04868v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Juliette Dubois, Michael Herty, Siegfried M\"uller</dc:creator>
    </item>
    <item>
      <title>High-order BUG dynamical low-rank integrators based on explicit Runge--Kutta methods</title>
      <link>https://arxiv.org/abs/2502.07040</link>
      <description>arXiv:2502.07040v5 Announce Type: replace 
Abstract: In this work, we introduce high-order Basis-Update &amp; Galerkin (BUG) integrators based on explicit Runge-Kutta methods for large-scale matrix differential equations. These dynamical low-rank integrators extend the BUG integrator to arbitrary explicit Runge-Kutta schemes by performing a BUG step at each stage of the method. The resulting Runge-Kutta BUG (RK-BUG) integrators are robust with respect to small singular values, fully forward in time, and high-order accurate, while enabling conservation and rank adaptivity. We prove that RK-BUG integrators retain the order of convergence of the underlying Runge-Kutta method until the error reaches a plateau corresponding to the low-rank truncation error, which vanishes as the rank becomes full. This theoretical analysis is supported by several numerical experiments. The results demonstrate the high-order convergence of the RK-BUG integrator and its superior accuracy compared to other existing dynamical low-rank integrators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07040v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Nobile, S\'ebastien Riffaud</dc:creator>
    </item>
    <item>
      <title>Mass conservation, positivity and energy identical-relation preserving scheme for the Navier-Stokes equations with variable density</title>
      <link>https://arxiv.org/abs/2503.00405</link>
      <description>arXiv:2503.00405v3 Announce Type: replace 
Abstract: In this paper, we consider a mass conservation, positivity and energy identical-relation preserving scheme for the Navier-Stokes equations with variable density. Utilizing the square transformation, we first ensure the positivity of the numerical fluid density, which is form-invariant and regardless of the discrete scheme. Then, by proposing a new recovery technique to eliminate the numerical dissipation of the energy and to balance the loss of the mass when approximating the reformation form, we preserve the original energy identical-relation and mass conservation of the proposed scheme. To the best of our knowledge, this is the first work that can preserve the original energy identical-relation for the Navier-Stokes equations with variable density. Moreover, the error estimates of the considered scheme are derived. Finally, we show some numerical examples to verify the correctness and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00405v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Yang, Haiyun Dong, Maojun Li, Kun Wang</dc:creator>
    </item>
    <item>
      <title>Certified Model Order Reduction for parametric Hermitian eigenproblems</title>
      <link>https://arxiv.org/abs/2504.02672</link>
      <description>arXiv:2504.02672v3 Announce Type: replace 
Abstract: This article deals with the efficient and certified numerical approximation of the smallest eigenvalue and the associated eigenspace of a large-scale parametric Hermitian matrix. For this aim, we rely on projection-based model order reduction (MOR), i.e., we approximate the large-scale problem by projecting it onto a suitable subspace and reducing it to one of a much smaller dimension. Such a subspace is constructed by means of weak greedy-type strategies. After detailing the connections with the reduced basis method for source problems, we introduce a novel error estimate for the approximation error related to the eigenspace associated with the smallest eigenvalue. Since the difference between the second smallest and the smallest eigenvalue, the so-called spectral gap, is crucial for the reliability of the error estimate, we propose efficiently computable upper and lower bounds for higher eigenvalues and for the spectral gap, which enable the assembly of a subspace for the MOR approximation of the spectral gap. Based on that, a second subspace is then generated for the MOR approximation of the eigenspace associated with the smallest eigenvalue. We also provide efficiently computable conditions to ensure that the multiplicity of the smallest eigenvalue is fully captured in the reduced space. This work is motivated by a specific application: the repeated identifications of the states with minimal energy, the so-called ground states, of parametric quantum spin system models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02672v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mattia Manucci, Benjamin Stamm, Zhuoyao Zeng</dc:creator>
    </item>
    <item>
      <title>Hybrid Nitsche method for distributed computing</title>
      <link>https://arxiv.org/abs/2504.05036</link>
      <description>arXiv:2504.05036v2 Announce Type: replace 
Abstract: We extend a distributed finite element method built upon model order reduction to arbitrary polynomial degree using a hybrid Nitsche scheme. The new method considerably simplifies the transformation of the finite element system to the reduced basis for large problems. We prove that the error of the reduced Nitsche solution converges optimally with respect to the approximation order of the finite element spaces and linearly with respect to the dimension reduction parameter. Numerical tests with nontrivial tetrahedral meshes using second-degree polynomial bases support the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05036v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Gustafsson, Antti Hannukainen, Vili Kohonen, Juha Videman</dc:creator>
    </item>
    <item>
      <title>Projection Coefficients Estimation in Continuous-Variable Quantum Circuits</title>
      <link>https://arxiv.org/abs/2504.16246</link>
      <description>arXiv:2504.16246v3 Announce Type: replace 
Abstract: In this work, we propose a continuous-variable quantum algorithm to compute the projection coefficients of a holomorphic function in the Segal--Bargmann space by leveraging its isometric correspondence with single-mode quantum states. Using CV quantum circuits, we prepare the state $\ket{f}$ associated with $f(z)$ and extract the coefficients $c_n = \braket{n}{f}$ via photon-number-resolved detection, enhanced by interferometric phase referencing to recover full complex amplitudes. This enables direct quantum estimation and visualization of the coefficient sequence -- offering a scalable, measurement-based alternative to classical numerical integration for functional analysis and non-Gaussian state characterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16246v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>quant-ph</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>M. W. AlMasri</dc:creator>
    </item>
    <item>
      <title>Efficient approximations of matrix multiplication using truncated decompositions</title>
      <link>https://arxiv.org/abs/2504.19308</link>
      <description>arXiv:2504.19308v3 Announce Type: replace 
Abstract: We exploit the truncated singular value decomposition and the recently proposed circulant decomposition for an efficient first-order approximation of the multiplication of large dense matrices. A decomposition of each matrix into a sum of a sparse matrix with relatively few dominant entries and a dense residue can also use the above approach, and we present methods for multiplication using a Fourier decomposition and a cycle decomposition-based sparsifications. The proposed methods scale as $\mathcal{O}(n^2 \log n)$ in arithmetic operations for $n \times n$ matrices for usable tolerances in relative error $\sim$ 1\%. Note that different decompositions for the two matrices $A$ and $B$ in the product $AB$ are also possible in this approach, using efficient a priori evaluations for suitability, to improve further on the error tolerances demonstrated here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19308v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suvendu Kar, Hariprasad M., Sai Gowri J. N., Murugesan Venkatapathi</dc:creator>
    </item>
    <item>
      <title>R-PINN: Recovery-type a-posteriori estimator enhanced adaptive PINN</title>
      <link>https://arxiv.org/abs/2506.10243</link>
      <description>arXiv:2506.10243v2 Announce Type: replace 
Abstract: In recent years, with the advancements in machine learning and neural networks, algorithms using physics-informed neural networks (PINNs) to solve PDEs have gained widespread applications. While these algorithms are well-suited for a wide range of equations, they often exhibit suboptimal performance when applied to equations with large local gradients, resulting in substantial localized errors. To address this issue, this paper proposes an adaptive PINN algorithm designed to improve accuracy in such cases. The core idea of the algorithm is to adaptively adjust the distribution of collocation points based on the recovery-type a-posterior error of the current numerical solution, enabling a better approximation of the true solution. This approach is inspired by the adaptive finite element method. By combining the recovery-type a-posteriori estimator, a gradient-recovery estimator commonly used in the adaptive finite element method (FEM) with PINNs, we introduce the Recovery-type a-posteriori estimator enhanced adaptive PINN (R-PINN) and compare its performance with a typical adaptive PINN algorithm, FI-PINN. Our results demonstrate that R-PINN achieves faster convergence with fewer adaptive points and significantly outperforms in the cases with multiple regions of large errors than FI-PINN. Notably, our method is a hybrid numerical approach for solving partial differential equations, integrating adaptive FEM with PINNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10243v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongxin Lu, Jiwei Jia, Young Ju Lee, Zheng Lu, Chen-Song Zhang</dc:creator>
    </item>
    <item>
      <title>Deep random difference method for high-dimensional quasilinear parabolic partial differential equations</title>
      <link>https://arxiv.org/abs/2506.20308</link>
      <description>arXiv:2506.20308v2 Announce Type: replace 
Abstract: Solving high-dimensional parabolic partial differential equations (PDEs) with deep learning methods is often computationally and memory intensive, primarily due to the need for automatic differentiation (AD) to compute large Hessian matrices in the PDE. In this work, we propose a deep random difference method (DRDM) that addresses these issues by approximating the convection-diffusion operator using only first-order differences and the solution by deep neural networks, thus avoiding Hessian and other derivative computations. The DRDM is implemented within a Galerkin framework to reduce sampling variance, and the solution space is explored using stochastic differential equations (SDEs) to capture the dynamics of the convection-diffusion operator. The approach is then extended to solve Hamilton-Jacobi-Bellman (HJB) equations, which recovers existing martingale deep learning methods for PDEs [{\it SIAM J. Sci. Comput.}, 47 (2025), pp. C795-C819], without using stochastic calculus. The proposed method offers two main advantages: it avoids the need to compute derivatives in PDEs and enables parallel computation of the loss function in both time and space. Moreover, a rigorous error estimate is proven for the quasi-linear parabolic equation, showing first-order accuracy in $h$, the time step used in the discretization of the SDE paths by the Euler-Maruyama scheme. Numerical experiments demonstrate that the method can efficiently and accurately solve quasilinear parabolic PDEs and HJB equations in dimensions up to $10^5$ and $10^4$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20308v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Cai, Shuixin Fang, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>Convergence analysis for the Barrett--Garcke--Nurnberg method of transport type for evolving curves</title>
      <link>https://arxiv.org/abs/2509.07834</link>
      <description>arXiv:2509.07834v2 Announce Type: replace 
Abstract: In this paper, we propose a Barrett-Garcke-Nurnberg (BGN) method for evolving geometries under general flows and present the corresponding convergence analysis. Specifically, we examine the scenario where a closed curve evolves according to a prescribed background velocity field. Unlike mean curvature flow and surface diffusion, where the evolution velocities inherently exhibit parabolicity, this case is dominated by transport which poses a significant difficulty in establishing convergence proofs. To address the challenges imposed by this transport-dominant nature, we derive several discrete energy estimates of the transport type on discretized polynomial surfaces within the framework of the projection error. The use of the projection error is indispensable as it provides crucial additional stability through its orthogonality structure. We prove that the proposed method converges sub-optimally in the L2 norm, and this is the first convergence proof for a fully discrete numerical method solving the evolution of curves driven by general flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07834v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Genming Bai, Harald Garcke, Shravan Veerapaneni</dc:creator>
    </item>
    <item>
      <title>Spotlight inversion by orthogonal projections</title>
      <link>https://arxiv.org/abs/2509.15512</link>
      <description>arXiv:2509.15512v2 Announce Type: replace 
Abstract: Many computational problems involve solving a linear system of equations, although only a subset of the entries of the solution are needed. In inverse problems, where the goal is to estimate unknown parameters from indirect noisy observations, it is not uncommon that the forward model linking the observed variables to the unknowns depends on variables that are not of primary interest, often referred to as nuisance parameters. In this article, we consider linear problems, and propose a novel projection technique to eliminate, or at least mitigate, the contribution of the nuisance parameters in the model. We refer to this approach as spotlight inversion, as it allows to focus on only the portion of primary interest of the unknown parameter vector, leaving the uninteresting part in the shadow. The viability of the approach is illustrated with two computed examples, one where it works as model reduction for a finite element approximation of an elliptic PDE, the other amounting to local fanbeam X-ray tomography, spotlighting the region of interest that is part of the full target.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15512v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Calvetti, Nuutti Hyv\"onen, Ville Kolehmainen, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>Ensemble Parameter Estimation for the Lumped Parameter Linear Superposition (LPLSP) Framework: A Rapid Approach to Reduced-Order Modeling for Transient Thermal Systems</title>
      <link>https://arxiv.org/abs/2512.14467</link>
      <description>arXiv:2512.14467v2 Announce Type: replace 
Abstract: This work introduces an ensemble parameter estimation framework that enables the Lumped Parameter Linear Superposition (LPLSP) method to generate reduced order thermal models from a single transient dataset. Unlike earlier implementations that relied on multiple parametric simulations to excite each heat source independently, the proposed approach simultaneously identifies all model coefficients using fully transient excitations. Two estimation strategies namely rank-reduction and two-stage decomposition are developed to further reduce computational cost and improve scalability for larger systems. The proposed strategies yield ROMs with mean temperature-prediction errors within 5% of CFD simulations while reducing model-development times to O(10^0 s)-O(10^1 s). Once constructed, the ROM evaluates new transient operating conditions in O(10^0 s), enabling rapid thermal analysis and enabling automated generation of digital twins for both simulated and physical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14467v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Neelakantan Padmanabhan</dc:creator>
    </item>
    <item>
      <title>Data-Free Asymptotics-Informed Operator Networks for Singularly Perturbed PDEs</title>
      <link>https://arxiv.org/abs/2512.22006</link>
      <description>arXiv:2512.22006v2 Announce Type: replace 
Abstract: Recent advances in machine learning (ML) have opened new possibilities for solving partial differential equations (PDEs), yet robust performance in challenging regimes remains limited. In particular, singularly perturbed differential equations exhibit sharp boundary or interior layers with rapid transitions, where standard ML surrogates often fail without extensive resolution. Generating training data for such problems is also costly, as accurate reference solutions typically require massive adaptive mesh refinement. In this work, we propose eFEONet, an enriched Finite Element Operator Network tailored to singularly perturbed problems. Guided by classical singular perturbation theory, eFEONet augments the operator-learning framework with specialized enrichment basis functions that encode the asymptotic structure of layer solutions. This design enables accurate approximation of sharp transitions without relying on large datasets, and can operate with minimal supervision-or even in a data-free manner under appropriate settings. We further provide a rigorous convergence analysis of the proposed method and demonstrate its effectiveness through extensive experiments on representative problems featuring both boundary and interior layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.22006v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinsil Lee, Youngjoon Hong, Seungchan Ko, Jae Yong Lee</dc:creator>
    </item>
    <item>
      <title>A Fourth-Order Cut-cell Multigrid Method for Solving Elliptic Equations on Arbitrary Domains</title>
      <link>https://arxiv.org/abs/2601.02975</link>
      <description>arXiv:2601.02975v2 Announce Type: replace 
Abstract: To numerically solve a generic elliptic equation on two-dimensional domains with rectangular Cartesian grids, we propose a cut-cell geometric multigrid method that features (1) general algorithmic steps that apply to all forms of elliptic equations and all types of boundary conditions, (2) the versatility of handling both regular and irregular domains with arbitrarily complex topology and geometry, (3) the fourth-order accuracy even at the presence of ${\cal C}^1$ discontinuities on the domain boundary, and (4) the optimal complexity of $O(h^{-2})$.Test results demonstrate the generality, accuracy, efficiency, robustness, and excellent conditioning of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02975v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiyu Liu, Zhixuan Li, Jiatu Yan, Zhiqi Li, Qinghai Zhang</dc:creator>
    </item>
    <item>
      <title>Dimension reduction for path signatures</title>
      <link>https://arxiv.org/abs/2412.14723</link>
      <description>arXiv:2412.14723v2 Announce Type: replace-cross 
Abstract: This paper focuses on the mathematical framework for reducing the complexity of models using path signatures. The structure of these signatures, which can be interpreted as collections of iterated integrals along paths, is discussed and their applications in areas such as stochastic differential equations (SDEs) and financial modeling are pointed out. In particular, exploiting the rough paths view, solutions of SDEs continuously depend on the lift of the driver. Such continuous mappings can be approximated using (truncated) signatures, which are solutions of high-dimensional linear systems. In order to lower the complexity of these models, this paper presents methods for reducing the order of high-dimensional truncated signature models while retaining essential characteristics. The derivation of reduced models and the universal approximation property of (truncated) signatures are treated in detail. Numerical examples, including applications to the (rough) Bergomi model in financial markets, illustrate the proposed reduction techniques and highlight their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14723v2</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Bayer, Martin Redmann</dc:creator>
    </item>
    <item>
      <title>Time-complexity of sampling from a multimodal distribution using sequential Monte Carlo</title>
      <link>https://arxiv.org/abs/2508.02763</link>
      <description>arXiv:2508.02763v2 Announce Type: replace-cross 
Abstract: We study a sequential Monte Carlo algorithm to sample from the Gibbs measure with a non-convex energy function at a low temperature. We use the practical and popular geometric annealing schedule, and use a Langevin diffusion at each temperature level. The Langevin diffusion only needs to run for a time that is long enough to ensure local mixing within energy valleys, which is much shorter than the time required for global mixing. Our main result shows convergence of Monte Carlo estimators with time complexity that, approximately, scales like the fourth power of the inverse temperature, and the square of the inverse allowed error. We also study this algorithm in an illustrative model scenario where more explicit estimates can be given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02763v2</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiyu Han, Gautam Iyer, Dejan Slep\v{c}ev</dc:creator>
    </item>
    <item>
      <title>A Kernel-based Stochastic Approximation Framework for Nonlinear Operator Learning</title>
      <link>https://arxiv.org/abs/2509.11070</link>
      <description>arXiv:2509.11070v3 Announce Type: replace-cross 
Abstract: We develop a stochastic approximation framework for learning nonlinear operators between infinite-dimensional spaces utilizing general Mercer operator-valued kernels. Our framework encompasses two key classes: (i) compact kernels, which admit discrete spectral decompositions, and (ii) diagonal kernels of the form $K(x,x')=k(x,x')T$, where $k$ is a scalar-valued kernel and $T$ is a positive operator on the output space. This broad setting induces expressive vector-valued reproducing kernel Hilbert spaces (RKHSs) that generalize the classical $K=kI$ paradigm, thereby enabling rich structural modeling with rigorous theoretical guarantees. To address target operators lying outside the RKHS, we introduce vector-valued interpolation spaces to precisely quantify misspecification error. Within this framework, we establish dimension-free polynomial convergence rates, demonstrating that nonlinear operator learning can overcome the curse of dimensionality. The use of general operator-valued kernels further allows us to derive rates for intrinsically nonlinear operator learning, going beyond the linear-type behavior inherent in diagonal constructions of $K=kI$. Importantly, this framework accommodates a wide range of operator learning tasks, ranging from integral operators such as Fredholm operators to architectures based on encoder-decoder representations. Moreover, we validate its effectiveness through numerical experiments on the two-dimensional Navier-Stokes equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11070v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia-Qi Yang, Lei Shi</dc:creator>
    </item>
    <item>
      <title>Stochastic Control Methods for Optimization</title>
      <link>https://arxiv.org/abs/2601.01248</link>
      <description>arXiv:2601.01248v2 Announce Type: replace-cross 
Abstract: In this work, we investigate a stochastic control framework for global optimization over both Euclidean spaces and the Wasserstein space of probability measures, where the objective function may be non-convex and/or non-differentiable. In the Euclidean setting, the original minimization problem is approximated by a family of regularized stochastic control problems; using dynamic programming, we analyze the associated Hamilton--Jacobi--Bellman equations and obtain tractable representations via the Cole--Hopf transformation and the Feynman--Kac formula. For optimization over probability measures, we formulate a regularized mean-field control problem characterized by a master equation, and further approximate it by controlled $N$-particle systems. We establish that, as the regularization parameter tends to zero (and as the particle number tends to infinity for the optimization over probability measures), the value of the control problem converges to the global minimum of the original objective. Building on the resulting probabilistic representations, Monte Carlo-based numerical schemes are proposed and numerical experiments are reported to illustrate the effectiveness of the methods and to support the theoretical convergence rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01248v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Tue, 13 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinniao Qiu</dc:creator>
    </item>
  </channel>
</rss>
