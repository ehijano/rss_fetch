<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.CP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.CP</link>
    <description>q-fin.CP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.CP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A monotone piecewise constant control integration approach for the two-factor uncertain volatility model</title>
      <link>https://arxiv.org/abs/2402.06840</link>
      <description>arXiv:2402.06840v3 Announce Type: replace 
Abstract: Option contracts on two underlying assets within uncertain volatility models have their worst-case and best-case prices determined by a two-dimensional (2D) Hamilton-Jacobi-Bellman (HJB) partial differential equation (PDE) with cross-derivative terms. This paper introduces a novel ``decompose and integrate, then optimize'' approach to tackle this HJB PDE. Within each timestep, our method applies piecewise constant control, yielding a set of independent linear 2D PDEs, each corresponding to a discretized control value. Leveraging closed-form Green's functions, these PDEs are efficiently solved via 2D convolution integrals using a monotone numerical integration method. The value function and optimal control are then obtained by synthesizing the solutions of the individual PDEs. For enhanced efficiency, we implement the integration via Fast Fourier Transforms, exploiting the Toeplitz matrix structure. The proposed method is unconditionally $\ell_{\infty}$-stable, consistent in the viscosity sense, and converges to the viscosity solution of the HJB equation. Numerical results show excellent agreement with benchmark solutions obtained by finite differences, tree methods, and Monte Carlo simulation, highlighting its robustness and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06840v3</guid>
      <category>q-fin.CP</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duy-Minh Dang, Hao Zhou</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of American option pricing in a two-asset jump-diffusion model</title>
      <link>https://arxiv.org/abs/2410.04745</link>
      <description>arXiv:2410.04745v3 Announce Type: replace 
Abstract: This paper addresses an important gap in rigorous numerical treatments for pricing American options under correlated two-asset jump-diffusion models using the viscosity solution framework, with a particular focus on the Merton model. The pricing of these options is governed by complex two-dimensional (2-D) variational inequalities that incorporate cross-derivative terms and nonlocal integro-differential terms due to the presence of jumps. Existing numerical methods, primarily based on finite differences, often struggle with preserving monotonicity in the approximation of cross-derivatives, a key requirement for ensuring convergence to the viscosity solution. In addition, these methods face challenges in accurately discretizing 2-D jump integrals.
  We introduce a novel approach to effectively tackle the aforementioned variational inequalities while seamlessly handling cross-derivative terms and nonlocal integro-differential terms through an efficient and straightforward-to-implement monotone integration scheme. Within each timestep, our approach explicitly enforces the inequality constraint, resulting in a 2-D Partial Integro-Differential Equation (PIDE) to solve. Its solution is expressed as a 2-D convolution integral involving the Green's function of the PIDE. We derive an infinite series representation of this Green's function, where each term is non-negative and computable. This facilitates the numerical approximation of the PIDE solution through a monotone integration method. To enhance efficiency, we develop an implementation of this monotone scheme via FFTs, exploiting the Toeplitz matrix structure.
  The proposed method is proved to be both $\ell_{\infty} $-stable and consistent in the viscosity sense, ensuring its convergence to the viscosity solution of the variational inequality. Extensive numerical results validate the effectiveness and robustness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04745v3</guid>
      <category>q-fin.CP</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Zhou, Duy-Minh Dang</dc:creator>
    </item>
    <item>
      <title>Designing Universal Causal Deep Learning Models: The Case of Infinite-Dimensional Dynamical Systems from Stochastic Analysis</title>
      <link>https://arxiv.org/abs/2210.13300</link>
      <description>arXiv:2210.13300v3 Announce Type: replace-cross 
Abstract: Several non-linear operators in stochastic analysis, such as solution maps to stochastic differential equations, depend on a temporal structure which is not leveraged by contemporary neural operators designed to approximate general maps between Banach space. This paper therefore proposes an operator learning solution to this open problem by introducing a deep learning model-design framework that takes suitable infinite-dimensional linear metric spaces, e.g. Banach spaces, as inputs and returns a universal \textit{sequential} deep learning model adapted to these linear geometries specialized for the approximation of operators encoding a temporal structure. We call these models \textit{Causal Neural Operators}. Our main result states that the models produced by our framework can uniformly approximate on compact sets and across arbitrarily finite-time horizons H\"older or smooth trace class operators, which causally map sequences between given linear metric spaces. Our analysis uncovers new quantitative relationships on the latent state-space dimension of Causal Neural Operators, which even have new implications for (classical) finite-dimensional Recurrent Neural Networks. In addition, our guarantees for recurrent neural networks are tighter than the available results inherited from feedforward neural networks when approximating dynamical systems between finite-dimensional spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.13300v3</guid>
      <category>math.DS</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Galimberti, Anastasis Kratsios, Giulia Livieri</dc:creator>
    </item>
  </channel>
</rss>
