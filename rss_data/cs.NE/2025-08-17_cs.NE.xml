<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 18 Aug 2025 04:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>SDSNN: A Single-Timestep Spiking Neural Network with Self-Dropping Neuron and Bayesian Optimization</title>
      <link>https://arxiv.org/abs/2508.10913</link>
      <description>arXiv:2508.10913v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs), as an emerging biologically inspired computational model, demonstrate significant energy efficiency advantages due to their event-driven information processing mechanism. Compared to traditional Artificial Neural Networks (ANNs), SNNs transmit information through discrete spike signals, which substantially reduces computational energy consumption through their sparse encoding approach. However, the multi-timestep computation model significantly increases inference latency and energy, limiting the applicability of SNNs in edge computing scenarios. We propose a single-timestep SNN, which enhances accuracy and reduces computational energy consumption in a single timestep by optimizing spike generation and temporal parameters. We design a Self-Dropping Neuron mechanism, which enhances information-carrying capacity through dynamic threshold adjustment and selective spike suppression. Furthermore, we employ Bayesian optimization to globally search for time parameters and obtain an efficient inference mode with a single time step. Experimental results on the Fashion-MNIST, CIFAR-10, and CIFAR-100 datasets demonstrate that, compared to traditional multi-timestep SNNs employing the Leaky Integrate-and-Fire (LIF) model, our method achieves classification accuracies of 93.72%, 92.20%, and 69.45%, respectively, using only single-timestep spikes, while maintaining comparable or even superior accuracy. Additionally, it reduces energy consumption by 56%, 21%, and 22%, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10913v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changqing Xu, Buxuan Song, Yi Liu, Xinfang Liao, Wenbin Zheng, Yintang Yang</dc:creator>
    </item>
    <item>
      <title>Insect-Wing Structured Microfluidic System for Reservoir Computing</title>
      <link>https://arxiv.org/abs/2508.10915</link>
      <description>arXiv:2508.10915v1 Announce Type: new 
Abstract: As the demand for more efficient and adaptive computing grows, nature-inspired architectures offer promising alternatives to conventional electronic designs. Microfluidic platforms, drawing on biological forms and fluid dynamics, present a compelling foundation for low-power, high-resilience computing in environments where electronics are unsuitable. This study explores a hybrid reservoir computing system based on a dragonfly-wing inspired microfluidic chip, which encodes temporal input patterns as fluid interactions within the micro channel network.
  The system operates with three dye-based inlet channels and three camera-monitored detection areas, transforming discrete spatial patterns into dynamic color output signals. These reservoir output signals are then modified and passed to a simple and trainable readout layer for pattern classification. Using a combination of raw reservoir outputs and synthetically generated outputs, we evaluated system performance, system clarity, and data efficiency. The results demonstrate consistent classification accuracies up to $91\%$, even with coarse resolution and limited training data, highlighting the viability of the microfluidic reservoir computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10915v1</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Clouse (School of Computing, University of Nebraska-Lincoln, Lincoln, Nebraska, USA), Thomas Ramsey (Department of Mechanical and Materials Engineering, University of Nebraska-Lincoln, Lincoln, Nebraska, USA), Samitha Somathilaka (School of Computing, University of Nebraska-Lincoln, Lincoln, Nebraska, USA), Nicholas Kleinsasser (School of Computing, University of Nebraska-Lincoln, Lincoln, Nebraska, USA), Sangjin Ryu (Department of Mechanical and Materials Engineering, University of Nebraska-Lincoln, Lincoln, Nebraska, USA), Sasitharan Balasubramaniam (School of Computing, University of Nebraska-Lincoln, Lincoln, Nebraska, USA)</dc:creator>
    </item>
    <item>
      <title>Use of a genetic algorithm to find solutions to introductory physics problems</title>
      <link>https://arxiv.org/abs/2508.10920</link>
      <description>arXiv:2508.10920v1 Announce Type: new 
Abstract: In this work, we show how a genetic algorithm (GA) can be used to find step-by-step solutions to introductory physics problems. Our perspective is that the underlying task for this is one of finding a sequence of equations that will lead to the needed answer. Here a GA is used to find an appropriate equation sequence by minimizing a fitness function that measures the difference between the number of unknowns versus knowns in a set of equations. Information about knowns comes from the GA posing questions to the student about what quantities exist in the text of their problem. The questions are generated from enumerations pulled from the chromosomes that drive the GA. Equations with smaller known vs. unknown differences are considered more fit and are used to produce intermediate results that feed less fit equations. We show that this technique can guide a student to an answer to any introductory physics problem involving one-dimensional kinematics. Interpretability findings are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10920v1</guid>
      <category>cs.NE</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Bensky, Justin Kopcinski</dc:creator>
    </item>
    <item>
      <title>SO-PIFRNN: Self-optimization physics-informed Fourier-features randomized neural network for solving partial differential equations</title>
      <link>https://arxiv.org/abs/2508.10921</link>
      <description>arXiv:2508.10921v1 Announce Type: new 
Abstract: This study proposes a self-optimization physics-informed Fourier-features randomized neural network (SO-PIFRNN) framework, which significantly improves the numerical solving accuracy of PDEs through hyperparameter optimization mechanism. The framework employs a bi-level optimization architecture: the outer-level optimization utilizes a multi-strategy collaborated particle swarm optimization (MSC-PSO) algorithm to search for optimal hyperparameters of physics-informed Fourier-features randomized neural network, while the inner-level optimization determines the output layer weights of the neural network via the least squares method. The core innovation of this study is embodied in the following three aspects: First, the Fourier basis function activation mechanism is introduced in the hidden layer of neural network, which significantly enhances the ability of the network to capture multi-frequency components of the solution. Secondly, a novel derivative neural network method is proposed, which improves the calculation accuracy and efficiency of PIFRNN method. Finally, the MSC-PSO algorithm of the hybrid optimization strategy is designed to improve the global search ability and convergence accuracy through the synergistic effect of dynamic parameter adjustment, elitist and mutation strategies. Through a series of numerical experiments, including multiscale equations in complex regions, high-order equations, high-dimensional equations and nonlinear equations, the validity of SO-PIFRNN is verified. The experimental results affirm that SO-PIFRNN exhibits superior approximation accuracy and frequency capture capability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10921v1</guid>
      <category>cs.NE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiale Linghu, Weifeng Gao, Hao Dong, Yufeng Nie</dc:creator>
    </item>
    <item>
      <title>Allee Synaptic Plasticity and Memory</title>
      <link>https://arxiv.org/abs/2508.10929</link>
      <description>arXiv:2508.10929v1 Announce Type: new 
Abstract: Neural plasticity is fundamental to memory storage and retrieval in biological systems, yet existing models often fall short in addressing noise sensitivity and unbounded synaptic weight growth. This paper investigates the Allee-based nonlinear plasticity model, emphasizing its biologically inspired weight stabilization mechanisms, enhanced noise robustness, and critical thresholds for synaptic regulation. We analyze its performance in memory retention and pattern retrieval, demonstrating increased capacity and reliability compared to classical models like Hebbian and Oja's rules. To address temporal limitations, we extend the model by integrating time-dependent dynamics, including eligibility traces and oscillatory inputs, resulting in improved retrieval accuracy and resilience in dynamic environments. This work bridges theoretical insights with practical implications, offering a robust framework for modeling neural adaptation and informing advances in artificial intelligence and neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10929v1</guid>
      <category>cs.NE</category>
      <category>math.DS</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eddy Kwessi</dc:creator>
    </item>
    <item>
      <title>Generational Adversarial MAP-Elites for Multi-Agent Game Illumination</title>
      <link>https://arxiv.org/abs/2505.06617</link>
      <description>arXiv:2505.06617v2 Announce Type: replace 
Abstract: Unlike traditional optimization algorithms, which focus on finding a single optimal solution, Quality-Diversity (QD) algorithms illuminate a search space by finding high-performing solutions that cover a specified behavior space. However, tackling adversarial problems is more challenging due to the behavioral interdependence between opposing sides. Most applications of QD algorithms to these problems evolve only one side, thus reducing illumination coverage. In this paper, we propose a new QD algorithm, Generational Adversarial MAP-Elites (GAME), which coevolves solutions by alternating sides through a sequence of generations. Combining GAME with vision embedding models enables the algorithm to operate directly on videos of behaviors, rather than relying on handcrafted descriptors. Some key findings are that (1) emerging evolutionary dynamics sometimes resemble an arms race, (2) starting each generation from scratch increases open-endedness, and (3) keeping neutral mutations preserves stepping stones that seem necessary to reach the highest performance. In conclusion, the results demonstrate that GAME can successfully illuminate an adversarial multi-agent game, opening up interesting future directions in understanding the emergence of open-ended coevolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06617v2</guid>
      <category>cs.NE</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timoth\'ee Anne, Noah Syrkis, Meriem Elhosni, Florian Turati, Franck Legendre, Alain Jaquier, Sebastian Risi</dc:creator>
    </item>
    <item>
      <title>Equilibrio de carga para transformadores de distribucion electrica mejorando la calidad de servicio en fin de linea</title>
      <link>https://arxiv.org/abs/2505.09235</link>
      <description>arXiv:2505.09235v2 Announce Type: replace 
Abstract: The distribution of electrical energy faces global challenges, such as increasing demand, the integration of distributed generation, high energy losses, and the need to improve service quality. In particular, load imbalance-where loads are not evenly distributed across the circuit phase-can reduce efficiency, shorten equipment lifespan, and increase susceptibility to service interruptions. While methods that involve shifting loads from one phase to another can be costly, they are effective when smart meters are available and implemented efficiently. This work proposes the use of genetic algorithms to optimally identify which loads should be reassigned in order to improve both phase balance and voltage quality at the end nodes of the network while minimizing the number of required changes. The algorithm was evaluated through simulations using PandaPower, a power flow analysis tool, modeling simple networks based on real-world characteristics of the electrical system in Tucuman.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.09235v2</guid>
      <category>cs.NE</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan M. Bord\'on, Victor A. Jimenez, Adrian Will</dc:creator>
    </item>
    <item>
      <title>Effective Stimulus Propagation in Neural Circuits: Driver Node Selection</title>
      <link>https://arxiv.org/abs/2506.13615</link>
      <description>arXiv:2506.13615v4 Announce Type: replace-cross 
Abstract: Precise control of signal propagation in modular neural networks represents a fundamental challenge in computational neuroscience. We establish a framework for identifying optimal control nodes that maximize stimulus transmission between weakly coupled neural populations. Using spiking stochastic block model networks, we systematically compare driver node selection strategies - including random sampling and topology-based centrality measures (degree, betweenness, closeness, eigenvector, harmonic, and percolation centrality) - to determine minimal control inputs for achieving inter-population synchronization. Targeted stimulation of just 10-20% of the most central neurons in the source population significantly enhances spiking propagation fidelity compared to random selection. This approach yields a 64-fold increase in signal transfer efficiency at critical inter-module connection densities. These findings establish a theoretical foundation for precision neuromodulation in biological neural systems and neurotechnology applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13615v4</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bulat Batuev, Arsenii Onuchin, Sergey Sukhov</dc:creator>
    </item>
    <item>
      <title>Tapping into the Black Box: Uncovering Aligned Representations in Pretrained Neural Networks</title>
      <link>https://arxiv.org/abs/2507.22832</link>
      <description>arXiv:2507.22832v2 Announce Type: replace-cross 
Abstract: In ReLU networks, gradients of output units can be seen as their input-level representations, as they correspond to the units' pullbacks through the active subnetwork. However, gradients of deeper models are notoriously misaligned, significantly contributing to their black-box nature. We claim that this is because active subnetworks are inherently noisy due to the ReLU hard-gating. To tackle that noise, we propose soft-gating in the backward pass only. The resulting input-level vector field (called ''excitation pullback'') exhibits remarkable perceptual alignment, revealing high-resolution input- and target-specific features that ''just make sense'', therefore establishing a compelling novel explanation method. Furthermore, we speculate that excitation pullbacks approximate (directionally) the gradients of a simpler model, linear in the network's path space, learned implicitly during optimization and largely determining the network's decision; thus arguing for the faithfulness of the produced explanations and their overall significance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22832v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Mon, 18 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maciej Satkiewicz</dc:creator>
    </item>
  </channel>
</rss>
