<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 02:39:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A $4/3$ ratio approximation algorithm for the Tree Augmentation Problem by deferred local-ratio and climbing</title>
      <link>https://arxiv.org/abs/2601.09219</link>
      <description>arXiv:2601.09219v1 Announce Type: new 
Abstract: The \emph{Tree Augmentation Problem (TAP)} is given a tree $T=(V,E_T)$ and additional set of {\em links} $E$ on $V\times V$, find $F \subseteq E$ such that $T \cup F$ is $2$-edge-connected, and $|F|$ is minimum. The problem is APX-hard \cite{r} even in if links are only between leaves \cite{r}. The best known approximation ratio for TAP is $1.393$, due to Traub and Zenklusen~\cite{tr1} J.~ACM,~2025 using the {\em relative greedy} technique \cite{zel}.
  \noindent We introduce a new technique called the {\em deferred local ratio technique}. In this technique, the disjointness of the local-ratio primal-dual type does not hold. The technique applies Set Cover problem under certain conditions (see Section \ref{lr}). We use it provide a We use it to provide a $4/3$ approximation algorithm for TAP. It is possible this technique will find future applications.
  The running time is The running time is $O(m\cdot\sqrt{n})$ time \cite{vaz}, \cite{vaz1}. Faster than \cite{tr1} \cite{LS}
  and LP based algorithms as we do not enumeratestructures of size $exp(\Theta(f(1/\epsilon)\cdot \log n)).$ Nor do we scale and round.
  \noindent \cite{ed} has an implementation \cite{kol} that is extensively used in the industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09219v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guy Kortsarz (Rutgers University, Camden)</dc:creator>
    </item>
    <item>
      <title>Lower Bounds in Algebraic Complexity via Symmetry and Homomorphism Polynomials</title>
      <link>https://arxiv.org/abs/2601.09343</link>
      <description>arXiv:2601.09343v1 Announce Type: new 
Abstract: Valiant's conjecture asserts that the circuit complexity classes VP and VNP are distinct, meaning that the permanent does not admit polynomial-size algebraic circuits. As it is the case in many branches of complexity theory, the unconditional separation of these complexity classes seems elusive. In stark contrast, the symmetric analogue of Valiant's conjecture has been proven by Dawar and Wilsenach (2020): the permanent does not admit symmetric algebraic circuits of polynomial size, while the determinant does. Symmetric algebraic circuits are both a powerful computational model and amenable to proving unconditional lower bounds.
  In this paper, we develop a symmetric algebraic complexity theory by introducing symmetric analogues of the complexity classes VP, VBP, and VF called symVP, symVBP, and symVF. They comprise polynomials that admit symmetric algebraic circuits, skew circuits, and formulas, respectively, of polynomial orbit size. Having defined these classes, we show unconditionally that $\mathsf{symVF} \subsetneq \mathsf{symVBP} \subsetneq \mathsf{symVP}$. To that end, we characterise the polynomials in symVF and symVBP as those that can be written as linear combinations of homomorphism polynomials for patterns of bounded treedepth and pathwidth, respectively. This extends a previous characterisation by Dawar, Pago, and Seppelt (2026) of symVP.
  Finally, we show that symVBP and symVP contain homomorphism polynomials which are VBP- and VP-complete, respectively. We give general graph-theoretic criteria for homomorphism polynomials and their linear combinations to be VBP-, VP-, or VNP-complete. These conditional lower bounds drastically enlarge the realm of natural polynomials known to be complete for VNP, VP, or VBP. Under the assumption VFPT $\neq$ VW[1], we precisely identify the homomorphism polynomials that lie in VP as those whose patterns have bounded treewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09343v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <category>math.GR</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Prateek Dwivedi, Benedikt Pago, Tim Seppelt</dc:creator>
    </item>
    <item>
      <title>Wataridori is NP-Complete</title>
      <link>https://arxiv.org/abs/2601.09345</link>
      <description>arXiv:2601.09345v1 Announce Type: new 
Abstract: Wataridori is a pencil puzzle involving drawing paths to connect all circles in a rectangular grid into pairs, in order to satisfy several constraints. In this paper, we prove that deciding solvability of a given Wataridori puzzle is NP-complete via reduction from Numberlink, another pencil puzzle that has already been proved to be NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09345v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suthee Ruangwises</dc:creator>
    </item>
    <item>
      <title>Complexity Thresholds for the Constrained Colored Token Swapping Problem</title>
      <link>https://arxiv.org/abs/2601.09681</link>
      <description>arXiv:2601.09681v1 Announce Type: new 
Abstract: Consider the following puzzle: a farmland consists of several fields, each occupied by either a farmer, a fox, a chicken, or a caterpillar. Creatures in neighboring fields can swap positions as long as the fox avoids the farmer, the chicken avoids the fox, and the caterpillar avoids the chicken. The objective is to decide whether there exists a sequence of swaps that rearranges the creatures into a desired final configuration, while avoiding any unwanted encounters.
  The above puzzle can be cast an instance of the \emph{colored token swapping} problem with $k = 4$ colors (i.e., creature types), in which only certain pairs of colors can be swapped. We prove that such problem is $\mathsf{PSPACE}$-hard even when the graph representing the farmland is planar and cubic. We also show that the problem is polynomial-time solvable when at most three creature types are involved. We do so by providing a more general algorithm deciding instances with arbitrary values of $k$, as long as the set of all admissible swaps between creature types induces a \emph{spanning star}.
  Our results settle a problem explicitly left open in [Yang and Zhang, IPL 2025], which established $\mathsf{PSPACE}$-completeness for eight creature types and left the complexity status unresolved when the number of creature types is between three and seven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09681v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Bil\`o, Stefano Leucci, Andrea Martinelli</dc:creator>
    </item>
    <item>
      <title>Diagonalization Without Relativization A Closer Look at the Baker-Gill-Solovay Theorem</title>
      <link>https://arxiv.org/abs/2601.09702</link>
      <description>arXiv:2601.09702v1 Announce Type: new 
Abstract: We already know that several problems like the inequivalence of P and EXP as well as the undecidability of the acceptance problem and halting problem relativize. However, relativization is a limited tool which cannot separate other complexity classes. What has not been proven explicitly is whether the Turing-recognizability of the acceptance problem relativizes. We will consider an oracle for which R and RE are equivalent; RA = REA, where A is an oracle for the equivalence problem in the class ALL, but not in RE nor co-RE. We will then differentiate between relativization and what we will call "semi-relativization", i.e., separating classes using only the acceptance problem oracle. We argue the separation of R and RE is a fact that only "semi-relativization" proves. We will then "scale down" to the polynomial analog of R and RE, to evade the Baker-Gill-Solovay barrier using "semi-relativized" diagonalization, noting this subtle distinction between diagonalization and relativization. This "polynomial acceptance problem" is then reducible to CIRCUIT-SAT and 3-CNF-SAT proving that these problems are undecidable in polynomial time yet verifiable in polynomial time. "Semi-relativization" does not employ arithmetization to evade the relativization barrier, and so itself evades the algebrization barrier of Aaronson and Wigderson. Finally, since semi-relativization is a non-constructive technique, the natural proofs barrier of Razborov and Rudich is evaded. Thus the separation of R and RE as well as P and NP both do not relativize but do "semi-relativize", evading all three barriers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09702v1</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baruch Garcia</dc:creator>
    </item>
    <item>
      <title>Correspondences in computational and dynamical complexity I</title>
      <link>https://arxiv.org/abs/2601.09109</link>
      <description>arXiv:2601.09109v1 Announce Type: cross 
Abstract: We begin development of a method for studying dynamical systems using concepts from computational complexity theory. We associate families of decision problems, called telic problems, to dynamical systems of a certain class. These decision problems formalize finite-time reachability questions for the dynamics with respect to natural coarse-grainings of state space. Our main result shows that complexity-theoretic lower bounds have dynamical consequences: if a system admits a telic problem for which every decider runs in time $2^{\Omega(n)}$, then it must have positive topological entropy. This result and others lead to methods for classifying dynamical systems through proving bounds on the runtime of algorithms solving their associated telic problems, or by constructing polynomial-time reductions between telic problems coming from distinct dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09109v1</guid>
      <category>math.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Everett</dc:creator>
    </item>
    <item>
      <title>On the complexity of global Roman domination problem in graphs</title>
      <link>https://arxiv.org/abs/2601.09167</link>
      <description>arXiv:2601.09167v1 Announce Type: cross 
Abstract: A Roman dominating function of a graph $G=(V,E)$ is a labeling $f: V \rightarrow{} \{0 ,1, 2\}$ such that for each vertex $u \in V$ with $f(u) = 0$, there exists a vertex $v \in N(u)$ with $f(v) =2$. A Roman dominating function $f$ is a global Roman dominating function if it is a Roman dominating function for both $G$ and its complement $\overline{G}$. The weight of $f$ is the sum of $f(u)$ over all the vertices $u \in V$. The objective of Global Roman Domination problem is to find a global Roman dominating function with minimum weight. The objective of Global Roman Domination is to compute a global Roman dominating function of minimum weight.
  In this paper, we study the algorithmic aspects of Global Roman Domination problem on various graph classes and obtain the following results.
  1. We prove that Roman domination and Global Roman Domination problems are not computationally equivalent by identifying graph classes on which one is linear-time solvable, while the other is NP-complete.
 2. We show that Global Roman Domination problem is NP-complete on split graphs, thereby resolving an open question posed by Panda and Goyal [Discrete Applied Mathematics, 2023].
  3. We prove that Global Roman Domination problem is NP-complete on chordal bipartite graphs, planar bipartite graphs with maximum degree five and circle graphs.
  4. On the positive side, we present a linear-time algorithm for Global Roman domination problem on cographs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09167v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sangam Balchandar Reddy, Arun Kumar Das, Anjeneya Swami Kare, I. Vinod Reddy</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Swish</title>
      <link>https://arxiv.org/abs/2601.09289</link>
      <description>arXiv:2601.09289v1 Announce Type: cross 
Abstract: Swish is a card game in which players are given cards having symbols (hoops and balls), and find a valid superposition of cards, called a "swish." Dailly, Lafourcade, and Marcadet (FUN 2024) studied a generalized version of Swish and showed that the problem is solvable in polynomial time with one symbol per card, while it is NP-complete with three or more symbols per card. In this paper, we resolve the previously open case of two symbols per card, which corresponds to the original game. We show that Swish is NP-complete for this case. Specifically, we prove the NP-hardness when the allowed transformations of cards are restricted to a single (horizontal or vertical) flip or 180-degree rotation, and extend the results to the original setting allowing all three transformations. In contrast, when neither transformation is allowed, we present a polynomial-time algorithm. Combining known and our results, we establish a complete characterization of the computational complexity of Swish with respect to both the number of symbols per card and the allowed transformations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09289v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Horiyama, Takehiro Ito, Jun Kawahara, Shin-ichi Minato, Akira Suzuki, Ryuhei Uehara, Yutaro Yamaguchi</dc:creator>
    </item>
    <item>
      <title>On Numbers of Simplicial Walks and Equivalent Canonizations for Graph Recognition</title>
      <link>https://arxiv.org/abs/2601.09506</link>
      <description>arXiv:2601.09506v1 Announce Type: cross 
Abstract: Two graphs are isomorphic exactly when they admit the same number of homomorphisms from every graph. Hence, a graph is recognized up to isomorphism by homomorphism counts over the class of all graphs. Restricting to a specific graph class yields some natural isomorphism relaxations and modulates recognition to particular graph properties. A notable restriction is to the classes of bounded treewidth, yielding the isomorphism relaxation of Weisfeiler--Leman refinement (WL), as shown by Dvo\v{r}\'{a}k [JGT 2010]. The properties recognized by WL are exactly those definable in fragments of first-order logic with counting quantifiers, as shown by Cai, F\"{u}rer, and Immerman [Comb. 1992].
  We characterize the restriction to the classes of bounded pathwidth by numbers of simplicial walks, and formalize it into a refinement procedure (SW). The properties recognized by SW are exactly those definable in fragments of restricted-conjunction first-order logic with counting quantifiers, introduced by Montacute and Shah [LMCS 2024].
  Unlike WL, computing SW directly is not polynomial-time in general. We address this by representing SW in terms of multiplicity automata. We equip these automata with an involution, simplifying the canonization to standard forward reduction and omitting the backward one. The resulting canonical form is computable in time $O(kn^{3k})$ for any graph on $n$ vertices and the restriction to pathwidth at most $k$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09506v1</guid>
      <category>cs.DM</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marek \v{C}ern\'y</dc:creator>
    </item>
    <item>
      <title>On complexity of substructure connectivity and restricted connectivity of graphs</title>
      <link>https://arxiv.org/abs/2110.05917</link>
      <description>arXiv:2110.05917v4 Announce Type: replace 
Abstract: The connectivity of a graph is an important parameter to evaluate its reliability. $k$-restricted connectivity (resp. $R^h$-restricted connectivity) of a graph $G$ is the minimum cardinality of a set $S$ of vertices in $G$, if exists, whose deletion disconnects $G$ and leaves each component of $G-S$ with more than $k$ vertices (resp. $\delta(G-S)\geq h$). In contrast, structure (substructure) connectivity of $G$ is defined as the minimum number of vertex-disjoint subgraphs whose deletion disconnects $G$. As generalizations of the concept of connectivity, structure (substructure) connectivity, restricted connectivity and $R^h$-restricted connectivity have been extensively studied from the combinatorial point of view. Very little is known about the computational complexity of these variants, except for the recently established NP-completeness of $k$-restricted edge-connectivity. In this paper, we prove that the problems of determining structure, substructure, restricted, and $R^h$-restricted connectivity are all NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2110.05917v4</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huazhong L\"u, Tingzeng Wu</dc:creator>
    </item>
    <item>
      <title>NP-Completeness Proofs of Puzzles using the T-Metacell Framework</title>
      <link>https://arxiv.org/abs/2508.11570</link>
      <description>arXiv:2508.11570v2 Announce Type: replace 
Abstract: Pencil puzzles are puzzles that can be solved by writing down solutions on a paper, using only logical reasoning. In this paper, we utilize the "T-metacell" framework developed by Tang and the MIT Hardness Group to prove the NP-completeness of four new pencil puzzles: Grand Tour, Entry Exit, Zahlenschlange, and Yagit. Additionally, the first three are also proven to be ASP-complete. The results demonstrate how versatile the framework is, offering new insights into the computational complexity of problems with various constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11570v2</guid>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nattapol Kiatchaipipat, Suthee Ruangwises</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of Biclique Contraction and Balanced Biclique Contraction</title>
      <link>https://arxiv.org/abs/2307.10607</link>
      <description>arXiv:2307.10607v2 Announce Type: replace-cross 
Abstract: In this work, we initiate the complexity study of Biclique Contraction and Balanced Biclique Contraction. In these problems, given as input a graph G and an integer k, the objective is to determine whether one can contract at most k edges in G to obtain a biclique and a balanced biclique, respectively. We first prove that these problems are NP-complete even when the input graph is bipartite. Next, we study the parameterized complexity of these problems and show that they admit single exponential-time FPT algorithms when parameterized by the number k of edge contractions. Then, we show that Balanced Biclique Contraction admits a quadratic vertex kernel while Biclique Contraction does not admit any polynomial compression (or kernel) under standard complexity-theoretic assumptions. We also give faster FPT algorithms for contraction to restricted bicliques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10607v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Krithika, V. K. Kutty Malu, Roohani Sharma, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Property Testing</title>
      <link>https://arxiv.org/abs/2403.02968</link>
      <description>arXiv:2403.02968v4 Announce Type: replace-cross 
Abstract: Locality is a fundamental feature of many physical time evolutions. Assumptions on locality and related structural properties also underlie recently proposed procedures for learning an unknown Hamiltonian from access to the induced time evolution. However, no protocols to rigorously test whether an unknown Hamiltonian is local were known. We investigate Hamiltonian locality testing as a property testing problem, where the task is to determine whether an unknown $n$-qubit Hamiltonian $H$ is $k$-local or $\varepsilon$-far from all $k$-local Hamiltonians, given access to the time evolution along $H$. First, we emphasize the importance of the chosen distance measure: With respect to the operator norm, a worst-case distance measure, incoherent quantum locality testers require $\tilde{\Omega}(2^n)$ many time evolution queries and an expected total evolution time of $\tilde{\Omega}(2^n / \varepsilon)$, and even coherent testers need $\Omega(2^{n/2})$ many queries and $\Omega(2^{n/2}/\varepsilon)$ total evolution time. In contrast, when distances are measured according to the normalized Frobenius norm, corresponding to an average-case distance, we give a sample-, time-, and computationally efficient incoherent Hamiltonian locality testing algorithm based on randomized measurements. In fact, our procedure can be used to simultaneously test a wide class of Hamiltonian properties beyond locality. Finally, we prove that learning a general Hamiltonian remains exponentially hard with this average-case distance, thereby establishing an exponential separation between Hamiltonian testing and learning. Our work initiates the study of property testing for quantum Hamiltonians, demonstrating that a broad class of Hamiltonian properties is efficiently testable even with limited quantum capabilities, and positioning Hamiltonian testing as an independent area of research alongside Hamiltonian learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02968v4</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Bluhm, Matthias C. Caro, Aadil Oufkir</dc:creator>
    </item>
    <item>
      <title>Epistemic Skills: Reasoning about Knowledge and Oblivion</title>
      <link>https://arxiv.org/abs/2504.01733</link>
      <description>arXiv:2504.01733v3 Announce Type: replace-cross 
Abstract: This paper presents a class of epistemic logics that captures the dynamics of acquiring knowledge and descending into oblivion, while incorporating concepts of group knowledge. The approach is grounded in a system of weighted models, introducing an ``epistemic skills'' metric to represent the epistemic capacities tied to knowledge updates. Within this framework, knowledge acquisition is modeled as a process of upskilling, whereas oblivion is represented as a consequence of downskilling. The framework further enables exploration of ``knowability'' and ``forgettability,'' defined as the potential to gain knowledge through upskilling and to lapse into oblivion through downskilling, respectively. Additionally, it supports a detailed analysis of the distinctions between epistemic de re and de dicto expressions. The computational complexity of the model checking and satisfiability problems is examined, offering insights into their theoretical foundations and practical implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.01733v3</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaolong Liang, Y\`i N. W\'ang</dc:creator>
    </item>
    <item>
      <title>Noisy Quantum Learning Theory</title>
      <link>https://arxiv.org/abs/2512.10929</link>
      <description>arXiv:2512.10929v2 Announce Type: replace-cross 
Abstract: We develop a framework for learning from noisy quantum experiments in which fault-tolerant devices access uncharacterized systems through noisy couplings. Introducing the complexity class $\textsf{NBQP}$ ("noisy BQP''), we model noisy fault-tolerant quantum computers that cannot generally error-correct the oracle systems they query. Using this class, we prove that while noise can eliminate the exponential quantum learning advantages of unphysical, noiseless learners, a superpolynomial gap remains between $\textsf{NISQ}$ and fault-tolerant devices. Turning to canonical learning tasks in noisy settings, we find that the exponential two-copy advantage for purity testing collapses under local depolarizing noise. Nevertheless, we identify a setting motivated by AdS/CFT in which noise-resilient physical structure restores this quantum learning advantage. We then analyze noisy Pauli shadow tomography, deriving lower bounds characterizing how instance size, quantum memory and noise jointly control sample complexity, and design algorithms with parametrically matching scalings. We study similar tradeoffs in quantum metrology, and show that the Heisenberg-limited sensitivity of existing error-correction-based protocols persists only up to a timescale inverse-polynomial in the error rate per probe qubit. Together, our results demonstrate that the primitives underlying quantum-enhanced experiments are fundamentally fragile to noise, and that realizing meaningful quantum advantages in future experiments will require interfacing noise-robust physical properties with available algorithmic techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.10929v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jordan Cotler, Weiyuan Gong, Ishaan Kannan</dc:creator>
    </item>
  </channel>
</rss>
