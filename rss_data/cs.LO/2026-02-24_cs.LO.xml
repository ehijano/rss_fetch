<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Feb 2026 05:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>DSLean: A Framework for Type-Correct Interoperability Between Lean 4 and External DSLs</title>
      <link>https://arxiv.org/abs/2602.18657</link>
      <description>arXiv:2602.18657v1 Announce Type: new 
Abstract: Domain-specific languages (DSLs) mediate interactions between interactive proof assistants and external automation, but translating between the prover's internal representation and such DSLs is a tedious engineering chore. To simplify this task, we present DSLean, a framework for bidirectional translation between expressions in the Lean proof assistant and external syntax. DSLean requires only a specification of an external language and its Lean equivalents, abstracting away meta-level implementation details. We demonstrate DSLean's capabilities by implementing three new automation tactics, providing access to external solvers for interval arithmetic, ordinary differential equations, and ring ideal membership.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18657v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tate Rowney, Riyaz Ahuja, Jeremy Avigad, Sean Welleck</dc:creator>
    </item>
    <item>
      <title>Nazrin: Atomic Tactics for Graph Neural Networks for Theorem Proving in Lean 4</title>
      <link>https://arxiv.org/abs/2602.18767</link>
      <description>arXiv:2602.18767v1 Announce Type: new 
Abstract: In Machine-Assisted Theorem Proving, a theorem proving agent searches for a sequence of expressions and tactics that can prove a conjecture in a proof assistant.
  In this work, we introduce several novel concepts and capabilities to address obstacles faced by machine-assisted theorem proving. We first present a set of \textbf{atomic tactics}, a small finite set of tactics capable of proving any provable statement in Lean. We then introduce a \textbf{transposing atomization} algorithm which turns arbitrary proof expressions into a series of atomic tactics. We next introduce the \textbf{ExprGraph} data structure, which provides a succinct representation for Lean expressions. Finally, we present the \textbf{Nazrin Prover}, a graph neural network-based theorem proving agent using atomic tactics and ExprGraph. Nazrin circumvents many challenges faced by existing proving agents by exclusively dispatching atomic tactics, and it is robust enough to both train and evaluate on consumer-grade hardware. We demonstrate the potential of tools like Nazrin using theorems from Lean's standard library and from Mathlib.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18767v1</guid>
      <category>cs.LO</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leni Aniva, Iori Oikawa, David Dill, Clark Barrett</dc:creator>
    </item>
    <item>
      <title>When Agda met Vampire</title>
      <link>https://arxiv.org/abs/2602.18844</link>
      <description>arXiv:2602.18844v1 Announce Type: new 
Abstract: Dependently-typed proof assistants furnish expressive foundations for mechanised mathematics and verified software. However, automation for these systems has been either modest in scope or complex in implementation. We aim to improve the situation by integrating proof assistants with automated theorem provers (ATPs) in a simple way, while preserving the correctness guarantees of the former. A central difficulty arises from the fact that most ATPs operate in classical first-order logic, whereas these proof assistants are grounded in constructive dependent type theory. We identify an expressive fragment of both languages -- essentially equational Horn -- that admits sound, straightforward translations in both directions. The approach produces a prototype system for Agda forwarding proof obligations to the ATP Vampire, then transforming the resulting classical proof into a constructive proof term that Agda can type-check. The prototype automatically derives proofs concerning the properties of a complex field equipped with roots of unity, which took professional Agda developers two full days to complete. The required engineering effort is modest, and we anticipate that the methodology will extend readily to other ATPs and proof assistants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18844v1</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Artjoms \v{S}inkarovs, Michael Rawson</dc:creator>
    </item>
    <item>
      <title>Constructing (Co)inductive Types via Large Sizes</title>
      <link>https://arxiv.org/abs/2602.18921</link>
      <description>arXiv:2602.18921v1 Announce Type: new 
Abstract: To ensure decidability and consistency of its type theory, a proof assistant should only accept terminating recursive functions and productive corecursive functions. Most proof assistants enforce this through syntactic conditions, which can be restrictive and non-modular. Sized types are a type-based alternative where (co)inductive types are annotated with additional size information. Well-founded induction on sizes can then be used to prove termination and productivity. An implementation of sized types exists in Agda, but it is currently inconsistent due to the addition of a largest size. We investigate an alternative approach, where intensional type theory is extended with a large type of sizes and parametric quantifiers over sizes. We show that inductive and coinductive types can be constructed in this theory, which improves on earlier work where this was only possible for the finitely-branching inductive types. The consistency of the theory is justified by an impredicative realisability model, which interprets the type of sizes as an uncountable ordinal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18921v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benno van den Berg, Bastiaan Laarakker, Dani\"el Otten</dc:creator>
    </item>
    <item>
      <title>A Relational Theory of Grounding and a new Grounder for SMT</title>
      <link>https://arxiv.org/abs/2602.19102</link>
      <description>arXiv:2602.19102v1 Announce Type: new 
Abstract: Satisfiability Modulo Theories (SMT) specifications often rely on quantifiers to remain concise and declarative. However, checking the satisfiability of such specifications directly can be inefficient. A common optimization is to ground the specification - that is, to expand quantified formulas into equivalent variable-free formulas. While dedicated tools known as grounders are a cornerstone of Answer Set Programming (ASP) solvers, they are are largely absent from SMT solving workflows. As a result, users frequently resort to writing ad-hoc, error-prone code to perform this transformation.
  In this work, I propose a theoretical framework for grounding first order logic formulas with aggregates, based on relational algebra. Within this framework, I formulate a method for efficiently grounding such formulas. Remarkably, the method allows certain formulas that quantify over infinite domains to be transformed into equivalent formulas of finite size.
  I have implemented this method in a new SMT-LIB grounder, called xmt-lib. It leverages an embedded relational database (SQLite) to execute relational operations efficiently. An evaluation on a public benchmark for grounders demonstrates that xmt-lib significantly improves the performance of the Z3 SMT solver compared to its purely declarative use, and makes it com</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19102v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Carbonnelle</dc:creator>
    </item>
    <item>
      <title>Hypersequent Calculi Have Ackermannian Complexity</title>
      <link>https://arxiv.org/abs/2602.19229</link>
      <description>arXiv:2602.19229v1 Announce Type: new 
Abstract: For substructural logics with contraction or weakening admitting cut-free sequent calculi, proof search was analyzed using well-quasi-orders on $\mathbb{N}^d$ (Dickson's lemma), yielding Ackermannian upper bounds via controlled bad-sequence arguments. For hypersequent calculi, that argument lifted the ordering to the powerset, since a hypersequent is a (multi)set of sequents. This induces a jump from Ackermannian to hyper-Ackermannian complexity in the fast-growing hierarchy, suggesting that cut-free hypersequent calculi for extensions of the commutative Full Lambek calculus with contraction or weakening ($\mathbf{FL_{ec}}$/$\mathbf{FL_{ew}}$) inherently entail hyper-Ackermannian upper bounds. We show that this intuition does not hold: every extension of $\mathbf{FL_{ec}}$ and $\mathbf{FL_{ew}}$ admitting a cut-free hypersequent calculus has an Ackermannian upper bound on provability.
  To avoid the powerset, we exploit novel dependencies between individual sequents within any hypersequent in backward proof search. The weakening case, in particular, introduces a Karp-Miller style acceleration, and it improves the upper bound for the fundamental fuzzy logic $\mathbf{MTL}$. Our Ackermannian upper bound is optimal for the contraction case (realized by the logic $\mathbf{FL_{ec}}$).</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19229v1</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. R. Balasubramanian, Vitor Greati, Revantha Ramanayake</dc:creator>
    </item>
    <item>
      <title>Towards Proving Liveness on Weak Memory (Extended Version)</title>
      <link>https://arxiv.org/abs/2602.19609</link>
      <description>arXiv:2602.19609v1 Announce Type: new 
Abstract: Reasoning about concurrent programs executed on weak memory models is an inherently complex task. So far, existing proof calculi for weak memory models only cover safety properties. In this paper, we provide the first proof calculus for reasoning about liveness. Our proof calculus is based on Manna and Pnueli's proof rules for response under weak fairness, formulated in linear temporal logic. Our extension includes the incorporation of memory fairness into rules as well as the usage of ranking functions defined over weak memory state. We have applied our reasoning technique to the Ticket lock algorithm and have proved it to guarantee starvation freedom under memory models Release-Acquire and StrongCoherence for any number of concurrent threads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19609v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lara Bargmann, Heike Wehrheim</dc:creator>
    </item>
    <item>
      <title>Identifying and Explaining (Non-)Equivalence of First-Order Logic Formulas</title>
      <link>https://arxiv.org/abs/2602.19673</link>
      <description>arXiv:2602.19673v1 Announce Type: new 
Abstract: First-order logic is the basis for many knowledge representation formalisms and methods. Providing technological support for learning to write first-order formulas for natural language specifications requires methods to test formulas for (non-)equivalence and to provide explanations for non-equivalence. We propose such methods based on both theoretical insights and existing tools, implement them, and report on experiments testing their effectiveness on a large educational data set with &gt; 100.000 pairs of first-order formulas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19673v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabian Vehlken, Thomas Zeume, Emilio Carrasco Bustamante, Ma\"elle Corn\'ely, Lukas Pradel</dc:creator>
    </item>
    <item>
      <title>Layered Monoidal Theories I: Diagrammatic Algebra and Applications</title>
      <link>https://arxiv.org/abs/2602.19776</link>
      <description>arXiv:2602.19776v1 Announce Type: new 
Abstract: We develop layered monoidal theories -- a generalisation of monoidal theories combining formal descriptions of a system at different levels of abstraction. Via their representation as string diagrams, monoidal theories provide a graphical formalism to reason algebraically about information flow in models across different fields of science. Layered monoidal theories allow mixing several monoidal theories (together with translations between them) within the same string diagram, while retaining mathematical precision and semantic interpretability. We develop the mathematical foundations of layered monoidal theories, as well as providing several instances of our approach, including digital and electrical circuits, quantum processes, chemical reactions, concurrent processes, and probability theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19776v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Leo Lobski, Fabio Zanasi</dc:creator>
    </item>
    <item>
      <title>String Diagrams for Monoidal Categories, in Rocq</title>
      <link>https://arxiv.org/abs/2602.19806</link>
      <description>arXiv:2602.19806v1 Announce Type: new 
Abstract: We present a Rocq library for monoidal categories, which includes a decision procedure for proving equality of morphisms as well as notations that make it possible to reason as if they were strict, inferring MacLane isomorphims automatically in the background. Together with an external tool for visualising and editing string diagrams, this make it possible to perform rewriting steps in monoidal categories graphically, and to translate them into textual formal proofs which are concise and readable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19806v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Pous (PLUME, LIP)</dc:creator>
    </item>
    <item>
      <title>noDice: Inference for Discrete Probabilistic Programs with Nondeterminism and Conditioning</title>
      <link>https://arxiv.org/abs/2602.20049</link>
      <description>arXiv:2602.20049v1 Announce Type: new 
Abstract: Probabilistic programming languages (PPLs) are an expressive and intuitive means of representing complex probability distributions. In that realm, languages like Dice target an important class of probabilistic programs: those whose probability distributions are discrete. Discrete distributions are common in many fields, including text analysis, network verification, artificial intelligence, and graph analysis. Another important feature in the world of probabilistic modeling are nondeterministic choices as found in Markov Decision Processes (MDPs) which play a major role in reinforcement learning. Modern PPLs usually lack support for nondeterminism. We address this gap with the introduction of noDice, which extends the discrete probabilistic inference engine Dice. noDice performs inference on loop-free programs by constructing an MDP so that the distributions modeled by the program correspond to schedulers in the MDP. Furthermore, decision diagrams are used as an intermediate step to exploit the program structure and drastically reduce the state space of the MDP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20049v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tobias G\"urtler, Benjamin Lucien Kaminski</dc:creator>
    </item>
    <item>
      <title>Higher-order circuits</title>
      <link>https://arxiv.org/abs/2602.18701</link>
      <description>arXiv:2602.18701v1 Announce Type: cross 
Abstract: We write down a series of basic laws for (strict) higher-order circuit diagrams. More precisely, we define higher-order circuit theories in terms of: (a) nesting, (b) temporal and spatial composition, and (c) equivalence between lower-order bipartite processes and higher-order bipartite states. In category-theoretic terms, these laws are expressed using enrichment and cotensors in symmetric polycategories, along with a frobenius-like coherence between them. We describe how these laws capture the salient features of higher-order quantum theory, and discover an upper bound for higher-order circuits: any higher-order circuit theory embeds into the theory of strong profunctors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18701v1</guid>
      <category>quant-ph</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matt Wilson</dc:creator>
    </item>
    <item>
      <title>What Distributed Computing Got Wrong: The Category Mistake That Turned Design Choices into Laws of Nature</title>
      <link>https://arxiv.org/abs/2602.18723</link>
      <description>arXiv:2602.18723v1 Announce Type: cross 
Abstract: The foundational impossibility results of distributed computing -- the Fischer-Lynch-Paterson theorem, the Two Generals Problem, the CAP theorem -- are widely understood as discoveries about the physical limits of coordination. This paper argues that they are nothing of the sort. They are consequences of a category mistake: treating Forward-In-Time-Only (FITO) information flow as a law of nature rather than recognizing it as a design choice inherited from Shannon's channel model and Lamport's happened-before relation. We develop this argument in six steps. First, we introduce the category mistake framework from Ryle through Spekkens' ontic/epistemic distinction in quantum foundations. Second, we identify FITO as the hidden axiom that unifies the classical impossibility results. Third, we apply Spekkens' Leibnizian principle to show that FITO-based models contain surplus ontological structure. Fourth, we develop the counterfactual: what changes when FITO is dropped. Fifth, we demonstrate that the impossibility theorems are theorems about FITO systems, not about physics. Sixth, we sketch the transactional alternative -- bilateral interactions that dissolve the apparent impossibilities by replacing unidirectional message passing with atomic bilateral transactions. The implication is that distributed computing has spent fifty years optimizing within the wrong design space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18723v1</guid>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <category>quant-ph</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paul Borrill</dc:creator>
    </item>
    <item>
      <title>Reasoning Capabilities of Large Language Models. Lessons Learned from General Game Playing</title>
      <link>https://arxiv.org/abs/2602.19160</link>
      <description>arXiv:2602.19160v1 Announce Type: cross 
Abstract: This paper examines the reasoning capabilities of Large Language Models (LLMs) from a novel perspective, focusing on their ability to operate within formally specified, rule-governed environments. We evaluate four LLMs (Gemini 2.5 Pro and Flash variants, Llama 3.3 70B and GPT-OSS 120B) on a suite of forward-simulation tasks-including next / multistep state formulation, and legal action generation-across a diverse set of reasoning problems illustrated through General Game Playing (GGP) game instances. Beyond reporting instance-level performance, we characterize games based on 40 structural features and analyze correlations between these features and LLM performance. Furthermore, we investigate the effects of various game obfuscations to assess the role of linguistic semantics in game definitions and the impact of potential prior exposure of LLMs to specific games during training. The main results indicate that three of the evaluated models generally perform well across most experimental settings, with performance degradation observed as the evaluation horizon increases (i.e., with a higher number of game steps). Detailed case-based analysis of the LLM performance provides novel insights into common reasoning errors in the considered logic-based problem formulation, including hallucinated rules, redundant state facts, or syntactic errors. Overall, the paper reports clear progress in formal reasoning capabilities of contemporary models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19160v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maciej \'Swiechowski, Adam \.Zychowski, Jacek Ma\'ndziuk</dc:creator>
    </item>
    <item>
      <title>NILE: Formalizing Natural-Language Descriptions of Formal Languages</title>
      <link>https://arxiv.org/abs/2602.19743</link>
      <description>arXiv:2602.19743v1 Announce Type: cross 
Abstract: This paper explores how natural-language descriptions of formal languages can be compared to their formal representations and how semantic differences can be explained. This is motivated from educational scenarios where learners describe a formal language (presented, e.g., by a finite state automaton, regular expression, pushdown automaton, context-free grammar or in set notation) in natural language, and an educational support system has to (1) judge whether the natural-language description accurately describes the formal language, and to (2) provide explanations why descriptions are not accurate.
  To address this question, we introduce a representation language for formal languages, Nile, which is designed so that Nile expressions can mirror the syntactic structure of natural-language descriptions of formal languages. Nile is sufficiently expressive to cover a broad variety of formal languages, including all regular languages and fragments of context-free languages typically used in educational contexts. Generating Nile expressions that are syntactically close to natural-language descriptions then allows to provide explanations for inaccuracies in the descriptions algorithmically.
  In experiments on an educational data set, we show that LLMs can translate natural-language descriptions into equivalent, syntactically close Nile expressions with high accuracy - allowing to algorithmically provide explanations for incorrect natural-language descriptions. Our experiments also show that while natural-language descriptions can also be translated into regular expressions (but not context-free grammars), the expressions are often not syntactically close and thus not suitable for providing explanations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19743v1</guid>
      <category>cs.FL</category>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tristan Kneisel, Marko Schmellenkamp, Fabian Vehlken, Thomas Zeume</dc:creator>
    </item>
    <item>
      <title>Combining Small-Step and Big-Step Semantics to Verify Loop Optimizations</title>
      <link>https://arxiv.org/abs/2602.19868</link>
      <description>arXiv:2602.19868v1 Announce Type: cross 
Abstract: Verified compilers aim to guarantee that compilation preserves the observable behavior of source programs. While small-step semantics are widely used in such compilers, they are not always the most convenient framework for structural transformations such as loop optimizations. This paper proposes an approach that leverages both small-step and big-step semantics: small-step semantics are used for local transformations, while big-step semantics are employed for structural transformations. An abstract behavioral semantics is introduced as a common interface between the two styles. Coinductive big-step semantics is extended to correctly handle divergence with both finite and infinite traces, bringing it on par with the expressiveness of small-step semantics. This enables the insertion of big-step transformations into the middle of an existing small-step pipeline, thereby fully preserving all top-level semantic preservation theorems. This approach is practically demonstrated in CompCert by implementing and verifying a few new loop optimizations in big-step Cminor, including loop unswitching and, notably, full loop unrolling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19868v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Knothe, Oliver Bringmann</dc:creator>
    </item>
    <item>
      <title>Axis Decomposition for ODRL: Resolving Dimensional Ambiguity in Policy Constraints through Interval Semantics</title>
      <link>https://arxiv.org/abs/2602.19878</link>
      <description>arXiv:2602.19878v1 Announce Type: cross 
Abstract: Every ODRL 2.2 constraint compares a single scalar value: (leftOperand, operator, rightOperand). Five of ODRL's approximately 34 left operands, however, denote multi-dimensional quantities--image dimensions, canvas positions, geographic coordinates--whose specification text explicitly references multiple axes. For these operands, a single scalar constraint admits one interpretation per axis, making policy evaluation non-deterministic.
  We classify ODRL's left operands by value-domain structure (scalar, dimensional, concept-valued), grounded in the ODRL 2.2 specification text, and show that dimensional ambiguity is intrinsic to the constraint syntax.
  We present an axis-decomposition framework that refines each dimensional operand into axis-specific scalar operands and prove four properties: deterministic interpretation, AABB completeness, sound over-approximation under projection, and conservative extension.
  Conflict detection operates in two layers: per-axis verdicts are always decidable; box-level verdicts compose through Strong Kleene conjunction into a three-valued logic (Conflict, Compatible, Unknown). For ODRL's disjunctive (odrl:or) and exclusive-or (odrl:xone) logical constraints, where per-axis decomposition does not apply, the framework encodes coupled multi-axis conjectures directly.
  We instantiate the framework as the ODRL Spatial Axis Profile--15 axis-specific left operands for the five affected base terms--and evaluate it on 117 benchmark problems spanning nine categories across both TPTP FOF (Vampire) and SMT-LIB (Z3) encodings, achieving full concordance between provers. Benchmark scenarios are inspired by constraints arising in cultural heritage dataspaces such as Datenraum Kultur. All meta-theorems are mechanically verified in Isabelle/HOL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19878v1</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daham Mustafa, Diego Collarana, Yixin Peng, Rafiqul Haque, Christoph Lange-Bever, Christoph Quix, Stephan Decker</dc:creator>
    </item>
    <item>
      <title>Denotational Semantics for ODRL: Knowledge-Based Constraint Conflict Detection</title>
      <link>https://arxiv.org/abs/2602.19883</link>
      <description>arXiv:2602.19883v1 Announce Type: cross 
Abstract: ODRL's six set-based operators -- isA, isPartOf, hasPart, isAnyOf, isAllOf, isNoneOf -- depend on external domain knowledge that the W3C specification leaves unspecified. Without it, every cross-dataspace policy comparison defaults to Unknown. We present a denotational semantics that maps each ODRL constraint to the set of knowledge-base concepts satisfying it. Conflict detection reduces to denotation intersection under a three-valued verdict -- Conflict, Compatible, or Unknown -- that is sound under incomplete knowledge. The framework covers all three ODRL composition modes (and, or, xone) and all three semantic domains arising in practice: taxonomic (class subsumption), mereological (part-whole containment), and nominal (identity). For cross-dataspace interoperability, we define order-preserving alignments between knowledge bases and prove two guarantees: conflicts are preserved across different KB standards, and unmapped concepts degrade gracefully to Unknown -- never to false conflicts. A runtime soundness theorem ensures that design-time verdicts hold for all execution contexts. The encoding stays within the decidable EPR fragment of first-order logic. We validate it with 154 benchmarks across six knowledge base families (GeoNames, ISO 3166, W3C DPV, a GDPR-derived taxonomy, BCP 47, and ISO 639-3) and four structural KBs targeting adversarial edge cases. Both the Vampire theorem prover and the Z3 SMT solver agree on all 154 verdicts. A key finding is that exclusive composition (xone) requires strictly stronger KB axioms than conjunction or disjunction: open-world semantics blocks exclusivity even when positive evidence appears to satisfy exactly one branch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19883v1</guid>
      <category>cs.CL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daham Mustafa, Diego Collarana, Yixin Peng, Rafiqul Haque, Christoph Lange-Bever, Christoph Quix, Stephan Decker</dc:creator>
    </item>
    <item>
      <title>Parallelism and Adaptivity in Student-Teacher Witnessing</title>
      <link>https://arxiv.org/abs/2602.19934</link>
      <description>arXiv:2602.19934v1 Announce Type: cross 
Abstract: Student-Teacher Games are a model of computation in which a computationally restricted Student attempts to produce a string satisfying a refutable property, while an all-powerful Teacher refutes incorrect candidates by providing counterexamples. By the classical result of Kraj\'i\v{c}ek, Pudl\'ak, and Takeuti [KPT90], such games capture the witnessing of $\forall\exists\forall$-formulas in bounded arithmetic. In this paper, we introduce subclasses of total search problems in the polynomial hierarchy, classified by the number of rounds and candidate answers per round required for a Student at the corresponding level to solve them. Assuming the polynomial hierarchy does not collapse, we separate these classes for different number of rounds and queries. As applications we obtain the following results:
  (a) We study theories of bounded arithmetic axiomatized by fine-grained variants of length induction and bounded collection. We prove a general witnessing theorem connecting their $\forall\exists\forall$-consequences to the appropriate classes of Student-Teacher Games. Under the non-collapse of the polynomial hierarchy, we separate these theories.
  (b) These conditional separations resolve two open problems in bounded arithmetic: one by Buss and Ressayre [Bus85, CK93] on the strength of bounded collection, and one by Pollett [Pol97] on the difference between strict and non-strict double length induction.
  (c) Finally, we extend the unprovability of circuit upper bounds due to Kraj\'i\v{c}ek and Oliveira [KO17] to the theory $PV_1+BB(\Sigma^b_1)$, and the unprovability of strong co-nondeterministic circuit lower bounds due to Pich and Santhanam [PS21] to the theory $PV_1+LLIND(s\Sigma^b_1)$. By the preceding separations, both theories strictly extend $PV_1$ assuming $NP\nsubseteq P/poly$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19934v1</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ond\v{r}ej Je\v{z}il, Dimitrios Tsintsilidas</dc:creator>
    </item>
    <item>
      <title>Discernment is all you need</title>
      <link>https://arxiv.org/abs/2602.20038</link>
      <description>arXiv:2602.20038v1 Announce Type: cross 
Abstract: We explore the expressive power of HOL, a system of higher-order logic, and its relationship to the simply-typed lambda calculus and Church's simple theory of types, arguing for the potential of HOL as a unifying logical framework, capable of encoding a broad range of logical systems, including modal and non-classical logics. Along the way, we emphasize the essential role of discernment, the ability to tell things apart, as a language primitive; highlighting how it endows HOL with practical expressivity superpowers while elegantly enriching its theoretical properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20038v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Fuenmayor</dc:creator>
    </item>
    <item>
      <title>Verifying the Hashgraph Consensus Algorithm</title>
      <link>https://arxiv.org/abs/2102.01167</link>
      <description>arXiv:2102.01167v2 Announce Type: replace 
Abstract: The Hashgraph consensus algorithm is an algorithm for asynchronous Byzantine fault tolerance intended for distributed shared ledgers. Its main distinguishing characteristic is it achieves consensus without exchanging any extra messages; each participant's votes can be determined from public information, so votes need not be transmitted.
  In this paper, we discuss our experience formalizing the Hashgraph algorithm and its correctness proof using the Rocq proof assistant. The paper is self-contained; it includes a complete discussion of the algorithm and its correctness argument in English.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.01167v2</guid>
      <category>cs.LO</category>
      <category>cs.DC</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karl Crary</dc:creator>
    </item>
    <item>
      <title>Paraconsistent Belief Revision: A Replacement-Enriched LFI for Epistemic Entrenchment</title>
      <link>https://arxiv.org/abs/2412.06117</link>
      <description>arXiv:2412.06117v3 Announce Type: replace 
Abstract: We further develop the formal foundations of Paraconsistent Belief Revision (PBR) by introducing Logics of Formal Inconsistency (LFIs) specifically designed to support the development of epistemic entrenchment-based models for belief change. The interpretation of formal consistency -- and, more broadly, of paraconsistency -- in terms of the epistemic attitudes adopted by rational agents and of these agents reasoning with potentially contradictory yet non-trivial epistemic states, respectively, is already well-established within the literature on PBR based on LFIs. However, previous approaches faced a key limitation: the absence of replacement in most LFIs prevented the construction of entrenchment-based operations. We address this gap by first revisiting and systematizing core properties essential for such modeling, formalizing them within Cbr, a previously introduced logic whose foundational properties we now examine and develop in depth. Building on this, we introduce RCbr, a replacement-enriched, self-extensional extension of Cbr, which makes it possible -- within an LFI-based framework -- to formally define epistemic entrenchment and to construct entrenchment-based belief revision mechanisms. This development enables a fully constructive approach to Belief Revision in paraconsistent settings, further advancing the theoretical treatment of LFIs and paraconsistency within the broader landscape of epistemic states and belief dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06117v3</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marcelo E. Coniglio, Martin Figallo, Rafael R. Testa</dc:creator>
    </item>
    <item>
      <title>The Complexity of HyperQPTL</title>
      <link>https://arxiv.org/abs/2412.07341</link>
      <description>arXiv:2412.07341v3 Announce Type: replace 
Abstract: HyperQPTL and HyperQPTL$^+$ are expressive specification languages for hyperproperties, properties that relate multiple executions of a system. Tight complexity bounds are known for HyperQPTL finite-state satisfiability and model-checking. Here, we settle the complexity of satisfiability for HyperQPTL as well as satisfiability, finite-state satisfiability, and model-checking for HyperQPTL$^+$: the former is $\Sigma^2_1$-complete, the latter are all equivalent to truth in third-order arithmetic, i.e., all four are very undecidable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07341v3</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ga\"etan Regaud, Martin Zimmermann</dc:creator>
    </item>
    <item>
      <title>A No-go Theorem for Coalgebraic Product Construction</title>
      <link>https://arxiv.org/abs/2504.06592</link>
      <description>arXiv:2504.06592v5 Announce Type: replace 
Abstract: Verifying traces of systems is a central topic in formal verification. We study model checking of Markov chains (MCs) against temporal properties represented as (finite) automata. For instance, given an MC and a deterministic finite automaton (DFA), a simple but practically useful model checking problem asks for the probability of (terminating) traces accepted by the DFA, which can be computed via a product MC of the given MC and DFA and reduced to a simple reachability problem.
  Recently, Watanabe, Junges, Rot, and Hasuo proposed coalgebraic product constructions, a categorical framework that uniformly explains such coalgebraic constructions using distributive laws. This framework covers a range of instances, including the model checking of MCs against DFAs.
  In this paper, on top of their framework we first present a no-go theorem for product constructions, showing a case when we cannot do product constructions for model checking. Specifically, we show that there are no coalgebraic product MCs of MCs and nondeterministic finite automata for computing the probability of the accepting traces. The proof relies on a characterisation of natural transformations between certain functors that determine the type of branching, including nondeterministic or probabilistic branching.
  Second, we present a coalgebraic product construction of MCs and multiset finite automata (MFAs) as a new instance within our framework. This construction addresses a model checking problem that asks for the expected number of accepting runs on MFAs over traces of MCs. We show that this problem is solvable in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06592v5</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mayuko Kori, Kazuki Watanabe</dc:creator>
    </item>
    <item>
      <title>Generative Logic: A New Computer Architecture for Deterministic Reasoning and Knowledge Generation</title>
      <link>https://arxiv.org/abs/2508.00017</link>
      <description>arXiv:2508.00017v3 Announce Type: replace 
Abstract: We present Generative Logic (GL), a deterministic architecture that starts from user-supplied axiomatic definitions, written in a minimalist Mathematical Programming Language (MPL), and systematically explores a configurable region of their deductive neighborhood. A defining feature of the architecture is its unified hash-based inference engine, which executes both algebraic manipulations and deterministic logical transformations. Definitions are compiled into a distributed grid of simple Logic Blocks (LBs) that exchange messages; whenever the premises of an inference rule unify, a new fact is emitted with full provenance to its sources, yielding replayable, auditable proof graphs. Experimental validation is performed on Elementary Number Theory (ENT) utilizing a batched execution strategy. Starting from foundational axioms and definitions, the system first develops first-order Peano arithmetic, which is subsequently applied to autonomously derive and prove Gauss's summation formula as a main result. To manage combinatorial explosion, GL algorithmically enumerates conjectures and applies normalization, type constraints, and counterexample (CE) filtering. On commodity hardware, an end-to-end run completes in under 7 minutes. Generated proofs export as navigable HTML so that every inference step can be inspected independently. We outline a hardware-software co-design path toward massively parallel realizations and describe future integration with large language models (LLMs) for auto-formalization and conjecture seeding. The Python, C++, and MPL code to reproduce these experiments, along with the full proof graphs in HTML as well as machine-readable text format, are available in the project's GitHub repository at github.com/Generative-Logic/GL commit 1771330 and are permanently archived at doi:10.5281/zenodo.17206386.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00017v3</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolai Sergeev</dc:creator>
    </item>
    <item>
      <title>Interpolation in Classical Propositional Logic</title>
      <link>https://arxiv.org/abs/2508.11449</link>
      <description>arXiv:2508.11449v2 Announce Type: replace 
Abstract: We introduce Craig interpolation and related notions such as uniform interpolation, Beth definability, and theory decomposition in classical propositional logic. We present four approaches to computing interpolants: via quantifier elimination, from formulas in disjunctive normal form, and by extraction from resolution or tableau refutations. We close with a discussion of the size of interpolants and links to circuit complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11449v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Koopmann, Christoph Wernhard, Frank Wolter</dc:creator>
    </item>
    <item>
      <title>Strong Normalization for the Safe Fragment of a Minimal Rewrite Calculus: A Triple-Lexicographic Proof and a Conjecture on Full-Termination Limits for Pure Recursive Calculi (PRC)</title>
      <link>https://arxiv.org/abs/2512.00081</link>
      <description>arXiv:2512.00081v4 Announce Type: replace 
Abstract: We introduce Pure Recursive Calculi (PRC): finite, operator-only rewrite calculi with no variable binding, no external memory, no imported axioms, and an unrestricted step-duplicating recursor. We study KO7, a minimal witness system (7 constructors, 8 rules) designed to isolate the duplication barrier while remaining auditable. In the full relation, a non-local-join witness at eqW void void shows that unrestricted confluence is unavailable. We therefore define a guarded fragment, SafeStep, and prove strong normalization via a computable triple-lex measure (deltaFlag, kappa^M, tau). The proof is rule-by-rule and mechanized: rec-succ is discharged by a strict deltaFlag drop, rec-zero by a Dershowitz-Manna multiset decrease on kappa^M, and tie branches (including merge-cancel and guarded eqW cases) by tau. From this measure we derive a certified normalizer and prove totality and soundness. We then formalize a Newman engine for SafeStep, discharge the local-join hypothesis in the artifact, and obtain unconditional confluence and unique normal forms for the safe fragment. To characterize limits of internal termination proving under duplication, we report fourteen failed strategy families (twelve machine-checked, two meta-theoretical). These include additive and simple lexicographic counters, polynomial and weight-based interpretations, flag-only and depth-only rankings, naive multisets, local patch lemmas, and unrestricted recursion barriers; path-order methods are treated separately because they rely on imported subterm principles. We also connect safe-fragment normalization to fixed-target reachability via a normalize-and-compare decision pattern under confluence. These results motivate a conjecture: for PRCs with unrestricted step duplication, no internally definable method currently known proves full-calculus termination without importing external structural principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.00081v4</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moses Rahnama</dc:creator>
    </item>
    <item>
      <title>Positional $\omega$-regular languages</title>
      <link>https://arxiv.org/abs/2401.15384</link>
      <description>arXiv:2401.15384v4 Announce Type: replace-cross 
Abstract: In the context of two-player games over graphs, a language $L$ is called positional if, in all games using $L$ as winning objective, the protagonist can play optimally using positional strategies, that is, strategies that do not depend on the history of the play. In this work, we describe the class of parity automata recognising positional languages, providing a complete characterisation of positionality for $\omega$-regular languages. As corollaries, we establish decidability of positionality in polynomial time, finite-to-infinite and 1-to-2-players lifts, and show the closure under union of prefix-independent positional objectives, answering a conjecture by Kopczy\'nski in the $\omega$-regular case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.15384v4</guid>
      <category>cs.FL</category>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.46298/theoretics.26.5</arxiv:DOI>
      <arxiv:journal_reference>TheoretiCS, Volume 5 (2026), Article 5, 1-109</arxiv:journal_reference>
      <dc:creator>Antonio Casares, Pierre Ohlmann</dc:creator>
    </item>
    <item>
      <title>Empirical Measures and Strong Laws of Large Numbers in Categorical Probability</title>
      <link>https://arxiv.org/abs/2503.21576</link>
      <description>arXiv:2503.21576v2 Announce Type: replace-cross 
Abstract: The Glivenko--Cantelli theorem is a uniform version of the strong law of large numbers. It states that for every IID sequence of random variables, the empirical measure converges to the underlying distribution (in the sense of uniform convergence of the CDF). In this work, we provide tools to study such limits of empirical measures in categorical probability. We propose two axioms, namely permutation invariance and empirical adequacy, that a morphism of type $X^{\mathbb{N}} \to X$ should satisfy to be interpretable as taking an infinite sequence as input and producing a sample from its empirical measure as output. Since not all sequences have a well-defined empirical measure, such \emph{empirical sampling morphisms} live in quasi-Markov categories, which, unlike Markov categories, allow for partial morphisms.
  Given an empirical sampling morphism and a few other properties, we prove representability as well as abstract versions of the de Finetti theorem, the Glivenko--Cantelli theorem and the strong law of large numbers.
  We provide several concrete constructions of empirical sampling morphisms as partially defined Markov kernels on standard Borel spaces. Instantiating our abstract results then recovers the standard Glivenko--Cantelli theorem and the strong law of large numbers for random variables with finite first moment. Our work thus provides a joint proof of these two theorems in conjunction with the de Finetti theorem from first principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21576v2</guid>
      <category>math.PR</category>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Fritz, Tom\'a\v{s} Gonda, Antonio Lorenzin, Paolo Perrone, Areeb Shah Mohammed</dc:creator>
    </item>
    <item>
      <title>Generalised M\"obius Categories and Convolution Kleene Algebras</title>
      <link>https://arxiv.org/abs/2509.00168</link>
      <description>arXiv:2509.00168v2 Announce Type: replace-cross 
Abstract: Convolution algebras on maps from structures such as monoids, groups or categories into semirings, rings or fields abound in mathematics and the sciences. Of special interest in computing are convolution algebras based on variants of Kleene algebras, which are additively idempotent semirings equipped with a Kleene star. Yet an obstacle to the construction of convolution Kleene algebras on a wide class of structures has so far been the definition of a suitable star. We show that a generalisation of M\"obius categories combined with a generalisation of a classical definition of a star for formal power series allow such a construction. We discuss several instances of this construction on generalised M\"obius categories: convolution Kleene algebras with tests, modal convolution Kleene algebras, concurrent convolution Kleene algebras and higher convolution Kleene algebras (e.g. on strict higher categories and higher relational monoids). These are relevant to the verification of weighted and probabilistic sequential and concurrent programs, using quantitative Hoare logics or predicate transformer algebras, as well as for algebraic reasoning in higher-dimensional rewriting. We also adapt the convolution Kleene algebra construction to Conway semirings, which is widely studied in the context of weighted automata. Finally, we compare the convolution Kleene algebra construction with a previous construction of convolution quantales and present concrete example structures in preparation for future applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.00168v2</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Cranch, Georg Struth, Jana Wagemaker</dc:creator>
    </item>
    <item>
      <title>Conflict-Aware Fusion: Resolving Logic Inertia in Large Language Models via Structured Cognitive Priors</title>
      <link>https://arxiv.org/abs/2512.06393</link>
      <description>arXiv:2512.06393v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) excel at many natural language tasks, yet their reasoning reliability under structured perturbations of rule-based systems remains brittle. We present a controlled evaluation framework consisting of four stress tests: (1) rule deletion (redundant vs. essential); (2) contradictory evidence injection; (3) logic-preserving rewrites; and (4) multi-law equivalence stacking. While representative model families (BERT, Qwen2, and TinyLlama) achieve Acc = 1.0000 on base tasks, our framework reveals a critical failure mode termed Logic Inertia - a total breakdown (Acc = 0.0000) under contradictions, where deductive momentum overrides factual reality.
  To resolve this, we propose Conflict-Aware Fusion, a framework grounded in the Cognitive Structure Hypothesis which posits that robust reasoning requires an explicit structural inductive bias. By imposing a dual-process architecture that separates premise verification from logical deduction, Conflict-Aware Fusion eliminates logic inertia, achieving 1.0000 accuracy on both base and contradictory stress tests, and significantly enhancing robustness to missing evidence. Our results demonstrate that, for reliable multi-step reasoning, structural verification discipline is as critical as training data scale, providing a blueprint for building robust, contradiction-aware AI systems https://github.com/14H034160212/lemo. See the OpenAI/Evals pull request https://github.com/openai/evals/pull/1622.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06393v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiming Bao, Xiaoxuan Fu, Michael Witbrock</dc:creator>
    </item>
    <item>
      <title>Wider systems for linear logic with fixed points: proof theory and complexity</title>
      <link>https://arxiv.org/abs/2602.10280</link>
      <description>arXiv:2602.10280v2 Announce Type: replace-cross 
Abstract: We investigate infinitary wellfounded systems for linear logic with fixed points, with transfinite branching rules indexed by some closure ordinal $\alpha$ for fixed points. Our main result is that provability in the system for some computable ordinal $\alpha$ is complete for the $\omega^{\alpha^\omega}$ level of the hyperarithmetical hierarchy.
  To this end we first develop proof theoretic foundations, namely cut elimination and focussing results, to control both the upper and lower bound analysis. Our arguments employ a carefully calibrated notion of formula rank, calculating a tight bound on the height of the (cut-free) proof search space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.10280v2</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anupam Das, Tikhon Pshenitsyn</dc:creator>
    </item>
    <item>
      <title>Conformal Signal Temporal Logic for Robust Reinforcement Learning Control: A Case Study</title>
      <link>https://arxiv.org/abs/2602.14322</link>
      <description>arXiv:2602.14322v2 Announce Type: replace-cross 
Abstract: We investigate how formal temporal logic specifications can enhance the safety and robustness of reinforcement learning (RL) control in aerospace applications. Using the open source AeroBench F-16 simulation benchmark, we train a Proximal Policy Optimization (PPO) agent to regulate engine throttle and track commanded airspeed. The control objective is encoded as a Signal Temporal Logic (STL) requirement to maintain airspeed within a prescribed band during the final seconds of each maneuver. To enforce this specification at run time, we introduce a conformal STL shield that filters the RL agent's actions using online conformal prediction. We compare three settings: (i) PPO baseline, (ii) PPO with a classical rule-based STL shield, and (iii) PPO with the proposed conformal shield, under both nominal conditions and a severe stress scenario involving aerodynamic model mismatch, actuator rate limits, measurement noise, and mid-episode setpoint jumps. Experiments show that the conformal shield preserves STL satisfaction while maintaining near baseline performance and providing stronger robustness guarantees than the classical shield. These results demonstrate that combining formal specification monitoring with data driven RL control can substantially improve the reliability of autonomous flight control in challenging environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14322v2</guid>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hani Beirami, M M Manjurul Islam</dc:creator>
    </item>
  </channel>
</rss>
