<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 May 2024 04:01:22 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 01 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convergence and stability of randomized implicit two-stage Runge-Kutta schemes</title>
      <link>https://arxiv.org/abs/2404.19059</link>
      <description>arXiv:2404.19059v1 Announce Type: new 
Abstract: We randomize the implicit two-stage Runge-Kutta scheme in order to improve the rate of convergence (with respect to a deterministic scheme) and stability of the approximate solution (with respect to the solution generated by the explicit scheme). For stability analysis, we use Dahlquist's concept of A-stability, adopted to randomized schemes by considering three notions of stability: asymptotic, mean-square, and in probability. The randomized implicit RK2 scheme proves to be A-stable asymptotically and in probability but not in the mean-square sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19059v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomasz Bochacik, Pawe{\l} Przyby{\l}owicz</dc:creator>
    </item>
    <item>
      <title>Sparsity-promoting hierarchical Bayesian model for EIT with a blocky target</title>
      <link>https://arxiv.org/abs/2404.19115</link>
      <description>arXiv:2404.19115v1 Announce Type: new 
Abstract: The electrical impedance tomography (EIT) problem of estimating the unknown conductivity distribution inside a domain from boundary current or voltage measurements requires the solution of a nonlinear inverse problem. Sparsity promoting hierarchical Bayesian models have been shown to be very effective in the recovery of almost piecewise constant solutions in linear inverse problems. We demonstrate that by exploiting linear algebraic considerations it is possible to organize the calculation for the Bayesian solution of the nonlinear EIT inverse problem via finite element methods with sparsity promoting priors in a computationally efficient manner. The proposed approach uses the Iterative Alternating Sequential (IAS) algorithm for the solution of the linearized problems. Within the IAS algorithm, a substantial reduction in computational complexity is attained by exploiting the low dimensionality of the data space and an adjoint formulation of the Tikhonov regularized solution that constitutes part of the iterative updating scheme. Numerical tests illustrate the computational efficiency of the proposed algorithm. The paper sheds light also on the convexity properties of the objective function of the maximum a posteriori (MAP) estimation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19115v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniela Calvetti, Monica Pragliola, Erkki Somersalo</dc:creator>
    </item>
    <item>
      <title>Parameterized Wasserstein Gradient Flow</title>
      <link>https://arxiv.org/abs/2404.19133</link>
      <description>arXiv:2404.19133v1 Announce Type: new 
Abstract: We develop a fast and scalable numerical approach to solve Wasserstein gradient flows (WGFs), particularly suitable for high-dimensional cases. Our approach is to use general reduced-order models, like deep neural networks, to parameterize the push-forward maps such that they can push a simple reference density to the one solving the given WGF. The new dynamical system is called parameterized WGF (PWGF), and it is defined on the finite-dimensional parameter space equipped with a pullback Wasserstein metric. Our numerical scheme can approximate the solutions of WGFs for general energy functionals effectively, without requiring spatial discretization or nonconvex optimization procedures, thus avoiding some limitations of classical numerical methods and more recent deep-learning-based approaches. A comprehensive analysis of the approximation errors measured by Wasserstein distance is also provided in this work. Numerical experiments show promising computational efficiency and verified accuracy on various WGF examples using our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19133v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijie Jin, Shu Liu, Hao Wu, Xiaojing Ye, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Parameter Selection by GCV and a $\chi^2$ test within Iterative Methods for $\ell_1$-regularized Inverse Problems</title>
      <link>https://arxiv.org/abs/2404.19156</link>
      <description>arXiv:2404.19156v1 Announce Type: new 
Abstract: $\ell_1$ regularization is used to preserve edges or enforce sparsity in a solution to an inverse problem. We investigate the Split Bregman and the Majorization-Minimization iterative methods that turn this non-smooth minimization problem into a sequence of steps that include solving an $\ell_2$-regularized minimization problem. We consider selecting the regularization parameter in the inner generalized Tikhonov regularization problems that occur at each iteration in these $\ell_1$ iterative methods. The generalized cross validation and $\chi^2$ degrees of freedom methods are extended to these inner problems. In particular, for the $\chi^2$ method this includes extending the $\chi^2$ result for problems in which the regularization operator has more rows than columns, and showing how to use the $A-$weighted generalized inverse to estimate prior information at each inner iteration. Numerical experiments for image deblurring problems demonstrate that it is more effective to select the regularization parameter automatically within the iterative schemes than to keep it fixed for all iterations. Moreover, an appropriate regularization parameter can be estimated in the early iterations and used fixed to convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19156v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Sweeney, Rosemary Renaut, Malena Espa\~nol</dc:creator>
    </item>
    <item>
      <title>Asymptotically Compatible Fractional Gr\"onwall Inequality and its Applications</title>
      <link>https://arxiv.org/abs/2404.19170</link>
      <description>arXiv:2404.19170v1 Announce Type: new 
Abstract: In this work, we will give proper estimates for the discrete convolution complementary (DCC) kernels, which leads to the asymptotically compatible fractional Gr\"onwall inequality. The consequence can be applied in the analysis of the stability and pointwise-in-time error of difference-type schemes on a non-uniform mesh. The pointwise error is explicitly bound when a non-uniform time grid is given by a specific scale function e.g. graded mesh, can be given directly. Numerical experiments towards the conclusion of this work validate the error analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19170v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daopeng Yin, Liquan Mei</dc:creator>
    </item>
    <item>
      <title>Maximum bound principle and original energy dissipation of arbitrarily high-order rescaled exponential time differencing Runge-Kutta schemes for Allen--Cahn equations</title>
      <link>https://arxiv.org/abs/2404.19188</link>
      <description>arXiv:2404.19188v1 Announce Type: new 
Abstract: The energy dissipation law and the maximum bound principle are two critical physical properties of the Allen--Cahn equations. While many existing time-stepping methods are known to preserve the energy dissipation law, most apply to a modified form of energy. In this work, we demonstrate that, when the nonlinear term of the Allen--Cahn equation is Lipschitz continuous, a class of arbitrarily high-order exponential time differencing Runge--Kutta (ETDRK) schemes preserve the original energy dissipation property, under a mild step-size constraint. Additionally, we guarantee the Lipschitz condition on the nonlinear term by applying a rescaling post-processing technique, which ensures that the numerical solution unconditionally satisfies the maximum bound principle. Consequently, our proposed schemes maintain both the original energy dissipation law and the maximum bound principle and can achieve arbitrarily high-order accuracy. We also establish an optimal error estimate for the proposed schemes. Some numerical experiments are carried out to verify our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19188v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaoyu Quan, Xiaoming Wang, Pinzhong Zheng, Zhi Zhou</dc:creator>
    </item>
    <item>
      <title>A Nonnested Augmented Subspace Method for Kohn-Sham Equation</title>
      <link>https://arxiv.org/abs/2404.19249</link>
      <description>arXiv:2404.19249v1 Announce Type: new 
Abstract: In this paper, a novel adaptive finite element method is proposed to solve the Kohn-Sham equation based on the moving mesh (nonnested mesh) adaptive technique and the augmented subspace method. Different from the classical self-consistent field iterative algorithm which requires to solve the Kohn-Sham equation directly in each adaptive finite element space, our algorithm transforms the Kohn-Sham equation into some linear boundary value problems of the same scale in each adaptive finite element space, and then the wavefunctions derived from the linear boundary value problems are corrected by solving a small-scale Kohn-Sham equation defined in a low-dimensional augmented subspace. Since the new algorithm avoids solving large-scale Kohn-Sham equation directly, a significant improvement for the solving efficiency can be obtained. In addition, the adaptive moving mesh technique is used to generate the nonnested adaptive mesh for the nonnested augmented subspace method according to the singularity of the approximate wavefunctions. The modified Hessian matrix of the approximate wavefunctions is used as the metric matrix to redistribute the mesh. Through the moving mesh adaptive technique, the redistributed mesh is almost optimal. A number of numerical experiments are carried out to verify the efficiency and the accuracy of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19249v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guanghui Hu, Hehu Xie, Fei Xu, Gang Zhao</dc:creator>
    </item>
    <item>
      <title>Efficient inverse $Z$-transform and Wiener-Hopf factorization</title>
      <link>https://arxiv.org/abs/2404.19290</link>
      <description>arXiv:2404.19290v1 Announce Type: new 
Abstract: We suggest new closely related methods for numerical inversion of $Z$-transform and Wiener-Hopf factorization of functions on the unit circle, based on sinh-deformations of the contours of integration, corresponding changes of variables and the simplified trapezoid rule. As applications, we consider evaluation of high moments of probability distributions and construction of causal filters. Programs in Matlab running on a Mac with moderate characteristics achieves the precision E-14 in several dozen of microseconds and E-11 in several milliseconds, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19290v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Svetlana Boyarchenko, Sergei Levendorski\u{i}</dc:creator>
    </item>
    <item>
      <title>Adaptive Gaussian Process Regression for Bayesian inverse problems</title>
      <link>https://arxiv.org/abs/2404.19459</link>
      <description>arXiv:2404.19459v1 Announce Type: new 
Abstract: We introduce a novel adaptive Gaussian Process Regression (GPR) methodology for efficient construction of surrogate models for Bayesian inverse problems with expensive forward model evaluations. An adaptive design strategy focuses on optimizing both the positioning and simulation accuracy of training data in order to reduce the computational cost of simulating training data without compromising the fidelity of the posterior distributions of parameters. The method interleaves a goal-oriented active learning algorithm selecting evaluation points and tolerances based on the expected impact on the Kullback-Leibler divergence of surrogated and true posterior with a Markov Chain Monte Carlo sampling of the posterior. The performance benefit of the adaptive approach is demonstrated for two simple test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19459v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Paolo Villani, J\"org Unger, Martin Weiser</dc:creator>
    </item>
    <item>
      <title>Construction of 2D explicit cubic quasi-interpolating splines in Bernstein-B\'ezier form</title>
      <link>https://arxiv.org/abs/2404.19491</link>
      <description>arXiv:2404.19491v1 Announce Type: new 
Abstract: In this paper, the construction of $C^{1}$ cubic quasi-interpolants on a three-direction mesh of $\RR^{2}$ is addressed. The quasi-interpolating splines are defined by directly setting their Bernstein-B\'{e}zier coefficients relative to each triangle from point and gradient values in order to reproduce the polynomials of the highest possible degree. Moreover, additional global properties are required. Finally, we provide some numerical tests confirming the approximation properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19491v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Domingo Barrera, Salah Eddargani, Mar\'ia Jos\'e Ib\'a\~nez, Sara Remogna</dc:creator>
    </item>
    <item>
      <title>Comparison of the high-order Runge-Kutta discontinuous Galerkin method and gas-kinetic scheme for inviscid compressible flow simulations</title>
      <link>https://arxiv.org/abs/2404.19512</link>
      <description>arXiv:2404.19512v1 Announce Type: new 
Abstract: The Runge--Kutta discontinuous Galerkin (RKDG) method is a high-order technique for addressing hyperbolic conservation laws, which has been refined over recent decades and is effective in handling shock discontinuities. Despite its advancements, the RKDG method faces challenges, such as stringent constraints on the explicit time-step size and reduced robustness when dealing with strong discontinuities. On the other hand, the Gas-Kinetic Scheme (GKS) based on a high-order gas evolution model also delivers significant accuracy and stability in solving hyperbolic conservation laws through refined spatial and temporal discretizations. Unlike RKDG, GKS allows for more flexible CFL number constraints and features an advanced flow evolution mechanism at cell interfaces. Additionally, GKS' compact spatial reconstruction enhances the accuracy of the method and its ability to capture stable strong discontinuities effectively. In this study, we conduct a thorough examination of the RKDG method using various numerical fluxes and the GKS method employing both compact and non-compact spatial reconstructions. Both methods are applied under the framework of explicit time discretization and are tested solely in inviscid scenarios. We will present numerous numerical tests and provide a comparative analysis of the outcomes derived from these two computational approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19512v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixiao Wang, Xing Ji, Gang Chen, Kun Xu</dc:creator>
    </item>
    <item>
      <title>Discrete de-Rham complex involving a discontinuous finite element space for velocities: the case of periodic straight triangular and Cartesian meshes</title>
      <link>https://arxiv.org/abs/2404.19545</link>
      <description>arXiv:2404.19545v1 Announce Type: new 
Abstract: The aim of this article is to derive discontinuous finite elements vector spaces which can be put in a discrete de-Rham complex for which an harmonic gap property may be proven. First, discontinuous finite element spaces inspired by classical N{\'e}d{\'e}lec or Raviart-Thomas conforming space are considered, and we prove that by relaxing the normal or tangential constraint, discontinuous spaces ensuring the harmonic gap property can be built. Then the triangular case is addressed, for which we prove that such a property holds for the classical discontinuous finite element space for vectors. On Cartesian meshes, this result does not hold for the classical discontinuous finite element space for vectors. We then show how to use the de-Rham complex found for triangular meshes for enriching the finite element space on Cartesian meshes in order to recover a de-Rham complex, on which the same harmonic gap property is proven.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19545v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Perrier (CAGIRE, LMAP)</dc:creator>
    </item>
    <item>
      <title>Computational study of numerical flux schemes for mesoscale atmospheric flows in a Finite Volume framework</title>
      <link>https://arxiv.org/abs/2404.19559</link>
      <description>arXiv:2404.19559v1 Announce Type: new 
Abstract: We develop, and implement in a Finite Volume environment, a density-based approach for the Euler equations written in conservative form using density, momentum, and total energy as variables. Under simplifying assumptions, these equations are used to describe non-hydrostatic atmospheric flow. The well-balancing of the approach is ensured by a local hydrostatic reconstruction updated in runtime during the simulation to keep the numerical error under control. To approximate the solution of the Riemann problem, we consider four methods: Roe-Pike, HLLC, AUSM+-up and HLLC-AUSM. We assess our density-based approach and compare the accuracy of these four approximated Riemann solvers using two two classical benchmarks, namely the smooth rising thermal bubble and the density current.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19559v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.ao-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Clinco, Michele Girfoglio, Annalisa Quaini, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Machine learning of continuous and discrete variational ODEs with convergence guarantee and uncertainty quantification</title>
      <link>https://arxiv.org/abs/2404.19626</link>
      <description>arXiv:2404.19626v1 Announce Type: new 
Abstract: The article introduces a method to learn dynamical systems that are governed by Euler--Lagrange equations from data. The method is based on Gaussian process regression and identifies continuous or discrete Lagrangians and is, therefore, structure preserving by design. A rigorous proof of convergence as the distance between observation data points converges to zero is provided. Next to convergence guarantees, the method allows for quantification of model uncertainty, which can provide a basis of adaptive sampling techniques. We provide efficient uncertainty quantification of any observable that is linear in the Lagrangian, including of Hamiltonian functions (energy) and symplectic structures, which is of interest in the context of system identification. The article overcomes major practical and theoretical difficulties related to the ill-posedness of the identification task of (discrete) Lagrangians through a careful design of geometric regularisation strategies and through an exploit of a relation to convex minimisation problems in reproducing kernel Hilbert spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19626v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Offen</dc:creator>
    </item>
    <item>
      <title>Fast Adaptive Fourier Integration for Spectral Densities of Gaussian Processes</title>
      <link>https://arxiv.org/abs/2404.19053</link>
      <description>arXiv:2404.19053v1 Announce Type: cross 
Abstract: The specification of a covariance function is of paramount importance when employing Gaussian process models, but the requirement of positive definiteness severely limits those used in practice. Designing flexible stationary covariance functions is, however, straightforward in the spectral domain, where one needs only to supply a positive and symmetric spectral density. In this work, we introduce an adaptive integration framework for efficiently and accurately evaluating covariance functions and their derivatives at irregular locations directly from \textit{any} continuous, integrable spectral density. In order to make this approach computationally tractable, we employ high-order panel quadrature, the nonuniform fast Fourier transform, and a Nyquist-informed panel selection heuristic, and derive novel algebraic truncation error bounds which are used to monitor convergence. As a result, we demonstrate several orders of magnitude speedup compared to naive uniform quadrature approaches, allowing us to evaluate covariance functions from slowly decaying, singular spectral densities at millions of locations to a user-specified tolerance in seconds on a laptop. We then apply our methodology to perform gradient-based maximum likelihood estimation using a previously numerically infeasible long-memory spectral model for wind velocities below the atmospheric boundary layer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19053v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Paul G. Beckman, Christopher J. Geoga</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Optimization of a Neural Representation Network for Time-Space Tomography Reconstruction</title>
      <link>https://arxiv.org/abs/2404.19075</link>
      <description>arXiv:2404.19075v1 Announce Type: cross 
Abstract: 4D time-space reconstruction of dynamic events or deforming objects using X-ray computed tomography (CT) is an extremely ill-posed inverse problem. Existing approaches assume that the object remains static for the duration of several tens or hundreds of X-ray projection measurement images (reconstruction of consecutive limited-angle CT scans). However, this is an unrealistic assumption for many in-situ experiments that causes spurious artifacts and inaccurate morphological reconstructions of the object. To solve this problem, we propose to perform a 4D time-space reconstruction using a distributed implicit neural representation (DINR) network that is trained using a novel distributed stochastic training algorithm. Our DINR network learns to reconstruct the object at its output by iterative optimization of its network parameters such that the measured projection images best match the output of the CT forward measurement model. We use a continuous time and space forward measurement model that is a function of the DINR outputs at a sparsely sampled set of continuous valued object coordinates. Unlike existing state-of-the-art neural representation architectures that forward and back propagate through dense voxel grids that sample the object's entire time-space coordinates, we only propagate through the DINR at a small subset of object coordinates in each iteration resulting in an order-of-magnitude reduction in memory and compute for training. DINR leverages distributed computation across several compute nodes and GPUs to produce high-fidelity 4D time-space reconstructions even for extremely large CT data sizes. We use both simulated parallel-beam and experimental cone-beam X-ray CT datasets to demonstrate the superior performance of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19075v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>K. Aditya Mohan, Massimiliano Ferrucci, Chuck Divin, Garrett A. Stevenson, Hyojin Kim</dc:creator>
    </item>
    <item>
      <title>Study on the Temporal Evolution of Literature Bradford Curves in the Context of Library Specialization</title>
      <link>https://arxiv.org/abs/2404.19267</link>
      <description>arXiv:2404.19267v1 Announce Type: cross 
Abstract: The Bradford's law of bibliographic scattering is a fundamental law in bibliometrics and can provide valuable guidance to academic libraries in literature search and procurement. However, the Bradford's curves can take various shapes at different time points and there is still a lack of causal explanation for it, so the prediction of its shape is still an open question. This paper attributes the deviation of Bradford curve from the theoretical J-shape to the integer constraints of the journal number and article number, and extends the Leimkuhler and Egghe's formula to cover the core region of very productive journals, where the theoretical journal number of which fall below one. The key parameters of the extended formula are identified and studied by using the Simon-Yule model. The reasons for the Groos Droop are explained and the critical point for the shape change are studied. Finally, the proposed formulae are validated with the empirical data found in the literature. It is found that the proposed method can be used to predict the evolution of Bradford's curves and thus guide the academic library for scientific literature procurement and utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19267v1</guid>
      <category>cs.DL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haobai Xue, Xian Liu</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of the transformed gradient projection algorithms on compact matrix manifolds</title>
      <link>https://arxiv.org/abs/2404.19392</link>
      <description>arXiv:2404.19392v1 Announce Type: cross 
Abstract: In this paper, to address the optimization problem on a compact matrix manifold, we introduce a novel algorithmic framework called the Transformed Gradient Projection (TGP) algorithm, using the projection onto this compact matrix manifold. Compared with the existing algorithms, the key innovation in our approach lies in the utilization of a new class of search directions and various stepsizes, including the Armijo, nonmonotone Armijo, and fixed stepsizes, to guide the selection of the next iterate. Our framework offers flexibility by encompassing the classical gradient projection algorithms as special cases, and intersecting the retraction-based line-search algorithms. Notably, our focus is on the Stiefel or Grassmann manifold, revealing that many existing algorithms in the literature can be seen as specific instances within our proposed framework, and this algorithmic framework also induces several new special cases. Then, we conduct a thorough exploration of the convergence properties of these algorithms, considering various search directions and stepsizes. To achieve this, we extensively analyze the geometric properties of the projection onto compact matrix manifolds, allowing us to extend classical inequalities related to retractions from the literature. Building upon these insights, we establish the weak convergence, convergence rate, and global convergence of TGP algorithms under three distinct stepsizes. In cases where the compact matrix manifold is the Stiefel or Grassmann manifold, our convergence results either encompass or surpass those found in the literature. Finally, through a series of numerical experiments, we observe that the TGP algorithms, owing to their increased flexibility in choosing search directions, outperform classical gradient projection and retraction-based line-search algorithms in several scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19392v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wentao Ding, Jianze Li, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Comparison of two numerical methods for Riemannian cubic polynomials on Stiefel manifolds</title>
      <link>https://arxiv.org/abs/2404.19407</link>
      <description>arXiv:2404.19407v1 Announce Type: cross 
Abstract: In this paper we compare two numerical methods to integrate Riemannian cubic polynomials on the Stiefel manifold $\textbf{St}_{n,k}$. The first one is the adjusted de Casteljau algorithm, and the second one is a symplectic integrator constructed through discretization maps. In particular, we choose the cases of $n=3$ together with $k=1$ and $k=2$. The first case is diffeomorphic to the sphere and the quasi-geodesics appearing in the adjusted de Casteljau algorithm are actually geodesics. The second case is an example where we have a pure quasi-geodesic different from a geodesic. We provide a numerical comparison of both methods and discuss the obtained results to highlight the benefits of each method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19407v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Anahory Simoes, Leonardo Colombo, F\'atima Silva Leite</dc:creator>
    </item>
    <item>
      <title>Finetuning greedy kernel models by exchange algorithms</title>
      <link>https://arxiv.org/abs/2404.19487</link>
      <description>arXiv:2404.19487v1 Announce Type: cross 
Abstract: Kernel based approximation offers versatile tools for high-dimensional approximation, which can especially be leveraged for surrogate modeling. For this purpose, both "knot insertion" and "knot removal" approaches aim at choosing a suitable subset of the data, in order to obtain a sparse but nevertheless accurate kernel model. In the present work, focussing on kernel based interpolation, we aim at combining these two approaches to further improve the accuracy of kernel models, without increasing the computational complexity of the final kernel model. For this, we introduce a class of kernel exchange algorithms (KEA). The resulting KEA algorithm can be used for finetuning greedy kernel surrogate models, allowing for an reduction of the error up to 86.4% (17.2% on average) in our experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19487v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tizian Wenzel, Armin Iske</dc:creator>
    </item>
    <item>
      <title>Stabilized POD Reduced Order Models for convection-dominated incompressible flows</title>
      <link>https://arxiv.org/abs/2404.19600</link>
      <description>arXiv:2404.19600v1 Announce Type: cross 
Abstract: We present a comparative computational study of two stabilized Reduced Order Models (ROMs) for the simulation of convection-dominated incompressible flow (Reynolds number of the order of a few thousands). Representative solutions in the parameter space, which includes either time only or time and Reynolds number, are computed with a Finite Volume method and used to generate a reduced basis via Proper Orthogonal Decomposition (POD). Galerkin projection of the Navier-Stokes equations onto the reduced space is used to compute the ROM solution. To ensure computational efficiency, the number of POD modes is truncated and ROM solution accuracy is recovered through two stabilization methods: i) adding a global constant artificial viscosity to the reduced dimensional model, and ii) adding a different value of artificial viscosity for the different POD modes. We test the stabilized ROMs for fluid flow in an idealized medical device consisting of a conical convergent, a narrow throat, and a sudden expansion. Both stabilization methods significantly improve the ROM solution accuracy over a standard (non-stabilized) POD-Galerkin model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19600v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierfrancesco Siena, Michele Girfoglio, Annalisa Quaini, Gianluigi Rozza</dc:creator>
    </item>
    <item>
      <title>Uncertainty quantification for charge transport in GNRs through particle Galerkin methods for the semiclassical Boltzmann equation</title>
      <link>https://arxiv.org/abs/2404.19602</link>
      <description>arXiv:2404.19602v1 Announce Type: cross 
Abstract: In this article, we investigate some issues related to the quantification of uncertainties associated with the electrical properties of graphene nanoribbons. The approach is suited to understand the effects of missing information linked to the difficulty of fixing some material parameters, such as the band gap, and the strength of the applied electric field. In particular, we focus on the extension of particle Galerkin methods for kinetic equations in the case of the semiclassical Boltzmann equation for charge transport in graphene nanoribbons with uncertainties. To this end, we develop an efficient particle scheme which allows us to parallelize the computation and then, after a suitable generalization of the scheme to the case of random inputs, we present a Galerkin reformulation of the particle dynamics, obtained by means of a generalized polynomial chaos approach, which allows the reconstruction of the kinetic distribution. As a consequence, the proposed particle-based scheme preserves the physical properties and the positivity of the distribution function also in the presence of a complex scattering in the transport equation of electrons. The impact of the uncertainty of the band gap and applied field on the electrical current is analyzed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19602v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Medaglia, Giovanni Nastasi, Vittorio Romano, Mattia Zanella</dc:creator>
    </item>
    <item>
      <title>Best polynomial approximation for non-autonomous linear ODEs in the $\star$-product framework</title>
      <link>https://arxiv.org/abs/2404.19645</link>
      <description>arXiv:2404.19645v1 Announce Type: cross 
Abstract: We present the first formulation of the optimal polynomial approximation of the solution of linear non-autonomous systems of ODEs in the framework of the so-called $\star$-product. This product is the basis of new approaches for the solution of such ODEs, both in the analytical and the numerical sense. The paper shows how to formally state the problem and derives upper bounds for its error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19645v1</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Stefano Pozza</dc:creator>
    </item>
    <item>
      <title>Continuum limit of $p$-biharmonic equations on graphs</title>
      <link>https://arxiv.org/abs/2404.19689</link>
      <description>arXiv:2404.19689v1 Announce Type: cross 
Abstract: This paper studies the $p$-biharmonic equation on graphs, which arises in point cloud processing and can be interpreted as a natural extension of the graph $p$-Laplacian from the perspective of hypergraph. The asymptotic behavior of the solution is investigated when the random geometric graph is considered and the number of data points goes to infinity. We show that the continuum limit is an appropriately weighted $p$-biharmonic equation with homogeneous Neumann boundary conditions. The result relies on the uniform $L^p$ estimates for solutions and gradients of nonlocal and graph Poisson equations. The $L^\infty$ estimates of solutions are also obtained as a byproduct.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.19689v1</guid>
      <category>math.AP</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kehan Shi, Martin Burger</dc:creator>
    </item>
    <item>
      <title>Swarm-Based Gradient Descent Method for Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2211.17157</link>
      <description>arXiv:2211.17157v2 Announce Type: replace 
Abstract: We introduce a new Swarm-Based Gradient Descent (SBGD) method for non-convex optimization. The swarm consists of agents, each is identified with a position, ${\mathbf x}$, and mass, $m$. The key to their dynamics is communication: masses are being transferred from agents at high ground to low(-est) ground. At the same time, agents change positions with step size, $h=h({\mathbf x},m)$, adjusted to their relative mass: heavier agents proceed with small time-steps in the direction of local gradient, while lighter agents take larger time-steps based on a backtracking protocol. Accordingly, the crowd of agents is dynamically divided between `heavier' leaders, expected to approach local minima, and `lighter' explorers. With their large-step protocol, explorers are expected to encounter improved position for the swarm; if they do, then they assume the role of `heavy' swarm leaders and so on. Convergence analysis and numerical simulations in one-, two-, and 20-dimensional benchmarks demonstrate the effectiveness of SBGD as a global optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.17157v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingcheng Lu, Eitan Tadmor, Anil Zenginoglu</dc:creator>
    </item>
    <item>
      <title>A Nystr\"{o}m Method for Scattering by a Two-layered Medium with a Rough Boundary</title>
      <link>https://arxiv.org/abs/2303.02339</link>
      <description>arXiv:2303.02339v2 Announce Type: replace 
Abstract: This paper considers the problems of scattering of time-harmonic acoustic waves by a two-layered medium with a non-locally perturbed boundary (called a rough boundary in this paper) in two dimensions, where a Dirichlet or impedance boundary condition is imposed on the boundary. The two-layered medium is composed of two unbounded media with different physical properties and the interface between the two media is considered to be a planar surface. We formulate the considered scattering problems as the boundary value problems and prove that each boundary value problem has a unique solution by utilizing the integral equation method associated with the two-layered Green function. Moreover, we develop the Nystr\"{o}m method for numerically solving the considered boundary value problems, based on the proposed integral equation formulations. We establish the convergence results of the Nystr\"{o}m method with the convergence rates depending on the smoothness of the rough boundary. It is worth noting that in establishing the well-posedness of the boundary value problems as well as the convergence results of the Nystr\"{o}m method, an essential role is played by the investigation of the asymptotic properties of the two-layered Green function for small and large arguments. Finally, numerical experiments are carried out to show the effectiveness of the Nystr\"{o}m method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02339v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiyang Liu, Long Li, Jiansheng Yang, Bo Zhang, Haiwen Zhang</dc:creator>
    </item>
    <item>
      <title>Virtual element methods for Biot-Kirchhoff poroelasticity</title>
      <link>https://arxiv.org/abs/2306.13890</link>
      <description>arXiv:2306.13890v2 Announce Type: replace 
Abstract: This paper analyses conforming and nonconforming virtual element formulations of arbitrary polynomial degrees on general polygonal meshes for the coupling of solid and fluid phases in deformable porous plates. The governing equations consist of one fourth-order equation for the transverse displacement of the middle surface coupled with a second-order equation for the pressure head relative to the solid with mixed boundary conditions. We propose novel enrichment operators that connect nonconforming virtual element spaces of general degree to continuous Sobolev spaces. These operators satisfy additional orthogonal and best-approximation properties (referred to as a conforming companion operator in the context of finite element methods), which play an important role in the nonconforming methods. This paper proves a priori error estimates in the best-approximation form, and derives residual--based reliable and efficient a posteriori error estimates in appropriate norms, and shows that these error bounds are robust with respect to the main model parameters. The computational examples illustrate the numerical behaviour of the suggested virtual element discretisations and confirm the theoretical findings on different polygonal meshes with mixed boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13890v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rekha Khot, David Mora, Ricardo Ruiz-Baier</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of a weak Galerkin finite element method on a Shishkin mesh for a singularly perturbed fourth-order problem in 2D</title>
      <link>https://arxiv.org/abs/2306.15867</link>
      <description>arXiv:2306.15867v3 Announce Type: replace 
Abstract: We consider the singularly perturbed fourth-order boundary value problem $\varepsilon ^{2}\Delta ^{2}u-\Delta u=f $ on the unit square $\Omega \subset \mathbb{R}^2$, with boundary conditions $u = \partial u / \partial n = 0$ on $\partial \Omega$, where $\varepsilon \in (0, 1)$ is a small parameter. The problem is solved numerically by means of a weak Galerkin(WG) finite element method, which is highly robust and flexible in the element construction by using discontinuous piecewise polynomials on finite element partitions consisting of polygons of arbitrary shape. The resulting WG finite element formulation is symmetric, positive definite, and parameter-free. Under reasonable assumptions on the structure of the boundary layers that appear in the solution, a family of suitable Shishkin meshes with $N^2$ elements is constructed ,convergence of the method is proved in a discrete $H^2$ norm for the corresponding WG finite element solutions and numerical results are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15867v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shicheng Liu, Xiangyun Meng, Qilong Zhai</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Magnetic Polarizability Tensor Spectral Signatures for Object Characterisation in Metal Detection</title>
      <link>https://arxiv.org/abs/2307.05590</link>
      <description>arXiv:2307.05590v2 Announce Type: replace 
Abstract: Purpose: Magnetic polarizability tensors (MPTs) provide an economical characterisation of conducting magnetic metallic objects and their spectral signature can aid in the solution of metal detection inverse problems, such as scrap metal sorting, searching for unexploded ordnance in areas of former conflict, and security screening at event venues and transport hubs. In this work, the authors discuss methods for efficiently building large dictionaries for classification approaches. Design/methodology/approach: Previous work has established explicit formulae for MPT coefficients, underpinned by a rigorous mathematical theory. To assist with the efficient computation of MPTs at differing parameters and objects of interest this work applies new observations about the way the MPT coefficients can be computed. Furthermore, the authors discuss discretisation strategies for hp-finite elements on meshes of unstructured tetrahedra combined with prismatic boundary layer elements for resolving thin skin depths and using an adaptive proper orthogonal decomposition (POD) reduced order modelling methodology to accelerate computations for varying parameters. Findings: The success of the proposed methodologies is demonstrated using a series of examples. A significant reduction in computational effort is observed across all examples. The authors identify and recommend a simple discretisation strategy, and improved accuracy is obtained using adaptive POD. Originality: The authors present novel computations, timings, and error certificates of MPT characterisations of realistic objects made of magnetic materials. A novel postprocessing implementation is introduced, and an adaptive POD algorithm is demonstrated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05590v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Elgy, Paul D. Ledger</dc:creator>
    </item>
    <item>
      <title>Integral equation methods for acoustic scattering by fractals</title>
      <link>https://arxiv.org/abs/2309.02184</link>
      <description>arXiv:2309.02184v2 Announce Type: replace 
Abstract: We study sound-soft time-harmonic acoustic scattering by general scatterers, including fractal scatterers, in 2D and 3D space. For an arbitrary compact scatterer $\Gamma$ we reformulate the Dirichlet boundary value problem for the Helmholtz equation as a first kind integral equation (IE) on $\Gamma$ involving the Newton potential. The IE is well-posed, except possibly at a countable set of frequencies, and reduces to existing single-layer boundary IEs when $\Gamma$ is the boundary of a bounded Lipschitz open set, a screen, or a multi-screen. When $\Gamma$ is uniformly of $d$-dimensional Hausdorff dimension in a sense we make precise (a $d$-set), the operator in our equation is an integral operator on $\Gamma$ with respect to $d$-dimensional Hausdorff measure, with kernel the Helmholtz fundamental solution, and we propose a piecewise-constant Galerkin discretization of the IE, which converges in the limit of vanishing mesh width. When $\Gamma$ is the fractal attractor of an iterated function system of contracting similarities we prove convergence rates under assumptions on $\Gamma$ and the IE solution, and describe a fully discrete implementation using recently proposed quadrature rules for singular integrals on fractals. We present numerical results for a range of examples and make our software available as a Julia code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02184v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. M. Caetano, S. N. Chandler-Wilde, X. Claeys, A. Gibbs, D. P. Hewett, A. Moiola</dc:creator>
    </item>
    <item>
      <title>Computing the matrix exponential and the Cholesky factor of a related finite horizon Gramian</title>
      <link>https://arxiv.org/abs/2310.13462</link>
      <description>arXiv:2310.13462v2 Announce Type: replace 
Abstract: In this article, an efficient numerical method for computing finite-horizon controllability Gramians in Cholesky-factored form is proposed. The method is applicable to general dense matrices of moderate size and produces a Cholesky factor of the Gramian without computing the full product. In contrast to other methods applicable to this task, the proposed method is a generalization of the scaling-and-squaring approach for approximating the matrix exponential. It exploits a similar doubling formula for the Gramian, and thereby keeps the required computational effort modest. Most importantly, a rigorous backward error analysis is provided, which guarantees that the approximation is accurate to the round-off error level in double precision. This accuracy is illustrated in practice on a large number of standard test examples.
  The method has been implemented in the Julia package FiniteHorizonGramians.jl, which is available online under the MIT license. Code for reproducing the experimental results is included in this package, as well as code for determining the optimal method parameters. The analysis can thus easily be adapted to a different finite-precision arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13462v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tony Stillfjord, Filip Tronarp</dc:creator>
    </item>
    <item>
      <title>Perfectly matched layers for the Boltzmann equation: stability and sensitivity analysis</title>
      <link>https://arxiv.org/abs/2312.03273</link>
      <description>arXiv:2312.03273v2 Announce Type: replace 
Abstract: We study the stability and sensitivity of an absorbing layer for the Boltzmann equation by examining the Bhatnagar-Gross-Krook (BGK) approximation and using the perfectly matched layer (PML) technique. To ensure stability, we discard some parameters in the model and calculate the total sensitivity indices of the remaining parameters using the ANOVA expansion of multivariate functions. We conduct extensive numerical experiments on two test cases to study stability and compute the total sensitivity indices, which allow us to identify the essential parameters of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03273v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2024.113047</arxiv:DOI>
      <dc:creator>Marco Sutti, Jan S. Hesthaven</dc:creator>
    </item>
    <item>
      <title>Identifying heterogeneous micromechanical properties of biological tissues via physics-informed neural networks</title>
      <link>https://arxiv.org/abs/2402.10741</link>
      <description>arXiv:2402.10741v2 Announce Type: replace 
Abstract: The heterogeneous micromechanical properties of biological tissues have profound implications across diverse medical and engineering domains. However, identifying the full-field heterogeneous elastic properties of soft materials using traditional computational and engineering approaches is fundamentally challenging due to difficulties in estimating local stress fields. Recently, there has been a growing interest in using data-driven models to learn full-field mechanical responses such as displacement and strain from experimental or synthetic data. However, research studies on inferring the full-field elastic properties of materials, a more challenging problem, are scarce, particularly for large deformation, hyperelastic materials. Here, we propose a physics-informed machine learning approach to identify the elastic modulus distribution in nonlinear, large deformation hyperelastic materials. We evaluate the prediction accuracies and computational efficiency of physics-informed neural networks (PINNs) on inferring the heterogeneous material parameter maps across three nonlinear materials with structural complexity that closely resemble real tissue patterns, such as brain tissue and tricuspid valve tissue. Our improved PINN architecture accurately estimates the full-field elastic properties of three hyperelastic constitutive models, with relative errors of less than 5% across all examples. This research has significant potential for advancing our understanding of micromechanical behaviors in biological materials, impacting future innovations in engineering and medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10741v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.bio-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wensi Wu, Mitchell Daneker, Kevin T. Turner, Matthew A. Jolley, Lu Lu</dc:creator>
    </item>
    <item>
      <title>PDEformer: Towards a Foundation Model for One-Dimensional Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2402.12652</link>
      <description>arXiv:2402.12652v2 Announce Type: replace 
Abstract: This paper introduces PDEformer, a neural solver for partial differential equations (PDEs) capable of simultaneously addressing various types of PDEs. We propose to represent the PDE in the form of a computational graph, facilitating the seamless integration of both symbolic and numerical information inherent in a PDE. A graph Transformer and an implicit neural representation (INR) are employed to generate mesh-free predicted solutions. Following pretraining on data exhibiting a certain level of diversity, our model achieves zero-shot accuracies on benchmark datasets that is comparable to those of specifically trained expert models. Additionally, PDEformer demonstrates promising results in the inverse problem of PDE coefficient recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12652v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhanhong Ye, Xiang Huang, Leheng Chen, Hongsheng Liu, Zidong Wang, Bin Dong</dc:creator>
    </item>
    <item>
      <title>Discrete minimizers of the interaction energy in collective behavior: a brief numerical and analytic review</title>
      <link>https://arxiv.org/abs/2403.00594</link>
      <description>arXiv:2403.00594v2 Announce Type: replace 
Abstract: We consider minimizers of the N-particle interaction potential energy and briefly review numerical methods used to calculate them. We consider simple pair potentials which are repulsive at short distances and attractive at long distances, focusing on examples which are sums of two powers. The range of powers we look at includes the well-known case of the Lennard-Jones potential, but we are also interested in less singular potentials which are relevant in collective behavior models. We report on results using the software GMIN developed by Wales and collaborators for problems in chemistry. For all cases, this algorithm gives good candidates for the minimizers for relatively low values of the particle number N. This is well-known for potentials similar to Lennard-Jones, but not for the range which is of interest in collective behavior. Standard minimization procedures have been used in the literature in this range, but they are likely to yield stationary states which are not minimizers. We illustrate numerically some properties of the minimizers in 2D, such as lattice structure, Wulff shapes, and the continuous large-N limit for locally integrable (that is, less singular) potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00594v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e A. Ca\~nizo, Alejandro Ramos-Lora</dc:creator>
    </item>
    <item>
      <title>A High-Order Conservative Cut Finite Element Method for Problems in Time-Dependent Domains</title>
      <link>https://arxiv.org/abs/2404.10756</link>
      <description>arXiv:2404.10756v3 Announce Type: replace 
Abstract: A mass-conservative high-order unfitted finite element method for convection-diffusion equations in evolving domains is proposed. The space-time method presented in [P. Hansbo, M. G. Larson, S. Zahedi, Comput. Methods Appl. Mech. Engrg. 307 (2016)] is extended to naturally achieve mass conservation by utilizing Reynold's transport theorem. Furthermore, by partitioning the time-dependent domain into macroelements, a more efficient stabilization procedure for the cut finite element method in time-dependent domains is presented. Numerical experiments illustrate that the method fulfills mass conservation, attains high-order convergence, and the condition number of the resulting system matrix is controlled while sparsity is increased. Problems in bulk domains as well as coupled bulk-surface problems are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10756v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sebastian Myrb\"ack, Sara Zahedi</dc:creator>
    </item>
    <item>
      <title>Extending h adaptivity with refinement patterns</title>
      <link>https://arxiv.org/abs/2404.18800</link>
      <description>arXiv:2404.18800v2 Announce Type: replace 
Abstract: This contribution introduces the idea of refinement patterns for the generation of optimal meshes in the context of the Finite Element Method. The main idea is to generate a library of possible patterns on which elements can be refined and use this library to inform an h adaptive code on how to handle complex refinements in regions of interest. There are no restrictions on the type of elements that can be refined, and the patterns can be generated for any element type. The main advantage of this approach is that it allows for the generation of optimal meshes in a systematic way where, even if a certain pattern is not available, it can easily be included through a simple text file with nodes and sub-elements. The contribution presents a detailed methodology for incorporating refinement patterns into h adaptive Finite Element Method codes and demonstrates the effectiveness of the approach through mesh refinement of problems with complex geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18800v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giovane Avancini, Nathan Shauer, Francisco T. Orlandini, Paulo Cesar A. Lucci, Philippe R. B. Devloo</dc:creator>
    </item>
    <item>
      <title>Orthonormal Expansions for Translation-Invariant Kernels</title>
      <link>https://arxiv.org/abs/2206.08648</link>
      <description>arXiv:2206.08648v4 Announce Type: replace-cross 
Abstract: We present a general Fourier analytic technique for constructing orthonormal basis expansions of translation-invariant kernels from orthonormal bases of $\mathscr{L}_2(\mathbb{R})$. This allows us to derive explicit expansions on the real line for (i) Mat\'ern kernels of all half-integer orders in terms of associated Laguerre functions, (ii) the Cauchy kernel in terms of rational functions, and (iii) the Gaussian kernel in terms of Hermite functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08648v4</guid>
      <category>math.CA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filip Tronarp, Toni Karvonen</dc:creator>
    </item>
    <item>
      <title>A mathematical model of the visual MacKay effect</title>
      <link>https://arxiv.org/abs/2311.07338</link>
      <description>arXiv:2311.07338v3 Announce Type: replace-cross 
Abstract: This paper investigates the intricate connection between visual perception and the mathematical modelling of neural activity in the primary visual cortex (V1). The focus is on modelling the visual MacKay effect [Mackay, Nature 1957]. While bifurcation theory has been a prominent mathematical approach for addressing issues in neuroscience, especially in describing spontaneous pattern formations in V1 due to parameter changes, it faces challenges in scenarios with localized sensory inputs. This is evident, for instance, in Mackay's psychophysical experiments, where the redundancy of visual stimuli information results in irregular shapes, making bifurcation theory and multi-scale analysis less effective. To address this, we follow a mathematical viewpoint based on the input-output controllability of an Amari-type neural fields model. In this framework, we consider sensory input as a control function, a cortical representation via the retino-cortical map of the visual stimulus that captures its distinct features. This includes highly localized information in the center of MacKay's funnel pattern "MacKay rays". From a control theory point of view, the Amari-type equation's exact controllability property is discussed for linear and nonlinear response functions. For the visual MacKay effect modelling, we adjust the parameter representing intra-neuron connectivity to ensure that cortical activity exponentially stabilizes to the stationary state in the absence of sensory input. Then, we perform quantitative and qualitative studies to demonstrate that they capture all the essential features of the induced after-image reported by MacKay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07338v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyprien Tamekue, Dario Prandi, Yacine Chitour</dc:creator>
    </item>
  </channel>
</rss>
