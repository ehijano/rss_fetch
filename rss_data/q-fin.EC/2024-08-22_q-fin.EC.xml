<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Aug 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 22 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Theory of Recommendations</title>
      <link>https://arxiv.org/abs/2408.11362</link>
      <description>arXiv:2408.11362v1 Announce Type: new 
Abstract: This paper investigates the value of recommendations for disseminating economic information, with a focus on frictions resulting from preference heterogeneity. We consider Bayesian expected-payoff maximizers who receive non-strategic recommendations by other consumers. The paper provides conditions under which different consumer types accept these recommendations. Moreover, we assess the overall value of a recommendation system and the determinants of that value. Our analysis highlights the importance of disentangling objective information from subjective preferences when designing value-maximizing recommendation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11362v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Michel Benkert, Armin Schmutzler</dc:creator>
    </item>
    <item>
      <title>A Novel $\delta$-SBM-OPA Approach for Policy-Driven Analysis of Carbon Emission Efficiency under Uncertainty in the Chinese Industrial Sector</title>
      <link>https://arxiv.org/abs/2408.11600</link>
      <description>arXiv:2408.11600v1 Announce Type: new 
Abstract: Regional differences in carbon emission efficiency arise from disparities in resource distribution, industrial structure, and development level, which are often influenced by government policy preferences. However, currently, most studies fail to consider the impact of government policy preferences and data uncertainty on carbon emission efficiency. To address the above limitations, this study proposes a hybrid model based on $\delta$-slack-based model ($\delta$-SBM) and ordinal priority approach (OPA) for measuring carbon emission efficiency driven by government policy preferences under data uncertainty. The proposed $\delta$-SBM-OPA model incorporates constraints on the importance of input and output variables under different policy preference scenarios. It then develops the efficiency optimization model with Farrell frontiers and efficiency tapes to deal with the data uncertainty in input and output variables. This study demonstrates the proposed model by analyzing industrial carbon emission efficiency of Chinese provinces in 2021. It examines the carbon emission efficiency and corresponding clustering results of provinces under three types of policies: economic priority, environmental priority, and technological priority, with varying priority preferences. The results indicate that the carbon emission efficiency of the 30 provinces can mainly be categorized into technology-driven, development-balanced, and transition-potential types, with most provinces achieving optimal efficiency under the technology-dominant preferences across all policy scenarios. Ultimately, this study suggests a tailored roadmap and crucial initiatives for different provinces to progressively and systematically work towards achieving the low carbon goal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11600v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shutian Cui, Renlong Wang, Xiaoyan Li</dc:creator>
    </item>
    <item>
      <title>Network-based diversification of stock and cryptocurrency portfolios</title>
      <link>https://arxiv.org/abs/2408.11739</link>
      <description>arXiv:2408.11739v1 Announce Type: new 
Abstract: Maintaining a balance between returns and volatility is a common strategy for portfolio diversification, whether investing in traditional equities or digital assets like cryptocurrencies. One approach for diversification is the application of community detection or clustering, using a network representing the relationships between assets. We examine two network representations, one based on a standard distance matrix based on correlation, and another based on mutual information. The Louvain and Affinity propagation algorithms were employed for finding the network communities (clusters) based on annual data. Furthermore, we examine building assets' co-occurrence networks, where communities are detected for each month throughout a whole year and then the links represent how often assets belong to the same community. Portfolios are then constructed by selecting several assets from each community based on local properties (degree centrality), global properties (closeness centrality), or explained variance (Principal component analysis), with three value ranges (max, med, min), calculated on a maximal spanning tree or a fully connected community sub-graph. We explored these various strategies on data from the S\&amp;P 500 and the Top 203 cryptocurrencies with a market cap above 2M USD in the period from Jan 2019 to Sep 2022. Moreover, we study into more details the periods of the beginning of the COVID-19 outbreak and the start of the war in Ukraine. The results confirm some of the previous findings already known for traditional stock markets and provide some further insights, while they reveal an opposing trend in the crypto-assets market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11739v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitar Kitanovski, Igor Mishkovski, Viktor Stojkoski, Miroslav Mirchev</dc:creator>
    </item>
    <item>
      <title>Deviations from the Nash equilibrium and emergence of tacit collusion in a two-player optimal execution game with reinforcement learning</title>
      <link>https://arxiv.org/abs/2408.11773</link>
      <description>arXiv:2408.11773v1 Announce Type: cross 
Abstract: The use of reinforcement learning algorithms in financial trading is becoming increasingly prevalent. However, the autonomous nature of these algorithms can lead to unexpected outcomes that deviate from traditional game-theoretical predictions and may even destabilize markets. In this study, we examine a scenario in which two autonomous agents, modeled with Double Deep Q-Learning, learn to liquidate the same asset optimally in the presence of market impact, using the Almgren-Chriss (2000) framework. Our results show that the strategies learned by the agents deviate significantly from the Nash equilibrium of the corresponding market impact game. Notably, the learned strategies exhibit tacit collusion, closely aligning with the Pareto-optimal solution. We further explore how different levels of market volatility influence the agents' performance and the equilibria they discover, including scenarios where volatility differs between the training and testing phases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11773v1</guid>
      <category>q-fin.TR</category>
      <category>econ.GN</category>
      <category>q-fin.CP</category>
      <category>q-fin.EC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabrizio Lillo, Andrea Macr\`i</dc:creator>
    </item>
    <item>
      <title>From Time-inconsistency to Time-consistency for Optimal Stopping Problems</title>
      <link>https://arxiv.org/abs/2404.02498</link>
      <description>arXiv:2404.02498v2 Announce Type: replace 
Abstract: For optimal stopping problems with time-inconsistent preference, we measure the inherent level of time-inconsistency by taking the time needed to turn the naive strategies into the sophisticated ones. In particular, when in a repeated experiment the naive agent can observe her actual sequence of actions which are inconsistent with what she has planned at the initial time, she then chooses her immediate action based on the observations on her later actual behavior. The procedure is repeated until her actual sequence of actions are consistent with her plan at any time. We show that for the preference value of cumulative prospect theory, in which the time-inconsistency is due to the probability distortion, the higher the degree of probability distortion, the more severe the level of time-inconsistency, and the more time required to turn the naive strategies into the sophisticated ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02498v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sang Hu, Zihan Zhou</dc:creator>
    </item>
  </channel>
</rss>
