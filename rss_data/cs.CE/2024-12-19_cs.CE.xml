<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Dec 2024 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Generative Optimization: A Perspective on AI-Enhanced Problem Solving in Engineering</title>
      <link>https://arxiv.org/abs/2412.13281</link>
      <description>arXiv:2412.13281v1 Announce Type: new 
Abstract: The field of engineering is shaped by the tools and methods used to solve problems. Optimization is one such class of powerful, robust, and effective engineering tools proven over decades of use. Within just a few years, generative artificial intelligence (GenAI) has risen as another promising tool for general-purpose problem-solving. While optimization shines at finding high-quality and precise solutions that satisfy constraints, GenAI excels at inferring problem requirements, bridging solution domains, handling mixed data modalities, and rapidly generating copious numbers of solutions. These differing attributes also make the two frameworks complementary. Hybrid generative optimization algorithms present a new paradigm for engineering problem-solving and have shown promise across a few engineering applications. We expect significant developments in the near future around generative optimization, leading to changes in how engineers solve problems using computational tools. We offer our perspective on existing methods, areas of promise, and key research questions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13281v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cyril Picard, Lyle Regenwetter, Amin Heyrani Nobari, Akash Srivastava, Faez Ahmed</dc:creator>
    </item>
    <item>
      <title>Inverse design of anisotropic microstructures using physics-augmented neural networks</title>
      <link>https://arxiv.org/abs/2412.13370</link>
      <description>arXiv:2412.13370v1 Announce Type: new 
Abstract: Composite materials often exhibit mechanical anisotropy owing to the material properties or geometrical configurations of the microstructure. This makes their inverse design a two-fold problem. First, we must learn the type and orientation of anisotropy and then find the optimal design parameters to achieve the desired mechanical response. In our work, we solve this challenge by first training a forward surrogate model based on the macroscopic stress-strain data obtained via computational homogenization for a given multiscale material. To this end, we use partially Input Convex Neural Networks (pICNNs) to obtain a polyconvex representation of the strain energy in terms of the invariants of the Cauchy-Green deformation tensor. The network architecture and the strain energy function are modified to incorporate, by construction, physics and mechanistic assumptions into the framework. While training the neural network, we find the type of anisotropy, if any, along with the preferred directions. Once the model is trained, we solve the inverse problem using an evolution strategy to obtain the design parameters that give a desired mechanical response. We test the framework against synthetic macroscale and also homogenized data. For cases where polyconvexity might be violated during the homogenization process, we present viable alternate formulations. The trained model is also integrated into a finite element framework to invert design parameters that result in a desired macroscopic response. We show that the invariant-based model is able to solve the inverse problem for a stress-strain dataset with a different preferred direction than the one it was trained on and is able to not only learn the polyconvex potentials of hyperelastic materials but also recover the correct parameters for the inverse design problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13370v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Asghar A. Jadoon, Karl A. Kalina, Manuel K. Rausch, Reese Jones, Jan N. Fuhg</dc:creator>
    </item>
    <item>
      <title>Stochastic Analysis of Retention Time of Coupled Memory Topology</title>
      <link>https://arxiv.org/abs/2412.13197</link>
      <description>arXiv:2412.13197v1 Announce Type: cross 
Abstract: Recently, it has been experimentally demonstrated that individual memory units coupled in certain topology can provide the intended performance. However, experimental or simulation based evaluation of different coupled memory topologies and materials are costly and time consuming. In this paper, inspired by Glauber dynamics models in non-equilibrium statistical mechanics, we propose a physically accurate generic mathematical framework for analyzing retention times of various coupled memory topologies and materials. We demonstrate efficacy of the proposed framework by deriving closed form expressions for a few popular coupled and uncoupled memory topologies, which match simulations. Our analysis also offers analytical insights helping us estimate the impact of materials and topologies on retention time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13197v1</guid>
      <category>cs.ET</category>
      <category>cs.CE</category>
      <category>physics.app-ph</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirudh Bangalore Shankar, Avhishek Chatterjee, Bhaswar Chakrabarti, Anjan Chakravorty</dc:creator>
    </item>
    <item>
      <title>Uncertainty separation via ensemble quantile regression</title>
      <link>https://arxiv.org/abs/2412.13738</link>
      <description>arXiv:2412.13738v1 Announce Type: cross 
Abstract: This paper introduces a novel and scalable framework for uncertainty estimation and separation with applications in data driven modeling in science and engineering tasks where reliable uncertainty quantification is critical. Leveraging an ensemble of quantile regression (E-QR) models, our approach enhances aleatoric uncertainty estimation while preserving the quality of epistemic uncertainty, surpassing competing methods, such as Deep Ensembles (DE) and Monte Carlo (MC) dropout. To address challenges in separating uncertainty types, we propose an algorithm that iteratively improves separation through progressive sampling in regions of high uncertainty. Our framework is scalable to large datasets and demonstrates superior performance on synthetic benchmarks, offering a robust tool for uncertainty quantification in data-driven applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13738v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Navid Ansari, Hans-Peter Seidel, Vahid Babaei</dc:creator>
    </item>
    <item>
      <title>Deep encoder-decoder hierarchical convolutional neural networks for conjugate heat transfer surrogate modeling</title>
      <link>https://arxiv.org/abs/2311.17068</link>
      <description>arXiv:2311.17068v2 Announce Type: replace 
Abstract: Conjugate heat transfer (CHT) analyses are vital for the design of many energy systems. However, high-fidelity CHT numerical simulations are computationally intensive, which limits their applications such as design optimization, where hundreds to thousands of evaluations are required. In this work, we develop a modular deep encoder-decoder hierarchical (DeepEDH) convolutional neural network, a novel deep-learning-based surrogate modeling methodology for computationally intensive CHT analyses. Leveraging convective temperature dependencies, we propose a two-stage temperature prediction architecture that couples velocity and temperature fields. The proposed DeepEDH methodology is demonstrated by modeling the pressure, velocity, and temperature fields for a liquid-cooled cold-plate-based battery thermal management system with variable channel geometry. A computational mesh and CHT formulation of the cold plate is created and solved using the finite element method (FEM), generating a dataset of 1,500 simulations. Our performance analysis covers the impact of the novel architecture, separate DeepEDH models for each field, output geometry masks, multi-stage temperature field predictions, and optimizations of the hyperparameters and architecture. Furthermore, we quantify the influence of the CHT analysis' thermal boundary conditions on surrogate model performance, highlighting improved temperature model performance with higher heat fluxes. Compared to other deep learning neural network surrogate models, such as U-Net and DenseED, the proposed DeepEDH architecture for CHT analyses exhibits up to a 65% enhancement in the coefficient of determination $R^{2}$. (*Due to the notification of arXiv "The Abstract field cannot be longer than 1,920 characters", the appeared Abstract is shortened. For the full Abstract, please download the Article.)</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.17068v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apenergy.2024.123723</arxiv:DOI>
      <arxiv:journal_reference>Applied Energy 372 (2024) 123723</arxiv:journal_reference>
      <dc:creator>Takiah Ebbs-Picken, David A. Romero, Carlos M. Da Silva, Cristina H. Amon</dc:creator>
    </item>
    <item>
      <title>Reducing computational effort in topology optimization considering the deformation in additive manufacturing</title>
      <link>https://arxiv.org/abs/2403.02711</link>
      <description>arXiv:2403.02711v2 Announce Type: replace 
Abstract: Integrating topology optimization and additive manufacturing (AM) technology can facilitate innovative product development. However, laser powder bed fusion, which is the predominant method in metal AM, can lead to issues such as residual stress and deformation. Recently, topology optimization methods considering these stresses and deformations have been proposed; however, they suffer from challenges caused by an increased computational cost. In this study, we propose a method for reducing computational cost in topology optimization considering the deformation in AM. An inherent strain method-based analytical model is presented for simulating the residual stress and deformation in the AM process. Subsequently, a constraint condition to suppress the deformation is formulated, and a method to reduce the computational cost of the adjoint analysis in deriving sensitivity is proposed. The minimum mean compliance problem considering AM deformation and self-support constraints can then be incorporated into the level set-based topology optimization framework. Finally, numerical examples are presented for validating the effectiveness of the proposed topology optimization method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02711v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takao Miki</dc:creator>
    </item>
    <item>
      <title>Level set-based inverse homogenisation of three-dimensional piezoelectric materials</title>
      <link>https://arxiv.org/abs/2410.03148</link>
      <description>arXiv:2410.03148v2 Announce Type: replace 
Abstract: In this paper we use memory-distributed level set-based topology optimisation to design three-dimensional periodic piezoelectric materials with enhanced properties. We compare and assess several existing iterative solvers with respect to their weak scalability and find that an approximate Schur complement preconditioned generalized minimal residual method method demonstrates the best performance and scalability for solving the piezoelectric homogenisation equations. We use the developed techniques to computationally design high-resolution piezoelectric metamaterials with enhanced stiffness and piezoelectric properties that yield new insights into material design for sensor, hydrophone, and actuator applications. We suggest two robust structures with no fine-scale features features that exhibit enhanced piezoelectric properties several times larger than those of the base material. We find that level set-based topology optimisation is well suited to problems involving piezoelectricity and has the advantage of avoiding large regions of intermediate density material. Our memory-distributed level-set implementation is open source and provided for practitioners in the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03148v2</guid>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachary J. Wegert, Anthony P. Roberts, Vivien J. Challis</dc:creator>
    </item>
    <item>
      <title>Topological Separation of Vortices</title>
      <link>https://arxiv.org/abs/2407.03384</link>
      <description>arXiv:2407.03384v3 Announce Type: replace-cross 
Abstract: Vortices and their analysis play a critical role in the understanding of complex phenomena in turbulent flows. Traditional vortex extraction methods, notably region-based techniques, often overlook the entanglement phenomenon, resulting in the inclusion of multiple vortices within a single extracted region. Their separation is necessary for quantifying different types of vortices and their statistics. In this study, we propose a novel vortex separation method that extends the conventional contour tree-based segmentation approach with an additional step termed "layering". Upon extracting a vortical region using specified vortex criteria (e.g., $\lambda_2$), we initially establish topological segmentation based on the contour tree, followed by the layering process to allocate appropriate segmentation IDs to unsegmented cells, thus separating individual vortices within the region. However, these regions may still suffer from inaccurate splits, which we address statistically by leveraging the continuity of vorticity lines across the split boundaries. Our findings demonstrate a significant improvement in both the separation of vortices and the mitigation of inaccurate splits compared to prior methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03384v3</guid>
      <category>physics.flu-dyn</category>
      <category>cs.CE</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adeel Zafar, Zahra Poorshayegh, Di Yang, Guoning Chen</dc:creator>
    </item>
    <item>
      <title>Beyond Monte Carlo: Harnessing Diffusion Models to Simulate Financial Market Dynamics</title>
      <link>https://arxiv.org/abs/2412.00036</link>
      <description>arXiv:2412.00036v2 Announce Type: replace-cross 
Abstract: We propose a highly efficient and accurate methodology for generating synthetic financial market data using a diffusion model approach. The synthetic data produced by our methodology align closely with observed market data in several key aspects: (i) they pass the two-sample Cramer - von Mises test for portfolios of assets, and (ii) Q - Q plots demonstrate consistency across quantiles, including in the tails, between observed and generated market data. Moreover, the covariance matrices derived from a large set of synthetic market data exhibit significantly lower condition numbers compared to the estimated covariance matrices of the observed data. This property makes them suitable for use as regularized versions of the latter. For model training, we develop an efficient and fast algorithm based on numerical integration rather than Monte Carlo simulations. The methodology is tested on a large set of equity data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00036v2</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>q-fin.PM</category>
      <pubDate>Thu, 19 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Lesniewski, Giulio Trigila</dc:creator>
    </item>
  </channel>
</rss>
