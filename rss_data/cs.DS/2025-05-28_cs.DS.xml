<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 May 2025 01:54:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Colouring Probe $H$-Free Graphs</title>
      <link>https://arxiv.org/abs/2505.20784</link>
      <description>arXiv:2505.20784v1 Announce Type: new 
Abstract: The NP-complete problems Colouring and k-Colouring $(k\geq 3$) are well studied on $H$-free graphs, i.e., graphs that do not contain some fixed graph $H$ as an induced subgraph. We research to what extent the known polynomial-time algorithms for $H$-free graphs can be generalized if we only know some of the edges of the input graph. We do this by considering the classical probe graph model introduced in the early nineties. For a graph $H$, a partitioned probe $H$-free graph $(G,P,N)$ consists of a graph $G=(V,E)$, together with a set $P\subseteq V$ of probes and an independent set $N=V\setminus P$ of non-probes, such that $G+F$ is $H$-free for some edge set $F\subseteq \binom{N}{2}$. We first fully classify the complexity of Colouring on partitioned probe $H$-free graphs and show that this dichotomy is different from the known dichotomy of Colouring for $H$-free graphs. Our main result is a dichotomy of $3$-Colouring for partitioned probe $P_t$-free graphs: we prove that the problem is polynomial-time solvable if $t\leq 5$ but NP-complete if $t\geq 6$. In contrast, $3$-Colouring on $P_t$-free graphs is known to be polynomial-time solvable if $t\leq 7$ and quasi polynomial-time solvable for $t\geq 8$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20784v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dani\"el Paulusma, Johannes Rauch, Erik Jan van Leeuwen</dc:creator>
    </item>
    <item>
      <title>Course Allocation with Credits via Stable Matching</title>
      <link>https://arxiv.org/abs/2505.21229</link>
      <description>arXiv:2505.21229v1 Announce Type: new 
Abstract: In the {\sc Course Allocation} problem, there are a set of students and a set of courses at a given university. University courses may have different numbers of credits, typically related to different numbers of learning hours, and there may be other constraints such as courses running concurrently. Our goal is to allocate the students to the courses such that the resulting matching is stable, which means that no student and course(s) have an incentive to break away from the matching and become assigned to one another. We study several definitions of stability and for each we give a mixture of polynomial-time algorithms and hardness results for problems involving verifying the stability of a matching, finding a stable matching or determining that none exists, and finding a maximum size stable matching. We also study variants of the problem with master lists of students, and lower quotas on the number of students allocated to a course, establishing additional complexity results in these settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21229v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jos\'e Rodr\'iguez, David Manlove</dc:creator>
    </item>
    <item>
      <title>Scheduling with Uncertain Holding Costs and its Application to Content Moderation</title>
      <link>https://arxiv.org/abs/2505.21331</link>
      <description>arXiv:2505.21331v1 Announce Type: new 
Abstract: In content moderation for social media platforms, the cost of delaying the review of a content is proportional to its view trajectory, which fluctuates and is apriori unknown. Motivated by such uncertain holding costs, we consider a queueing model where job states evolve based on a Markov chain with state-dependent instantaneous holding costs. We demonstrate that in the presence of such uncertain holding costs, the two canonical algorithmic principles, instantaneous-cost ($c\mu$-rule) and expected-remaining-cost ($c\mu/\theta$-rule), are suboptimal. By viewing each job as a Markovian ski-rental problem, we develop a new index-based algorithm, Opportunity-adjusted Remaining Cost (OaRC), that adjusts to the opportunity of serving jobs in the future when uncertainty partly resolves. We show that the regret of OaRC scales as $\tilde{O}(L^{1.5}\sqrt{N})$, where $L$ is the maximum length of a job's holding cost trajectory and $N$ is the system size. This regret bound shows that OaRC achieves asymptotic optimality when the system size $N$ scales to infinity. Moreover, its regret is independent of the state-space size, which is a desirable property when job states contain contextual information. We corroborate our results with an extensive simulation study based on two holding cost patterns (online ads and user-generated content) that arise in content moderation for social media platforms. Our simulations based on synthetic and real datasets demonstrate that OaRC consistently outperforms existing practice, which is based on the two canonical algorithmic principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21331v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <category>math.PR</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caner Gocmen, Thodoris Lykouris, Deeksha Sinha, Wentao Weng</dc:creator>
    </item>
    <item>
      <title>Optimal Approximations for the Requirement Cut Problem on Sparse Graph Classes</title>
      <link>https://arxiv.org/abs/2505.21433</link>
      <description>arXiv:2505.21433v2 Announce Type: new 
Abstract: We study the Requirement Cut problem, a generalization of numerous classical graph partitioning problems including Multicut, Multiway Cut, $k$-Cut, and Steiner Multicut among others. Given a graph with edge costs, terminal groups $(S_1, ..., S_g)$ and integer requirements $(r_1,... , r_g)$; the goal is to compute a minimum-cost edge cut that separates each group $S_i$ into at least $r_i$ connected components. Despite many efforts, the best known approximation for Requirement Cut yields a double-logarithmic $O(\log(g).\log(n))$ approximation ratio as it relies on embedding general graphs into trees and solving the tree instance.
  In this paper, we explore two largely unstudied structural parameters in order to obtain single-logarithmic approximation ratios: (1) the number of minimal Steiner trees in the instance, which in particular is upper-bounded by the number of spanning trees of the graphs multiplied by $g$, and (2) the depth of series-parallel graphs. Specifically, we show that if the number of minimal Steiner trees is polynomial in $n$, then a simple LP-rounding algorithm yields an $O(\log n)$-approximation, and if the graph is series-parallel with a constant depth then a refined analysis of a known probabilistic embedding yields a $O(depth.\log(g))$-approximation on series-parallel graphs of bounded depth. Both results extend the known class of graphs that have a single-logarithmic approximation ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21433v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nadym Mallek, Kirill Simonov</dc:creator>
    </item>
    <item>
      <title>Strong Low Degree Hardness for the Number Partitioning Problem</title>
      <link>https://arxiv.org/abs/2505.20607</link>
      <description>arXiv:2505.20607v1 Announce Type: cross 
Abstract: In the number partitioning problem (NPP) one aims to partition a given set of $N$ real numbers into two subsets with approximately equal sum. The NPP is a well-studied optimization problem and is famous for possessing a statistical-to-computational gap: when the $N$ numbers to be partitioned are i.i.d. standard gaussian, the optimal discrepancy is $2^{-\Theta(N)}$ with high probability, but the best known polynomial-time algorithms only find solutions with a discrepancy of $2^{-\Theta(\log^2 N)}$. This gap is a common feature in optimization problems over random combinatorial structures, and indicates the need for a study that goes beyond worst-case analysis.
  We provide evidence of a nearly tight algorithmic barrier for the number partitioning problem. Namely we consider the family of low coordinate degree algorithms (with randomized rounding into the Boolean cube), and show that degree $D$ algorithms fail to solve the NPP to accuracy beyond $2^{-\widetilde O(D)}$. According to the low degree heuristic, this suggests that simple brute-force search algorithms are nearly unimprovable, given any allotted runtime between polynomial and exponential in $N$. Our proof combines the isolation of solutions in the landscape with a conditional form of the overlap gap property: given a good solution to an NPP instance, slightly noising the NPP instance typically leaves no good solutions near the original one. In fact our analysis applies whenever the $N$ numbers to be partitioned are independent with uniformly bounded density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20607v1</guid>
      <category>math.ST</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rushil Mallarapu, Mark Sellke</dc:creator>
    </item>
    <item>
      <title>Complexity landscape for local certification</title>
      <link>https://arxiv.org/abs/2505.20915</link>
      <description>arXiv:2505.20915v1 Announce Type: cross 
Abstract: An impressive recent line of work has charted the complexity landscape of distributed graph algorithms. For many settings, it has been determined which time complexities exist, and which do not (in the sense that no local problem could have an optimal algorithm with that complexity). In this paper, we initiate the study of the landscape for space complexity of distributed graph algorithms. More precisely, we focus on the local certification setting, where a prover assigns certificates to nodes to certify a property, and where the space complexity is measured by the size of the certificates.
  Already for anonymous paths and cycles, we unveil a surprising landscape:
  - There is a gap between complexity $O(1)$ and $\Theta(\log \log n)$ in paths. This is the first gap established in local certification.
  - There exists a property that has complexity $\Theta(\log \log n)$ in paths, a regime that was not known to exist for a natural property.
  - There is a gap between complexity $O(1)$ and $\Theta(\log n)$ in cycles, hence a gap that is exponentially larger than for paths.
  We then generalize our result for paths to the class of trees. Namely, we show that there is a gap between complexity $O(1)$ and $\Theta(\log \log d)$ in trees, where $d$ is the diameter. We finally describe some settings where there are no gaps at all. To prove our results we develop a new toolkit, based on various results of automata theory and arithmetic, which is of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20915v1</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Bousquet, Laurent Feuilloley, S\'ebastien Zeitoun</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Calibration from Swap Regret</title>
      <link>https://arxiv.org/abs/2505.21460</link>
      <description>arXiv:2505.21460v1 Announce Type: cross 
Abstract: We study the online calibration of multi-dimensional forecasts over an arbitrary convex set $\mathcal{P} \subset \mathbb{R}^d$ relative to an arbitrary norm $\Vert\cdot\Vert$. We connect this with the problem of external regret minimization for online linear optimization, showing that if it is possible to guarantee $O(\sqrt{\rho T})$ worst-case regret after $T$ rounds when actions are drawn from $\mathcal{P}$ and losses are drawn from the dual $\Vert \cdot \Vert_*$ unit norm ball, then it is also possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\rho /\epsilon^2))$ rounds. When $\mathcal{P}$ is the $d$-dimensional simplex and $\Vert \cdot \Vert$ is the $\ell_1$-norm, the existence of $O(\sqrt{T\log d})$-regret algorithms for learning with experts implies that it is possible to obtain $\epsilon$-calibrated forecasts after $T = \exp(O(\log{d}/\epsilon^2)) = d^{O(1/\epsilon^2)}$ rounds, recovering a recent result of Peng (2025).
  Interestingly, our algorithm obtains this guarantee without requiring access to any online linear optimization subroutine or knowledge of the optimal rate $\rho$ -- in fact, our algorithm is identical for every setting of $\mathcal{P}$ and $\Vert \cdot \Vert$. Instead, we show that the optimal regularizer for the above OLO problem can be used to upper bound the above calibration error by a swap regret, which we then minimize by running the recent TreeSwap algorithm with Follow-The-Leader as a subroutine.
  Finally, we prove that any online calibration algorithm that guarantees $\epsilon T$ $\ell_1$-calibration error over the $d$-dimensional simplex requires $T \geq \exp(\mathrm{poly}(1/\epsilon))$ (assuming $d \geq \mathrm{poly}(1/\epsilon)$). This strengthens the corresponding $d^{\Omega(\log{1/\epsilon})}$ lower bound of Peng, and shows that an exponential dependence on $1/\epsilon$ is necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21460v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxwell Fishelson, Noah Golowich, Mehryar Mohri, Jon Schneider</dc:creator>
    </item>
    <item>
      <title>Algorithms and SQ Lower Bounds for Robustly Learning Real-valued Multi-index Models</title>
      <link>https://arxiv.org/abs/2505.21475</link>
      <description>arXiv:2505.21475v1 Announce Type: cross 
Abstract: We study the complexity of learning real-valued Multi-Index Models (MIMs) under the Gaussian distribution. A $K$-MIM is a function $f:\mathbb{R}^d\to \mathbb{R}$ that depends only on the projection of its input onto a $K$-dimensional subspace. We give a general algorithm for PAC learning a broad class of MIMs with respect to the square loss, even in the presence of adversarial label noise. Moreover, we establish a nearly matching Statistical Query (SQ) lower bound, providing evidence that the complexity of our algorithm is qualitatively optimal as a function of the dimension. Specifically, we consider the class of bounded variation MIMs with the property that degree at most $m$ distinguishing moments exist with respect to projections onto any subspace. In the presence of adversarial label noise, the complexity of our learning algorithm is $d^{O(m)}2^{\mathrm{poly}(K/\epsilon)}$. For the realizable and independent noise settings, our algorithm incurs complexity $d^{O(m)}2^{\mathrm{poly}(K)}(1/\epsilon)^{O(K)}$. To complement our upper bound, we show that if for some subspace degree-$m$ distinguishing moments do not exist, then any SQ learner for the corresponding class of MIMs requires complexity $d^{\Omega(m)}$. As an application, we give the first efficient learner for the class of positive-homogeneous $L$-Lipschitz $K$-MIMs. The resulting algorithm has complexity $\mathrm{poly}(d) 2^{\mathrm{poly}(KL/\epsilon)}$. This gives a new PAC learning algorithm for Lipschitz homogeneous ReLU networks with complexity independent of the network size, removing the exponential dependence incurred in prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21475v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Giannis Iakovidis, Daniel M. Kane, Lisheng Ren</dc:creator>
    </item>
    <item>
      <title>The Complexity of Diameter on H-free graphs</title>
      <link>https://arxiv.org/abs/2402.16678</link>
      <description>arXiv:2402.16678v4 Announce Type: replace 
Abstract: The intensively studied Diameter problem is to find the diameter of a given connected graph. We investigate, for the first time in a structured manner, the complexity of Diameter for H-free graphs, that is, graphs that do not contain a fixed graph H as an induced subgraph. We first show that if H is not a linear forest with small components, then Diameter cannot be solved in subquadratic time for H-free graphs under SETH. For some small linear forests, we do show linear-time algorithms for solving Diameter. For other linear forests H, we make progress towards linear-time algorithms by considering specific diameter values. If H is a linear forest, the maximum value of the diameter of any graph in a connected H-free graph class is some constant dmax dependent only on H. We give linear-time algorithms for deciding if a connected H-free graph has diameter dmax, for several linear forests H. In contrast, for one such linear forest H, Diameter cannot be solved in subquadratic time for H-free graphs under SETH. Moreover, we even show that, for several other linear forests H, one cannot decide in subquadratic time if a connected H-free graph has diameter dmax under SETH.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16678v4</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jelle J. Oostveen, Dani\"el Paulusma, Erik Jan van Leeuwen</dc:creator>
    </item>
    <item>
      <title>Work-Efficient Parallel Counting via Sampling</title>
      <link>https://arxiv.org/abs/2408.09719</link>
      <description>arXiv:2408.09719v2 Announce Type: replace 
Abstract: A canonical approach to approximating the partition function of a Gibbs distribution via sampling is simulated annealing. This method has led to efficient reductions from counting to sampling, including:
  $\bullet$ classic non-adaptive (parallel) algorithms with sub-optimal cost (Dyer-Frieze-Kannan '89; Bez\'akov\'a-\v{S}tefankovi\v{c}-Vazirani-Vigoda '08);
  $\bullet$ adaptive (sequential) algorithms with near-optimal cost (\v{S}tefankovi\v{c}-Vempala-Vigoda '09; Huber '15; Kolmogorov '18; Harris-Kolmogorov '24).
  We present an algorithm that achieves both near-optimal total work and efficient parallelism, providing a reduction from counting to sampling with logarithmic depth and near-optimal work. As consequences, we obtain work-efficient parallel counting algorithms for several important models, including the hardcore and Ising models within the uniqueness regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09719v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongyang Liu, Yitong Yin, Yiyao Zhang</dc:creator>
    </item>
    <item>
      <title>U-index: A Universal Indexing Framework for Matching Long Patterns</title>
      <link>https://arxiv.org/abs/2502.14488</link>
      <description>arXiv:2502.14488v3 Announce Type: replace 
Abstract: Text indexing is a fundamental and well-studied problem. Classic solutions either replace the original text with a compressed representation, e.g., the FM-index and its variants, or keep it uncompressed but attach some redundancy - an index - to accelerate matching. The former solutions thus retain excellent compressed space, but are slow in practice. The latter approaches, like the suffix array, instead sacrifice space for speed.
  We show that efficient text indexing can be achieved using just a small extra space on top of the original text, provided that the query patterns are sufficiently long. More specifically, we develop a new indexing paradigm in which a sketch of a query pattern is first matched against a sketch of the text. Once candidate matches are retrieved, they are verified using the original text. This paradigm is thus universal in the sense that it allows us to use any solution to index the sketched text, like a suffix array, FM-index, or r-index.
  We explore both the theory and the practice of this universal framework. With an extensive experimental analysis, we show that, surprisingly, universal indexes can be constructed much faster than their unsketched counterparts and take a fraction of the space, as a direct consequence of (i) having a lower bound on the length of patterns and (ii) working in sketch space. Furthermore, these data structures have the potential of retaining or even improving query time, because matching against the sketched text is faster and verifying candidates can be theoretically done in constant time per occurrence (or, in practice, by short and cache-friendly scans of the text). Finally, we discuss some important applications of this novel indexing paradigm to computational biology. We hypothesize that such indexes will be particularly effective when the queries are sufficiently long, and so demonstrate applications in long-read mapping.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14488v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorraine A. K. Ayad, Gabriele Fici, Ragnar Groot Koerkamp, Grigorios Loukides, Rob Patro, Giulio Ermanno Pibiri, Solon P. Pissis</dc:creator>
    </item>
    <item>
      <title>PtrHash: Minimal Perfect Hashing at RAM Throughput</title>
      <link>https://arxiv.org/abs/2502.15539</link>
      <description>arXiv:2502.15539v2 Announce Type: replace 
Abstract: Given a set $K$ of $n$ keys, a minimal perfect hash function (MPHF) is a collision-free bijective map $\mathsf{H_{mphf}}$ from $K$ to $\{0, \dots, n-1\}$. This work presents a (minimal) perfect hash function that first prioritizes query throughput, while also allowing efficient construction for $10^9$ or more elements using 2.4 bits of memory per key.
  Both PTHash and PHOBIC first map all $n$ keys to $n/\lambda &lt; n$ buckets. Then, each bucket stores a pilot that controls the final hash value of the keys mapping to it. PtrHash builds on this by using 1) fixed-width (uncompressed) 8-bit pilots, 2) a construction algorithm similar to cuckoo-hashing to find suitable pilot values. Further, it 3) uses the same number of buckets and slots for each part, with 4) a single remap table to map intermediate positions $\geq n$ to $&lt;n$, 5) encoded using per-cacheline Elias-Fano coding. Lastly, 6) PtrHash support streaming queries, where we use prefetching to answer a stream of multiple queries more efficiently than one-by-one processing.
  With default parameters, PtrHash takes 2.0 bits per key. On 300 million string keys, PtrHash is as fast or faster to build than other MPHFs, and at least $2.1\times$ faster to query. When streaming multiple queries, this improves to $3.3\times$ speedup over the fastest alternative, while also being significantly faster to construct. When using $10^9$ integer keys instead, query times are as low as 12 ns/key when iterating in a for loop, or even down to 8 ns/key when using the streaming approach, just short of the 7.4 ns inverse throughput of random memory accesses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15539v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ragnar Groot Koerkamp</dc:creator>
    </item>
    <item>
      <title>Enumeration Algorithms for Conjunctive Queries with Projection</title>
      <link>https://arxiv.org/abs/2101.03712</link>
      <description>arXiv:2101.03712v5 Announce Type: replace-cross 
Abstract: We investigate the enumeration of query results for an important subset of CQs with projections, namely star and path queries. The task is to design data structures and algorithms that allow for efficient enumeration with delay guarantees after a preprocessing phase. Our main contribution is a series of results based on the idea of interleaving precomputed output with further join processing to maintain delay guarantees, which maybe of independent interest. In particular, for star queries, we design combinatorial algorithms that provide instance-specific delay guarantees in linear preprocessing time. These algorithms improve upon the currently best known results. Further, we show how existing results can be improved upon by using fast matrix multiplication. We also present new results involving tradeoff between preprocessing time and delay guarantees for enumeration of path queries that contain projections. Boolean matrix multiplication is an important query that can be expressed as a CQ with projection where the join attribute is projected away. Our results can therefore also be interpreted as sparse, output-sensitive matrix multiplication with delay guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.03712v5</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaleen Deep, Xiao Hu, Paraschos Koutris</dc:creator>
    </item>
    <item>
      <title>Elementary first-order model checking for sparse graphs</title>
      <link>https://arxiv.org/abs/2401.16230</link>
      <description>arXiv:2401.16230v2 Announce Type: replace-cross 
Abstract: It is known that for subgraph-closed graph classes the first-order model checking problem is fixed-parameter tractable if and only if the class is nowhere dense [Grohe, Kreutzer, Siebertz, STOC 2014]. However, the dependency on the formula size is non-elementary, and in fact, this is unavoidable even for the class of all trees [Frick and Grohe, LICS 2002]. On the other hand, it is known that the dependency is elementary for classes of bounded degree [Frick and Grohe, LICS 2002] as well as for classes of bounded pathwidth [Lampis, ICALP 2023]. In this paper we generalise these results and almost completely characterise subgraph-closed graph classes for which the model checking problem is fixed-parameter tractable with an elementary dependency on the formula size. Those are the graph classes for which there exists a number $d$ such that for every $r$, some tree of depth $d$ and size bounded by an elementary function of $r$ is avoided as an $({\leq} r)$-subdivision in all graphs in the class. In particular, this implies that if the class in question excludes a fixed tree as a topological minor, then first-order model checking for graphs in the class is fixed-parameter tractable with an elementary dependency on the formula size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16230v2</guid>
      <category>cs.LO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.LO</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Gajarsk\'y, Micha{\l} Pilipczuk, Marek Soko{\l}owski, Giannos Stamoulis, Szymon Toru\'nczyk</dc:creator>
    </item>
    <item>
      <title>An average case efficient algorithm for solving two-variable linear Diophantine equations</title>
      <link>https://arxiv.org/abs/2409.14052</link>
      <description>arXiv:2409.14052v4 Announce Type: replace-cross 
Abstract: We revisit two algorithms to solve two-variable linear Diophantine equations. We write the iterative version of one of them. For another, we analyze the number of recursive calls. We find that the number of recursive calls is a periodic function. We derive the period of this function and various upper bounds on this function. We find that for a fixed value of $a$, $b$ and $a$ varying $c$, such that equation $ax+by = c$ (where $a &gt; b$) is solvable, we can find the solution in $O\left(\frac{\log b}{gcd(a,b)}\right)$ average number of recursions. We computationally evaluate and verify this bound. We compare this bound and another bound with the average number of recursive calls in Extended Euclid's algorithm on random $512$-bit inputs. We propose an iterative version of the algorithm. Our algorithm performs better in terms of the average number of iterations against the two existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14052v4</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.NT</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mayank Deora, Pinakpani Pal</dc:creator>
    </item>
    <item>
      <title>Achieving adaptivity and optimality for multi-armed bandits using Exponential-Kullback Leibler Maillard Sampling</title>
      <link>https://arxiv.org/abs/2502.14379</link>
      <description>arXiv:2502.14379v2 Announce Type: replace-cross 
Abstract: We study the problem of $K$-armed bandits with reward distributions belonging to a one-parameter exponential distribution family. In the literature, several criteria have been proposed to evaluate the performance of such algorithms, including Asymptotic Optimality, Minimax Optimality, Sub-UCB, and variance-adaptive worst-case regret bound. Thompson Sampling-based and Upper Confidence Bound-based algorithms have been employed to achieve some of these criteria. However, none of these algorithms simultaneously satisfy all the aforementioned criteria.
  In this paper, we design an algorithm, Exponential Kullback-Leibler Maillard Sampling (abbrev. Exp-KL-MS), that can achieve multiple optimality criteria simultaneously, including Asymptotic Optimality, Minimax Optimality with a $\sqrt{\ln (K)}$ factor, Sub-UCB, and variance-adaptive worst-case regret bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14379v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Qin, Kwang-Sung Jun, Chicheng Zhang</dc:creator>
    </item>
    <item>
      <title>Grassroots Consensus</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v2 Announce Type: replace-cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic and decentralized/plutocratic alike. Within the grassroots architecture, consensus is needed to realize platforms that employ digital social contracts, which are like smart contracts except that they are among people not accounts and are executed by these people's smartphones not by high-performance servers controlled by parties outside to the contract. Key envisioned grassroots platforms include sovereign democratic digital communities and federations, community banks and their grassroots cryptocurrencies, and digital cooperatives.
  The grassroots architecture can benefit from a consensus protocol that is (i) quiescent, (ii) efficient during low- and high-throughput, (iii) responsive, (iv) blocklace-based, (v) UDP-ready, and (vi) grassroots. The Grassroots Consensus protocol addresses all these requirements while having competitive performance in both low- and high-throughput scenarios and being one of the most concise and elegant consensus protocols for partial synchrony. It achieves that by building on two cutting-edge consensus protocols -- the quiescent high-performance Morpheus and the blocklace-based Cordial Miners, improving the latter's dissemination protocol and making it UDP-ready, and extending the protocol with a constitution and a constitutional amendment component, making it grassroots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v2</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Wed, 28 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro</dc:creator>
    </item>
  </channel>
</rss>
