<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 02:41:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The Artificial Benchmark for Community Detection with Outliers and Overlapping Communities (ABCD+$o^2$)</title>
      <link>https://arxiv.org/abs/2506.05486</link>
      <description>arXiv:2506.05486v1 Announce Type: new 
Abstract: The Artificial Benchmark for Community Detection (ABCD) graph is a random graph model with community structure and power-law distribution for both degrees and community sizes. The model generates graphs similar to the well-known LFR model but it is faster, more interpretable, and can be investigated analytically. In this paper, we use the underlying ingredients of the ABCD model, and its generalization to include outliers (ABCD+$o$), and introduce another variant that allows for overlapping communities, ABCD+$o^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05486v1</guid>
      <category>cs.SI</category>
      <category>math.CO</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jordan Barrett, Ryan DeWolfe, Bogumi{\l} Kami\'nski, Pawe{\l} Pra{\l}at, Aaron Smith, Fran\c{c}ois Th\'eberge</dc:creator>
    </item>
    <item>
      <title>Understanding Community-Level Blocklists in Decentralized Social Media</title>
      <link>https://arxiv.org/abs/2506.05522</link>
      <description>arXiv:2506.05522v1 Announce Type: new 
Abstract: Community-level blocklists are key to content moderation practices in decentralized social media. These blocklists enable moderators to prevent other communities, such as those acting in bad faith, from interacting with their own -- and, if shared publicly, warn others about communities worth blocking. Prior work has examined blocklists in centralized social media, noting their potential for collective moderation outcomes, but has focused on blocklists as individual-level tools. To understand how moderators perceive and utilize community-level blocklists and what additional support they may need, we examine social media communities running Mastodon, an open-source microblogging software built on the ActivityPub protocol. We conducted (1) content analysis of the community-level blocklist ecosystem, and (2) semi-structured interviews with twelve Mastodon moderators. Our content analysis revealed wide variation in blocklist goals, inclusion criteria, and transparency. Interviews showed moderators balance proactive safety, reactive practices, and caution around false positives when using blocklists for moderation. They noted challenges and limitations in current blocklist use, suggesting design improvements like comment receipts, category filters, and collaborative voting. We discuss implications for decentralized content moderation, highlighting trade-offs between openness, safety, and nuance; the complexity of moderator roles; and opportunities for future design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05522v1</guid>
      <category>cs.SI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Owen Xingjian Zhang, Sohyeon Hwang, Yuhan Liu, Manoel Horta Ribeiro, Andr\'es Monroy-Hern\'andez</dc:creator>
    </item>
    <item>
      <title>Detecting Coordination on Short-Video Platforms: The Challenge of Multimodality and Complex Similarity on TikTok</title>
      <link>https://arxiv.org/abs/2506.05868</link>
      <description>arXiv:2506.05868v1 Announce Type: new 
Abstract: Research on online coordinated behaviour has predominantly focused on text-based social media platforms, where coordination manifests clearly through the frequent posting of identical hyperlinks or the frequent re-sharing of the same textual content by the same group of users. However, the rise of short-video platforms like TikTok introduces distinct challenges, by supporting integrated multimodality within posts and complex similarity between them. In this paper, we propose an approach to detecting coordination that addresses these characteristic challenges. Our methodology, based on multilayer network analysis, is tailored to capture coordination across multiple modalities, including video, audio, and text, and explicitly handles complex forms of similarity inherent in video and audio content. We test this approach on political videos posted on TikTok and extracted via the TikTok researcher API. This application demonstrates the capacity of the approach to identify coordination, while also critically highlighting potential pitfalls and limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05868v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Inga K. Wohlert, Davide Vega, Matteo Magnani, Alexandra Sergerberg</dc:creator>
    </item>
    <item>
      <title>Measuring the co-evolution of online engagement with (mis)information and its visibility at scale</title>
      <link>https://arxiv.org/abs/2506.06106</link>
      <description>arXiv:2506.06106v1 Announce Type: new 
Abstract: Online attention is an increasingly valuable resource in the digital age, with extraordinary events such as the COVID-19 pandemic fuelling fierce competition around it. As misinformation pervades online platforms, users seek credible sources, while news outlets compete to attract and retain their attention. Here we measure the co-evolution of online "engagement" with (mis)information and its "visibility", where engagement corresponds to user interactions on social media, and visibility to fluctuations in user follower counts. Using a scalable temporal network modelling framework applied to over 100 million COVID-related retweets spanning 3 years, we find that highly engaged sources experience sharp spikes in follower growth during major events (e.g., vaccine rollouts, epidemic severity), whereas sources with more questionable credibility tend to sustain faster growth outside of these periods. Our framework lends itself to studying other large-scale events where online attention is at stake, such as climate and political debates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06106v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yueting Han, Paolo Turrini, Marya Bazzi, Giulia Andrighetto, Eugenia Polizzi, Manlio De Domenico</dc:creator>
    </item>
    <item>
      <title>Personalized Large Language Models Can Increase the Belief Accuracy of Social Networks</title>
      <link>https://arxiv.org/abs/2506.06153</link>
      <description>arXiv:2506.06153v1 Announce Type: new 
Abstract: Large language models (LLMs) are increasingly involved in shaping public understanding on contested issues. This has led to substantial discussion about the potential of LLMs to reinforce or correct misperceptions. While existing literature documents the impact of LLMs on individuals' beliefs, limited work explores how LLMs affect social networks. We address this gap with a pre-registered experiment (N = 1265) around the 2024 US presidential election, where we empirically explore the impact of personalized LLMs on belief accuracy in the context of social networks. The LLMs are constructed to be personalized, offering messages tailored to individuals' profiles, and to have guardrails for accurate information retrieval. We find that the presence of a personalized LLM leads individuals to update their beliefs towards the truth. More importantly, individuals with a personalized LLM in their social network not only choose to follow it, indicating they would like to obtain information from it in subsequent interactions, but also construct subsequent social networks to include other individuals with beliefs similar to the LLM -- in this case, more accurate beliefs. Therefore, our results show that LLMs have the capacity to influence individual beliefs and the social networks in which people exist, and highlight the potential of LLMs to act as corrective agents in online environments. Our findings can inform future strategies for responsible AI-mediated communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06153v1</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adiba Mahbub Proma, Neeley Pate, Sean Kelty, Gourab Ghoshal, James N. Druckman, Ehsan Hoque</dc:creator>
    </item>
    <item>
      <title>Masked Language Models are Good Heterogeneous Graph Generalizers</title>
      <link>https://arxiv.org/abs/2506.06157</link>
      <description>arXiv:2506.06157v1 Announce Type: new 
Abstract: Heterogeneous graph neural networks (HGNNs) excel at capturing structural and semantic information in heterogeneous graphs (HGs), while struggling to generalize across domains and tasks. Recently, some researchers have turned to integrating HGNNs with large language models (LLMs) for more generalizable heterogeneous graph learning. However, these approaches typically extract structural information via HGNNs as HG tokens, and disparities in embedding spaces between HGNNs and LLMs have been shown to bias the LLM's comprehension of HGs. Moreover, as these HG tokens are often derived from node-level tasks, the model's ability to generalize across tasks remains limited. To this end, we propose a simple yet effective Masked Language Modeling-based method, called MLM4HG. MLM4HG introduces metapath-based textual sequences instead of HG tokens to extract structural and semantic information inherent in HGs, and designs customized textual templates to unify different graph tasks into a coherent cloze-style "mask" token prediction paradigm. Specifically, MLM4HG first converts HGs from various domains to texts based on metapaths, and subsequently combines them with the unified task texts to form a HG-based corpus. Moreover, the corpus is fed into a pretrained LM for fine-tuning with a constrained target vocabulary, enabling the fine-tuned LM to generalize to unseen target HGs. Extensive cross-domain and multi-task experiments on four real-world datasets demonstrate the superior generalization performance of MLM4HG over state-of-the-art methods in both few-shot and zero-shot scenarios. Our code is available at https://github.com/BUPT-GAMMA/MLM4HG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06157v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinyu Yang, Cheng Yang, Shanyuan Cui, Zeyuan Guo, Liangwei Yang, Muhan Zhang, Chuan Shi</dc:creator>
    </item>
    <item>
      <title>HGOT: Self-supervised Heterogeneous Graph Neural Network with Optimal Transport</title>
      <link>https://arxiv.org/abs/2506.02619</link>
      <description>arXiv:2506.02619v1 Announce Type: cross 
Abstract: Heterogeneous Graph Neural Networks (HGNNs), have demonstrated excellent capabilities in processing heterogeneous information networks. Self-supervised learning on heterogeneous graphs, especially contrastive self-supervised strategy, shows great potential when there are no labels. However, this approach requires the use of carefully designed graph augmentation strategies and the selection of positive and negative samples. Determining the exact level of similarity between sample pairs is non-trivial.To solve this problem, we propose a novel self-supervised Heterogeneous graph neural network with Optimal Transport (HGOT) method which is designed to facilitate self-supervised learning for heterogeneous graphs without graph augmentation strategies. Different from traditional contrastive self-supervised learning, HGOT employs the optimal transport mechanism to relieve the laborious sampling process of positive and negative samples. Specifically, we design an aggregating view (central view) to integrate the semantic information contained in the views represented by different meta-paths (branch views). Then, we introduce an optimal transport plan to identify the transport relationship between the semantics contained in the branch view and the central view. This allows the optimal transport plan between graphs to align with the representations, forcing the encoder to learn node representations that are more similar to the graph space and of higher quality. Extensive experiments on four real-world datasets demonstrate that our proposed HGOT model can achieve state-of-the-art performance on various downstream tasks. In particular, in the node classification task, HGOT achieves an average of more than 6% improvement in accuracy compared with state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02619v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanbei Liu, Chongxu Wang, Zhitao Xiao, Lei Geng, Yanwei Pang, Xiao Wang</dc:creator>
    </item>
    <item>
      <title>Combating Misinformation in the Arab World: Challenges &amp; Opportunities</title>
      <link>https://arxiv.org/abs/2506.05582</link>
      <description>arXiv:2506.05582v1 Announce Type: cross 
Abstract: Misinformation and disinformation pose significant risks globally, with the Arab region facing unique vulnerabilities due to geopolitical instabilities, linguistic diversity, and cultural nuances. We explore these challenges through the key facets of combating misinformation: detection, tracking, mitigation and community-engagement. We shed light on how connecting with grass-roots fact-checking organizations, understanding cultural norms, promoting social correction, and creating strong collaborative information networks can create opportunities for a more resilient information ecosystem in the Arab world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05582v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3737450</arxiv:DOI>
      <dc:creator>Azza Abouzied, Firoj Alam, Raian Ali, Paolo Papotti</dc:creator>
    </item>
    <item>
      <title>Positional Encoding meets Persistent Homology on Graphs</title>
      <link>https://arxiv.org/abs/2506.05814</link>
      <description>arXiv:2506.05814v1 Announce Type: cross 
Abstract: The local inductive bias of message-passing graph neural networks (GNNs) hampers their ability to exploit key structural information (e.g., connectivity and cycles). Positional encoding (PE) and Persistent Homology (PH) have emerged as two promising approaches to mitigate this issue. PE schemes endow GNNs with location-aware features, while PH methods enhance GNNs with multiresolution topological features. However, a rigorous theoretical characterization of the relative merits and shortcomings of PE and PH has remained elusive. We bridge this gap by establishing that neither paradigm is more expressive than the other, providing novel constructions where one approach fails but the other succeeds. Our insights inform the design of a novel learnable method, PiPE (Persistence-informed Positional Encoding), which is provably more expressive than both PH and PE. PiPE demonstrates strong performance across a variety of tasks (e.g., molecule property prediction, graph classification, and out-of-distribution generalization), thereby advancing the frontiers of graph representation learning. Code is available at https://github.com/Aalto-QuML/PIPE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05814v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yogesh Verma, Amauri H. Souza, Vikas Garg</dc:creator>
    </item>
    <item>
      <title>Computing well-balanced spanning trees of unweighted networks</title>
      <link>https://arxiv.org/abs/2205.06628</link>
      <description>arXiv:2205.06628v3 Announce Type: replace 
Abstract: A spanning tree of a network or graph is a subgraph that connects all nodes with the least number or weight of edges. The spanning tree is one of the most straightforward techniques for network simplification and sampling, and for discovering its backbone or skeleton. Prim's algorithm and Kruskal's algorithm are well-known algorithms for computing a spanning tree of a weighted network, and are therefore also the default procedure for unweighted networks in the most popular network libraries. In this paper, we empirically study the performance of these algorithms on unweighted networks and compare them with different priority-first search algorithms. We show that the structure of a network, such as the distances between the nodes, is better preserved by a simpler algorithm based on breadth-first search. The spanning trees are also most compact and well-balanced as measured by classical graph indices. We support our findings with experiments on synthetic graphs and more than a thousand real networks, and demonstrate practical applications of the computed spanning trees. We conclude that if a spanning tree is to maintain the structure of an unweighted network, the breadth-first search algorithm should be the preferred choice, and it should be implemented as such in network libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.06628v3</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lovro \v{S}ubelj</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network Generalization with Gaussian Mixture Model Based Augmentation</title>
      <link>https://arxiv.org/abs/2411.08638</link>
      <description>arXiv:2411.08638v3 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) have shown great promise in tasks like node and graph classification, but they often struggle to generalize, particularly to unseen or out-of-distribution (OOD) data. These challenges are exacerbated when training data is limited in size or diversity. To address these issues, we introduce a theoretical framework using Rademacher complexity to compute a regret bound on the generalization error and then characterize the effect of data augmentation. This framework informs the design of GRATIN, an efficient graph data augmentation algorithm leveraging the capability of Gaussian Mixture Models (GMMs) to approximate any distribution. Our approach not only outperforms existing augmentation techniques in terms of generalization but also offers improved time complexity, making it highly suitable for real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08638v3</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>International Conference on Machine Learning (ICML) 2025</arxiv:journal_reference>
      <dc:creator>Yassine Abbahaddou, Fragkiskos D. Malliaros, Johannes F. Lutzeyer, Amine Mohamed Aboussalah, Michalis Vazirgiannis</dc:creator>
    </item>
    <item>
      <title>User Altruism in Recommendation Systems</title>
      <link>https://arxiv.org/abs/2506.04525</link>
      <description>arXiv:2506.04525v2 Announce Type: replace-cross 
Abstract: Users of social media platforms based on recommendation systems (RecSys) (e.g. TikTok, X, YouTube) strategically interact with platform content to influence future recommendations. On some such platforms, users have been documented to form large-scale grassroots movements encouraging others to purposefully interact with algorithmically suppressed content in order to "boost" its recommendation; we term this behavior user altruism. To capture this behavior, we study a game between users and a RecSys, where users provide the RecSys (potentially manipulated) preferences over the contents available to them, and the RecSys -- limited by data and computation constraints -- creates a low-rank approximation preference matrix, and ultimately provides each user her (approximately) most-preferred item. We compare the users' social welfare under truthful preference reporting and under a class of strategies capturing user altruism. In our theoretical analysis, we provide sufficient conditions to ensure strict increases in user social welfare under user altruism, and provide an algorithm to find an effective altruistic strategy. Interestingly, we show that for commonly assumed recommender utility functions, effectively altruistic strategies also improve the utility of the RecSys! We show that our results are robust to several model misspecifications, thus strengthening our conclusions. Our theoretical analysis is complemented by empirical results of effective altruistic strategies on the GoodReads dataset, and an online survey on how real-world users behave altruistically in RecSys. Overall, our findings serve as a proof-of-concept of the reasons why traditional RecSys may incentivize users to form collectives and/or follow altruistic strategies when interacting with them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04525v2</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Mon, 09 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ekaterina Fedorova, Madeline Kitch, Chara Podimata</dc:creator>
    </item>
  </channel>
</rss>
