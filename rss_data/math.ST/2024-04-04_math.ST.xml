<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Apr 2024 04:00:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Consistency of the bootstrap for asymptotically linear estimators based on machine learning</title>
      <link>https://arxiv.org/abs/2404.03064</link>
      <description>arXiv:2404.03064v1 Announce Type: new 
Abstract: The bootstrap is a popular method of constructing confidence intervals due to its ease of use and broad applicability. Theoretical properties of bootstrap procedures have been established in a variety of settings. However, there is limited theoretical research on the use of the bootstrap in the context of estimation of a differentiable functional in a nonparametric or semiparametric model when nuisance functions are estimated using machine learning. In this article, we provide general conditions for consistency of the bootstrap in such scenarios. Our results cover a range of estimator constructions, nuisance estimation methods, bootstrap sampling distributions, and bootstrap confidence interval types. We provide refined results for the empirical bootstrap and smoothed bootstraps, and for one-step estimators, plug-in estimators, empirical mean plug-in estimators, and estimating equations-based estimators. We illustrate the use of our general results by demonstrating the asymptotic validity of bootstrap confidence intervals for the average density value and G-computed conditional mean parameters, and compare their performance in finite samples using numerical studies. Throughout, we emphasize whether and how the bootstrap can produce asymptotically valid confidence intervals when standard methods fail to do so.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03064v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhou Tang, Ted Westling</dc:creator>
    </item>
    <item>
      <title>Robust estimators for the log-logistic model based on ranked set sampling</title>
      <link>https://arxiv.org/abs/2404.03346</link>
      <description>arXiv:2404.03346v1 Announce Type: new 
Abstract: In this paper we introduce a new family of estimators for the parameters of shape and scale of the log-logistic distribution being robust when rank set sample method is used to select the data. Rank set sampling arises as a way to reduce the impact of extremal data. Log-logistic distribution is an important distribution suitable for modeling many different situations ranging from Economy to Engineering and Hydrology. This new family of estimators is based on density power divergences. The choice of this family of divergence measures is motivated by the fact that they have shown a very good behavior in terms of robustness at a reduced cost in efficiency. This new family recovers the classical maximum likelihood estimator as a special case. We have developed the form of these estimators and derived their corresponding asymptotic distribution. A simulation study is carried out, suggesting that these new estimators are very robust when contamination arises and are competitive with classical estimators in terms of efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03346v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Angel Felipe, Mar\'ia Jaenada, Pedro Miranda, Leandro Pardo</dc:creator>
    </item>
    <item>
      <title>Combining exchangeable p-values</title>
      <link>https://arxiv.org/abs/2404.03484</link>
      <description>arXiv:2404.03484v1 Announce Type: new 
Abstract: Significant recent progress has been made on deriving combination rules that can take as input a set of arbitrarily dependent p-values, and produce as output a single valid p-value. Here, we show that under the assumption of exchangeability of the p-values, many of those rules can be improved (made more powerful). While this observation by itself has practical implications (for example, under repeated tests involving data splitting), it also has implications for combining arbitrarily dependent p-values, since the latter can be made exchangeable by applying a uniformly random permutation. In particular, we derive several simple randomized combination rules for arbitrarily dependent p-values that are more powerful than their deterministic counterparts. For example, we derive randomized and exchangeable improvements of well known p-value combination rules like "twice the median" and "twice the average", as well as geometric and harmonic means. The main technical advance is to show that all these combination rules can be obtained by calibrating the p-values to e-values (using an $\alpha$-dependent calibrator), averaging those e-values, converting to a level $\alpha$ test using Markov's inequality, and finally obtaining p-values by combining this family of tests. The improvements are delivered via recent randomized and exchangeable variants of Markov's inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03484v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Gasparin, Ruodu Wang, Aaditya Ramdas</dc:creator>
    </item>
    <item>
      <title>Generalized R\'enyi statistics</title>
      <link>https://arxiv.org/abs/2404.03548</link>
      <description>arXiv:2404.03548v1 Announce Type: new 
Abstract: In R\'enyi's representation for exponential order statistics, we change the iid exponential sequence to any iid sequence, and call the resulting order statistic \emph{generalized R\'enyi statistic}. We prove that randomly reordering the variables in the generalized R\'enyi statistic, in the limit we obtain a sequence of iid exponentials. This result allows us to propose a new model for heavy-tailed data. We investigate the problem of estimation of the tail index in the new model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03548v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P\'eter Kevei, L\'aszl\'o Viharos</dc:creator>
    </item>
    <item>
      <title>Asymptotically-exact selective inference for quantile regression</title>
      <link>https://arxiv.org/abs/2404.03059</link>
      <description>arXiv:2404.03059v1 Announce Type: cross 
Abstract: When analyzing large datasets, it is common to select a model prior to making inferences. For reliable inferences, it is important to make adjustments that account for the model selection process, resulting in selective inferences. Our paper introduces an asymptotic pivot to infer about the effects of selected variables on conditional quantile functions. Utilizing estimators from smoothed quantile regression, our proposed pivot is easy to compute and ensures asymptotically-exact selective inferences without making strict distributional assumptions about the response variable. At the core of the pivot is the use of external randomization, which enables us to utilize the full sample for both selection and inference without the need to partition the data into independent data subsets or discard data at either step. On simulated data, we find that: (i) the asymptotic confidence intervals based on our pivot achieve the desired coverage rates, even in cases where sample splitting fails due to insufficient sample size for inference; (ii) our intervals are consistently shorter than those produced by sample splitting across various models and signal settings. We report similar findings when we apply our approach to study risk factors for low birth weights in a publicly accessible dataset of US birth records from 2022.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03059v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yumeng Wang, Snigdha Panigrahi, Xuming He</dc:creator>
    </item>
    <item>
      <title>Cryptographic Hardness of Score Estimation</title>
      <link>https://arxiv.org/abs/2404.03272</link>
      <description>arXiv:2404.03272v1 Announce Type: cross 
Abstract: We show that $L^2$-accurate score estimation, in the absence of strong assumptions on the data distribution, is computationally hard even when sample complexity is polynomial in the relevant problem parameters. Our reduction builds on the result of Chen et al. (ICLR 2023), who showed that the problem of generating samples from an unknown data distribution reduces to $L^2$-accurate score estimation. Our hard-to-estimate distributions are the "Gaussian pancakes" distributions, originally due to Diakonikolas et al. (FOCS 2017), which have been shown to be computationally indistinguishable from the standard Gaussian under widely believed hardness assumptions from lattice-based cryptography (Bruna et al., STOC 2021; Gupte et al., FOCS 2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03272v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Min Jae Song</dc:creator>
    </item>
    <item>
      <title>Gaussian-Smoothed Sliced Probability Divergences</title>
      <link>https://arxiv.org/abs/2404.03273</link>
      <description>arXiv:2404.03273v1 Announce Type: cross 
Abstract: Gaussian smoothed sliced Wasserstein distance has been recently introduced for comparing probability distributions, while preserving privacy on the data. It has been shown that it provides performances similar to its non-smoothed (non-private) counterpart. However, the computationaland statistical properties of such a metric have not yet been well-established. This work investigates the theoretical properties of this distance as well as those of generalized versions denoted as Gaussian-smoothed sliced divergences. We first show that smoothing and slicing preserve the metric property and the weak topology. To study the sample complexity of such divergences, we then introduce $\hat{\hat\mu}_{n}$ the double empirical distribution for the smoothed-projected $\mu$. The distribution $\hat{\hat\mu}_{n}$ is a result of a double sampling process: one from sampling according to the origin distribution $\mu$ and the second according to the convolution of the projection of $\mu$ on the unit sphere and the Gaussian smoothing. We particularly focus on the Gaussian smoothed sliced Wasserstein distance and prove that it converges with a rate $O(n^{-1/2})$. We also derive other properties, including continuity, of different divergences with respect to the smoothing parameter. We support our theoretical findings with empirical studies in the context of privacy-preserving domain adaptation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03273v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mokhtar Z. Alaya (LMAC), Alain Rakotomamonjy (LITIS), Maxime Berar (LITIS), Gilles Gasso (LITIS)</dc:creator>
    </item>
    <item>
      <title>Conditioning of Banach Space Valued Gaussian Random Variables: An Approximation Approach Based on Martingales</title>
      <link>https://arxiv.org/abs/2404.03453</link>
      <description>arXiv:2404.03453v1 Announce Type: cross 
Abstract: In this paper we investigate the conditional distributions of two Banach space valued, jointly Gaussian random variables. These conditional distributions are again Gaussian and their means and covariances are determined by a general approximation scheme based upon a martingale idea. We then apply our general results to the case of Gaussian processes with continuous paths conditioned to partial observations of their paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03453v1</guid>
      <category>math.PR</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ingo Steinwart</dc:creator>
    </item>
    <item>
      <title>Online Estimation with Rolling Validation: Adaptive Nonparametric Estimation with Streaming Data</title>
      <link>https://arxiv.org/abs/2310.12140</link>
      <description>arXiv:2310.12140v2 Announce Type: replace 
Abstract: Online nonparametric estimators are gaining popularity due to their efficient computation and competitive generalization abilities. An important example includes variants of stochastic gradient descent. These algorithms often take one sample point at a time and instantly update the parameter estimate of interest. In this work we consider model selection and hyperparameter tuning for such online algorithms. We propose a weighted rolling-validation procedure, an online variant of leave-one-out cross-validation, that costs minimal extra computation for many typical stochastic gradient descent estimators. Similar to batch cross-validation, it can boost base estimators to achieve a better, adaptive convergence rate. Our theoretical analysis is straightforward, relying mainly on some general statistical stability assumptions. The simulation study underscores the significance of diverging weights in rolling validation in practice and demonstrates its sensitivity even when there is only a slim difference between candidate estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12140v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tianyu Zhang, Jing Lei</dc:creator>
    </item>
    <item>
      <title>A replica analysis of Self-Training of Linear Classifier</title>
      <link>https://arxiv.org/abs/2205.07739</link>
      <description>arXiv:2205.07739v2 Announce Type: replace-cross 
Abstract: Self-training (ST) is a simple and standard approach in semi-supervised learning that has been applied to many machine learning problems. Despite its widespread acceptance and practical effectiveness, it is still not well understood why and how ST improves performance by fitting the model to potentially erroneous pseudo-labels. To investigate the properties of ST, in this study, we derive and analyze a sharp characterization of the behavior of iterative ST when training a linear classifier by minimizing the ridge-regularized convex loss for binary Gaussian mixtures, in the asymptotic limit where input dimension and data size diverge proportionally. The derivation is based on the replica method of statistical mechanics. The result indicates that, when the total number of iterations is large, ST may find a classification plane with the optimal direction regardless of the label imbalance by accumulating small parameter updates over long iterations. It is argued that this is because the small update of ST can accumulate information of the data in an almost noiseless way. However, when a label imbalance is present in true labels, the performance of the ST is significantly lower than that of supervised learning with true labels, because the ratio between the norm of the weight and the magnitude of the bias can become significantly large. To overcome the problems in label imbalanced cases, several heuristics are introduced. By numerically analyzing the asymptotic formula, it is demonstrated that with the proposed heuristics, ST can find a classifier whose performance is nearly compatible with supervised learning using true labels even in the presence of significant label imbalance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07739v2</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takashi Takahashi</dc:creator>
    </item>
    <item>
      <title>Semiparametric adaptive estimation under informative sampling</title>
      <link>https://arxiv.org/abs/2208.06039</link>
      <description>arXiv:2208.06039v3 Announce Type: replace-cross 
Abstract: In survey sampling, survey data do not necessarily represent the target population, and the samples are often biased. However, information on the survey weights aids in the elimination of selection bias. The Horvitz-Thompson estimator is a well-known unbiased, consistent, and asymptotically normal estimator; however, it is not efficient. Thus, this study derives the semiparametric efficiency bound for various target parameters by considering the survey weight as a random variable and consequently proposes a semiparametric optimal estimator with certain working models on the survey weights. The proposed estimator is consistent, asymptotically normal, and efficient in a class of the regular and asymptotically linear estimators. Further, a limited simulation study is conducted to investigate the finite sample performance of the proposed method. The proposed method is applied to the 1999 Canadian Workplace and Employee Survey data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.06039v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kosuke Morikawa, Yoshikazu Terada, Jae Kwang Kim</dc:creator>
    </item>
    <item>
      <title>High-dimensional scaling limits and fluctuations of online least-squares SGD with smooth covariance</title>
      <link>https://arxiv.org/abs/2304.00707</link>
      <description>arXiv:2304.00707v2 Announce Type: replace-cross 
Abstract: We derive high-dimensional scaling limits and fluctuations for the online least-squares Stochastic Gradient Descent (SGD) algorithm by taking the properties of the data generating model explicitly into consideration. Our approach treats the SGD iterates as an interacting particle system, where the expected interaction is characterized by the covariance structure of the input. Assuming smoothness conditions on moments of order up to eight orders, and without explicitly assuming Gaussianity, we establish the high-dimensional scaling limits and fluctuations in the form of infinite-dimensional Ordinary Differential Equations (ODEs) or Stochastic Differential Equations (SDEs). Our results reveal a precise three-step phase transition of the iterates; it goes from being ballistic, to diffusive, and finally to purely random behavior, as the noise variance goes from low, to moderate and finally to very-high noise setting. In the low-noise setting, we further characterize the precise fluctuations of the (scaled) iterates as infinite-dimensional SDEs. We also show the existence and uniqueness of solutions to the derived limiting ODEs and SDEs. Our results have several applications, including characterization of the limiting mean-square estimation or prediction errors and their fluctuations, which can be obtained by analytically or numerically solving the limiting equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00707v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krishnakumar Balasubramanian, Promit Ghosal, Ye He</dc:creator>
    </item>
    <item>
      <title>Speeding up Monte Carlo Integration: Control Neighbors for Optimal Convergence</title>
      <link>https://arxiv.org/abs/2305.06151</link>
      <description>arXiv:2305.06151v3 Announce Type: replace-cross 
Abstract: A novel linear integration rule called $\textit{control neighbors}$ is proposed in which nearest neighbor estimates act as control variates to speed up the convergence rate of the Monte Carlo procedure on metric spaces. The main result is the $\mathcal{O}(n^{-1/2} n^{-s/d})$ convergence rate -- where $n$ stands for the number of evaluations of the integrand and $d$ for the dimension of the domain -- of this estimate for H\"older functions with regularity $s \in (0,1]$, a rate which, in some sense, is optimal. Several numerical experiments validate the complexity bound and highlight the good performance of the proposed estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.06151v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R\'emi Leluc, Fran\c{c}ois Portier, Johan Segers, Aigerim Zhuman</dc:creator>
    </item>
  </channel>
</rss>
