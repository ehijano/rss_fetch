<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:51 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A concise introduction to Koopman operator theory and the Extended Dynamic Mode Decomposition</title>
      <link>https://arxiv.org/abs/2410.02766</link>
      <description>arXiv:2410.02766v1 Announce Type: new 
Abstract: The framework of Koopman operator theory is discussed along with its connections to Dynamic Mode Decomposition (DMD) and (Kernel) Extended Dynamic Mode Decomposition (EDMD). This paper provides a succinct overview with consistent notation. The authors hope to provide an exposition that more naturally emphasizes the connections between theory and algorithms which may result in a sense of clarity on the subject.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02766v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christophe Patyn, Geert Deconinck</dc:creator>
    </item>
    <item>
      <title>A M\"untz-collocation spectral method for weakly singular Volterra delay-integro-differential equations</title>
      <link>https://arxiv.org/abs/2410.02784</link>
      <description>arXiv:2410.02784v1 Announce Type: new 
Abstract: A M\"untz spectral collocation method is implemented for solving weakly singular Volterra integro-differential equations (VDIEs) with proportional delays. After constructing the numerical scheme to seek an approximate solution, we derive error estimates in a weighted $L^2$ and $L^{\infty}$-norms. A rigorous proof reveals that the proposed method can handle the weak singularity of the exact solution at the initial point $t=0$, with the numerical errors decaying exponentially in certain cases. Moreover, several examples will illustrate our convergence analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02784v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Borui Zhao</dc:creator>
    </item>
    <item>
      <title>Boundary Interpolation on Triangles via Neural Network Operators</title>
      <link>https://arxiv.org/abs/2410.02793</link>
      <description>arXiv:2410.02793v1 Announce Type: new 
Abstract: The primary objective of this study is to develop novel interpolation operators that interpolate the boundary values of a function defined on a triangle. This is accomplished by constructing New Generalized Boolean sum neural network operator $\mathcal{B}_{n_1, n_2, \xi }$ using a class of activation functions. Its interpolation properties are established and the estimates for the error of approximation corresponding to operator $\mathcal{B}_{n_1, n_2, \xi }$ is computed in terms of mixed modulus of continuity. The advantage of our method is that it does not require training the network. Instead, the number of hidden neurons adjusts the weights and bias. Numerical examples are illustrated to show the efficacy of these newly constructed operators. Further, with the help of MATLAB, comparative and graphical analysis is given to show the validity and efficiency of the results obtained for these operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02793v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.FA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aaqib Ayoub Bhat, Asif Khan</dc:creator>
    </item>
    <item>
      <title>Mathematical Considerations on Randomized Orthgonal Decomposition Method for Developing Twin Data Models</title>
      <link>https://arxiv.org/abs/2410.02813</link>
      <description>arXiv:2410.02813v1 Announce Type: new 
Abstract: This paper introduces the approach of Randomized Orthogonal Decomposition (ROD) for producing twin data models in order to overcome the drawbacks of existing reduced order modelling techniques. When compared to Fourier empirical decomposition, ROD provides orthonormal shape modes that maximize their projection on the data space, which is a significant benefit. A shock wave event described by the viscous Burgers equation model is used to illustrate and evaluate the novel method. The new twin data model is thoroughly evaluated using certain criteria of numerical accuracy and computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02813v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Transylvanian Journal of Mathematics and Mechanics, 14 (2), 105-115, 2022</arxiv:journal_reference>
      <dc:creator>Diana A. Bistrian</dc:creator>
    </item>
    <item>
      <title>Neural Networks in Numerical Analysis and Approximation Theory</title>
      <link>https://arxiv.org/abs/2410.02814</link>
      <description>arXiv:2410.02814v1 Announce Type: new 
Abstract: In this Master Thesis, we study the approximation capabilities of Neural Networks in the context of numerical resolution of elliptic PDEs and Approximation Theory. First of all, in Chapter 1, we introduce the mathematical definition of Neural Networks and perform some basic estimates on their composition and parallelization. Then, we implement in Chapter 2 the Galerkin method using Neural Network. In particular, we manage to build a Neural Network that approximates the inverse of positive-definite symmetric matrices, which allows to get a Garlerkin numerical solution of elliptic PDEs. Finally, in Chapter 3, we introduce the approximation space of Neural Networks, a space which consists of functions in $L^p$ that are approximated at a certain rate when increasing the number of weights of Neural Networks. We find the relation of this space with the Besov space: the smoother a function is, the faster it can be approximated with Neural Networks when increasing the number of weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02814v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Gonzalo Romera</dc:creator>
    </item>
    <item>
      <title>Physics-Informed Graph-Mesh Networks for PDEs: A hybrid approach for complex problems</title>
      <link>https://arxiv.org/abs/2410.02819</link>
      <description>arXiv:2410.02819v1 Announce Type: new 
Abstract: The recent rise of deep learning has led to numerous applications, including solving partial differential equations using Physics-Informed Neural Networks. This approach has proven highly effective in several academic cases. However, their lack of physical invariances, coupled with other significant weaknesses, such as an inability to handle complex geometries or their lack of generalization capabilities, make them unable to compete with classical numerical solvers in industrial settings. In this work, a limitation regarding the use of automatic differentiation in the context of physics-informed learning is highlighted. A hybrid approach combining physics-informed graph neural networks with numerical kernels from finite elements is introduced. After studying the theoretical properties of our model, we apply it to complex geometries, in two and three dimensions. Our choices are supported by an ablation study, and we evaluate the generalisation capacity of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02819v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.advengsoft.2024.103758</arxiv:DOI>
      <dc:creator>Marien Chenaud, Fr\'ed\'eric Magoul\`es, Jos\'e Alves</dc:creator>
    </item>
    <item>
      <title>A second order finite volume IMEX Runge-Kutta scheme for two dimensional PDEs in finance</title>
      <link>https://arxiv.org/abs/2410.02925</link>
      <description>arXiv:2410.02925v1 Announce Type: new 
Abstract: In this article we present a novel and general methodology for building second order finite volume implicit-explicit (IMEX) numerical schemes for solving two dimensional financial parabolic PDEs with mixed derivatives. In particular, applications to basket and Heston models are presented. The obtained numerical schemes have excellent properties and are able to overcome the well-documented difficulties related with numerical approximations in the financial literature. The methods achieve true second order convergence with non-regular initial conditions. Besides, the IMEX time integrator allows to overcome the tiny time-step induced by the diffusive term in the explicit schemes, also providing very accurate and non-oscillatory approximations of the Greeks. Finally, in order to assess all the aforementioned good properties of the developed numerical schemes, we compute extremely accurate semi-analytic solutions using multi-dimensional Fourier cosine expansions. A novel technique to truncate the Fourier series for basket options is presented and it is efficiently implemented using multi-GPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02925v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. G. L\'opez-Salas, M. Su\'arez-Taboada, M. J. Castro, A. M. Ferreiro-Ferreiro, J. A. Garc\'ia-Rodr\'iguez</dc:creator>
    </item>
    <item>
      <title>Boundary treatment for high-order IMEX Runge-Kutta local discontinuous Galerkin schemes for multidimensional nonlinear parabolic PDEs</title>
      <link>https://arxiv.org/abs/2410.02927</link>
      <description>arXiv:2410.02927v1 Announce Type: new 
Abstract: In this article, we propose novel boundary treatment algorithms to avoid order reduction when implicit-explicit Runge-Kutta time discretization is used for solving convection-diffusion-reaction problems with time-dependent Di\-richlet boundary conditions. We consider Cartesian meshes and PDEs with stiff terms coming from the diffusive parts of the PDE. The algorithms treat boundary values at the implicit-explicit internal stages in the same way as the interior points. The boundary treatment strategy is designed to work with multidimensional problems with possible nonlinear advection and source terms. The proposed methods recover the designed order of convergence by numerical verification. For the spatial discretization, in this work, we consider Local Discontinuous Galerkin methods, although the developed boundary treatment algorithms can operate with other discretization schemes in space, such as Finite Differences, Finite Elements or Finite Volumes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02927v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>q-fin.CP</category>
      <category>q-fin.MF</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>V. Gonz\'alez-Tabernero, J. G. L\'opez-Salas, M. J. Castro-D\'iaz, J. A. Garc\'ia-Rodr\'iguez</dc:creator>
    </item>
    <item>
      <title>Unisolvence of Kansa collocation for elliptic equations by polyharmonic splines with random fictitious centers</title>
      <link>https://arxiv.org/abs/2410.03279</link>
      <description>arXiv:2410.03279v1 Announce Type: new 
Abstract: We make a further step in the unisolvence open problem for unsymmetric Kansa collocation, proving nonsingularity of Kansa matrices with polyharmonic splines and random fictitious centers, for second-order elliptic equations with mixed boundary conditions. We also show some numerical tests, where the fictitious centers are local random perturbations of predetermined collocation points.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03279v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maryam Mohammadi, Alvise Sommariva, Marco Vianello</dc:creator>
    </item>
    <item>
      <title>Kernel Methods in the Deep Ritz framework: Theory and practice</title>
      <link>https://arxiv.org/abs/2410.03503</link>
      <description>arXiv:2410.03503v1 Announce Type: new 
Abstract: In this contribution, kernel approximations are applied as ansatz functions within the Deep Ritz method. This allows to approximate weak solutions of elliptic partial differential equations with weak enforcement of boundary conditions using Nitsche's method. A priori error estimates are proven in different norms leveraging both standard results for weak solutions of elliptic equations and well-established convergence results for kernel methods. This availability of a priori error estimates renders the method useful for practical purposes. The procedure is described in detail, meanwhile providing practical hints and implementation details. By means of numerical examples, the performance of the proposed approach is evaluated numerically and the results agree with the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03503v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Kleikamp, Tizian Wenzel</dc:creator>
    </item>
    <item>
      <title>Generalizing the Fr\'echet Derivative Algorithm for the Matrix Exponential</title>
      <link>https://arxiv.org/abs/2410.03575</link>
      <description>arXiv:2410.03575v1 Announce Type: new 
Abstract: The computation of off-diagonal blocks of matrix functions $f(T)$, where $T$ is block triangular, poses a challenging problem in scientific computing. We present a novel algorithm that exploits the structure of block triangular matrices, generalizing the algorithm of Al-Mohy and Higham for computing the Fr\'echet derivative of the matrix exponential. This work has significant applications in fields such as exponential integrators for solving systems of first-order differential equations, Hamiltonian linear systems in control theory, and option pricing in finance. Our approach introduces a linear operator that maps off-diagonal blocks of $T$ into their counterparts in $f(T)$. By studying the algebraic properties of the operator, we establish a comprehensive computational framework, paving the way to extend existing Fr\'echet derivative algorithms of matrix functions to more general settings. For the matrix exponential, in particular, the algorithm employs the scaling and squaring method with diagonal Pad\'e approximants to $\exp(x)$, with parameters chosen based on a rigorous backward error analysis, which notably does not depend on the norm of the off-diagonal blocks. The numerical experiment demonstrates that our algorithm surpasses existing algorithms in terms of accuracy and efficiency, making it highly valuable for a wide range of applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03575v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Awad H. Al-Mohy</dc:creator>
    </item>
    <item>
      <title>Stabilizing the Consistent Quasidiffusion Method with Linear Prolongation</title>
      <link>https://arxiv.org/abs/2410.03605</link>
      <description>arXiv:2410.03605v1 Announce Type: new 
Abstract: The quasidiffusion (QD) method, also known as the Variable Eddington Factor (VEF) method in the astrophysical community, is an established iterative method for accelerating source iterations in SN calculations. A great advantage of the QD method is that the diffusion equation that accelerates the SN source iterations can be discretized in any valid discretization without concern for consistency with the transport discretization. QD has comparable effectiveness with diffusion synthetic acceleration (DSA), but the converged scalar flux of the diffusion equation will differ from the transport solution by the spatial truncation errors. Larsen et al. introduced a new consistent QD method (CQD), which includes a straightforwardly defined transport consistency factor closely related to the well-known coarse mesh finite difference (CMFD) and diffusion synthetic acceleration (DSA) methods. The CQD method preserves the discretized scalar flux solution of the SN equations, and it is stable for problems with optically thin spatial cells, but just like nonlinear diffusion acceleration (NDA), it degrades in performance and eventually becomes unstable when the spatial cells become greater than about one mean free path thick. In this paper, we performed a formal Fourier analysis of the CQD method to show that its theoretical spectral radius is essentially the same as that of the NDA method. To improve the stability of CQD, we introduce the lpCQD method, which adopts the idea of the linear prolongation CMFD (lpCMFD) method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03605v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dean Wang</dc:creator>
    </item>
    <item>
      <title>A mixed-dimensional model for the electrostatic problem on coupled domains</title>
      <link>https://arxiv.org/abs/2410.03622</link>
      <description>arXiv:2410.03622v1 Announce Type: new 
Abstract: We derive a mixed-dimensional 3D-1D formulation of the electrostatic equation in two domains with different dielectric constants to compute, with an affordable computational cost, the electric field and potential in the relevant case of thin inclusions in a larger 3D domain. The numerical solution is obtained by Mixed Finite Elements for the 3D problem and Finite Elements on the 1D domain. We analyze some test cases with simple geometries to validate the proposed approach against analytical solutions, and perform comparisons with the fully resolved 3D problem. We treat the case where ramifications are present in the one-dimensional domain and show some results on the geometry of an electrical treeing, a ramified structure that propagates in insulators causing their failure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03622v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beatrice Crippa, Anna Scotti, Andrea Villa</dc:creator>
    </item>
    <item>
      <title>Sine-transform-based fast solvers for Riesz fractional nonlinear Schr\"odinger equations with attractive nonlinearities</title>
      <link>https://arxiv.org/abs/2410.03643</link>
      <description>arXiv:2410.03643v1 Announce Type: new 
Abstract: This paper presents fast solvers for linear systems arising from the discretization of fractional nonlinear Schr\"odinger equations with Riesz derivatives and attractive nonlinearities. These systems are characterized by complex symmetry, indefiniteness, and a $d$-level Toeplitz-plus-diagonal structure. We propose a Toeplitz-based anti-symmetric and normal splitting iteration method for the equivalent real block linear systems, ensuring unconditional convergence. The derived optimal parameter is approximately equal to 1. By combining this iteration method with sine-transform-based preconditioning, we introduce a novel preconditioner that enhances the convergence rate of Krylov subspace methods. Both theoretical and numerical analyses demonstrate that the new preconditioner exhibits a parameter-free property (allowing the iteration parameter to be fixed at 1). The eigenvalues of the preconditioned system matrix are nearly clustered in a small neighborhood around 1, and the convergence rate of the corresponding preconditioned GMRES method is independent of the spatial mesh size and the fractional order of the Riesz derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03643v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Chen, Xi Yang, Fei-Yan Zhang</dc:creator>
    </item>
    <item>
      <title>A mathematical model for Nordic skiing</title>
      <link>https://arxiv.org/abs/2410.02767</link>
      <description>arXiv:2410.02767v1 Announce Type: cross 
Abstract: Nordic skiing provides fascinating opportunities for mathematical modelling studies that exploit methods and insights from physics, applied mathematics, data analysis, scientific computing and sports science. A typical ski course winds over varied terrain with frequent changes in elevation and direction, and so its geometry is naturally described by a three-dimensional space curve. The skier travels along a course under the influence of various forces, and their dynamics can be described using a nonlinear system of ordinary differential equations (ODEs) that are derived from Newton's laws of motion. We develop an algorithm for solving the governing equations that combines Hermite spline interpolation, numerical quadrature and a high-order ODE solver. Numerical simulations are compared with measurements of skiers on actual courses to demonstrate the effectiveness of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02767v1</guid>
      <category>physics.class-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jane Shaw MacDonald, Rafael Ordo\~nez Cardales, John M. Stockie</dc:creator>
    </item>
    <item>
      <title>Convergence Guarantees for Neural Network-Based Hamilton-Jacobi Reachability</title>
      <link>https://arxiv.org/abs/2410.02904</link>
      <description>arXiv:2410.02904v1 Announce Type: cross 
Abstract: We provide a novel uniform convergence guarantee for DeepReach, a deep learning-based method for solving Hamilton-Jacobi-Isaacs (HJI) equations associated with reachability analysis. Specifically, we show that the DeepReach algorithm, as introduced by Bansal et al. in their eponymous paper from 2020, is stable in the sense that if the loss functional for the algorithm converges to zero, then the resulting neural network approximation converges uniformly to the classical solution of the HJI equation, assuming that a classical solution exists. We also provide numerical tests of the algorithm, replicating the experiments provided in the original DeepReach paper and empirically examining the impact that training with a supremum norm loss metric has on approximation error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02904v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>William Hofgard</dc:creator>
    </item>
    <item>
      <title>Random vortex and expansion-rate model for Oberbeck-Boussinesq fluid flows</title>
      <link>https://arxiv.org/abs/2410.02923</link>
      <description>arXiv:2410.02923v1 Announce Type: cross 
Abstract: By using a formulation of a class of compressible viscous flows with a heat source via vorticity and expansion-rate, we study the Oberbeck-Boussinesq flows. To this end we establish a new integral representation for solutions of parabolic equations subject to certain boundary condition, which allows us to develop a random vortex method for certain compressible flows and to compute numerically solutions of their dynamical models. Numerical experiments are carried out, which not only capture detailed B\'enard convection but also are capable of providing additional information on the fluid density and the dynamics of expansion-rate of the flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02923v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zihao Guo, Zhongmin Qian, Zihao Shen</dc:creator>
    </item>
    <item>
      <title>Geometry is All You Need: A Unified Taxonomy of Matrix and Tensor Factorization for Compression of Generative Language Models</title>
      <link>https://arxiv.org/abs/2410.03040</link>
      <description>arXiv:2410.03040v1 Announce Type: cross 
Abstract: Matrix and tensor-guided parametrization for Natural Language Processing (NLP) models is fundamentally useful for the improvement of the model's systematic efficiency. However, the internal links between these two algebra structures and language model parametrization are poorly understood. Also, the existing matrix and tensor research is math-heavy and far away from machine learning (ML) and NLP research concepts. These two issues result in the recent progress on matrices and tensors for model parametrization being more like a loose collection of separate components from matrix/tensor and NLP studies, rather than a well-structured unified approach, further hindering algorithm design. To this end, we propose a unified taxonomy, which bridges the matrix/tensor compression approaches and model compression concepts in ML and NLP research. Namely, we adopt an elementary concept in linear algebra, that of a subspace, which is also the core concept in geometric algebra, to reformulate the matrix/tensor and ML/NLP concepts (e.g. attention mechanism) under one umbrella. In this way, based on our subspace formalization, typical matrix and tensor decomposition algorithms can be interpreted as geometric transformations. Finally, we revisit recent literature on matrix- or tensor-guided language model compression, rephrase and compare their core ideas, and then point out the current research gap and potential solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03040v1</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingxue Xu, Sadia Sharmin, Danilo P. Mandic</dc:creator>
    </item>
    <item>
      <title>Discretizing the Fokker-Planck equation with second-order accuracy: a dissipation driven approach</title>
      <link>https://arxiv.org/abs/2410.03367</link>
      <description>arXiv:2410.03367v1 Announce Type: cross 
Abstract: We propose a fully discrete finite volume scheme for the standard Fokker-Planck equation. The space discretization relies on the well-known square-root approximation, which falls into the framework of two-point flux approximations. Our time discretization is novel and relies on a tailored nonlinear mid-point rule, designed to accurately capture the dissipative structure of the model. We establish well-posedness for the scheme, positivity of the solutions, as well as a fully discrete energy-dissipation inequality mimicking the continuous one. We then prove the rigorous convergence of the scheme under mildly restrictive conditions on the unstructured grids, which can be easily satisfied in practice. Numerical simulations show that our scheme is second order accurate both in time and space, and that one can solve the discrete nonlinear systems arising at each time step using Newton's method with low computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03367v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Canc\`es (RAPSODI, LPP), L\'eonard Monsaingeon (IECL), Andrea Natale (RAPSODI, LPP)</dc:creator>
    </item>
    <item>
      <title>Compressing multivariate functions with tree tensor networks</title>
      <link>https://arxiv.org/abs/2410.03572</link>
      <description>arXiv:2410.03572v1 Announce Type: cross 
Abstract: Tensor networks are a compressed format for multi-dimensional data. One-dimensional tensor networks -- often referred to as tensor trains (TT) or matrix product states (MPS) -- are increasingly being used as a numerical ansatz for continuum functions by "quantizing" the inputs into discrete binary digits. Here we demonstrate the power of more general tree tensor networks for this purpose. We provide direct constructions of a number of elementary functions as generic tree tensor networks and interpolative constructions for more complicated functions via a generalization of the tensor cross interpolation algorithm. For a range of multi-dimensional functions we show how more structured tree tensor networks offer a significantly more efficient ansatz than the commonly used tensor train. We demonstrate an application of our methods to solving multi-dimensional, non-linear Fredholm equations, providing a rigorous bound on the rank of the solution which, in turn, guarantees exponentially scaling accuracy with the size of the tree tensor network for certain problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03572v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joseph Tindall, Miles Stoudenmire, Ryan Levy</dc:creator>
    </item>
    <item>
      <title>How Discrete and Continuous Diffusion Meet: Comprehensive Analysis of Discrete Diffusion Models via a Stochastic Integral Framework</title>
      <link>https://arxiv.org/abs/2410.03601</link>
      <description>arXiv:2410.03601v1 Announce Type: cross 
Abstract: Discrete diffusion models have gained increasing attention for their ability to model complex distributions with tractable sampling and inference. However, the error analysis for discrete diffusion models remains less well-understood. In this work, we propose a comprehensive framework for the error analysis of discrete diffusion models based on L\'evy-type stochastic integrals. By generalizing the Poisson random measure to that with a time-independent and state-dependent intensity, we rigorously establish a stochastic integral formulation of discrete diffusion models and provide the corresponding change of measure theorems that are intriguingly analogous to It\^o integrals and Girsanov's theorem for their continuous counterparts. Our framework unifies and strengthens the current theoretical results on discrete diffusion models and obtains the first error bound for the $\tau$-leaping scheme in KL divergence. With error sources clearly identified, our analysis gives new insight into the mathematical properties of discrete diffusion models and offers guidance for the design of efficient and accurate algorithms for real-world discrete diffusion model applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03601v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yinuo Ren, Haoxuan Chen, Grant M. Rotskoff, Lexing Ying</dc:creator>
    </item>
    <item>
      <title>The effect of linear dispersive errors on nonlinear timestepping accuracy in the f-plane rotating shallow water equations</title>
      <link>https://arxiv.org/abs/2305.06685</link>
      <description>arXiv:2305.06685v2 Announce Type: replace 
Abstract: For simulations of time evolution problems, such as weather and climate models, taking the largest stable timestep is advantageous for reducing wall-clock time. A drawback of doing so is the potential reduction in nonlinear accuracy of the numerical solution - we investigate this for the Rotating Shallow Water Equations (RSWEs) on an f-plane. First, we examine how linear dispersion errors can impact the nonlinear dynamics. By deriving an alternate time evolution equation for the RSWEs, the dynamics can be expressed through interactions of three linear waves in triads. Linear dispersion errors may appear in the numerical representation of the frequency of each triad, which will impact the timestepped nonlinear dynamics. A new triadic error quantifies this by composing three stability polynomials from the oscillatory Dahlquist test equation. Second, we design two new test cases to examine the effect of timestep size in a numerical model. These tests investigate how well a timestepper replicates slow nonlinear dynamics amidst fast linear oscillations. The first test case of a Gaussian height perturbation contains a nonlinear phase shift that can be missed with a large timestep. The second set of triadic test cases excite a few linear waves to instigate specific triadic interactions. Two triadic cases are examined: one with a dominant directly resonant triad and another with near-resonances that redistribute fast mode energy into rings in spectral space. Three numerical models, including LFRic from the Met Office, are examined in these test cases with different timesteppers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.06685v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy C. Andrews, Jemma Shipton, Beth A. Wingate</dc:creator>
    </item>
    <item>
      <title>A fast fractional block-centered finite difference method for two-sided space-fractional diffusion equations on general nonuniform grids</title>
      <link>https://arxiv.org/abs/2312.10577</link>
      <description>arXiv:2312.10577v2 Announce Type: replace 
Abstract: In this paper, a two-sided variable-coefficient space-fractional diffusion equation with fractional Neumann boundary condition is considered. To conquer the weak singularity caused by nonlocal space-fractional differential operators, a fractional block-centered finite difference (BCFD) method on general nonuniform grids is proposed. However, this discretization still results in an unstructured dense coefficient matrix with huge memory requirement and computational complexity. To address this issue, a fast version fractional BCFD algorithm by employing the well-known sum-of-exponentials (SOE) approximation technique is also proposed. Based upon the Krylov subspace iterative methods, fast matrix-vector multiplications of the resulting coefficient matrices with any vector are developed, in which they can be implemented in only $\mathcal{O}(MN_{exp})$ operations per iteration without losing any accuracy compared to the direct solvers, where $N_{exp}\ll M$ is the number of exponentials in the SOE approximation. Moreover, the coefficient matrices do not necessarily need to be generated explicitly, while they can be stored in $\mathcal{O}(MN_{exp})$ memory by only storing some coefficient vectors. Numerical experiments are provided to demonstrate the efficiency and accuracy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10577v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Meijie Kong, Hongfei Fu</dc:creator>
    </item>
    <item>
      <title>Symmetric, Optimization-based, Cross-element Compatible Nodal Distributions for High-order Finite Elements</title>
      <link>https://arxiv.org/abs/2401.13209</link>
      <description>arXiv:2401.13209v2 Announce Type: replace 
Abstract: We present a general framework to construct symmetric, well-conditioned, cross-element compatible nodal distributions that can be used for high-order and high-dimensional finite elements. Starting from the inherent symmetries of an element geometry, we construct node groups in a systematic and efficient manner utilizing the natural coordinates of each element, while ensuring nodes stay within the elements. Proper constraints on the symmetry group lead to nodal distributions that ensure cross-element compatibility (i.e., nodes of adjacent elements are co-located) on both homogeneous and mixed meshes. The final nodal distribution is defined as a minimizer of an optimization problem over symmetry group parameters with linear constraints that ensure nodes remain with an element and enforce other properties (e.g., cross-element compatibility). We demonstrate the merit of this framework by comparing the proposed optimization-based nodal distributions with other popular distributions available in the literature, and its robustness by generating optimized nodal distributions for otherwise difficult elements (such as simplex and pyramid elements).</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13209v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julian M. Kaufmann, Matthew J. Zahr</dc:creator>
    </item>
    <item>
      <title>SWIFT: A Monotonic, Flux-Form Semi-Lagrangian Tracer Transport Scheme for Flow with Large Courant Numbers</title>
      <link>https://arxiv.org/abs/2405.20006</link>
      <description>arXiv:2405.20006v2 Announce Type: replace 
Abstract: Local conservation of mass and entropy are becoming increasingly desirable properties for modern numerical weather and climate models. This work presents a Flux-Form Semi-Lagrangian (FFSL) transport scheme, called SWIFT, that facilitates this conservation for tracer variables, whilst maintaining other vital properties such as preservation of a constant, monotonicity and positivity. Importantly, these properties all hold for large Courant numbers and multi-dimensional flow, making the scheme appropriate for use within a dynamical core which takes large time steps.
  The SWIFT scheme presented here can be seen as an evolution of the FFSL methods of Leonard et al and Lin and Rood. Two-dimensional and three-dimensional schemes consist of a splitting into a sequence of one-dimensional calculations. The new SWIFT splitting presented here allows monotonic and positivity properties from the one-dimensional calculations to be inherited by the multi-dimensional scheme. These one-dimensional calculations involve separating the mass flux into terms that correspond to integer and fractional parts of the Courant number. Key to achieving conservation is coupling the transport of tracers to the transport of the fluid density, through re-use of the discrete mass flux that was calculated from the fluid density in the transport of the tracers. This work also describes how these properties can still be attained when the tracer is vertically-staggered from the density in a Charney-Phillips grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20006v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.ao-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas M. Bendall, James Kent</dc:creator>
    </item>
    <item>
      <title>Probabilistic Analysis of Least Squares, Orthogonal Projection, and QR Factorization Algorithms Subject to Gaussian Noise</title>
      <link>https://arxiv.org/abs/2409.18905</link>
      <description>arXiv:2409.18905v2 Announce Type: replace 
Abstract: In this paper, we extend the work of Liesen et al. (2002), which analyzes how the condition number of an orthonormal matrix Q changes when a column is added ([Q, c]), particularly focusing on the perpendicularity of c to the span of Q. Their result, presented in Theorem 2.3 of Liesen et al. (2002), assumes exact arithmetic and orthonormality of Q, which is a strong assumption when applying these results to numerical methods such as QR factorization algorithms. In our work, we address this gap by deriving bounds on the condition number increase for a matrix B without assuming perfect orthonormality, even when a column is not perfectly orthogonal to the span of B. This framework allows us to analyze QR factorization methods where orthogonalization is imperfect and subject to Gaussian noise. We also provide results on the performance of orthogonal projection and least squares under Gaussian noise, further supporting the development of this theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18905v2</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Lotfi, Julien Langou, Mohammad Meysami</dc:creator>
    </item>
    <item>
      <title>Semi-Supervised Manifold Learning with Complexity Decoupled Chart Autoencoders</title>
      <link>https://arxiv.org/abs/2208.10570</link>
      <description>arXiv:2208.10570v2 Announce Type: replace-cross 
Abstract: Autoencoding is a popular method in representation learning. Conventional autoencoders employ symmetric encoding-decoding procedures and a simple Euclidean latent space to detect hidden low-dimensional structures in an unsupervised way. Some modern approaches to novel data generation such as generative adversarial networks askew this symmetry, but still employ a pair of massive networks--one to generate the image and another to judge the images quality based on priors learned from a training set. This work introduces a chart autoencoder with an asymmetric encoding-decoding process that can incorporate additional semi-supervised information such as class labels. Besides enhancing the capability for handling data with complicated topological and geometric structures, the proposed model can successfully differentiate nearby but disjoint manifolds and intersecting manifolds with only a small amount of supervision. Moreover, this model only requires a low-complexity encoding operation, such as a locally defined linear projection. We discuss the approximation power of such networks and derive a bound that essentially depends on the intrinsic dimension of the data manifold rather than the dimension of ambient space. Next we incorporate bounds for the sampling rate of training data need to faithfully represent a given data manifold. We present numerical experiments that verify that the proposed model can effectively manage data with multi-class nearby but disjoint manifolds of different classes, overlapping manifolds, and manifolds with non-trivial topology. Finally, we conclude with some experiments on computer vision and molecular dynamics problems which showcase the efficacy of our methods on real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.10570v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan C. Schonsheck, Scott Mahan, Timo Klock, Alexander Cloninger, Rongjie Lai</dc:creator>
    </item>
    <item>
      <title>Unadjusted Hamiltonian MCMC with Stratified Monte Carlo Time Integration</title>
      <link>https://arxiv.org/abs/2211.11003</link>
      <description>arXiv:2211.11003v3 Announce Type: replace-cross 
Abstract: A randomized time integrator is suggested for unadjusted Hamiltonian Monte Carlo (uHMC) which involves a very minor modification to the usual Verlet time integrator, and hence, is easy to implement. For target distributions of the form $\mu(dx) \propto e^{-U(x)} dx$ where $U: \mathbb{R}^d \to \mathbb{R}_{\ge 0}$ is $K$-strongly convex but only $L$-gradient Lipschitz, and initial distributions $\nu$ with finite second moment, coupling proofs reveal that an $\varepsilon$-accurate approximation of the target distribution in $L^2$-Wasserstein distance $\boldsymbol{\mathcal{W}}^2$ can be achieved by the uHMC algorithm with randomized time integration using $O\left((d/K)^{1/3} (L/K)^{5/3} \varepsilon^{-2/3} \log( \boldsymbol{\mathcal{W}}^2(\mu, \nu) / \varepsilon)^+\right)$ gradient evaluations; whereas for such rough target densities the corresponding complexity of the uHMC algorithm with Verlet time integration is in general $O\left((d/K)^{1/2} (L/K)^2 \varepsilon^{-1} \log( \boldsymbol{\mathcal{W}}^2(\mu, \nu) / \varepsilon)^+ \right)$. Metropolis-adjustable randomized time integrators are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.11003v3</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nawaf Bou-Rabee, Milo Marsden</dc:creator>
    </item>
    <item>
      <title>TensorGPT: Efficient Compression of Large Language Models based on Tensor-Train Decomposition</title>
      <link>https://arxiv.org/abs/2307.00526</link>
      <description>arXiv:2307.00526v2 Announce Type: replace-cross 
Abstract: High-dimensional token embeddings underpin Large Language Models (LLMs), as they can capture subtle semantic information and significantly enhance the modelling of complex language patterns. However, this high dimensionality also introduces considerable model parameters and prohibitively high model storage and memory requirements, which is particularly unaffordable for low-end devices. Targeting no extra training data and insufficient computation cases, we propose a training-free model compression approach based on the Tensor-Train Decomposition (TTD), whereby each pre-trained token embedding is converted into a lower-dimensional Matrix Product State (MPS). We then comprehensively investigate the low-rank structures extracted by this approach, in terms of the compression ratio, the language task performance, and latency on a typical low-end device (i.e. Raspberry Pi). Taking GPT family models (i.e. GPT-2 and CerebrasGPT) as case studies, our approach theoretically results in $46.89\%$ fewer parameters of the entire model, with a compression ratio $39.38\times$ - $65.64\times$ for the embedding layers. With different hyperparameter choices, the model compressed with our approach can achieve a comparable language task performance to the original model with around $2.0\times$ embedding layer compression. This empirically proves the existence of low-rank structure in GPT family models, and demonstrates that about half of the parameters in the embedding layers are redundant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.00526v2</guid>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingxue Xu, Yao Lei Xu, Danilo P. Mandic</dc:creator>
    </item>
  </channel>
</rss>
