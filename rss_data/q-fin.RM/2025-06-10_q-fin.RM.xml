<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.RM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.RM</link>
    <description>q-fin.RM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.RM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 10 Jun 2025 04:00:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Subgame Perfect Nash Equilibria in Large Reinsurance Markets</title>
      <link>https://arxiv.org/abs/2506.07291</link>
      <description>arXiv:2506.07291v1 Announce Type: new 
Abstract: We consider a model of a reinsurance market consisting of multiple insurers on the demand side and multiple reinsurers on the supply side, thereby providing a unifying framework and extension of the recent literature on optimality and equilibria in reinsurance markets. Each insurer has preferences represented by a general Choquet risk measure and can purchase coverage from any or all reinsurers. Each reinsurer has preferences represented by a general Choquet risk measure and can provide coverage to any or all insurers. Pricing in this market is done via a nonlinear pricing rule given by a Choquet integral. We model the market as a sequential game in which the reinsurers have the first-move advantage. We characterize the Subgame Perfect Nash Equilibria in this market in some cases of interest, and we examine their Pareto efficiency. In addition, we consider two special cases of our model that correspond to existing models in the related literature, and we show how our findings extend these previous results. Finally, we illustrate our results in a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07291v1</guid>
      <category>q-fin.RM</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Andraos, Mario Ghossoub, Michael B. Zhu</dc:creator>
    </item>
    <item>
      <title>Partial comonotonicity and distortion riskmetrics</title>
      <link>https://arxiv.org/abs/2506.07472</link>
      <description>arXiv:2506.07472v1 Announce Type: new 
Abstract: We establish a connection between subclasses of distortion riskmetrics and dependence structures, ensuring their additivity. A new notion of positive dependence, called partial comonotonicity, is developed, which nests the existing concepts of comonotonicity and single-point concentration. For two random variables, being comonotonic with a third one does not imply that they are comonotonic; instead, this defines an instance of partial comonotonicity. Any specific instance of partial comonotonicity uniquely characterizes a class of distortion riskmetrics through additivity under this dependence structure. An implication of this result is the characterization of the Expected Shortfall using single-point concentration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07472v1</guid>
      <category>q-fin.RM</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muqiao Huang</dc:creator>
    </item>
    <item>
      <title>Uncertainty-Aware Strategies: A Model-Agnostic Framework for Robust Financial Optimization through Subsampling</title>
      <link>https://arxiv.org/abs/2506.07299</link>
      <description>arXiv:2506.07299v1 Announce Type: cross 
Abstract: This paper addresses the challenge of model uncertainty in quantitative finance, where decisions in portfolio allocation, derivative pricing, and risk management rely on estimating stochastic models from limited data. In practice, the unavailability of the true probability measure forces reliance on an empirical approximation, and even small misestimations can lead to significant deviations in decision quality. Building on the framework of Klibanoff et al. (2005), we enhance the conventional objective - whether this is expected utility in an investing context or a hedging metric - by superimposing an outer "uncertainty measure", motivated by traditional monetary risk measures, on the space of models. In scenarios where a natural model distribution is lacking or Bayesian methods are impractical, we propose an ad hoc subsampling strategy, analogous to bootstrapping in statistical finance and related to mini-batch sampling in deep learning, to approximate model uncertainty. To address the quadratic memory demands of naive implementations, we also present an adapted stochastic gradient descent algorithm that enables efficient parallelization. Through analytical, simulated, and empirical studies - including multi-period, real data and high-dimensional examples - we demonstrate that uncertainty measures outperform traditional mixture of measures strategies and our model-agnostic subsampling-based approach not only enhances robustness against model risk but also achieves performance comparable to more elaborate Bayesian methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.07299v1</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hans Buehler, Blanka Horvath, Yannick Limmer, Thorsten Schmidt</dc:creator>
    </item>
    <item>
      <title>Dynamic spillovers and investment strategies across artificial intelligence ETFs, artificial intelligence tokens, and green markets</title>
      <link>https://arxiv.org/abs/2503.01148</link>
      <description>arXiv:2503.01148v3 Announce Type: replace 
Abstract: This paper investigates the risk spillovers among AI ETFs, AI tokens, and green markets using the R2 decomposition method. We reveal several key insights. First, the overall transmission connectedness index (TCI) closely aligns with the contemporaneous TCI, while the lagged TCI is significantly lower. Second, AI ETFs and clean energy act as risk transmitters, whereas AI tokens and green bond function as risk receivers. Third, AI tokens are difficult to hedge and provide limited hedging ability compared to AI ETFs and green assets. However, multivariate portfolios effectively reduce AI tokens investment risk. Among them, the minimum correlation portfolio outperforms the minimum variance and minimum connectedness portfolios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01148v3</guid>
      <category>q-fin.RM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ying-Hui Shao, Yan-Hong Yang, Han-Xian Zhou, Wei-Xing Zhou</dc:creator>
    </item>
    <item>
      <title>Interpretable LLMs for Credit Risk: A Systematic Review and Taxonomy</title>
      <link>https://arxiv.org/abs/2506.04290</link>
      <description>arXiv:2506.04290v2 Announce Type: replace 
Abstract: Large Language Models (LLM), which have developed in recent years, enable credit risk assessment through the analysis of financial texts such as analyst reports and corporate disclosures. This paper presents the first systematic review and taxonomy focusing on LLMbased approaches in credit risk estimation. We determined the basic model architectures by selecting 60 relevant papers published between 2020-2025 with the PRISMA research strategy. And we examined the data used for scenarios such as credit default prediction and risk analysis. Since the main focus of the paper is interpretability, we classify concepts such as explainability mechanisms, chain of thought prompts and natural language justifications for LLM-based credit models. The taxonomy organizes the literature under four main headings: model architectures, data types, explainability mechanisms and application areas. Based on this analysis, we highlight the main future trends and research gaps for LLM-based credit scoring systems. This paper aims to be a reference paper for artificial intelligence and financial researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.04290v2</guid>
      <category>q-fin.RM</category>
      <category>cs.LG</category>
      <pubDate>Tue, 10 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammed Golec, Maha AlabdulJalil</dc:creator>
    </item>
  </channel>
</rss>
