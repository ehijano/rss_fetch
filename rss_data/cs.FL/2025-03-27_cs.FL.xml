<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.FL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.FL</link>
    <description>cs.FL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.FL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>When is a Bottom-Up Deterministic Tree Translation Top-Down Deterministic?</title>
      <link>https://arxiv.org/abs/2503.21329</link>
      <description>arXiv:2503.21329v1 Announce Type: new 
Abstract: We consider two natural subclasses of deterministic top-down tree-to-tree transducers, namely, linear and uniform-copying transducers. For both classes we show that it is decidable whether the translation of a transducer with look-ahead can be realized by a transducer from the same class without look-ahead. The transducers constructed in this way, may still make use of inspection, i.e., have an additional tree automaton restricting the domain. We provide a second procedure which decides whether inspection can be removed. The procedure relies on a precise abstract interpretation of inspection requirements and a dedicated earliest normal form for linear as well as uniform-copying transducers which can be constructed in polynomial time. As a consequence, equivalence of these transducers can be decided in polynomial time. Applying these results to deterministic bottom-up tree transducers, we obtain that it is decidable whether or not their translations can be realized by deterministic linear or uniform-copying top-down transducers without look-ahead (but with inspection) -- or without both look-ahead and inspection. Look-ahead removal has been known to be a notoriously difficult problem. To the best of our knowledge, this paper is the first to present look-ahead removal for natural and known subclasses of top-down tree transducers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21329v1</guid>
      <category>cs.FL</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Maneth, Helmut Seidl</dc:creator>
    </item>
    <item>
      <title>From conceptualization to operationalized meaning via ontological components</title>
      <link>https://arxiv.org/abs/2503.21661</link>
      <description>arXiv:2503.21661v1 Announce Type: new 
Abstract: Ontologies enable knowledge sharing and interdisciplinary collaboration by providing standardized, structured vocabularies for diverse communities. While logical axioms are a cornerstone of ontology design, natural language elements such as annotations are equally critical for conveying intended meaning and ensuring consistent term usage. This paper explores how meaning is represented in ontologies and how it can be effectively represented and communicated, addressing challenges such as indeterminacy of reference and meaning holism. To this end, it proposes an approach founded on the use of a new structure, named 'ontological component' and defined by: a term-centered design; enhanced characterization of both formal and natural language statements; an operationalizable definition of communicated meaning based on general assertions; and the integration of natural language elements into the logical theory. By formalizing the meaning of ontological components, this work seeks to enhance the semantic robustness of terms, improving their clarity and accessibility across domains. Furthermore, it aims to address practical challenges in applied ontologies, such as facilitating reuse and managing versioning, thereby strengthening their role in diverse applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21661v1</guid>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Fabry, Adrien Barton, Jean-Fran\c{c}ois \'Ethier</dc:creator>
    </item>
    <item>
      <title>The commutativity problem for effective varieties of formal series, and applications</title>
      <link>https://arxiv.org/abs/2503.21697</link>
      <description>arXiv:2503.21697v1 Announce Type: new 
Abstract: A formal series in noncommuting variables $\Sigma$ over the rationals is a mapping $\Sigma^* \to \mathbb Q$. We say that a series is commutative if the value in the output does not depend on the order of the symbols in the input. The commutativity problem for a class of series takes as input a (finite presentation of) a series from the class and amounts to establishing whether it is commutative. This is a very natural, albeit nontrivial problem, which has not been considered before from an algorithmic perspective.
  We show that commutativity is decidable for all classes of series that constitute a so-called effective prevariety, a notion generalising Reutenauer's varieties of formal series. For example, the class of rational series, introduced by Sch\"utzenberger in the 1960's, is well-known to be an effective (pre)variety, and thus commutativity is decidable for it.
  In order to showcase the applicability of our result, we consider classes of formal series generalising the rational ones. We consider polynomial automata, shuffle automata, and infiltration automata, and we show that each of these models recognises an effective prevariety of formal series. Consequently, their commutativity problem is decidable, which is a novel result. We find it remarkable that commutativity can be decided in a uniform way for such disparate computation models.
  Finally, we present applications of commutativity outside the theory of formal series. We show that we can decide solvability in sequences and in power series for restricted classes of algebraic difference and differential equations, for which such problems are undecidable in full generality. Thanks to this, we can prove that the syntaxes of multivariate polynomial recursive sequences and of constructible differentially algebraic power series are effective, which are new results which were left open in previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21697v1</guid>
      <category>cs.FL</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Clemente</dc:creator>
    </item>
    <item>
      <title>On the Computational Power of Particle Methods</title>
      <link>https://arxiv.org/abs/2304.10286</link>
      <description>arXiv:2304.10286v3 Announce Type: replace 
Abstract: We investigate the computational power of particle methods, a well-established class of algorithms with applications in scientific computing and computer simulation. The computational power of a compute model determines the class of problems it can solve. Automata theory allows describing the computational power of abstract machines (automata) and the problems they can solve. At the top of the Chomsky hierarchy of formal languages and grammars are Turing machines, which resemble the concept on which most modern computers are built. Although particle methods can be interpreted as automata based on their formal definition, their computational power has so far not been studied. We address this by analyzing Turing completeness of particle methods. In particular, we prove two sets of restrictions under which a particle method is still Turing powerful, and we show when it loses Turing powerfulness. This contributes to understanding the theoretical foundations of particle methods and provides insight into the powerfulness of computer simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.10286v3</guid>
      <category>cs.FL</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Johannes Pahlke, Ivo F. Sbalzarini</dc:creator>
    </item>
    <item>
      <title>Blow-up in Non-Deterministic Automata</title>
      <link>https://arxiv.org/abs/2407.09891</link>
      <description>arXiv:2407.09891v4 Announce Type: replace 
Abstract: In this paper we examine the difficulty of finding an equivalent deterministic automaton when confronted with a non-deterministic one. While for some automata the exponential blow-up in their number of states is unavoidable, we show that in general, any approximation of state complexity with polynomial precision remains PSPACE-hard. The same is true when using the subset construction to determinize the NFA, meaning that it is PSPACE-hard to predict whether subset construction will produce an exponential ''blow-up'' in the number of states or not. To give an explanation for its behaviour, we propose the notion of subset complexity, which serves as an upper bound on the size of subset construction. Due to it simple and intuitive nature it allows to identify large classes of automata which can have limited non-determinism and completely avoid the ''blow-up''. Subset complexity also remains invariant under NFA reversal and allows to predict how the introduction or removal of transitions from the NFA will affect its size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09891v4</guid>
      <category>cs.FL</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ivan Baburin, Ryan Cotterell</dc:creator>
    </item>
    <item>
      <title>An elementary proof of Bridy's theorem</title>
      <link>https://arxiv.org/abs/2308.10977</link>
      <description>arXiv:2308.10977v2 Announce Type: replace-cross 
Abstract: Christol's theorem states that a power series with coefficients in a finite field is algebraic if and only if its coefficient sequence is automatic. A natural question is how the size of a polynomial describing such a sequence relates to the size of an automaton describing the same sequence. Bridy used tools from algebraic geometry to bound the size of the minimal automaton for a sequence, given its minimal polynomial. We produce a new proof of Bridy's bound by embedding algebraic sequences as diagonals of rational functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10977v2</guid>
      <category>math.NT</category>
      <category>cs.FL</category>
      <category>cs.SC</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ffa.2025.102621</arxiv:DOI>
      <dc:creator>Eric Rowland, Manon Stipulanti, Reem Yassawi</dc:creator>
    </item>
  </channel>
</rss>
