<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Formalizing Representation Theorems for a Logical Framework with Rewriting</title>
      <link>https://arxiv.org/abs/2504.07537</link>
      <description>arXiv:2504.07537v1 Announce Type: new 
Abstract: Representation theorems for formal systems often take the form of an inductive translation that satisfies certain invariants, which are proved inductively. Theory morphisms and logical relations are common patterns of such inductive constructions. They allow representing the translation and the proofs of the invariants as a set of translation rules, corresponding to the cases of the inductions. Importantly, establishing the invariants is reduced to checking a finite set of, typically decidable, statements. Therefore, in a framework supporting theory morphisms and logical relations, translations that fit one of these patterns become much easier to formalize and to verify. The $\lambda\Pi$-calculus modulo rewriting is a logical framework designed for representing and translating between formal systems that has previously not systematically supported such patterns. In this paper, we extend it with theory morphisms and logical relations. We apply these to define and verify invariants for a number of translations between formal systems. In doing so, we identify some best practices that enable us to obtain elegant novel formalizations of some challenging translations, in particular type erasure translations from typed to untyped languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07537v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Traversi\'e (MICS, DEDUCTEAM), Florian Rabe (FAU)</dc:creator>
    </item>
    <item>
      <title>Towards a Computational Quantum Logic: An Overview of an Ongoing Research Program</title>
      <link>https://arxiv.org/abs/2504.07609</link>
      <description>arXiv:2504.07609v1 Announce Type: new 
Abstract: This invited paper presents an overview of an ongoing research program aimed at extending the Curry-Howard-Lambek correspondence to quantum computation. We explore two key frameworks that provide both logical and computational foundations for quantum programming languages. The first framework, the Lambda-$S$ calculus, extends the lambda calculus by incorporating quantum superposition, enforcing linearity, and ensuring unitarity, to model quantum control. Its categorical semantics establishes a structured connection between classical and quantum computation through an adjunction between Cartesian closed categiries and additive symmetric monoidal closed categories. The second framework, the $\mathcal L^{\mathbb C}$ calculus, introduces a proof language for intuitionistic linear logic augmented with sum and scalar operations. This enables the formal encoding of quantum superpositions and measurements, leading to a computational model grounded in categorical structures with biproducts. These approaches suggest a fundamental duality between quantum computation and linear logic, highlighting structural correspondences between logical proofs and quantum programs. We discuss ongoing developments, including extensions to polymorphism, categorical and realizability models, as well as the integration of the modality !, which further solidify the connection between logic and quantum programming languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07609v1</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro D\'iaz-Caro</dc:creator>
    </item>
    <item>
      <title>Totality for Mixed Inductive and Coinductive Types</title>
      <link>https://arxiv.org/abs/1901.07820</link>
      <description>arXiv:1901.07820v5 Announce Type: replace 
Abstract: This paper introduces an ML / Haskell like programming language with nested inductive and coinductive algebraic datatypes called \chariot. Functions are defined by arbitrary recursive definitions and can thus lead to non-termination and other ``bad'' behavior. \chariot comes with a totality checker that tags possibly ill-behaved definitions. Such a totality checker is mandatory in the context of proof assistants based on type theory like Agda. Proving correctness of this checker is far from trivial and relies on - an interpretation of types as parity games, - an interpretation of correct values as winning strategies for those games, - the Lee, Jones and Ben Amram's size-change principle, used to check that the strategies induced by recursive definitions are winning. This paper develops the first two points, the last step being the subject of an upcoming paper. A prototype has been implemented and can be used to experiment with the resulting totality checker, giving a practical argument in favor of this principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:1901.07820v5</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Hyvernat (LAMA)</dc:creator>
    </item>
    <item>
      <title>A Simple Formal Language for Probabilistic Decision Problems</title>
      <link>https://arxiv.org/abs/2410.10643</link>
      <description>arXiv:2410.10643v2 Announce Type: replace 
Abstract: Probabilistic puzzles can be confusing, partly because they are formulated in natural languages - full of unclarities and ambiguities - and partly because there is no widely accepted and intuitive formal language to express them. We propose a simple formal language with arrow notation ($\gets$) for sampling from a distribution and with observe statements for conditioning (updating, belief revision). We demonstrate the usefulness of this simple language by solving several famous puzzles from probabilistic decision theory. The operational semantics of our language is expressed via the (finite, discrete) subdistribution monad. Our broader message is that proper formalisation dispels confusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10643v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Di Lavore, Bart Jacobs, Mario Rom\'an</dc:creator>
    </item>
    <item>
      <title>A framework for computing upper bounds in passive learning settings</title>
      <link>https://arxiv.org/abs/2504.03517</link>
      <description>arXiv:2504.03517v2 Announce Type: replace 
Abstract: The task of inferring logical formulas from examples has garnered significant attention as a means to assist engineers in creating formal specifications used in the design, synthesis, and verification of computing systems. Among various approaches, enumeration algorithms have emerged as some of the most effective techniques for this task. These algorithms employ advanced strategies to systematically enumerate candidate formulas while minimizing redundancies by avoiding the generation of syntactically different but semantically equivalent formulas. However, a notable drawback is that these algorithms typically do not provide guarantees of termination, which poses challenges for their use in real-world applications.
  This paper develops an abstract framework to bound the size of possible solutions for a logic inference task, thereby providing a termination guarantee for enumeration algorithms through the introduction of a sufficient stopping criterion. The proposed framework is designed with flexibility in mind and is applicable to a broad spectrum of practically relevant logical formalisms, including Modal Logic, Linear Temporal Logic, Computation Tree Logic, Alternating-time Temporal Logic, and even selected inference task for finite automata. In addition, our approach enabled us to develop a new class of algorithms that enumerate over the semantics of formulas rather than their syntactic representations, offering new possibilities for reducing redundancy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03517v2</guid>
      <category>cs.LO</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Bordais, Daniel Neider</dc:creator>
    </item>
    <item>
      <title>A Uniform Framework for Handling Position Constraints in String Solving (Technical Report)</title>
      <link>https://arxiv.org/abs/2504.07033</link>
      <description>arXiv:2504.07033v2 Announce Type: replace 
Abstract: We introduce a novel decision procedure for solving the class of position string constraints, which includes string disequalities, not-prefixof, not-suffixof, str$.$at, and not-str$.$at. These constraints are generated frequently in almost any application of string constraint solving. Our procedure avoids expensive encoding of the constraints to word equations and, instead, reduces the problem to checking conflicts on positions satisfying an integer constraint obtained from the Parikh image of a polynomial-sized finite automaton with a special structure. By the reduction to counting, solving position constraints becomes NP-complete and for some cases even falls into PTime. This is much cheaper than the previously used techniques, which either used reductions generating word equations and length constraints (for which modern string solvers use exponential-space algorithms) or incomplete techniques. Our method is relevant especially for automata-based string solvers, which have recently achieved the best results in terms of practical efficiency, generality, and completeness guarantees. This work allows them to excel also on position constraints, which used to be their weakness. Besides the efficiency gains, we show that our framework may be extended to solve a large fragment of not-contains (in NExpTime), for which decidability has been long open, and gives a hope to solve the general problem. Our implementation of the technique within the Z3-Noodler solver significantly improves its performance on position constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.07033v2</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yu-Fang Chen, Vojt\v{e}ch Havlena, Michal He\v{c}ko, Luk\'a\v{s} Hol\'ik, Ond\v{r}ej Leng\'al</dc:creator>
    </item>
    <item>
      <title>On the Nature of Fractal Numbers and the Classical Continuum Hypothesis (CH)</title>
      <link>https://arxiv.org/abs/2504.04637</link>
      <description>arXiv:2504.04637v4 Announce Type: replace-cross 
Abstract: We propose a reinterpretation of the continuum grounded in the stratified structure of definability rather than classical cardinality. In this framework, a real number is not an abstract point on the number line, but an object expressible at some level Fn of a formal hierarchy. We introduce the notion of "fractal numbers" -- entities defined not within a fixed set-theoretic universe, but through layered expressibility across constructive systems. This reconceptualizes irrationality as a relative property, depending on definability depth, and replaces the binary dichotomy between countable and uncountable sets with a gradated spectrum of definability classes. We show that the classical Continuum Hypothesis loses its force in this context: between aleph_0 and c lies not a single cardinal jump, but a stratified sequence of definitional stages, each forming a countable yet irreducible approximation to the continuum. We argue that the real line should not be seen as a completed totality but as an evolving architecture of formal expressibility. We conclude with a discussion of rational invariants, the relativity of irrationality, and the emergence of a fractal metric for definitional density.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04637v4</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Fri, 11 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stanislav Semenov</dc:creator>
    </item>
  </channel>
</rss>
