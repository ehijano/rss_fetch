<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.CB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.CB</link>
    <description>q-bio.CB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.CB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Mar 2025 02:16:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Physical Principles of Quantum Biology</title>
      <link>https://arxiv.org/abs/2503.11747</link>
      <description>arXiv:2503.11747v1 Announce Type: cross 
Abstract: This technical monograph provides a comprehensive overview of the field of quantum biology. It approaches quantum biology from a physical perspective with core quantum mechanical concepts presented foremost to provide a theoretical foundation for the field. An extensive body of research is covered to clarify the significance of quantum biology as a scientific field, outlining the field's long-standing importance in the historical development of quantum theory. This lays the essential groundwork to enable further advances in nanomedicine and biotechnology. Written for academics, biological science researchers, physicists, biochemists, medical technologists, and students of quantum mechanics, this text brings clarity to fundamental advances being made in the emerging science of quantum biology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11747v1</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.BM</category>
      <category>q-bio.CB</category>
      <category>q-bio.SC</category>
      <category>q-bio.TO</category>
      <category>quant-ph</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan S. Babcock, Brandy N. Babcock</dc:creator>
    </item>
    <item>
      <title>MicroVQA: A Multimodal Reasoning Benchmark for Microscopy-Based Scientific Research</title>
      <link>https://arxiv.org/abs/2503.13399</link>
      <description>arXiv:2503.13399v1 Announce Type: cross 
Abstract: Scientific research demands sophisticated reasoning over multimodal data, a challenge especially prevalent in biology. Despite recent advances in multimodal large language models (MLLMs) for AI-assisted research, existing multimodal reasoning benchmarks only target up to college-level difficulty, while research-level benchmarks emphasize lower-level perception, falling short of the complex multimodal reasoning needed for scientific discovery. To bridge this gap, we introduce MicroVQA, a visual-question answering (VQA) benchmark designed to assess three reasoning capabilities vital in research workflows: expert image understanding, hypothesis generation, and experiment proposal. MicroVQA consists of 1,042 multiple-choice questions (MCQs) curated by biology experts across diverse microscopy modalities, ensuring VQA samples represent real scientific practice. In constructing the benchmark, we find that standard MCQ generation methods induce language shortcuts, motivating a new two-stage pipeline: an optimized LLM prompt structures question-answer pairs into MCQs; then, an agent-based `RefineBot' updates them to remove shortcuts. Benchmarking on state-of-the-art MLLMs reveal a peak performance of 53\%; models with smaller LLMs only slightly underperform top models, suggesting that language-based reasoning is less challenging than multimodal reasoning; and tuning with scientific articles enhances performance. Expert analysis of chain-of-thought responses shows that perception errors are the most frequent, followed by knowledge errors and then overgeneralization errors. These insights highlight the challenges in multimodal scientific reasoning, showing MicroVQA is a valuable resource advancing AI-driven biomedical research. MicroVQA is available at https://huggingface.co/datasets/jmhb/microvqa, and project page at https://jmhb0.github.io/microvqa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13399v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>q-bio.CB</category>
      <pubDate>Tue, 18 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Burgess, Jeffrey J Nirschl, Laura Bravo-S\'anchez, Alejandro Lozano, Sanket Rajan Gupte, Jesus G. Galaz-Montoya, Yuhui Zhang, Yuchang Su, Disha Bhowmik, Zachary Coman, Sarina M. Hasan, Alexandra Johannesson, William D. Leineweber, Malvika G Nair, Ridhi Yarlagadda, Connor Zuraski, Wah Chiu, Sarah Cohen, Jan N. Hansen, Manuel D Leonetti, Chad Liu, Emma Lundberg, Serena Yeung-Levy</dc:creator>
    </item>
  </channel>
</rss>
