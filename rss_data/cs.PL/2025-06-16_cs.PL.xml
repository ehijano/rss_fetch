<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Jun 2025 02:28:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Performance Model for Warp Specialization Kernels</title>
      <link>https://arxiv.org/abs/2506.11209</link>
      <description>arXiv:2506.11209v1 Announce Type: new 
Abstract: This paper presents a performance model tailored for warp specialization kernels, focusing on factors such as warp size, tilling size, input matrix size, memory bandwidth, and thread divergence. Our model offers accurate predictions of execution time by leveraging differential equations validated through simulations and experiments. The insights gained from this model not only enhance our understanding of warp specialization techniques but also have practical implications for optimizing GPU-accelerated applications through compiler optimizations, kernel parameter tuning, and algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11209v1</guid>
      <category>cs.PL</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengyang Liu, Vinod Grover</dc:creator>
    </item>
    <item>
      <title>PermRust: A Token-based Permission System for Rust</title>
      <link>https://arxiv.org/abs/2506.11701</link>
      <description>arXiv:2506.11701v1 Announce Type: new 
Abstract: Permission systems which restrict access to system resources are a well-established technology in operating systems, especially for smartphones. However, as such systems are implemented in the operating system they can at most manage access on the process-level. Since moderns software often (re)uses code from third-parties libraries, a permission system for libraries can be desirable to enhance security. In this short-paper, we adapt concepts from capability systems building a novel theoretical foundation for permission system at the level of the programming language. This leads to PermRust, a token-based permission system for the Rust programming language as a zero cost abstraction on top of its type-system. With it access to system resources can be managed per library.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11701v1</guid>
      <category>cs.PL</category>
      <category>cs.CR</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lukas Gehring, Sebastian Rehms, Florian Tschorsch</dc:creator>
    </item>
    <item>
      <title>ALEA IACTA EST: A Declarative Domain-Specific Language for Manually Performable Random Experiments</title>
      <link>https://arxiv.org/abs/2506.11794</link>
      <description>arXiv:2506.11794v1 Announce Type: new 
Abstract: Random experiments that are simple and clear enough to be performed by human agents feature prominently in the teaching of elementary stochastics as well as in games. We present Alea, a domain-specific language for the specification of random experiments. Alea code can either be analyzed statically to obtain and inspect probability distributions of outcomes, or be executed with a source pseudo-randomness for simulation or as a game assistant. The language is intended for ease of use by non-expert programmers, in particular students of elementary stochastics, and players and designers of games of chance, by focusing on concepts common to functional programming and basic mathematics. Both the design of the language and the implementation of runtime environments are work in progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11794v1</guid>
      <category>cs.PL</category>
      <category>math.PR</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Baltasar Tranc\'on y Widemann, Markus Lepper</dc:creator>
    </item>
    <item>
      <title>From Reasoning to Code: GRPO Optimization for Underrepresented Languages</title>
      <link>https://arxiv.org/abs/2506.11027</link>
      <description>arXiv:2506.11027v2 Announce Type: cross 
Abstract: Generating accurate and executable code using large language models (LLMs) is challenging for languages with limited public training data compared to popular languages such as Python. This paper introduces a generalizable approach that uses small-scale code versions of the Qwen 2.5 model combined with Group Relative Policy Optimization (GRPO) to enable effective code generation through explicit reasoning steps, which is particularly beneficial for languages with smaller source code databases. Using Prolog as a representative use case -- given its limited online presence -- the initial model faced challenges in generating executable code. After some training steps, the model successfully produces logically consistent and syntactically accurate code by directly integrating reasoning-driven feedback into the reinforcement learning loop. Experimental evaluations using mathematical logic problem benchmarks illustrate significant improvements in reasoning quality, code accuracy, and logical correctness, underscoring the potential of this approach to benefit a wide range of programming languages lacking extensive training resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11027v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Pennino, Bianca Raimondi, Massimo Rondelli, Andrea Gurioli, Maurizio Gabbrielli</dc:creator>
    </item>
    <item>
      <title>QPanda3: A High-Performance Software-Hardware Collaborative Framework for Large-Scale Quantum-Classical Computing Integration</title>
      <link>https://arxiv.org/abs/2504.02455</link>
      <description>arXiv:2504.02455v2 Announce Type: replace 
Abstract: In emerging quantum-classical integration applications, the classical time cost-especially from compilation and protocol-level communication often exceeds the execution time of quantum circuits themselves, posing a severe bottleneck to practical deployment. To overcome these limitations, QPanda3 has been extensively optimized as a high-performance quantum programming framework tailored for the demands of the NISQ era and quantum-classical hybrid workflows. It features optimized circuit compilation, a custom binary instruction stream (OriginBIS), and hardware-aware execution strategies to significantly reduce latency and communication overhead. OriginBIS achieves up to 86.9$\times$ faster encoding and 35.6$\times$ faster decoding than OpenQASM 2.0, addressing critical bottlenecks in hybrid quantum systems. Benchmarks show 10.7$\times$ compilation speedup and up to 597$\times$ acceleration in compiling large-scale circuits (e.g., a 118-qubit W-state) compared to Qiskit. n high-performance simulation, QPanda3 excels in variational quantum algorithms, achieving up to 26$\times$ faster gradient computation than Qiskit, with minimal time-complexity growth across circuit depths. These capabilities make QPanda3 well-suited for scalable quantum algorithm development in finance, materials science, and combinatorial optimization, while supporting industrial deployment and cloud-based execution in quantum-classical hybrid computing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02455v2</guid>
      <category>cs.PL</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianrui Zou, Yuan Fang, Jing Wang, Menghan Dou, Jun Fu, ZiQiang Zhao, ShuBin Zhao, Lei Yu, Dongyi Zhao, Zhaoyun Chen, Guoping Guo</dc:creator>
    </item>
    <item>
      <title>CompilerGPT: Leveraging Large Language Models for Analyzing and Acting on Compiler Optimization Reports</title>
      <link>https://arxiv.org/abs/2506.06227</link>
      <description>arXiv:2506.06227v2 Announce Type: replace 
Abstract: Current compiler optimization reports often present complex, technical information that is difficult for programmers to interpret and act upon effectively. This paper assesses the capability of large language models (LLM) to understand compiler optimization reports and automatically rewrite the code accordingly.
  To this end, the paper introduces CompilerGPT, a novel framework that automates the interaction between compilers, LLMs, and user defined test and evaluation harness. CompilerGPT's workflow runs several iterations and reports on the obtained results.
  Experiments with two leading LLM models (GPT-4o and Claude Sonnet), optimization reports from two compilers (Clang and GCC), and five benchmark codes demonstrate the potential of this approach. Speedups of up to 6.5x were obtained, though not consistently in every test. This method holds promise for improving compiler usability and streamlining the software optimization process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06227v2</guid>
      <category>cs.PL</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Pirkelbauer, Chunhua Liao</dc:creator>
    </item>
    <item>
      <title>A bargain for mergesorts -- How to prove your mergesort correct and stable, almost for free</title>
      <link>https://arxiv.org/abs/2403.08173</link>
      <description>arXiv:2403.08173v2 Announce Type: replace-cross 
Abstract: We present a novel characterization of stable mergesort functions using relational parametricity, and show that it implies the functional correctness of mergesort. As a result, one can prove the correctness of several variations of mergesort (e.g., top-down, bottom-up, tail-recursive, non-tail-recursive, smooth, and non-smooth mergesorts) by proving the characteristic property for each variation. Thanks to our characterization and the parametricity translation, we deduced the correctness results, including stability, of various implementations of mergesort for lists, including highly optimized ones, in the Rocq Prover (formerly the Coq Proof Assistant).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08173v2</guid>
      <category>cs.LO</category>
      <category>cs.DS</category>
      <category>cs.PL</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyril Cohen, Kazuhiko Sakaguchi</dc:creator>
    </item>
    <item>
      <title>Black-Box Adversarial Attacks on LLM-Based Code Completion</title>
      <link>https://arxiv.org/abs/2408.02509</link>
      <description>arXiv:2408.02509v2 Announce Type: replace-cross 
Abstract: Modern code completion engines, powered by large language models (LLMs), assist millions of developers with their strong capabilities to generate functionally correct code. Due to this popularity, it is crucial to investigate the security implications of relying on LLM-based code completion. In this work, we demonstrate that state-of-the-art black-box LLM-based code completion engines can be stealthily biased by adversaries to significantly increase their rate of insecure code generation. We present the first attack, named INSEC, that achieves this goal. INSEC works by injecting an attack string as a short comment in the completion input. The attack string is crafted through a query-based optimization procedure starting from a set of carefully designed initialization schemes. We demonstrate INSEC's broad applicability and effectiveness by evaluating it on various state-of-the-art open-source models and black-box commercial services (e.g., OpenAI API and GitHub Copilot). On a diverse set of security-critical test cases, covering 16 CWEs across 5 programming languages, INSEC increases the rate of generated insecure code by more than 50%, while maintaining the functional correctness of generated code. We consider INSEC practical -- it requires low resources and costs less than 10 US dollars to develop on commodity hardware. Moreover, we showcase the attack's real-world deployability, by developing an IDE plug-in that stealthily injects INSEC into the GitHub Copilot extension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02509v2</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Mon, 16 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Slobodan Jenko, Niels M\"undler, Jingxuan He, Mark Vero, Martin Vechev</dc:creator>
    </item>
  </channel>
</rss>
