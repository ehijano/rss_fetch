<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SY</link>
    <description>eess.SY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 30 Jan 2026 05:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Mean-Field Learning for Storage Aggregation</title>
      <link>https://arxiv.org/abs/2601.21039</link>
      <description>arXiv:2601.21039v1 Announce Type: new 
Abstract: Distributed energy storage devices can be pooled and coordinated by aggregators to participate in power system operations and market clearings. This requires representing a massive device population as a single, tractable surrogate that is computationally efficient, accurate, and compatible with market participation requirements. However, surrogate identification is challenging due to heterogeneity, nonconvexity, and high dimensionality of storage devices. To address these challenges, this paper develops a mean-field learning framework for storage aggregation. We interpret aggregation as the average behavior of a large storage population and show that, as the population grows, aggregate performance converges to a unique, convex mean-field limit, enabling tractable population-level modeling. This convexity further yields a price-responsive characterization of aggregate storage behavior and allows us to bound the mean-field approximation error. Leveraging these results, we construct a convex surrogate model that approximates the aggregate behavior of large storage populations and can be embedded directly into power system operations and market clearing. Surrogate parameter identification is formulated as an optimization problem using historical market price-response data, and we adopt a gradient-based algorithm for efficient learning procedure. Case studies validate the theoretical findings and demonstrate the effectiveness of the proposed framework in approximation accuracy, data efficiency, and profit outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21039v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingguan Liu, Cong Chen, Xiaomeng Ai, Jiakun Fang, Jinsong Wang, Jinyu Wen</dc:creator>
    </item>
    <item>
      <title>The Impact of Shared Autonomous Vehicles in Microtransit Systems: A Case Study in Atlanta</title>
      <link>https://arxiv.org/abs/2601.21046</link>
      <description>arXiv:2601.21046v1 Announce Type: new 
Abstract: Microtransit systems represent an enhancement to solve the first- and last-mile problem, integrating traditional rail and bus networks with on-demand shuttles into a flexible, integrated system. This type of demand responsive transport provides greater accessibility and higher quality levels of service compared to conventional fixed-route transit services. Advances in technology offer further opportunities to enhance microtransit performance. In particular, shared autonomous vehicles (SAVs) have the potential to transform the mobility landscape by enabling more sustainable operations, enhanced user convenience, and greater system reliability. This paper investigates the integration of SAVs in microtransit systems, advancing the technological capabilities of on-demand shuttles. A shuttle dispatching optimization model is enhanced to accommodate for driver behavior and SAV functionalities. A model predictive control approach is proposed that dynamically rebalances on-demand shuttles towards areas of higher demand without relying on vast historical data. Scenario-driven experiments are conducted using data from the MARTA Reach microtransit pilot. The results demonstrate that SAVs can elevate both service quality and user experience compared to traditional on-demand shuttles in microtransit systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21046v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jason Lu, Tejas Santanam, Hongzhao Guan, Connor Riley, Meen-Sung Kim, Anthony Trasatti, Neda Masoud, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Towards Governance of Localized VANET: An Adjustable Degree Distribution Model</title>
      <link>https://arxiv.org/abs/2601.21176</link>
      <description>arXiv:2601.21176v1 Announce Type: new 
Abstract: Vehicular Ad-hoc Networks (VANETs) serve as a critical enabler for intelligent transportation systems. However, their practical deployment faces a core governance dilemma: the network topology requires a dynamic trade-off between robustness against targeted attacks and ensuring low-latency information transmission. Most existing models generate fixed degree distributions, lacking the ability to adapt autonomously to the demands of diverse traffic scenarios. To address this challenge, this paper innovatively proposes a schedulable degree distribution model for localized VANETs. The core of this model lies in introducing a hybrid connection mechanism. When establishing connections, newly joining nodes do not follow a single rule but instead collaboratively perform random attachment and preferential attachment. Through theoretical derivation and simulation validation, this study demonstrates that by adjusting the cooperative weighting between these two mechanisms, the overall network degree distribution can achieve a continuous and controllable transition between a uniform distribution and a power-law distribution. The former effectively disperses attack risks and enhances robustness, while the latter facilitates the formation of hub nodes, shortening transmission paths to reduce latency. Experimental results based on the real-world road network of Beijing indicate that this model can precisely regulate node connection heterogeneity, attack resistance, and average transmission path length through the reshaping of the underlying topology. This provides a forward-looking and practical governance paradigm for constructing next-generation VANETs capable of dynamically adapting to complex environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21176v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruixing Ren, Junhui Zhao, Xiaoke Sun, Shanjin Ni</dc:creator>
    </item>
    <item>
      <title>Deep Koopman Iterative Learning and Stability-Guaranteed Control for Unknown Nonlinear Time-Varying Systems</title>
      <link>https://arxiv.org/abs/2601.21230</link>
      <description>arXiv:2601.21230v1 Announce Type: new 
Abstract: This paper proposes a Koopman-based framework for modeling, prediction, and control of unknown nonlinear time-varying systems. We present a novel Koopman-based learning method for predicting the state of unknown nonlinear time-varying systems, upon which a robust controller is designed to ensure that the resulting closed-loop system is input-to-state stable with respect to the Koopman approximation error. The error of the lifted system model learned through the Koopman-based method increases over time due to the time-varying nature of the nonlinear time-varying system. To address this issue, an online iterative update scheme is incorporated into the learning process to update the lifted system model, aligning it more precisely with the time-varying nonlinear system by integrating the updated data and discarding the outdated data. A necessary condition for the feasibility of the proposed iterative learning method is derived. In order to reduce unnecessary system updates while ensuring the prediction accuracy of the lifted system, the update mechanism is enhanced to determine whether to update the lifted system and meanwhile to reduce updates that deteriorate the fitting performance. Furthermore, based on the online-updated lifted system, a controller is designed to ensure the closed-loop controlled system be input-to-state stable with respect to the Koopman approximation error. Numerical simulations on the Duffing oscillator, the serial manipulator, and the synthetic biological network system are presented to demonstrate the effectiveness of the proposed method for the approximation and control of unknown nonlinear time-varying systems. The results show that the proposed approach outperforms existing methods in terms of approximation accuracy and computational efficiency, even under significant system variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21230v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hengde Zhang, Yunxiao Ren, Zhisheng Duan, Zhiyong Sun, Guanrong Chen</dc:creator>
    </item>
    <item>
      <title>Distributed Circumnavigation Using Bearing Based Control with Limited Target Information</title>
      <link>https://arxiv.org/abs/2601.21300</link>
      <description>arXiv:2601.21300v1 Announce Type: new 
Abstract: In this paper, we address the problem of circumnavigation of a stationary target by a heterogeneous group comprising of $\textbf{n}$ autonomous agents, having unicycle kinematics. The agents are assumed to have constant linear speeds, we control only the angular speeds. Assuming limited sensing capabilities of the agents, in the proposed framework, only a subset of agents, termed as \textit{leaders}, know the target location. The rest, termed as \textit{followers}, do not. We propose a distributed guidance law which drives all the agents towards the desired objective; global asymptotic stability (GAS) is ensured by using Zubov's theorem. The efficacy of the approach is demonstrated through both numerical simulations and hardware experiments on the TurtleBots utilising OptiTrack motion capture system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21300v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kushal Pratap Singh, Manvi Bengani, Darshit Mittal, Twinkle Tripathy</dc:creator>
    </item>
    <item>
      <title>Resilient Grid Hardening against Multiple Hazards: An Adaptive Two-Stage Stochastic Optimization Approach</title>
      <link>https://arxiv.org/abs/2601.21371</link>
      <description>arXiv:2601.21371v1 Announce Type: new 
Abstract: The growing prevalence of extreme weather events driven by climate change poses significant challenges to power system resilience. Infrastructure damage and prolonged power outages highlight the urgent need for effective grid-hardening strategies. While some measures provide long-term protection against specific hazards, they can become counterproductive under conflicting threats. In this work, we develop an adaptive two-stage stochastic optimization framework to support dynamic decision-making for hardening critical grid components under multiple hazard exposures. Unlike traditional approaches, our model adapts to evolving climate conditions, enabling more resilient investment strategies. Furthermore, we integrate long-term (undergrounding) and short-term (vegetation management) hardening actions to jointly minimize total system costs. Extensive simulation results validate the effectiveness of the proposed framework in reducing outage and repair costs while enhancing the adaptability and robustness of grid infrastructure planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21371v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.epsr.2025.112345</arxiv:DOI>
      <arxiv:journal_reference>Electric Power Systems Research, 253 (2026) 112345</arxiv:journal_reference>
      <dc:creator>Sifat Chowdhury, Yihsu Chen, Yu Zhang</dc:creator>
    </item>
    <item>
      <title>Surrogate model of a HVAC system for PV self-consumption maximisation</title>
      <link>https://arxiv.org/abs/2601.21390</link>
      <description>arXiv:2601.21390v1 Announce Type: new 
Abstract: In the last few years, energy efficiency has become a challenge. Not only mitigating environmental impact but reducing energy waste can lead to financial advantages. Buildings play an important role in this: they are among the biggest consumers. So, finding manners to reduce energy consumption is a way to minimise energy waste, and a technique for that is creating Demand Response (DR) strategies. This paper proposes a novel way to decrease computational effort of simulating the behaviour of a building using surrogate models based on active learning. Before going straight to the problem of a building, which is complex and computationally costly, the paper proposes the approach of active learning to a smaller problem: with reduced simulations, regress the curve of voltage versus current of a thermo-resistor. Then, the paper implements a surrogate model of energy consumption of a building. The goal is to be able to learn the consumption pattern based on a limited number of simulations. The result given by the surrogate can be used to set the reference temperature, maximising the PV self-consumption, and reducing energy usage from the grid. Thanks to the surrogate, the total time spent to map all possible consumption scenarios is reduced around 7 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21390v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ecmx.2023.100396</arxiv:DOI>
      <arxiv:journal_reference>Energy Conversion and Management X (ISSN: 2590-1745), Vol. 19, 2023, pp 1-14</arxiv:journal_reference>
      <dc:creator>B. da Costa Paulo, N. Aginako, J. Ugartemendia, I. Landa del Barrio, M. Quartulli, H. Camblong</dc:creator>
    </item>
    <item>
      <title>Decentralized Analysis Approach for Oscillation Damping in Grid-Forming and Grid-Following Heterogeneous Power Systems</title>
      <link>https://arxiv.org/abs/2601.21562</link>
      <description>arXiv:2601.21562v1 Announce Type: new 
Abstract: This letter proposes a decentralized local gain condition (LGC) to guarantee oscillation damping in inverter-based resource (IBR)-dominated power systems. The LGC constrains the dynamic gain between each IBR and the network at its point of connection. By satisfying the LGC locally, the closed-loop poles are confined to a desired region, thereby yielding system-wide oscillation damping without requiring global information. Notably, the LGC is agnostic to different IBR dynamics, well-suited for systems with heterogeneous IBRs, and flexible to various damping requirements. Moreover, a low-complexity algorithm is proposed to parameterize LGC, providing scalable and damping-constrained parameter tuning guidance for IBRs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21562v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Zhu, Xiuqiang He, Hongyang Qing, Hua Geng</dc:creator>
    </item>
    <item>
      <title>StarSD: One-for-Many Speculative Decoding</title>
      <link>https://arxiv.org/abs/2601.21622</link>
      <description>arXiv:2601.21622v1 Announce Type: new 
Abstract: Speculative decoding accelerates autoregressive generation by separating token proposal from verification, but most existing approaches are designed for single-node execution and do not scale well to multi-accelerator clusters used for serving modern Large Language Models (LLMs). We present StarSD, a one-for-many speculative decoding framework that uses a single draft model to serve multiple target models across distributed nodes via a star topology. StarSD decouples drafting and verification, enabling effective sharing of draft computation, and preventing distributed accelerators from remaining idle under bursty workloads. We provide a system-level analysis that characterizes when and why a single draft model can remain fully utilized by multiple verifiers, yielding predictable latency and utilization gains. Extensive experiments in real-world distributed inference settings demonstrate that StarSD simplifies deployment and supports flexible resource allocation across heterogeneous accelerators, while maintaining output quality. These results indicate that StarSD is a practical and scalable framework for bringing speculative decoding to modern cloud and edge inference infrastructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21622v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junhao He, Feiran You, Hongyang Du</dc:creator>
    </item>
    <item>
      <title>A Thermal-Electrical Co-Optimization Framework for Active Distribution Grids with Electric Vehicles and Heat Pumps</title>
      <link>https://arxiv.org/abs/2601.21651</link>
      <description>arXiv:2601.21651v1 Announce Type: new 
Abstract: The growing electrification of transportation and heating through Electric Vehicles (EVs) and Heat Pumps (HPs) introduces both flexibility and complexity to Active Distribution Networks (ADNs). These resources provide substantial operational flexibility but also create tightly coupled thermal-electrical dynamics that challenge conventional network management. This paper proposes a unified co-optimization framework that integrates a calibrated 3R2C grey-box building thermal model into a network-constrained Optimal Power Flow (OPF). The framework jointly optimizes EVs, HPs, and photovoltaic systems while explicitly enforcing thermal comfort, Distributed Energy Resource (DER) limits, and full power flow physics. To maintain computational tractability, Second-Order Cone Programming (SOCP) relaxations are evaluated on a realistic low-voltage feeder. The analysis shows that, despite network heterogeneity violating some theoretical exactness conditions, the relaxation remains exact in practice. Comparative assessments of convex DistFlow, bus injection, and branch flow formulations reveal that convex DistFlow achieves sub-second runtimes and near-optimal performance even at high DER penetration levels. Simulations confirm the effectiveness of coordinated scheduling, yielding reductions of 41% in transformer aging, 54% in losses, and complete elimination of voltage violations, demonstrating the value of integrated thermal-electrical coordination in future smart grids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21651v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Savvas Panagi, Chrysovalantis Spanias, Petros Aristidou</dc:creator>
    </item>
    <item>
      <title>BAP-SRL: Bayesian Adaptive Priority Safe Reinforcement Learning for Vehicle Motion Planning at Mixed Traffic Intersections</title>
      <link>https://arxiv.org/abs/2601.21679</link>
      <description>arXiv:2601.21679v1 Announce Type: new 
Abstract: Navigating urban intersections, especially when interacting with heterogeneous traffic participants, presents a formidable challenge for autonomous vehicles (AVs). In such environments, safety risks arise simultaneously from multiple sources, each carrying distinct priority levels and sensitivities that necessitate differential protection preferences. While safe reinforcement learning (RL) offers a robust paradigm for constrained decision-making, existing methods typically model safety as a single constraint or employ static, heuristic weighting schemes for multiple constraints. These approaches often fail to address the dynamic nature of multi-source risks, leading to gradient cancellation that hampers learning, and suboptimal trade-offs in critical dilemma zones. To address this, we propose a Bayesian adaptive priority safe reinforcement learning (BAP-SRL) based motion planning framework. Unlike heuristic weighting schemes, BAP formulates constraint prioritization as a probabilistic inference task. By modeling historical optimization difficulty as a Bayesian prior and instantaneous risk evidence as a likelihood, BAP dynamically gates gradient updates using a Bayesian inference mechanism on latent constraint criticality. Extensive experiments demonstrate that our approach outperforms state-of-the-art baselines in handling interactions with stochastic, heterogeneous agents, achieving lower collision rates and smoother conflict resolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21679v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuansheng Lian, Ke Zhang, Yaming Guo, Shen Li, Meng Li</dc:creator>
    </item>
    <item>
      <title>Optimal Transport for Time-Varying Multi-Agent Coverage Control</title>
      <link>https://arxiv.org/abs/2601.21753</link>
      <description>arXiv:2601.21753v1 Announce Type: new 
Abstract: Coverage control algorithms have traditionally focused on static target densities, where agents are deployed to optimally cover a fixed spatial distribution. However, many applications involve time-varying densities, including environmental monitoring, surveillance, and adaptive sensor deployment. Although time-varying coverage strategies have been studied within Voronoi-based frameworks, recent works have reformulated static coverage control as a semi-discrete optimal transport problem. Extending this optimal transport perspective to time-varying scenarios has remained an open challenge. This paper presents a rigorous optimal transport formulation for time-varying coverage control, in which agents minimize the instantaneous Wasserstein distance to a continuously evolving target density. The proposed solution relies on a coupled system of differential equations governing agent positions and the dual variables that define Laguerre regions. In one-dimensional domains, the resulting system admits a closed-form analytical solution, offering both computational benefits and theoretical insight into the structure of optimal time-varying coverage. Numerical simulations demonstrate improved tracking performance compared to quasi-static and Voronoi-based methods, validating the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21753v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Italo Napolitano, Mario di Bernardo</dc:creator>
    </item>
    <item>
      <title>Learning to Dial-a-Ride: A Deep Graph Reinforcement Learning Approach to the Electric Dial-a-Ride Problem</title>
      <link>https://arxiv.org/abs/2601.22052</link>
      <description>arXiv:2601.22052v1 Announce Type: new 
Abstract: Urban mobility systems are transitioning toward electric, on-demand services, creating operational challenges for fleet management under energy and service-quality constraints. The Electric Dial-a-Ride Problem (E-DARP) extends the classical dial-a-ride problem by incorporating limited battery capacity and nonlinear charging dynamics, increasing computational complexity and limiting the scalability of exact methods for real-time use. This paper proposes a deep reinforcement learning approach based on a graph neural network encoder and an attention-driven route construction policy. By operating directly on edge attributes such as travel time and energy consumption, the method captures non-Euclidean, asymmetric, and energy-dependent routing costs in real road networks. The learned policy jointly optimizes routing, charging, and service quality without relying on Euclidean assumptions or handcrafted heuristics. The approach is evaluated on two case studies using ride-sharing data from San Francisco. On benchmark instances, the method achieves solutions within 0.4% of best-known results while reducing computation times by orders of magnitude. A second case study considers large-scale instances with up to 250 request pairs, realistic energy models, and nonlinear charging. On these instances, the learned policy outperforms Adaptive Large Neighborhood Search (ALNS) by 9.5% in solution quality while achieving 100% service completion, with sub-second inference times compared to hours for the metaheuristic. Finally, sensitivity analyses quantify the impact of battery capacity, fleet size, ride-sharing capacity, and reward weights, while robustness experiments show that deterministically trained policies generalize effectively under stochastic conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22052v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sten Elling Tingstad Jacobsen, Attila Lischka, Bal\'azs Kulcs\'ar, Anders Lindman</dc:creator>
    </item>
    <item>
      <title>A Gradient-Based Capacity Accreditation Framework in Resource Adequacy: Formulation, Computation, and Practical Implications</title>
      <link>https://arxiv.org/abs/2601.22087</link>
      <description>arXiv:2601.22087v1 Announce Type: new 
Abstract: Probabilistic resource adequacy assessment is a cornerstone of modern capacity accreditation. This paper develops a gradient-based framework, in which capacity accreditation is interpreted as the directional derivative of a probabilistic resource adequacy metric with respect to resource capacity, that unifies two widely used accreditation approaches: Effective Load Carrying Capability (ELCC) and Marginal Reliability Impact (MRI). Under mild regularity conditions, we show that marginal ELCC and MRI yield equivalent accreditation factors, while their numerical implementations exhibit markedly different computational characteristics. Building on this framework, we demonstrate how infinitesimal perturbation analysis enables up to a $1000\times$ speedup in gradient estimation for capacity accreditation, and we implement gradient-informed search algorithms that significantly accelerate ELCC computations relative to standard bisection methods. Large-scale Monte Carlo experiments show that MRI achieves substantial runtime reductions compared to ELCC and exhibits greater robustness to perturbation step-size selection. These results provide practical guidance for implementing efficient and scalable capacity accreditation in large-scale power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22087v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Zhang, Feng Zhao, Gord Stephen, Chanan Singh, Le Xie</dc:creator>
    </item>
    <item>
      <title>Reformulating Energy Storage Capacity Accreditation Problem with Marginal Reliability Impact</title>
      <link>https://arxiv.org/abs/2601.22096</link>
      <description>arXiv:2601.22096v1 Announce Type: new 
Abstract: To enhance the efficiency of capacity markets, many electricity markets in the U.S. are adopting or planning to implement marginal capacity accreditation reforms. This paper provides new insights into energy storage capacity accreditation using Marginal Reliability Impact (MRI). We reformulate the commonly used reliability-based storage dispatch model as an optimization problem, enabling direct calculation of the MRI from the Lagrange multipliers, rather than using brute-force perturbation analysis. The analysis demonstrates that the EUE is a piecewise linear function and the storage MRI retains a non-negative property across various system scenarios. We further explore the influence of qualified capacity (QC), storage dispatch rules, and other key factors on storage accreditation, providing practical insights for system operators. Additionally, comparisons of storage capacity accreditation under different reliability criteria offer valuable guidance for policymakers in setting future standards. Numerical results from a modified California system validate our findings and highlight several important phenomena associated with the MRI-based accreditation scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22096v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Zhang, Feng Zhao, Tongxin Zheng, Le Xie</dc:creator>
    </item>
    <item>
      <title>Comparative Assessment of Look-Ahead Economic Dispatch and Ramp Products for Grid Flexibility</title>
      <link>https://arxiv.org/abs/2601.22120</link>
      <description>arXiv:2601.22120v1 Announce Type: new 
Abstract: High renewable penetration increases the frequency and magnitude of net-load ramps, stressing real-time flexibility. Two commonly deployed remedies are look-ahead economic dispatch (LAED) and ramp products (RPs), yet their operational equivalence under the industry-standard rolling-window dispatch implementation is not well understood. This paper develops linear optimization models for multi-interval LAED and RP-based co-optimization, and proves that an enhanced RP formulation can match LAED's dispatch feasible region at a single time step when additional intertemporal deliverability constraints are enforced. We then show that this equivalence does not generally persist under rolling-window operation because LAED and RP formulations optimize different intertemporal objectives, leading to divergent end-of-window states. Using different test systems under stressed ramping conditions and multiple load levels, we show LAED achieves similar or lower load shedding than RP implementations with the same look-ahead horizon, with the most pronounced differences under high-load, ramp-limited conditions. The study highlights the limitations of current ramp product implementations and suggests enhancements, such as introducing more mid-duration RPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22120v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qian Zhang, Le Xie, Long Zhao, Congcong Wang</dc:creator>
    </item>
    <item>
      <title>Experimental Design for Matching</title>
      <link>https://arxiv.org/abs/2601.21036</link>
      <description>arXiv:2601.21036v1 Announce Type: cross 
Abstract: Matching mechanisms play a central role in operations management across diverse fields including education, healthcare, and online platforms. However, experimentally comparing a new matching algorithm against a status quo presents some fundamental challenges due to matching interference, where assigning a unit in one matching may preclude its assignment in the other. In this work, we take a design-based perspective to study the design of randomized experiments to compare two predetermined matching plans on a finite population, without imposing outcome or behavioral models. We introduce the notation of a disagreement set, which captures the difference between the two matching plans, and show that it admits a unique decomposition into disjoint alternating paths and cycles with useful structural properties. Based on these properties, we propose the Alternating Path Randomized Design, which sequentially randomizes along these paths and cycles to effectively manage interference. Within a minimax framework, we optimize the conditional randomization probability and show that, for long paths, the optimal choice converges to $\sqrt{2}-1$, minimizing worst-case variance. We establish the unbiasedness of the Horvitz-Thompson estimator and derive a finite-population Central Limit Theorem that accommodates complex and unstable path and cycle structures as the population grows. Furthermore, we extend the design to many-to-one matchings, where capacity constraints fundamentally alter the structure of the disagreement set. Using graph-theoretic tools, including finding augmenting paths and Euler-tour decomposition on an auxiliary unbalanced directed graph, we construct feasible alternating path and cycle decompositions that allow the design and inference results to carry over.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21036v1</guid>
      <category>stat.ME</category>
      <category>cs.SY</category>
      <category>econ.EM</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chonghuan Wang</dc:creator>
    </item>
    <item>
      <title>Safety Generalization Under Distribution Shift in Safe Reinforcement Learning: A Diabetes Testbed</title>
      <link>https://arxiv.org/abs/2601.21094</link>
      <description>arXiv:2601.21094v1 Announce Type: cross 
Abstract: Safe Reinforcement Learning (RL) algorithms are typically evaluated under fixed training conditions. We investigate whether training-time safety guarantees transfer to deployment under distribution shift, using diabetes management as a safety-critical testbed. We benchmark safe RL algorithms on a unified clinical simulator and reveal a safety generalization gap: policies satisfying constraints during training frequently violate safety requirements on unseen patients. We demonstrate that test-time shielding, which filters unsafe actions using learned dynamics models, effectively restores safety across algorithms and patient populations. Across eight safe RL algorithms, three diabetes types, and three age groups, shielding achieves Time-in-Range gains of 13--14\% for strong baselines such as PPO-Lag and CPO while reducing clinical risk index and glucose variability. Our simulator and benchmark provide a platform for studying safety under distribution shift in safety-critical control domains. Code is available at https://github.com/safe-autonomy-lab/GlucoSim and https://github.com/safe-autonomy-lab/GlucoAlg.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21094v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minjae Kwon, Josephine Lamp, Lu Feng</dc:creator>
    </item>
    <item>
      <title>Deep QP Safety Filter: Model-free Learning for Reachability-based Safety Filter</title>
      <link>https://arxiv.org/abs/2601.21297</link>
      <description>arXiv:2601.21297v1 Announce Type: cross 
Abstract: We introduce Deep QP Safety Filter, a fully data-driven safety layer for black-box dynamical systems. Our method learns a Quadratic-Program (QP) safety filter without model knowledge by combining Hamilton-Jacobi (HJ) reachability with model-free learning. We construct contraction-based losses for both the safety value and its derivatives, and train two neural networks accordingly. In the exact setting, the learned critic converges to the viscosity solution (and its derivative), even for non-smooth values. Across diverse dynamical systems -- even including a hybrid system -- and multiple RL tasks, Deep QP Safety Filter substantially reduces pre-convergence failures while accelerating learning toward higher returns than strong baselines, offering a principled and practical route to safe, model-free control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21297v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Byeongjun Kim, H. Jin Kim</dc:creator>
    </item>
    <item>
      <title>A Time-Domain Dual-Edge Asynchronous Pipelined SAR ADC Featuring Reset-Free Quantization at Multi-GS/s</title>
      <link>https://arxiv.org/abs/2601.21308</link>
      <description>arXiv:2601.21308v1 Announce Type: cross 
Abstract: Time-domain ADCs are attractive for high-speed wireline receivers, as time resolution scales favorably with advanced CMOS technologies, enabling multi-GS/s single-channel sampling rates. However, conventional time-domain ADCs require explicit reset of voltage-to-time and time-domain signal paths between samples, introducing dead time that fundamentally limits resolution, speed, and energy efficiency. This paper introduces a dual-edge reset-free quantization concept for asynchronous pipelined SAR time-domain ADCs, in which both rising and falling signal edges are exploited to enable reset-free quantization within a single conversion period. By eliminating explicit reset phases, the proposed approach expands the effective conversion window and relaxes the resolution-speed tradeoff at high sampling rates. An 8-bit dual-edge asynchronous pipelined SAR time-domain ADC is implemented in 22-nm FD-SOI, incorporating a linearity-compensated dual-edge voltage-to-time converter and a dual-edge time-to-digital converter with independently tunable rising- and falling-edge delays. The prototype occupies a core area of 0.0089 mm^2 and achieves continuous single-channel operation at 3.5 GS/s, with architectural scalability demonstrated through intermittent operation at 10.5 GS/s and higher. At 3.5 GS/s, the ADC achieves 21.6 dB SNDR and 32.2 dB SFDR. The measured performance is primarily limited by identifiable implementation-level factors rather than by architectural constraints, demonstrating the feasibility of dual-edge reset-free quantization for high-speed time-domain ADCs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21308v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Zeng, Anthony Chan Carusone, Xilin Liu</dc:creator>
    </item>
    <item>
      <title>IROS: A Dual-Process Architecture for Real-Time VLM-Based Indoor Navigation</title>
      <link>https://arxiv.org/abs/2601.21506</link>
      <description>arXiv:2601.21506v1 Announce Type: cross 
Abstract: Indoor mobile robot navigation requires fast responsiveness and robust semantic understanding, yet existing methods struggle to provide both. Classical geometric approaches such as SLAM offer reliable localization but depend on detailed maps and cannot interpret human-targeted cues (e.g., signs, room numbers) essential for indoor reasoning. Vision-Language-Action (VLA) models introduce semantic grounding but remain strictly reactive, basing decisions only on visible frames and failing to anticipate unseen intersections or reason about distant textual cues. Vision-Language Models (VLMs) provide richer contextual inference but suffer from high computational latency, making them unsuitable for real-time operation on embedded platforms. In this work, we present IROS, a real-time navigation framework that combines VLM-level contextual reasoning with the efficiency of lightweight perceptual modules on low-cost, on-device hardware. Inspired by Dual Process Theory, IROS separates fast reflexive decisions (System One) from slow deliberative reasoning (System Two), invoking the VLM only when necessary. Furthermore, by augmenting compact VLMs with spatial and textual cues, IROS delivers robust, human-like navigation with minimal latency. Across five real-world buildings, IROS improves decision accuracy and reduces latency by 66% compared to continuous VLM-based navigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21506v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joonhee Lee, Hyunseung Shin, Jeonggil Ko</dc:creator>
    </item>
    <item>
      <title>Authenticated encryption for space telemetry</title>
      <link>https://arxiv.org/abs/2601.21657</link>
      <description>arXiv:2601.21657v1 Announce Type: cross 
Abstract: We explore how command stack protection requirements outlined in NASA-STD-1006A can be satisfied within the context of emergency space telemetry. Proposed implementation of lightweight authenticated encryption offers strong security without sacrificing performance in resource-constrained environments. It produces fixed-length messages, maintaining compatibility with the underlying data transport protocols. By focusing on predictable properties and robust authentication, we create a scheme that protects the confidentiality, integrity and authenticity of telemetry data in emergency communications while balancing security requirements with the operational constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21657v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.52202/083082-0066</arxiv:DOI>
      <arxiv:journal_reference>Space Communications and Navigation Symposium (IAF 2025), pages 553-563</arxiv:journal_reference>
      <dc:creator>Andrew Savchenko</dc:creator>
    </item>
    <item>
      <title>SmartMeterFM: Unifying Smart Meter Data Generative Tasks Using Flow Matching Models</title>
      <link>https://arxiv.org/abs/2601.21706</link>
      <description>arXiv:2601.21706v1 Announce Type: cross 
Abstract: Smart meter data is the foundation for planning and operating the distribution network. Unfortunately, such data are not always available due to privacy regulations. Meanwhile, the collected data may be corrupted due to sensor or transmission failure, or it may not have sufficient resolution for downstream tasks. A wide range of generative tasks is formulated to address these issues, including synthetic data generation, missing data imputation, and super-resolution. Despite the success of machine learning models on these tasks, dedicated models need to be designed and trained for each task, leading to redundancy and inefficiency. In this paper, by recognizing the powerful modeling capability of flow matching models, we propose a new approach to unify diverse smart meter data generative tasks with a single model trained for conditional generation. The proposed flow matching models are trained to generate challenging, high-dimensional time series data, specifically monthly smart meter data at a 15 min resolution. By viewing different generative tasks as distinct forms of partial data observations and injecting them into the generation process, we unify tasks such as imputation and super-resolution with a single model, eliminating the need for re-training. The data generated by our model not only are consistent with the given observations but also remain realistic, showing better performance against interpolation and other machine learning based baselines dedicated to the tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21706v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nan Lin, Yanbo Wang, Jacco Heres, Peter Palensky, Pedro P. Vergara</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Continual Learning for Mobile Edge UAV Networks: Mitigating Catastrophic Forgetting</title>
      <link>https://arxiv.org/abs/2601.21861</link>
      <description>arXiv:2601.21861v1 Announce Type: cross 
Abstract: This paper addresses the critical challenge of coordinating mobile edge UAV networks to maintain robust service in highly dynamic spatiotemporal environments. Conventional Deep Reinforcement Learning (DRL) approaches often suffer from catastrophic forgetting when transitioning between distinct task scenarios, such as moving from dense urban clusters to sparse rural areas. These transitions typically necessitate computationally expensive retraining or model resets to adapt to new user distributions, leading to service interruptions. To overcome these limitations, we propose a computationally efficient Spatiotemporal Continual Learning (STCL) framework realized through a Group-Decoupled Multi-Agent Proximal Policy Optimization (G-MAPPO) algorithm. Our approach integrates a novel Group-Decoupled Policy Optimization (GDPO) mechanism that utilizes dynamic $z$-score normalization to autonomously balance heterogeneous objectives, including energy efficiency, user fairness, and coverage. This mechanism effectively mitigates gradient conflicts induced by concept drifts without requiring offline retraining. Furthermore, the framework leverages the 3D mobility of UAVs as a spatial compensation layer, enabling the swarm to autonomously adjust altitudes to accommodate extreme density fluctuations. Extensive simulations demonstrate that the proposed STCL framework achieves superior resilience, characterized by an elastic recovery of service reliability to approximately 0.95 during phase transitions. Compared to the MADDPG baseline, G-MAPPO not only prevents knowledge forgetting but also delivers an effective capacity gain of 20\% under extreme traffic loads, validating its potential as a scalable solution for edge-enabled aerial swarms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21861v1</guid>
      <category>cs.NI</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuan-Chi Lai</dc:creator>
    </item>
    <item>
      <title>Generalized Information Gathering Under Dynamics Uncertainty</title>
      <link>https://arxiv.org/abs/2601.21988</link>
      <description>arXiv:2601.21988v1 Announce Type: cross 
Abstract: An agent operating in an unknown dynamical system must learn its dynamics from observations. Active information gathering accelerates this learning, but existing methods derive bespoke costs for specific modeling choices: dynamics models, belief update procedures, observation models, and planners. We present a unifying framework that decouples these choices from the information-gathering cost by explicitly exposing the causal dependencies between parameters, beliefs, and controls. Using this framework, we derive a general information-gathering cost based on Massey's directed information that assumes only Markov dynamics with additive noise and is otherwise agnostic to modeling choices. We prove that the mutual information cost used in existing literature is a special case of our cost. Then, we leverage our framework to establish an explicit connection between the mutual information cost and information gain in linearized Bayesian estimation, thereby providing theoretical justification for mutual information-based active learning approaches. Finally, we illustrate the practical utility of our framework through experiments spanning linear, nonlinear, and multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21988v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Palafox, Jingqi Li, Jesse Milzman, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Volt/VAR Optimization in Transmission Networks with Discrete-Control Devices</title>
      <link>https://arxiv.org/abs/2601.22080</link>
      <description>arXiv:2601.22080v1 Announce Type: cross 
Abstract: Voltage (Volt) and reactive-power (VAR) control in transmission networks is critical for reliability and increasingly needs fast, implementable decisions. This paper presents a transmission Volt/VAR Optimization (VVO) framework that co-optimizes discrete control of on-load tap-changing transformers (OLTCs) and capacitor banks (CBs) with AC power flow (ACPF) physics to improve voltage stability and minimize VAR generation. The framework follows a relax-round-resolve pipeline: a continuous relaxation proposes targets, a rounding step selects feasible discrete settings, and a final solve enforces AC power flow physics. Extensive experiments on IEEE, PEGASE, and RTE systems show consistent improvements in voltage and VAR quality metrics with modest generator redispatch while preserving economic operation and achieving compatible runtimes with real-time transmission operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22080v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuaicheng Tong, Michael A. Boateng, Mathieu Tanneau, Pascal Van Hentenryck</dc:creator>
    </item>
    <item>
      <title>Beyond Martingale Estimators: Structured Estimators for Maximizing Information Freshness in Query-Based Update Systems</title>
      <link>https://arxiv.org/abs/2601.22098</link>
      <description>arXiv:2601.22098v1 Announce Type: cross 
Abstract: This paper investigates information freshness in a remote estimation system in which the remote information source is a continuous-time Markov chain (CTMC). For such systems, estimators have been mainly restricted to the class of martingale estimators in which the remote estimate at any time is equal to the value of the most recently received update. This is mainly due to the simplicity and ease of analysis of martingale estimators, which however are far from optimal, especially in query-based (i.e., pull-based) update systems. In such systems, maximum a-posteriori probability (MAP) estimators are optimal. However, MAP estimators can be challenging to analyze in continuous-time settings. In this paper, we introduce a new class of estimators, called structured estimators, which can seamlessly shift from a martingale estimator to a MAP estimator, enabling them to retain useful characteristics of the MAP estimate, while still being analytically tractable. Particularly, we introduce a new estimator termed as the $p$-MAP estimator which is a piecewise-constant approximation of the MAP estimator with finitely many discontinuities, bringing us closer to a full characterization of MAP estimators when modeling information freshness. In fact, we show that for time-reversible CTMCs, the MAP estimator reduces to a $p$-MAP estimator. Using the binary freshness (BF) process for the characterization of information freshness, we derive the freshness expressions and provide optimal state-dependent sampling policies (i.e., querying policies) for maximizing the mean BF (MBF) for pull-based remote estimation of a single CTMC information source, when structured estimators are used. Moreover, we provide optimal query rate allocation policies when a monitor pulls information from multiple heterogeneous CTMCs with a constraint on the overall query rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22098v1</guid>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sahan Liyanaarachchi, Sennur Ulukus, Nail Akar</dc:creator>
    </item>
    <item>
      <title>Physics Informed Reconstruction of Four-Dimensional Atmospheric Wind Fields Using Multi-UAS Swarm Observations in a Synthetic Turbulent Environment</title>
      <link>https://arxiv.org/abs/2601.22111</link>
      <description>arXiv:2601.22111v1 Announce Type: cross 
Abstract: Accurate reconstruction of atmospheric wind fields is essential for applications such as weather forecasting, hazard prediction, and wind energy assessment, yet conventional instruments leave spatio-temporal gaps within the lower atmospheric boundary layer. Unmanned aircraft systems (UAS) provide flexible in situ measurements, but individual platforms sample wind only along their flight trajectories, limiting full wind-field recovery. This study presents a framework for reconstructing four-dimensional atmospheric wind fields using measurements obtained from a coordinated UAS swarm. A synthetic turbulence environment and high-fidelity multirotor simulation are used to generate training and evaluation data. Local wind components are estimated from UAS dynamics using a bidirectional long short-term memory network (Bi-LSTM) and assimilated into a physics-informed neural network (PINN) to reconstruct a continuous wind field in space and time. For local wind estimation, the bidirectional LSTM achieves root-mean-square errors (RMSE) of 0.064 and 0.062 m/s for the north and east components in low-wind conditions, increasing to 0.122 to 0.129 m/s under moderate winds and 0.271 to 0.273 m/s in high-wind conditions, while the vertical component exhibits higher error, with RMSE values of 0.029 to 0.091 m/s. The physics-informed reconstruction recovers the dominant spatial and temporal structure of the wind field up to 1000 m altitude while preserving mean flow direction and vertical shear. Under moderate wind conditions, the reconstructed mean wind field achieves an overall RMSE between 0.118 and 0.154 m/s across evaluated UAS configurations, with the lowest error obtained using a five-UAS swarm. These results demonstrate that coordinated UAS measurements enable accurate and scalable four-dimensional wind-field reconstruction without dedicated wind sensors or fixed infrastructure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22111v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>physics.ao-ph</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Tasim, Wei Sun</dc:creator>
    </item>
    <item>
      <title>SINA: A Circuit Schematic Image-to-Netlist Generator Using Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2601.22114</link>
      <description>arXiv:2601.22114v1 Announce Type: cross 
Abstract: Current methods for converting circuit schematic images into machine-readable netlists struggle with component recognition and connectivity inference. In this paper, we present SINA, an open-source, fully automated circuit schematic image-to-netlist generator. SINA integrates deep learning for accurate component detection, Connected-Component Labeling (CCL) for precise connectivity extraction, and Optical Character Recognition (OCR) for component reference designator retrieval, while employing a Vision-Language Model (VLM) for reliable reference designator assignments. In our experiments, SINA achieves 96.47% overall netlist-generation accuracy, which is 2.72x higher than state-of-the-art approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22114v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saoud Aldowaish, Yashwanth Karumanchi, Kai-Chen Chiang, Soroosh Noorzad, Morteza Fayazi</dc:creator>
    </item>
    <item>
      <title>Late Breaking Results: Conversion of Neural Networks into Logic Flows for Edge Computing</title>
      <link>https://arxiv.org/abs/2601.22151</link>
      <description>arXiv:2601.22151v1 Announce Type: cross 
Abstract: Neural networks have been successfully applied in various resource-constrained edge devices, where usually central processing units (CPUs) instead of graphics processing units exist due to limited power availability. State-of-the-art research still focuses on efficiently executing enormous numbers of multiply-accumulate (MAC) operations. However, CPUs themselves are not good at executing such mathematical operations on a large scale, since they are more suited to execute control flow logic, i.e., computer algorithms. To enhance the computation efficiency of neural networks on CPUs, in this paper, we propose to convert them into logic flows for execution. Specifically, neural networks are first converted into equivalent decision trees, from which decision paths with constant leaves are then selected and compressed into logic flows. Such logic flows consist of if and else structures and a reduced number of MAC operations. Experimental results demonstrate that the latency can be reduced by up to 14.9 % on a simulated RISC-V CPU without any accuracy degradation.
  The code is open source at https://github.com/TUDa-HWAI/NN2Logic</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22151v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Stein, Shaoyi Huang, Rolf Drechsler, Bing Li, Grace Li Zhang</dc:creator>
    </item>
    <item>
      <title>The Feasibility Theory of Constrained Reinforcement Learning: A Tutorial Study</title>
      <link>https://arxiv.org/abs/2404.10064</link>
      <description>arXiv:2404.10064v2 Announce Type: replace 
Abstract: Satisfying safety constraints is a priority concern when solving optimal control problems (OCPs). Due to the existence of infeasibility phenomenon, where a constraint-satisfying solution cannot be found, it is necessary to identify a feasible region before implementing a policy. Existing feasibility theories built for model predictive control (MPC) only consider the feasibility of optimal policy. However, reinforcement learning (RL), as another important control method, solves the optimal policy in an iterative manner, which comes with a series of non-optimal intermediate policies. Feasibility analysis of these non-optimal policies is also necessary for iteratively improving constraint satisfaction; but that is not available under existing MPC feasibility theories. This paper proposes a feasibility theory that applies to both MPC and RL by filling in the missing part of feasibility analysis for an arbitrary policy. The basis of our theory is to decouple policy solving and implementation into two temporal domains: virtual-time domain and real-time domain. This allows us to separately define initial and endless, state and policy feasibility, and their corresponding feasible regions. Based on these definitions, we analyze the containment relationships between different feasible regions, which enables us to describe the feasible region of an arbitrary policy. We further provide virtual-time constraint design rules along with a practical design tool called feasibility function that helps to achieve the maximum feasible region. We review most of existing constraint formulations and point out that they are essentially applications of feasibility functions in different forms. We demonstrate our feasibility theory by visualizing different feasible regions under both MPC and RL policies in an emergency braking control task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10064v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yujie Yang, Zhilong Zheng, Masayoshi Tomizuka, Changliu Liu, Shengbo Eben Li</dc:creator>
    </item>
    <item>
      <title>Multi-threshold time series analysis enables characterization of variable renewable energy droughts in Europe</title>
      <link>https://arxiv.org/abs/2410.00244</link>
      <description>arXiv:2410.00244v4 Announce Type: replace 
Abstract: Variable renewable energy droughts, so called Dunkelflaute events, emerge as a challenge for climate-neutral energy systems based on variable renewables. Here we characterize European drought events for on- and offshore wind power, solar photovoltaics, and renewable technology portfolios, using 38 historic weather years and an advanced identification method. Their characteristics heavily depend on the chosen drought threshold, questioning the usefulness of single-threshold analyses. Applying a multi-threshold framework, we quantify how the complementarity of wind and solar power temporally and spatially alleviates drought frequency, return periods, duration, and severity within (portfolio effect) and across countries (balancing effect). We identify the most extreme droughts, which drive major discharging periods of long-duration storage in a fully renewable European energy system, based on a policy-relevant decarbonization scenario. Such events comprise sequences of shorter droughts of varying severity. The most extreme event occurred in winter 1996/97 and lasted 55 days in an idealized, perfectly interconnected setting. The average renewable availability during this period was still 47% of its long-run mean. System planners must consider such events when planning for storage and other flexibility technologies. Methodologically, we conclude that using arbitrary single calendar years is not suitable for modeling weather-resilient energy scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00244v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>physics.ao-ph</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Kittel, Wolf-Peter Schill</dc:creator>
    </item>
    <item>
      <title>High Effort, Low Gain: Fundamental Limits of Active Learning for Linear Dynamical Systems</title>
      <link>https://arxiv.org/abs/2509.11907</link>
      <description>arXiv:2509.11907v2 Announce Type: replace 
Abstract: In this work, we consider the problem of identifying an unknown linear dynamical system given a finite hypothesis class. In particular, we analyze the effect of the excitation input on the sample complexity of identifying the true system with high probability. To this end, we present sample complexity lower bounds that capture the choice of the selected excitation input. The sample complexity lower bound gives rise to a system theoretic condition to determine the potential benefit of experiment design. Informed by the analysis of the sample complexity lower bound, we propose a persistent excitation (PE) condition tailored to the considered setting, which we then use to establish sample complexity upper bounds. Notably, the PE condition is weaker than in the case of an infinite hypothesis class and allows analyzing different excitation inputs modularly. Crucially, the lower and upper bounds share the same dependency on key problem parameters. Finally, we leverage these insights to propose an active learning algorithm that sequentially excites the system optimally with respect to the current estimate, and provide sample complexity guarantees for the presented algorithm. Concluding simulations showcase the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11907v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Chatzikiriakos, Kevin Jamieson, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Next-Generation Grid Codes: Toward a New Paradigm for Dynamic Ancillary Services</title>
      <link>https://arxiv.org/abs/2601.07090</link>
      <description>arXiv:2601.07090v2 Announce Type: replace 
Abstract: This paper presents preliminary results toward a conceptual foundation for Next Generation Grid Codes (NGGCs) based on decentralized stability and performance certification for dynamic ancillary services. The proposed NGGC framework targets two core outcomes: (i) guaranteed closed-loop stability and (ii) explicit performance assurances for power-system frequency and voltage dynamics. Stability is addressed using loop-shifting and passivity-based methods that yield local frequency-domain certificates for individual devices, enabling fully decentralized verification of the interconnected system. Performance is characterized by deriving quantitative bounds on key time-domain metrics (e.g., nadirs, rate-of-change-of-frequency (RoCoF), steady-state deviations, and oscillation damping) through frequency-domain constraints on local device behavior. The framework is non-parametric and model-agnostic, accommodating a broad class of device dynamics under mild assumptions, and provides an initial unified approach to stability and performance certification without explicit device-model parameterization. As such, these results offer a principled starting point for the development of future grid codes and control design methodologies in modern power systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07090v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Verena H\"aberle, Kehao Zhuang, Xiuqiang He, Linbin Huang, Gabriela Hug, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Model-Free Output Feedback Stabilization via Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2601.19284</link>
      <description>arXiv:2601.19284v2 Announce Type: replace 
Abstract: Stabilizing a dynamical system is a fundamental problem that serves as a cornerstone for many complex tasks in the field of control systems. The problem becomes challenging when the system model is unknown. Among the Reinforcement Learning (RL) algorithms that have been successfully applied to solve problems pertaining to unknown linear dynamical systems, the policy gradient (PG) method stands out due to its ease of implementation and can solve the problem in a model-free manner. However, most of the existing works on PG methods for unknown linear dynamical systems assume full-state feedback. In this paper, we take a step towards model-free learning for partially observable linear dynamical systems with output feedback and focus on the fundamental stabilization problem of the system. We propose an algorithmic framework that stretches the boundary of PG methods to the problem without global convergence guarantees. We show that by leveraging zeroth-order PG update based on system trajectories and its convergence to stationary points, the proposed algorithms return a stabilizing output feedback policy for discrete-time linear dynamical systems. We also explicitly characterize the sample complexity of our algorithm and verify the effectiveness of the algorithm using numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.19284v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ankang Zhang, Ming Chi, Xiaoling Wang, Lintao Ye</dc:creator>
    </item>
    <item>
      <title>Incorporating the ChEES Criterion into Sequential Monte Carlo Samplers</title>
      <link>https://arxiv.org/abs/2504.02627</link>
      <description>arXiv:2504.02627v2 Announce Type: replace-cross 
Abstract: Markov chain Monte Carlo (MCMC) methods are a powerful but computationally expensive way of performing non-parametric Bayesian inference. MCMC proposals which utilise gradients, such as Hamiltonian Monte Carlo (HMC), can better explore the parameter space of interest if the additional hyper-parameters are chosen well. The No-U-Turn Sampler (NUTS) is a variant of HMC which is extremely effective at selecting these hyper-parameters but is slow to run and is not suited to GPU architectures. An alternative to NUTS, Change in the Estimator of the Expected Square HMC (ChEES-HMC) was shown not only to run faster than NUTS on GPU but also sample from posteriors more efficiently. Sequential Monte Carlo (SMC) samplers are another sampling method which instead output weighted samples from the posterior. They are very amenable to parallelisation and therefore being run on GPUs while having additional flexibility in their choice of proposal over MCMC. We incorporate (ChEEs-HMC) as a proposal into SMC samplers and demonstrate competitive but faster performance than NUTS on a number of tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02627v2</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Millard, Joshua Murphy, Daniel Frisch, Simon Maskell</dc:creator>
    </item>
    <item>
      <title>Transport and Delivery of Objects with a Soft Everting Robot</title>
      <link>https://arxiv.org/abs/2507.22188</link>
      <description>arXiv:2507.22188v2 Announce Type: replace-cross 
Abstract: Soft everting robots present significant advantages over traditional rigid robots, including enhanced dexterity, improved environmental interaction, and safe navigation in unpredictable environments. While soft everting robots have been widely demonstrated for exploration type tasks, their potential to move and deploy payloads in such tasks has been less investigated, with previous work focusing on sensors and tools for the robot. Leveraging the navigation capabilities, and deployed body, of the soft everting robot to deliver payloads in hazardous areas, e.g. carrying a water bottle to a person stuck under debris, would represent a significant capability in many applications. In this work, we present an analysis of how soft everting robots can be used to deploy larger, heavier payloads through the inside of the robot. We analyze both what objects can be deployed and what terrain features they can be carried through. Building on existing models, we present methods to quantify the effects of payloads on robot growth and self-support, and develop a model to predict payload slip. We then experimentally quantify payload transport using soft everting robot with a variety of payload shapes, sizes, and weights and though a series of tasks: steering, vertical transport, movement through holes, and movement across gaps. Overall, the results show that we can transport payloads in a variety of shapes and up to 1.5kg in weight and that we can move through circular apertures with as little as 0.01cm clearance around payloads, carry out discrete turns up to 135 degrees, and move across unsupported gaps of 1.15m in length.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22188v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LRA.2026.3655537</arxiv:DOI>
      <dc:creator>Ethan DeVries, Jack Ferlazzo, Mustafa Ugur, Laura H. Blumenschein</dc:creator>
    </item>
    <item>
      <title>Applying the Spectral Method for Modeling Linear Filters: Butterworth, Linkwitz-Riley, and Chebyshev filters</title>
      <link>https://arxiv.org/abs/2508.07206</link>
      <description>arXiv:2508.07206v2 Announce Type: replace-cross 
Abstract: This paper proposes a new technique for computer modeling linear filters based on the spectral form of mathematical description of linear systems. It assumes the representation of input and output signals of the filter as orthogonal expansions, while filters themselves are described by two-dimensional non-stationary transfer functions. This technique allows one to model the output signal in continuous time, and it is successfully tested on the Butterworth, Linkwitz-Riley, and Chebyshev filters with different orders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.07206v2</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.fraope.2026.100508</arxiv:DOI>
      <arxiv:journal_reference>Franklin Open 2026, 14, 100508</arxiv:journal_reference>
      <dc:creator>Konstantin A. Rybakov, Egor D. Shermatov</dc:creator>
    </item>
    <item>
      <title>Neural Policy Composition from Free Energy Minimization</title>
      <link>https://arxiv.org/abs/2512.04745</link>
      <description>arXiv:2512.04745v2 Announce Type: replace-cross 
Abstract: The ability to compose acquired skills to plan and execute behaviors is a hallmark of natural intelligence. Yet, despite remarkable cross-disciplinary efforts, a principled account of how task structure shapes gating and how such computations could be delivered in neural circuits, remains elusive. Here we introduce GateMod, an interpretable theoretically grounded computational model linking the emergence of gating to the underlying decision-making task, and to a neural circuit architecture. We first develop GateFrame, a normative framework casting policy gating into the minimization of the free energy. This framework, relating gating rules to task, applies broadly across neuroscience, cognitive and computational sciences. We then derive GateFlow, a continuous-time energy based dynamics that provably converges to GateFrame optimal solution. Convergence, exponential and global, follows from a contractivity property that also yields robustness and other desirable properties. Finally, we derive a neural circuit from GateFlow, GateNet. This is a soft-competitive recurrent circuit whose components perform local and contextual computations consistent with known dendritic and neural processing motifs. We evaluate GateMod across two different settings: collective behaviors in multi-agent systems and human decision-making in multi-armed bandits. In all settings, GateMod provides interpretable mechanistic explanations of gating and quantitatively matches or outperforms established models. GateMod offers a unifying framework for neural policy gating, linking task objectives, dynamical computation, and circuit-level mechanisms. It provides a framework to understand gating in natural agents beyond current explanations and to equip machines with this ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.04745v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Francesca Rossi, Veronica Centorrino, Francesco Bullo, Giovanni Russo</dc:creator>
    </item>
    <item>
      <title>When Does Adaptation Win? Scaling Laws for Meta-Learning in Quantum Control</title>
      <link>https://arxiv.org/abs/2601.18973</link>
      <description>arXiv:2601.18973v2 Announce Type: replace-cross 
Abstract: Quantum hardware suffers from intrinsic device heterogeneity and environmental drift, forcing practitioners to choose between suboptimal non-adaptive controllers or costly per-device recalibration. We derive a scaling law lower bound for meta-learning showing that the adaptation gain (expected fidelity improvement from task-specific gradient steps) saturates exponentially with gradient steps and scales linearly with task variance, providing a quantitative criterion for when adaptation justifies its overhead. Validation on quantum gate calibration shows negligible benefits for low-variance tasks but $&gt;40\%$ fidelity gains on two-qubit gates under extreme out-of-distribution conditions (10$\times$ the training noise), with implications for reducing per-device calibration time on cloud quantum processors. Further validation on classical linear-quadratic control confirms these laws emerge from general optimization geometry rather than quantum-specific physics. Together, these results offer a transferable framework for decision-making in adaptive control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18973v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>quant-ph</category>
      <pubDate>Fri, 30 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nima Leclerc, Chris Miller, Nicholas Brawand</dc:creator>
    </item>
  </channel>
</rss>
