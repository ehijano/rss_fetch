<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Dec 2024 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Polynomial and analytic methods for classifying complexity of planar graph homomorphisms</title>
      <link>https://arxiv.org/abs/2412.17122</link>
      <description>arXiv:2412.17122v1 Announce Type: new 
Abstract: We introduce some polynomial and analytic methods in the classification program for the complexity of planar graph homomorphisms. These methods allow us to handle infinitely many lattice conditions and isolate the new P-time tractable matrices represented by tensor products of matchgates. We use these methods to prove a complexity dichotomy for $4 \times 4$ matrices that says Valiant's holographic algorithm is universal for planar tractability in this setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17122v1</guid>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jin-Yi Cai, Ashwin Maran</dc:creator>
    </item>
    <item>
      <title>Inference Scaling vs Reasoning: An Empirical Analysis of Compute-Optimal LLM Problem-Solving</title>
      <link>https://arxiv.org/abs/2412.16260</link>
      <description>arXiv:2412.16260v1 Announce Type: cross 
Abstract: Recent advances in large language models (LLMs) have predominantly focused on maximizing accuracy and reasoning capabilities, often overlooking crucial computational efficiency considerations. While this approach has yielded impressive accuracy improvements, it has led to methods that may be impractical for real-world deployment due to computational overhead and latency constraints. This paper investigates the potential synergy between reasoning enhancement and computational efficiency by analyzing the integration of two contrasting approaches: Quiet-STaR (Self-Taught Reasoner) and REBASE (REward BAlanced SEarch). Through comprehensive empirical analysis using the Mistral-7B model on the GSM8K dataset, we demonstrate that while each method excels in its primary objective-Quiet-STaR achieving superior accuracy (32.03%) despite high computational cost (554.66s runtime, 12.73T FLOPs), and REBASE providing exceptional efficiency (8.47s runtime, 2.35T FLOPs) while maintaining baseline-comparable accuracy (10.94%)-their integration reveals fundamental challenges in reconciling reasoning depth with computational efficiency. The combined approach unexpectedly results in degraded performance (9.38% accuracy, 143.66s runtime), highlighting critical insights about the complex interplay between reasoning enhancement and efficiency optimization in LLMs. Our findings illuminate the need for novel architectures and algorithms specifically designed to bridge the gap between these competing objectives, while providing concrete directions for future research in compute-efficient reasoning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16260v1</guid>
      <category>cs.LG</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marwan AbdElhameed, Pavly Halim</dc:creator>
    </item>
    <item>
      <title>Knowledge as a Breaking of Ergodicity</title>
      <link>https://arxiv.org/abs/2412.16411</link>
      <description>arXiv:2412.16411v1 Announce Type: cross 
Abstract: We construct a thermodynamic potential that can guide training of a generative model defined on a set of binary degrees of freedom. We argue that upon reduction in description, so as to make the generative model computationally-manageable, the potential develops multiple minima. This is mirrored by the emergence of multiple minima in the free energy proper of the generative model itself. The variety of training samples that employ N binary degrees of freedom is ordinarily much lower than the size 2^N of the full phase space. The non-represented configurations, we argue, should be thought of as comprising a high-temperature phase separated by an extensive energy gap from the configurations composing the training set. Thus, training amounts to sampling a free energy surface in the form of a library of distinct bound states, each of which breaks ergodicity. The ergodicity breaking prevents escape into the near continuum of states comprising the high-temperature phase; thus it is necessary for proper functionality. It may however have the side effect of limiting access to patterns that were underrepresented in the training set. At the same time, the ergodicity breaking within the library complicates both learning and retrieval. As a remedy, one may concurrently employ multiple generative models -- up to one model per free energy minimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16411v1</guid>
      <category>cs.AI</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.CC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang He, Vassiliy Lubchenko</dc:creator>
    </item>
    <item>
      <title>An alternative non-unitary implementation for the quantum search algorithm</title>
      <link>https://arxiv.org/abs/2412.16514</link>
      <description>arXiv:2412.16514v1 Announce Type: cross 
Abstract: In this paper, we describe an alternative circuit implementation for the Grover search algorithm by replacing the amplitude amplification part with a non-unitary gate which can be implemented by using an additional ancilla register. We show that the final quantum state in the Grover search algorithm is the normalized marked quantum state in the Gram-Schmidt process. Therefore, one can try to generate this vector by using a non-unitary gate or an approximation of this non-unitary gate. Since we still use the marking part of the original algorithm, $U_{mark}$, the complexity of the algorithm is bounded by the complexity of this operator. We discuss how the implementation of the non-unitary may not be easy task and show the approximations to this operator e.g. through linear combination of unitary matrices or similar methods. Finally we discuss, how these approximations may change the complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16514v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ammar Daskin</dc:creator>
    </item>
    <item>
      <title>Parameterized Complexity of Caching in Networks</title>
      <link>https://arxiv.org/abs/2412.16585</link>
      <description>arXiv:2412.16585v1 Announce Type: cross 
Abstract: The fundamental caching problem in networks asks to find an allocation of contents to a network of caches with the aim of maximizing the cache hit rate. Despite the problem's importance to a variety of research areas -- including not only content delivery, but also edge intelligence and inference -- and the extensive body of work on empirical aspects of caching, very little is known about the exact boundaries of tractability for the problem beyond its general NP-hardness. We close this gap by performing a comprehensive complexity-theoretic analysis of the problem through the lens of the parameterized complexity paradigm, which is designed to provide more precise statements regarding algorithmic tractability than classical complexity. Our results include algorithmic lower and upper bounds which together establish the conditions under which the caching problem becomes tractable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16585v1</guid>
      <category>cs.NI</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Ganian, Fionn Mc Inerney, Dimitra Tsigkari</dc:creator>
    </item>
    <item>
      <title>Dynamic T-decomposition for classical simulation of quantum circuits</title>
      <link>https://arxiv.org/abs/2412.17182</link>
      <description>arXiv:2412.17182v1 Announce Type: cross 
Abstract: It is known that a quantum circuit may be simulated with classical hardware via stabilizer state (T-)decomposition in $O(2^{\alpha t})$ time, given $t$ non-Clifford gates and a decomposition efficiency $\alpha$. The past years have seen a number of papers presenting new decompositions of lower $\alpha$ to reduce this runtime and enable simulation of ever larger circuits. More recently, it has been demonstrated that well placed applications of apparently weaker (higher $\alpha$) decompositions can in fact result in better overall efficiency when paired with the circuit simplification strategies of ZX-calculus.
  In this work, we take the most generalized T-decomposition (namely vertex cutting), which achieves a poor efficiency of $\alpha=1$, and identify common structures to which applying this can, after simplification via ZX-calculus rewriting, yield very strong effective efficiencies $\alpha_{\text{eff}}\ll1$. By taking into account this broader scope of the ZX-diagram and incorporating the simplification facilitated by the well-motivated cuts, we derive a handful of efficient T-decompositions whose applicabilities are relatively frequent. In benchmarking these new 'dynamic' decompositions against the existing alternatives, we observe a significant reduction in overall $\alpha$ and hence overall runtime for classical simulation, particularly for certain common circuit classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17182v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wira Azmoon Ahmad, Matthew Sutcliffe</dc:creator>
    </item>
    <item>
      <title>Fast Gradient Computation for RoPE Attention in Almost Linear Time</title>
      <link>https://arxiv.org/abs/2412.17316</link>
      <description>arXiv:2412.17316v1 Announce Type: cross 
Abstract: The Rotary Position Embedding (RoPE) mechanism has become a powerful enhancement to the Transformer architecture, which enables models to capture token relationships when encoding positional information. However, the RoPE mechanisms make the computations of attention mechanisms more complicated, which makes efficient algorithms challenging. Earlier research introduced almost linear time, i.e., $n^{1+o(1)}$ where $n$ is the number of input tokens, algorithms for the forward computation under specific parameter settings. However, achieving a subquadratic time algorithm for other parameter regimes remains impossible unless the widely accepted Strong Exponential Time Hypothesis (SETH) is disproven. In this work, we develop the first almost linear time algorithm for backward computations in the RoPE-based attention under bounded entries. Our approach builds on recent advancements in fast RoPE attention computations, utilizing a novel combination of the polynomial method and the Fast Fourier Transform. Furthermore, we show that with lower bounds derived from the SETH, the bounded entry condition is necessary for subquadratic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17316v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.CL</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifang Chen, Jiayan Huo, Xiaoyu Li, Yingyu Liang, Zhenmei Shi, Zhao Song</dc:creator>
    </item>
    <item>
      <title>Translational Aperiodic Sets of 7 Polyominoes</title>
      <link>https://arxiv.org/abs/2412.17382</link>
      <description>arXiv:2412.17382v1 Announce Type: cross 
Abstract: Recently, two extraordinary results on aperiodic monotiles have been obtained in two different settings. One is a family of aperiodic monotiles in the plane discovered by Smith, Myers, Kaplan and Goodman-Strauss in 2023, where rotation is allowed, breaking the 50-year-old record (aperiodic sets of two tiles found by Roger Penrose in the 1970s) on the minimum size of aperiodic sets in the plane. The other is the existence of an aperiodic monotile in the translational tiling of $\mathbb{Z}^n$ for some huge dimension $n$ proved by Greenfeld and Tao. This disproves the long-standing periodic tiling conjecture. However, it is known that there is no aperiodic monotile for translational tiling of the plane. The smallest size of known aperiodic sets for translational tilings of the plane is $8$, which was discovered more than $30$ years ago by Ammann. In this paper, we prove that translational tiling of the plane with a set of $7$ polyominoes is undecidable. As a consequence of the undecidability, we have constructed a family of aperiodic sets of size $7$ for the translational tiling of the plane. This breaks the 30-year-old record of Ammann.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17382v1</guid>
      <category>math.CO</category>
      <category>cs.CC</category>
      <category>cs.CG</category>
      <category>math.MG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Yang, Zhujun Zhang</dc:creator>
    </item>
    <item>
      <title>Hiding, Shuffling, and Triangle Finding: Quantum Algorithms on Edge Lists</title>
      <link>https://arxiv.org/abs/2412.17786</link>
      <description>arXiv:2412.17786v1 Announce Type: cross 
Abstract: The edge list model is arguably the simplest input model for graphs, where the graph is specified by a list of its edges. In this model, we study the quantum query complexity of three variants of the triangle finding problem. The first asks whether there exists a triangle containing a target edge and raises general questions about the hiding of a problem's input among irrelevant data. The second asks whether there exists a triangle containing a target vertex and raises general questions about the shuffling of a problem's input. The third asks for finding a triangle in the input edge list; this problem bridges the $3$-distinctness and $3$-sum problems, which have been extensively studied by both cryptographers and complexity theorists. We provide tight or nearly tight results for all of our problems as well as some first answers to the general questions they raise. In particular, given a graph with low maximum degree, such as a random sparse graph, we prove that the quantum query complexity of triangle finding in its length-$m$ edge list is $m^{5/7 \pm o(1)}$. We prove the lower bound in Zhandry's recording query framework [CRYPTO '19] and the upper bound by adapting Belovs's learning graph algorithm for $3$-distinctness [FOCS '12].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17786v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Shiraz Gilani, Daochen Wang, Pei Wu, Xingyu Zhou</dc:creator>
    </item>
    <item>
      <title>A correspondence between the time and space complexity</title>
      <link>https://arxiv.org/abs/2311.01184</link>
      <description>arXiv:2311.01184v2 Announce Type: replace 
Abstract: We investigate the correspondence between the time and space recognition complexity of languages. For this purpose, we will code the long-continued computations of deterministic two-tape Turing machines by the relatively short-length quantified Boolean formulae. The modified Meyer and Stockmeyer method will appreciably be used for this simulation. It will be proved using this modeling that the complexity classes Deterministic Exponential Time and Deterministic Polynomial Space coincide. It will also be proven that any language recognized in polynomial time can be recognized in almost logarithmic space. Furthermore, this allows us slightly to improve the early founded lower complexity bound of decidable theories that are nontrivial relative to some equivalence relation (this relation may be equality) -- each of these theories is consistent with the formula, which asserts that there are two non-equivalent elements.
  Keywords: computational complexity, the coding of computations through formulae, exponential time, polynomial space, the lower complexity bound of the language recognition</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.01184v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan V. Latkin</dc:creator>
    </item>
    <item>
      <title>Multi-Structural Games and Beyond</title>
      <link>https://arxiv.org/abs/2301.13329</link>
      <description>arXiv:2301.13329v5 Announce Type: replace-cross 
Abstract: Multi-structural (MS) games are combinatorial games that capture the number of quantifiers of first-order sentences. On the face of their definition, MS games differ from Ehrenfeucht-Fraisse (EF) games in two ways: first, MS games are played on two sets of structures, while EF games are played on a pair of structures; second, in MS games, Duplicator can make any number of copies of structures. In the first part of this paper, we perform a finer analysis of MS games and develop a closer comparison of MS games with EF games. In particular, we point out that the use of sets of structures is of the essence and that when MS games are played on pairs of structures, they capture Boolean combinations of first-order sentences with a fixed number of quantifiers. After this, we focus on another important difference between MS games and EF games, namely, the necessity for Spoiler to play on top of a previous move in order to win some MS games. Via an analysis of the types realized during MS games, we delineate the expressive power of the variant of MS games in which Spoiler never plays on top of a previous move. In the second part we focus on simultaneously capturing number of quantifiers and number of variables in first-order logic. We show that natural variants of the MS game do *not* achieve this. We then introduce a new game, the quantifier-variable tree game, and show that it simultaneously captures the number of quantifiers and number of variables. We conclude by generalizing this game to a family of games, the *syntactic games*, that simultaneously capture reasonable syntactic measures and the number of variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.13329v5</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Carmosino, Ronald Fagin, Neil Immerman, Phokion Kolaitis, Jonathan Lenchner, Rik Sengupta</dc:creator>
    </item>
    <item>
      <title>Computational Complexity-Constrained Spectral Efficiency Analysis for 6G Waveforms</title>
      <link>https://arxiv.org/abs/2407.05805</link>
      <description>arXiv:2407.05805v2 Announce Type: replace-cross 
Abstract: In this work, we present a tutorial on how to account for the computational time complexity overhead of signal processing in the spectral efficiency (SE) analysis of wireless waveforms. Our methodology is particularly relevant in scenarios where achieving higher SE entails a penalty in complexity, a common trade-off present in 6G candidate waveforms. We consider that SE derives from the data rate, which is impacted by time-dependent overheads. Thus, neglecting the computational complexity overhead in the SE analysis grants an unfair advantage to more computationally complex waveforms, as they require larger computational resources to meet a signal processing runtime below the symbol period. We demonstrate our points with two case studies. In the first, we refer to IEEE 802.11a-compliant baseband processors from the literature to show that their runtime significantly impacts the SE perceived by upper layers. In the second case study, we show that waveforms considered less efficient in terms of SE can outperform their more computationally expensive counterparts if provided with equivalent high-performance computational resources. Based on these cases, we believe our tutorial can address the comparative SE analysis of waveforms that operate under different computational resource constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05805v2</guid>
      <category>eess.SP</category>
      <category>cs.CC</category>
      <category>cs.PF</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saulo Queiroz, Jo\~ao P. Vilela, Benjamin Koon Kei Ng, Chan-Tong Lam, Edmundo Monteiro</dc:creator>
    </item>
  </channel>
</rss>
