<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 06 Jan 2026 03:22:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>StockBot 2.0: Vanilla LSTMs Outperform Transformer-based Forecasting for Stock Prices</title>
      <link>https://arxiv.org/abs/2601.00197</link>
      <description>arXiv:2601.00197v1 Announce Type: new 
Abstract: Accurate forecasting of financial markets remains a long-standing challenge due to complex temporal and often latent dependencies, non-linear dynamics, and high volatility. Building on our earlier recurrent neural network framework, we present an enhanced StockBot architecture that systematically evaluates modern attention-based, convolutional, and recurrent time-series forecasting models within a unified experimental setting. While attention-based and transformer-inspired models offer increased modeling flexibility, extensive empirical evaluation reveals that a carefully constructed vanilla LSTM consistently achieves superior predictive accuracy and more stable buy/sell decision-making when trained under a common set of default hyperparameters. These results highlight the robustness and data efficiency of recurrent sequence models for financial time-series forecasting, particularly in the absence of extensive hyperparameter tuning or the availability of sufficient data when discretized to single-day intervals. Additionally, these results underscore the importance of architectural inductive bias in data-limited market prediction tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00197v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shaswat Mohanty</dc:creator>
    </item>
    <item>
      <title>Coupled thermo-chemo-mechanical phase field-based modelling of hydrogen-assisted cracking in girth welds</title>
      <link>https://arxiv.org/abs/2601.00471</link>
      <description>arXiv:2601.00471v1 Announce Type: new 
Abstract: A new computational framework is presented to predict the structural integrity of welds in hydrogen transmission pipelines. The framework combines: (i) a thermo-mechanical weld process model, and (ii) a coupled deformation-diffusion-fracture phase field-based model that accounts for plasticity and hydrogen trapping, considering multiple trap types, with stationary and evolving trap densities. This enables capturing, for the first time, the interplay between residual stresses, trap creation, hydrogen transport, and fracture. The computational framework is particularised and applied to the study of weld integrity in X80 pipeline steel. The focus is on girth welds, as they are more complex due to their multi-pass nature. The weld process model enables identifying the dimensions and characteristics of the three weld regions: base metal, heat-affected zone, and weld metal, and these are treated distinctively. This is followed by virtual fracture experiments, which reveal a very good agreement with laboratory studies. Then, weld pipeline integrity is assessed, estimating critical failure pressures for a wide range of scenarios. Of particular interest is to assess the structural integrity implications of welding defects present in existing natural gas pipelines under consideration for hydrogen transport: pores, lack of penetration, imperfections, lack of fusion, root contraction, and undercutting. The results obtained in hydrogen-containing environments reveal an important role of the weld microstructure and the detrimental effect of weld defects that are likely to be present in existing natural gas pipelines, as they are considered safe in gas pipeline standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00471v1</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.app-ph</category>
      <category>physics.chem-ph</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L. Castro, Y. Navidtehrani. C. Beteg\'on, E. Mart\'inez-Pa\~neda</dc:creator>
    </item>
    <item>
      <title>Transfer-learned Kolosov-Muskhelishvili Informed Neural Networks for Fracture Mechanics</title>
      <link>https://arxiv.org/abs/2601.00491</link>
      <description>arXiv:2601.00491v1 Announce Type: new 
Abstract: Physics-informed neural networks have been widely applied to solid mechanics problems. However, balancing the governing partial differential equations and boundary conditions remains challenging, particularly in fracture mechanics, where accurate predictions strongly depend on refined sampling near crack tips. To overcome these limitations, a Kolosov-Muskhelishvili informed neural network with Williams enrichment is developed in this study. Benefiting from the holomorphic representation, the governing equations are satisfied by construction, and only boundary points are required for training. Across a series of benchmark problems, the Kolosov-Muskhelishvili informed neural network shows excellent agreement with analytical and finite element method references, achieving average relative errors below 1\% and $R^2$ above 0.99 for both mode I and mode II loadings. Furthermore, three crack propagation criteria (maximum tangential stress, maximum energy release rate, and principle of local symmetry) are integrated into the framework using a transfer learning strategy to predict crack propagation directions. The predicted paths are nearly identical across all criteria, and the transfer learning strategy reduces the required training time by more than 70\%. Overall, the developed framework provides a unified, mesh-free, and physically consistent approach for accurate and efficient crack propagation analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00491v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuwei Zhou, Christian Haeffner, Shuancheng Wang, Sophie Stebner, Zhen Liao, Bing Yang, Zhichao Wei, Sebastian Muenstermann</dc:creator>
    </item>
    <item>
      <title>Effect of Electric Charge on Biotherapeutic Transport, Binding and Absorption: A Computational Study</title>
      <link>https://arxiv.org/abs/2601.00505</link>
      <description>arXiv:2601.00505v1 Announce Type: new 
Abstract: This study explores the effects of electric charge on the dynamics of drug transport and absorption in subcutaneous injections of monoclonal antibodies (mAbs). We develop a novel mathematical and computational model, based on the Nernst-Planck equations and porous media flow theory, to investigate the complex interactions between mAbs and charged species in subcutaneous tissue. The model enables us to study short-term transport dynamics and long-term binding and absorption for two mAbs with different electric properties. We examine the influence of buffer pH, body mass index, injection depth, and formulation concentration on drug distribution and compare our numerical results with experimental data from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00505v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario de Lucio, Pavlos P. Vlachos, Hector Gomez</dc:creator>
    </item>
    <item>
      <title>Toward Efficient FSI Modeling in Patient-Specific Arteries: SPH Simulation of Blood Flow in Thin Deformable Vessels</title>
      <link>https://arxiv.org/abs/2601.00546</link>
      <description>arXiv:2601.00546v1 Announce Type: new 
Abstract: Accurate simulation of blood flow in deformable vessels is critical in cardiovascular research for understanding disease progression and informing clinical decision-making. However, due to the thin-walled nature of arteries, traditional smoothed particle hydrodynamics (SPH) approaches based on full-dimensional volume modeling often require extremely fine particle spacing to ensure numerical convergence for the solid mechanics. This, in turn, leads to redundant resolution in the fluid domain to maintain sufficient kernel support near the fluid-solid interface in fluid-structure interaction (FSI) simulations. To address this limitation, we propose an efficient reduced-dimensional shell-based SPH method for modeling thin-walled deformable arteries, and conduct FSI for capturing hemodynamics and arterial wall mechanics. Through a series of validation cases, the proposed shell model demonstrates comparable accuracy in fluid dynamics to the volume model, while achieving faster convergence in solid mechanics and reduced computational cost. We further investigate the influence of wall compliance on flow transitions and key hemodynamic indices, highlighting the necessity of FSI modeling over rigid-wall assumptions. Finally, the method is applied to two patient-specific vascular geometries, i.e. the carotid artery and the aorta, which demonstrates its robustness, efficiency and physiological relevance in realistic cardiovascular simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00546v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenxi Zhao, Dong Wu, Weiyi Kong, Oskar J. Haidn, Xiangyu Hu</dc:creator>
    </item>
    <item>
      <title>LLM Agents for Combinatorial Efficient Frontiers: Investment Portfolio Optimization</title>
      <link>https://arxiv.org/abs/2601.00770</link>
      <description>arXiv:2601.00770v1 Announce Type: new 
Abstract: Investment portfolio optimization is a task conducted in all major financial institutions. The Cardinality Constrained Mean-Variance Portfolio Optimization (CCPO) problem formulation is ubiquitous for portfolio optimization. The challenge of this type of portfolio optimization, a mixed-integer quadratic programming (MIQP) problem, arises from the intractability of solutions from exact solvers, where heuristic algorithms are used to find approximate portfolio solutions. CCPO entails many laborious and complex workflows and also requires extensive effort pertaining to heuristic algorithm development, where the combination of pooled heuristic solutions results in improved efficient frontiers. Hence, common approaches are to develop many heuristic algorithms. Agentic frameworks emerge as a promising candidate for many problems within combinatorial optimization, as they have been shown to be equally efficient with regard to automating large workflows and have been shown to be excellent in terms of algorithm development, sometimes surpassing human-level performance. This study implements a novel agentic framework for the CCPO and explores several concrete architectures. In benchmark problems, the implemented agentic framework matches state-of-the-art algorithms. Furthermore, complex workflows and algorithm development efforts are alleviated, while in the worst case, lower but acceptable error is reported.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00770v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Paquette-Greenbaum, Jiangbo Yu</dc:creator>
    </item>
    <item>
      <title>Comparative Evaluation of Embedding Representations for Financial News Sentiment Analysis</title>
      <link>https://arxiv.org/abs/2512.13749</link>
      <description>arXiv:2512.13749v1 Announce Type: cross 
Abstract: Financial sentiment analysis enhances market understanding; however, standard natural language processing approaches encounter significant challenges when applied to small datasets. This study provides a comparative evaluation of embedding-based methods for financial news sentiment classification in resource-constrained environments. Word2Vec, GloVe, and sentence transformer representations are evaluated in combination with gradient boosting on manually labeled headlines. Experimental results identify a substantial gap between validation and test performance, with models performing worse than trivial baselines despite strong validation metrics. The analysis demonstrates that pretrained embeddings yield diminishing returns below a critical data sufficiency threshold, and that small validation sets contribute to overfitting during model selection. Practical application is illustrated through weekly sentiment aggregation and narrative summarization for market monitoring workflows. The findings offer empirical evidence that embedding quality alone cannot address fundamental data scarcity in sentiment classification. For practitioners operating with limited resources, the results indicate the need to consider alternative approaches such as few-shot learning, data augmentation, or lexicon-enhanced hybrid methods when labeled samples are scarce.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13749v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joyjit Roy, Samaresh Kumar Singh</dc:creator>
    </item>
    <item>
      <title>Active learning for data-driven reduced models of parametric differential systems with Bayesian operator inference</title>
      <link>https://arxiv.org/abs/2601.00038</link>
      <description>arXiv:2601.00038v1 Announce Type: cross 
Abstract: This work develops an active learning framework to intelligently enrich data-driven reduced-order models (ROMs) of parametric dynamical systems, which can serve as the foundation of virtual assets in a digital twin. Data-driven ROMs are explainable, computationally efficient scientific machine learning models that aim to preserve the underlying physics of complex dynamical simulations. Since the quality of data-driven ROMs is sensitive to the quality of the limited training data, we seek to identify training parameters for which using the associated training data results in the best possible parametric ROM. Our approach uses the operator inference methodology, a regression-based strategy which can be tailored to particular parametric structure for a large class of problems. We establish a probabilistic version of parametric operator inference, casting the learning problem as a Bayesian linear regression. Prediction uncertainties stemming from the resulting probabilistic ROM solutions are used to design a sequential adaptive sampling scheme to select new training parameter vectors that promote ROM stability and accuracy globally in the parameter domain. We conduct numerical experiments for several nonlinear parametric systems of partial differential equations and compare the results to ROMs trained on random parameter samples. The results demonstrate that the proposed adaptive sampling strategy consistently yields more stable and accurate ROMs than random sampling does under the same computational budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00038v1</guid>
      <category>stat.ML</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shane A. McQuarrie, Mengwu Guo, Anirban Chaudhuri</dc:creator>
    </item>
    <item>
      <title>FCMBench: A Comprehensive Financial Credit Multimodal Benchmark for Real-world Applications</title>
      <link>https://arxiv.org/abs/2601.00150</link>
      <description>arXiv:2601.00150v1 Announce Type: cross 
Abstract: As multimodal AI becomes widely used for credit risk assessment and document review, a domain-specific benchmark is urgently needed that (1) reflects documents and workflows specific to financial credit applications, (2) includes credit-specific understanding and real-world robustness, and (3) preserves privacy compliance without sacrificing practical utility. Here, we introduce FCMBench-V1.0 -- a large-scale financial credit multimodal benchmark for real-world applications, covering 18 core certificate types, with 4,043 privacy-compliant images and 8,446 QA samples. The FCMBench evaluation framework consists of three dimensions: Perception, Reasoning, and Robustness, including 3 foundational perception tasks, 4 credit-specific reasoning tasks that require decision-oriented understanding of visual evidence, and 10 real-world acquisition artifact types for robustness stress testing. To reconcile compliance with realism, we construct all samples via a closed synthesis-capture pipeline: we manually synthesize document templates with virtual content and capture scenario-aware images in-house. This design also mitigates pre-training data leakage by avoiding web-sourced or publicly released images. FCMBench can effectively discriminate performance disparities and robustness across modern vision-language models. Extensive experiments were conducted on 23 state-of-the-art vision-language models (VLMs) from 14 top AI companies and research institutes. Among them, Gemini 3 Pro achieves the best F1(\%) score as a commercial model (64.61), Qwen3-VL-235B achieves the best score as an open-source baseline (57.27), and our financial credit-specific model, Qfin-VL-Instruct, achieves the top overall score (64.92). Robustness evaluations show that even top-performing models suffer noticeable performance drops under acquisition artifacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00150v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.MM</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yehui Yang, Dalu Yang, Wenshuo Zhou, Fangxin Shang, Yifan Liu, Jie Ren, Haojun Fei, Qing Yang, Tao Chen</dc:creator>
    </item>
    <item>
      <title>Benchmarking ERP Analysis: Manual Features, Deep Learning, and Foundation Models</title>
      <link>https://arxiv.org/abs/2601.00573</link>
      <description>arXiv:2601.00573v1 Announce Type: cross 
Abstract: Event-related potential (ERP), a specialized paradigm of electroencephalographic (EEG), reflects neurological responses to external stimuli or events, generally associated with the brain's processing of specific cognitive tasks. ERP plays a critical role in cognitive analysis, the detection of neurological diseases, and the assessment of psychological states. Recent years have seen substantial advances in deep learning-based methods for spontaneous EEG and other non-time-locked task-related EEG signals. However, their effectiveness on ERP data remains underexplored, and many existing ERP studies still rely heavily on manually extracted features. In this paper, we conduct a comprehensive benchmark study that systematically compares traditional manual features (followed by a linear classifier), deep learning models, and pre-trained EEG foundation models for ERP analysis. We establish a unified data preprocessing and training pipeline and evaluate these approaches on two representative tasks, ERP stimulus classification and ERP-based brain disease detection, across 12 publicly available datasets. Furthermore, we investigate various patch-embedding strategies within advanced Transformer architectures to identify embedding designs that better suit ERP data. Our study provides a landmark framework to guide method selection and tailored model design for future ERP analysis. The code is available at https://github.com/DL4mHealth/ERP-Benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00573v1</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yihe Wang, Zhiqiao Kang, Bohan Chen, Yu Zhang, Xiang Zhang</dc:creator>
    </item>
    <item>
      <title>Physio-DPO: Aligning Large Language Models with the Protein Energy Landscape to Eliminate Structural Hallucinations</title>
      <link>https://arxiv.org/abs/2601.00647</link>
      <description>arXiv:2601.00647v1 Announce Type: cross 
Abstract: Large Protein Language Models have shown strong potential for generative protein design, yet they frequently produce structural hallucinations, generating sequences with high linguistic likelihood that fold into thermodynamically unstable conformations. Existing alignment approaches such as Direct Preference Optimization are limited in this setting, as they model preferences as binary labels and ignore the continuous structure of the physical energy landscape. We propose Physio-DPO, a physics informed alignment framework that grounds protein language models in thermodynamic stability. Physio-DPO introduces a magnitude aware objective that scales optimization updates according to the energy gap between native structures and physics perturbed hard negatives. Experiments show that Physio-DPO consistently outperforms strong baselines including SFT, PPO, and standard DPO, reducing self consistency RMSD to 1.28 \AA\ and increasing foldability to 92.8%. Qualitative analysis further demonstrates that Physio-DPO effectively mitigates structural hallucinations by recovering biophysical interactions such as hydrophobic core packing and hydrogen bond networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.00647v1</guid>
      <category>cs.CL</category>
      <category>cs.CE</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>QiWei Meng</dc:creator>
    </item>
    <item>
      <title>Evolutionary Optimization of Physics-Informed Neural Networks: Advancing Generalizability by the Baldwin Effect</title>
      <link>https://arxiv.org/abs/2312.03243</link>
      <description>arXiv:2312.03243v4 Announce Type: replace-cross 
Abstract: Physics-informed neural networks (PINNs) are at the forefront of scientific machine learning, making possible the creation of machine intelligence that is cognizant of physical laws and able to accurately simulate them. However, today's PINNs are often trained for a single physics task and require computationally expensive re-training for each new task, even for tasks from similar physics domains. To address this limitation, this paper proposes a pioneering approach to advance the generalizability of PINNs through the framework of Baldwinian evolution. Drawing inspiration from the neurodevelopment of precocial species that have evolved to learn, predict and react quickly to their environment, we envision PINNs that are pre-wired with connection strengths inducing strong biases towards efficient learning of physics. A novel two-stage stochastic programming formulation coupling evolutionary selection pressure (based on proficiency over a distribution of physics tasks) with lifetime learning (to specialize on a sampled subset of those tasks) is proposed to instantiate the Baldwin effect. The evolved Baldwinian-PINNs demonstrate fast and physics-compliant prediction capabilities across a range of empirically challenging problem instances with more than an order of magnitude improvement in prediction accuracy at a fraction of the computation cost compared to state-of-the-art gradient-based meta-learning methods. For example, when solving the diffusion-reaction equation, a 70x improvement in accuracy was obtained while taking 700x less computational time. This paper thus marks a leap forward in the meta-learning of PINNs as generalizable physics solvers. Sample codes are available at https://github.com/chiuph/Baldwinian-PINN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03243v4</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jian Cheng Wong, Chin Chun Ooi, Abhishek Gupta, Pao-Hsiung Chiu, Joshua Shao Zheng Low, My Ha Dao, Yew-Soon Ong</dc:creator>
    </item>
    <item>
      <title>Evolutionary Optimization of Physics-Informed Neural Networks: Evo-PINN Frontiers and Opportunities</title>
      <link>https://arxiv.org/abs/2501.06572</link>
      <description>arXiv:2501.06572v5 Announce Type: replace-cross 
Abstract: Deep learning models trained on finite data lack a complete understanding of the physical world. On the other hand, physics-informed neural networks (PINNs) are infused with such knowledge through the incorporation of mathematically expressible laws of nature into their training loss function. By complying with physical laws, PINNs provide advantages over purely data-driven models in limited-data regimes and present as a promising route towards Physical AI. This feature has propelled them to the forefront of scientific machine learning, a domain characterized by scarce and costly data. However, the vision of accurate physics-informed learning comes with significant challenges. This work examines PINNs in terms of model optimization and generalization, shedding light on the need for new algorithmic advances to overcome issues pertaining to the training speed, precision, and generalizability of today's PINN models. Of particular interest are gradient-free evolutionary algorithms (EAs) for optimizing the uniquely complex loss landscapes arising in PINN training. Methods synergizing gradient descent and EAs for discovering bespoke neural architectures and balancing multiple terms in physics-informed learning objectives are positioned as important avenues for future research. Another exciting track is to cast EAs as a meta-learner of generalizable PINN models. To substantiate these proposed avenues, we further highlight results from recent literature to showcase the early success of such approaches in addressing the aforementioned challenges in PINN optimization and generalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06572v5</guid>
      <category>cs.NE</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jian Cheng Wong, Abhishek Gupta, Chin Chun Ooi, Pao-Hsiung Chiu, Jiao Liu, Yew-Soon Ong</dc:creator>
    </item>
    <item>
      <title>KANO: Kolmogorov-Arnold Neural Operator</title>
      <link>https://arxiv.org/abs/2509.16825</link>
      <description>arXiv:2509.16825v4 Announce Type: replace-cross 
Abstract: We introduce Kolmogorov--Arnold Neural Operator (KANO), a dual-domain neural operator jointly parameterized by both spectral and spatial bases with intrinsic symbolic interpretability. We theoretically demonstrate that KANO overcomes the pure-spectral bottleneck of Fourier Neural Operator (FNO): KANO remains expressive over generic position-dependent dynamics (variable coefficient PDEs) for any physical input, whereas FNO stays practical only for spectrally sparse operators and strictly imposes a fast-decaying input Fourier tail. We verify our claims empirically on position-dependent differential operators, for which KANO robustly generalizes but FNO fails to. In the quantum Hamiltonian learning benchmark, KANO reconstructs ground-truth Hamiltonians in closed-form symbolic representations accurate to the fourth decimal place in coefficients and attains $\approx 6\times10^{-6}$ state infidelity from projective measurement data, substantially outperforming that of the FNO trained with ideal full wave function data, $\approx 1.5\times10^{-2}$, by orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.16825v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Mon, 05 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jin Lee, Ziming Liu, Xinling Yu, Yixuan Wang, Haewon Jeong, Murphy Yuezhen Niu, Zheng Zhang</dc:creator>
    </item>
  </channel>
</rss>
