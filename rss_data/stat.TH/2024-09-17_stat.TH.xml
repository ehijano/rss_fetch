<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Sep 2024 04:01:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Variance Residual Life Ageing Intensity Function</title>
      <link>https://arxiv.org/abs/2409.10591</link>
      <description>arXiv:2409.10591v1 Announce Type: new 
Abstract: Quantitative measurement of ageing across systems and components is crucial for accurately assessing reliability and predicting failure probabilities. This measurement supports effective maintenance scheduling, performance optimisation, and cost management. Examining the ageing characteristics of a system that operates beyond a specified time $t &gt; 0$ yields valuable insights. This paper introduces a novel metric for ageing, termed the Variance Residual Life Ageing Intensity (VRLAI) function, and explores its properties across various probability distributions. Additionally, we characterise the closure properties of the two ageing classes defined by the VRLAI function. We propose a new ordering, called the Variance Residual Life Ageing Intensity (VRLAI) ordering, and discuss its various properties. Furthermore, we examine the closure of the VRLAI order under coherent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10591v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ashutosh Singh</dc:creator>
    </item>
    <item>
      <title>Learning with Sparsely Permuted Data: A Robust Bayesian Approach</title>
      <link>https://arxiv.org/abs/2409.10678</link>
      <description>arXiv:2409.10678v1 Announce Type: new 
Abstract: Data dispersed across multiple files are commonly integrated through probabilistic linkage methods, where even minimal error rates in record matching can significantly contaminate subsequent statistical analyses. In regression problems, we examine scenarios where the identifiers of predictors or responses are subject to an unknown permutation, challenging the assumption of correspondence. Many emerging approaches in the literature focus on sparsely permuted data, where only a small subset of pairs ($k &lt;&lt; n$) are affected by the permutation, treating these permuted entries as outliers to restore original correspondence and obtain consistent estimates of regression parameters. In this article, we complement the existing literature by introducing a novel generalized robust Bayesian formulation of the problem. We develop an efficient posterior sampling scheme by adapting the fractional posterior framework and addressing key computational bottlenecks via careful use of discrete optimal transport and sampling in the space of binary matrices with fixed margins. Further, we establish new posterior contraction results within this framework, providing theoretical guarantees for our approach. The utility of the proposed framework is demonstrated via extensive numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10678v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhisek Chakraborty, Saptati Datta</dc:creator>
    </item>
    <item>
      <title>Valid Credible Ellipsoids for Linear Functionals by a Renormalized Bernstein-von Mises Theorem</title>
      <link>https://arxiv.org/abs/2409.10947</link>
      <description>arXiv:2409.10947v1 Announce Type: new 
Abstract: We consider a semi-parametric Gaussian regression model, equipped with a high-dimensional Gaussian prior. We address the frequentist validity of posterior credible sets for a vector of linear functionals.
  We specify conditions for a 'renormalized' Bernstein-von Mises theorem (BvM), where the posterior, centered at its mean, and the posterior mean, centered at the ground truth, have the same normal approximation. This requires neither a solution to the information equation nor a $\sqrt{N}$-consistent estimator.
  We show that our renormalized BvM implies that a credible ellipsoid, specified by the mean and variance of the posterior, is an asymptotic confidence set. For a single linear functional, we identify such a credible ellipsoid with a symmetric credible interval around the posterior mean. We bound the diameter.
  We check the conditions for Darcy's problem, where the information equation has no solution in natural settings. For the Schr\"odinger problem, we recover an efficient semi-parametric BvM from our renormalized BvM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10947v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gustav R{\o}mer</dc:creator>
    </item>
    <item>
      <title>Functional Adaptive Huber Linear Regression</title>
      <link>https://arxiv.org/abs/2409.11053</link>
      <description>arXiv:2409.11053v1 Announce Type: new 
Abstract: Robust estimation has played an important role in statistical and machine learning. However, its applications to functional linear regression are still under-developed. In this paper, we focus on Huber's loss with a diverging robustness parameter which was previously used in parametric models. Compared to other robust methods such as median regression, the distinction is that the proposed method aims to estimate the conditional mean robustly, instead of estimating the conditional median. We only require $(1+\kappa)$-th moment assumption ($\kappa&gt;0$) on the noise distribution, and the established error bounds match the optimal rate in the least-squares case as soon as $\kappa\ge 1$. We establish convergence rate in probability when the functional predictor has a finite 4-th moment, and finite-sample bound with exponential tail when the functional predictor is Gaussian, in terms of both prediction error and $L^2$ error. The results also extend to the case of functional estimation in a reproducing kernel Hilbert space (RKHS).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11053v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ling Peng, Xiaohui Liu, Heng Lian</dc:creator>
    </item>
    <item>
      <title>Poisson and Gamma Model Marginalisation and Marginal Likelihood calculation using Moment-generating Functions</title>
      <link>https://arxiv.org/abs/2409.11167</link>
      <description>arXiv:2409.11167v1 Announce Type: cross 
Abstract: We present a new analytical method to derive the likelihood function that has the population of parameters marginalised out in Bayesian hierarchical models. This method is also useful to find the marginal likelihoods in Bayesian models or in random-effect linear mixed models. The key to this method is to take high-order (sometimes fractional) derivatives of the prior moment-generating function if particular existence and differentiability conditions hold.
  In particular, this analytical method assumes that the likelihood is either Poisson or gamma. Under Poisson likelihoods, the observed Poisson count determines the order of the derivative. Under gamma likelihoods, the shape parameter, which is assumed to be known, determines the order of the fractional derivative.
  We also present some examples validating this new analytical method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11167v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Siyang Li, David van Dyk, Maximilian Autenrieth</dc:creator>
    </item>
    <item>
      <title>Edge spectra of Gaussian random symmetric matrices with correlated entries</title>
      <link>https://arxiv.org/abs/2409.11381</link>
      <description>arXiv:2409.11381v1 Announce Type: cross 
Abstract: We study the largest eigenvalue of a Gaussian random symmetric matrix $X_n$, with zero-mean, unit variance entries satisfying the condition $\sup_{(i, j) \ne (i', j')}|\mathbb{E}[X_{ij} X_{i'j'}]| = O(n^{-(1 + \varepsilon)})$, where $\varepsilon &gt; 0$. It follows from Catalano et al. (2024) that the empirical spectral distribution of $n^{-1/2} X_n$ converges weakly almost surely to the standard semi-circle law. Using a F\"{u}redi-Koml\'{o}s-type high moment analysis, we show that the largest eigenvalue $\lambda_1(n^{-1/2} X_n)$ of $n^{-1/2} X_n$ converges almost surely to $2$. This result is essentially optimal in the sense that one cannot take $\varepsilon = 0$ and still obtain an almost sure limit of $2$. We also derive Gaussian fluctuation results for the largest eigenvalue in the case where the entries have a common non-zero mean. Let $Y_n = X_n + \frac{\lambda}{\sqrt{n}}\mathbf{1} \mathbf{1}^\top$. When $\varepsilon \ge 1$ and $\lambda \gg n^{1/4}$, we show that \[
  n^{1/2}\bigg(\lambda_1(n^{-1/2} Y_n) - \lambda - \frac{1}{\lambda}\bigg) \xrightarrow{d} \sqrt{2} Z, \] where $Z$ is a standard Gaussian. On the other hand, when $0 &lt; \varepsilon &lt; 1$, we have $\mathrm{Var}(\frac{1}{n}\sum_{i, j}X_{ij}) = O(n^{1 - \varepsilon})$. Assuming that $\mathrm{Var}(\frac{1}{n}\sum_{i, j} X_{ij}) = \sigma^2 n^{1 - \varepsilon} (1 + o(1))$, if $\lambda \gg n^{\varepsilon/4}$, then we have \[
  n^{\varepsilon/2}\bigg(\lambda_1(n^{-1/2} Y_n) - \lambda - \frac{1}{\lambda}\bigg) \xrightarrow{d} \sigma Z. \] While the ranges of $\lambda$ in these fluctuation results are certainly not optimal, a striking aspect is that different scalings are required in the two regimes $0 &lt; \varepsilon &lt; 1$ and $\varepsilon \ge 1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11381v1</guid>
      <category>math.PR</category>
      <category>math-ph</category>
      <category>math.CO</category>
      <category>math.MP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Debapratim Banerjee, Soumendu Sundar Mukherjee, Dipranjan Pal</dc:creator>
    </item>
    <item>
      <title>Large Deviations Principle for Bures-Wasserstein Barycenters</title>
      <link>https://arxiv.org/abs/2409.11384</link>
      <description>arXiv:2409.11384v1 Announce Type: cross 
Abstract: We prove the large deviations principle for empirical Bures-Wasserstein barycenters of independent, identically-distributed samples of covariance matrices and covariance operators. As an application, we explore some consequences of our results for the phenomenon of dimension-free concentration of measure for Bures-Wasserstein barycenters. Our theory reveals a novel notion of exponential tilting in the Bures-Wasserstein space, which, in analogy with Cr\'amer's theorem in the Euclidean case, solves the relative entropy projection problem under a constraint on the barycenter. Notably, this method of proof is easy to adapt to other geometric settings of interest; with the same method, we obtain large deviations principles for empirical barycenters in Riemannian manifolds and the univariate Wasserstein space, and we obtain large deviations upper bounds for empirical barycenters in the general multivariate Wasserstein space. In fact, our results are the first known large deviations principles for Fr\'echet means in any non-linear metric space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.11384v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Quinn Jaffe, Leonardo V. Santoro</dc:creator>
    </item>
    <item>
      <title>Censoring heavy-tail count distributions for parameter estimation with an application to stable distributions</title>
      <link>https://arxiv.org/abs/2212.11697</link>
      <description>arXiv:2212.11697v4 Announce Type: replace 
Abstract: A new approach based on censoring and moment criterion is introduced for parameter estimation of count distributions when the probability generating function is available even though a closed form of the probability mass function and/or finite moments do not exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11697v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.spl.2023.109903</arxiv:DOI>
      <dc:creator>Antonio Di Noia, Marzia Marcheselli, Caterina Pisani, Luca Pratelli</dc:creator>
    </item>
    <item>
      <title>A unified analysis of likelihood-based estimators in the Plackett--Luce model</title>
      <link>https://arxiv.org/abs/2306.02821</link>
      <description>arXiv:2306.02821v3 Announce Type: replace 
Abstract: The Plackett--Luce model has been extensively used for rank aggregation in social choice theory. A central question in this model concerns estimating the utility vector that governs the model's likelihood. In this paper, we investigate the asymptotic theory of utility vector estimation by maximizing different types of likelihood, such as full, marginal, and quasi-likelihood. Starting from interpreting the estimating equations of these estimators to gain some initial insights, we analyze their asymptotic behavior as the number of compared objects increases. In particular, we establish both the uniform consistency and asymptotic normality of these estimators and discuss the trade-off between statistical efficiency and computational complexity. For generality, our results are proven for deterministic graph sequences under appropriate graph topology conditions. These conditions are shown to be revealing and sharp when applied to common sampling scenarios, such as nonuniform random hypergraph models and hypergraph stochastic block models. Numerical results are provided to support our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.02821v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruijian Han, Yiming Xu</dc:creator>
    </item>
    <item>
      <title>False discovery proportion envelopes with m-consistency</title>
      <link>https://arxiv.org/abs/2306.07819</link>
      <description>arXiv:2306.07819v2 Announce Type: replace 
Abstract: We provide new non-asymptotic false discovery proportion (FDP) confidence envelopes in several multiple testing settings relevant for modern high dimensional-data methods. We revisit the multiple testing scenarios considered in the recent work of Katsevich and Ramdas (2020): top-$k$, preordered (including knockoffs), online. Our emphasis is on obtaining FDP confidence bounds that both have non-asymptotic coverage and are asymptotically accurate in a specific sense, as the number $m$ of tested hypotheses grows. Namely, we introduce and study the property (which we call $m$-consistency) that the confidence bound converges to or below the desired level $\alpha$ when applied to a specific reference $\alpha$-level false discovery rate (FDR) controlling procedure. In this perspective, we derive new bounds that provide improvements over existing ones, both theoretically and practically, and are suitable for situations where at least a moderate number of rejections is expected. These improvements are illustrated with numerical experiments and real data examples. In particular, the improvement is significant in the knockoffs setting, which shows the impact of the method for a practical use. As side results, we introduce a new confidence envelope for the empirical cumulative distribution function of i.i.d. uniform variables, and we provide new power results in sparse cases, both being of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07819v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Iqraa Meah, Gilles Blanchard, Etienne Roquain</dc:creator>
    </item>
    <item>
      <title>Bayesian inference of covariate-parameter relationships for population modelling</title>
      <link>https://arxiv.org/abs/2407.09640</link>
      <description>arXiv:2407.09640v3 Announce Type: replace 
Abstract: We consider population modelling using parametrised ordinary differential equation initial value problems (ODE-IVPs). For each individual drawn randomly from the unknown population distribution, the corresponding parameters for the ODE-IVP cannot be measured directly, but a vector of covariates is given, and one component of the solution to the corresponding ODE-IVP is observed at a fixed finite time grid. The task is to identify a covariate-parameter relationship that maps covariate vectors to parameter vectors. Such settings and problems arise in pharmacokinetics, where the observations are blood drug concentrations, the covariates are clinically observable quantities, and the covariate-parameter relationship is used for personalised drug dosing. For linear homogeneous ODE-IVPs with vector fields defined by matrices that are diagonalisable over $\mathbb{R}$, and for fixed time and random covariate design, we use recent results of Nickl et al. for Bayesian nonlinear statistical inverse problems, to prove posterior contraction and Bernstein--von Mises results for the unknown covariate-parameter relationship. We analytically demonstrate our results on an example from the pharmacokinetics literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09640v3</guid>
      <category>math.ST</category>
      <category>math.CA</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>On the maximal correlation coefficient for the bivariate Marshall Olkin distribution</title>
      <link>https://arxiv.org/abs/2409.08661</link>
      <description>arXiv:2409.08661v2 Announce Type: replace 
Abstract: We prove a formula for the maximal correlation coefficient of the bivariate Marshall Olkin distribution that was conjectured in Lin, Lai, and Govindaraju (2016, Stat. Methodol., 29:1-9). The formula is applied to obtain a new proof for a variance inequality in extreme value statistics that links the disjoint and the sliding block maxima method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08661v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Axel B\"ucher, Torben Staud</dc:creator>
    </item>
    <item>
      <title>The Asymptotics of Wide Remedians</title>
      <link>https://arxiv.org/abs/2409.09528</link>
      <description>arXiv:2409.09528v2 Announce Type: replace 
Abstract: The remedian uses a $k\times b$ matrix to approximate the median of $n\leq b^{k}$ streaming input values by recursively replacing buffers of $b$ values with their medians, thereby ignoring its $200(\lceil b/2\rceil / b)^{k}%$ most extreme inputs. Rousseeuw &amp; Bassett (1990) and Chao &amp; Lin (1993); Chen &amp; Chen (2005) study the remedian's distribution as $k\rightarrow\infty$ and as $k,b\rightarrow\infty$. The remedian's breakdown point vanishes as $k\rightarrow\infty$, but approaches $(1/2)^{k}$ as $b\rightarrow\infty$. We study the remedian's robust-regime distribution as $b\rightarrow\infty$, deriving a normal distribution for standardized (mean, median, remedian, remedian rank) as $b\rightarrow\infty$, thereby illuminating the remedian's accuracy in approximating the sample median. We derive the asymptotic efficiency of the remedian relative to the mean and the median. Finally, we discuss the estimation of more than one quantile at once, proposing an asymptotic distribution for the random vector that results when we apply remedian estimation in parallel to the components of i.i.d. random vectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09528v2</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip T. Labo</dc:creator>
    </item>
    <item>
      <title>A Dynamical System View of Langevin-Based Non-Convex Sampling</title>
      <link>https://arxiv.org/abs/2210.13867</link>
      <description>arXiv:2210.13867v3 Announce Type: replace-cross 
Abstract: Non-convex sampling is a key challenge in machine learning, central to non-convex optimization in deep learning as well as to approximate probabilistic inference. Despite its significance, theoretically there remain many important challenges: Existing guarantees (1) typically only hold for the averaged iterates rather than the more desirable last iterates, (2) lack convergence metrics that capture the scales of the variables such as Wasserstein distances, and (3) mainly apply to elementary schemes such as stochastic gradient Langevin dynamics. In this paper, we develop a new framework that lifts the above issues by harnessing several tools from the theory of dynamical systems. Our key result is that, for a large class of state-of-the-art sampling schemes, their last-iterate convergence in Wasserstein distances can be reduced to the study of their continuous-time counterparts, which is much better understood. Coupled with standard assumptions of MCMC sampling, our theory immediately yields the last-iterate Wasserstein convergence of many advanced sampling schemes such as proximal, randomized mid-point, and Runge-Kutta integrators. Beyond existing methods, our framework also motivates more efficient schemes that enjoy the same rigorous guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.13867v3</guid>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Reza Karimi, Ya-Ping Hsieh, Andreas Krause</dc:creator>
    </item>
    <item>
      <title>Central Limit Theorems for Smooth Optimal Transport Maps</title>
      <link>https://arxiv.org/abs/2312.12407</link>
      <description>arXiv:2312.12407v2 Announce Type: replace-cross 
Abstract: One of the central objects in the theory of optimal transport is the Brenier map: the unique monotone transformation which pushes forward an absolutely continuous probability law onto any other given law. A line of recent work has analyzed $L^2$ convergence rates of plugin estimators of Brenier maps, which are defined as the Brenier map between density estimators of the underlying distributions. In this work, we show that such estimators satisfy a pointwise central limit theorem when the underlying laws are supported on the flat torus of dimension $d \geq 3$. We also derive a negative result, showing that these estimators do not converge weakly in $L^2$ when the dimension is sufficiently large. Our proofs hinge upon a quantitative linearization of the Monge-Amp\`ere equation, which may be of independent interest. This result allows us to reduce our problem to that of deriving limit laws for the solution of a uniformly elliptic partial differential equation with a stochastic right-hand side, subject to periodic boundary conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.12407v2</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tudor Manole, Sivaraman Balakrishnan, Jonathan Niles-Weed, Larry Wasserman</dc:creator>
    </item>
    <item>
      <title>High-arity PAC learning via exchangeability</title>
      <link>https://arxiv.org/abs/2402.14294</link>
      <description>arXiv:2402.14294v3 Announce Type: replace-cross 
Abstract: We develop a theory of high-arity PAC learning, which is statistical learning in the presence of "structured correlation". In this theory, hypotheses are either graphs, hypergraphs or, more generally, structures in finite relational languages, and i.i.d. sampling is replaced by sampling an induced substructure, producing an exchangeable distribution. Our main theorems establish a high-arity (agnostic) version of the fundamental theorem of statistical learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14294v3</guid>
      <category>cs.LG</category>
      <category>math.LO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo N. Coregliano, Maryanthe Malliaris</dc:creator>
    </item>
    <item>
      <title>Wasserstein Proximal Coordinate Gradient Algorithms</title>
      <link>https://arxiv.org/abs/2405.04628</link>
      <description>arXiv:2405.04628v2 Announce Type: replace-cross 
Abstract: Motivated by approximation Bayesian computation using mean-field variational approximation and the computation of equilibrium in multi-species systems with cross-interaction, this paper investigates the composite geodesically convex optimization problem over multiple distributions. The objective functional under consideration is composed of a convex potential energy on a product of Wasserstein spaces and a sum of convex self-interaction and internal energies associated with each distribution. To efficiently solve this problem, we introduce the Wasserstein Proximal Coordinate Gradient (WPCG) algorithms with parallel, sequential, and random update schemes. Under a quadratic growth (QG) condition that is weaker than the usual strong convexity requirement on the objective functional, we show that WPCG converges exponentially fast to the unique global optimum. In the absence of the QG condition, WPCG is still demonstrated to converge to the global optimal solution, albeit at a slower polynomial rate. Numerical results for both motivating examples are consistent with our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04628v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rentian Yao, Xiaohui Chen, Yun Yang</dc:creator>
    </item>
    <item>
      <title>Faster algorithms for the alignment of sparse correlated Erd\"os-R\'enyi random graphs</title>
      <link>https://arxiv.org/abs/2405.08421</link>
      <description>arXiv:2405.08421v2 Announce Type: replace-cross 
Abstract: The correlated Erd\"os-R\'enyi random graph ensemble is a probability law on pairs of graphs with $n$ vertices, parametrized by their average degree $\lambda$ and their correlation coefficient $s$. It can be used as a benchmark for the graph alignment problem, in which the labels of the vertices of one of the graphs are reshuffled by an unknown permutation; the goal is to infer this permutation and thus properly match the pairs of vertices in both graphs. A series of recent works has unveiled the role of Otter's constant $\alpha$ (that controls the exponential rate of growth of the number of unlabeled rooted trees as a function of their sizes) in this problem: for $s&gt;\sqrt{\alpha}$ and $\lambda$ large enough it is possible to recover in a time polynomial in $n$ a positive fraction of the hidden permutation. The exponent of this polynomial growth is however quite large and depends on the other parameters, which limits the range of applications of the algorithm. In this work we present a family of faster algorithms for this task, show through numerical simulations that their accuracy is only slightly reduced with respect to the original one, and conjecture that they undergo, in the large $\lambda$ limit, phase transitions at modified Otter's thresholds $\sqrt{\widehat{\alpha}}&gt;\sqrt{\alpha}$, with $\widehat{\alpha}$ related to the enumeration of a restricted family of trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08421v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Muratori, Guilhem Semerjian</dc:creator>
    </item>
    <item>
      <title>Wasserstein Distributionally Robust Optimization with Heterogeneous Data Sources</title>
      <link>https://arxiv.org/abs/2407.13582</link>
      <description>arXiv:2407.13582v2 Announce Type: replace-cross 
Abstract: We study decision problems under uncertainty, where the decision-maker has access to $K$ data sources that carry {\em biased} information about the underlying risk factors. The biases are measured by the mismatch between the risk factor distribution and the $K$ data-generating distributions with respect to an optimal transport (OT) distance. In this situation the decision-maker can exploit the information contained in the biased samples by solving a distributionally robust optimization (DRO) problem, where the ambiguity set is defined as the intersection of $K$ OT neighborhoods, each of which is centered at the empirical distribution on the samples generated by a biased data source. We show that if the decision-maker has a prior belief about the biases, then the out-of-sample performance of the DRO solution can improve with $K$ -- irrespective of the magnitude of the biases. We also show that, under standard convexity assumptions, the proposed DRO problem is computationally tractable if either $K$ or the dimension of the risk factors is kept constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13582v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yves Rychener, Adrian Esteban-Perez, Juan M. Morales, Daniel Kuhn</dc:creator>
    </item>
    <item>
      <title>Why you should also use OLS estimation of tail exponents</title>
      <link>https://arxiv.org/abs/2409.10448</link>
      <description>arXiv:2409.10448v2 Announce Type: replace-cross 
Abstract: Even though practitioners often estimate Pareto exponents running OLS rank-size regressions, the usual recommendation is to use the Hill MLE with a small-sample correction instead, due to its unbiasedness and efficiency. In this paper, we advocate that you should also apply OLS in empirical applications. On the one hand, we demonstrate that, with a small-sample correction, the OLS estimator is also unbiased. On the other hand, we show that the MLE assigns significantly greater weight to smaller observations. This suggests that the OLS estimator may outperform the MLE in cases where the distribution is (i) strictly Pareto but only in the upper tail or (ii) regularly varying rather than strictly Pareto. We substantiate our theoretical findings with Monte Carlo simulations and real-world applications, demonstrating the practical relevance of the OLS method in estimating tail exponents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10448v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 18 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Trafane Oliveira Santos (Central Bank of Brazil, Bras\'ilia, Brazil. Department of %Economics, University of Brasilia, Brazil), Daniel Oliveira Cajueiro (Department of Economics, University of Brasilia, Brazil. National Institute of Science and Technology for Complex Systems)</dc:creator>
    </item>
  </channel>
</rss>
