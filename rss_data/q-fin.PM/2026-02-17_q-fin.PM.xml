<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.PM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.PM</link>
    <description>q-fin.PM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.PM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Feb 2026 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sustainable Investment: ESG Impacts on Large Portfolio</title>
      <link>https://arxiv.org/abs/2602.14439</link>
      <description>arXiv:2602.14439v1 Announce Type: new 
Abstract: This paper investigates the impact of environmental, social, and governance (ESG) constraint on a regularized mean-variance (MV) portfolio optimization problem in a large-dimensional setting, in which a positive definite regularization matrix is imposed on the sample covariance matrix. We first derive the asymptotic results for the out-of-sample (OOS) Sharpe ratio (SR) of the proposed portfolio, which help quantify the impact of imposing an ESG-level constraint as well as the effect of estimation error arising from the sample mean estimation of the assets' ESG score. Furthermore, to study the influence of the choices of the regularization matrix, we develop an estimator for the OOS Sharpe ratio. The corresponding asymptotic properties of the Sharpe ratio estimator are established based on random matrix theory. Simulation results show that the proposed estimators perform close to the corresponding oracle level. Moreover, we numerically investigate the impact of various forms of regularization matrices on the OOS SR, which provides useful guidance for practical implementation. Finally, based on OOS SR estimator, we propose an adaptive regularized portfolio which uses the best regularization matrix yielding the highest estimated SR (among a set of candidates) at each decision node. Empirical evidence based on the S\&amp;P 500 index demonstrates that the proposed adaptive ESG-constrained portfolio achieves a high OOS SR while satisfying the required ESG level, offering a practically effective approach for sustainable investment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14439v1</guid>
      <category>q-fin.PM</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruike Wu, Yonghe Lu, Yanrong Yang</dc:creator>
    </item>
    <item>
      <title>Merton's Problem with Recursive Perturbed Utility</title>
      <link>https://arxiv.org/abs/2602.13544</link>
      <description>arXiv:2602.13544v1 Announce Type: cross 
Abstract: The classical Merton investment problem predicts deterministic, state-dependent portfolio rules; however, laboratory and field evidence suggests that individuals often prefer randomized decisions leading to stochastic and noisy choices. Fudenberg et al. (2015) develop the additive perturbed utility theory to explain the preference for randomization in the static setting, which, however, becomes ill-posed or intractable in the dynamic setting. We introduce the recursive perturbed utility (RPU), a special stochastic differential utility that incorporates an entropy-based preference for randomization into a recursive aggregator. RPU endogenizes the intertemporal trade-off between utilities from randomization and bequest via a discounting term dependent on past accumulated randomization, thereby avoiding excessive randomization and yielding a well-posed problem. In a general Markovian incomplete market with CRRA preferences, we prove that the RPU-optimal portfolio policy (in terms of the risk exposure ratio) is Gaussian and can be expressed in closed form, independent of wealth. Its variance is inversely proportional to risk aversion and stock volatility, while its mean is based on the solution to a partial differential equation. Moreover, the mean is the sum of a myopic term and an intertemporal hedging term (against market incompleteness) that intertwines with policy randomization. Finally, we carry out an asymptotic expansion in terms of the perturbed utility weight to show that the optimal mean policy deviates from the classical Merton policy at first order, while the associated relative wealth loss is of a higher order, quantifying the financial cost of the preference for randomization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.13544v1</guid>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min Dai, Yuchao Dong, Yanwei Jia, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Constrained Portfolio Optimization via Quantum Approximate Optimization Algorithm (QAOA) with XY-Mixers and Trotterized Initialization: A Hybrid Approach for Direct Indexing</title>
      <link>https://arxiv.org/abs/2602.14827</link>
      <description>arXiv:2602.14827v1 Announce Type: cross 
Abstract: Portfolio optimization under strict cardinality constraints is a combinatorial challenge that defies classical convex optimization techniques, particularly in the context of "Direct Indexing" and ESG-constrained mandates. In the Noisy Intermediate-Scale Quantum (NISQ) era, the Quantum Approximate Optimization Algorithm (QAOA) offers a promising hybrid approach. However, standard QAOA implementations utilizing transverse field mixers often fail to strictly enforce hard constraints, necessitating soft penalties that distort the energy landscape. This paper presents a comprehensive analysis of a constraint-preserving QAOA formulation against Simulated Annealing (SA) and Hierarchical Risk Parity (HRP). We implement a specific QAOA ansatz utilizing a Dicke state initialization and an XY-mixer Hamiltonian that strictly preserves the Hamming weight of the solution, ensuring only valid portfolios of size K are explored. Furthermore, we introduce a Trotterized parameter initialization schedule inspired by adiabatic quantum computing to mitigate the "Barren Plateau" problem. Backtesting on a basket of 10 US equities over 2025 reveals that our QAOA approach achieves a Sharpe Ratio of 1.81, significantly outperforming Simulated Annealing (1.31) and HRP (0.98). We further analyze the operational implications of the algorithm's high turnover (76.8%), discussing the trade-offs between theoretical optimality and implementation costs in institutional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.14827v1</guid>
      <category>quant-ph</category>
      <category>q-fin.CP</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Mancilla, Theodoros D. Bouloumis, Frederic Goguikian</dc:creator>
    </item>
    <item>
      <title>Data-Driven Merton's Strategies via Policy Randomization</title>
      <link>https://arxiv.org/abs/2312.11797</link>
      <description>arXiv:2312.11797v3 Announce Type: replace 
Abstract: We study Merton's expected utility maximization problem in an incomplete market, characterized by a factor process in addition to the stock price process, where all the model primitives are unknown. The agent under consideration is a price taker who has access only to the stock and factor value processes and the instantaneous volatility. We propose an auxiliary problem in which the agent can invoke policy randomization according to a specific class of Gaussian distributions, and prove that the mean of its optimal Gaussian policy solves the original Merton problem. With randomized policies, we are in the realm of continuous-time reinforcement learning (RL) recently developed in Wang et al. (2020) and Jia and Zhou (2022a, 2022b, 2023), enabling us to solve the auxiliary problem in a data-driven way without having to estimate the model primitives. Specifically, we establish a policy improvement theorem based on which we design both online and offline actor-critic RL algorithms for learning Merton's strategies. A key insight from this study is that RL in general and policy randomization in particular are useful beyond the purpose for exploration -- they can be employed as a technical tool to solve a problem that cannot be otherwise solved by mere deterministic policies. At last, we carry out both simulation and empirical studies in a stochastic volatility environment to demonstrate the decisive outperformance of the devised RL algorithms in comparison to the conventional model-based, plug-in method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11797v3</guid>
      <category>q-fin.PM</category>
      <category>cs.LG</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Min Dai, Yuchao Dong, Yanwei Jia, Xun Yu Zhou</dc:creator>
    </item>
    <item>
      <title>Two-fund separation under hyperbolically distributed returns and concave utility functions</title>
      <link>https://arxiv.org/abs/2410.04459</link>
      <description>arXiv:2410.04459v4 Announce Type: replace 
Abstract: Portfolio selection problems that optimize expected utility are usually difficult to solve. If the number of assets in the portfolio is large, such expected utility maximization problems become even harder to solve numerically. Therefore, analytical expressions for optimal portfolios are always preferred. In our work, we study portfolio optimization problems under the expected utility criterion for a wide range of utility functions, assuming return vectors follow hyperbolic distributions. Our main result demonstrates that under this setup, the two-fund monetary separation holds. Specifically, an individual with any utility function from this broad class will always choose to hold the same portfolio of risky assets, only adjusting the mix between this portfolio and a riskless asset based on their initial wealth and the specific utility function used for decision making. We provide explicit expressions for this mutual fund of risky assets. As a result, in our economic model, an individual's optimal portfolio is expressed in closed form as a linear combination of the riskless asset and the mutual fund of risky assets. Additionally, we discuss expected utility maximization problems under exponential utility functions over any domain of the portfolio set. In this part of our work, we show that the optimal portfolio in any given convex domain of the portfolio set either lies on the boundary of the domain or is the unique globally optimal portfolio within the entire domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04459v4</guid>
      <category>q-fin.PM</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nuerxiati Abudurexiti, Erhan Bayraktar, Takaki Hayashi, Hasanjan Sayit</dc:creator>
    </item>
    <item>
      <title>Multi-period Mean-Buffered Probability of Exceedance in Defined Contribution Portfolio Optimization</title>
      <link>https://arxiv.org/abs/2505.22121</link>
      <description>arXiv:2505.22121v3 Announce Type: replace 
Abstract: We investigate multi-period mean-risk portfolio optimization for long-horizon Defined Contribution plans, focusing on buffered Probability of Exceedance (bPoE), a more intuitive, dollar-based alternative to Conditional Value-at-Risk (CVaR). We formulate both pre-commitment and time-consistent Mean-bPoE and Mean-CVaR portfolio optimization problems under realistic investment constraints (e.g., no leverage, no short selling) and jump-diffusion dynamics. These formulations are naturally framed as bilevel optimization problems, with an outer search over the shortfall threshold and an inner optimization over rebalancing decisions. We establish an equivalence between the pre-commitment formulations through a one-to-one correspondence of their scalarization optimal sets, while showing that no such equivalence holds in the time-consistent setting. We develop provably convergent numerical schemes for the value functions associated with both pre-commitment and time-consistent formulations of these mean-risk control problems.
  Using nearly a century of market data, we find that time-consistent Mean-bPoE strategies closely resemble their pre-commitment counterparts. In particular, they maintain alignment with investors' preferences for a minimum acceptable terminal wealth level-unlike time-consistent Mean-CVaR, which often leads to counterintuitive control behavior. We further show that bPoE, as a strictly tail-oriented measure, prioritizes guarding against catastrophic shortfalls while allowing meaningful upside exposure, making it especially appealing for long-horizon wealth security. These findings highlight bPoE's practical advantages for Defined Contribution investment planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.22121v3</guid>
      <category>q-fin.PM</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Duy-Minh Dang, Chang Chen</dc:creator>
    </item>
    <item>
      <title>A post hoc test on the Sharpe ratio</title>
      <link>https://arxiv.org/abs/1911.04090</link>
      <description>arXiv:1911.04090v2 Announce Type: replace-cross 
Abstract: We describe a post hoc test for the Sharpe ratio, analogous to Tukey's test for pairwise equality of means. The test can be applied after rejection of the hypothesis that all population Signal-Noise ratios are equal. The test is applicable under a simple correlation structure among asset returns. Simulations indicate the test maintains nominal type I rate under a wide range of conditions and is moderately powerful under reasonable alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:1911.04090v2</guid>
      <category>stat.ME</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven Pav</dc:creator>
    </item>
    <item>
      <title>Market-Based Probability of Stock Returns</title>
      <link>https://arxiv.org/abs/2302.07935</link>
      <description>arXiv:2302.07935v5 Announce Type: replace-cross 
Abstract: This paper describes the dependence of market-based statistical moments of returns on statistical moments and correlations of the current and past trade values. We use Markowitz's definition of value weighted return of a portfolio as the definition of market-based average return of trades during the averaging period. Then we derive the dependence of market-based volatility and higher statistical moments of returns on statistical moments, volatilities, and correlations of the current and past trade values. We derive the approximations of the characteristic function and the probability of returns by a finite number q of market-based statistical moments. To forecast market-based average and volatility of returns at horizon T, one should predict the first two statistical moments and correlation of current and past trade values at the same horizon. We discuss the economic reasons that limit the number of predicted statistical moments of returns by the first two. That limits the accuracy of the forecasts of probability of returns by the accuracy of the Gaussian approximations. To improve the reliability of large macroeconomic and market models like BlackRock's Aladdin, JP Morgan, and the U.S. Fed., the developers should use market-based statistical moments of returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07935v5</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>q-fin.GN</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 17 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Victor Olkhov</dc:creator>
    </item>
  </channel>
</rss>
