<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 01:25:58 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>State-based approach to the numerical solution of Dirichlet boundary optimal control problems for the Laplace equation</title>
      <link>https://arxiv.org/abs/2507.11646</link>
      <description>arXiv:2507.11646v1 Announce Type: new 
Abstract: We investigate the Dirichlet boundary control of the Laplace equation, considering the control in $H^{1/2}(\partial \Omega)$, which is the natural space for Dirichlet data when the state belongs to $H^1(\Omega)$. The cost of the control is measured in the $H^{1/2}(\partial \Omega)$ norm that also plays the role of the regularization term. We discuss regularization and finite element error estimates enabling us to derive an optimal relation between the finite element mesh size $h$ and the regularization parameter $\varrho$, balancing the energy cost for the control and the accuracy of the approximation of the desired state. This relationship is also crucial in designing efficient solvers. We also discuss additional box constraints imposed on the control and the state. Our theoretical findings are complemented by numerical examples, including one example with box constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11646v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulrich Langer, Richard L\"oscher, Olaf Steinbach, Huidong Yang</dc:creator>
    </item>
    <item>
      <title>Discontinuous Galerkin approximation for a Stokes-Brinkman-type formulation for the eigenvalue problem in porous media</title>
      <link>https://arxiv.org/abs/2507.11695</link>
      <description>arXiv:2507.11695v1 Announce Type: new 
Abstract: We introduce a family of discontinuous Galerkin methods to approximate the eigenvalues and eigenfunctions of a Stokes-Brinkman type of problem based in the interior penalty strategy. Under the standard assumptions on the meshes and a suitable norm, we prove the stability of the discrete scheme. Due to the non-conforming nature of the method, we use the well-known non-compact operators theory to derive convergence and error estimates for the method. We present an exhaustive computational analysis where we compute the spectrum with different stabilization parameters with the aim of study its influence when the spectrum is approximated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11695v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Lepe, Gonzalo Rivera, Jesus Vellojin</dc:creator>
    </item>
    <item>
      <title>Norm-Stabilized Imaginary-Time Evolution via Feedback Control</title>
      <link>https://arxiv.org/abs/2507.11700</link>
      <description>arXiv:2507.11700v1 Announce Type: new 
Abstract: We present a norm-stabilized imaginary-time evolution (ITE) scheme for the one-dimensional nonlinear Schrodinger equation (NLSE). Traditional ITE solvers often require explicit renormalization of the wavefunction after each step to preserve norm, which can be disruptive and algorithmically inflexible. We propose an alternative approach in which the evolution is continuously stabilized using an adaptive feedback term mu(tau), proportional to the time derivative of the wavefunction norm. This results in a self-regulating flow that requires no external normalization while preserving convergence toward soliton solutions. We demonstrate the method's effectiveness by comparing the final wavefunction profiles and L2 errors against analytical solutions and baseline methods without feedback. Although this work focuses on the 1D case, the framework is designed to extend naturally to higher dimensions. Future work will explore the behavior of the feedback mechanism in 2D and 3D systems, multi-soliton scenarios, and external potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11700v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>nlin.PS</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stylianos Savva</dc:creator>
    </item>
    <item>
      <title>Acceleration methods for fixed point iterations</title>
      <link>https://arxiv.org/abs/2507.11746</link>
      <description>arXiv:2507.11746v1 Announce Type: new 
Abstract: A pervasive approach in scientific computing is to express the solution to a given problem as the limit of a sequence of vectors or other mathematical objects. In many situations these sequences are generated by slowly converging iterative procedures and this led practitioners to seek faster alternatives to reach the limit. ``Acceleration techniques'' comprise a broad array of methods specifically designed with this goal in mind. They started as a means of improving the convergence of general scalar sequences by various forms of ``extrapolation to the limit'', i.e., by extrapolating the most recent iterates to the limit via linear combinations. Extrapolation methods of this type, the best known example of which is Aitken's Delta-squared process, require only the sequence of vectors as input. However, limiting methods to only use the iterates is too restrictive. Accelerating sequences generated by fixed-point iterations by utilizing both the iterates and the fixed-point mapping itself has proven highly successful across various areas of physics. A notable example of these Fixed-Point accelerators (FP-Accelerators) is a method developed by D. Anderson in 1965 and now widely known as Anderson Acceleration (AA). Furthermore, Quasi-Newton and Inexact Newton methods can also be placed in this category as well. This paper presents an overview of these methods -- with an emphasis on those, such as AA, that are geared toward accelerating fixed point iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11746v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:journal_reference>Acta Numerica, vol 34 (2024), pp. 805-890</arxiv:journal_reference>
      <dc:creator>Yousef Saad</dc:creator>
    </item>
    <item>
      <title>A quasi-interpolation operator yielding fully computable error bounds</title>
      <link>https://arxiv.org/abs/2507.11819</link>
      <description>arXiv:2507.11819v1 Announce Type: new 
Abstract: We design a quasi-interpolation operator from the Sobolev space $H^1_0(\Omega)$ to its finite-dimensional finite element subspace formed by piecewise polynomials on a simplicial mesh with a computable approximation constant. The operator 1) is defined on the entire $H^1_0(\Omega)$, no additional regularity is needed; 2) allows for an arbitrary polynomial degree; 3) works in any space dimension; 4) is defined locally, in vertex patches of mesh elements; 5) yields optimal estimates for both the $H^1$ seminorm and the $L^2$ norm error; 6) gives a computable constant for both the $H^1$ seminorm and the $L^2$ norm error; 7) leads to the equivalence of global-best and local-best errors; 8) possesses the projection property. Its construction follows the so-called potential reconstruction from a posteriori error analysis. Numerical experiments illustrate that our quasi-interpolation operator systematically gives the correct convergence rates in both the $H^1$ seminorm and the $L^2$ norm and its certified overestimation factor is rather sharp and stable in all tested situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11819v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Chaumont-Frelet, M. Vohralik</dc:creator>
    </item>
    <item>
      <title>Analysis of a fast fully discrete finite element method for fractional viscoelastic wave propagation</title>
      <link>https://arxiv.org/abs/2507.11822</link>
      <description>arXiv:2507.11822v1 Announce Type: new 
Abstract: This paper is devoted to a numerical analysis of a fractional viscoelastic wave propagation model that generalizes the fractional Maxwell model and the fractional Zener model. First, we convert the model problem into a velocity type integro-differential equation and establish existence, uniqueness and regularity of its solution. Then we consider a conforming linear/bilinear/trilinear finite element semi-discrete scheme and a fast scheme of backward Euler full discretization with a sum-of-exponentials (SOE) approximation for the convolution integral, and derive error estimates for the semi-discrete and fully discrete schemes. Finally, we provide several numerical examples to verify the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11822v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hao Yuan, Xiaoping Xie</dc:creator>
    </item>
    <item>
      <title>Automatic reproducing kernel and regularization for learning convolution kernels</title>
      <link>https://arxiv.org/abs/2507.11944</link>
      <description>arXiv:2507.11944v1 Announce Type: new 
Abstract: Learning convolution kernels in operators from data arises in numerous applications and represents an ill-posed inverse problem of broad interest. With scant prior information, kernel methods offer a natural nonparametric approach with regularization. However, a major challenge is to select a proper reproducing kernel, especially as operators and data vary. We show that the input data and convolution operator themselves induce an automatic, data-adaptive RKHS (DA-RKHS), obviating manual kernel selection. In particular, when the observation data is discrete and finite, there is a finite set of automatic basis functions sufficient to represent the estimators in the DA-RKHS, including the minimal-norm least-squares, Tikhonov, and conjugate-gradient estimators. We develop both Tikhonov and scalable iterative and hybrid algorithms using the automatic basis functions. Numerical experiments on integral, nonlocal, and aggregation operators confirm that our automatic RKHS regularization consistently outperforms standard ridge regression and Gaussian process methods with preselected kernels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11944v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haibo Li, Fei Lu</dc:creator>
    </item>
    <item>
      <title>Structured First-Layer Initialization Pre-Training Techniques to Accelerate Training Process Based on $\varepsilon$-Rank</title>
      <link>https://arxiv.org/abs/2507.11962</link>
      <description>arXiv:2507.11962v1 Announce Type: new 
Abstract: Training deep neural networks for scientific computing remains computationally expensive due to the slow formation of diverse feature representations in early training stages. Recent studies identify a staircase phenomenon in training dynamics, where loss decreases are closely correlated with increases in $\varepsilon$-rank, reflecting the effective number of linearly independent neuron functions. Motivated by this observation, this work proposes a structured first-layer initialization (SFLI) pre-training method to enhance the diversity of neural features at initialization by constructing $\varepsilon$-linearly independent neurons in the input layer. We present systematic initialization schemes compatible with various activation functions and integrate the strategy into multiple neural architectures, including modified multi-layer perceptrons and physics-informed residual adaptive networks. Extensive numerical experiments on function approximation and PDE benchmarks, demonstrate that SFLI significantly improves the initial $\varepsilon$-rank, accelerates convergence, mitigates spectral bias, and enhances prediction accuracy. With the help of SILP, we only need to add one line of code to conventional existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11962v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Tang, Jiang Yang, Yuxiang Zhao, Quanhui Zhu</dc:creator>
    </item>
    <item>
      <title>The Arrow-Hurwicz iteration for virtual element discretizations of the incompressible Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2507.12036</link>
      <description>arXiv:2507.12036v1 Announce Type: new 
Abstract: This article presents a detailed analysis of the Arrow-Hurwicz iteration applied to the solution of the incompressible Navier-Stokes equations, discretized by a divergence-free mixed virtual element method. Under a set of appropriate assumptions, it is rigorously demonstrated that the method exhibits geometric convergence, with a contraction factor that remains independent of the mesh sizes. A series of numerical experiments are conducted to validate the theoretical findings and to assess the computational performance of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12036v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binbin Du, Shenxiang Cheng, Yue Yu, Chuanjun Chen</dc:creator>
    </item>
    <item>
      <title>A Hybrid High-Order method for the power-law Brinkman problem robust in all regimes</title>
      <link>https://arxiv.org/abs/2507.12140</link>
      <description>arXiv:2507.12140v1 Announce Type: new 
Abstract: In this work we propose and analyze a new Hybrid High-Order method for the Brinkman problem for fluids with power-law viscosity. The proposed method supports general meshes and arbitrary approximation orders and is robust in all regimes, from pure (power-law) Stokes to pure Darcy. Robustness is reflected by error estimates that distinguish the contributions from Stokes- and Darcy-dominated elements as identified by an appropriate dimensionless number, and that additionally account for pre-asymptotic orders of convergence. Theoretical results are illustrated by a complete panel of numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12140v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Casta\~n\'on Quiroz, Daniele A. Di Pietro, J\'er\^ome Droniou, Marwa Salah</dc:creator>
    </item>
    <item>
      <title>Optimal Spectral Approximation in the Overlaps for Generalized Finite Element Methods</title>
      <link>https://arxiv.org/abs/2507.12226</link>
      <description>arXiv:2507.12226v1 Announce Type: new 
Abstract: In this paper, we study a generalized finite element method for solving second-order elliptic partial differential equations with rough coefficients. The method uses local approximation spaces computed by solving eigenvalue problems on rings around the boundary of local subdomains. Compared to the corresponding method that solves eigenvalue problems on the whole subdomains, the problem size and the bandwidth of the resulting system matrices are substantially reduced, resulting in faster spectral computations. We prove a nearly exponential a priori decay result for the local approximation errors of the proposed method, which implies the nearly exponential decay of the overall approximation error of the method. The proposed method can also be used as a preconditioner, and only a slight adaptation of our theory is necessary to prove the optimal convergence of the preconditioned iteration. Numerical experiments are presented to support the effectiveness of the proposed method and to investigate its coefficient robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12226v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Christian Alber, Peter Bastian, Moritz Hauck, Robert Scheichl</dc:creator>
    </item>
    <item>
      <title>The iterated Golub-Kahan-Tikhonov method</title>
      <link>https://arxiv.org/abs/2507.12307</link>
      <description>arXiv:2507.12307v1 Announce Type: new 
Abstract: The Golub-Kahan-Tikhonov method is a popular solution technique for large linear discrete ill-posed problems. This method first applies partial Golub-Kahan bidiagonalization to reduce the size of the given problem and then uses Tikhonov regularization to compute a meaningful approximate solution of the reduced problem. It is well known that iterated variants of this method often yield approximate solutions of higher quality than the standard non-iterated method. Moreover, it produces more accurate computed solutions than the Arnoldi method when the matrix that defines the linear discrete ill-posed problem is far from symmetric.
  This paper starts with an ill-posed operator equation in infinite-dimensional Hilbert space, discretizes the equation, and then applies the iterated Golub-Kahan-Tikhonov method to the solution of the latter problem. An error analysis that addresses all discretization and approximation errors is provided. Additionally, a new approach for choosing the regularization parameter is described. This solution scheme produces more accurate approximate solutions than the standard (non-iterated) Golub-Kahan-Tikhonov method and the iterated Arnoldi-Tikhonov method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12307v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Bianchi, Marco Donatelli, Davide Furch\`i, Lothar Reichel</dc:creator>
    </item>
    <item>
      <title>A bound-preserving and conservative enriched Galerkin method for elliptic problems</title>
      <link>https://arxiv.org/abs/2507.12338</link>
      <description>arXiv:2507.12338v1 Announce Type: new 
Abstract: We propose a locally conservative enriched Galerkin scheme that respects the discrete maximum principle of an elliptic problem. To this end, we use a substantial over-penalization of the discrete solution's jumps to obtain optimal convergence. To avoid the ill-conditioning issues that arise in over-penalized schemes, we introduce an involved splitting approach that separates the system of equations for the discontinuous solution part from the system of equations for the continuous solution part, yielding well-behaved subproblems. We prove the existence of discrete solutions and optimal error estimates, which are validated numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12338v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriel R. Barrenechea, Philip L. Lederer, Andreas Rupp</dc:creator>
    </item>
    <item>
      <title>Refinement of the theory and convergence of the Sinc convolution</title>
      <link>https://arxiv.org/abs/2507.12406</link>
      <description>arXiv:2507.12406v1 Announce Type: new 
Abstract: The Sinc convolution is an approximate formula for indefinite convolutions proposed by F. Stenger. The formula was derived based on the Sinc indefinite integration formula combined with the single-exponential transformation. Although its efficiency has been confirmed in variety of areas, there remain some open problems in its theory. The first contribution of this study is to resolve those problems by refinement of the theory of the Sinc convolution. This contribution includes a partial resolution of Stenger's conjecture. The second contribution of this study is to improve the convergence rate by replacement of the single-exponential transformation with the double-exponential transformation. In both theoretical and numerical ways, this study also shows that the convergence rate of the new formula is improved compared to Stenger's formula.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12406v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoaki Okayama</dc:creator>
    </item>
    <item>
      <title>Approaching Optimality for Solving Dense Linear Systems with Low-Rank Structure</title>
      <link>https://arxiv.org/abs/2507.11724</link>
      <description>arXiv:2507.11724v1 Announce Type: cross 
Abstract: We provide new high-accuracy randomized algorithms for solving linear systems and regression problems that are well-conditioned except for $k$ large singular values. For solving such $d \times d$ positive definite system our algorithms succeed whp. and run in time $\tilde O(d^2 + k^\omega)$. For solving such regression problems in a matrix $\mathbf{A} \in \mathbb{R}^{n \times d}$ our methods succeed whp. and run in time $\tilde O(\mathrm{nnz}(\mathbf{A}) + d^2 + k^\omega)$ where $\omega$ is the matrix multiplication exponent and $\mathrm{nnz}(\mathbf{A})$ is the number of non-zeros in $\mathbf{A}$. Our methods nearly-match a natural complexity limit under dense inputs for these problems and improve upon a trade-off in prior approaches that obtain running times of either $\tilde O(d^{2.065}+k^\omega)$ or $\tilde O(d^2 + dk^{\omega-1})$ for $d\times d$ systems. Moreover, we show how to obtain these running times even under the weaker assumption that all but $k$ of the singular values have a suitably bounded generalized mean. Consequently, we give the first nearly-linear time algorithm for computing a multiplicative approximation to the nuclear norm of an arbitrary dense matrix. Our algorithms are built on three general recursive preconditioning frameworks, where matrix sketching and low-rank update formulas are carefully tailored to the problems' structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11724v1</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micha{\l} Derezi\'nski, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>An augmented Lagrangian method for strongly regular minimizers in a class of convex composite optimization problems</title>
      <link>https://arxiv.org/abs/2507.12040</link>
      <description>arXiv:2507.12040v1 Announce Type: cross 
Abstract: In this paper, we study a class of convex composite optimization problems. We begin by characterizing the equivalence between the primal/dual strong second-order sufficient condition and the dual/primal nondegeneracy condition. Building on this foundation, we derive a specific set of equivalent conditions for the perturbation analysis of the problem. Furthermore, we employ the augmented Lagrangian method (ALM) to solve the problem and provide theoretical guarantees for its performance. Specifically, we establish the equivalence between the primal/dual second-order sufficient condition and the dual/primal strict Robinson constraint qualification, as well as the equivalence between the dual nondegeneracy condition and the nonsingularity of Clarke's generalized Jacobian for the ALM subproblem. These theoretical results form a solid foundation for designing efficient algorithms. Finally, we apply the ALM to the von Neumann entropy optimization problem and present numerical experiments to demonstrate the algorithm's effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12040v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chengjing Wang, Peipei Tang</dc:creator>
    </item>
    <item>
      <title>RiemannLoRA: A Unified Riemannian Framework for Ambiguity-Free LoRA Optimization</title>
      <link>https://arxiv.org/abs/2507.12142</link>
      <description>arXiv:2507.12142v1 Announce Type: cross 
Abstract: Low-Rank Adaptation (LoRA) has become a widely adopted standard for parameter-efficient fine-tuning of large language models (LLMs), significantly reducing memory and computational demands. However, challenges remain, including finding optimal initialization strategies or mitigating overparametrization in low-rank matrix factorization. In this work, we propose a novel approach that addresses both of the challenges simultaneously within a unified framework. Our method treats a set of fixed-rank LoRA matrices as a smooth manifold. Considering adapters as elements on this manifold removes overparametrization, while determining the direction of the fastest loss decrease along the manifold provides initialization. Special care is taken to obtain numerically stable and computationally efficient implementation of our method, using best practices from numerical linear algebra and Riemannian optimization. Experimental results on LLM and diffusion model architectures demonstrate that RiemannLoRA consistently improves both convergence speed and final performance over standard LoRA and its state-of-the-art modifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12142v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Bogachev, Vladimir Aletov, Alexander Molozhavenko, Denis Bobkov, Vera Soboleva, Aibek Alanov, Maxim Rakhuba</dc:creator>
    </item>
    <item>
      <title>Linearization-Based Feedback Stabilization of McKean-Vlasov PDEs</title>
      <link>https://arxiv.org/abs/2507.12411</link>
      <description>arXiv:2507.12411v1 Announce Type: cross 
Abstract: We study the feedback stabilization of the McKean-Vlasov PDE on the torus. Our goal is to steer the dynamics toward a prescribed stationary distribution or accelerate convergence to it using a time-dependent control potential. We reformulate the controlled PDE in a weighted-projected space and apply the ground-state transform to obtain a Schrodinger-type operator. The resulting operator framework enables spectral analysis, verification of the infinite-dimensional Hautus test, and the construction of Riccati-based feedback laws. We rigorously prove local exponential stabilization via maximal regularity arguments and nonlinear estimates. Numerical experiments on well-studied models (the noisy Kuramoto model for synchronization, the O(2) spin model in a magnetic field, and the Gaussian/von Mises attractive interaction potential) showcase the effectiveness of our control strategy, demonstrating convergence speed-ups and stabilization of otherwise unstable equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12411v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Kalise, Lucas M. Moschen, Grigorios A. Pavliotis</dc:creator>
    </item>
    <item>
      <title>Fast adaptive high-order integral equation methods for electromagnetic scattering from smooth perfect electric conductors</title>
      <link>https://arxiv.org/abs/2306.04473</link>
      <description>arXiv:2306.04473v2 Announce Type: replace 
Abstract: Many integral equation-based methods are available for problems of time-harmonic electromagnetic scattering from perfect electric conductors. Among the many challenges that arise in such calculations are the avoidance of spurious resonances, robustness of the method to scatterers of non-trivial topology or multiscale features, stability under mesh refinement, ease of implementation with high-order basis functions, and behavior in the static limit. Since three-dimensional scattering is a challenging, large-scale problem, many of these issues have been historically difficult to investigate. It is only with the advent of fast algorithms for matrix-vector multiplies coupled with modern iterative methods that a careful study of these issues can be carried out effectively. Our focus here is on comparing the behavior of several integral equation formulations with regard to the issues noted above, namely: the well-known, standard electric, magnetic, and combined field integral equations with standard RWG basis functions, and the more modern non-resonant charge-current and decoupled potential integral equation. Numerical results are provided to demonstrate the behavior of each of these schemes. Furthermore, we provide some analytical properties and comparisons with the electric charge-current integral equation and the augmented regularized combined source integral equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04473v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Vico, Leslie Greengard, Michael O'Neil, Manas Rachh</dc:creator>
    </item>
    <item>
      <title>A posteriori error estimates for the Generalized Burgers-Huxley equation with weakly singular kernels</title>
      <link>https://arxiv.org/abs/2403.08269</link>
      <description>arXiv:2403.08269v2 Announce Type: replace 
Abstract: This paper explores the residual based a posteriori error estimations for the generalized Burgers-Huxley equation (GBHE) featuring weakly singular kernels. Initially, we present a reliable and efficient error estimator for both the stationary GBHE and the semi-discrete GBHE with memory, utilizing the discontinuous Galerkin finite element method (DGFEM) in spatial dimensions. Additionally, employing backward Euler and Crank Nicolson discretization in the temporal domain and DGFEM in spatial dimensions, we introduce an estimator for the fully discrete GBHE, taking into account the influence of past history. The paper also establishes optimal $L^2$ error estimates for both the stationary GBHE and GBHE. Ultimately, we validate the effectiveness of the proposed error estimator through numerical results, demonstrating its efficacy in an adaptive refinement strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08269v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumit Mahajan, Arbaz Khan</dc:creator>
    </item>
    <item>
      <title>A linearly-implicit energy-momentum preserving scheme for geometrically nonlinear mechanics based on non-canonical Hamiltonian formulations</title>
      <link>https://arxiv.org/abs/2503.04695</link>
      <description>arXiv:2503.04695v3 Announce Type: replace 
Abstract: This work presents a novel formulation and numerical strategy for the simulation of geometrically nonlinear structures. First, a non-canonical Hamiltonian (Poisson) formulation is introduced by including the dynamics of the stress tensor. This framework is developed for von-K\'arm\'an nonlinearities in beams and plates, as well as geometrically nonlinear elasticity with Saint-Venant material behavior. In the case of plates, both negligible and non-negligible membrane inertia are considered. For the former case the two-dimensional elasticity complex is leveraged to express the dynamics in terms of the Airy stress function. The finite element discretization employs a mixed approach, combining a conforming approximation for displacement and velocity fields with a discontinuous stress tensor representation. A staggered, linear implicit time integration scheme is proposed, establishing connections with existing explicit-implicit energy-preserving methods. The stress degrees of freedom are statically condensed, reducing the computational complexity to solving a system with a positive definite matrix. The integration strategy preserves energy and angular momentum exactly. The methodology is validated through numerical experiments on the Duffing oscillator, a von-K\'arm\'an beam, and a column undergoing finite deformations. Comparisons with fully implicit energy-preserving method and the leapfrog scheme demonstrate that the proposed approach achieves superior accuracy while maintaining energy stability. Additionally, it enables larger time steps compared to explicit schemes and exhibits computational efficiency comparable to the leapfrog method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.04695v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11071-025-11601-6</arxiv:DOI>
      <arxiv:journal_reference>Nonlinear Dynamics, 2025</arxiv:journal_reference>
      <dc:creator>Andrea Brugnoli, Denis Matignon, Joseph Morlier</dc:creator>
    </item>
    <item>
      <title>Mathematical Introduction to Deep Learning: Methods, Implementations, and Theory</title>
      <link>https://arxiv.org/abs/2310.20360</link>
      <description>arXiv:2310.20360v3 Announce Type: replace-cross 
Abstract: This book aims to provide an introduction to the topic of deep learning algorithms. We review essential components of deep learning algorithms in full mathematical detail including different artificial neural network (ANN) architectures (such as fully-connected feedforward ANNs, convolutional ANNs, recurrent ANNs, residual ANNs, and ANNs with batch normalization) and different optimization algorithms (such as the basic stochastic gradient descent (SGD) method, accelerated methods, and adaptive methods). We also cover several theoretical aspects of deep learning algorithms such as approximation capacities of ANNs (including a calculus for ANNs), optimization theory (including Kurdyka-{\L}ojasiewicz inequalities), and generalization errors. In the last part of the book some deep learning approximation methods for PDEs are reviewed including physics-informed neural networks (PINNs) and deep Galerkin methods. We hope that this book will be useful for students and scientists who do not yet have any background in deep learning at all and would like to gain a solid foundation as well as for practitioners who would like to obtain a firmer mathematical understanding of the objects and methods considered in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.20360v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnulf Jentzen, Benno Kuckuck, Philippe von Wurstemberger</dc:creator>
    </item>
    <item>
      <title>BiLO: Bilevel Local Operator Learning for PDE Inverse Problems. Part I: PDE-Constrained Optimization</title>
      <link>https://arxiv.org/abs/2404.17789</link>
      <description>arXiv:2404.17789v5 Announce Type: replace-cross 
Abstract: We propose a new neural network based method for solving inverse problems for partial differential equations (PDEs) by formulating the PDE inverse problem as a bilevel optimization problem. At the upper level, we minimize the data loss with respect to the PDE parameters. At the lower level, we train a neural network to locally approximate the PDE solution operator in the neighborhood of a given set of PDE parameters, which enables an accurate approximation of the descent direction for the upper level optimization problem. The lower level loss function includes the L2 norms of both the residual and its derivative with respect to the PDE parameters. We apply gradient descent simultaneously on both the upper and lower level optimization problems, leading to an effective and fast algorithm. The method, which we refer to as BiLO (Bilevel Local Operator learning), is also able to efficiently infer unknown functions in the PDEs through the introduction of an auxiliary variable. We provide a theoretical analysis that justifies our approach. Through extensive experiments over multiple PDE systems, we demonstrate that our method enforces strong PDE constraints, is robust to sparse and noisy data, and eliminates the need to balance the residual and the data loss, which is inherent to the soft PDE constraints in many existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17789v5</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ray Zirui Zhang, Christopher E. Miles, Xiaohui Xie, John S. Lowengrub</dc:creator>
    </item>
    <item>
      <title>Structured and Balanced Multi-Component and Multi-Layer Neural Networks</title>
      <link>https://arxiv.org/abs/2407.00765</link>
      <description>arXiv:2407.00765v3 Announce Type: replace-cross 
Abstract: In this work, we propose a balanced multi-component and multi-layer neural network (MMNN) structure to accurately and efficiently approximate functions with complex features, in terms of both degrees of freedom and computational cost. The main idea is inspired by a multi-component approach, in which each component can be effectively approximated by a single-layer network, combined with a multi-layer decomposition strategy to capture the complexity of the target function. Although MMNNs can be viewed as a simple modification of fully connected neural networks (FCNNs) or multi-layer perceptrons (MLPs) by introducing balanced multi-component structures, they achieve a significant reduction in training parameters, a much more efficient training process, and improved accuracy compared to FCNNs or MLPs. Extensive numerical experiments demonstrate the effectiveness of MMNNs in approximating highly oscillatory functions and their ability to automatically adapt to localized features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.00765v3</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shijun Zhang, Hongkai Zhao, Yimin Zhong, Haomin Zhou</dc:creator>
    </item>
    <item>
      <title>Moving-Boundary Port-Hamiltonian Systems</title>
      <link>https://arxiv.org/abs/2501.14930</link>
      <description>arXiv:2501.14930v2 Announce Type: replace-cross 
Abstract: In this paper, we consider linear boundary port-Hamiltonian distributed parameter systems on a time-varying spatial domain. We derive the specific time-varying Dirac structure that these systems give rise to and use it to formally establish a new class of moving-boundary port-Hamiltonian systems by showing that these distributed parameter systems on a time-varying spatial domain admit a port-Hamiltonian representation. We demonstrate that our results can be leveraged to develop a spatial discretization scheme with dynamic meshing for approximating the telegrapher's equations on a time-varying spatial domain, which we subsequently verify numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14930v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>T. J. Meijer, A. Das, S. Weiland</dc:creator>
    </item>
    <item>
      <title>Kolmogorov-Arnold Networks: Approximation and Learning Guarantees for Functions and their Derivatives</title>
      <link>https://arxiv.org/abs/2504.15110</link>
      <description>arXiv:2504.15110v2 Announce Type: replace-cross 
Abstract: Inspired by the Kolmogorov-Arnold superposition theorem, Kolmogorov-Arnold Networks (KANs) have recently emerged as an improved backbone for most deep learning frameworks, promising more adaptivity than their multilayer perception (MLP) predecessor by allowing for trainable spline-based activation functions. In this paper, we probe the theoretical foundations of the KAN architecture by showing that it can optimally approximate any Besov function in $B^{s}_{p,q}(\mathcal{X})$ on a bounded open, or even fractal, domain $\mathcal{X}$ in $\mathbb{R}^d$ at the optimal approximation rate with respect to any weaker Besov norm $B^{\alpha}_{p,q}(\mathcal{X})$; where $\alpha &lt; s$. We complement our approximation guarantee with a dimension-free estimate on the sample complexity of a residual KAN model when learning a function of Besov regularity from $N$ i.i.d. noiseless samples. Our KAN architecture incorporates contemporary deep learning wisdom by leveraging residual/skip connections between layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15110v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>cs.NE</category>
      <category>math.FA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anastasis Kratsios, Bum Jun Kim, Takashi Furuya</dc:creator>
    </item>
    <item>
      <title>Magneto-radiative modelling and artificial neural network optimization of biofluid flow in a stenosed arterial domain</title>
      <link>https://arxiv.org/abs/2507.06273</link>
      <description>arXiv:2507.06273v2 Announce Type: replace-cross 
Abstract: The increasing complexity of cardiovascular diseases and limitations in traditional healing methods mandate the invention of new drug delivery systems that assure targeted, effective, and regulated treatments, contributing directly to UN SDGs 3 and 9, thereby encouraging the utilization of sustainable medical technologies in healthcare. This study investigates the flow of a Casson-Maxwell nanofluid through a stenosed arterial domain. The quantities, such as skin friction and heat transfer rate, are analysed in detail. The Casson-Maxwell fluid shows a lower velocity profile than the Casson fluids, which indicates the improved residence time for efficient drug delivery. The heat transfer rate shows an increase with higher volume fractions of copper and aluminium oxide nanoparticles and a decrease with higher volume fractions of silver nanoparticles. The skin friction coefficient decreases by 219% with a unit increase in the Maxwell parameter, whereas it increases by 66.1% with a unit rise in the Casson parameter. This work supports SDGs 4 and 17 by fostering interdisciplinary learning and collaboration in fluid dynamics and healthcare innovation. Additionally, the rate of heat flow was forecasted (with an overall R-value of 0.99457) using the Levenberg-Marquardt backpropagation training scheme under the influence of magneto-radiative, linear heat source and Casson-Maxwell parameters along with the tri-metallic nanoparticle volume fractions. It is also observed that the drag coefficient is most sensitive to the changes in the Maxwell parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06273v2</guid>
      <category>physics.med-ph</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.bio-ph</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S P Shivakumar, Gunisetty Ramasekhar, P Nimmy, Sujesh Areekara, L Thanuja, T V Smitha, S Devanathan, Ganesh R Naik, K V Nagaraja</dc:creator>
    </item>
  </channel>
</rss>
