<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Deep Learning Accelerated Algebraic Multigrid Methods for Polytopal Discretizations of Second-Order Differential Problems</title>
      <link>https://arxiv.org/abs/2510.01442</link>
      <description>arXiv:2510.01442v1 Announce Type: new 
Abstract: Algebraic Multigrid (AMG) methods are state-of-the-art algebraic solvers for partial differential equations. Still, their efficiency depends heavily on the choice of suitable parameters and/or ingredients. Paradigmatic examples include the so-called strong threshold parameter $\theta$, which controls the algebraic coarse-grid hierarchy, as well as the smoother, i.e., the relaxation methods used on the fine grid to damp out high-frequency errors. In AMG, since the coarse grids are constructed algebraically (without geometric intuition), the smoother's performance is even more critical. For the linear systems stemming from polytopal discretizations, such as Polytopal Discontinuous Galerkin (PolyDG) and Virtual Element Methods (VEM), AMG sensitivity to such choices is even more critical due to the significant variability of the underlying meshes, which results in algebraic systems with different sparsity patterns. We propose a novel deep learning approach that automatically tunes the strong threshold parameter, as well as the smoother choice in AMG solvers, for linear systems of equations arising from polytopal discretizations, thereby maximizing AMG performance. We interpret the sparse matrix resulting from polytopal discretization as a grayscale image, and by applying pooling, our neural network extracts compact features that preserve the necessary information at a low computational cost. We test various differential problems in both two- and three-dimensional settings, with heterogeneous coefficients and polygonal/polyhedral meshes, and demonstrate that the proposed approach generalizes well. In practice, we demonstrate that we can reduce AMG solver time by up to $27\%$ with minimal changes to existing PolyDG and VEM codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01442v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paola F. Antonietti, Matteo Caldana, Lorenzo Gentile, Marco Verani</dc:creator>
    </item>
    <item>
      <title>Data selection: at the interface of PDE-based inverse problem and randomized linear algebra</title>
      <link>https://arxiv.org/abs/2510.01567</link>
      <description>arXiv:2510.01567v1 Announce Type: new 
Abstract: All inverse problems rely on data to recover unknown parameters, yet not all data are equally informative. This raises the central question of data selection. A distinctive challenge in PDE-based inverse problems is their inherently infinite-dimensional nature: both the parameter space and the design space are infinite, which greatly complicates the selection process. Somewhat unexpectedly, randomized numerical linear algebra (RNLA), originally developed in very different contexts, has provided powerful tools for addressing this challenge. These methods are inherently probabilistic, with guarantees typically stating that information is preserved with probability at least 1-p when using N randomly selected, weighted samples. Here, the notion of information can take different mathematical forms depending on the setting. In this review, we survey the problem of data selection in PDE-based inverse problems, emphasize its unique infinite-dimensional aspects, and highlight how RNLA strategies have been adapted and applied in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01567v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kathrin Hellmuth, Ruhui Jin, Qin Li, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Instability of the Sherman-Morrison formula and stabilization by iterative refinement</title>
      <link>https://arxiv.org/abs/2510.01696</link>
      <description>arXiv:2510.01696v1 Announce Type: new 
Abstract: Owing to its simplicity and efficiency, the Sherman-Morrison (SM) formula has seen widespread use across various scientific and engineering applications for solving rank-one perturbed linear systems of the form $(A+uv^T)x = b$. Although the formula dates back at least to 1944, its numerical stability properties have remained an open question and continue to be a topic of current research. We analyze the backward stability of the SM, demonstrate its instability in a scenario increasingly common in scientific computing and address an open question posed by Nick Higham on the proportionality of the backward error bound to the condition number of $A$. We then incorporate fixed-precision iterative refinement into the SM framework reusing the previously computed decompositions and prove that, under reasonable assumptions, it achieves backward stability without sacrificing the efficiency of the SM formula. While our theory does not prove the SM formula with iterative refinement always outputs a backward stable solution, empirically it is observed to eventually produce a backward stable solution in all our numerical experiments. We conjecture that with iterative refinement, the SM formula yields a backward stable solution provided that $\kappa_2(A), \kappa_2(A+uv^T)$ are both bounded safely away from $\epsilon_M^{-1}$, where $\epsilon_M$ is the unit roundoff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01696v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Behnam Hashemi, Yuji Nakatsukasa</dc:creator>
    </item>
    <item>
      <title>Efficient manifold evolution algorithm using adaptive B-Spline interpolation</title>
      <link>https://arxiv.org/abs/2510.01790</link>
      <description>arXiv:2510.01790v1 Announce Type: new 
Abstract: This paper explores an efficient Lagrangian approach for evolving point cloud data on smooth manifolds. In this preliminary study, we focus on analyzing plane curves, and our ultimate goal is to provide an alternative to the conventional radial basis function (RBF) approach for manifolds in higher dimensions. In particular, we use the B-Spline as the basis function for all local interpolations. Just like RBF and other smooth basis functions, B-Splines enable the approximation of geometric features such as normal vectors and curvature. Once properly set up, the advantage of using B-Splines is that their coefficients carry geometric meanings. This allows the coefficients to be manipulated like points, facilitates rapid updates of the interpolant, and eliminates the need for frequent re-interpolation. Consequently, the removal and insertion of point cloud data become seamless processes, particularly advantageous in regions experiencing significant fluctuations in point density. The numerical results demonstrate the convergence of geometric quantities and the effectiveness of our approach. Finally, we show simulations of curvature flows whose speeds depend on the solutions of coupled reaction--diffusion systems for pattern formation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01790v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.DG</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.enganabound.2025.106488</arxiv:DOI>
      <dc:creator>Muhammad Ammad, Leevan Ling</dc:creator>
    </item>
    <item>
      <title>Asymptotic preserving schemes for hyperbolic systems with relaxation</title>
      <link>https://arxiv.org/abs/2510.01828</link>
      <description>arXiv:2510.01828v1 Announce Type: new 
Abstract: This paper presents the construction of two numerical schemes for the solution of hyperbolic systems with relaxation source terms. The methods are built by considering the relaxation system as a whole, without separating the resolution of the convective part from that of the source term. The first scheme combines the centered FORCE approach of Toro and co-authors with the unsplit strategy proposed by B{\'e}reux and Sainsaulieu. The second scheme consists of an approximate Riemann solver which carefully handles the source term approximation. The two schemes are built to be asymptotic preserving, in the sense that their limit schemes are consistent with the equilibrium model as the relaxation parameter tends to zero, without any CFL restriction. For specific models, it is possible to prove that they preserve invariant domains and admit a discrete entropy inequality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01828v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C Mahmoud (IMAG, ANGUS), H Mathis (IMAG, ANGUS)</dc:creator>
    </item>
    <item>
      <title>A nodally bound-preserving composite discontinuous Galerkin method on polytopic meshes</title>
      <link>https://arxiv.org/abs/2510.02094</link>
      <description>arXiv:2510.02094v1 Announce Type: new 
Abstract: We introduce a nodally bound-preserving Galerkin method for second-order elliptic problems on general polygonal/polyhedral, henceforth collectively termed as \emph{polytopic}, meshes. Starting from an interior penalty discontinuous Galerkin (DG) formulation posed on a polytopic mesh, the method enforces preservation of \emph{a priori} prescribed upper and lower bounds for the numerical solution at an arbitrary number of user-defined points \emph{within} each polytopic element. This is achieved by employing a simplicial submesh and enforcing bound preservation at the submesh nodes via a nonlinear iteration. By construction, the submeshing procedure preserves the order of accuracy of the DG method, \emph{without} introducing any additional global numerical degrees of freedom compared to the baseline DG method, thereby, falling into the category of composite finite element approaches. A salient feature of the proposed method is that it automatically reverts to the standard DG method on polytopic meshes when no prescribed bound violation occurs. In particular, the choice of the discontinuity-penalisation parameter is independent of the submesh granularity. The resulting composite method combines the geometric flexibility of polytopic meshes with the accuracy and stability of discontinuous Galerkin discretisations, while rigorously guaranteeing bound preservation. The existence and uniqueness of the numerical solution is proven. A priori error bounds, assuming sufficient regularity of the exact solution are shown, employing a non-standard construction of discrete nodally bound-preserving interpolant. Numerical experiments confirm optimal convergence for smooth problems and demonstrate robustness in the presence of sharp gradients, such as boundary and interior layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02094v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdolreza Amiri, Gabriel R. Barrenechea, Emmanuil H. Georgoulis, Tristan Pryer</dc:creator>
    </item>
    <item>
      <title>Coarse scrambling for Sobol' and Niederreiter sequences</title>
      <link>https://arxiv.org/abs/2510.02111</link>
      <description>arXiv:2510.02111v1 Announce Type: new 
Abstract: We introduce \emph{coarse scrambling}, a novel randomization for digital sequences that permutes blocks of digits in a mixed-radix representation. This construction is designed to preserve the powerful $(0,\boldsymbol{e},d)$-sequence property of the underlying points. For sufficiently smooth integrands, we prove that this method achieves the canonical $O(n^{-3+\epsilon})$ variance decay rate, matching that of standard Owen's scrambling. Crucially, we show that its maximal gain coefficient grows only logarithmically with dimension, $O(\log d)$, thus providing theoretical robustness against the curse of dimensionality affecting scrambled Sobol' sequences. Numerical experiments validate these findings and illustrate a practical trade-off: while Owen's scrambling is superior for integrands sensitive to low-dimensional projections, coarse scrambling is competitive for functions with low effective truncation dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02111v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kosuke Suzuki</dc:creator>
    </item>
    <item>
      <title>Mixed-precision iterative refinement for low-rank Lyapunov equations</title>
      <link>https://arxiv.org/abs/2510.02126</link>
      <description>arXiv:2510.02126v1 Announce Type: new 
Abstract: We develop a mixed-precision iterative refinement framework for solving low-rank Lyapunov matrix equations $AX + XA^T + W =0$, where $W=LL^T$ or $W=LSL^T$. Via rounding error analysis of the algorithms we derive sufficient conditions for the attainable normwise residuals in different precision settings and show how the algorithmic parameters should be chosen. Using the sign function Newton iteration as the solver, we show that reduced precisions, such as the half precision, can be used as the solver precision (with unit roundoff $u_s$) to accelerate the solution of Lyapunov equations of condition number up to $1/u_s$ without compromising its quality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02126v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Benner, Xiaobo Liu</dc:creator>
    </item>
    <item>
      <title>A Fast solver for high condition linear systems using randomized stable solutions of its blocks</title>
      <link>https://arxiv.org/abs/2510.02156</link>
      <description>arXiv:2510.02156v1 Announce Type: new 
Abstract: We present an enhanced version of the row-based randomized block-Kaczmarz method to solve a linear system of equations. This improvement makes use of a regularization during block updates in the solution, and a dynamic proposal distribution based on the current residue and effective orthogonality between blocks. This improved method provides significant gains in solving high-condition number linear systems that are either sparse, or dense least-squares problems that are significantly over/under determined. Considering the poor generalizability of preconditioners for such problems, it can also serve as a pre-solver for other iterative numerical methods when required, and as an inner iteration in certain types of GMRES solvers for linear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02156v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suvendu Kar, Murugesan Venkatapathi</dc:creator>
    </item>
    <item>
      <title>Improving Runtime Performance of Tensor Computations using Rust From Python</title>
      <link>https://arxiv.org/abs/2510.01495</link>
      <description>arXiv:2510.01495v1 Announce Type: cross 
Abstract: In this work, we investigate improving the runtime performance of key computational kernels in the Python Tensor Toolbox (pyttb), a package for analyzing tensor data across a wide variety of applications. Recent runtime performance improvements have been demonstrated using Rust, a compiled language, from Python via extension modules leveraging the Python C API -- e.g., web applications, data parsing, data validation, etc. Using this same approach, we study the runtime performance of key tensor kernels of increasing complexity, from simple kernels involving sums of products over data accessed through single and nested loops to more advanced tensor multiplication kernels that are key in low-rank tensor decomposition and tensor regression algorithms. In numerical experiments involving synthetically generated tensor data of various sizes and these tensor kernels, we demonstrate consistent improvements in runtime performance when using Rust from Python over 1) using Python alone, 2) using Python and the Numba just-in-time Python compiler (for loop-based kernels), and 3) using the NumPy Python package for scientific computing (for pyttb kernels).</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01495v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kimmie Harding, Daniel M. Dunlavy</dc:creator>
    </item>
    <item>
      <title>Exponential convergence of a distributed divide-and-conquer algorithm for constrained convex optimization on networks</title>
      <link>https://arxiv.org/abs/2510.01511</link>
      <description>arXiv:2510.01511v1 Announce Type: cross 
Abstract: We propose a divide-and-conquer (DAC) algorithm for constrained convex optimization over networks, where the global objective is the sum of local objectives attached to individual agents. The algorithm is fully distributed: each iteration solves local subproblems around selected fusion centers and coordinates only with neighboring fusion centers. Under standard assumptions of smoothness, strong convexity, and locality on the objective function, together with polynomial growth conditions on the underlying graph, we establish exponential convergence of the DAC iterations and derive explicit bounds for both exact and inexact local solvers. Numerical experiments on three representative losses ($L_2$ distance, quadratic, and entropy) confirm the theory and demonstrate scalability and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01511v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nazar Emirov, Guohui Song, Qiyu Sun</dc:creator>
    </item>
    <item>
      <title>Quantum advantages in ground state preparation, combinatorial optimization, and quantum state preparation</title>
      <link>https://arxiv.org/abs/2510.01563</link>
      <description>arXiv:2510.01563v1 Announce Type: cross 
Abstract: We show that for any quantum Hamiltonian with an inverse-polynomial gap, the ground state can be prepared in a polynomial circuit depth to inverse-polynomial precision, if the system size is sufficiently large. The resulting circuit is composed of a polynomial number of Pauli rotations without ancilla qubit. Extending this result, we prove that for sufficiently large qubit number, any quantum state can be approximately prepared with a constant (polynomial) number of Pauli rotations to constant (inverse-polynomial) precision. Our theoretical findings reveal exponential quantum advantages in the prominent applications: ground state preparation, combinatorial optimization, and quantum state preparation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01563v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taehee Ko, Sungbin Lim</dc:creator>
    </item>
    <item>
      <title>A Novel Algorithm for Representing Positive Semi-Definite Polynomials as Sums of Squares with Rational Coefficients</title>
      <link>https://arxiv.org/abs/2510.01568</link>
      <description>arXiv:2510.01568v1 Announce Type: cross 
Abstract: This paper presents a novel algorithm for constructing a sum-of-squares (SOS) decomposition for positive semi-definite polynomials with rational coefficients. Unlike previous methods that typically yield SOS decompositions with floating-point coefficients, our approach ensures that all coefficients in the decomposition remain rational. This is particularly useful in formal verification and symbolic computation, where exact arithmetic is required. We introduce a stepwise reduction technique that transforms a given polynomial into a sum of ladder-like squares while preserving rationality. Experimental results demonstrate the effectiveness of our method compared to existing numerical approaches. This artical is an extension of the following Chinnese paper: HUANG Yong , ZENG Zhenbing , YANG Lu , RAO Yongsheng. An Algorithm to Represent Positive Semi-Definite Polynomials to Sum of Lader-Like Squares of Polynomials with Rational Coefficients (in Chinese). Journal of Systems Science and Mathematical Sciences, 2024, 44(5): 1241-1271 https://doi.org/10.12341/jssms23584CM</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01568v1</guid>
      <category>cs.SC</category>
      <category>cs.NA</category>
      <category>math.AG</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenbing Zeng, Yong Huang, Lu Yang, Yongsheng Rao</dc:creator>
    </item>
    <item>
      <title>Learning Regularization Functionals for Inverse Problems: A Comparative Study</title>
      <link>https://arxiv.org/abs/2510.01755</link>
      <description>arXiv:2510.01755v1 Announce Type: cross 
Abstract: In recent years, a variety of learned regularization frameworks for solving inverse problems in imaging have emerged. These offer flexible modeling together with mathematical insights. The proposed methods differ in their architectural design and training strategies, making direct comparison challenging due to non-modular implementations. We address this gap by collecting and unifying the available code into a common framework. This unified view allows us to systematically compare the approaches and highlight their strengths and limitations, providing valuable insights into their future potential. We also provide concise descriptions of each method, complemented by practical guidelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01755v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Hertrich, Hok Shing Wong, Alexander Denker, Stanislas Ducotterd, Zhenghan Fang, Markus Haltmeier, \v{Z}eljko Kereta, Erich Kobler, Oscar Leong, Mohammad Sadegh Salehi, Carola-Bibiane Sch\"onlieb, Johannes Schwab, Zakhar Shumaylov, Jeremias Sulam, German Sh\^ama Wache, Martin Zach, Yasi Zhang, Matthias J. Ehrhardt, Sebastian Neumayer</dc:creator>
    </item>
    <item>
      <title>Neural non-canonical Hamiltonian dynamics for long-time simulations</title>
      <link>https://arxiv.org/abs/2510.01788</link>
      <description>arXiv:2510.01788v1 Announce Type: cross 
Abstract: This work focuses on learning non-canonical Hamiltonian dynamics from data, where long-term predictions require the preservation of structure both in the learned model and in numerical schemes. Previous research focused on either facet, respectively with a potential-based architecture and with degenerate variational integrators, but new issues arise when combining both. In experiments, the learnt model is sometimes numerically unstable due to the gauge dependency of the scheme, rendering long-time simulations impossible. In this paper, we identify this problem and propose two different training strategies to address it, either by directly learning the vector field or by learning a time-discrete dynamics through the scheme. Several numerical test cases assess the ability of the methods to learn complex physical dynamics, like the guiding center from gyrokinetic plasma physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01788v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ementine Court\`es (IRMA, MACARON), Emmanuel Franck (MACARON), Michael Kraus (IPP), Laurent Navoret (IRMA, MACARON), L\'eopold Tr\'emant (LML)</dc:creator>
    </item>
    <item>
      <title>A quantum analogue of convex optimization</title>
      <link>https://arxiv.org/abs/2510.02151</link>
      <description>arXiv:2510.02151v1 Announce Type: cross 
Abstract: Convex optimization is the powerhouse behind the theory and practice of optimization. We introduce a quantum analogue of unconstrained convex optimization: computing the minimum eigenvalue of a Schr\"odinger operator $h = -\Delta + V $ with convex potential $V:\mathbb R^n \rightarrow \mathbb R_{\ge 0}$ such that $V(x)\rightarrow\infty $ as $\|x\|\rightarrow\infty$. For this problem, we present an efficient quantum algorithm, called the Fundamental Gap Algorithm (FGA), that computes the minimum eigenvalue of $h$ up to error $\epsilon$ in polynomial time in $n$, $1/\epsilon$, and parameters that depend on $V$. Adiabatic evolution of the ground state is used as a key subroutine, which we analyze with novel techniques that allow us to focus on the low-energy space. We apply the FGA to give the first known polynomial-time algorithm for finding the lowest frequency of an $n$-dimensional convex drum, or mathematically, the minimum eigenvalue of the Dirichlet Laplacian on an $n$-dimensional region that is defined by $m$ linear constraints in polynomial time in $n$, $m$, $1/\epsilon$ and the radius $R$ of a ball encompassing the region.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02151v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eunou Lee</dc:creator>
    </item>
    <item>
      <title>Non-commutative multiple bi-orthogonal polynomials: formal approach and integrability</title>
      <link>https://arxiv.org/abs/2510.02207</link>
      <description>arXiv:2510.02207v1 Announce Type: cross 
Abstract: We define the non-commutative multiple bi-orthogonal polynomial systems, which simultaneously generalize the concepts of multiple orthogonality, matrix orthogonal polynomials and of the bi-orthogonality. We present quasideterminantal expressions for such polynomial systems in terms of formal bi-moments. The normalization functions for such monic polynomials satisfy the non-commutative Hirota equations, while the polynomials provide solution of the corresponding linear system. This shows, in particular, that our polynomial systems form a part of the theory of integrable systems. We study also a specialization of the problem to non-commutative multiple orthogonal polynomials, what results in the corresponding Hankel-type quasideterminantal expressions in terms of the moments. Moreover, such a reduction allows to introduce in a standard way the discrete-time variable and gives rise to an integrable system which is non-commutative version of the multidimensional discrete-time Toda equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02207v1</guid>
      <category>nlin.SI</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adam Doliwa</dc:creator>
    </item>
    <item>
      <title>Approximation in Hilbert spaces of the Gaussian and related analytic kernels</title>
      <link>https://arxiv.org/abs/2209.12473</link>
      <description>arXiv:2209.12473v4 Announce Type: replace 
Abstract: We consider linear approximation based on function evaluations in reproducing kernel Hilbert spaces of certain analytic weighted power series kernels and stationary kernels on the interval $[-1,1]$. Both classes contain the popular Gaussian kernel $K(x, y) = \exp(-\tfrac{1}{2}\varepsilon^2(x-y)^2)$. For weighted power series kernels we derive almost matching upper and lower bounds on the worst-case error. When applied to the Gaussian kernel, our results state that, up to a sub-exponential factor, the $n$th minimal error decays as $(\varepsilon/2)^n (n!)^{-1/2}$. The proofs are based on weighted polynomial interpolation and classical polynomial coefficient estimates that we use to bound the Hilbert space norm of a weighted polynomial fooling function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.12473v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/imanum/draf050</arxiv:DOI>
      <dc:creator>Toni Karvonen, Yuya Suzuki</dc:creator>
    </item>
    <item>
      <title>Structure preserving discretization: A Berezin-Toeplitz Quantization viewpoint</title>
      <link>https://arxiv.org/abs/2411.01085</link>
      <description>arXiv:2411.01085v2 Announce Type: replace 
Abstract: In this paper, we introduce a comprehensive axiomatization of structure-preserving discretization through the framework of commutative diagrams. By establishing a formal language that captures the essential properties of discretization processes, we provide a rigorous foundation for analyzing how various structures (such as algebraic, geometric, and topological features) are maintained during the transition from continuous to discrete settings. Specifically, we establish that the transition from continuous to discrete differential settings invariably leads to noncommutative structures, reinforcing previous observation on the interplay between discretization and noncommutativity. We demonstrate the applicability of our axiomatization by applying it to the Berezin-Toeplitz quantization, showing that this quantization method adheres to our proposed criteria for structure-preserving discretization. We establish in this setting a precise limit theorem for the approximation of the Laplacian by a sequence of matrix approximations. This work not only enriches the theoretical understanding of the nature of discretization but also sets the stage for further exploration of its applications across various discretization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01085v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Damien Tageddine, Jean-Christophe Nave</dc:creator>
    </item>
    <item>
      <title>Finite element discretization of nonlinear models of ultrasound heating</title>
      <link>https://arxiv.org/abs/2501.18307</link>
      <description>arXiv:2501.18307v2 Announce Type: replace 
Abstract: Heating generated by high-intensity focused ultrasound waves is central to many emerging medical applications, including non-invasive cancer therapy and targeted drug delivery. In this study, we aim to gain a fundamental understanding of numerical simulations in this context by analyzing conforming finite element approximations of the underlying nonlinear models that describe ultrasound-heat interactions. These models are based on a coupling of a nonlinear Westervelt--Kuznetsov acoustic wave equation to the heat equation with a pressure-dependent source term. A particular challenging feature of the system is that the acoustic medium parameters may depend on the temperature. The core of our new arguments in the \emph{a prior} error analysis lies in devising energy estimates for the coupled semi-discrete system that can accommodate the nonlinearities present in the model. To derive them, we exploit the parabolic nature of the system thanks to the strong damping present in the acoustic component. Theoretically obtained optimal convergence rates in the energy norm are confirmed by the numerical experiments. In addition, we conduct a further numerical study of the problem, where we simulate the propagation of acoustic waves in liver tissue for an initially excited profile and under high-frequency sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18307v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julio Careaga, Benjamin D\"orich, Vanja Nikoli\'c</dc:creator>
    </item>
    <item>
      <title>Numerical Approximation of the Critical Value of Eikonal Hamilton-Jacobi Equations on Networks</title>
      <link>https://arxiv.org/abs/2502.20993</link>
      <description>arXiv:2502.20993v2 Announce Type: replace 
Abstract: The critical value of an eikonal equation is the unique value of a parameter for which the equation admits solutions and is deeply related to the effective Hamiltonian of a corresponding homogenization problem. We study approximation strategies for the critical value of eikonal equations posed on networks. They are based on the large time behavior of corresponding time-dependent Hamilton-Jacobi equations. We provide error estimates and some numerical tests, showing the performance and the convergence properties of the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20993v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentina Coscetti, Marco Pozza</dc:creator>
    </item>
    <item>
      <title>Improved Polynomial Bounds and Acceleration of GMRES by Solving a min-max Problem on Rectangles, and by Deflating</title>
      <link>https://arxiv.org/abs/2504.05723</link>
      <description>arXiv:2504.05723v2 Announce Type: replace 
Abstract: Polynomial convergence bounds are considered for left, right, and split preconditioned GMRES. They include the cases of Weighted and Deflated GMRES for a linear system Ax = b. In particular, the case of positive definite A is considered. The well-known polynomial bounds are generalized to the cases considered, and then reduced to solving a min-max problem on rectangles on the complex plane. Several approaches are considered and compared. The new bounds can be improved by using specific deflation spaces and preconditioners. This in turn accelerates the convergence of GMRES. Numerical examples illustrate the results obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.05723v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Spillane (CMAP), Daniel B Szyld</dc:creator>
    </item>
    <item>
      <title>Matrix Factorizations with Uniformly Random Pivoting</title>
      <link>https://arxiv.org/abs/2505.02023</link>
      <description>arXiv:2505.02023v3 Announce Type: replace 
Abstract: This paper highlights a formal connection between two families of widely used matrix factorization algorithms in numerical linear algebra. One family consists of the Jacobi eigenvalue algorithm and its variants for computing the Hermitian eigendecomposition and singular value decomposition. The other consists of Gaussian elimination and the Gram-Schmidt procedure with various pivoting rules for computing the Cholesky decomposition and QR decomposition respectively.
  Both families are cast as special cases of a more general class of factorization algorithms. We provide a randomized pivoting rule that applies to this general class (which differs substantially from the usual pivoting rules for Gaussian elimination / Gram-Schmidt) which admits a unified analysis of the entire class of algorithms. The result is the same linear rate of convergence for each algorithm, irrespective of which factorization it computes.
  One important consequence of this randomized pivoting rule is a provable, effective bound on the numerical stability of the Jacobi eigenvalue algorithm, which addresses a longstanding open problem of Demmel and Veseli\'c `92.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02023v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabel Detherage, Rikhav Shah</dc:creator>
    </item>
    <item>
      <title>Advances on the finite element discretization of fluid-structure interaction problems</title>
      <link>https://arxiv.org/abs/2505.02594</link>
      <description>arXiv:2505.02594v3 Announce Type: replace 
Abstract: We review the main features of an unfitted finite element method for interface and fluid-structure interaction problems based on a distributed Lagrange multiplier in the spirit of the fictitious domain approach. We recall our theoretical findings concerning well-posedness, stability, and convergence of the numerical schemes, and discuss the related computational challenges. In the case of elliptic interface problems, we also present a posteriori error estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02594v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s40065-025-00570-8</arxiv:DOI>
      <dc:creator>Najwa Alshehri, Daniele Boffi, Fabio Credali, Lucia Gastaldi</dc:creator>
    </item>
    <item>
      <title>On sliced Cram\'er metrics</title>
      <link>https://arxiv.org/abs/2508.02678</link>
      <description>arXiv:2508.02678v2 Announce Type: replace 
Abstract: This paper studies the family of sliced Cram\'er metrics, quantifying their stability under distortions of the input functions. Our results bound the growth of the sliced Cram\'er distance between a function and its geometric deformation by the product of the deformation's displacement size and the function's mean mixed norm. These results extend to sliced Cram\'er distances between tomographic projections. In addition, we remark on the effect of convolution on the sliced Cram\'er metrics. We also analyze efficient Fourier-based discretizations in 1D and 2D, and prove that they are robust to heteroscedastic noise. The results are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02678v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Leeb</dc:creator>
    </item>
    <item>
      <title>A Tensor Train Approach for Deterministic Arithmetic Operations on Discrete Representations of Probability Distributions</title>
      <link>https://arxiv.org/abs/2508.06303</link>
      <description>arXiv:2508.06303v2 Announce Type: replace 
Abstract: Computing with discrete representations of high-dimensional probability distributions is fundamental to uncertainty quantification, Bayesian inference, and stochastic modeling. However, storing and manipulating such distributions suffers from the curse of dimensionality, as memory and computational costs grow exponentially with dimension. Monte Carlo methods require thousands to billions of samples, incurring high computational costs and producing inconsistent results due to stochasticity. We present an efficient tensor train method for performing exact arithmetic operations on discretizations of continuous probability distributions while avoiding exponential growth. Our approach leverages low-rank tensor train decomposition to represent latent random variables compactly using Dirac deltas, enabling deterministic addition, subtraction and multiplication operations directly in the compressed format. We develop an efficient implementation using sparse matrices and specialized data structures that further enhances performance. Theoretical analysis demonstrates polynomial scaling of memory and computational complexity under rank assumptions, and shows how statistics of latent variables can be computed with polynomial complexity. Numerical experiments spanning randomized linear algebra to stochastic differential equations demonstrate orders-of-magnitude improvements in memory usage and computational time compared to conventional approaches, enabling tractable deterministic computations on discretized random variables in previously intractable dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06303v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gerhard Kirsten, Bilgesu Bilgin, Janith Petangoda, Phillip Stanley-Marbell</dc:creator>
    </item>
    <item>
      <title>CutVEM: Conforming virtual element method on embedded domains with shape-agnostic element agglomeration</title>
      <link>https://arxiv.org/abs/2508.10570</link>
      <description>arXiv:2508.10570v2 Announce Type: replace 
Abstract: The virtual element method (VEM) is a stabilized Galerkin method that is robust and accurate on general polygonal meshes. This feature makes it an appealing candidate for simulations involving meshes with embedded interfaces and evolving geometries. However, similar to the finite element method, in such scenarios the VEM can also yield poorly conditioned stiffness matrices due to meshes having cut cells. With the objective of developing an embedded domain method, we propose a novel element agglomeration algorithm for the VEM to address this issue. The agglomeration algorithm renders the VEM robust over planar polygonal meshes, particularly on finite element meshes cut by immersed geometries. The algorithm relies on the element stability ratio, which we define using the extreme eigenvalues of the element stiffness matrix. The resulting element agglomeration criterion is free from nebulous polygon quality metrics and is defined independently of polygon shapes. The algorithm proceeds iteratively and element-wise to maximize the minimum element stability ratio, even at the expense of degrading elements with better ratios. The resulting method, which we label as CutVEM, retains node locations of cut elements unchanged, and yields discretizations that conform to embedded interfaces. This, in turn, facilitates straightforward imposition of boundary conditions and interfacial constraints. Through detailed numerical experiments that sample varied element-interface intersections, we demonstrate that CutVEM enjoys dramatically improved condition numbers of global stiffness matrices over the VEM. Furthermore, simulations of prototypical heat conduction problems with Dirichlet and Neumann boundary conditions on domains with immersed geometries show that element agglomeration does not noticeably degrade solution accuracy and that CutVEM retains the VEM's optimal convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10570v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ramsharan Rangarajan, N. Sukumar</dc:creator>
    </item>
    <item>
      <title>An Overview of Meshfree Collocation Methods</title>
      <link>https://arxiv.org/abs/2509.20056</link>
      <description>arXiv:2509.20056v2 Announce Type: replace 
Abstract: We provide a comprehensive overview of meshfree collocation methods for numerically approximating differential operators on continuously labeled unstructured point clouds. Meshfree collocation methods do not require a computational grid or mesh. Instead, they approximate smooth functions and their derivatives at potentially irregularly distributed collocation points, often called particles, to a desired order of consistency. We review several meshfree collocation methods from the literature, trace the historical development of key concepts, and propose a classification of methods according to their principle of derivation. Although some of the methods reviewed are similar or identical, there are subtle yet important differences between many, which we highlight and discuss. We present a unifying formulation of meshfree collocation methods that renders these differences apparent and show how each method can be derived from this formulation. Finally, we propose a generalized derivation for meshfree collocation methods going forward.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20056v2</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomas Halada, Serhii Yaskovets, Abhinav Singh, Ludek Benes, Pratik Suchde, Ivo F. Sbalzarini</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of online algorithms for vector-valued kernel regression</title>
      <link>https://arxiv.org/abs/2309.07779</link>
      <description>arXiv:2309.07779v5 Announce Type: replace-cross 
Abstract: We consider the problem of approximating the regression function $f_\mu:\, \Omega \to Y$ from noisy $\mu$-distributed vector-valued data $(\omega_m,y_m)\in\Omega\times Y$ by an online learning algorithm using a reproducing kernel Hilbert space $H$ (RKHS) as prior. In an online algorithm, i.i.d. samples become available one by one via a random process and are successively processed to build approximations to the regression function. Assuming that the regression function essentially belongs to $H$ (soft learning scenario), we provide estimates for the expected squared error in the RKHS norm of the approximations $f^{(m)}\in H$ obtained by a standard regularized online approximation algorithm. In particular, we show an order-optimal estimate $$ \mathbb{E}(\|\epsilon^{(m)}\|_H^2)\le C (m+1)^{-s/(2+s)},\qquad m=1,2,\ldots, $$ where $\epsilon^{(m)}$ denotes the error term after $m$ processed data, the parameter $0&lt;s\leq 1$ expresses an additional smoothness assumption on the regression function, and the constant $C$ depends on the variance of the input noise, the smoothness of the regression function, and other parameters of the algorithm. The proof, which is inspired by results on Schwarz iterative methods in the noiseless case, uses only elementary Hilbert space techniques and minimal assumptions on the noise, the feature map that defines $H$ and the associated covariance operator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07779v5</guid>
      <category>stat.ML</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Griebel, Peter Oswald</dc:creator>
    </item>
    <item>
      <title>Accuracy of Discretely Sampled Stochastic Policies in Continuous-time Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2503.09981</link>
      <description>arXiv:2503.09981v2 Announce Type: replace-cross 
Abstract: Stochastic policies (also known as relaxed controls) are widely used in continuous-time reinforcement learning algorithms. However, executing a stochastic policy and evaluating its performance in a continuous-time environment remain open challenges. This work introduces and rigorously analyzes a policy execution framework that samples actions from a stochastic policy at discrete time points and implements them as piecewise constant controls. We prove that as the sampling mesh size tends to zero, the controlled state process converges weakly to the dynamics with coefficients aggregated according to the stochastic policy. We explicitly quantify the convergence rate based on the regularity of the coefficients and establish an optimal first-order convergence rate for sufficiently regular coefficients. Additionally, we prove a $1/2$-order weak convergence rate that holds uniformly over the sampling noise with high probability, and establish a $1/2$-order pathwise convergence for each realization of the system noise in the absence of volatility control. Building on these results, we analyze the bias and variance of various policy evaluation and policy gradient estimators based on discrete-time observations. Our results provide theoretical justification for the exploratory stochastic control framework in [H. Wang, T. Zariphopoulou, and X.Y. Zhou, J. Mach. Learn. Res., 21 (2020), pp. 1-34].</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09981v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanwei Jia, Du Ouyang, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>The Marcinkiewicz-Zygmund Property for Riemann Differences with Geometric Nodes</title>
      <link>https://arxiv.org/abs/2507.11463</link>
      <description>arXiv:2507.11463v2 Announce Type: replace-cross 
Abstract: We study when a Riemann difference of order $ n $ possesses the Marcinkiewicz-Zygmund (MZ) property: that is, whether the conditions $ f(h) = o(h^{n-1}) $ and $ Df(h) = o(h^n) $ imply $ f(h) = o(h^n) $. This implication is known to hold for some classical examples with geometric nodes, such as $ \{0, 1, q, \dots, q^{n-1}\} $ and $ \{1, q, \dots, q^n\} $, leading to a conjecture that these are the only such Riemann differences with the MZ property. However, this conjecture was disproved by the third-order example with nodes $ \{-1, 0, 1, 2\} $, and we provide further counterexamples and a general classification here.
  We establish a complete analytic criterion for the MZ property by developing a recurrence framework: we analyze when a function $ R(h) $ satisfying $ D(h) = R(qh) - A R(h) $, together with $ D(h) = o(h^n) $ and $ R(h) = o(h^{n-1}) $, forces $ R(h) = o(h^n) $. We prove that this holds if and only if $ A $ lies outside a critical modulus annulus determined by $ q $ and $ n $, covering both $ |q| &gt; 1 $ and $ |q| &lt; 1 $ cases. This leads to a complete characterization of all Riemann differences with geometric nodes that possess the MZ property, and provides a flexible analytic framework applicable to broader classes of generalized differences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11463v2</guid>
      <category>math.CA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hajrudin Fejzi\'c</dc:creator>
    </item>
    <item>
      <title>Reconstruction in the Calder\'on problem on a fixed partition from finite and partial boundary data</title>
      <link>https://arxiv.org/abs/2507.19410</link>
      <description>arXiv:2507.19410v2 Announce Type: replace-cross 
Abstract: This short note modifies a reconstruction method by the author (Comm.~PDE, 45(9):1118--1133, 2020), for reconstructing piecewise constant conductivities in the Calder\'on problem (electrical impedance tomography). In the former paper, a layering assumption and the local Neumann-to-Dirichlet map were needed since the piecewise constant partition also was assumed unknown. Here I show how to modify the method in case the partition is known, for general piecewise constant conductivities and only a finite number of partial boundary measurements. Moreover, no lower/upper bounds on the unknown conductivity are needed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19410v2</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henrik Garde</dc:creator>
    </item>
    <item>
      <title>Sketching Low-Rank Plus Diagonal Matrices</title>
      <link>https://arxiv.org/abs/2509.23587</link>
      <description>arXiv:2509.23587v2 Announce Type: replace-cross 
Abstract: Many relevant machine learning and scientific computing tasks involve high-dimensional linear operators accessible only via costly matrix-vector products. In this context, recent advances in sketched methods have enabled the construction of *either* low-rank *or* diagonal approximations from few matrix-vector products. This provides great speedup and scalability, but approximation errors arise due to the assumed simpler structure. This work introduces SKETCHLORD, a method that simultaneously estimates both low-rank *and* diagonal components, targeting the broader class of Low-Rank *plus* Diagonal (LoRD) linear operators. We demonstrate theoretically and empirically that this joint estimation is superior also to any sequential variant (diagonal-then-low-rank or low-rank-then-diagonal). Then, we cast SKETCHLORD as a convex optimization problem, leading to a scalable algorithm. Comprehensive experiments on synthetic (approximate) LoRD matrices confirm SKETCHLORD's performance in accurately recovering these structures. This positions it as a valuable addition to the structured approximation toolkit, particularly when high-fidelity approximations are desired for large-scale operators, such as the deep learning Hessian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23587v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andres Fernandez, Felix Dangel, Philipp Hennig, Frank Schneider</dc:creator>
    </item>
  </channel>
</rss>
