<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Nov 2024 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Generalisation of Voter Model: Influential Nodes and Convergence Properties</title>
      <link>https://arxiv.org/abs/2411.04564</link>
      <description>arXiv:2411.04564v1 Announce Type: new 
Abstract: Consider an undirected graph G, representing a social network, where each node is blue or red, corresponding to positive or negative opinion on a topic. In the voter model, in discrete time rounds, each node picks a neighbour uniformly at random and adopts its colour. Despite its significant popularity, this model does not capture some fundamental real-world characteristics such as the difference in the strengths of individuals connections, individuals with neutral opinion on a topic, and individuals who are reluctant to update their opinion. To address these issues, we introduce and study a generalisation of the voter model. Motivating by campaigning strategies, we study the problem of selecting a set of seeds blue nodes to maximise the expected number of blue nodes after some rounds. We prove that the problem is NP- hard and provide a polynomial time approximation algorithm with the best possible approximation guarantee. Our experiments on real-world and synthetic graph data demonstrate that the proposed algorithm outperforms other algorithms. We also investigate the convergence properties of the model. We prove that the process could take an exponential number of rounds to converge. However, if we limit ourselves to strongly connected graphs, the convergence time is polynomial and the period (the number of states in convergence) divides the length of all cycles in the graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04564v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhiram Manohara, Ahad N. Zehmakan</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean Mixture Model for Social Network Embedding</title>
      <link>https://arxiv.org/abs/2411.04876</link>
      <description>arXiv:2411.04876v1 Announce Type: new 
Abstract: It is largely agreed that social network links are formed due to either homophily or social influence. Inspired by this, we aim at understanding the generation of links via providing a novel embedding-based graph formation model. Different from existing graph representation learning, where link generation probabilities are defined as a simple function of the corresponding node embeddings, we model the link generation as a mixture model of the two factors. In addition, we model the homophily factor in spherical space and the influence factor in hyperbolic space to accommodate the fact that (1) homophily results in cycles and (2) influence results in hierarchies in networks. We also design a special projection to align these two spaces. We call this model Non-Euclidean Mixture Model, i.e., NMM. We further integrate NMM with our non-Euclidean graph variational autoencoder (VAE) framework, NMM-GNN. NMM-GNN learns embeddings through a unified framework which uses non-Euclidean GNN encoders, non-Euclidean Gaussian priors, a non-Euclidean decoder, and a novel space unification loss component to unify distinct non-Euclidean geometric spaces. Experiments on public datasets show NMM-GNN significantly outperforms state-of-the-art baselines on social network generation and classification tasks, demonstrating its ability to better explain how the social network is formed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04876v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roshni G. Iyer, Yewen Wang, Wei Wang, Yizhou Sun</dc:creator>
    </item>
    <item>
      <title>Centrality Graph Shift Operators for Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2411.04655</link>
      <description>arXiv:2411.04655v1 Announce Type: cross 
Abstract: Graph Shift Operators (GSOs), such as the adjacency and graph Laplacian matrices, play a fundamental role in graph theory and graph representation learning. Traditional GSOs are typically constructed by normalizing the adjacency matrix by the degree matrix, a local centrality metric. In this work, we instead propose and study Centrality GSOs (CGSOs), which normalize adjacency matrices by global centrality metrics such as the PageRank, $k$-core or count of fixed length walks. We study spectral properties of the CGSOs, allowing us to get an understanding of their action on graph signals. We confirm this understanding by defining and running the spectral clustering algorithm based on different CGSOs on several synthetic and real-world datasets. We furthermore outline how our CGSO can act as the message passing operator in any Graph Neural Network and in particular demonstrate strong performance of a variant of the Graph Convolutional Network and Graph Attention Network using our CGSOs on several real-world benchmark datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04655v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>math.SP</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yassine Abbahaddou, Fragkiskos D. Malliaros, Johannes F. Lutzeyer, Michalis Vazirgiannis</dc:creator>
    </item>
    <item>
      <title>A dynamical model of platform choice and online segregation</title>
      <link>https://arxiv.org/abs/2411.04681</link>
      <description>arXiv:2411.04681v1 Announce Type: cross 
Abstract: In order to truly understand how social media might shape online discourses or contribute to societal polarization, we need refined models of platform choice, that is: models that help us understand why users prefer one social media platform over another. This study develops a dynamic model of platform selection, extending Social Feedback Theory by incorporating multi-agent reinforcement learning to capture how user decisions are shaped by past rewards across different platforms. A key parameter ($\mu$) in the model governs users' tendencies to either seek approval from like-minded peers or engage with opposing views. Our findings reveal that online environments can evolve into suboptimal states characterized by polarized, strongly opinionated echo chambers, even when users prefer diverse perspectives. Interestingly, this polarizing state coexists with another equilibrium, where users gravitate toward a single dominant platform, marginalizing other platforms into extremity. Using agent-based simulations and dynamical systems analysis, our model underscores the complex interplay of user preferences and platform dynamics, offering insights into how digital spaces might be better managed to foster diverse discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04681v1</guid>
      <category>nlin.AO</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sven Banisch, Dennis Jacob, Tom Willaert, Eckehard Olbrich</dc:creator>
    </item>
    <item>
      <title>Fed-LDR: Federated Local Data-infused Graph Creation with Node-centric Model Refinement</title>
      <link>https://arxiv.org/abs/2411.04936</link>
      <description>arXiv:2411.04936v1 Announce Type: cross 
Abstract: The rapid acceleration of global urbanization has introduced novel challenges in enhancing urban infrastructure and services. Spatio-temporal data, integrating spatial and temporal dimensions, has emerged as a critical tool for understanding urban phenomena and promoting sustainability. In this context, Federated Learning (FL) has gained prominence as a distributed learning paradigm aligned with the privacy requirements of urban IoT environments. However, integrating traditional and deep learning models into the FL framework poses significant challenges, particularly in capturing complex spatio-temporal dependencies and adapting to diverse urban conditions. To address these challenges, we propose the Federated Local Data-Infused Graph Creation with Node-centric Model Refinement (Fed-LDR) algorithm. Fed-LDR leverages FL and Graph Convolutional Networks (GCN) to enhance spatio-temporal data analysis in urban environments. The algorithm comprises two key modules: (1) the Local Data-Infused Graph Creation (LDIGC) module, which dynamically reconfigures adjacency matrices to reflect evolving spatial relationships within urban environments, and (2) the Node-centric Model Refinement (NoMoR) module, which customizes model parameters for individual urban nodes to accommodate heterogeneity. Evaluations on the PeMSD4 and PeMSD8 datasets demonstrate Fed-LDR's superior performance over six baseline methods. Fed-LDR achieved the lowest Mean Absolute Error (MAE) values of 20.15 and 17.30, and the lowest Root Mean Square Error (RMSE) values of 32.30 and 27.15, respectively, while maintaining a high correlation coefficient of 0.96 across both datasets. Notably, on the PeMSD4 dataset, Fed-LDR reduced MAE and RMSE by up to 81\% and 78\%, respectively, compared to the best-performing baseline FedMedian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04936v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiechao Gao, Yuangang Li, Syeda Faiza Ahmed</dc:creator>
    </item>
    <item>
      <title>The dynamics of higher-order novelties</title>
      <link>https://arxiv.org/abs/2307.06147</link>
      <description>arXiv:2307.06147v3 Announce Type: replace-cross 
Abstract: Studying how we explore the world in search of novelties is key to understand the mechanisms that can lead to new discoveries. Previous studies analyzed novelties in various exploration processes, defining them as the first appearance of an element. However, novelties can also be generated by combining what is already known. We hence define higher-order novelties as the first time two or more elements appear together, and we introduce higher-order Heaps' exponents as a way to characterize their pace of discovery. Through extensive analysis of real-world data, we find that processes with the same pace of discovery, as measured by the standard Heaps' exponent, can instead differ at higher orders. We then propose to model an exploration process as a random walk on a network in which the possible connections between elements evolve in time. The model reproduces the empirical properties of higher-order novelties, revealing how the network we explore changes over time along with the exploration process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06147v3</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Di Bona, Alessandro Bellina, Giordano De Marzo, Angelo Petralia, Iacopo Iacopini, Vito Latora</dc:creator>
    </item>
    <item>
      <title>A minimal model of cognition based on oscillatory and current-based reinforcement processes</title>
      <link>https://arxiv.org/abs/2402.02520</link>
      <description>arXiv:2402.02520v3 Announce Type: replace-cross 
Abstract: Building mathematical models of brains is difficult because of the sheer complexity of the problem. One potential starting point is through basal cognition, which gives abstract representation of a range of organisms without central nervous systems, including fungi, slime moulds and bacteria. We propose one such model, demonstrating how a combination of oscillatory and current-based reinforcement processes can be used to couple resources in an efficient manner, mimicking the way these organisms function. A key ingredient in our model, not found in previous basal cognition models, is that we explicitly model oscillations in the number of particles (i.e. the nutrients, chemical signals or similar, which make up the biological system) and the flow of these particles within the modelled organisms. Using this approach, we find that our model builds efficient solutions, provided the environmental oscillations are sufficiently out of phase. We further demonstrate that amplitude differences can promote efficient solutions and that the system is robust to frequency differences. In the context of these findings, we discuss connections between our model and basal cognition in biological systems and slime moulds, in particular, how oscillations might contribute to self-organised problem-solving by these organisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.02520v3</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <category>math.DS</category>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linn\'ea Gyllingberg, Yu Tian, David J. T. Sumpter</dc:creator>
    </item>
    <item>
      <title>Deep-Graph-Sprints: Accelerated Representation Learning in Continuous-Time Dynamic Graphs</title>
      <link>https://arxiv.org/abs/2407.07712</link>
      <description>arXiv:2407.07712v3 Announce Type: replace-cross 
Abstract: Continuous-time dynamic graphs (CTDGs) are essential for modeling interconnected, evolving systems. Traditional methods for extracting knowledge from these graphs often depend on feature engineering or deep learning. Feature engineering is limited by the manual and time-intensive nature of crafting features, while deep learning approaches suffer from high inference latency, making them impractical for real-time applications. This paper introduces Deep-Graph-Sprints (DGS), a novel deep learning architecture designed for efficient representation learning on CTDGs with low-latency inference requirements. We benchmark DGS against state-of-the-art (SOTA) feature engineering and graph neural network methods using five diverse datasets. The results indicate that DGS achieves competitive performance while inference speed improves between 4x and 12x compared to other deep learning approaches on our benchmark datasets. Our method effectively bridges the gap between deep representation learning and low-latency application requirements for CTDGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07712v3</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 08 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ahmad Naser Eddin, Jacopo Bono, David Apar\'icio, Hugo Ferreira, Pedro Ribeiro, Pedro Bizarro</dc:creator>
    </item>
  </channel>
</rss>
