<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 17 Dec 2024 05:01:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Crosstalk-induced Side Channel Threats in Multi-Tenant NISQ Computers</title>
      <link>https://arxiv.org/abs/2412.10507</link>
      <description>arXiv:2412.10507v1 Announce Type: new 
Abstract: As quantum computing rapidly advances, its near-term applications are becoming increasingly evident. However, the high cost and under-utilization of quantum resources are prompting a shift from single-user to multi-user access models. In a multi-tenant environment, where multiple users share one quantum computer, protecting user confidentiality becomes crucial. The varied uses of quantum computers increase the risk that sensitive data encoded by one user could be compromised by others, rendering the protection of data integrity and confidentiality essential. In the evolving quantum computing landscape, it is imperative to study these security challenges within the scope of realistic threat model assumptions, wherein an adversarial user can mount practical attacks without relying on any heightened privileges afforded by physical access to a quantum computer or rogue cloud services. In this paper, we demonstrate the potential of crosstalk as an attack vector for the first time on a Noisy Intermediate Scale Quantum (NISQ) machine, that an adversarial user can exploit within a multi-tenant quantum computing model. The proposed side-channel attack is conducted with minimal and realistic adversarial privileges, with the overarching aim of uncovering the quantum algorithm being executed by a victim. Crosstalk signatures are used to estimate the presence of CNOT gates in the victim circuit, and subsequently, this information is encoded and classified by a graph-based learning model to identify the victim quantum algorithm. When evaluated on up to 336 benchmark circuits, our attack framework is found to be able to unveil the victim's quantum algorithm with up to 85.7\% accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10507v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Navnil Choudhury, Chaithanya Naik Mude, Sanjay Das, Preetham Chandra Tikkireddi, Swamit Tannu, Kanad Basu</dc:creator>
    </item>
    <item>
      <title>A Low-cost IoT Architecture to support Urban Mobility for Visually Impaired People</title>
      <link>https://arxiv.org/abs/2412.11363</link>
      <description>arXiv:2412.11363v1 Announce Type: new 
Abstract: People with visual impairments struggle with urban mobility and independent travel, opening up opportunities for technological advances to improve their quality of life. The Internet of Things (IoT) plays an essential role in bringing improvements and accessibility for visually impaired people. Although alternatives aimed to use IoT in urban mobility, those solutions are still in the initial stages and do not supports urban mobility for people with visual impairment. This paper proposed and evaluated a low-cost IoT architecture that uses Single-Border Computers (SBCs) to support urban mobility. A performance evaluation showcased that our low-cost architecture handles bus trace workload and is suitable for supporting impaired people to get information concerning bus location on Smart Cities scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11363v1</guid>
      <category>cs.ET</category>
      <category>cs.CY</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5753/wpeif.2021.17193</arxiv:DOI>
      <dc:creator>N\'adia Aparecida de Oliveira Silva, Rodrigo Moreira, Larissa Ferreira Rodrigues, Rafael Marinho e Silva</dc:creator>
    </item>
    <item>
      <title>The Reliability Issue in ReRam-based CIM Architecture for SNN: A Survey</title>
      <link>https://arxiv.org/abs/2412.10389</link>
      <description>arXiv:2412.10389v1 Announce Type: cross 
Abstract: The increasing complexity and energy demands of deep learning models have highlighted the limitations of traditional computing architectures, especially for edge devices with constrained resources. Spiking Neural Networks (SNNs) offer a promising alternative by mimicking biological neural networks, enabling energy-efficient computation through event-driven processing and temporal encoding. Concurrently, emerging hardware technologies like Resistive Random Access Memory (ReRAM) and Compute-in-Memory (CIM) architectures aim to overcome the Von Neumann bottleneck by integrating storage and computation. This survey explores the intersection of SNNs and ReRAM-based CIM architectures, focusing on the reliability challenges that arise from device-level variations and operational errors. We review the fundamental principles of SNNs and ReRAM crossbar arrays, discuss the inherent reliability issues in both technologies, and summarize existing solutions to mitigate these challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10389v1</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Wei-Ting Chen</dc:creator>
    </item>
    <item>
      <title>GAP: Game Theory-Based Approach for Reliability and Power Management in Emerging Fog Computing</title>
      <link>https://arxiv.org/abs/2412.11310</link>
      <description>arXiv:2412.11310v1 Announce Type: cross 
Abstract: Fog computing brings about a transformative shift in data management, presenting unprecedented opportunities for enhanced performance and reduced latency. However, one of the key aspects of fog computing revolves around ensuring efficient power and reliability management. To address this challenge, we have introduced a novel model that proposes a non-cooperative game theory-based strategy to strike a balance between power consumption and reliability in decision-making processes. Our proposed model capitalizes on the Cold Primary/Backup strategy (CPB) to guarantee reliability target by re-executing tasks to different nodes when a fault occurs, while also leveraging Dynamic Voltage and Frequency Scaling (DVFS) to reduce power consumption during task execution and maximizing overall efficiency. Non-cooperative game theory plays a pivotal role in our model, as it facilitates the development of strategies and solutions that uphold reliability while reducing power consumption. By treating the trade-off between power and reliability as a non-cooperative game, our proposed method yields significant energy savings, with up to a 35% reduction in energy consumption, 41% decrease in wait time, and 31% shorter completion time compared to state-of-the-art approaches. Our findings underscore the value of game theory in optimizing power and reliability within fog computing environments, demonstrating its potential for driving substantial improvements</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11310v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abolfazl Younesi, Mohsen Ansari, Alireza Ejlali, Mohammad Amin Fazli, Muhammad Shafique, J\"org Henkel</dc:creator>
    </item>
    <item>
      <title>Towards 6G Network Slicing</title>
      <link>https://arxiv.org/abs/2412.11366</link>
      <description>arXiv:2412.11366v1 Announce Type: cross 
Abstract: Networks should connect communicating peers, supporting vertical services requirements. The network evolution towards 6G requires native network slicing techniques. Some literature approaches claim network slice realization, but they do not convincingly address the deployment across multiple Autonomous Systems. This work investigates the current 6G network slicing landscape, presents some gaps, and introduces the concept of the recursive network slicing between multiple Autonomous Systems, supported by the NASOR approach. This innovative concept supports implementing new network services required by the 6G vision. This work also sheds light on the 6G requirements for network slicing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11366v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5753/w6g.2021.17231.</arxiv:DOI>
      <dc:creator>Rodrigo Moreira, Fl\'avio de Oliveira Silva</dc:creator>
    </item>
    <item>
      <title>On Large Language Models in Mission-Critical IT Governance: Are We Ready Yet?</title>
      <link>https://arxiv.org/abs/2412.11698</link>
      <description>arXiv:2412.11698v1 Announce Type: cross 
Abstract: Context. The security of critical infrastructure has been a fundamental concern since the advent of computers, and this concern has only intensified in today's cyber warfare landscape. Protecting mission-critical systems (MCSs), including essential assets like healthcare, telecommunications, and military coordination, is vital for national security. These systems require prompt and comprehensive governance to ensure their resilience, yet recent events have shown that meeting these demands is increasingly challenging. Aim. Building on prior research that demonstrated the potential of GAI, particularly Large Language Models (LLMs), in improving risk analysis tasks, we aim to explore practitioners' perspectives, specifically developers and security personnel, on using generative AI (GAI) in the governance of IT MCSs seeking to provide insights and recommendations for various stakeholders, including researchers, practitioners, and policymakers. Method. We designed a survey to collect practical experiences, concerns, and expectations of practitioners who develop and implement security solutions in the context of MCSs. Analyzing this data will help identify key trends, challenges, and opportunities for introducing GAIs in this niche domain. Conclusions and Future Works. Our findings highlight that the safe use of LLMs in MCS governance requires interdisciplinary collaboration. Researchers should focus on designing regulation-oriented models and focus on accountability; practitioners emphasize data protection and transparency, while policymakers must establish a unified AI framework with global benchmarks to ensure ethical and secure LLMs-based MCS governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11698v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Esposito, Francesco Palagiano, Valentina Lenarduzzi, Davide Taibi</dc:creator>
    </item>
    <item>
      <title>HEANA: A Hybrid Time-Amplitude Analog Optical Accelerator with Flexible Dataflows for Energy-Efficient CNN Inference</title>
      <link>https://arxiv.org/abs/2402.03247</link>
      <description>arXiv:2402.03247v3 Announce Type: replace-cross 
Abstract: Several photonic microring resonators (MRRs) based analog accelerators have been proposed to accelerate the inference of integer-quantized CNNs with remarkably higher throughput and energy efficiency compared to their electronic counterparts. However, the existing analog photonic accelerators suffer from three shortcomings: (i) severe hampering of wavelength parallelism due to various crosstalk effects, (ii) inflexibility of supporting various dataflows other than the weight-stationary dataflow, and (iii) failure in fully leveraging the ability of photodetectors to perform in-situ accumulations. These shortcomings collectively hamper the performance and energy efficiency of prior accelerators. To tackle these shortcomings, we present a novel Hybrid timE Amplitude aNalog optical Accelerator, called HEANA. HEANA employs hybrid time-amplitude analog optical multipliers (TAOMs) that increase the flexibility of HEANA to support multiple dataflows. A spectrally hitless arrangement of TAOMs significantly reduces the crosstalk effects, thereby increasing the wavelength parallelism in HEANA. Moreover, HEANA employs our invented balanced photo-charge accumulators (BPCAs) that enable buffer-less, in-situ, temporal accumulations to eliminate the need to use reduction networks in HEANA, relieving it from related latency and energy overheads. Our evaluation for the inference of four modern CNNs indicates that HEANA provides improvements of atleast 66x and 84x in frames-per-second (FPS) and FPS/W (energy-efficiency), respectively, for equal-area comparisons, on gmean over two MRR-based analog CNN accelerators from prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03247v3</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sairam Sri Vatsavai, Venkata Sai Praneeth Karempudi, Ishan Thakkar</dc:creator>
    </item>
    <item>
      <title>Towards a Dynamic Future with Adaptable Computing and Network Convergence (ACNC)</title>
      <link>https://arxiv.org/abs/2403.07573</link>
      <description>arXiv:2403.07573v2 Announce Type: replace-cross 
Abstract: In the context of advancing 6G, a substantial paradigm shift is anticipated, highlighting comprehensive everything-to-everything interactions characterized by numerous connections and stringent adherence to Quality of Service/Experience (QoS/E) prerequisites. The imminent challenge stems from resource scarcity, prompting a deliberate transition to Computing-Network Convergence (CNC) as an auspicious approach for joint resource orchestration. While CNC-based mechanisms have garnered attention, their effectiveness in realizing future services, particularly in use cases like the Metaverse, may encounter limitations due to the continually changing nature of users, services, and resources. Hence, this paper presents the concept of Adaptable CNC (ACNC) as an autonomous Machine Learning (ML)-aided mechanism crafted for the joint orchestration of computing and network resources, catering to dynamic and voluminous user requests with stringent requirements. ACNC encompasses two primary functionalities: state recognition and context detection. Given the intricate nature of the user-service-computing-network space, the paper employs dimension reduction to generate live, holistic, abstract system states in a hierarchical structure. To address the challenges posed by dynamic changes, Continual Learning (CL) is employed, classifying the system state into contexts controlled by dedicated ML agents, enabling them to operate efficiently. These two functionalities are intricately linked within a closed loop overseen by the End-to-End (E2E) orchestrator to allocate resources. The paper introduces the components of ACNC, proposes a Metaverse scenario to exemplify ACNC's role in resource provisioning with Segment Routing v6 (SRv6), outlines ACNC's workflow, details a numerical analysis for efficiency assessment, and concludes with discussions on relevant challenges and potential avenues for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07573v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masoud Shokrnezhad, Hao Yu, Tarik Taleb, Richard Li, Kyunghan Lee, Jaeseung Song, Cedric Westphal</dc:creator>
    </item>
    <item>
      <title>SocialEyes: Scaling mobile eye-tracking to multi-person social settings</title>
      <link>https://arxiv.org/abs/2407.06345</link>
      <description>arXiv:2407.06345v3 Announce Type: replace-cross 
Abstract: Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60). We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06345v3</guid>
      <category>cs.HC</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shreshth Saxena, Areez Visram, Neil Lobo, Zahid Mirza, Mehak Rafi Khan, Biranugan Pirabaharan, Alexander Nguyen, Lauren K. Fink</dc:creator>
    </item>
    <item>
      <title>Hyper-Compression: Model Compression via Hyperfunction</title>
      <link>https://arxiv.org/abs/2409.00592</link>
      <description>arXiv:2409.00592v2 Announce Type: replace-cross 
Abstract: The rapid growth of large models' size has far outpaced that of GPU memory. To bridge this gap, inspired by the parsimonious relationship between genotype and phenotype, we turn the model compression problem into the issue of parameter representation to propose the so-called hyper-compression. The hyper-compression uses a hyperfunction to represent the parameters of the target network per ergodic theory, that addresses the following approximation problem: if a low-dimensional dynamic system can fill the high-dimensional space eventually. Empirically, the proposed hyper-compression enjoys the following merits: 1) \textbf{P}referable compression ratio; 2) \textbf{N}o post-hoc retraining; 3) \textbf{A}ffordable inference time; and 4) \textbf{S}hort compression time. It compresses LLaMA2-7B in an hour and achieves close-to-int4-quantization performance, without retraining and with a performance drop of less than 1\%. Our work can facilitate the harmony between the scaling law and the stagnation of hardware upgradation in terms of saving both computation and data. We have open-sourced our \href{https://github.com/Juntongkuki/Hyper-Compression.git}{code} for readers' free download and evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00592v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fenglei Fan, Juntong Fan, Dayang Wang, Jingbo Zhang, Zelin Dong, Shijun Zhang, Ge Wang, Tieyong Zeng</dc:creator>
    </item>
    <item>
      <title>A QUBO Formulation for the Generalized LinkedIn Queens and Takuzu/Tango Game</title>
      <link>https://arxiv.org/abs/2410.06429</link>
      <description>arXiv:2410.06429v2 Announce Type: replace-cross 
Abstract: In this paper, we present a QUBO formulation designed to solve a series of generalisations of the LinkedIn queens game, a version of the N-queens problem, for the Takuzu game (or Binairo), for the most recent LinkedIn game, Tango, and for its generalizations. We adapt this formulation for several particular cases of the problem, as Tents &amp; Trees, by trying to optimise the number of variables and interactions, improving the possibility of applying it on quantum hardware by means of Quantum Annealing or the Quantum Approximated Optimization Algorithm (QAOA). We also present two new types of problems, the Coloured Chess Piece Problem and the Max Chess Pieces Problem, with their corresponding QUBO formulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06429v2</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>physics.pop-ph</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Mata Ali, Edgar Mencia</dc:creator>
    </item>
    <item>
      <title>Synthesis of Binary-Input Multi-Valued Output Optical Cascades for Reversible and Quantum Technologies</title>
      <link>https://arxiv.org/abs/2410.18367</link>
      <description>arXiv:2410.18367v3 Announce Type: replace-cross 
Abstract: This paper extends the decomposition from the group theory based methods of Sasao and Saraivanov to design binary input multivalued output quantum cascades realized with optical NOT, SWAP, and Fredkin Gates. We present this method for 3, 5, and 7 valued outputs, but in general it can be used for odd prime valued outputs. The method can be extended to realize hybrid functions with different valued outputs. A class of local transformations is presented that can simplify the final cascade circuits. Using these simplifying transformations, we present an upper bound on the maximum number of gates in an arbitrary $n$-variable input and $k$-valued output function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.18367v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>math.GR</category>
      <pubDate>Tue, 17 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ishani Agarwal, Miroslav Saraivanov, Marek Perkowski</dc:creator>
    </item>
  </channel>
</rss>
