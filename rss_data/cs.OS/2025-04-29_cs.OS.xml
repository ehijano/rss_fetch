<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.OS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.OS</link>
    <description>cs.OS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.OS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Apr 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>From Good to Great: Improving Memory Tiering Performance Through Parameter Tuning</title>
      <link>https://arxiv.org/abs/2504.18714</link>
      <description>arXiv:2504.18714v1 Announce Type: new 
Abstract: Memory tiering systems achieve memory scaling by adding multiple tiers of memory wherein different tiers have different access latencies and bandwidth. For maximum performance, frequently accessed (hot) data must be placed close to the host in faster tiers and infrequently accessed (cold) data can be placed in farther slower memory tiers. Existing tiering solutions employ heuristics and pre-configured thresholds to make data placement and migration decisions. Unfortunately, these systems fail to adapt to different workloads and the underlying hardware, so perform sub-optimally.
  In this paper, we improve performance of memory tiering by using application behavior knowledge to set various parameters (knobs) in existing tiering systems. To do so, we leverage Bayesian Optimization to discover the good performing configurations that capture the application behavior and the underlying hardware characteristics. We find that Bayesian Optimization is able to learn workload behaviors and set the parameter values that result in good performance. We evaluate this approach with existing tiering systems, HeMem and HMSDK. Our evaluation reveals that configuring the parameter values correctly can improve performance by 2x over the same systems with default configurations and 1.56x over state-of-the-art tiering system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18714v1</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konstantinos Kanellis, Sujay Yadalam, Fanchao Chen, Michael Swift, Shivaram Venkataraman</dc:creator>
    </item>
    <item>
      <title>Ariel OS: An Embedded Rust Operating System for Networked Sensors &amp; Multi-Core Microcontrollers</title>
      <link>https://arxiv.org/abs/2504.19662</link>
      <description>arXiv:2504.19662v1 Announce Type: new 
Abstract: Large swaths of low-level system software building blocks originally implemented in C/C++ are currently being swapped for equivalent rewrites in Rust, a relatively more secure and dependable programming language. So far, however, no embedded OS in Rust supports multicore preemptive scheduling on microcontrollers. In this paper, we thus fill this gap with a new operating system: Ariel OS. We describe its design, we provide the source code of its implementation, and we perform micro-benchmarks on the main 32-bit microcontroller architectures: ARM Cortex-M, RISC-V and Espressif Xtensa. We show how our scheduler takes advantage of several cores, while incurring only small overhead on single-core hardware. As such, Ariel OS provides a convenient embedded software platform for small networked devices, for both research and industry practitioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19662v1</guid>
      <category>cs.OS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elena Frank, Kaspar Schleiser, Romain Fouquet, Koen Zandberg, Christian Ams\"uss, Emmanuel Baccelli</dc:creator>
    </item>
    <item>
      <title>Scaling Data Center TCP to Terabits with Laminar</title>
      <link>https://arxiv.org/abs/2504.19058</link>
      <description>arXiv:2504.19058v1 Announce Type: cross 
Abstract: Laminar is the first TCP stack designed for the reconfigurable match-action table (RMT) architecture, widely used in high-speed programmable switches and SmartNICs. Laminar reimagines TCP processing as a pipeline of simple match-action operations, enabling line-rate performance with low latency and minimal energy consumption, while maintaining compatibility with standard TCP and POSIX sockets. Leveraging novel techniques like optimistic concurrency, pseudo segment updates, and bump-in-the-wire processing, Laminar handles the transport logic, including retransmission, reassembly, flow, and congestion control, entirely within the RMT pipeline.
  We prototype Laminar on an Intel Tofino2 switch and demonstrate its scalability to terabit speeds, its flexibility, and robustness to network dynamics. Laminar reaches an unprecedented 25M pkts/sec with a single host core for streaming workloads, enough to exceed 1.6Tbps with 8K MTU. Laminar delivers RDMA-equivalent performance, saving up to 16 host CPU cores versus the TAS kernel-bypass TCP stack with short RPC workloads, while achieving 1.3$\times$ higher peak throughput at 5$\times$ lower 99.99p tail latency. A key-value store on Laminar doubles the throughput-per-watt versus TAS. Demonstrating Laminar's flexibility, we implement TCP stack extensions, including a sequencer API for a linearizable distributed shared log, a new congestion control protocol, and delayed ACKs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19058v1</guid>
      <category>cs.NI</category>
      <category>cs.OS</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rajath Shashidhara, Antoine Kaufmann, Simon Peter</dc:creator>
    </item>
    <item>
      <title>Safe and usable kernel extensions with Rex</title>
      <link>https://arxiv.org/abs/2502.18832</link>
      <description>arXiv:2502.18832v2 Announce Type: replace 
Abstract: Safe kernel extensions have gained significant traction, evolving from simple packet filters to large, complex programs that customize storage, networking, and scheduling. Existing kernel extension mechanisms like eBPF rely on in-kernel verifiers to ensure safety of kernel extensions by static verification using symbolic execution. We identify significant usability issues -- safe extensions being rejected by the verifier -- due to the language-verifier gap, a mismatch between developers' expectation of program safety provided by a contract with the programming language, and the verifier's expectation.
  We present Rex, a new kernel extension framework that closes the language-verifier gap and improves the usability of kernel extensions in terms of programming experience and maintainability. Rex builds upon language-based safety to provide safety properties desired by kernel extensions, along with a lightweight extralingual runtime for properties that are unsuitable for static analysis, including safe exception handling, stack safety, and termination. With Rex, kernel extensions are written in safe Rust and interact with the kernel via a safe interface provided by Rex's kernel crate. No separate static verification is needed. Rex addresses usability issues of eBPF kernel extensions without compromising performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18832v2</guid>
      <category>cs.OS</category>
      <category>cs.PL</category>
      <pubDate>Tue, 29 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinghao Jia, Ruowen Qin, Milo Craun, Egor Lukiyanov, Ayush Bansal, Michael V. Le, Hubertus Franke, Hani Jamjoom, Tianyin Xu, Dan Williams</dc:creator>
    </item>
  </channel>
</rss>
