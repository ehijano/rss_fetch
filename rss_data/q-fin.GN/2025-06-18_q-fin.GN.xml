<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.GN</link>
    <description>q-fin.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 01:41:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimal Incentive for Regulated Production</title>
      <link>https://arxiv.org/abs/2506.14286</link>
      <description>arXiv:2506.14286v1 Announce Type: new 
Abstract: This paper explores stochastic control models in the context of decarbonization within the energy market. We study three progressively complex scenarios: (1) a single firm operating with two technologies-one polluting and one clean,(2)two firms model and (3) two firms without any regulatory incentive. For each setting, we formulate the corresponding stochastic control problem and characterize the firms' optimal strategies in terms of investment and production. The analysis highlights the strategic interactions between firms and the role of incentives in accelerating the transition to cleaner technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14286v1</guid>
      <category>q-fin.GN</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benhao Du, Thomas Treillard, Francois Wang</dc:creator>
    </item>
    <item>
      <title>The Value of Information from Sell-side Analysts</title>
      <link>https://arxiv.org/abs/2411.13813</link>
      <description>arXiv:2411.13813v4 Announce Type: replace 
Abstract: I examine the value of information from sell-side analysts by analyzing a large corpus of their written reports. Using embeddings from state-of-the-art large language models, I show that qualitative information in analyst reports explains above 10% of contemporaneous stock returns out-of-sample, a value that is more economically significant than quantitative forecasts. I then perform a Shapley value decomposition to assess how much each topic within the reports contributes to explaining stock returns. The results show that analysts' income statement analyses account for more than half of the reports' explanatory power. Expressing these findings in economic terms, I estimate that early acquisition of analyst reports can yield significant profits. Analyst information value peaks in the first week following earnings announcements, highlighting their vital role in interpreting new financial data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13813v4</guid>
      <category>q-fin.GN</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Linying Lv</dc:creator>
    </item>
    <item>
      <title>Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks</title>
      <link>https://arxiv.org/abs/2503.16974</link>
      <description>arXiv:2503.16974v3 Announce Type: replace 
Abstract: This study provides the first comprehensive assessment of consistency and reproducibility in Large Language Model (LLM) outputs in finance and accounting research. We evaluate how consistently LLMs produce outputs given identical inputs through extensive experimentation with 50 independent runs across five common tasks: classification, sentiment analysis, summarization, text generation, and prediction. Using three OpenAI models (GPT-3.5-turbo, GPT-4o-mini, and GPT-4o), we generate over 3.4 million outputs from diverse financial source texts and data, covering MD&amp;As, FOMC statements, finance news articles, earnings call transcripts, and financial statements. Our findings reveal substantial but task-dependent consistency, with binary classification and sentiment analysis achieving near-perfect reproducibility, while complex tasks show greater variability. More advanced models do not consistently demonstrate better consistency and reproducibility, with task-specific patterns emerging. LLMs significantly outperform expert human annotators in consistency and maintain high agreement even where human experts significantly disagree. We further find that simple aggregation strategies across 3-5 runs dramatically improve consistency. We also find that aggregation may come with an additional benefit of improved accuracy for sentiment analysis when using newer models. Simulation analysis reveals that despite measurable inconsistency in LLM outputs, downstream statistical inferences remain remarkably robust. These findings address concerns about what we term "G-hacking," the selective reporting of favorable outcomes from multiple Generative AI runs, by demonstrating that such risks are relatively low for finance and accounting tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16974v3</guid>
      <category>q-fin.GN</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Julian Junyan Wang, Victor Xiaoqi Wang</dc:creator>
    </item>
  </channel>
</rss>
