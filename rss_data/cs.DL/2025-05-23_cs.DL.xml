<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 May 2025 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Towards Machine-actionable FAIR Digital Objects with a Typing Model that Enables Operations</title>
      <link>https://arxiv.org/abs/2505.16550</link>
      <description>arXiv:2505.16550v1 Announce Type: new 
Abstract: FAIR Digital Objects support research data management aligned with the FAIR principles. To be machine-actionable, they must support operations that interact with their contents. This can be achieved by associating operations with FAIR-DO data types. However, current typing models and Data Type Registries lack support for type-associated operations. In this work, we introduce a typing model that describes type-associated and technology-agnostic FAIR Digital Object Operations in a machine-actionable way, building and improving on the existing concepts. In addition, we introduce the Integrated Data Type and Operations Registry with Inheritance System, a prototypical implementation of this model that integrates inheritance mechanisms for data types, a rule-based validation system, and the computation of type-operation associations. Our approach significantly improves the machine-actionability of FAIR Digital Objects, paving the way towards dynamic, interoperable, and reproducible research workflows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16550v1</guid>
      <category>cs.DL</category>
      <category>cs.DB</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Inckmann, Nicolas Blumenr\"ohr, Rossella Aversa</dc:creator>
    </item>
    <item>
      <title>Web2Wiki: Characterizing Wikipedia Linking Across the Web</title>
      <link>https://arxiv.org/abs/2505.15837</link>
      <description>arXiv:2505.15837v1 Announce Type: cross 
Abstract: Wikipedia is one of the most visited websites globally, yet its role beyond its own platform remains largely unexplored. In this paper, we present the first large-scale analysis of how Wikipedia is referenced across the Web. Using a dataset from Common Crawl, we identify over 90 million Wikipedia links spanning 1.68% of Web domains and examine their distribution, context, and function. Our analysis of English Wikipedia reveals three key findings: (1) Wikipedia is most frequently cited by news and science websites for informational purposes, while commercial websites reference it less often. (2) The majority of Wikipedia links appear within the main content rather than in boilerplate or user-generated sections, highlighting their role in structured knowledge presentation. (3) Most links (95%) serve as explanatory references rather than as evidence or attribution, reinforcing Wikipedia's function as a background knowledge provider. While this study focuses on English Wikipedia, our publicly released Web2Wiki dataset includes links from multiple language editions, supporting future research on Wikipedia's global influence on the Web.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15837v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Veniamin Veselovsky, Tiziano Piccardi, Ashton Anderson, Robert West, Akhil Arora</dc:creator>
    </item>
    <item>
      <title>Citation Parsing and Analysis with Language Models</title>
      <link>https://arxiv.org/abs/2505.15948</link>
      <description>arXiv:2505.15948v1 Announce Type: cross 
Abstract: A key type of resource needed to address global inequalities in knowledge production and dissemination is a tool that can support journals in understanding how knowledge circulates. The absence of such a tool has resulted in comparatively less information about networks of knowledge sharing in the Global South. In turn, this gap authorizes the exclusion of researchers and scholars from the South in indexing services, reinforcing colonial arrangements that de-center and minoritize those scholars. In order to support citation network tracking on a global scale, we investigate the capacity of open-weight language models to mark up manuscript citations in an indexable format. We assembled a dataset of matched plaintext and annotated citations from preprints and published research papers. Then, we evaluated a number of open-weight language models on the annotation task. We find that, even out of the box, today's language models achieve high levels of accuracy on identifying the constituent components of each citation, outperforming state-of-the-art methods. Moreover, the smallest model we evaluated, Qwen3-0.6B, can parse all fields with high accuracy in $2^5$ passes, suggesting that post-training is likely to be effective in producing small, robust citation parsing models. Such a tool could greatly improve the fidelity of citation networks and thus meaningfully improve research indexing and discovery, as well as further metascientific research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15948v1</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.SI</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parth Sarin, Juan Pablo Alperin</dc:creator>
    </item>
    <item>
      <title>Internal and External Impacts of Natural Language Processing Papers</title>
      <link>https://arxiv.org/abs/2505.16061</link>
      <description>arXiv:2505.16061v1 Announce Type: cross 
Abstract: We investigate the impacts of NLP research published in top-tier conferences (i.e., ACL, EMNLP, and NAACL) from 1979 to 2024. By analyzing citations from research articles and external sources such as patents, media, and policy documents, we examine how different NLP topics are consumed both within the academic community and by the broader public. Our findings reveal that language modeling has the widest internal and external influence, while linguistic foundations have lower impacts. We also observe that internal and external impacts generally align, but topics like ethics, bias, and fairness show significant attention in policy documents with much fewer academic citations. Additionally, external domains exhibit distinct preferences, with patents focusing on practical NLP applications and media and policy documents engaging more with the societal implications of NLP models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16061v1</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Zhang</dc:creator>
    </item>
    <item>
      <title>SC4ANM: Identifying Optimal Section Combinations for Automated Novelty Prediction in Academic Papers</title>
      <link>https://arxiv.org/abs/2505.16330</link>
      <description>arXiv:2505.16330v1 Announce Type: cross 
Abstract: Novelty is a core component of academic papers, and there are multiple perspectives on the assessment of novelty. Existing methods often focus on word or entity combinations, which provide limited insights. The content related to a paper's novelty is typically distributed across different core sections, e.g., Introduction, Methodology and Results. Therefore, exploring the optimal combination of sections for evaluating the novelty of a paper is important for advancing automated novelty assessment. In this paper, we utilize different combinations of sections from academic papers as inputs to drive language models to predict novelty scores. We then analyze the results to determine the optimal section combinations for novelty score prediction. We first employ natural language processing techniques to identify the sectional structure of academic papers, categorizing them into introduction, methods, results, and discussion (IMRaD). Subsequently, we used different combinations of these sections (e.g., introduction and methods) as inputs for pretrained language models (PLMs) and large language models (LLMs), employing novelty scores provided by human expert reviewers as ground truth labels to obtain prediction results. The results indicate that using introduction, results and discussion is most appropriate for assessing the novelty of a paper, while the use of the entire text does not yield significant results. Furthermore, based on the results of the PLMs and LLMs, the introduction and results appear to be the most important section for the task of novelty score prediction. The code and dataset for this paper can be accessed at https://github.com/njust-winchy/SC4ANM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16330v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.eswa.2025.126778</arxiv:DOI>
      <arxiv:journal_reference>Expert Systems With Applications, 2025</arxiv:journal_reference>
      <dc:creator>Wenqing Wu, Chengzhi Zhang, Tong Bao, Yi Zhao</dc:creator>
    </item>
    <item>
      <title>Utilizing citation index and synthetic quality measure to compare Wikipedia languages across various topics</title>
      <link>https://arxiv.org/abs/2505.16506</link>
      <description>arXiv:2505.16506v1 Announce Type: cross 
Abstract: This study presents a comparative analysis of 55 Wikipedia language editions employing a citation index alongside a synthetic quality measure. Specifically, we identified the most significant Wikipedia articles within distinct topical areas, selecting the top 10, top 25, and top 100 most cited articles in each topic and language version. This index was built on the basis of wikilinks between Wikipedia articles in each language version and in order to do that we processed 6.6 billion page-to-page link records. Next, we used a quality score for each Wikipedia article - a synthetic measure scaled from 0 to 100. This approach enabled quality comparison of Wikipedia articles even between language versions with different quality grading schemes. Our results highlight disparities among Wikipedia language editions, revealing strengths and gaps in content coverage and quality across topics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16506v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <category>stat.AP</category>
      <pubDate>Fri, 23 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>W{\l}odzimierz Lewoniewski, Krzysztof W\k{e}cel, Witold Abramowicz</dc:creator>
    </item>
  </channel>
</rss>
