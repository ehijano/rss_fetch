<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Mar 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Robust Second-Order Nonconvex Optimization and Its Application to Low Rank Matrix Sensing</title>
      <link>https://arxiv.org/abs/2403.10547</link>
      <description>arXiv:2403.10547v1 Announce Type: new 
Abstract: Finding an approximate second-order stationary point (SOSP) is a well-studied and fundamental problem in stochastic nonconvex optimization with many applications in machine learning. However, this problem is poorly understood in the presence of outliers, limiting the use of existing nonconvex algorithms in adversarial settings.
  In this paper, we study the problem of finding SOSPs in the strong contamination model, where a constant fraction of datapoints are arbitrarily corrupted. We introduce a general framework for efficiently finding an approximate SOSP with \emph{dimension-independent} accuracy guarantees, using $\widetilde{O}({D^2}/{\epsilon})$ samples where $D$ is the ambient dimension and $\epsilon$ is the fraction of corrupted datapoints.
  As a concrete application of our framework, we apply it to the problem of low rank matrix sensing, developing efficient and provably robust algorithms that can tolerate corruptions in both the sensing matrices and the measurements. In addition, we establish a Statistical Query lower bound providing evidence that the quadratic dependence on $D$ in the sample complexity is necessary for computationally efficient algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10547v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shuyao Li, Yu Cheng, Ilias Diakonikolas, Jelena Diakonikolas, Rong Ge, Stephen J. Wright</dc:creator>
    </item>
    <item>
      <title>Social Optima of a Linear Quadratic Collective Choice Model under Congestion</title>
      <link>https://arxiv.org/abs/2403.10612</link>
      <description>arXiv:2403.10612v1 Announce Type: new 
Abstract: This paper investigates the social optimum for a dynamic linear quadratic collective choice problem where a group of agents choose among multiple alternatives or destinations. The agents' common objective is to minimize the average cost of the entire population. A naive approach to finding a social optimum for this problem involves solving a number of linear quadratic regulator (LQR) problems that increases exponentially with the population size. By exploiting the problem's symmetries, we first show that one can equivalently solve a number of LQR problems equal to the number of destinations, followed by an optimal transport problem parameterized by the fraction of agents choosing each destination. Then, we further reduce the complexity of the solution search by defining an appropriate system of limiting equations, whose solution is used to obtain a strategy shown to be asymptotically optimal as the number of agents becomes large. The model includes a congestion effect captured by a negative quadratic term in the social cost function, which may cause agents to escape to infinity in finite time. Hence, we identify sufficient conditions, independent of the population size, for the existence of the social optimum. Lastly, we investigate the behavior of the model through numerical simulations in different scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10612v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noureddine Toumi, Roland Malham\'e, J\'er\^ome Le Ny</dc:creator>
    </item>
    <item>
      <title>Randomly Activated Proximal Methods for Nonsmooth Convex Minimization</title>
      <link>https://arxiv.org/abs/2403.10673</link>
      <description>arXiv:2403.10673v1 Announce Type: new 
Abstract: We propose stochastic algorithms for solving large scale nonsmooth convex composite minimization problems. They activate at each iteration blocks of randomly selected proximity operators and achieve almost sure convergence of the iterates to a solution without any regularity assumptions. Numerical applications to data analysis problems are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10673v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick L. Combettes, Javier I. Madariaga</dc:creator>
    </item>
    <item>
      <title>PyHySCO: GPU-Enabled Susceptibility Artifact Distortion Correction in Seconds</title>
      <link>https://arxiv.org/abs/2403.10706</link>
      <description>arXiv:2403.10706v1 Announce Type: new 
Abstract: Over the past decade, reversed Gradient Polarity (RGP) methods have become a popular approach for correcting susceptibility artifacts in Echo-Planar Imaging (EPI). Although several post-processing tools for RGP are available, their implementations do not fully leverage recent hardware, algorithmic, and computational advances, leading to correction times of several minutes per image volume. To enable 3D RGP correction in seconds, we introduce PyHySCO, a user-friendly EPI distortion correction tool implemented in PyTorch that enables multi-threading and efficient use of graphics processing units (GPUs). PyHySCO uses a time-tested physical distortion model and mathematical formulation and is, therefore, reliable without training. An algorithmic improvement in PyHySCO is its novel initialization scheme that uses 1D optimal transport. PyHySCO is published under the GNU public license and can be used from the command line or its Python interface. Our extensive numerical validation using 3T and 7T data from the Human Connectome Project suggests that PyHySCO achieves accuracy comparable to that of leading RGP tools at a fraction of the cost. We also validate the new initialization scheme, compare different optimization algorithms, and test the algorithm on different hardware and arithmetic precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10706v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abigail Julian, Lars Ruthotto</dc:creator>
    </item>
    <item>
      <title>Frequency-Reactive Power Optimization Strategy of Grid-forming Offshore Wind Farm Using DRU-HVDC Transmission</title>
      <link>https://arxiv.org/abs/2403.10797</link>
      <description>arXiv:2403.10797v1 Announce Type: new 
Abstract: The diode rectifier unit-based high voltage direct current (DRU-HVDC) transmission with grid-forming (GFM) wind turbine is becoming a promising scheme for offshore wind farm(OWF) integration due to its high reliability and low cost. In this scheme, the AC network of the OWF and the DRU has completely different synchronization mechanisms and power flow characteristics from the traditional power system. To optimize the power flow and reduce the net loss, this paper carries out the power flow modeling and optimization analysis for the DRU-HVDC transmission system with grid-forming OWFs. The influence of the DRU and the GFM wind turbines on the power flow of the system is analyzed. On this basis, improved constraint conditions are proposed and an optimal power flow (OPF) method is established. This method can minimize the power loss by adjusting the reactive power output of each wind turbine and internal network frequency. Finally, based on MATLAB, this paper uses YALMIP toolkit and CPLEX mathematical solver to realize the programming solution of the OPF model proposed in this paper. The results show that the proposed optimization strategy can effectively reduce the power loss of the entire OWF and the transmission system with an optimization ratio of network losses exceeding 25.3%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10797v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhekai Li, Kun Han, Xu Cai, Renxin Yang, Haotian Yu, Kepeng Xia, Lulu Liu</dc:creator>
    </item>
    <item>
      <title>Circle Packing Problem Using Nature-Inspired Optimization Techniques</title>
      <link>https://arxiv.org/abs/2403.10965</link>
      <description>arXiv:2403.10965v1 Announce Type: new 
Abstract: This paper deals with the problem of circle packing, in which the largest radii circle is to be fit in a confined space filled with arbitrary circles of different radii and centers. A circle packing problem is one of a variety of cutting and packing problems. We suggest four different nature-inspired Meta-heuristic algorithms to solve this problem. Algorithms are based on the social behavior of other biology species such as birds, wolves, fireflies, and bats. Moreover, recent advancements in these algorithms are also considered for problem-solving. The circle packing problem is one of the NP-hard problems. It is challenging to solve NP-hard problems exactly, so the proposed algorithms provide an approximate solution within the allotted time. Standard statistical parameters are used for comparison, and simulation and results indicate that the problem is highly non-linear and sensitive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10965v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pulkit Mundra, Veni Goyal, Kusum Deep</dc:creator>
    </item>
    <item>
      <title>Risk Quadrangle and Robust Optimization Based on $\varphi$-Divergence</title>
      <link>https://arxiv.org/abs/2403.10987</link>
      <description>arXiv:2403.10987v1 Announce Type: new 
Abstract: This paper studies robust and distributionally robust optimization based on the extended $\varphi$-divergence under the Fundamental Risk Quadrangle framework. We present the primal and dual representations of the quadrangle elements: risk, deviation, regret, error, and statistic. The framework provides an interpretation of portfolio optimization, classification and regression as robust optimization. We furnish illustrative examples demonstrating that many common problems are included in this framework. The $\varphi$-divergence risk measure used in distributionally robust optimization is a special case. We conduct a case study to visualize the risk envelope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10987v1</guid>
      <category>math.OC</category>
      <category>stat.OT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cheng Peng, Anton Malandii, Stan Uryasev</dc:creator>
    </item>
    <item>
      <title>Towards stochastic realization theory for Generalized Linear Switched Systems with inputs: decomposition into stochastic and deterministic components and existence and uniqueness of innovation form</title>
      <link>https://arxiv.org/abs/2403.11012</link>
      <description>arXiv:2403.11012v1 Announce Type: new 
Abstract: In this paper, we study a class of stochastic Generalized Linear Switched System (GLSS), which includes subclasses of jump-Markov, piecewide-linear and Linear Parameter-Varying (LPV) systems. We prove that the output of such systems can be decomposed into deterministic and stochastic components. Using this decomposition, we show existence of state-space representation in innovation form, and we provide sufficient conditions for such representations to be minimal and unique up to isomorphism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11012v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elie Rouphael, Manas Mejari, Mihaly Petreczky, Lotfi Belkoura</dc:creator>
    </item>
    <item>
      <title>Learning-Based Pricing and Matching for Two-Sided Queues</title>
      <link>https://arxiv.org/abs/2403.11093</link>
      <description>arXiv:2403.11093v1 Announce Type: new 
Abstract: We consider a dynamic system with multiple types of customers and servers. Each type of waiting customer or server joins a separate queue, forming a bipartite graph with customer-side queues and server-side queues. The platform can match the servers and customers if their types are compatible. The matched pairs then leave the system. The platform will charge a customer a price according to their type when they arrive and will pay a server a price according to their type. The arrival rate of each queue is determined by the price according to some unknown demand or supply functions. Our goal is to design pricing and matching algorithms to maximize the profit of the platform with unknown demand and supply functions, while keeping queue lengths of both customers and servers below a predetermined threshold. This system can be used to model two-sided markets such as ride-sharing markets with passengers and drivers. The difficulties of the problem include simultaneous learning and decision making, and the tradeoff between maximizing profit and minimizing queue length. We use a longest-queue-first matching algorithm and propose a learning-based pricing algorithm, which combines gradient-free stochastic projected gradient ascent with bisection search. We prove that our proposed algorithm yields a sublinear regret $\tilde{O}(T^{5/6})$ and queue-length bound $\tilde{O}(T^{2/3})$, where $T$ is the time horizon. We further establish a tradeoff between the regret bound and the queue-length bound: $\tilde{O}(T^{1-\gamma/4})$ versus $\tilde{O}(T^{\gamma})$ for $\gamma \in (0, 2/3].$</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11093v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zixian Yang, Lei Ying</dc:creator>
    </item>
    <item>
      <title>Superlinear Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2403.11115</link>
      <description>arXiv:2403.11115v1 Announce Type: new 
Abstract: This paper proposes several novel optimization algorithms for minimizing a nonlinear objective function. The algorithms are enlightened by the optimal state trajectory of an optimal control problem closely related to the minimized objective function. They are superlinear convergent when appropriate parameters are selected as required. Unlike Newton's method, all of them can be also applied in the case of a singular Hessian matrix. More importantly, by reduction, some of them avoid calculating the inverse of the Hessian matrix or an identical dimension matrix and some of them need only the diagonal elements of the Hessian matrix. In these cases, these algorithms still outperform the gradient descent method. The merits of the proposed optimization algorithm are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11115v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongxia Wang, Yeming Xu, Ziyuan Guo, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Understanding the PDHG Algorithm via High-Resolution Differential Equations</title>
      <link>https://arxiv.org/abs/2403.11139</link>
      <description>arXiv:2403.11139v1 Announce Type: new 
Abstract: The least absolute shrinkage and selection operator (Lasso) is widely recognized across various fields of mathematics and engineering. Its variant, the generalized Lasso, finds extensive application in the fields of statistics, machine learning, image science, and related areas. Among the optimization techniques used to tackle this issue, saddle-point methods stand out, with the primal-dual hybrid gradient (PDHG) algorithm emerging as a particularly popular choice. However, the iterative behavior of PDHG remains poorly understood. In this paper, we employ dimensional analysis to derive a system of high-resolution ordinary differential equations (ODEs) tailored for PDHG. This system effectively captures a key feature of PDHG, the coupled $x$-correction and $y$-correction, distinguishing it from the proximal Arrow-Hurwicz algorithm. The small but essential perturbation ensures that PDHG consistently converges, bypassing the periodic behavior observed in the proximal Arrow-Hurwicz algorithm. Through Lyapunov analysis, We investigate the convergence behavior of the system of high-resolution ODEs and extend our insights to the discrete PDHG algorithm. Our analysis indicates that numerical errors resulting from the implicit scheme serve as a crucial factor affecting the convergence rate and monotonicity of PDHG, showcasing a noteworthy pattern also observed for the Alternating Direction Method of Multipliers (ADMM), as identified in [Li and Shi, 2024]. In addition, we further discover that when one component of the objective function is strongly convex, the iterative average of PDHG converges strongly at a rate $O(1/N)$, where $N$ is the number of iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11139v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bowen Li, Bin Shi</dc:creator>
    </item>
    <item>
      <title>Error bounds for rank-one DNN reformulation of QAP and DC exact penalty approach</title>
      <link>https://arxiv.org/abs/2403.11210</link>
      <description>arXiv:2403.11210v1 Announce Type: new 
Abstract: This paper concerns the quadratic assignment problem (QAP), a class of challenging combinatorial optimization problems. We provide an equivalent rank-one doubly nonnegative (DNN) reformulation with fewer equality constraints, and derive the local error bounds for its feasible set. By leveraging these error bounds, we prove that the penalty problem induced by the difference of convexity (DC) reformulation of the rank-one constraint is a global exact penalty, and so is the penalty problem for its Burer-Monteiro (BM) factorization. As a byproduct, we verify that the penalty problem for the rank-one DNN reformulation proposed in \cite{Jiang21} is a global exact penalty without the calmness assumption. Then, we develop a continuous relaxation approach by seeking approximate stationary points of a finite number of penalty problems for the BM factorization with an augmented Lagrangian method, whose asymptotic convergence certificate is also provided under a mild condition. Numerical comparison with Gurobi for \textbf{131} benchmark instances validates the efficiency of the proposed DC exact penalty approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11210v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yitian Qian, Shaohua Pan, Shujun Bi, Houduo Qi</dc:creator>
    </item>
    <item>
      <title>Lagrange duality on DC evenly convex optimization problems via a generalized conjugation scheme</title>
      <link>https://arxiv.org/abs/2403.11248</link>
      <description>arXiv:2403.11248v1 Announce Type: new 
Abstract: In this paper we study how Lagrange duality is connected to optimization problems whose objective function is the difference of two convex functions, briefly called DC problems. We present two Lagrange dual problems, each of them obtained via a different approach. While one of the duals corresponds to the standard formulation of the Lagrange dual problem, the other is written in terms of conjugate functions. When one of the involved functions in the objective is evenly convex, both problems are equivalent, but this relation is no longer true in the general setting. For this reason, we study conditions ensuring not only weak, but also zero duality and strong duality between the primal and one of the dual problems written using conjugate functions. For the other dual, and due to the fact that weak duality holds by construction, we just develop conditions for zero duality gap and strong duality between the primal DC problem and its (standard) Lagrange dual problem. Finally, we characterize weak and strong duality together with zero duality gap between the primal problem and its Fenchel-Lagrange dual following techniques used throughout the manuscript.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11248v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>M. D. Fajardo, J. Vidal-Nunez</dc:creator>
    </item>
    <item>
      <title>Accelerating Gradient Tracking with Periodic Global Averaging</title>
      <link>https://arxiv.org/abs/2403.11293</link>
      <description>arXiv:2403.11293v1 Announce Type: new 
Abstract: Decentralized optimization algorithms have recently attracted increasing attention due to its wide applications in all areas of science and engineering. In these algorithms, a collection of agents collaborate to minimize the average of a set of heterogeneous cost functions in a decentralized manner. State-of-the-art decentralized algorithms like Gradient Tracking (GT) and Exact Diffusion (ED) involve communication at each iteration. Yet, communication between agents is often expensive, resource intensive, and can be very slow. To this end, several strategies have been developed to balance between communication overhead and convergence rate of decentralized methods. In this paper, we introduce GT-PGA, which incorporates~GT with periodic global averaging. With the additional PGA, the influence of poor network connectivity in the GT algorithm can be compensated or controlled by a careful selection of the global averaging period. Under the stochastic, nonconvex setup, our analysis quantifies the crucial trade-off between the connectivity of network topology and the PGA period. Thus, with a suitable design of the PGA period, GT-PGA improves the convergence rate of vanilla GT. Numerical experiments are conducted to support our theory, and simulation results reveal that the proposed GT-PGA accelerates practical convergence, especially when the network is sparse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11293v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shujing Feng, Xin Jiang</dc:creator>
    </item>
    <item>
      <title>An SDP-based Branch-and-Cut Algorithm for Biclustering</title>
      <link>https://arxiv.org/abs/2403.11351</link>
      <description>arXiv:2403.11351v1 Announce Type: new 
Abstract: Biclustering, also called co-clustering, block clustering, or two-way clustering, involves the simultaneous clustering of both the rows and columns of a data matrix into distinct groups, such that the rows and columns within a group display similar patterns. As a model problem for biclustering, we consider the $k$-densest-disjoint biclique problem, whose goal is to identify $k$ disjoint complete bipartite subgraphs (called bicliques) of a given weighted complete bipartite graph such that the sum of their densities is maximized. To address this problem, we present a tailored branch-and-cut algorithm. For the upper bound routine, we consider a semidefinite programming relaxation and propose valid inequalities to strengthen the bound. We solve this relaxation in a cutting-plane fashion using a first-order method. For the lower bound, we design a maximum weight matching rounding procedure that exploits the solution of the relaxation solved at each node. Computational results on both synthetic and real-world instances show that the proposed algorithm can solve instances approximately 20 times larger than those handled by general-purpose solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11351v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio M. Sudoso</dc:creator>
    </item>
    <item>
      <title>Dynamic Home Care Routing and Scheduling with Uncertain Number of Visits per Referral</title>
      <link>https://arxiv.org/abs/2403.11410</link>
      <description>arXiv:2403.11410v1 Announce Type: new 
Abstract: Despite the rapid growth of the home care industry, research on the scheduling and routing of home care visits in the presence of uncertainty is still limited. This paper investigates a dynamic version of this problem in which the number of referrals and their required number of visits are uncertain. We develop a Markov decision process (MDP) model for the single-nurse problem to minimize the expected weighted sum of the rejection, diversion, overtime, and travel time costs. Since optimally solving the MDP is intractable, we employ an approximate linear program (ALP) to obtain a feasible policy. The typical ALP approach can only solve very small-scale instances of the problem. We derive an intuitively explainable closed-form solution for the optimal ALP parameters in a special case of the problem. Inspired by this form, we provide two heuristic reduction techniques for the ALP model in the general problem to solve large-scale instances in an acceptable time. Numerical results show that the ALP policy outperforms a myopic policy that reflects current practice, and is better than a scenario-based policy in most instances considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11410v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Danial Khorasanian, Jonathan Patrick, Antoine Saur\'e</dc:creator>
    </item>
    <item>
      <title>Formalization of Complexity Analysis of the First-order Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2403.11437</link>
      <description>arXiv:2403.11437v1 Announce Type: new 
Abstract: The convergence rate of various first-order optimization algorithms is a pivotal concern within the numerical optimization community, as it directly reflects the efficiency of these algorithms across different optimization problems. Our goal is making a significant step forward in the formal mathematical representation of optimization techniques using the Lean4 theorem prover. We first formalize the gradient for smooth functions and the subgradient for convex functions on a Hilbert space, laying the groundwork for the accurate formalization of algorithmic structures. Then, we extend our contribution by proving several properties of differentiable convex functions that have not yet been formalized in Mathlib. Finally, a comprehensive formalization of these algorithms is presented. These developments are not only noteworthy on their own but also serve as essential precursors to the formalization of a broader spectrum of numerical algorithms and their applications in machine learning as well as many other areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11437v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Li, Ziyu Wang, Wanyi He, Yuxuan Wu,  Shengyang, Zaiwen Wen</dc:creator>
    </item>
    <item>
      <title>On Linear Threshold Policies for Continuous-Time Dynamic Yield Management</title>
      <link>https://arxiv.org/abs/2403.11443</link>
      <description>arXiv:2403.11443v1 Announce Type: new 
Abstract: We study the finite-horizon continuous-time yield management problem with stationary arrival rates and two customer classes. We consider a class of linear threshold policies proposed by Hodge (2008), in which each online (i.e., less desirable) customer is accepted if and only if the remaining inventory at the customer's arrival time exceeds a threshold that linearly decreases over the selling horizon. Using a discrete-time Markov chain representation of sample paths over inventory-time space, we show that a range of such linear threshold policies achieve uniformly bounded regret. We then generalize this result to analogous policies for the same problem with arbitrarily many customer classes. Numerical simulations demonstrate linear threshold policies' competitiveness with existing heuristics and illustrate the effects of the linear threshold's slope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11443v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipayan Banerjee, Alan Erera, Alejandro Toriello</dc:creator>
    </item>
    <item>
      <title>Forward-backward-forward dynamics for bilevel equilibrium problem</title>
      <link>https://arxiv.org/abs/2403.11493</link>
      <description>arXiv:2403.11493v1 Announce Type: new 
Abstract: We introduce a forward-backward-forward (FBF) algorithm for solving bilevel equilibrium problem associated with bifunctions on a real Hilbert space. This modifies the forward-backward algorithm by relaxing cocoercivity with monotone and Lipschitzness. Further, we present the FBF dynamical system and investigate the generated trajectory's existence, uniqueness and weak convergence. We illustrate the proposed method for equilibrium problem under saddle point constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11493v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kanchan Mittal, Pankaj Gautam, V. Vetrivel</dc:creator>
    </item>
    <item>
      <title>Towards Scalable Semidefinite Programming: Optimal Metric ADMM with A Worst-case Performance Guarantee</title>
      <link>https://arxiv.org/abs/2403.11533</link>
      <description>arXiv:2403.11533v1 Announce Type: new 
Abstract: Despite the numerous uses of semidefinite programming (SDP) and its universal solvability via interior point methods (IPMs), it is rarely applied to practical large-scale problems. This mainly owes to the computational cost of IPMs that increases in a bad exponential way with the data size. While first-order algorithms such as ADMM can alleviate this issue, but the scalability improvement appears far not enough. In this work, we aim to achieve extra acceleration for ADMM by appealing to a non-Euclidean metric space, while maintaining everything in closed-form expressions. The efficiency gain comes from the extra degrees of freedom of a variable metric compared to a scalar step-size, which allows us to capture some additional ill-conditioning structures.
  On the application side, we consider the quadratically constrained quadratic program (QCQP), which naturally appears in an SDP form after a dualization procedure. This technique, known as semidefinite relaxation, has important uses across different fields, particularly in wireless communications. Numerically, we observe that the scalability property is significantly improved. Depending on the data generation process, the extra acceleration can easily surpass the scalar-parameter efficiency limit, and the advantage is rapidly increasing as the data conditioning becomes worse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11533v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Ran, Stefan Vlaski, Wei Dai</dc:creator>
    </item>
    <item>
      <title>Norm-induced Cuts: Optimization with Lipschitzian Black-box Functions</title>
      <link>https://arxiv.org/abs/2403.11546</link>
      <description>arXiv:2403.11546v1 Announce Type: new 
Abstract: In this paper, we consider a finite dimensional optimization problem minimizing a continuous objective on a compact domain subject to a multi-dimensional constraint function. For the latter, we only assume the availability of a Lipschitz property. In recent literature methods based on non-convex outer approximation are proposed for tackling one dimensional equality constraints on bounded polyhedral domains, which are Lipschitz with respect to the maximum norm. To the best of our knowledge, however, there exists no non-convex outer approximation method for a general problem class. We introduce a meta-level solution framework to solve such problems and tackle the underlying theoretical foundations. Considering the feasible domain without the constraint function as manageable, our method relaxes the multidimensional constraint and iteratively refines the feasible region by means of norm-induced cuts, relying on an oracle for the resulting sub-problems. We show the method's correctness and investigate the problem complexity. In order to account for discussions about functionality, limits, and extensions, we present computational examples including illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11546v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian G\"o{\ss}, Alexander Martin, Sebastian Pokutta, Kartikey Sharma</dc:creator>
    </item>
    <item>
      <title>Distributed Adaptive Gradient Algorithm with Gradient Tracking for Stochastic Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.11557</link>
      <description>arXiv:2403.11557v1 Announce Type: new 
Abstract: This paper considers a distributed stochastic non-convex optimization problem, where the nodes in a network cooperatively minimize a sum of $L$-smooth local cost functions with sparse gradients. By adaptively adjusting the stepsizes according to the historical (possibly sparse) gradients, a distributed adaptive gradient algorithm is proposed, in which a gradient tracking estimator is used to handle the heterogeneity between different local cost functions. We establish an upper bound on the optimality gap, which indicates that our proposed algorithm can reach a first-order stationary solution dependent on the upper bound on the variance of the stochastic gradients. Finally, numerical examples are presented to illustrate the effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11557v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyu Han, Kun Liu, Yeming Lin, Yuanqing Xia</dc:creator>
    </item>
    <item>
      <title>Decentralized Stochastic Subgradient Methods for Nonsmooth Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2403.11565</link>
      <description>arXiv:2403.11565v1 Announce Type: new 
Abstract: In this paper, we concentrate on decentralized optimization problems with nonconvex and nonsmooth objective functions, especially on the decentralized training of nonsmooth neural networks. We introduce a unified framework, named DSM, to analyze the global convergence of decentralized stochastic subgradient methods. We prove the global convergence of our proposed framework under mild conditions, by establishing that the generated sequence asymptotically approximates the trajectories of its associated differential inclusion. Furthermore, we establish that our proposed framework encompasses a wide range of existing efficient decentralized subgradient methods, including decentralized stochastic subgradient descent (DSGD), DSGD with gradient-tracking technique (DSGD-T), and DSGD with momentum (DSGDm). In addition, we introduce SignSGD employing the sign map to regularize the update directions in DSGDm, and show it is enclosed in our proposed framework. Consequently, our convergence results establish, for the first time, global convergence of these methods when applied to nonsmooth nonconvex objectives. Preliminary numerical experiments demonstrate that our proposed framework yields highly efficient decentralized subgradient methods with convergence guarantees in the training of nonsmooth neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11565v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Zhang, Nachuan Xiao, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Citerion of Internal Stability of Linear Formations</title>
      <link>https://arxiv.org/abs/2403.11605</link>
      <description>arXiv:2403.11605v1 Announce Type: new 
Abstract: Necessary and sufficient conditions for the internal stability of formations whose dynamics are obtained is determined by linear differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11605v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. V. Lakeyev</dc:creator>
    </item>
    <item>
      <title>A Quantile Neural Network Framework for Two-stage Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2403.11707</link>
      <description>arXiv:2403.11707v1 Announce Type: new 
Abstract: Two-stage stochastic programming is a popular framework for optimization under uncertainty, where decision variables are split between first-stage decisions, and second-stage (or recourse) decisions, with the latter being adjusted after uncertainty is realized. These problems are often formulated using Sample Average Approximation (SAA), where uncertainty is modeled as a finite set of scenarios, resulting in a large "monolithic" problem, i.e., where the model is repeated for each scenario. The resulting models can be challenging to solve, and several problem-specific decomposition approaches have been proposed. An alternative approach is to approximate the expected second-stage objective value using a surrogate model, which can then be embedded in the first-stage problem to produce good heuristic solutions. In this work, we propose to instead model the distribution of the second-stage objective, specifically using a quantile neural network. Embedding this distributional approximation enables capturing uncertainty and is not limited to expected-value optimization, e.g., the proposed approach enables optimization of the Conditional Value at Risk (CVaR). We discuss optimization formulations for embedding the quantile neural network and demonstrate the effectiveness of the proposed framework using several computational case studies including a set of mixed-integer optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11707v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Antonio Alc\'antara, Carlos Ruiz, Calvin Tsay</dc:creator>
    </item>
    <item>
      <title>Exploiting Agent Symmetries for Performance Analysis of Distributed Optimization Methods</title>
      <link>https://arxiv.org/abs/2403.11724</link>
      <description>arXiv:2403.11724v1 Announce Type: new 
Abstract: We show that, in many settings, the worst-case performance of a distributed optimization algorithm is independent of the number of agents in the system, and can thus be computed in the fundamental case with just two agents. This result relies on a novel approach that systematically exploits symmetries in worst-case performance computation, framed as Semidefinite Programming (SDP) via the Performance Estimation Problem (PEP) framework. Harnessing agent symmetries in the PEP yields compact problems whose size is independent of the number of agents in the system. When all agents are equivalent in the problem, we establish the explicit conditions under which the resulting worst-case performance is independent of the number of agents and is therefore equivalent to the basic case with two agents. Our compact PEP formulation also allows the consideration of multiple equivalence classes of agents, and its size only depends on the number of equivalence classes. This enables practical and automated performance analysis of distributed algorithms in numerous complex and realistic settings, such as the analysis of the worst agent performance. We leverage this new tool to analyze the performance of the EXTRA algorithm in advanced settings and its scalability with the number of agents, providing a tighter analysis and deeper understanding of the algorithm performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11724v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastien Colla, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>A First-Order Gradient Approach for the Connectivity Analysis of Weighted Graphs</title>
      <link>https://arxiv.org/abs/2403.11744</link>
      <description>arXiv:2403.11744v1 Announce Type: new 
Abstract: Weighted graphs are commonly used to model various complex systems, including social networks, power grids, transportation networks, and biological systems. In many applications, the connectivity of these networks can be expressed through the Mean First Passage Times (MFPTs) of a Markov chain modeling a random walker on the graph. In this paper, we generalize the network metrics based on Markov chains' MFPTs and extend them to networks affected by uncertainty, in which edges may fail and hence not be present according to a pre-determined stochastic model. To find optimally connected graphs, we present a parameterization-free method for optimizing the MFPTs of the underlying Markov chain. More specifically, we show how to extend the Simultaneous Perturbation Stochastic Approximation (SPSA) algorithm in the context of Markov chain optimization. The proposed algorithm is suitable for both fixed and random networks. Using various numerical experiments, we demonstrate scalability compared to established benchmarks. Importantly, our algorithm finds an optimal solution without requiring prior knowledge of edge failure probabilities, allowing for an online optimization approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11744v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian P. C. Franssen, Alessandro Zocca, Bernd F. Heidergott</dc:creator>
    </item>
    <item>
      <title>Convex Co-Design of Control Barrier Function and Safe Feedback Controller Under Input Constraints</title>
      <link>https://arxiv.org/abs/2403.11763</link>
      <description>arXiv:2403.11763v1 Announce Type: new 
Abstract: We study the problem of co-designing control barrier functions (CBF) and linear state feedback controllers for continuous-time linear systems. We achieve this by means of a single semi-definite optimization program. Our formulation can handle mixed-relative degree problems without requiring an explicit safe controller. Different L-norm based input limitations can be introduced as convex constraints in the proposed program. We demonstrate our results on an omni-directional car numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11763v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Han Wang, Kostas Margellos, Antonis Papachristodoulou, Claudio De Persis</dc:creator>
    </item>
    <item>
      <title>Detecting immersed obstacle in Stokes fluid flow using the coupled complex boundary method</title>
      <link>https://arxiv.org/abs/2403.11819</link>
      <description>arXiv:2403.11819v1 Announce Type: new 
Abstract: A non-conventional shape optimization approach is introduced to address the identification of an obstacle immersed in a fluid described by the Stokes equation within a larger bounded domain, relying on boundary measurements on the accessible surface. The approach employs tools from shape optimization, utilizing the coupled complex boundary method to transform the over-specified problem into a complex boundary value problem by incorporating a complex Robin boundary condition. This condition is derived by coupling the Dirichlet and Neumann boundary conditions along the accessible boundary. The identification of the obstacle involves optimizing a cost function constructed based on the imaginary part of the solution across the entire domain. The subsequent calculation of the shape gradient of this cost function, rigorously performed via the rearrangement method, enables the iterative solution of the optimization problem using a Sobolev gradient descent algorithm. The feasibility of the method is illustrated through numerical experiments in both two and three spatial dimensions, demonstrating its effectiveness in reconstructing obstacles with pronounced concavities under high-level noise-contaminated data, all without perimeter or volume functional penalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11819v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius Fergy Tiongson Rabago, Lekbir Afraites, Hirofumi Notsu</dc:creator>
    </item>
    <item>
      <title>An Optimal-Control Approach to Infinite-Horizon Restless Bandits: Achieving Asymptotic Optimality with Minimal Assumptions</title>
      <link>https://arxiv.org/abs/2403.11913</link>
      <description>arXiv:2403.11913v1 Announce Type: new 
Abstract: We adopt an optimal-control framework for addressing the undiscounted infinite-horizon discrete-time restless $N$-armed bandit problem. Unlike most studies that rely on constructing policies based on the relaxed single-armed Markov Decision Process (MDP), we propose relaxing the entire bandit MDP as an optimal-control problem through the certainty equivalence control principle. Our main contribution is demonstrating that the reachability of an optimal stationary state within the optimal-control problem is a sufficient condition for the existence of an asymptotically optimal policy. Such a policy can be devised using an "align and steer" strategy. This reachability assumption is less stringent than any prior assumptions imposed on the arm-level MDP, notably the unichain condition is no longer needed. Through numerical examples, we show that employing model predictive control for steering generally results in superior performance compared to other existing policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11913v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chen YAN</dc:creator>
    </item>
    <item>
      <title>The Share-a-Ride Problem with mixed ride-hailing and logistic vehicles</title>
      <link>https://arxiv.org/abs/2403.11944</link>
      <description>arXiv:2403.11944v1 Announce Type: new 
Abstract: This study explores the potential of using ride-hailing vehicles (RVs) for integrated passenger and freight transport based on shared mobility. In this crowd-sourced mode, ride-hailing platforms can profit from parcel delivery services, and logistics companies can reduce operational costs by utilizing the capacities of RVs. The Share-a-Ride problem with ride-hailing and logistic vehicles (SARP-RL) determines the number of logistic vehicles (LVs) and the assignment of passenger/parcel requests to RVs and LVs, aiming at maximizing the total RV profits and minimizing logistic costs. An exact solution framework is proposed by (1) generating a feasible trip that serves a given set of requests at maximal profits; (2) generating all feasible trips for the entire set of passenger and parcel requests via an efficient enumeration method; and (3) finding all Pareto-optimal solutions of the bi-objective problem via an $\varepsilon$-constraint method. Not only is the proposed method exact, it also converts the NP-hard problem to a simple vehicle-trip matching problem. More importantly, the total computational time can be compressed to an arbitrary degree via straightforward parallelization. A case study of the Manhattan network demonstrates the solution characteristics of SARP-RL. The results indicate that: (i) Coordinating RV and LV operations to serve passenger and parcel requests (SARP-RL) can simultaneously reduce logistic costs and increase RV profits. (ii) Key factors influencing the performance of SARP-RL include the RV fleet size, spatial distribution of parcel requests, passenger/parcel request ratio, and unit price of transport service, which are quantitatively analyzed to offer managerial insights for real-world implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11944v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wen Ji, Shenglin Liu, Ke Han, Tao Liu</dc:creator>
    </item>
    <item>
      <title>No-gap second-order conditions for minimization problems in spaces of measures</title>
      <link>https://arxiv.org/abs/2403.12001</link>
      <description>arXiv:2403.12001v1 Announce Type: new 
Abstract: Over the last years, minimization problems over spaces of measures have received increased interest due to their relevance in the context of inverse problems, optimal control and machine learning. A fundamental role in their numerical analysis is played by the assumption that the optimal dual state admits finitely many global extrema and satisfies a second-order sufficient optimality condition in each one of them. In this work, we show the full equivalence of these structural assumptions to a no-gap second-order condition involving the second subderivative of the Radon norm as well as to a local quadratic growth property of the objective functional with respect to the bounded Lipschitz norm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12001v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gerd Wachsmuth, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>Depreciation Cost is a Poor Proxy for Revenue Lost to Aging in Grid Storage Optimization</title>
      <link>https://arxiv.org/abs/2403.10617</link>
      <description>arXiv:2403.10617v1 Announce Type: cross 
Abstract: Dispatch of a grid energy storage system for arbitrage is typically formulated into a rolling-horizon optimization problem that includes a battery aging model within the cost function. Quantifying degradation as a depreciation cost in the objective can increase overall profits by extending lifetime. However, depreciation is just a proxy metric for battery aging; it is used because simulating the entire system life is challenging due to computational complexity and the absence of decades of future data. In cases where the depreciation cost does not match the loss of possible future revenue, different optimal usage profiles result and this reduces overall profit significantly compared to the best case (e.g., by 30-50%). Representing battery degradation perfectly within the rolling-horizon optimization does not resolve this - in addition, the economic cost of degradation throughout life should be carefully considered. For energy arbitrage, optimal economic dispatch requires a trade-off between overuse, leading to high return rate but short lifetime, vs. underuse, leading to a long but not profitable life. We reveal the intuition behind selecting representative costs for the objective function, and propose a simple moving average filter method to estimate degradation cost. Results show that this better captures peak revenue, assuming reliable price forecasts are available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10617v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Volkan Kumtepeli, Holger Hesse, Thomas Morstyn, Seyyed Mostafa Nosratabadi, Marko Aunedi, David A. Howey</dc:creator>
    </item>
    <item>
      <title>Default Resilience and Worst-Case Effects in Financial Networks</title>
      <link>https://arxiv.org/abs/2403.10631</link>
      <description>arXiv:2403.10631v1 Announce Type: cross 
Abstract: In this paper we analyze the resilience of a network of banks to joint price fluctuations of the external assets in which they have shared exposures, and evaluate the worst-case effects of the possible default contagion. Indeed, when the prices of certain external assets either decrease or increase, all banks exposed to them experience varying degrees of simultaneous shocks to their balance sheets. These coordinated and structured shocks have the potential to exacerbate the likelihood of defaults. In this context, we introduce first a concept of {default resilience margin}, $\epsilon^*$, i.e., the maximum amplitude of asset prices fluctuations that the network can tolerate without generating defaults. Such threshold value is computed by considering two different measures of price fluctuations, one based on the maximum individual variation of each asset, and the other based on the sum of all the asset's absolute variations. For any price perturbation having amplitude no larger than $\epsilon^*$, the network absorbs the shocks remaining default free. When the perturbation amplitude goes beyond $\epsilon^*$, however, defaults may occur. In this case we find the worst-case systemic loss, that is, the total unpaid debt under the most severe price variation of given magnitude. Computation of both the threshold level $\epsilon^*$ and of the worst-case loss and of a corresponding worst-case asset price scenario, amounts to solving suitable linear programming problems.}</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10631v1</guid>
      <category>q-fin.RM</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giuseppe Calafiore, Giulia Fracastoro, Anton Proskurnikov</dc:creator>
    </item>
    <item>
      <title>A Primal-Dual Algorithm for Faster Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2403.10763</link>
      <description>arXiv:2403.10763v1 Announce Type: cross 
Abstract: We consider the penalized distributionally robust optimization (DRO) problem with a closed, convex uncertainty set, a setting that encompasses the $f$-DRO, Wasserstein-DRO, and spectral/$L$-risk formulations used in practice. We present Drago, a stochastic primal-dual algorithm that achieves a state-of-the-art linear convergence rate on strongly convex-strongly concave DRO problems. The method combines both randomized and cyclic components with mini-batching, which effectively handles the unique asymmetric nature of the primal and dual problems in DRO. We support our theoretical results with numerical benchmarks in classification and regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10763v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ronak Mehta, Jelena Diakonikolas, Zaid Harchaoui</dc:creator>
    </item>
    <item>
      <title>Inverse learning of black-box aggregator for robust Nash equilibrium</title>
      <link>https://arxiv.org/abs/2403.10980</link>
      <description>arXiv:2403.10980v1 Announce Type: cross 
Abstract: In this note, we investigate the robustness of Nash equilibria (NE) in multi-player aggregative games with coupling constraints. There are many algorithms for computing an NE of an aggregative game given a known aggregator. When the coupling parameters are affected by uncertainty, robust NE need to be computed. We consider a scenario where players' weight in the aggregator is unknown, making the aggregator kind of "a black box". We pursue a suitable learning approach to estimate the unknown aggregator by proposing an inverse variational inequality-based relationship. We then utilize the counterpart to reconstruct the game and obtain first-order conditions for robust NE in the worst case. Furthermore, we characterize the generalization property of the learning methodology via an upper bound on the violation probability. Simulation experiments show the effectiveness of the proposed inverse learning approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10980v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanpu Chen, Gehui Xu, Fengxiang He, Dacheng Tao, Thomas Parisini, Karl Henrik Johansson</dc:creator>
    </item>
    <item>
      <title>MPC for Tracking applied to rendezvous with non-cooperative tumbling targets ensuring stability and feasibility</title>
      <link>https://arxiv.org/abs/2403.10986</link>
      <description>arXiv:2403.10986v1 Announce Type: cross 
Abstract: A Model Predictive Controller for Tracking is introduced for rendezvous with non-cooperative tumbling targets in active debris removal applications. The target's three-dimensional non-periodic rotational dynamics as well as other state and control constraints are considered. The approach is based on applying an intermediate coordinate transformation that eliminates the time-dependency due to rotations in the constraints. The control law is then found as the solution to a QP problem with linear constraints and dynamics, as derived from the HCW equations, that provides feasibility and stability guarantees by means of a terminal LQR and dead-beat region. The proposed control algorithm performs well in a realistic simulation scenario, namely a near rendezvous with the Envisat spacecraft.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10986v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jose Antonio Rebollo, Rafael Vazquez, Ignacio Alvarado, Daniel Limon</dc:creator>
    </item>
    <item>
      <title>Stellarator Optimization with Constraints</title>
      <link>https://arxiv.org/abs/2403.11033</link>
      <description>arXiv:2403.11033v1 Announce Type: cross 
Abstract: In this work we consider the problem of optimizing a stellarator subject to hard constraints on the design variables and physics properties of the equilibrium. We survey current numerical methods for handling these constraints, and summarize a number of methods from the wider optimization community that have not been used extensively for stellarator optimization thus far. We demonstrate the utility of new methods of constrained optimization by optimizing a QA stellarator for favorable physics properties while preventing strong shaping of the plasma boundary which can be difficult to create with external current sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11033v1</guid>
      <category>physics.plasm-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rory Conlin, Patrick Kim, Daniel W. Dudt, Dario Panici, Egemen Kolemen</dc:creator>
    </item>
    <item>
      <title>A Simple Mixture Policy Parameterization for Improving Sample Efficiency of CVaR Optimization</title>
      <link>https://arxiv.org/abs/2403.11062</link>
      <description>arXiv:2403.11062v1 Announce Type: cross 
Abstract: Reinforcement learning algorithms utilizing policy gradients (PG) to optimize Conditional Value at Risk (CVaR) face significant challenges with sample inefficiency, hindering their practical applications. This inefficiency stems from two main facts: a focus on tail-end performance that overlooks many sampled trajectories, and the potential of gradient vanishing when the lower tail of the return distribution is overly flat. To address these challenges, we propose a simple mixture policy parameterization. This method integrates a risk-neutral policy with an adjustable policy to form a risk-averse policy. By employing this strategy, all collected trajectories can be utilized for policy updating, and the issue of vanishing gradients is counteracted by stimulating higher returns through the risk-neutral component, thus lifting the tail and preventing flatness. Our empirical study reveals that this mixture parameterization is uniquely effective across a variety of benchmark domains. Specifically, it excels in identifying risk-averse CVaR policies in some Mujoco environments where the traditional CVaR-PG fails to learn a reasonable policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11062v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yudong Luo, Yangchen Pan, Han Wang, Philip Torr, Pascal Poupart</dc:creator>
    </item>
    <item>
      <title>Barely Random Algorithms for Metrical Task Systems</title>
      <link>https://arxiv.org/abs/2403.11267</link>
      <description>arXiv:2403.11267v1 Announce Type: cross 
Abstract: We consider metrical task systems on general metric spaces with $n$ points, and show that any fully randomized algorithm can be turned into a randomized algorithm that uses only $2\log n$ random bits, and achieves the same competitive ratio up to a factor $2$. This provides the first order-optimal barely random algorithms for metrical task systems, i.e. which use a number of random bits that does not depend on the number of requests addressed to the system. We put forward an equivalent view that we call collective metrical task systems where $k$ agents in a metrical task system team up, and suffer the average cost paid by each agent. Our results imply that such team can be $O(\log n^2)$-competitive, as soon as $k\geq n^2$ (in comparison, a single agent is $\Omega(n)$-competitive at best). We discuss implications on various aspects of online decision making such as: distributed systems, transaction costs, and advice complexity, suggesting broad applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11267v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Romain Cosson, Laurent Massouli\'e</dc:creator>
    </item>
    <item>
      <title>Span-Based Optimal Sample Complexity for Weakly Communicating and General Average Reward MDPs</title>
      <link>https://arxiv.org/abs/2403.11477</link>
      <description>arXiv:2403.11477v1 Announce Type: cross 
Abstract: We study the sample complexity of learning an $\epsilon$-optimal policy in an average-reward Markov decision process (MDP) under a generative model. For weakly communicating MDPs, we establish the complexity bound $\tilde{O}(SA\frac{H}{\epsilon^2})$, where $H$ is the span of the bias function of the optimal policy and $SA$ is the cardinality of the state-action space. Our result is the first that is minimax optimal (up to log factors) in all parameters $S,A,H$ and $\epsilon$, improving on existing work that either assumes uniformly bounded mixing times for all policies or has suboptimal dependence on the parameters. We further investigate sample complexity in general (non-weakly-communicating) average-reward MDPs. We argue a new transient time parameter $B$ is necessary, establish an $\tilde{O}(SA\frac{B+H}{\epsilon^2})$ complexity bound, and prove a matching (up to log factors) minimax lower bound. Both results are based on reducing the average-reward MDP to a discounted MDP, which requires new ideas in the general setting. To establish the optimality of this reduction, we develop improved bounds for $\gamma$-discounted MDPs, showing that $\tilde{\Omega}\left(SA\frac{H}{(1-\gamma)^2\epsilon^2}\right)$ samples suffice to learn an $\epsilon$-optimal policy in weakly communicating MDPs under the regime that $\gamma\geq 1-1/H$, and $\tilde{\Omega}\left(SA\frac{B+H}{(1-\gamma)^2\epsilon^2}\right)$ samples suffice in general MDPs when $\gamma\geq 1-\frac{1}{B+H}$. Both these results circumvent the well-known lower bound of $\tilde{\Omega}\left(SA\frac{1}{(1-\gamma)^3\epsilon^2}\right)$ for arbitrary $\gamma$-discounted MDPs. Our analysis develops upper bounds on certain instance-dependent variance parameters in terms of the span and transient time parameters. The weakly communicating bounds are tighter than those based on the mixing time or diameter of the MDP and may be of broader use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11477v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Zurek, Yudong Chen</dc:creator>
    </item>
    <item>
      <title>Primal-dual interior-point algorithm for linearly constrained convex optimization based on a parametric algebraic transformation</title>
      <link>https://arxiv.org/abs/2403.11684</link>
      <description>arXiv:2403.11684v1 Announce Type: cross 
Abstract: In this paper, we present an interior point algorithm with a full-Newton step for solving a linearly constrained convex optimization problem, in which we propose a generalization of the work of Kheirfam and Nasrollahi \cite{kheirfam2018full}, that consists in determining the descent directions through a parametric algebraic transformation. The work concludes with a complete study of the convergence of the algorithm and its complexity, where we show that the obtained algorithm achieves a polynomial complexity bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11684v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Aicha Kraria, Bachir Merikhi, Djamel Benterki</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Implicit Differentiation: Deterministic and Stochastic Convergence Rates</title>
      <link>https://arxiv.org/abs/2403.11687</link>
      <description>arXiv:2403.11687v1 Announce Type: cross 
Abstract: We study the problem of efficiently computing the derivative of the fixed-point of a parametric non-differentiable contraction map. This problem has wide applications in machine learning, including hyperparameter optimization, meta-learning and data poisoning attacks. We analyze two popular approaches: iterative differentiation (ITD) and approximate implicit differentiation (AID). A key challenge behind the nonsmooth setting is that the chain rule does not hold anymore. Building upon the recent work by Bolte et al. (2022), who proved the linear convergence of non-differentiable ITD, we provide refined linear convergence rates for both ITD and AID in the deterministic case. We further introduce NSID, a new method to compute the implicit derivative when the fixed point is defined as the composition of an outer map and an inner map which is accessible only through a stochastic unbiased estimator. We establish rates for the convergence of NSID to the true derivative, encompassing the best available rates in the smooth setting. We present illustrative experiments confirming our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11687v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Grazzi, Massimiliano Pontil, Saverio Salzo</dc:creator>
    </item>
    <item>
      <title>On the Convergence of A Data-Driven Regularized Stochastic Gradient Descent for Nonlinear Ill-Posed Problems</title>
      <link>https://arxiv.org/abs/2403.11787</link>
      <description>arXiv:2403.11787v1 Announce Type: cross 
Abstract: Stochastic gradient descent (SGD) is a promising method for solving large-scale inverse problems, due to its excellent scalability with respect to data size. In this work, we analyze a new data-driven regularized stochastic gradient descent for the efficient numerical solution of a class of nonlinear ill-posed inverse problems in infinite dimensional Hilbert spaces. At each step of the iteration, the method randomly selects one equation from the nonlinear system combined with a corresponding equation from the learned system based on training data to obtain a stochastic estimate of the gradient and then performs a descent step with the estimated gradient. We prove the regularizing property of this method under the tangential cone condition and a priori parameter choice and then derive the convergence rates under the additional source condition and range invariance conditions. Several numerical experiments are provided to complement the analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11787v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zehui Zhou</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Solutions of Constrained Learning Problems</title>
      <link>https://arxiv.org/abs/2403.11844</link>
      <description>arXiv:2403.11844v1 Announce Type: cross 
Abstract: With the widespread adoption of machine learning systems, the need to curtail their behavior has become increasingly apparent. This is evidenced by recent advancements towards developing models that satisfy robustness, safety, and fairness requirements. These requirements can be imposed (with generalization guarantees) by formulating constrained learning problems that can then be tackled by dual ascent algorithms. Yet, though these algorithms converge in objective value, even in non-convex settings, they cannot guarantee that their outcome is feasible. Doing so requires randomizing over all iterates, which is impractical in virtually any modern applications. Still, final iterates have been observed to perform well in practice. In this work, we address this gap between theory and practice by characterizing the constraint violation of Lagrangian minimizers associated with optimal dual variables, despite lack of convexity. To do this, we leverage the fact that non-convex, finite-dimensional constrained learning problems can be seen as parametrizations of convex, functional problems. Our results show that rich parametrizations effectively mitigate the issue of feasibility in dual methods, shedding light on prior empirical successes of dual learning. We illustrate our findings in fair learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11844v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Elenter, Luiz F. O. Chamon, Alejandro Ribeiro</dc:creator>
    </item>
    <item>
      <title>Numerical method for nonlinear Kolmogorov PDEs via sensitivity analysis</title>
      <link>https://arxiv.org/abs/2403.11910</link>
      <description>arXiv:2403.11910v1 Announce Type: cross 
Abstract: We examine nonlinear Kolmogorov partial differential equations (PDEs). Here the nonlinear part of the PDE comes from its Hamiltonian where one maximizes over all possible drift and diffusion coefficients which fall within a $\varepsilon$-neighborhood of pre-specified baseline coefficients. Our goal is to quantify and compute how sensitive those PDEs are to such a small nonlinearity, and then use the results to develop an efficient numerical method for their approximation. We show that as $\varepsilon\downarrow 0$, the nonlinear Kolmogorov PDE equals the linear Kolmogorov PDE defined with respect to the corresponding baseline coefficients plus $\varepsilon$ times a correction term which can be also characterized by the solution of another linear Kolmogorov PDE involving the baseline coefficients. As these linear Kolmogorov PDEs can be efficiently solved in high-dimensions by exploiting their Feynman-Kac representation, our derived sensitivity analysis then provides a Monte Carlo based numerical method which can efficiently solve these nonlinear Kolmogorov equations. We provide numerical examples in up to 100 dimensions to empirically demonstrate the applicability of our numerical method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11910v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Bartl, Ariel Neufeld, Kyunghyun Park</dc:creator>
    </item>
    <item>
      <title>Relation between Value and Age of Information in Feedback Control</title>
      <link>https://arxiv.org/abs/2403.11926</link>
      <description>arXiv:2403.11926v1 Announce Type: cross 
Abstract: In this chapter, we investigate the value of information as a more comprehensive instrument than the age of information for optimally shaping the information flow in a networked control system. In particular, we quantify the value of information based on the variation in a value function, and discuss the structural properties of this metric. Through our analysis, we establish the mathematical relation between the value of information and the age of information. We prove that the value of information is in general a function of an estimation discrepancy that depends on the age of information and the primitive variables. In addition, we prove that there exists a condition under which the value of information becomes completely expressible in terms of the age of information. Nonetheless, we show that this condition is not achievable without a degradation in the performance of the system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11926v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, John S. Baras, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Consistency of Value of Information: Effects of Packet Loss and Time Delay in Networked Control Systems Tasks</title>
      <link>https://arxiv.org/abs/2403.11932</link>
      <description>arXiv:2403.11932v1 Announce Type: cross 
Abstract: In this chapter, we study the consistency of the value of information$\unicode{x2014}$a semantic metric that claims to determine the right piece of information in networked control systems tasks$\unicode{x2014}$in a lossy and delayed communication regime. Our analysis begins with a focus on state estimation, and subsequently extends to feedback control. To that end, we make a causal tradeoff between the packet rate and the mean square error. Associated with this tradeoff, we demonstrate the existence of an optimal policy profile, comprising a symmetric threshold scheduling policy based on the value of information for the encoder and a non-Gaussian linear estimation policy for the decoder. Our structural results assert that the scheduling policy is expressible in terms of $3d-1$ variables related to the source and the channel, where $d$ is the time delay, and that the estimation policy incorporates no residual related to signaling. We then construct an optimal control policy by exploiting the separation principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11932v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, John S. Baras, Siyi Wang, Sandra Hirche, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Kernel Modelling of Fading Memory Systems</title>
      <link>https://arxiv.org/abs/2403.11945</link>
      <description>arXiv:2403.11945v1 Announce Type: cross 
Abstract: The paper introduces a kernel-based framework to model and identify time-invariant systems with the fading memory property. The key departure from the previous literature is to bypass the state-space representation of the model. Instead, a kernel representation is used to directly model the memory functional that maps past inputs to the present output. We explore the versatility of this approach to encode important system properties in the hyperparameters of the kernel. The approach is illustrated on the Hodgkin and Huxley model of neuronal excitability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11945v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yongkang Huo, Thomas Chaffey, Rodolphe Sepulchre</dc:creator>
    </item>
    <item>
      <title>Dynamic Mode Decomposition with Control Liouville Operators</title>
      <link>https://arxiv.org/abs/2101.02620</link>
      <description>arXiv:2101.02620v4 Announce Type: replace 
Abstract: This paper builds the theoretical foundations for dynamic mode decomposition (DMD) of control-affine dynamical systems by leveraging the theory of vector-valued reproducing kernel Hilbert spaces (RKHSs). Specifically, control Liouville operators and control occupation kernels are introduced to separate the drift dynamics from the input dynamics. A given feedback controller is represented through a multiplication operator and a composition of the control Liouville operator and the multiplication operator is used to express the nonlinear closed-loop system as a linear total derivative operator on RKHSs. A spectral decomposition of a finite-rank representation of the total derivative operator yields a DMD of the closed-loop system. The DMD generates a model that can be used to predict the trajectories of the closed-loop system. For a large class of systems, the total derivative operator is shown to be compact provided the domain and the range RKHSs are selected appropriately. The sequence of models, resulting from increasing-rank finite-rank representations of the compact total derivative operator, are shown to converge to the true system dynamics, provided sufficiently rich data are available. Numerical experiments are included to demonstrate the efficacy of the developed technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.02620v4</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joel A. Rosenfeld, Rushikesh Kamalapurkar</dc:creator>
    </item>
    <item>
      <title>Set Values for Mean Field Games</title>
      <link>https://arxiv.org/abs/2107.01661</link>
      <description>arXiv:2107.01661v4 Announce Type: replace 
Abstract: In this paper we study mean field games with possibly multiple mean field equilibria. Instead of focusing on the individual equilibria, we propose to study the set of values over all possible equilibria, which we call the set value of the mean field game. When the mean field equilibrium is unique, typically under certain monotonicity conditions, our set value reduces to the singleton of the standard value function which solves the master equation. The set value is by nature unique, and we shall establish two crucial properties: (i) the dynamic programming principle, also called time consistency; and (ii) the convergence of the set values of the corresponding $N$-player games, which can be viewed as a type of stability result. To our best knowledge, this is the first work in the literature which studies the dynamic value of mean field games without requiring the uniqueness of mean field equilibria. We emphasize that the set value is very sensitive to the type of the admissible controls. In particular, for the convergence one has to restrict to corresponding types of equilibria for the N-player game and for the mean field game. We shall illustrate this point by investigating three cases, two in finite state space models and the other in a continuous time model with controlled diffusions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.01661v4</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Melih Iseri, Jianfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Superlinear and quadratic convergence of a stabilized sequential quadratic semidefinite programming method for nonlinear semidefinite programming problems</title>
      <link>https://arxiv.org/abs/2210.17169</link>
      <description>arXiv:2210.17169v4 Announce Type: replace 
Abstract: In this paper, we present a stabilized sequential quadratic semidefinite programming (SQSDP) method for nonlinear semidefinite programming (NSDP) problems and prove its local convergence. The stabilized SQSDP method is originally developed to solve degenerate NSDP problems and is based on the stabilized sequential programming (SQP) methods for nonlinear programming (NLP) problems. Although some SQP-type methods for NSDP problems have been proposed, most of them are SQSDP methods which are based on the SQP methods for NLP problems, and there are few researches regarding the stabilized SQSDP methods. In particular, there is room for the development of locally fast convergent stabilized SQSDP methods. We prove not only superlinear but also quadratic convergence of the proposed method under some mild assumptions, such as strict Robinson's constraint qualification and second-order sufficient condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.17169v4</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuya Yamakawa</dc:creator>
    </item>
    <item>
      <title>Closed-Loop Stackelberg Strategy for Linear-Quadratic Leader-Follower Game</title>
      <link>https://arxiv.org/abs/2212.08977</link>
      <description>arXiv:2212.08977v2 Announce Type: replace 
Abstract: This paper is concerned with the closed-loop Stackelberg strategy for linear-quadratic leader-follower game. Completely different from the open-loop and feedback Stackelberg strategy, the solvability of the closed-loop solution even the linear case remains challenging. The main contribution of the paper is to derive the explicitly linear closed-loop Stackelberg strategy with one-step memory in terms of Riccati equations. The key technique is to apply the constrained maximum principle to the leader-follower game and explicitly solve the corresponding forward and backward difference equations. Numerical examples verify the effectiveness of the results, which achieves better performance than feedback strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.08977v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongdan Li, Juanjuan Xu, Hunashui Zhang</dc:creator>
    </item>
    <item>
      <title>Multimodal Transportation Pricing Alliance Design: Large-Scale Optimization for Rapid Gains</title>
      <link>https://arxiv.org/abs/2301.03414</link>
      <description>arXiv:2301.03414v2 Announce Type: replace 
Abstract: Transit agencies have the opportunity to outsource certain services to established Mobility-on-Demand (MOD) providers. Such alliances can improve service quality, coverage, and ridership; reduce public sector costs and vehicular emissions; and integrate the passenger experience. To amplify the effectiveness of such alliances, we develop a fare-setting model that jointly optimizes fares and discounts across a multimodal network. We capture commuters' travel decisions with a discrete choice model, resulting in a large-scale, mixed-integer, non-convex optimization problem. To solve this challenging problem, we develop a two-stage decomposition with the pricing decisions in the first stage and a mixed-integer linear optimization of fare discounts and passengers' travel decisions in the second stage. To solve the decomposition, we develop a new solution approach combining tailored coordinate descent, parsimonious second-stage evaluations, and interpolations using special ordered sets. This approach, enhanced by acceleration techniques based on slanted traversal, randomization and warm-start, significantly outperforms algorithmic benchmarks. Different alliance priorities result in qualitatively different fare designs: flat fares decrease the total vehicle-miles traveled, while geographically-informed discounts improve passenger happiness. The model responds appropriately to equity-oriented and passenger-centric priorities, improving system utilization and lowering prices for low-income and long-distance commuters. Our profit allocation mechanism improves outcomes for both types of operators, thus incentivizing profit-oriented MOD operators to adopt transit priorities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.03414v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kayla Cummings, Vikrant Vaze, \"Ozlem Ergun, Cynthia Barnhart</dc:creator>
    </item>
    <item>
      <title>Optimal Real Time Drone Path Planning for Harvesting Information from a Wireless Sensor Network</title>
      <link>https://arxiv.org/abs/2309.01604</link>
      <description>arXiv:2309.01604v2 Announce Type: replace 
Abstract: We consider a remote sensing system in which fixed sensors are placed in a region, and a drone flies over the region to collect information from cluster heads. We assume that the drone has a fixed maximum range, and that the energy consumption for information transmission from the cluster heads increases with distance according to a power law. Given these assumptions, we derive local optimum conditions for a drone path that either minimizes the total energy or the maximum energy required by the cluster heads to transmit information to the drone. We show how a homotopy approach can produce a family of solutions for different drone path lengths, so that a locally optimal solution can be found for any drone range. We implement the homotopy solution in python, and demonstrate the tradeoff between drone range and cluster head power consumption for several geometries. Execution time is sufficiently rapid for the computation to be performed real time, so the drone path can be recalculated on the fly. The solution is shown to be globally optimal for sufficiently long drone path lengths. For future work, we indicate how the solution can be modified to accommodate moving sensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.01604v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ramkumar Ganapathy, Christopher Thron</dc:creator>
    </item>
    <item>
      <title>Distributed Optimal Control and Application to Consensus of Multi-Agent Systems</title>
      <link>https://arxiv.org/abs/2309.12577</link>
      <description>arXiv:2309.12577v2 Announce Type: replace 
Abstract: This paper develops a novel approach to the consensus problem of multi-agent systems by minimizing a weighted state error with neighbor agents via linear quadratic (LQ) optimal control theory. Existing consensus control algorithms only utilize the current state of each agent, and the design of distributed controller depends on nonzero eigenvalues of the communication topology. The presented optimal consensus controller is obtained by solving Riccati equations and designing appropriate observers to account for agents' historical state information. It is shown that the corresponding cost function under the proposed controllers is asymptotically optimal. Simulation examples demonstrate the effectiveness of the proposed scheme, and a much faster convergence speed than the conventional consensus methods. Moreover, the new method avoids computing nonzero eigenvalues of the communication topology as in the traditional consensus methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12577v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liping Zhang, Juanjuan Xu, Huanshui Zhang, Lihua Xie</dc:creator>
    </item>
    <item>
      <title>Event-Triggered Control of Neuron Growth with Actuation at Soma</title>
      <link>https://arxiv.org/abs/2310.00131</link>
      <description>arXiv:2310.00131v2 Announce Type: replace 
Abstract: We introduce a dynamic event-triggering mechanism for regulating the axonal growth of a neuron. We apply boundary actuation at the soma (the part of a neuron that contains the nucleus) and regulate the dynamics of tubulin concentration and axon length. The control law is formulated by applying a Zero-Order Hold (ZOH) to a continuous-time controller which guides the axon to reach the desired length. The proposed dynamic event-triggering mechanism determines the specific time instants at which control inputs are sampled from the continuous-time control law. We establish the existence of a minimum dwell-time between two triggering times that ensures avoidance of Zeno behavior. Through employing the Lyapunov analysis with PDE backstepping, we prove the local stability of the closed-loop system in $L_2$-norm, initially for the target system, and subsequently for the original system. The effectiveness of the proposed method is showcased through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00131v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cenk Demir, Shumon Koga, Miroslav Krstic</dc:creator>
    </item>
    <item>
      <title>Powered Descent Guidance via First-Order Optimization with Expansive Projection</title>
      <link>https://arxiv.org/abs/2310.00397</link>
      <description>arXiv:2310.00397v2 Announce Type: replace 
Abstract: This paper introduces a first-order method for solving optimal powered descent guidance (PDG) problems, that directly handles the nonconvex constraints associated with the maximum and minimum thrust bounds with varying mass and the pointing angle constraints on thrust vectors. This issue has been conventionally circumvented via lossless convexification (LCvx), which lifts a nonconvex feasible set to a higher-dimensional convex set, and via linear approximation of another nonconvex feasible set defined by exponential functions. However, this approach sometimes results in an infeasible solution when the solution obtained from the higher-dimensional space is projected back to the original space, especially when the problem involves a nonoptimal time of flight. Additionally, the Taylor series approximation introduces an approximation error that grows with both flight time and deviation from the reference trajectory. In this paper, we introduce a first-order approach that makes use of orthogonal projections onto nonconvex sets, allowing expansive projection (ExProj). We show that 1) this approach produces a feasible solution with better performance even for the nonoptimal time of flight cases for which conventional techniques fail to generate achievable trajectories and 2) the proposed method compensates for the linearization error that arises from Taylor series approximation, thus generating a superior guidance solution with less fuel consumption. We provide numerical examples featuring quantitative assessments to elucidate the effectiveness of the proposed methodology, particularly in terms of fuel consumption and flight time. Our analysis substantiates the assertion that the proposed approach affords enhanced flexibility in devising viable trajectories for a diverse array of planetary soft landing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00397v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiwoo Choi, Jong-Han Kim</dc:creator>
    </item>
    <item>
      <title>Optimal Impact Angle Guidance via First-Order Optimization under Nonconvex Constraints</title>
      <link>https://arxiv.org/abs/2310.00398</link>
      <description>arXiv:2310.00398v2 Announce Type: replace 
Abstract: Most of the optimal guidance problems can be formulated as nonconvex optimization problems, which can be solved indirectly by relaxation, convexification, or linearization. Although these methods are guaranteed to converge to the global optimum of the modified problems, the obtained solution may not guarantee global optimality or even the feasibility of the original nonconvex problems. In this paper, we propose a computational optimal guidance approach that directly handles the nonconvex constraints encountered in formulating the guidance problems. The proposed computational guidance approach alternately solves the least squares problems and projects the solution onto nonconvex feasible sets, which rapidly converges to feasible suboptimal solutions or sometimes to the globally optimal solutions. The proposed algorithm is verified via a series of numerical simulations on impact angle guidance problems under state dependent maneuver vector constraints, and it is demonstrated that the proposed algorithm provides superior guidance performance than conventional techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00398v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gyubin Park, Jiwoo Choi, Da Hoon Jeong, Jong-Han Kim</dc:creator>
    </item>
    <item>
      <title>Hybrid Zonotope-Based Backward Reachability Analysis for Neural Feedback Systems With Nonlinear System Models</title>
      <link>https://arxiv.org/abs/2310.06921</link>
      <description>arXiv:2310.06921v2 Announce Type: replace 
Abstract: The increasing prevalence of neural networks in safety-critical control systems underscores the imperative need for rigorous methods to ensure the reliability and safety of these systems. This work introduces a novel approach employing hybrid zonotopes to compute the over-approximation of backward reachable sets for neural feedback systems with nonlinear system models and general activation functions. Closed-form expressions as hybrid zonotopes are provided for the over-approximated backward reachable sets, and a refinement procedure is proposed to alleviate the potential conservatism of the approximation. Two numerical examples are provided to illustrate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06921v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hang Zhang, Yuhao Zhang, Xiangru Xu</dc:creator>
    </item>
    <item>
      <title>Unit Commitment Predictor With a Performance Guarantee: A Support Vector Machine Classifier</title>
      <link>https://arxiv.org/abs/2310.08601</link>
      <description>arXiv:2310.08601v2 Announce Type: replace 
Abstract: The system operators usually need to solve large-scale unit commitment problems within limited time frame for computation. This paper provides a pragmatic solution, showing how by learning and predicting the on/off commitment decisions of conventional units, there is a potential for system operators to warm start their solver and speed up their computation significantly. For the prediction, we train linear and kernelized support vector machine classifiers, providing an out-of-sample performance guarantee if properly regularized, converting to distributionally robust classifiers. For the unit commitment problem, we solve a mixed-integer second-order cone problem. Our results based on the IEEE 6- and 118-bus test systems show that the kernelized SVM with proper regularization outperforms other classifiers, reducing the computational time by a factor of 1.7. In addition, if there is a tight computational limit, while the unit commitment problem without warm start is far away from the optimal solution, its warmly-started version can be solved to (near) optimality within the time limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08601v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farzaneh Pourahmadi, Jalal Kazempour</dc:creator>
    </item>
    <item>
      <title>Combining Learning and Control in Linear Systems</title>
      <link>https://arxiv.org/abs/2310.14409</link>
      <description>arXiv:2310.14409v2 Announce Type: replace 
Abstract: In this paper, we provide a theoretical framework that separates the control and learning tasks in a linear system. This separation allows us to combine offline model-based control with online learning approaches and thus circumvent current challenges in deriving optimal control strategies in applications where a large volume of data is added to the system gradually in real time and not altogether in advance. We provide an analytical example to illustrate the framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14409v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andreas A. Malikopoulos</dc:creator>
    </item>
    <item>
      <title>Predictive Optimization of Hybrid Energy Systems with Temperature Dependency</title>
      <link>https://arxiv.org/abs/2311.00884</link>
      <description>arXiv:2311.00884v2 Announce Type: replace 
Abstract: Hybrid Energy Systems (HES), amalgamating renewable sources, energy storage, and conventional generation, have emerged as a responsive resource for providing valuable grid services. Subsequently, modeling and analysis of HES has become critical, and the quality of grid services hedges on it. Currently, most HES models are temperature-agnostic. However, the temperature-dependent factors can significantly impact HES performance, necessitating advanced modeling and optimization techniques. With the inclusion of temperature-dependent models, the challenges and complexity of solving optimization problem increases. In this paper, the electro-thermal modeling of HES is discussed. Based on this model, a nonlinear predictive optimization framework is formulated. A simplified model is developed to address the challenges associated with solving nonlinear problems. Further, projection and homotopy approaches are proposed. In the homotopy method, the NLP is solved by incrementally changing the C-rating of the battery. Simulation-based analysis of the algorithms highlights the effects of different battery ratings, ambient temperatures, and energy price variations. Finally, comparative assessments with a temperature-agnostic approach illustrates the effectiveness of electro-thermal methods in optimizing HES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00884v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanmay Mishra, Amritanshu Pandey, Mads R. Almassalkhi</dc:creator>
    </item>
    <item>
      <title>An analytic framework for the multiplicative best-worst method</title>
      <link>https://arxiv.org/abs/2311.06762</link>
      <description>arXiv:2311.06762v2 Announce Type: replace 
Abstract: The Best-Worst Method (BWM) is a well-known Multi-Criteria Decision-Making (MCDM) method. This article deals with the multiplicative model of BWM. We first formulate an optimization model that is equivalent to the existing multiplicative model. This model provides a solid foundation for obtaining an analytic form of optimal interval-weights, Consistency Index (CI) and Consistency Ratio (CR). The proposed approach does not require any optimization software, which makes it easy to implement as well as time efficient. Also, the obtained analytical form of CR permits it to serve as an input-based consistency measure. After obtaining these analytic forms, a secondary objective function is introduced to select the best optimal weight set from the collection of all optimal weight sets. Finally, we discuss some numerical examples and a real-world application of the proposed approach in ranking the drivers of Sustainable Additive Manufacturing (SAM) to illustrate the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06762v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Harshit Ratandhara, Mohit Kumar</dc:creator>
    </item>
    <item>
      <title>Distributed Consensus of Heterogeneous Multi-Agent Systems Based on Feedforward Control</title>
      <link>https://arxiv.org/abs/2311.14976</link>
      <description>arXiv:2311.14976v2 Announce Type: replace 
Abstract: This paper studies the consensus problem of heterogeneous multi-agent systems by the feedforward control and linear quadratic (LQ) optimal control theory. Different from the existing consensus control algorithms, which require to design an additional distributed observer for estimating the leader's information and to solve a set of regulator equations. In this paper, by designing a distributed feedforward controller, a non-standard neighbor error system is transformed into a standard linear system, and then an optimal consensus controller is designed by minimizing a combined state error with neighbour agents. The proposed optimal controller is obtained by solving Riccati equations, and it is shown that the corresponding cost function under the proposed distributed controllers is asymptotically optimal. The proposed consensus algorithm can be directly applicable to solve the consensus problem of homogeneous systems. Simulation example indicates the effectiveness of the proposed scheme and a much faster convergence speed than the existing algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14976v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liping Zhang, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Optimization Methods Rooting in Optimal Control</title>
      <link>https://arxiv.org/abs/2312.01334</link>
      <description>arXiv:2312.01334v2 Announce Type: replace 
Abstract: In the paper, we propose solving optimization problems (OPs) and understanding the Newton method from the optimal control view. We propose a new optimization algorithm based on the optimal control problem (OCP). The algorithm features converging more rapidly than gradient descent, meanwhile, it is superior to Newton's method because it is not divergent in general and can be applied in the case of a singular Hessian matrix. These merits are supported by the convergence analysis for the algorithm in the paper. We also point out that the convergence rate of the proposed algorithm is inversely proportional to the magnitude of the control weight matrix and proportional to the control terminal time inherited from OCP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01334v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanshui Zhang, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Solution of the Probabilistic Lambert Problem: Connections with Optimal Mass Transport, Schr\"odinger Bridge and Reaction-Diffusion PDEs</title>
      <link>https://arxiv.org/abs/2401.07961</link>
      <description>arXiv:2401.07961v3 Announce Type: replace 
Abstract: Lambert's problem concerns with transferring a spacecraft from a given initial to a given terminal position within prescribed flight time via velocity control subject to a gravitational force field. We consider a probabilistic variant of the Lambert problem where the knowledge of the endpoint constraints in position vectors are replaced by the knowledge of their respective joint probability density functions. We show that the Lambert problem with endpoint joint probability density constraints is a generalized optimal mass transport (OMT) problem, thereby connecting this classical astrodynamics problem with a burgeoning area of research in modern stochastic control and stochastic machine learning. This newfound connection allows us to rigorously establish the existence and uniqueness of solution for the probabilistic Lambert problem. The same connection also helps to numerically solve the probabilistic Lambert problem via diffusion regularization, i.e., by leveraging further connection of the OMT with the Schr\"odinger bridge problem (SBP). This also shows that the probabilistic Lambert problem with additive dynamic process noise is in fact a generalized SBP, and can be solved numerically using the so-called Schr\"odinger factors, as we do in this work. We explain how the resulting analysis leads to solving a boundary-coupled system of reaction-diffusion PDEs where the nonlinear gravitational potential appears as the reaction rate. We propose novel algorithms for the same, and present illustrative numerical results. Our analysis and the algorithmic framework are nonparametric, i.e., we make neither statistical (e.g., Gaussian, first few moments, mixture or exponential family, finite dimensionality of the sufficient statistic) nor dynamical (e.g., Taylor series) approximations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07961v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexis M. H. Teter, Iman Nodozi, Abhishek Halder</dc:creator>
    </item>
    <item>
      <title>A low-rank augmented Lagrangian method for large-scale semidefinite programming based on a hybrid convex-nonconvex approach</title>
      <link>https://arxiv.org/abs/2401.12490</link>
      <description>arXiv:2401.12490v3 Announce Type: replace 
Abstract: This paper introduces HALLaR, a new first-order method for solving large-scale semidefinite programs (SDPs) with bounded domain. HALLaR is an inexact augmented Lagrangian (AL) method where the AL subproblems are solved by a novel hybrid low-rank (HLR) method. The recipe behind HLR is based on two key ingredients: 1) an adaptive inexact proximal point method with inner acceleration; 2) Frank-Wolfe steps to escape from spurious local stationary points. In contrast to the low-rank method of Burer and Monteiro, HALLaR finds a near-optimal solution (with provable complexity bounds) of SDP instances satisfying strong duality. Computational results comparing HALLaR to state-of-the-art solvers on several large SDP instances arising from maximum stable set, phase retrieval, and matrix completion show that the former finds higher accurate solutions in substantially less CPU time than the latter ones. For example, in less than 20 minutes, HALLaR can solve a maximum stable set SDP instance with dimension pair $(n,m)\approx (10^6,10^7)$ within $10^{-5}$ relative precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12490v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato D. C. Monteiro, Arnesh Sujanani, Diego Cifuentes</dc:creator>
    </item>
    <item>
      <title>Non-Convex Stochastic Composite Optimization with Polyak Momentum</title>
      <link>https://arxiv.org/abs/2403.02967</link>
      <description>arXiv:2403.02967v2 Announce Type: replace 
Abstract: The stochastic proximal gradient method is a powerful generalization of the widely used stochastic gradient descent (SGD) method and has found numerous applications in Machine Learning. However, it is notoriously known that this method fails to converge in non-convex settings where the stochastic noise is significant (i.e. when only small or bounded batch sizes are used). In this paper, we focus on the stochastic proximal gradient method with Polyak momentum. We prove this method attains an optimal convergence rate for non-convex composite optimization problems, regardless of batch size. Additionally, we rigorously analyze the variance reduction effect of the Polyak momentum in the composite optimization setting and we show the method also converges when the proximal step can only be solved inexactly. Finally, we provide numerical experiments to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02967v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>A global Barzilai and Borwein's gradient normalization descent method for multiobjective optimization</title>
      <link>https://arxiv.org/abs/2403.05070</link>
      <description>arXiv:2403.05070v2 Announce Type: replace 
Abstract: In this paper, we consider the unconstrained multiobjective optimization problem. In recent years, researchers pointed out that the steepest decent method may generate small stepsize which leads to slow convergence rates. To address the issue, we propose a global Barzilai and Borwein's gradient normalization descent method for multiobjective optimization (GBBN). In our method, we propose a new normalization technique to generate new descent direction. We demonstrate that line search can achieve better stepsize along the descent direction. Furthermore, we prove the global convergence of accumulation points generated by GBBN as Pareto critical points and establish a linear rate of convergence under reasonable assumptions. Finally, we evaluated the effectiveness of the proposed GBBN method based on the quality of the approximated Pareto frontier and computational complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05070v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingxue Yang</dc:creator>
    </item>
    <item>
      <title>Analysis of a continuous opinion and discrete action dynamics model coupled with an external observation dynamics</title>
      <link>https://arxiv.org/abs/2403.09473</link>
      <description>arXiv:2403.09473v2 Announce Type: replace 
Abstract: We consider a set of consumers in a city or town (who thus generate pollution) whose opinion is governed by a continuous opinion and discrete action (CODA) dynamics model. This dynamics is coupled with an observation signal dynamics, which defines the information the consumers have access to regarding the common pollution. We show that the external observation signal has a significant impact on the asymptotic behavior of the CODA model. When the coupling is strong, it induces either a chaotic behavior or convergence towards a limit cycle. When the coupling is weak, a more classical behavior characterized by local agreements in polarized clusters is observed. In both cases, conditions under which clusters of consumers don't change their actions are provided.Numerical examples are provided to illustrate the derived analytical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09473v2</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Couthures, Thomas Mongaillard, Vineeth S. Varma, Samson Lasaulce, Irinel-Constantin Morarescu</dc:creator>
    </item>
    <item>
      <title>Utility maximization under endogenous pricing</title>
      <link>https://arxiv.org/abs/2005.04312</link>
      <description>arXiv:2005.04312v4 Announce Type: replace-cross 
Abstract: We study the expected utility maximization problem of a large investor who is allowed to make transactions on tradable assets in an incomplete financial market with endogenous permanent market impacts. The asset prices are assumed to follow a nonlinear price curve quoted in the market as the utility indifference curve of a representative liquidity supplier. We show that optimality can be fully characterized via a system of coupled forward-backward stochastic differential equations (FBSDEs) which corresponds to a non-linear backward stochastic partial differential equation (BSPDE). We show existence of solutions to the optimal investment problem and the FBSDEs in the case where the driver function of the representative market maker grows at least quadratically or the utility function of the large investor falls faster than quadratically or is exponential. Furthermore, we derive smoothness results for the existence of solutions of BSPDEs. Examples are provided when the market is complete or the utility function is exponential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2005.04312v4</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thai Nguyen, Mitja Stadje</dc:creator>
    </item>
    <item>
      <title>Zeroth-Order Hard-Thresholding: Gradient Error vs. Expansivity</title>
      <link>https://arxiv.org/abs/2210.05279</link>
      <description>arXiv:2210.05279v2 Announce Type: replace-cross 
Abstract: $\ell_0$ constrained optimization is prevalent in machine learning, particularly for high-dimensional problems, because it is a fundamental approach to achieve sparse learning. Hard-thresholding gradient descent is a dominant technique to solve this problem. However, first-order gradients of the objective function may be either unavailable or expensive to calculate in a lot of real-world problems, where zeroth-order (ZO) gradients could be a good surrogate. Unfortunately, whether ZO gradients can work with the hard-thresholding operator is still an unsolved problem. To solve this puzzle, in this paper, we focus on the $\ell_0$ constrained black-box stochastic optimization problems, and propose a new stochastic zeroth-order gradient hard-thresholding (SZOHT) algorithm with a general ZO gradient estimator powered by a novel random support sampling. We provide the convergence analysis of SZOHT under standard assumptions. Importantly, we reveal a conflict between the deviation of ZO estimators and the expansivity of the hard-thresholding operator, and provide a theoretical minimal value of the number of random directions in ZO gradients. In addition, we find that the query complexity of SZOHT is independent or weakly dependent on the dimensionality under different settings. Finally, we illustrate the utility of our method on a portfolio optimization problem as well as black-box adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.05279v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William de Vazelhes, Hualin Zhang, Huimin Wu, Xiao-Tong Yuan, Bin Gu</dc:creator>
    </item>
    <item>
      <title>A Convex Hull Cheapest Insertion Heuristic for Precedence Constrained Traveling Salesperson Problems or Sequential Ordering Problems</title>
      <link>https://arxiv.org/abs/2303.05333</link>
      <description>arXiv:2303.05333v2 Announce Type: replace-cross 
Abstract: The convex hull cheapest insertion heuristic is a well-known method that efficiently generates good solutions to the Traveling Salesperson Problem. However, this heuristic has not been adapted to account for precedence constraints that restrict the order in which locations can be visited. Such constraints result in the precedence constrained traveling salesperson problem or the sequential ordering problem, which are commonly encountered in applications where items have to be picked up before they are delivered. In this paper, we present an adapted version of this heuristic that accounts for precedence constraints in the problem definition. This algorithm is compared with the widely used Nearest Neighbor heuristic on the TSPLIB benchmark data with added precedence constraints. It is seen that the proposed algorithm is particularly well suited to cases where delivery nodes are centrally positioned, with pickup nodes located in the periphery, outperforming the Nearest Neighbor algorithm in 97\% of the examined instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05333v2</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mithun Goutham, Stephanie Stockar</dc:creator>
    </item>
    <item>
      <title>Properties of Discrete Sliced Wasserstein Losses</title>
      <link>https://arxiv.org/abs/2307.10352</link>
      <description>arXiv:2307.10352v3 Announce Type: replace-cross 
Abstract: The Sliced Wasserstein (SW) distance has become a popular alternative to the Wasserstein distance for comparing probability measures. Widespread applications include image processing, domain adaptation and generative modelling, where it is common to optimise some parameters in order to minimise SW, which serves as a loss function between discrete probability measures (since measures admitting densities are numerically unattainable). All these optimisation problems bear the same sub-problem, which is minimising the Sliced Wasserstein energy. In this paper we study the properties of $\mathcal{E}: Y \longmapsto \mathrm{SW}_2^2(\gamma_Y, \gamma_Z)$, i.e. the SW distance between two uniform discrete measures with the same amount of points as a function of the support $Y \in \mathbb{R}^{n \times d}$ of one of the measures. We investigate the regularity and optimisation properties of this energy, as well as its Monte-Carlo approximation $\mathcal{E}_p$ (estimating the expectation in SW using only $p$ samples) and show convergence results on the critical points of $\mathcal{E}_p$ to those of $\mathcal{E}$, as well as an almost-sure uniform convergence. Finally, we show that in a certain sense, Stochastic Gradient Descent methods minimising $\mathcal{E}$ and $\mathcal{E}_p$ converge towards (Clarke) critical points of these energies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10352v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eloi Tanguy, R\'emi Flamary, Julie Delon</dc:creator>
    </item>
    <item>
      <title>Convergence of SGD for Training Neural Networks with Sliced Wasserstein Losses</title>
      <link>https://arxiv.org/abs/2307.11714</link>
      <description>arXiv:2307.11714v3 Announce Type: replace-cross 
Abstract: Optimal Transport has sparked vivid interest in recent years, in particular thanks to the Wasserstein distance, which provides a geometrically sensible and intuitive way of comparing probability measures. For computational reasons, the Sliced Wasserstein (SW) distance was introduced as an alternative to the Wasserstein distance, and has seen uses for training generative Neural Networks (NNs). While convergence of Stochastic Gradient Descent (SGD) has been observed practically in such a setting, there is to our knowledge no theoretical guarantee for this observation. Leveraging recent works on convergence of SGD on non-smooth and non-convex functions by Bianchi et al. (2022), we aim to bridge that knowledge gap, and provide a realistic context under which fixed-step SGD trajectories for the SW loss on NN parameters converge. More precisely, we show that the trajectories approach the set of (sub)-gradient flow equations as the step decreases. Under stricter assumptions, we show a much stronger convergence result for noised and projected SGD schemes, namely that the long-run limits of the trajectories approach a set of generalised critical points of the loss function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.11714v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Transactions on Machine Learning Research, 2023 2835-8856</arxiv:journal_reference>
      <dc:creator>Eloi Tanguy</dc:creator>
    </item>
    <item>
      <title>Safety Control of Uncertain MIMO Systems Using Dynamic Output Feedback Barrier Pairs</title>
      <link>https://arxiv.org/abs/2308.00326</link>
      <description>arXiv:2308.00326v2 Announce Type: replace-cross 
Abstract: Safety control of dynamical systems using barrier functions relies on knowing the full state information. This paper introduces a novel approach for safety control in uncertain MIMO systems with partial state information. The proposed method combines the synthesis of a vector norm barrier function and a dynamic output feedback safety controller to ensure robust safety enforcement. The safety controller guarantees the invariance of the barrier function under uncertain dynamics and disturbances. To address the challenges associated with safety verification using partial state information, a barrier function estimator is developed. This estimator employs an identifier-based state estimator to obtain a state estimate that is affine in the uncertain model parameters of the system. By incorporating a priori knowledge of the limits of the uncertain model parameters and disturbances, the state estimate provides a robust upper bound for the barrier function. Comparative analysis with existing control barrier function based methods shows the advantage of the proposed approach in enforcing safety constraints under tight input constraints and the utilization of estimated state information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.00326v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binghan He, Takashi Tanaka</dc:creator>
    </item>
    <item>
      <title>Global Convergence of SGD For Logistic Loss on Two Layer Neural Nets</title>
      <link>https://arxiv.org/abs/2309.09258</link>
      <description>arXiv:2309.09258v2 Announce Type: replace-cross 
Abstract: In this note, we demonstrate a first-of-its-kind provable convergence of SGD to the global minima of appropriately regularized logistic empirical risk of depth $2$ nets -- for arbitrary data and with any number of gates with adequately smooth and bounded activations like sigmoid and tanh. We also prove an exponentially fast convergence rate for continuous time SGD that also applies to smooth unbounded activations like SoftPlus. Our key idea is to show the existence of Frobenius norm regularized logistic loss functions on constant-sized neural nets which are "Villani functions" and thus be able to build on recent progress with analyzing SGD on such objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09258v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pulkit Gopalani, Samyak Jha, Anirbit Mukherjee</dc:creator>
    </item>
    <item>
      <title>Geometric structure of shallow neural networks and constructive ${\mathcal L}^2$ cost minimization</title>
      <link>https://arxiv.org/abs/2309.10370</link>
      <description>arXiv:2309.10370v2 Announce Type: replace-cross 
Abstract: In this paper, we approach the problem of cost (loss) minimization in underparametrized shallow neural networks through the explicit construction of upper bounds, without any use of gradient descent. A key focus is on elucidating the geometric structure of approximate and precise minimizers. We consider shallow neural networks with one hidden layer, a ReLU activation function, an ${\mathcal L}^2$ Schatten class (or Hilbert-Schmidt) cost function, input space ${\mathbb R}^M$, output space ${\mathbb R}^Q$ with $Q\leq M$, and training input sample size $N&gt;QM$ that can be arbitrarily large. We prove an upper bound on the minimum of the cost function of order $O(\delta_P)$ where $\delta_P$ measures the signal to noise ratio of training inputs. In the special case $M=Q$, we explicitly determine an exact degenerate local minimum of the cost function, and show that the sharp value differs from the upper bound obtained for $Q\leq M$ by a relative error $O(\delta_P^2)$. The proof of the upper bound yields a constructively trained network; we show that it metrizes a particular $Q$-dimensional subspace in the input space ${\mathbb R}^M$. We comment on the characterization of the global minimum of the cost function in the given context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.10370v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen, Patricia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>From Complexity to Clarity: Analytical Expressions of Deep Neural Network Weights via Clifford's Geometric Algebra and Convexity</title>
      <link>https://arxiv.org/abs/2309.16512</link>
      <description>arXiv:2309.16512v3 Announce Type: replace-cross 
Abstract: In this paper, we introduce a novel analysis of neural networks based on geometric (Clifford) algebra and convex optimization. We show that optimal weights of deep ReLU neural networks are given by the wedge product of training samples when trained with standard regularized loss. Furthermore, the training problem reduces to convex optimization over wedge product features, which encode the geometric structure of the training dataset. This structure is given in terms of signed volumes of triangles and parallelotopes generated by data vectors. The convex problem finds a small subset of samples via $\ell_1$ regularization to discover only relevant wedge product features. Our analysis provides a novel perspective on the inner workings of deep neural networks and sheds light on the role of the hidden layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.16512v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mert Pilanci</dc:creator>
    </item>
    <item>
      <title>Global $\mathcal{L}^2$ minimization at uniform exponential rate via geometrically adapted gradient descent in Deep Learning</title>
      <link>https://arxiv.org/abs/2311.15487</link>
      <description>arXiv:2311.15487v3 Announce Type: replace-cross 
Abstract: We consider the gradient descent flow widely used for the minimization of the $\mathcal{L}^2$ cost function in Deep Learning networks, and introduce two modified versions; one adapted for the overparametrized setting, and the other for the underparametrized setting. Both have a clear and natural invariant geometric meaning, taking into account the pullback vector bundle structure in the overparametrized, and the pushforward vector bundle structure in the underparametrized setting. In the overparametrized case, we prove that, provided that a rank condition holds, all orbits of the modified gradient descent drive the $\mathcal{L}^2$ cost to its global minimum at a uniform exponential convergence rate; one thereby obtains an a priori stopping time for any prescribed proximity to the global minimum. We point out relations of the latter to sub-Riemannian geometry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.15487v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Chen</dc:creator>
    </item>
    <item>
      <title>CaVE: A Cone-Aligned Approach for Fast Predict-then-optimize with Binary Linear Programs</title>
      <link>https://arxiv.org/abs/2312.07718</link>
      <description>arXiv:2312.07718v2 Announce Type: replace-cross 
Abstract: The end-to-end predict-then-optimize framework, also known as decision-focused learning, has gained popularity for its ability to integrate optimization into the training procedure of machine learning models that predict the unknown cost (objective function) coefficients of optimization problems from contextual instance information. Naturally, most of the problems of interest in this space can be cast as integer linear programs. In this work, we focus on binary linear programs (BLPs) and propose a new end-to-end training method to predict-then-optimize. Our method, Cone-aligned Vector Estimation (CaVE), aligns the predicted cost vectors with the normal cone corresponding to the true optimal solution of a training instance. When the predicted cost vector lies inside the cone, the optimal solution to the linear relaxation of the binary problem is optimal. This alignment not only produces decision-aware learning models but also dramatically reduces training time as it circumvents the need to solve BLPs to compute a loss function with its gradients. Experiments across multiple datasets show that our method exhibits a favorable trade-off between training time and solution quality, particularly with large-scale optimization problems such as vehicle routing, a hard BLP that has yet to benefit from predict-then-optimize methods in the literature due to its difficulty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07718v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Tang, Elias B. Khalil</dc:creator>
    </item>
    <item>
      <title>Accelerated Convergence of Stochastic Heavy Ball Method under Anisotropic Gradient Noise</title>
      <link>https://arxiv.org/abs/2312.14567</link>
      <description>arXiv:2312.14567v2 Announce Type: replace-cross 
Abstract: Heavy-ball momentum with decaying learning rates is widely used with SGD for optimizing deep learning models. In contrast to its empirical popularity, the understanding of its theoretical property is still quite limited, especially under the standard anisotropic gradient noise condition for quadratic regression problems. Although it is widely conjectured that heavy-ball momentum method can provide accelerated convergence and should work well in large batch settings, there is no rigorous theoretical analysis. In this paper, we fill this theoretical gap by establishing a non-asymptotic convergence bound for stochastic heavy-ball methods with step decay scheduler on quadratic objectives, under the anisotropic gradient noise condition. As a direct implication, we show that heavy-ball momentum can provide $\tilde{\mathcal{O}}(\sqrt{\kappa})$ accelerated convergence of the bias term of SGD while still achieving near-optimal convergence rate with respect to the stochastic variance term. The combined effect implies an overall convergence rate within log factors from the statistical minimax rate. This means SGD with heavy-ball momentum is useful in the large-batch settings such as distributed machine learning or federated learning, where a smaller number of iterations can significantly reduce the number of communication rounds, leading to acceleration in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14567v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rui Pan, Yuxing Liu, Xiaoyu Wang, Tong Zhang</dc:creator>
    </item>
    <item>
      <title>The Two Lives of the Grassmannian</title>
      <link>https://arxiv.org/abs/2401.03684</link>
      <description>arXiv:2401.03684v2 Announce Type: replace-cross 
Abstract: The real Grassmannian is both a projective variety (via Pl\"ucker coordinates) and an affine variety (via orthogonal projections). We connect these two representations, and we develop the commutative algebra of the latter variety. We introduce the squared Grassmannian, and we study applications to determinantal point processes in statistics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03684v2</guid>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karel Devriendt, Hannah Friedman, Bernhard Reinke, Bernd Sturmfels</dc:creator>
    </item>
    <item>
      <title>How Free is Parameter-Free Stochastic Optimization?</title>
      <link>https://arxiv.org/abs/2402.03126</link>
      <description>arXiv:2402.03126v2 Announce Type: replace-cross 
Abstract: We study the problem of parameter-free stochastic optimization, inquiring whether, and under what conditions, do fully parameter-free methods exist: these are methods that achieve convergence rates competitive with optimally tuned methods, without requiring significant knowledge of the true problem parameters. Existing parameter-free methods can only be considered ``partially'' parameter-free, as they require some non-trivial knowledge of the true problem parameters, such as a bound on the stochastic gradient norms, a bound on the distance to a minimizer, etc. In the non-convex setting, we demonstrate that a simple hyperparameter search technique results in a fully parameter-free method that outperforms more sophisticated state-of-the-art algorithms. We also provide a similar result in the convex setting with access to noisy function values under mild noise assumptions. Finally, assuming only access to stochastic gradients, we establish a lower bound that renders fully parameter-free stochastic convex optimization infeasible, and provide a method which is (partially) parameter-free up to the limit indicated by our lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03126v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Attia, Tomer Koren</dc:creator>
    </item>
  </channel>
</rss>
