<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Jun 2024 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Minimax Linear Regression under the Quantile Risk</title>
      <link>https://arxiv.org/abs/2406.12145</link>
      <description>arXiv:2406.12145v1 Announce Type: new 
Abstract: We study the problem of designing minimax procedures in linear regression under the quantile risk. We start by considering the realizable setting with independent Gaussian noise, where for any given noise level and distribution of inputs, we obtain the exact minimax quantile risk for a rich family of error functions and establish the minimaxity of OLS. This improves on the known lower bounds for the special case of square error, and provides us with a lower bound on the minimax quantile risk over larger sets of distributions. Under the square error and a fourth moment assumption on the distribution of inputs, we show that this lower bound is tight over a larger class of problems. Specifically, we prove a matching upper bound on the worst-case quantile risk of a variant of the recently proposed min-max regression procedure, thereby establishing its minimaxity, up to absolute constants. We illustrate the usefulness of our approach by extending this result to all $p$-th power error functions for $p \in (2, \infty)$. Along the way, we develop a generic analogue to the classical Bayesian method for lower bounding the minimax risk when working with the quantile risk, as well as a tight characterization of the quantiles of the smallest eigenvalue of the sample covariance matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12145v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayoub El Hanchi, Chris J. Maddison, Murat A. Erdogdu</dc:creator>
    </item>
    <item>
      <title>Slow rates of approximation of U-statistics and V-statistics by quadratic forms of Gaussians</title>
      <link>https://arxiv.org/abs/2406.12437</link>
      <description>arXiv:2406.12437v1 Announce Type: new 
Abstract: We construct examples of degree-two U- and V-statistics of $n$ i.i.d.~heavy-tailed random vectors in $\mathbb{R}^{d(n)}$, whose $\nu$-th moments exist for ${\nu &gt; 2}$, and provide tight bounds on the error of approximating both statistics by a quadratic form of Gaussians. In the case ${\nu=3}$, the error of approximation is $\Theta(n^{-1/12})$. The proof adapts a result of Huang, Austern and Orbanz [12] to U- and V-statistics. The lower bound for U-statistics is a simple example of the concept of variance domination used in [12].</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12437v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Han Huang, Peter Orbanz</dc:creator>
    </item>
    <item>
      <title>Adaptive Mean Estimation in the Hidden Markov sub-Gaussian Mixture Model</title>
      <link>https://arxiv.org/abs/2406.12446</link>
      <description>arXiv:2406.12446v1 Announce Type: new 
Abstract: We investigate the problem of center estimation in the high dimensional binary sub-Gaussian Mixture Model with Hidden Markov structure on the labels. We first study the limitations of existing results in the high dimensional setting and then propose a minimax optimal procedure for the problem of center estimation. Among other findings, we show that our procedure reaches the optimal rate that is of order $\sqrt{\delta d/n} + d/n$ instead of $\sqrt{d/n} + d/n$ where $\delta \in(0,1)$ is a dependence parameter between labels. Along the way, we also develop an adaptive variant of our procedure that is globally minimax optimal. In order to do so, we rely on a more refined and localized analysis of the estimation risk. Overall, leveraging the hidden Markovian dependence between the labels, we show that it is possible to get a strict improvement of the rates adaptively at almost no cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12446v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vahe Karagulyan, Mohamed Ndaoud</dc:creator>
    </item>
    <item>
      <title>Order-Optimal Instance-Dependent Bounds for Offline Reinforcement Learning with Preference Feedback</title>
      <link>https://arxiv.org/abs/2406.12205</link>
      <description>arXiv:2406.12205v1 Announce Type: cross 
Abstract: We consider offline reinforcement learning (RL) with preference feedback in which the implicit reward is a linear function of an unknown parameter. Given an offline dataset, our objective consists in ascertaining the optimal action for each state, with the ultimate goal of minimizing the {\em simple regret}. We propose an algorithm, \underline{RL} with \underline{L}ocally \underline{O}ptimal \underline{W}eights or {\sc RL-LOW}, which yields a simple regret of $\exp ( - \Omega(n/H) )$ where $n$ is the number of data samples and $H$ denotes an instance-dependent hardness quantity that depends explicitly on the suboptimality gap of each action. Furthermore, we derive a first-of-its-kind instance-dependent lower bound in offline RL with preference feedback. Interestingly, we observe that the lower and upper bounds on the simple regret match order-wise in the exponent, demonstrating order-wise optimality of {\sc RL-LOW}. In view of privacy considerations in practical applications, we also extend {\sc RL-LOW} to the setting of $(\varepsilon,\delta)$-differential privacy and show, somewhat surprisingly, that the hardness parameter $H$ is unchanged in the asymptotic regime as $n$ tends to infinity; this underscores the inherent efficiency of {\sc RL-LOW} in terms of preserving the privacy of the observed rewards. Given our focus on establishing instance-dependent bounds, our work stands in stark contrast to previous works that focus on establishing worst-case regrets for offline RL with preference feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12205v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhirui Chen, Vincent Y. F. Tan</dc:creator>
    </item>
    <item>
      <title>Structured Prediction in Online Learning</title>
      <link>https://arxiv.org/abs/2406.12366</link>
      <description>arXiv:2406.12366v1 Announce Type: cross 
Abstract: We study a theoretical and algorithmic framework for structured prediction in the online learning setting. The problem of structured prediction, i.e. estimating function where the output space lacks a vectorial structure, is well studied in the literature of supervised statistical learning. We show that our algorithm is a generalisation of optimal algorithms from the supervised learning setting, and achieves the same excess risk upper bound also when data are not i.i.d. Moreover, we consider a second algorithm designed especially for non-stationary data distributions, including adversarial data. We bound its stochastic regret in function of the variation of the data distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12366v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Boudart (DI-ENS, PSL), Alessandro Rudi (PSL, DI-ENS, Inria), Pierre Gaillard (UGA, LJK)</dc:creator>
    </item>
    <item>
      <title>Bayesian Data Selection</title>
      <link>https://arxiv.org/abs/2406.12560</link>
      <description>arXiv:2406.12560v1 Announce Type: cross 
Abstract: A wide range of machine learning algorithms iteratively add data to the training sample. Examples include semi-supervised learning, active learning, multi-armed bandits, and Bayesian optimization. We embed this kind of data addition into decision theory by framing data selection as a decision problem. This paves the way for finding Bayes-optimal selections of data. For the illustrative case of self-training in semi-supervised learning, we derive the respective Bayes criterion. We further show that deploying this criterion mitigates the issue of confirmation bias by empirically assessing our method for generalized linear models, semi-parametric generalized additive models, and Bayesian neural networks on simulated and real-world data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12560v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Rodemann</dc:creator>
    </item>
    <item>
      <title>A variational Bayes approach to debiased inference for low-dimensional parameters in high-dimensional linear regression</title>
      <link>https://arxiv.org/abs/2406.12659</link>
      <description>arXiv:2406.12659v1 Announce Type: cross 
Abstract: We propose a scalable variational Bayes method for statistical inference for a single or low-dimensional subset of the coordinates of a high-dimensional parameter in sparse linear regression. Our approach relies on assigning a mean-field approximation to the nuisance coordinates and carefully modelling the conditional distribution of the target given the nuisance. This requires only a preprocessing step and preserves the computational advantages of mean-field variational Bayes, while ensuring accurate and reliable inference for the target parameter, including for uncertainty quantification. We investigate the numerical performance of our algorithm, showing that it performs competitively with existing methods. We further establish accompanying theoretical guarantees for estimation and uncertainty quantification in the form of a Bernstein--von Mises theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12659v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isma\"el Castillo, Alice L'Huillier, Kolyan Ray, Luke Travis</dc:creator>
    </item>
    <item>
      <title>Contraction rates for conjugate gradient and Lanczos approximate posteriors in Gaussian process regression</title>
      <link>https://arxiv.org/abs/2406.12678</link>
      <description>arXiv:2406.12678v1 Announce Type: cross 
Abstract: Due to their flexibility and theoretical tractability Gaussian process (GP) regression models have become a central topic in modern statistics and machine learning. While the true posterior in these models is given explicitly, numerical evaluations depend on the inversion of the augmented kernel matrix $ K + \sigma^2 I $, which requires up to $ O(n^3) $ operations. For large sample sizes n, which are typically given in modern applications, this is computationally infeasible and necessitates the use of an approximate version of the posterior. Although such methods are widely used in practice, they typically have very limtied theoretical underpinning.
  In this context, we analyze a class of recently proposed approximation algorithms from the field of Probabilistic numerics. They can be interpreted in terms of Lanczos approximate eigenvectors of the kernel matrix or a conjugate gradient approximation of the posterior mean, which are particularly advantageous in truly large scale applications, as they are fundamentally only based on matrix vector multiplications amenable to the GPU acceleration of modern software frameworks. We combine result from the numerical analysis literature with state of the art concentration results for spectra of kernel matrices to obtain minimax contraction rates. Our theoretical findings are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12678v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bernhard Stankewitz, Botond Szabo</dc:creator>
    </item>
    <item>
      <title>The Laplace asymptotic expansion in high dimensions: a nonasymptotic analysis</title>
      <link>https://arxiv.org/abs/2406.12706</link>
      <description>arXiv:2406.12706v1 Announce Type: cross 
Abstract: We study the classical Laplace asymptotic expansion of $\int_{\mathbb R^d} f(x)e^{-nv(x)}dx$ in high dimensions $d$. We derive an error bound to the expansion when truncated to arbitrary order. The error bound is fully explicit except for absolute constants, and it depends on $d$, $n$, and operator norms of the derivatives of $v$ and $f$ in a neighborhood of the minimizer of $v$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12706v1</guid>
      <category>math.CA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anya Katsevich</dc:creator>
    </item>
    <item>
      <title>Optimal Excess Risk Bounds for Empirical Risk Minimization on $p$-Norm Linear Regression</title>
      <link>https://arxiv.org/abs/2310.12437</link>
      <description>arXiv:2310.12437v2 Announce Type: replace 
Abstract: We study the performance of empirical risk minimization on the $p$-norm linear regression problem for $p \in (1, \infty)$. We show that, in the realizable case, under no moment assumptions, and up to a distribution-dependent constant, $O(d)$ samples are enough to exactly recover the target. Otherwise, for $p \in [2, \infty)$, and under weak moment assumptions on the target and the covariates, we prove a high probability excess risk bound on the empirical risk minimizer whose leading term matches, up to a constant that depends only on $p$, the asymptotically exact rate. We extend this result to the case $p \in (1, 2)$ under mild assumptions that guarantee the existence of the Hessian of the risk at its minimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12437v2</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayoub El Hanchi, Murat A. Erdogdu</dc:creator>
    </item>
    <item>
      <title>Convergence of Kinetic Langevin Monte Carlo on Lie groups</title>
      <link>https://arxiv.org/abs/2403.12012</link>
      <description>arXiv:2403.12012v2 Announce Type: replace 
Abstract: Explicit, momentum-based dynamics for optimizing functions defined on Lie groups was recently constructed, based on techniques such as variational optimization and left trivialization. We appropriately add tractable noise to the optimization dynamics to turn it into a sampling dynamics, leveraging the advantageous feature that the trivialized momentum variable is Euclidean despite that the potential function lives on a manifold. We then propose a Lie-group MCMC sampler, by delicately discretizing the resulting kinetic-Langevin-type sampling dynamics. The Lie group structure is exactly preserved by this discretization. Exponential convergence with explicit convergence rate for both the continuous dynamics and the discrete sampler are then proved under $W_2$ distance. Only compactness of the Lie group and geodesically $L$-smoothness of the potential function are needed. To the best of our knowledge, this is the first convergence result for kinetic Langevin on curved spaces, and also the first quantitative result that requires no convexity or, at least not explicitly, any common relaxation such as isoperimetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12012v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingkai Kong, Molei Tao</dc:creator>
    </item>
    <item>
      <title>Generalized multi-view model: Adaptive density estimation under low-rank constraints</title>
      <link>https://arxiv.org/abs/2404.17209</link>
      <description>arXiv:2404.17209v2 Announce Type: replace 
Abstract: We study the problem of bivariate discrete or continuous probability density estimation under low-rank constraints.For discrete distributions, we assume that the two-dimensional array to estimate is a low-rank probability matrix. In the continuous case, we assume that the density with respect to the Lebesgue measure satisfies a generalized multi-view model, meaning that it is $\beta$-H{\"o}lder and can be decomposed as a sum of $K$ components, each of which is a product of one-dimensional functions. In both settings, we propose estimators that achieve, up to logarithmic factors, the minimax optimal convergence rates under such low-rank constraints. In the discrete case, the proposed estimator is adaptive to the rank $K$. In the continuous case, our estimator converges with the $L_1$ rate $\min((K/n)^{\beta/(2\beta+1)}, n^{-\beta/(2\beta+2)})$ up to logarithmic factors, and it is adaptive to the unknown support as well as to the smoothness $\beta$ and to the unknown number of separable components $K$. We present efficient algorithms for computing our estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17209v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Julien Chhor (TSE), Olga Klopp (CREST-ENSAE), Alexandre Tsybakov (CREST-ENSAE)</dc:creator>
    </item>
    <item>
      <title>Orthogonal and Linear Regressions and Pencils of Confocal Quadrics</title>
      <link>https://arxiv.org/abs/2209.01679</link>
      <description>arXiv:2209.01679v3 Announce Type: replace-cross 
Abstract: This paper enhances and develops bridges between statistics, mechanics, and geometry. For a given system of points in $\mathbb R^k$ representing a sample of full rank, we construct an explicit pencil of confocal quadrics with the following properties: (i) All the hyperplanes for which the hyperplanar moments of inertia for the given system of points are equal, are tangent to the same quadrics from the pencil of quadrics. As an application, we develop regularization procedures for the orthogonal least square method, analogues of lasso and ridge methods from linear regression. (ii) For any given point $P$ among all the hyperplanes that contain it, the best fit is the tangent hyperplane to the quadric from the confocal pencil corresponding to the maximal Jacobi coordinate of the point $P$; the worst fit among the hyperplanes containing $P$ is the tangent hyperplane to the ellipsoid from the confocal pencil that contains $P$. The confocal pencil of quadrics provides a universal tool to solve the restricted principal component analysis restricted at any given point. Both results (i) and (ii) can be seen as generalizations of the classical result of Pearson on orthogonal regression. They have natural and important applications in the statistics of the errors-in-variables models (EIV). For the classical linear regressions we provide a geometric characterization of hyperplanes of least squares in a given direction among all hyperplanes which contain a given point. The obtained results have applications in restricted regressions, both ordinary and orthogonal ones. For the latter, a new formula for test statistic is derived. The developed methods and results are illustrated in natural statistics examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.01679v3</guid>
      <category>math.AG</category>
      <category>math.DS</category>
      <category>math.ST</category>
      <category>nlin.SI</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladimir Dragovi\'c, Borislav Gaji\'c</dc:creator>
    </item>
    <item>
      <title>Using Autodiff to Estimate Posterior Moments, Marginals and Samples</title>
      <link>https://arxiv.org/abs/2310.17374</link>
      <description>arXiv:2310.17374v2 Announce Type: replace-cross 
Abstract: Importance sampling is a popular technique in Bayesian inference: by reweighting samples drawn from a proposal distribution we are able to obtain samples and moment estimates from a Bayesian posterior over latent variables. Recent work, however, indicates that importance sampling scales poorly -- in order to accurately approximate the true posterior, the required number of importance samples grows is exponential in the number of latent variables [Chatterjee and Diaconis, 2018]. Massively parallel importance sampling works around this issue by drawing $K$ samples for each of the $n$ latent variables and reasoning about all $K^n$ combinations of latent samples. In principle, we can reason efficiently over $K^n$ combinations of samples by exploiting conditional independencies in the generative model. However, in practice this requires complex algorithms that traverse backwards through the graphical model, and we need separate backward traversals for each computation (posterior expectations, marginals and samples). Our contribution is to exploit the source term trick from physics to entirely avoid the need to hand-write backward traversals. Instead, we demonstrate how to simply and easily compute all the required quantities -- posterior expectations, marginals and samples -- by differentiating through a slightly modified marginal likelihood estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17374v2</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sam Bowyer, Thomas Heap, Laurence Aitchison</dc:creator>
    </item>
    <item>
      <title>Perturbation-based Effect Measures for Compositional Data</title>
      <link>https://arxiv.org/abs/2311.18501</link>
      <description>arXiv:2311.18501v2 Announce Type: replace-cross 
Abstract: Existing effect measures for compositional features are inadequate for many modern applications for two reasons. First, modern datasets with compositional covariates, for example in microbiome research, display traits such as high-dimensionality and sparsity that can be poorly modelled with traditional parametric approaches. Second, assessing -- in an unbiased way -- how summary statistics of a composition (e.g., racial diversity) affect a response variable is not straightforward. In this work, we propose a framework based on hypothetical data perturbations that addresses both issues. Unlike many existing effect measures for compositional features, we do not define our effects based on a parametric model or a transformation of the data. Instead, we use perturbations to define interpretable statistical functionals on the compositions themselves, which we call average perturbation effects. These effects naturally account for confounding that biases frequently used marginal dependence analyses. We show how average perturbation effects can be estimated efficiently by deriving a perturbation-dependent reparametrization and applying semiparametric estimation techniques. We analyze the proposed estimators empirically on simulated and semi-synthetic data and demonstrate advantages over existing techniques on data from New York schools and microbiome data. For all proposed estimators, we provide confidence intervals with uniform asymptotic coverage guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18501v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anton Rask Lundborg, Niklas Pfister</dc:creator>
    </item>
    <item>
      <title>Estimating the linear relation between variables that are never jointly observed</title>
      <link>https://arxiv.org/abs/2403.00140</link>
      <description>arXiv:2403.00140v3 Announce Type: replace-cross 
Abstract: In modern experimental science there is a commonly encountered problem of estimating the coefficients of a linear regression in the context where the variables of interest can never be observed simultaneously. Assuming that the global experiment can be decomposed into sub-experiments with distinct first moments, we propose two estimators of the linear regression that take this additional information into account. We consider an estimator based on moments, and an estimator based on optimal transport theory. These estimators are proven to be consistent as well as asymptotically Gaussian under weak hypotheses. The asymptotic variance has no explicit expression, except in some particular cases, for which reason a stratified bootstrap approach is developed to build confidence intervals for the estimated parameters, whose consistency is also shown. A simulation study, assessing and comparing the finite sample performances of these estimators, demonstrated the advantages of the bootstrap approach in multiple realistic scenarios. An application to in vivo experiments, conducted in the context of studying radio-induced adverse effects on mice, revealed important relationships between the biomarkers of interest that could not be identified with the considered naive approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00140v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Polina Arsenteva, Mohamed Amine Benadjaoud, Herv\'e Cardot</dc:creator>
    </item>
    <item>
      <title>Review and Prospect of Algebraic Research in Equivalent Framework between Statistical Mechanics and Machine Learning Theory</title>
      <link>https://arxiv.org/abs/2406.10234</link>
      <description>arXiv:2406.10234v2 Announce Type: replace-cross 
Abstract: Mathematical equivalence between statistical mechanics and machine learning theory has been known since the 20th century, and researches based on such equivalence have provided novel methodology in both theoretical physics and statistical learning theory. For example, algebraic approach in statistical mechanics such as operator algebra enables us to analyze phase transition phenomena mathematically. In this paper, for theoretical physicists who are interested in artificial intelligence, we review and prospect algebraic researches in machine learning theory. If a learning machine has hierarchical structure or latent variables, then the random Hamiltonian cannot be expressed by any quadratic perturbation because it has singularities. To study an equilibrium state defined by such a singular random Hamiltonian, algebraic approach is necessary to derive asymptotic form of the free energy and the generalization error. We also introduce the most recent advance, in fact, theoretical foundation for alignment of artificial intelligence is now being constructed based on algebraic learning theory. This paper is devoted to the memory of Professor Huzihiro Araki who is a pioneer founder of algebraic research in both statistical mechanics and quantum field theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10234v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sumio Watanabe</dc:creator>
    </item>
  </channel>
</rss>
