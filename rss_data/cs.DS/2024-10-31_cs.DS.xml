<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Breaking the Bellman-Ford Shortest-Path Bound</title>
      <link>https://arxiv.org/abs/2410.23383</link>
      <description>arXiv:2410.23383v1 Announce Type: new 
Abstract: In this paper we give a single-source shortest-path algorithm that breaks, after over 65 years, the $O(n \cdot m)$ bound for the running time of the Bellman-Ford-Moore algorithm, where $n$ is the number of vertices and $m$ is the number of arcs of the graph. Our algorithm converts the input graph to a graph with nonnegative weights by performing at most $\min(2 \cdot \sqrt{n},2 \cdot \sqrt{m/\log n})$ calls to a modified version of Dijkstra's algorithm, such that the shortest-path trees are the same for the new graph as those for the original. When Dijkstra's algorithm is implemented using Fibonacci heaps, the running time of our algorithm is therefore $O(\sqrt{n} \cdot m + n \cdot \sqrt{m \log n})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23383v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amr Elmasry</dc:creator>
    </item>
    <item>
      <title>All-Hops Shortest Paths</title>
      <link>https://arxiv.org/abs/2410.23617</link>
      <description>arXiv:2410.23617v1 Announce Type: new 
Abstract: Let $G=(V,E,w)$ be a weighted directed graph without negative cycles. For two vertices $s,t\in V$, we let $d_{\le h}(s,t)$ be the minimum, according to the weight function $w$, of a path from $s$ to $t$ that uses at most $h$ edges, or hops. We consider algorithms for computing $d_{\le h}(s,t)$ for every $1\le h\le n$, where $n=|V|$, in various settings. We consider the single-pair, single-source and all-pairs versions of the problem. We also consider a distance oracle version of the problem in which we are not required to explicitly compute all distances $d_{\le h}(s,t)$, but rather return each one of these distances upon request. We consider both the case in which the edge weights are arbitrary, and in which they are small integers in the range $\{-M,\ldots,M\}$. For some of our results we obtain matching conditional lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23617v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Virginia Vassilevska Williams, Zoe Xi, Yinzhan Xu, Uri Zwick</dc:creator>
    </item>
    <item>
      <title>Lightweight Near-Additive Spanners</title>
      <link>https://arxiv.org/abs/2410.23826</link>
      <description>arXiv:2410.23826v1 Announce Type: new 
Abstract: An $(\alpha,\beta)$-spanner of a weighted graph $G=(V,E)$, is a subgraph $H$ such that for every $u,v\in V$, $d_G(u,v) \le d_H(u,v)\le\alpha\cdot d_G(u,v)+\beta$. The main parameters of interest for spanners are their size (number of edges) and their lightness (the ratio between the total weight of $H$ to the weight of a minimum spanning tree).
  In this paper we focus on near-additive spanners, where $\alpha=1+\varepsilon$ for arbitrarily small $\varepsilon&gt;0$. We show the first construction of {\em light} spanners in this setting. Specifically, for any integer parameter $k\ge 1$, we obtain an $(1+\varepsilon,O(k/\varepsilon)^k\cdot W(\cdot,\cdot))$-spanner with lightness $\tilde{O}(n^{1/k})$ (where $W(\cdot,\cdot)$ indicates for every pair $u, v \in V$ the heaviest edge in some shortest path between $u,v$). In addition, we can also bound the number of edges in our spanner by $O(kn^{1+3/k})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23826v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuval Gitlitz, Ofer Neiman, Richard Spence</dc:creator>
    </item>
    <item>
      <title>Feedback Vertex Set for pseudo-disk graphs in subexponential FPT time</title>
      <link>https://arxiv.org/abs/2410.23878</link>
      <description>arXiv:2410.23878v1 Announce Type: new 
Abstract: In this paper, we investigate the existence of parameterized algorithms running in subexponential time for two fundamental cycle-hitting problems: Feedback Vertex Set (FVS) and Triangle Hitting (TH). We focus on the class of pseudo-disk graphs, which forms a common generalization of several graph classes where such results exist, like disk graphs and square graphs. In these graphs, we show that TH can be solved in time $2^{O(k^{3/4}\log k)}n^{O(1)}$, and given a geometric representation FVS can be solved in time $2^{O(k^{6/7}\log k)}n^{O(1)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23878v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ga\'etan Berthe, Marin Bougeret, Daniel Gon\c{c}alves, Jean-Florent Raymond</dc:creator>
    </item>
    <item>
      <title>An Algorithm for a Modification of the Shortest Common Superstring Problem</title>
      <link>https://arxiv.org/abs/2410.23900</link>
      <description>arXiv:2410.23900v1 Announce Type: new 
Abstract: The purpose of this study is to develop an efficient algorithm to solve a variation of the NP-hard Shortest Common Superstring (SCS) problem. In this version of the problem, one string is allowed to have up to K mistakes, meaning it does not match the SCS in at most K places. Also, there is a slight constraint on the problem in that no string can be a substring of another. The algorithm proposed is exact, not an approximation, meaning it finds the best answer in all cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23900v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Gilfanov</dc:creator>
    </item>
    <item>
      <title>Clustering to Minimize Cluster-Aware Norm Objectives</title>
      <link>https://arxiv.org/abs/2410.24104</link>
      <description>arXiv:2410.24104v1 Announce Type: new 
Abstract: We initiate the study of the following general clustering problem. We seek to partition a given set $P$ of data points into $k$ clusters by finding a set $X$ of $k$ centers and assigning each data point to one of the centers. The cost of a cluster, represented by a center $x\in X$, is a monotone, symmetric norm $f$ (inner norm) of the vector of distances of points assigned to $x$. The goal is to minimize a norm $g$ (outer norm) of the vector of cluster costs. This problem, which we call $(f,g)$-Clustering, generalizes many fundamental clustering problems such as $k$-Center, $k$-Median , Min-Sum of Radii, and Min-Load $k$-Clustering . A recent line of research (Chakrabarty, Swamy [STOC'19]) studies norm objectives that are oblivious to the cluster structure such as $k$-Median and $k$-Center. In contrast, our problem models cluster-aware objectives including Min-Sum of Radii and Min-Load $k$-Clustering.
  Our main results are as follows. First, we design a constant-factor approximation algorithm for $(\textsf{top}_\ell,\mathcal{L}_1)$-Clustering where the inner norm ($\textsf{top}_\ell$) sums over the $\ell$ largest distances. Second, we design a constant-factor approximation\ for $(\mathcal{L}_\infty,\textsf{Ord})$-Clustering where the outer norm is a convex combination of $\textsf{top}_\ell$ norms (ordered weighted norm).</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24104v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin G. Herold, Evangelos Kipouridis, Joachim Spoerhase</dc:creator>
    </item>
    <item>
      <title>An algebraic interpretation of Pauli flow, leading to faster flow-finding algorithms</title>
      <link>https://arxiv.org/abs/2410.23439</link>
      <description>arXiv:2410.23439v1 Announce Type: cross 
Abstract: The one-way model of quantum computation is an alternative to the circuit model. A one-way computation is driven entirely by successive adaptive measurements of a pre-prepared entangled resource state. For each measurement, only one outcome is desired; hence a fundamental question is whether some intended measurement scheme can be performed in a robustly deterministic way. So-called flow structures witness robust determinism by providing instructions for correcting undesired outcomes. Pauli flow is one of the broadest of these structures and has been studied extensively. It is known how to find flow structures in polynomial time when they exist; nevertheless, their lengthy and complex definitions often hinder working with them.
  We simplify these definitions by providing a new algebraic interpretation of Pauli flow. This involves defining two matrices arising from the adjacency matrix of the underlying graph: the flow-demand matrix $M$ and the order-demand matrix $N$. We show that Pauli flow exists if and only if there is a right inverse $C$ of $M$ such that the product $NC$ forms the adjacency matrix of a directed acyclic graph. From the newly defined algebraic interpretation, we obtain $\mathcal{O}(n^3)$ algorithms for finding Pauli flow, improving on the previous $\mathcal{O}(n^4)$ bound for finding generalised flow, a weaker variant of flow, and $\mathcal{O}(n^5)$ bound for finding Pauli flow. We also introduce a first lower bound for the Pauli flow-finding problem, by linking it to the matrix invertibility and multiplication problems over $\mathbb{F}_2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23439v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Mitosek, Miriam Backens</dc:creator>
    </item>
    <item>
      <title>Coach Reservation for Groups Requests</title>
      <link>https://arxiv.org/abs/2410.23542</link>
      <description>arXiv:2410.23542v1 Announce Type: cross 
Abstract: Passenger transportation is a core aspect of a railway company's business, with ticket sales playing a central role in generating revenue. Profitable operations in this context rely heavily on the effectiveness of reject-or-assign policies for coach reservations. As in traditional revenue management, uncertainty in demand presents a significant challenge, particularly when seat availability is limited and passengers have varying itineraries. We extend traditional models from the literature by addressing both offline and online versions of the coach reservation problem for group requests, where two or more passengers must be seated in the same coach. For the offline case, in which all requests are known in advance, we propose an exact mathematical programming formulation that incorporates a first-come, first-served fairness condition, ensuring compliance with transportation regulations. We also propose algorithms for online models of the problem, in which requests are only revealed upon arrival, and the reject-or-assign decisions must be made in real-time. Our analysis for one of these models overcomes known barriers in the packing literature, yielding strong competitive ratio guarantees when group sizes are relatively small compared to coach capacity - a common scenario in practice. Using data from Shinkansen Tokyo-Shin-Osaka line, our numerical experiments demonstrate the practical effectiveness of the proposed policies. Our work provides compelling evidence supporting the adoption of fairness constraints, as revenue losses are minimal, and simple algorithms are sufficient for real-time decision-making. Moreover, our findings provide a strong support for the adoption of fairness in the railway industry and highlight the financial viability of a regulatory framework that allows railway companies to delay coach assignments if they adhere to stricter rules regarding request rejections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23542v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos H. Cardonha, Arvind U. Raghunathan</dc:creator>
    </item>
    <item>
      <title>Anytime-Constrained Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2410.23637</link>
      <description>arXiv:2410.23637v1 Announce Type: cross 
Abstract: We introduce anytime constraints to the multi-agent setting with the corresponding solution concept being anytime-constrained equilibrium (ACE). Then, we present a comprehensive theory of anytime-constrained Markov games, which includes (1) a computational characterization of feasible policies, (2) a fixed-parameter tractable algorithm for computing ACE, and (3) a polynomial-time algorithm for approximately computing feasible ACE. Since computing a feasible policy is NP-hard even for two-player zero-sum games, our approximation guarantees are the best possible under worst-case analysis. We also develop the first theory of efficient computation for action-constrained Markov games, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23637v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan, Xiaojin Zhu</dc:creator>
    </item>
    <item>
      <title>Robust Sparse Regression with Non-Isotropic Designs</title>
      <link>https://arxiv.org/abs/2410.23937</link>
      <description>arXiv:2410.23937v1 Announce Type: cross 
Abstract: We develop a technique to design efficiently computable estimators for sparse linear regression in the simultaneous presence of two adversaries: oblivious and adaptive. We design several robust algorithms that outperform the state of the art even in the special case when oblivious adversary simply adds Gaussian noise. In particular, we provide a polynomial-time algorithm that with high probability recovers the signal up to error $O(\sqrt{\varepsilon})$ as long as the number of samples $n \ge \tilde{O}(k^2/\varepsilon)$, only assuming some bounds on the third and the fourth moments of the distribution ${D}$ of the design.
  In addition, prior to this work, even in the special case of Gaussian design and noise, no polynomial time algorithm was known to achieve error $o(\sqrt{\varepsilon})$ in the sparse setting $n &lt; d^2$. We show that under some assumptions on the fourth and the eighth moments of ${D}$, there is a polynomial-time algorithm that achieves error $o(\sqrt{\varepsilon})$ as long as $n \ge \tilde{O}(k^4 / \varepsilon^3)$. For Gaussian distribution, this algorithm achieves error $O(\varepsilon^{3/4})$. Moreover, our algorithm achieves error $o(\sqrt{\varepsilon})$ for all log-concave distributions if $\varepsilon \le 1/\text{polylog(d)}$.
  Our algorithms are based on the filtering of the covariates that uses sum-of-squares relaxations, and weighted Huber loss minimization with $\ell_1$ regularizer. We provide a novel analysis of weighted penalized Huber loss that is suitable for heavy-tailed designs in the presence of two adversaries. Furthermore, we complement our algorithmic results with Statistical Query lower bounds, providing evidence that our estimators are likely to have nearly optimal sample complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23937v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chih-Hung Liu, Gleb Novikov</dc:creator>
    </item>
    <item>
      <title>Interactive proofs for verifying (quantum) learning and testing</title>
      <link>https://arxiv.org/abs/2410.23969</link>
      <description>arXiv:2410.23969v1 Announce Type: cross 
Abstract: We consider the problem of testing and learning from data in the presence of resource constraints, such as limited memory or weak data access, which place limitations on the efficiency and feasibility of testing or learning. In particular, we ask the following question: Could a resource-constrained learner/tester use interaction with a resource-unconstrained but untrusted party to solve a learning or testing problem more efficiently than they could without such an interaction? In this work, we answer this question both abstractly and for concrete problems, in two complementary ways: For a wide variety of scenarios, we prove that a resource-constrained learner cannot gain any advantage through classical interaction with an untrusted prover. As a special case, we show that for the vast majority of testing and learning problems in which quantum memory is a meaningful resource, a memory-constrained quantum algorithm cannot overcome its limitations via classical communication with a memory-unconstrained quantum prover. In contrast, when quantum communication is allowed, we construct a variety of interactive proof protocols, for specific learning and testing problems, which allow memory-constrained quantum verifiers to gain significant advantages through delegation to untrusted provers. These results highlight both the limitations and potential of delegating learning and testing problems to resource-rich but untrusted third parties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23969v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias C. Caro, Jens Eisert, Marcel Hinsche, Marios Ioannou, Alexander Nietner, Ryan Sweke</dc:creator>
    </item>
    <item>
      <title>Convex optimization with $p$-norm oracles</title>
      <link>https://arxiv.org/abs/2410.24158</link>
      <description>arXiv:2410.24158v1 Announce Type: cross 
Abstract: In recent years, there have been significant advances in efficiently solving $\ell_s$-regression using linear system solvers and $\ell_2$-regression [Adil-Kyng-Peng-Sachdeva, J. ACM'24]. Would efficient $\ell_p$-norm solvers lead to even faster rates for solving $\ell_s$-regression when $2 \leq p &lt; s$? In this paper, we give an affirmative answer to this question and show how to solve $\ell_s$-regression using $\tilde{O}(n^{\frac{\nu}{1+\nu}})$ iterations of solving smoothed $\ell_s$ regression problems, where $\nu := \frac{1}{p} - \frac{1}{s}$. To obtain this result, we provide improved accelerated rates for convex optimization problems when given access to an $\ell_p^s(\lambda)$-proximal oracle, which, for a point $c$, returns the solution of the regularized problem $\min_{x} f(x) + \lambda \|x-c\|_p^s$. Additionally, we show that the rates we establish for the $\ell_p^s(\lambda)$-proximal oracle are near-optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24158v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deeksha Adil, Brian Bullins, Arun Jambulapati, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Structural Parameterizations of Vertex Integrity</title>
      <link>https://arxiv.org/abs/2311.05892</link>
      <description>arXiv:2311.05892v3 Announce Type: replace 
Abstract: The graph parameter vertex integrity measures how vulnerable a graph is to a removal of a small number of vertices. More precisely, a graph with small vertex integrity admits a small number of vertex removals to make the remaining connected components small. In this paper, we initiate a systematic study of structural parameterizations of the problem of computing the unweighted/weighted vertex integrity. As structural graph parameters, we consider well-known parameters such as clique-width, treewidth, pathwidth, treedepth, modular-width, neighborhood diversity, twin cover number, and cluster vertex deletion number. We show several positive and negative results and present sharp complexity contrasts. We also show that the vertex integrity can be approximated within an $\mathcal{O}(\log \mathsf{opt})$ factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.05892v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatsuya Gima, Tesshu Hanaka, Yasuaki Kobayashi, Ryota Murai, Hirotaka Ono, Yota Otachi</dc:creator>
    </item>
    <item>
      <title>Computing Diameter +1 in Truly Subquadratic Time for Unit-Disk Graphs</title>
      <link>https://arxiv.org/abs/2401.12881</link>
      <description>arXiv:2401.12881v2 Announce Type: replace 
Abstract: Finding the diameter of a graph in general cannot be done in truly subquadratic assuming the Strong Exponential Time Hypothesis (SETH), even when the underlying graph is unweighted and sparse. When restricting to concrete classes of graphs and assuming SETH, planar graphs and minor-free graphs admit truly subquadratic algorithms, while geometric intersection graphs of unit balls, congruent equilateral triangles, and unit segments do not. Unit-disk graphs are one of the major open cases where the complexity of diameter computation remains unknown. More generally, it is conjectured that a truly-subquadratic time algorithm exists for pseudo-disk graphs where each pair of objects has at most two intersections on the boundary.
  In this paper, we show a truly-subquadratic algorithm of running time $\tilde{O}(n^{2-1/18})$, for finding the diameter in a unit-disk graph, whose output differs from the optimal solution by at most 1. This is the first algorithm that provides an additive guarantee in distortion, independent of the size or the diameter of the graph. Our algorithm requires two important technical elements. First, we show that for the intersection graph of pseudo-disks, the graph VC-dimension, either of $k$-hop balls or the distance encoding vectors, is 4. Second, we introduce a clique-based $r$-clustering for geometric intersection graphs, which is an analog of the $r$-division construction for planar graphs. We also showcase the new techniques by establishing new results for distance oracles for unit-disk graphs with subquadratic storage and $O(1)$ query time. The results naturally extend to unit $L_1$- or $L_\infty$-disks and fat pseudo-disks of similar size. Last, if the pseudo-disks additionally have bounded ply, we have a truly-subquadratic algorithm to find the exact diameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12881v2</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Hsien-Chih Chang, Jie Gao, Hung Le</dc:creator>
    </item>
    <item>
      <title>Online Unbounded Knapsack</title>
      <link>https://arxiv.org/abs/2407.02045</link>
      <description>arXiv:2407.02045v2 Announce Type: replace 
Abstract: We analyze the competitive ratio and the advice complexity of the online unbounded knapsack problem. An instance is given as a sequence of n items with a size and a value each, and an algorithm has to decide how often to pack each item into a knapsack of bounded capacity. The items are given online and the total size of the packed items must not exceed the knapsack's capacity, while the objective is to maximize the total value of the packed items. While each item can only be packed once in the classical 0-1 knapsack problem, the unbounded version allows for items to be packed multiple times. We show that the simple unbounded knapsack problem, where the size of each item is equal to its value, allows for a competitive ratio of 2. We also analyze randomized algorithms and show that, in contrast to the 0-1 knapsack problem, one uniformly random bit cannot improve an algorithm's performance. More randomness lowers the competitive ratio to less than 1.736, but it can never be below 1.693. In the advice complexity setting, we measure how many bits of information the algorithm has to know to achieve some desired solution quality. For the simple unbounded knapsack problem, one advice bit lowers the competitive ratio to 3/2. While this cannot be improved with fewer than log(n) advice bits for instances of length n, a competitive ratio of 1+epsilon can be achieved with O(log(n/epsilon)/epsilon) advice bits for any epsilon&gt;0. We further show that no amount of advice bounded by a function f(n) allows an algorithm to be optimal. We also study the online general unbounded knapsack problem and show that it does not allow for any bounded competitive ratio for deterministic and randomized algorithms, as well as for algorithms using fewer than log(n) advice bits. We also provide an algorithm that uses O(log(n/epsilon)/epsilon) advice bits to achieve a competitive ratio of 1+epsilon for any epsilon&gt;0.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02045v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hans-Joachim B\"ockenhauer, Matthias Gehnen, Juraj Hromkovi\v{c}, Ralf Klasing, Dennis Komm, Henri Lotze, Daniel Mock, Peter Rossmanith, Moritz Stocker</dc:creator>
    </item>
    <item>
      <title>GreedyML: A Parallel Algorithm for Maximizing Submodular Functions</title>
      <link>https://arxiv.org/abs/2403.10332</link>
      <description>arXiv:2403.10332v2 Announce Type: replace-cross 
Abstract: We describe a parallel approximation algorithm for maximizing monotone submodular functions subject to hereditary constraints on distributed memory multiprocessors. Our work is motivated by the need to solve submodular optimization problems on massive data sets, for practical applications in areas such as data summarization, machine learning, and graph sparsification. Our work builds on the randomized distributed RandGreedI algorithm, proposed by Barbosa, Ene, Nguyen, and Ward (2015). This algorithm computes a distributed solution by randomly partitioning the data among all the processors and then employing a single accumulation step in which all processors send their partial solutions to one processor. However, for large problems, the accumulation step could exceed the memory available on a processor, and the processor which performs the accumulation could become a computational bottleneck.
  Here, we propose a generalization of the RandGreedI algorithm that employs multiple accumulation steps to reduce the memory required. We analyze the approximation ratio and the time complexity of the algorithm (in the BSP model). We also evaluate the new GreedyML algorithm on three classes of problems, and report results from massive data sets with millions of elements. The results show that the GreedyML algorithm can solve problems where the sequential Greedy and distributed RandGreedI algorithms fail due to memory constraints. For certain computationally intensive problems, the GreedyML algorithm can be faster than the RandGreedI algorithm. The observed approximation quality of the solutions computed by the GreedyML algorithm closely matches those obtained by the RandGreedI algorithm on these problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.10332v2</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivaram Gopal, S M Ferdous, Hemanta K. Maji, Alex Pothen</dc:creator>
    </item>
    <item>
      <title>Aleph Filter: To Infinity in Constant Time</title>
      <link>https://arxiv.org/abs/2404.04703</link>
      <description>arXiv:2404.04703v5 Announce Type: replace-cross 
Abstract: Filter data structures are widely used in various areas of computer science to answer approximate set-membership queries. In many applications, the data grows dynamically, requiring their filters to expand along with the data. However, existing methods for expanding filters cannot maintain stable performance, memory footprint, and false positive rate (FPR) simultaneously. We address this problem with Aleph Filter, which makes the following contributions. (1) It supports all operations (insertions, queries, deletes, etc.) in constant time, no matter how much the data grows. (2) Given an estimate of how much the data will ultimately grow, Aleph Filter provides a memory vs. FPR trade-offs on par with static filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04703v5</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niv Dayan, Ioana-Oriana Bercea, Rasmus Pagh</dc:creator>
    </item>
    <item>
      <title>Deterministic Policies for Constrained Reinforcement Learning in Polynomial Time</title>
      <link>https://arxiv.org/abs/2405.14183</link>
      <description>arXiv:2405.14183v2 Announce Type: replace-cross 
Abstract: We present a novel algorithm that efficiently computes near-optimal deterministic policies for constrained reinforcement learning (CRL) problems. Our approach combines three key ideas: (1) value-demand augmentation, (2) action-space approximate dynamic programming, and (3) time-space rounding. Our algorithm constitutes a fully polynomial-time approximation scheme (FPTAS) for any time-space recursive (TSR) cost criteria. A TSR criteria requires the cost of a policy to be computable recursively over both time and (state) space, which includes classical expectation, almost sure, and anytime constraints. Our work answers three open questions spanning two long-standing lines of research: polynomial-time approximability is possible for 1) anytime-constrained policies, 2) almost-sure-constrained policies, and 3) deterministic expectation-constrained policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14183v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan</dc:creator>
    </item>
    <item>
      <title>The periodic structure of local consistency</title>
      <link>https://arxiv.org/abs/2406.19685</link>
      <description>arXiv:2406.19685v2 Announce Type: replace-cross 
Abstract: We connect the mixing behaviour of random walks over a graph to the power of the local-consistency algorithm for the solution of the corresponding constraint satisfaction problem (CSP). We extend this connection to arbitrary CSPs and their promise variant. In this way, we establish a linear-level (and, thus, optimal) lower bound against the local-consistency algorithm applied to the class of aperiodic promise CSPs. The proof is based on a combination of the probabilistic method for random Erd\H{o}s-R\'enyi hypergraphs and a structural result on the number of fibers (i.e., long chains of hyperedges) in sparse hypergraphs of large girth. As a corollary, we completely classify the power of local consistency for the approximate graph homomorphism problem by establishing that, in the nontrivial cases, the problem has linear width.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19685v2</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lorenzo Ciardo, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
  </channel>
</rss>
