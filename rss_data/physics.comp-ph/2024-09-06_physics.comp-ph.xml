<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>AI-Machine Learning-Enabled Tokamak Digital Twin</title>
      <link>https://arxiv.org/abs/2409.03112</link>
      <description>arXiv:2409.03112v1 Announce Type: new 
Abstract: In addressing the Department of Energy's April, 2022 announcement of a Bold Decadal Vision for delivering a Fusion Pilot Plant by 2035, associated software tools need to be developed for the integration of real world engineering and supply chain data with advanced science models that are accelerated with Machine Learning. An associated research and development effort has been introduced here with promising early progress on the delivery of a realistic Digital Twin Tokamak that has benefited from accelerated advances by the Princeton University AI Deep Learning innovative near-real-time simulators accompanied by technological capabilities from the NVIDIA Omniverse, an open computing platform for building and operating applications that connect with leading scientific computing visualization software. Working with the CAD files for the GA/DIII-D tokamak including equilibrium evolution as an exemplar tokamak application using Omniverse, the Princeton-NVIDIA collaboration has integrated modern AI/HPC-enabled near-real-time kinetic dynamics to connect and accelerate state-of-the-art, synthetic, HPC simulators to model fusion devices and control systems. The overarching goal is to deliver an interactive scientific digital twin of an advanced MFE tokamak that enables near-real-time simulation workflows built with Omniverse to eventually help open doors to new capabilities for generating clean power for a better future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03112v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.plasm-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>William Tang, Eliot Feibush, Ge Dong, Noah Borthwick, Apollo Lee, Juan-Felipe Gomez, Tom Gibbs, John Stone, Peter Messmer, Jack Wells, Xishuo Wei, Zhihong Lin</dc:creator>
    </item>
    <item>
      <title>Efficient prediction of potential energy surface and physical properties with Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2409.03430</link>
      <description>arXiv:2409.03430v1 Announce Type: new 
Abstract: The application of machine learning methodologies for predicting properties within materials science has garnered significant attention. Among recent advancements, Kolmogorov-Arnold Networks (KANs) have emerged as a promising alternative to traditional Multi-Layer Perceptrons (MLPs). This study evaluates the impact of substituting MLPs with KANs within three established machine learning frameworks: Allegro, Neural Equivariant Interatomic Potentials (NequIP), and the Edge-Based Tensor Prediction Graph Neural Network (ETGNN). Our results demonstrate that the integration of KANs generally yields enhanced prediction accuracies. Specifically, replacing MLPs with KANs in the output blocks leads to notable improvements in accuracy and, in certain scenarios, also results in reduced training times. Furthermore, employing KANs exclusively in the output block facilitates faster inference and improved computational efficiency relative to utilizing KANs throughout the entire model. The selection of an optimal basis function for KANs is found to be contingent upon the particular problem at hand. Our results demonstrate the strong potential of KANs in enhancing machine learning potentials and material property predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03430v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rui Wang, Hongyu Yu, Yang Zhong, Hongjun Xiang</dc:creator>
    </item>
    <item>
      <title>Mean field lattice Boltzmann model for reactive mixtures in porous media</title>
      <link>https://arxiv.org/abs/2409.02930</link>
      <description>arXiv:2409.02930v1 Announce Type: cross 
Abstract: A new lattice Boltzmann model (LBM) is presented to describe chemically reacting multicomponent fluid flow in homogenised porous media. In this work, towards further generalizing the multicomponent reactive lattice Boltzmann model, we propose a formulation which is capable of performing reactive multicomponent flow computation in porous media at the representative elementary volume (REV) scale. To that end, the submodel responsible for interspecies diffusion has been upgraded to include Knudsen diffusion, whereas the kinetic equations for the species, the momentum and the energy have been rewritten to accommodate the effects of volume fraction of a porous media though careful choice of the equilibrium distribution functions. Verification of the mesoscale kinetic system of equations by a Chapman--Enskog analysis reveals that at the macroscopic scale, the homogenized Navier--Stokes equations for compressible multicomponent reactive flows are recovered. The Dusty Gas Model (DGM) capability hence formulated is validated over a wide pressure range by comparison of experimental flow rates of component species counter diffusing through capillary tubes. Next, for developing a capability to compute heterogeneous reactions, source terms for maintaining energy and mass balance across the fluid phase species and the surface adsorbed phase species are proposed. The complete model is then used to perform detailed chemistry simulations in porous electrodes of a Solid Oxide Fuel Cell (SOFC), thereby predicting polarization curves which are of practical interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02930v1</guid>
      <category>physics.flu-dyn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nilesh Sawant, Ilya Karlin</dc:creator>
    </item>
    <item>
      <title>DiffGrad for Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2409.03239</link>
      <description>arXiv:2409.03239v1 Announce Type: cross 
Abstract: Physics-Informed Neural Networks (PINNs) are regarded as state-of-the-art tools for addressing highly nonlinear problems based on partial differential equations. Despite their broad range of applications, PINNs encounter several performance challenges, including issues related to efficiency, minimization of computational cost, and enhancement of accuracy. Burgers' equation, a fundamental equation in fluid dynamics that is extensively used in PINNs, provides flexible results with the Adam optimizer that does not account for past gradients. This paper introduces a novel strategy for solving Burgers' equation by incorporating DiffGrad with PINNs, a method that leverages the difference between current and immediately preceding gradients to enhance performance. A comprehensive computational analysis is conducted using optimizers such as Adam, Adamax, RMSprop, and DiffGrad to evaluate and compare their effectiveness. Our approach includes visualizing the solutions over space at various time intervals to demonstrate the accuracy of the network. The results show that DiffGrad not only improves the accuracy of the solution but also reduces training time compared to the other optimizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03239v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jamshaid Ul Rahman,  Nimra</dc:creator>
    </item>
    <item>
      <title>Supercomputer model of finite-dimensional quantum electrodynamics applications</title>
      <link>https://arxiv.org/abs/2403.07042</link>
      <description>arXiv:2403.07042v3 Announce Type: replace 
Abstract: A general scheme is given for supercomputer simulation of quantum processes, which are described by various modifications of finite-dimensional cavity quantum electrodynamics models, including Jaynes-Cummings-Hubbard model and Tavis-Cummings-Hubbard model. Conclusions and recommendations are illustrated using two examples: approximate model of hydrogen bonding and model of photon motion on a two-dimensional plane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07042v3</guid>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1134/S1995080224603849</arxiv:DOI>
      <dc:creator>Wanshun Li, Hui-hui Miao, Yuri Igorevich Ozhigov</dc:creator>
    </item>
    <item>
      <title>Understanding the Impact of openPMD on BIT1, a Particle-in-Cell Monte Carlo Code, through Instrumentation, Monitoring, and In-Situ Analysis</title>
      <link>https://arxiv.org/abs/2406.19058</link>
      <description>arXiv:2406.19058v3 Announce Type: replace 
Abstract: Particle-in-Cell Monte Carlo simulations on large-scale systems play a fundamental role in understanding the complexities of plasma dynamics in fusion devices. Efficient handling and analysis of vast datasets are essential for advancing these simulations. Previously, we addressed this challenge by integrating openPMD with BIT1, a Particle-in-Cell Monte Carlo code, streamlining data streaming and storage. This integration not only enhanced data management but also improved write throughput and storage efficiency. In this work, we delve deeper into the impact of BIT1 openPMD BP4 instrumentation, monitoring, and in-situ analysis. Utilizing cutting-edge profiling and monitoring tools such as gprof, CrayPat, Cray Apprentice2, IPM, and Darshan, we dissect BIT1's performance post-integration, shedding light on computation, communication, and I/O operations. Fine-grained instrumentation offers insights into BIT1's runtime behavior, while immediate monitoring aids in understanding system dynamics and resource utilization patterns, facilitating proactive performance optimization. Advanced visualization techniques further enrich our understanding, enabling the optimization of BIT1 simulation workflows aimed at controlling plasma-material interfaces with improved data analysis and visualization at every checkpoint without causing any interruption to the simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19058v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>physics.plasm-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy J. Williams, Stefan Costea, Allen D. Malony, David Tskhakaya, Leon Kos, Ales Podolnik, Jakub Hromadka, Kevin Huck, Erwin Laure, Stefano Markidis</dc:creator>
    </item>
    <item>
      <title>Large Scale Training of Graph Neural Networks for Optimal Markov-Chain Partitioning Using the Kemeny Constant</title>
      <link>https://arxiv.org/abs/2312.14847</link>
      <description>arXiv:2312.14847v3 Announce Type: replace-cross 
Abstract: Traditional clustering algorithms often struggle to capture the complex relationships within graphs and generalise to arbitrary clustering criteria. The emergence of graph neural networks (GNNs) as a powerful framework for learning representations of graph data provides new approaches to solving the problem. Previous work has shown GNNs to be capable of proposing partitionings using a variety of criteria, however, these approaches have not yet been extended to work on Markov chains or kinetic networks. These arise frequently in the study of molecular systems and are of particular interest to the biochemical modelling community. In this work, we propose several GNN-based architectures to tackle the graph partitioning problem for Markov Chains described as kinetic networks. This approach aims to minimize how much a proposed partitioning changes the Kemeny constant. We propose using an encoder-decoder architecture and show how simple GraphSAGE-based GNNs with linear layers can outperform much larger and more expressive attention-based models in this context. As a proof of concept, we first demonstrate the method's ability to cluster randomly connected graphs. We also use a linear chain architecture corresponding to a 1D free energy profile as our kinetic network. Subsequently, we demonstrate the effectiveness of our method through experiments on a data set derived from molecular dynamics. We compare the performance of our method to other partitioning techniques such as PCCA+. We explore the importance of feature and hyperparameter selection and propose a general strategy for large-scale parallel training of GNNs for discovering optimal graph partitionings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14847v3</guid>
      <category>physics.bio-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1021/acs.jpcb.3c08213</arxiv:DOI>
      <arxiv:journal_reference>J. Phys. Chem. B 2024, 128, 34, 8103-8115</arxiv:journal_reference>
      <dc:creator>Sam Alexander Martino, Jo\~ao Morado, Chenghao Li, Zhenghao Lu, Edina Rosta</dc:creator>
    </item>
    <item>
      <title>Optimizing BIT1, a Particle-in-Cell Monte Carlo Code, with OpenMP/OpenACC and GPU Acceleration</title>
      <link>https://arxiv.org/abs/2404.10270</link>
      <description>arXiv:2404.10270v2 Announce Type: replace-cross 
Abstract: On the path toward developing the first fusion energy devices, plasma simulations have become indispensable tools for supporting the design and development of fusion machines. Among these critical simulation tools, BIT1 is an advanced Particle-in-Cell code with Monte Carlo collisions, specifically designed for modeling plasma-material interaction and, in particular, analyzing the power load distribution on tokamak divertors. The current implementation of BIT1 relies exclusively on MPI for parallel communication and lacks support for GPUs. In this work, we address these limitations by designing and implementing a hybrid, shared-memory version of BIT1 capable of utilizing GPUs. For shared-memory parallelization, we rely on OpenMP and OpenACC, using a task-based approach to mitigate load-imbalance issues in the particle mover. On an HPE Cray EX computing node, we observe an initial performance improvement of approximately 42%, with scalable performance showing an enhancement of about 38% when using 8 MPI ranks. Still relying on OpenMP and OpenACC, we introduce the first version of BIT1 capable of using GPUs. We investigate two different data movement strategies: unified memory and explicit data movement. Overall, we report BIT1 data transfer findings during each PIC cycle. Among BIT1 GPU implementations, we demonstrate performance improvement through concurrent GPU utilization, especially when MPI ranks are assigned to dedicated GPUs. Finally, we analyze the performance of the first BIT1 GPU porting with the NVIDIA Nsight tools to further our understanding of BIT1 computational efficiency for large-scale plasma simulations, capable of exploiting current supercomputer infrastructures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10270v2</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-63749-0_22</arxiv:DOI>
      <dc:creator>Jeremy J. Williams, Felix Liu, David Tskhakaya, Stefan Costea, Ales Podolnik, Stefano Markidis</dc:creator>
    </item>
    <item>
      <title>Adaptive variational quantum computing approaches for Green's functions and nonlinear susceptibilities</title>
      <link>https://arxiv.org/abs/2407.01313</link>
      <description>arXiv:2407.01313v2 Announce Type: replace-cross 
Abstract: We present and benchmark quantum computing approaches for calculating real-time single-particle Green's functions and nonlinear susceptibilities of Hamiltonian systems. The approaches leverage adaptive variational quantum algorithms for state preparation and propagation. Using automatically generated compact circuits, the dynamical evolution is performed over sufficiently long times to achieve adequate frequency resolution of the response functions. We showcase accurate Green's function calculations using a statevector simulator on classical hardware for Fermi-Hubbard chains of 4 and 6 sites, with maximal ansatz circuit depths of 65 and 424 layers, respectively, and for the molecule LiH with a maximal ansatz circuit depth of 81 layers. Additionally, we consider an antiferromagnetic quantum spin-1 model that incorporates the Dzyaloshinskii-Moriya interaction to illustrate calculations of the third-order nonlinear susceptibilities, which can be measured in two-dimensional coherent spectroscopy experiments. These results demonstrate that real-time approaches using adaptive parameterized circuits to evaluate linear and nonlinear response functions can be feasible with near-term quantum processors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01313v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Mootz, Thomas Iadecola, Yong-Xin Yao</dc:creator>
    </item>
    <item>
      <title>What if? Numerical weather prediction at the crossroads</title>
      <link>https://arxiv.org/abs/2407.03787</link>
      <description>arXiv:2407.03787v2 Announce Type: replace-cross 
Abstract: This paper provides an outlook on the future of operational weather prediction given the recent evolution in science, computing and machine learning. In many parts, this evolution strongly deviates from the strategy operational centres have formulated only several years ago. New opportunities in digital technology have greatly accelerated progress, and the full integration of computational science in numerical weather prediction centres is common knowledge now. Within the last few years, a vast machine learning research community has emerged for creating new and tailor-made products, accelerating processing and - most of all - creating emulators for the entire production of global forecasts that outperform traditional systems at the spatial resolution of the training data. In this context, the role of both numerical models and observations is changing from being equation to data driven. Analyses and reanalyses are becoming the new currency for training machine learning, and operational centres are in a powerful position as they generate these datasets based on decades worth of experience. This environment creates incredible opportunities to progress much faster than in the past but also uncertainties about what the strategic implications on defining cost-effective and sustainable research and operations are, and how to achieve sufficient high-performance computing and data handling capacities. It will take individual national public services a while to understand what to focus on and how to coordinate their substantial investments in staff and infrastructure at institutional, national and international level. This paper addresses this new situation operational weather prediction finds itself in through formulating the most likely "what if?" scenarios for the near future and provides an outline for how weather centres could adapt.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03787v2</guid>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Peter Bauer</dc:creator>
    </item>
    <item>
      <title>On the design space between molecular mechanics and machine learning force fields</title>
      <link>https://arxiv.org/abs/2409.01931</link>
      <description>arXiv:2409.01931v2 Announce Type: replace-cross 
Abstract: A force field as accurate as quantum mechanics (QM) and as fast as molecular mechanics (MM), with which one can simulate a biomolecular system efficiently enough and meaningfully enough to get quantitative insights, is among the most ardent dreams of biophysicists -- a dream, nevertheless, not to be fulfilled any time soon. Machine learning force fields (MLFFs) represent a meaningful endeavor towards this direction, where differentiable neural functions are parametrized to fit ab initio energies, and furthermore forces through automatic differentiation. We argue that, as of now, the utility of the MLFF models is no longer bottlenecked by accuracy but primarily by their speed (as well as stability and generalizability), as many recent variants, on limited chemical spaces, have long surpassed the chemical accuracy of $1$ kcal/mol -- the empirical threshold beyond which realistic chemical predictions are possible -- though still magnitudes slower than MM. Hoping to kindle explorations and designs of faster, albeit perhaps slightly less accurate MLFFs, in this review, we focus our attention on the design space (the speed-accuracy tradeoff) between MM and ML force fields. After a brief review of the building blocks of force fields of either kind, we discuss the desired properties and challenges now faced by the force field development community, survey the efforts to make MM force fields more accurate and ML force fields faster, envision what the next generation of MLFF might look like.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01931v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanqing Wang, Kenichiro Takaba, Michael S. Chen, Marcus Wieder, Yuzhi Xu, Tong Zhu, John Z. H. Zhang, Arnav Nagle, Kuang Yu, Xinyan Wang, Daniel J. Cole, Joshua A. Rackers, Kyunghyun Cho, Joe G. Greener, Peter Eastman, Stefano Martiniani, Mark E. Tuckerman</dc:creator>
    </item>
  </channel>
</rss>
