<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Jun 2025 04:00:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Transaction Categorization with Relational Deep Learning in QuickBooks</title>
      <link>https://arxiv.org/abs/2506.09234</link>
      <description>arXiv:2506.09234v1 Announce Type: new 
Abstract: Automatic transaction categorization is crucial for enhancing the customer experience in QuickBooks by providing accurate accounting and bookkeeping. The distinct challenges in this domain stem from the unique formatting of transaction descriptions, the wide variety of transaction categories, and the vast scale of the data involved. Furthermore, organizing transaction data in a relational database creates difficulties in developing a unified model that covers the entire database. In this work, we develop a novel graph-based model, named Rel-Cat, which is built directly over the relational database. We introduce a new formulation of transaction categorization as a link prediction task within this graph structure. By integrating techniques from natural language processing and graph machine learning, our model not only outperforms the existing production model in QuickBooks but also scales effectively to a growing customer base with a simpler, more effective architecture without compromising on accuracy. This design also helps tackle a key challenge of the cold start problem by adapting to minimal data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09234v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaiwen Dong, Padmaja Jonnalagedda, Xiang Gao, Ayan Acharya, Maria Kissa, Mauricio Flores, Nitesh V. Chawla, Kamalika Das</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Design Structure Matrix Optimization</title>
      <link>https://arxiv.org/abs/2506.09749</link>
      <description>arXiv:2506.09749v1 Announce Type: new 
Abstract: In complex engineering systems, the interdependencies among components or development activities are often modeled and analyzed using Design Structure Matrix (DSM). Reorganizing elements within a DSM to minimize feedback loops and enhance modularity or process efficiency constitutes a challenging combinatorial optimization (CO) problem in engineering design and operations. As problem sizes increase and dependency networks become more intricate, traditional optimization methods that solely use mathematical heuristics often fail to capture the contextual nuances and struggle to deliver effective solutions. In this study, we explore the potential of Large Language Models (LLMs) for helping solve such CO problems by leveraging their capabilities for advanced reasoning and contextual understanding. We propose a novel LLM-based framework that integrates network topology with contextual domain knowledge for iterative optimization of DSM element sequencing - a common CO problem. Experiments on various DSM cases show that our method consistently achieves faster convergence and superior solution quality compared to both stochastic and deterministic baselines. Notably, we find that incorporating contextual domain knowledge significantly enhances optimization performance regardless of the chosen LLM backbone. These findings highlight the potential of LLMs to solve complex engineering CO problems by combining semantic and mathematical reasoning. This approach paves the way towards a new paradigm in LLM-based engineering design optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09749v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuo Jiang, Min Xie, Jianxi Luo</dc:creator>
    </item>
    <item>
      <title>Intelligent Design 4.0: Paradigm Evolution Toward the Agentic AI Era</title>
      <link>https://arxiv.org/abs/2506.09755</link>
      <description>arXiv:2506.09755v1 Announce Type: new 
Abstract: Research and practice in Intelligent Design (ID) have significantly enhanced engineering innovation, efficiency, quality, and productivity over recent decades, fundamentally reshaping how engineering designers think, behave, and interact with design processes. The recent emergence of Foundation Models (FMs), particularly Large Language Models (LLMs), has demonstrated general knowledge-based reasoning capabilities, and open new paths and avenues for further transformation in engineering design. In this context, this paper introduces Intelligent Design 4.0 (ID 4.0) as an emerging paradigm empowered by agentic AI systems. We review the historical evolution of ID across four distinct stages: rule-based expert systems, task-specific machine learning models, large-scale foundation AI models, and the recent emerging paradigm of multi-agent collaboration. We propose a conceptual framework for ID 4.0 and discuss its potential to support end-to-end automation of engineering design processes through coordinated, autonomous multi-agent-based systems. Furthermore, we discuss future perspectives to enhance and fully realize ID 4.0's potential, including more complex design scenarios, more practical design implementations, novel agent coordination mechanisms, and autonomous design goal-setting with better human value alignment. In sum, these insights lay a foundation for advancing Intelligent Design toward greater adaptivity, autonomy, and effectiveness in addressing increasingly complex design challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09755v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuo Jiang, Min Xie, Frank Youhua Chen, Jian Ma, Jianxi Luo</dc:creator>
    </item>
    <item>
      <title>Superstudent intelligence in thermodynamics</title>
      <link>https://arxiv.org/abs/2506.09822</link>
      <description>arXiv:2506.09822v1 Announce Type: new 
Abstract: In this short note, we report and analyze a striking event: OpenAI's large language model o3 has outwitted all students in a university exam on thermodynamics. The thermodynamics exam is a difficult hurdle for most students, where they must show that they have mastered the fundamentals of this important topic. Consequently, the failure rates are very high, A-grades are rare - and they are considered proof of the students' exceptional intellectual abilities. This is because pattern learning does not help in the exam. The problems can only be solved by knowledgeably and creatively combining principles of thermodynamics. We have given our latest thermodynamics exam not only to the students but also to OpenAI's most powerful reasoning model, o3, and have assessed the answers of o3 exactly the same way as those of the students. In zero-shot mode, the model o3 solved all problems correctly, better than all students who took the exam; its overall score was in the range of the best scores we have seen in more than 10,000 similar exams since 1985. This is a turning point: machines now excel in complex tasks, usually taken as proof of human intellectual capabilities. We discuss the consequences this has for the work of engineers and the education of future engineers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09822v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rebecca Loubet, Pascal Zittlau, Marco Hoffmann, Luisa Vollmer, Sophie Fellenz, Heike Leitte, Fabian Jirasek, Johannes Lenhard, Hans Hasse</dc:creator>
    </item>
    <item>
      <title>Natural Language Guided Ligand-Binding Protein Design</title>
      <link>https://arxiv.org/abs/2506.09332</link>
      <description>arXiv:2506.09332v1 Announce Type: cross 
Abstract: Can AI protein models follow human language instructions and design proteins with desired functions (e.g. binding to a ligand)? Designing proteins that bind to a given ligand is crucial in a wide range of applications in biology and chemistry. Most prior AI models are trained on protein-ligand complex data, which is scarce due to the high cost and time requirements of laboratory experiments. In contrast, there is a substantial body of human-curated text descriptions about protein-ligand interactions and ligand formula. In this paper, we propose InstructPro, a family of protein generative models that follow natural language instructions to design ligand-binding proteins. Given a textual description of the desired function and a ligand formula in SMILES, InstructPro generates protein sequences that are functionally consistent with the specified instructions. We develop the model architecture, training strategy, and a large-scale dataset, InstructProBench, to support both training and evaluation. InstructProBench consists of 9,592,829 triples of (function description, ligand formula, protein sequence). We train two model variants: InstructPro-1B (with 1 billion parameters) and InstructPro-3B~(with 3 billion parameters). Both variants consistently outperform strong baselines, including ProGen2, ESM3, and Pinal. Notably, InstructPro-1B achieves the highest docking success rate (81.52% at moderate confidence) and the lowest average root mean square deviation (RMSD) compared to ground truth structures (4.026{\AA}). InstructPro-3B further descreases the average RMSD to 2.527{\AA}, demonstrating InstructPro's ability to generate ligand-binding proteins that align with the functional specifications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09332v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhenqiao Song, Ramith Hettiarachchi, Chuan Li, Jianwen Xie, Lei Li</dc:creator>
    </item>
    <item>
      <title>Causal Climate Emulation with Bayesian Filtering</title>
      <link>https://arxiv.org/abs/2506.09891</link>
      <description>arXiv:2506.09891v1 Announce Type: cross 
Abstract: Traditional models of climate change use complex systems of coupled equations to simulate physical processes across the Earth system. These simulations are highly computationally expensive, limiting our predictions of climate change and analyses of its causes and effects. Machine learning has the potential to quickly emulate data from climate models, but current approaches are not able to incorporate physics-informed causal relationships. Here, we develop an interpretable climate model emulator based on causal representation learning. We derive a physics-informed approach including a Bayesian filter for stable long-term autoregressive emulation. We demonstrate that our emulator learns accurate climate dynamics, and we show the importance of each one of its components on a realistic synthetic dataset and data from two widely deployed climate models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09891v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>physics.ao-ph</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Hickman, Ilija Trajkovic, Julia Kaltenborn, Francis Pelletier, Alex Archibald, Yaniv Gurwicz, Peer Nowack, David Rolnick, Julien Boussard</dc:creator>
    </item>
    <item>
      <title>A Note on the Reliability of Goal-Oriented Error Estimates for Galerkin Finite Element Methods with Nonlinear Functionals</title>
      <link>https://arxiv.org/abs/2506.09913</link>
      <description>arXiv:2506.09913v1 Announce Type: cross 
Abstract: We consider estimating the discretization error in a nonlinear functional $J(u)$ in the setting of an abstract variational problem: find $u \in \mathcal{V}$ such that $B(u,\varphi) = L(\varphi) \; \forall \varphi \in \mathcal{V}$, as approximated by a Galerkin finite element method. Here, $\mathcal{V}$ is a Hilbert space, $B(\cdot,\cdot)$ is a bilinear form, and $L(\cdot)$ is a linear functional. We consider well-known error estimates $\eta$ of the form $J(u) - J(u_h) \approx \eta = L(z) - B(u_h, z)$, where $u_h$ denotes a finite element approximation to $u$, and $z$ denotes the solution to an auxiliary adjoint variational problem. We show that there exist nonlinear functionals for which error estimates of this form are not reliable, even in the presence of an exact adjoint solution solution $z$. An estimate $\eta$ is said to be reliable if there exists a constant $C \in \mathbb{R}_{&gt;0}$ independent of $u_h$ such that $|J(u) - J(u_h)| \leq C|\eta|$. We present several example pairs of bilinear forms and nonlinear functionals where reliability of $\eta$ is not achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09913v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Brian N. Granzow, Stephen D. Bond, D. Thomas Seidl, Bernhard Endtmayer</dc:creator>
    </item>
    <item>
      <title>polyGen: A Learning Framework for Atomic-level Polymer Structure Generation</title>
      <link>https://arxiv.org/abs/2504.17656</link>
      <description>arXiv:2504.17656v3 Announce Type: replace 
Abstract: Synthetic polymeric materials underpin fundamental technologies in the energy, electronics, consumer goods, and medical sectors, yet their development still suffers from prolonged design timelines. Although polymer informatics tools have supported speedup, polymer simulation protocols continue to face significant challenges in the on-demand generation of realistic 3D atomic structures that respect conformational diversity. Generative algorithms for 3D structures of inorganic crystals, bio-polymers, and small molecules exist, but have not addressed synthetic polymers because of challenges in representation and dataset constraints. In this work, we introduce polyGen, the first generative model designed specifically for polymer structures from minimal inputs such as the repeat unit chemistry alone. polyGen combines graph-based encodings with a latent diffusion transformer using positional biased attention for realistic conformation generation. Given the limited dataset of 3,855 DFT-optimized polymer structures, we incorporate joint training with small molecule data to enhance generation quality. We also establish structure matching criteria to benchmark our approach on this novel problem. polyGen overcomes the limitations of traditional crystal structure prediction methods for polymers, successfully generating realistic and diverse linear and branched conformations, with promising performance even on challenging large repeat units. As the first atomic-level proof-of-concept capturing intrinsic polymer flexibility, it marks a new capability in material structure generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17656v3</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ayush Jain, Rampi Ramprasad</dc:creator>
    </item>
    <item>
      <title>KP-PINNs: Kernel Packet Accelerated Physics Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2506.08563</link>
      <description>arXiv:2506.08563v2 Announce Type: replace 
Abstract: Differential equations are involved in modeling many engineering problems. Many efforts have been devoted to solving differential equations. Due to the flexibility of neural networks, Physics Informed Neural Networks (PINNs) have recently been proposed to solve complex differential equations and have demonstrated superior performance in many applications. While the L2 loss function is usually a default choice in PINNs, it has been shown that the corresponding numerical solution is incorrect and unstable for some complex equations. In this work, we propose a new PINNs framework named Kernel Packet accelerated PINNs (KP-PINNs), which gives a new expression of the loss function using the reproducing kernel Hilbert space (RKHS) norm and uses the Kernel Packet (KP) method to accelerate the computation. Theoretical results show that KP-PINNs can be stable across various differential equations. Numerical experiments illustrate that KP-PINNs can solve differential equations effectively and efficiently. This framework provides a promising direction for improving the stability and accuracy of PINNs-based solvers in scientific computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08563v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 12 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyuan Yang, Cheng Song, Zhilu Lai, Wenjia Wang</dc:creator>
    </item>
  </channel>
</rss>
