<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Apr 2025 02:02:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>NonOpt: Nonconvex, Nonsmooth Optimizer</title>
      <link>https://arxiv.org/abs/2503.22826</link>
      <description>arXiv:2503.22826v1 Announce Type: new 
Abstract: NonOpt, a C++ software package for minimizing locally Lipschitz objective functions, is presented. The software is intended primarily for minimizing objective functions that are nonconvex and/or nonsmooth. The package has implementations of two main algorithmic strategies: a gradient-sampling and a proximal-bundle method. Each algorithmic strategy can employ quasi-Newton techniques for accelerating convergence in practice. The main computational cost in each iteration is solving a subproblem with a quadratic objective function, a linear equality constraint, and bound constraints. The software contains dual active-set and interior-point subproblem solvers that are designed specifically for solving these subproblems efficiently. The results of numerical experiments with various test problems are provided to demonstrate the speed and reliability of the software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22826v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frank E. Curtis, Lara Zebiane</dc:creator>
    </item>
    <item>
      <title>Distances between finite-horizon linear behaviors</title>
      <link>https://arxiv.org/abs/2503.22849</link>
      <description>arXiv:2503.22849v1 Announce Type: new 
Abstract: The paper introduces a class of distances for linear behaviors over finite time horizons. These distances allow for comparisons between finite-horizon linear behaviors represented by matrices of possibly different dimensions. They remain invariant under coordinate changes, rotations, and permutations, ensuring independence from input-output partitions. Moreover, they naturally encode complexity-misfit trade-offs for Linear Time-Invariant (LTI) behaviors, providing a principled solution to a longstanding puzzle in behavioral systems theory. The resulting framework characterizes modeling as a minimum distance problem, identifying the Most Powerful Unfalsified Model (MPUM) as optimal among all systems unfalsified by a given dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22849v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Padoan, Jeremy Coulson</dc:creator>
    </item>
    <item>
      <title>A Riemannian approach for PDE constrained shape optimization over the diffeomorphism group using outer metrics</title>
      <link>https://arxiv.org/abs/2503.22872</link>
      <description>arXiv:2503.22872v1 Announce Type: new 
Abstract: In this paper, we study the use of outer metrics, in particular Sobolev-type metrics on the diffeomorphism group in the context of PDE-constrained shape optimization. Leveraging the structure of the diffeomorphism group we analyze the connection between the push-forward of a smooth function defined on the diffeomorphism group and the classical shape derivative as an Eulerian semi-derivative. We consider in particular, two predominant examples on PDE-constrained shape optimization. An electric impedance tomography inspired problem, and the optimization of a two-dimensional bridge. These problems are numerically solved using the Riemannian steepest descent method where the descent directions are taken to be the Riemannian gradients associated to various outer metrics. For comparison reasons, we also solve the problem using other previously proposed Riemannian metrics in particular the Steklov-Poincar\'e metric.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22872v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Estefania Loayza-Romero, Lidiya Pryymak, Kathrin Welker</dc:creator>
    </item>
    <item>
      <title>Nested Stochastic Gradient Descent for (Generalized) Sinkhorn Distance-Regularized Distributionally Robust Optimization</title>
      <link>https://arxiv.org/abs/2503.22923</link>
      <description>arXiv:2503.22923v1 Announce Type: new 
Abstract: Distributionally robust optimization (DRO) is a powerful technique to train robust models against data distribution shift. This paper aims to solve regularized nonconvex DRO problems, where the uncertainty set is modeled by a so-called generalized Sinkhorn distance and the loss function is nonconvex and possibly unbounded. Such a distance allows to model uncertainty of distributions with different probability supports and divergence functions. For this class of regularized DRO problems, we derive a novel dual formulation taking the form of nested stochastic programming, where the dual variable depends on the data sample. To solve the dual problem, we provide theoretical evidence to design a nested stochastic gradient descent (SGD) algorithm, which leverages stochastic approximation to estimate the nested stochastic gradients. We study the convergence rate of nested SGD and establish polynomial iteration and sample complexities that are independent of the data size and parameter dimension, indicating its potential for solving large-scale DRO problems. We conduct numerical experiments to demonstrate the efficiency and robustness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22923v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufeng Yang, Yi Zhou, Zhaosong Lu</dc:creator>
    </item>
    <item>
      <title>A Near-optimal Method for Linearly Constrained Composite Non-convex Non-smooth Problems</title>
      <link>https://arxiv.org/abs/2503.22927</link>
      <description>arXiv:2503.22927v1 Announce Type: new 
Abstract: We study first-order methods (FOMs) for solving \emph{composite nonconvex nonsmooth} optimization with linear constraints. Recently, the lower complexity bounds of FOMs on finding an ($\varepsilon,\varepsilon$)-KKT point of the considered problem is established in \cite{liu2025lowercomplexityboundsfirstorder}. However, optimization algorithms that achieve this lower bound had not been developed. In this paper, we propose an inexact proximal gradient method, where subproblems are solved using a recovering primal-dual procedure. Without making the bounded domain assumption, we establish that the oracle complexity of the proposed method, for finding an ($\varepsilon,\varepsilon$)-KKT point of the considered problem, matches the lower bounds up to a logarithmic factor. Consequently, in terms of the complexity, our algorithm outperforms all existing methods. We demonstrate the advantages of our proposed algorithm over the (linearized) alternating direction method of multipliers and the (proximal) augmented Lagrangian method in the numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22927v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Liu, Qihang Lin, Yangyang Xu</dc:creator>
    </item>
    <item>
      <title>Optimal Control of an Epidemic with Intervention Design</title>
      <link>https://arxiv.org/abs/2503.22928</link>
      <description>arXiv:2503.22928v1 Announce Type: new 
Abstract: In this paper, I propose a controlled SEIR model that advances epidemic management through optimal control theory. I improve the traditional framework by incorporating practical intervention constraints and economic considerations. Approaching this problem using modern methods of calculus of variations, I first conduct a rigorous mathematical analysis of the controlled system. Then, I formulate an infinite time horizon control problem and investigate its mathematical connections with finite time, setting the stage for applying the Hamiltonian procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22928v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Behrooz Moosavi Ramezanzadeh</dc:creator>
    </item>
    <item>
      <title>Pontryagin Maximum Principle for rough stochastic systems and pathwise stochastic control</title>
      <link>https://arxiv.org/abs/2503.22959</link>
      <description>arXiv:2503.22959v1 Announce Type: new 
Abstract: We analyze a novel class of rough stochastic control problems that allows for a convenient approach to solving pathwise stochastic control problems with both non-anticipative and anticipative controls. We first establish the well-posedness of a class of controlled rough SDEs with affine rough driver and establish the continuity of the solution w.r.t.~the driving rough path. This allows us to define pathwise stochastic control problems with anticipative controls. Subsequently, we apply a flow transformation argument to establish a necessary and sufficient maximum principle to identify and characterize optimal strategies for rough and hence pathwise stochastic control problems. We show that the rough and the corresponding pathwise stochastic control problems share the same value function. For the benchmark case of linear-quadratic problems with bounded controls a similar result is shown for optimal controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22959v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulrich Horst, Huilin Zhang</dc:creator>
    </item>
    <item>
      <title>An Adaptive Collaborative Neurodynamic Approach to Compute Nash Equilibrium in Normal-Form Games</title>
      <link>https://arxiv.org/abs/2503.22969</link>
      <description>arXiv:2503.22969v1 Announce Type: new 
Abstract: The Nash Equilibrium (NE), one of the elegant and fundamental concepts in game theory, plays a crucial part within various fields, including engineering and computer science. However, efficiently computing an NE in normal-form games remains a significant challenge, particularly for large-scale problems. In contrast to widely applied simplicial and homotopy methods, this paper designs a novel Adaptive Collaborative Neurodynamic Approach (ACNA), which for the first time guarantees both exact and global NE computation for general $N$-player normal-form games with mixed strategies, where the payoff functions are non-convex and the pseudo-gradient is non-monotone. Additionally, leveraging the adaptive penalty method, the ACNA ensures its state enters the constraint set in finite time, which avoids the second-order sufficiency conditions required by Lagrangian methods, and the computationally complicated penalty parameter estimation needed by exact penalty methods. Furthermore, by incorporating the particle swarm algorithm, it is demonstrated that the ACNA achieves global convergence to an exact NE with probability one. At last, a simulation is conducted to validate the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22969v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Chen</dc:creator>
    </item>
    <item>
      <title>A point cloud reconstruction method based on uncertainty feature enhancement for aerodynamic shape optimization</title>
      <link>https://arxiv.org/abs/2503.23082</link>
      <description>arXiv:2503.23082v2 Announce Type: new 
Abstract: The precision of shape representation and the dimensionality of the design space significantly influence the cost and outcomes of aerodynamic optimization. The design space can be represented more compactly by maintaining geometric precision while reducing dimensions, hence enhancing the cost-effectiveness of the optimization process. This research presents a new point cloud autoencoder architecture, called AE-BUFE, designed to attain efficient and precise generalized representations of 3D aircraft through uncertainty analysis of the deformation relationships among surface grid points. The deep learning architecture consists of two components: the uncertainty index-based feature enhancement module and the point cloud autoencoder module. It learns the shape features of the point cloud geometric representation to establish a low-dimensional latent space. To assess and evaluate the efficiency of the method, a comparison was conducted with the prevailing point cloud autoencoder architecture and the proper orthogonal decomposition (POD) linear dimensionality reduction method under conditions of complex shape deformation. The results showed that the new architecture significantly improved the extraction effect of the low-dimensional latent space. Then, we developed the SBO optimization framework based on the AE-BUFE parameterization method and completed a multi-objective aerodynamic optimization design for a wide-speed-range vehicle considering volume and moment constraints. While ensuring the take-off and landing performance, the aerodynamic performance is improved at transonic and hypersonic conditions, which verifies the efficiency and engineering practicability of this method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23082v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junlin Li, Yang Zhang, Bo Pang, Junqiang Bai, Jiakuan Xu</dc:creator>
    </item>
    <item>
      <title>Cost versus Resilience in Energy Communities: A Multi-Objective Member-Focused Analysis</title>
      <link>https://arxiv.org/abs/2503.23096</link>
      <description>arXiv:2503.23096v1 Announce Type: new 
Abstract: This paper develops a multi-objective optimization framework to analyze the trade-offs between annual costs and resilience in energy communities. Under this framework, three energy community operation strategies are analyzed: a reference case where all assets are member-owned, implementing a communal battery electric storage system, and subsidizing energy-poor members. The results indicate that increasing resilience leads to higher operational costs and smaller feasible ranges of energy community energy prices. The analysis reveals that those trade-offs have a heterogeneous impact across different member groups. Owners photovoltaics are most affected due to curtailed energy. Notably, the study shows that while implementing community-owned storage does not directly provide financial benefits to energy-poor members, alleviating the energy price for these members leads to an overall cost reduction of more than 30%. This research provides insights into the operational complexity of energy communities and highlights the importance of technologically robust and socially inclusive energy communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23096v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lia Gruber, Sonja Wogrin</dc:creator>
    </item>
    <item>
      <title>Controllability of the Fisher-Stefan system</title>
      <link>https://arxiv.org/abs/2503.23154</link>
      <description>arXiv:2503.23154v1 Announce Type: new 
Abstract: This paper addresses the exact controllability of trajectories in the one-dimensional Fisher-Stefan problem--a reaction-diffusion equation that models the spatial propagation of biological, chemical, or physical populations within a free-end domain, governed by Stefan's law. We establish the local exact controllability to the trajectories by reformulating the problem as the local null controllability of a nonlinear system with distributed controls. Our approach leverages the Lyusternik-Graves theorem to achieve local inversion, leading to the desired controllability result. Finally, we illustrate our theoretical findings through several numerical experiments based on the Physics-Informed Neural Networks (PINNs) approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23154v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idriss Boutaayamou, Fouad Et-tahri, Lahcen Maniar, Francisco Periago</dc:creator>
    </item>
    <item>
      <title>Structure of average distance minimizers in general dimensions</title>
      <link>https://arxiv.org/abs/2503.23256</link>
      <description>arXiv:2503.23256v1 Announce Type: new 
Abstract: For a fixed, compactly supported probability measure $\mu$ on $\mathbb{R}^d$, we consider the problem of minimizing the $p^{\mathrm{th}}$-power average distance functional over all compact, connected $\Sigma \subseteq \mathbb{R}^d$ with Hausdorff 1-measure $\mathcal{H}^1(\Sigma) \leq l$. This problem, known as the average distance problem, was first studied by Buttazzo, Oudet, and Stepanov in 2002, and has undergone a considerable amount of research since. We will provide a novel approach to studying this problem by analyzing it using the so-called barycentre field introduced previously by Hayase and two of the authors. This allows us to provide a complete topological description of minimizers in arbitrary dimension when $p = 2$ and $p &gt; \frac{1}{2}(3 + \sqrt{5}) \approx 2.618$, the first such result which includes the case when $d &gt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23256v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas O'Brien, Forest Kobayashi, Young-Heon Kim</dc:creator>
    </item>
    <item>
      <title>Modified Polyhedral Method for Elicitation of Shape-Free Utility and Conservatism Reduction in Robust Optimization</title>
      <link>https://arxiv.org/abs/2503.23269</link>
      <description>arXiv:2503.23269v1 Announce Type: new 
Abstract: In this paper, we propose a modified polyhedral method to elicit a decision maker's (DM's) nonlinear univariate utility function, which does not rely on explicit information about the shape structure, Lipschitz modulus, and the inflection point of the utility. The method is inspired by Toubia et al. (2004) for elicitation of the linear multi-variate utility and the success of the modification needs to overcome two main difficulties. First, we use the continuous piecewise linear function (PLF) to approximate the nonlinear utility and represent the PLF in terms of the vector of increments of linear pieces. Subsequently, elicitation of the nonlinear utility corresponds to reducing the polyhedral feasible set of the vectors of increments. Second, we reduce the size of the polyhedron by successive hyperplane cuts constructed by adaptively generating new queries (pairwise comparison lotteries) where the parameters of the lotteries are obtained by solving some optimization problems. In this reduction procedure, direction error of the cut hyperplane may occur due to the PLF approximation error. To tackle the issue, we develop a strategy by adding the support points of new lotteries to the set of breakpoints of the PLF. As an application, we use all the responses to the queries to construct an ambiguity set of utility functions which allows one to make decisions based on the worst-case utility and apply the modified polyhedral method in a preference robust optimization problem with proper conservatism reduction scheme. The preliminary numerical test results show that the proposed methods work very well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23269v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sainan Zhang, Shaoyan Guo, Melvyn Sim, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>Accelerated Distributed Aggregative Optimization</title>
      <link>https://arxiv.org/abs/2503.23325</link>
      <description>arXiv:2503.23325v1 Announce Type: new 
Abstract: This paper delves into the investigation of a distributed aggregative optimization problem within a network. In this scenario, each agent possesses its own local cost function, which relies not only on the local state variable but also on an aggregated function of state variables from all agents. To expedite the optimization process, we amalgamate the heavy ball and Nesterovs accelerated method with distributed aggregative gradient tracking, resulting in the proposal of two innovative algorithms, aimed at resolving the distributed aggregative optimization problem. Our analysis demonstrates that the proposed algorithms can converge to an optimal solution at a global linear convergence rate when the objective function is strongly convex with the Lipschitz-continuous gradient, and when the parameters (e.g., step size and momentum coefficients) are chosen within specific ranges. Additionally, we present several numerical experiments to verify the effectiveness, robustness and superiority of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23325v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiaxu Liu, Song Chen, Shengze Cai, Chao Xu, Jian Chu</dc:creator>
    </item>
    <item>
      <title>Solving Indefinite Quadratic Programs by Dynamical Systems: Preliminary Investigations</title>
      <link>https://arxiv.org/abs/2503.23420</link>
      <description>arXiv:2503.23420v1 Announce Type: new 
Abstract: Preliminary results of our investigations on solving indefinite qua\-dra\-tic programs by dynamical systems are given. First, dynamical systems corresponding to two fundamental DC programming algorithms to deal with indefinite quadratic programs are considered. Second, the existence and the uniqueness of the global solution of the dynamical system are proved by using some theorems from nonsmooth analysis and the theory of ordinary differential equations. Third, the strong pseudomonotonicity of the restriction of an affine operator on a closed convex set is analyzed in a special case. Finally, for a parametric indefinite quadratic program related to that special case, convergence of the trajectories of the dynamical system to the Karush-Kuhn-Tucker points is established. The elementary direct proofs in the third and fourth topics would be useful for understanding the meaning and significance of several open problems proposed in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23420v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Massimo Pappalardo, Nguyen Nang Thieu, Nguyen Dong Yen</dc:creator>
    </item>
    <item>
      <title>Compressed Zeroth-Order Algorithm for Stochastic Distributed Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2503.23426</link>
      <description>arXiv:2503.23426v1 Announce Type: new 
Abstract: This paper studies the stochastic distributed nonconvex optimization problem over a network of agents, where agents only access stochastic zeroth-order information about their local cost functions and collaboratively optimizes the global objective over bandwidth-limited communication networks. To mitigate communication overhead and handle the unavailability of explicit gradient information, we propose a communication compressed zeroth-order stochastic distributed (CZSD) algorithm. By integrating a generalized contractive compressor and a stochastic two-point zeroth-order oracle, CZSD achieves convergence rates comparable to its exact communication counterpart while reducing both communication overhead and sampling complexity. Specifically, to the best of our knowledge, CZSD is the first compressed zeroth-order algorithm achieving linear speedup, with convergence rates of $\mathcal{O}(\sqrt{p}/\sqrt{nT})$ and $\mathcal{O}(p/(nT))$ under general nonconvex settings and the Polyak--{\L}ojasiewicz condition, respectively. Numerical experiments validate the algorithm's effectiveness and communication efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23426v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haonan Wang, Xinlei Yi, Yiguang Hong</dc:creator>
    </item>
    <item>
      <title>Tractable Characterization of Discrete-Time Periodic Monotonicity Preserving Systems</title>
      <link>https://arxiv.org/abs/2503.23520</link>
      <description>arXiv:2503.23520v1 Announce Type: new 
Abstract: This paper studies three classes of discrete-time linear time-invariant systems, which differ by the set of periodic signals that they leave invariant. The first class preserves the property of periodic monotonicity, i.e., period-wise unimodality. The second class is invariant to signals with at most two sign changes per period, and the third class results from the second by additionally requiring that periodic signals with zero sign-changes are mapped to the same kind. We provide tractable characterizations for each system class by the use and extension of total positivity theory and combination with its geometric interpretations. In particular, central to our results is the characterization of sequentially convex contours.
  Moreover, as many static non-linearities, e.g., ideal relay, saturation, sigmoid function, quantizer, etc. also preserve these signal sets, our invariance characterizations also apply to the loop gain of Lur'e feedback systems. Thus, potentially forming the base for new developments of signal-based fixed-point theorems towards the prediction of self-sustained oscillations. In particular, our examples provide first indications for how the property of periodic monotonicity preservation is valuable to the study of relay feedback systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23520v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Christian Grussler</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization over Wasserstein Balls with i.i.d. Structure</title>
      <link>https://arxiv.org/abs/2503.23543</link>
      <description>arXiv:2503.23543v1 Announce Type: new 
Abstract: Distributionally robust optimization (DRO) is a principled approach to incorporate robustness against ambiguity in the specified probabilistic models. This paper considers data-driven DRO problems with Wasserstein ambiguity sets, where the uncertain distribution splits into i.i.d. components. By exploiting the latter decomposition, we construct a tighter ambiguity set that narrows down the plausible models to product distributions only, consequently reducing the conservatism of the DRO problem. To solve the resulting nonconvex optimization problem we devise a novel sequence of convex relaxations that asymptotically converges to the true value of the original problem under mild conditions. The benefits of the approach are demonstrated via illustrative examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23543v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrey Kharitenko, Marta Fochesato, Anastasios Tsiamis, Niklas Schmid, John Lygeros</dc:creator>
    </item>
    <item>
      <title>A Class of Optimal Directed Graphs for Network Synchronization</title>
      <link>https://arxiv.org/abs/2503.23564</link>
      <description>arXiv:2503.23564v1 Announce Type: new 
Abstract: In a paper by Nishikawa and Motter, a quantity called the normalized spread of the Laplacian eigenvalues is used to measure the synchronizability of certain network dynamics. Through simulations, and without theoretical validation, it is conjectured that among all simple directed graphs with a fixed number of vertices and arcs, the optimal value of this quantity is achieved if the Laplacian spectrum satisfies a specific pattern. This paper proves that the conjectured Laplacian spectrum is always achievable by a class of almost regular directed graphs. For a few special cases, it is also shown that the corresponding value of the quantity is indeed optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23564v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susie Lu, Ji Liu</dc:creator>
    </item>
    <item>
      <title>A stochastic perturbed augmented Lagrangian method for smooth convex constrained minimization</title>
      <link>https://arxiv.org/abs/2503.23572</link>
      <description>arXiv:2503.23572v1 Announce Type: new 
Abstract: This paper considers smooth convex optimization problems with many functional constraints. To solve this general class of problems we propose a new stochastic perturbed augmented Lagrangian method, called SGDPA, where a perturbation is introduced in the augmented Lagrangian function by multiplying the dual variables with a subunitary parameter. Essentially, we linearize the objective and one randomly chosen functional constraint within the perturbed augmented Lagrangian at the current iterate and add a quadratic regularization that leads to a stochastic gradient descent update for the primal variables, followed by a perturbed random coordinate ascent step to update the dual variables. We provide a convergence analysis in both optimality and feasibility criteria for the iterates of SGDPA algorithm using basic assumptions on the problem. In particular, when the dual updates are assumed to be bounded, we prove sublinear rates of convergence for the iterates of algorithm SGDPA of order $\mathcal{O} (k^{-1/2})$ when the objective is convex and of order $\mathcal{O} (k^{-1})$ when the objective is strongly convex, where $k$ is the iteration counter. Under some additional assumptions, we prove that the dual iterates are bounded and in this case we obtain convergence rates of order $\mathcal{O} (k^{-1/4})$ and $\mathcal{O} (k^{-1/2})$ when the objective is convex and strongly convex, respectively. Preliminary numerical experiments on problems with many quadratic constraints demonstrate the viability and performance of our method when compared to some existing state-of-the-art optimization methods and software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23572v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitesh Kumar Singh, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>Multi-Objective Optimization and Hyperparameter Tuning With Desirability Functions</title>
      <link>https://arxiv.org/abs/2503.23595</link>
      <description>arXiv:2503.23595v1 Announce Type: new 
Abstract: The goal of this article is to provide an introduction to the desirability function approach to multi-objective optimization (direct and surrogate model-based), and multi-objective hyperparameter tuning. This work is based on the paper by Kuhn (2016). It presents a `Python` implementation of Kuhn's `R` package `desirability`. The `Python` package `spotdesirability` is available as part of the `sequential parameter optimization` framework. After a brief introduction to the desirability function approach is presented, three examples are given that demonstrate how to use the desirability functions for classical optimization, surrogate-model based optimization, and hyperparameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23595v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Thomas Bartz-Beielstein</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization and Integral Quadratic Constraints: A new approach to regret analysis</title>
      <link>https://arxiv.org/abs/2503.23600</link>
      <description>arXiv:2503.23600v1 Announce Type: new 
Abstract: We propose a novel approach for analyzing dynamic regret of first-order constrained online convex optimization algorithms for strongly convex and Lipschitz-smooth objectives. Crucially, we provide a general analysis that is applicable to a wide range of first-order algorithms that can be expressed as an interconnection of a linear dynamical system in feedback with a first-order oracle. By leveraging Integral Quadratic Constraints (IQCs), we derive a semi-definite program which, when feasible, provides a regret guarantee for the online algorithm. For this, the concept of variational IQCs is introduced as the generalization of IQCs to time-varying monotone operators. Our bounds capture the temporal rate of change of the problem in the form of the path length of the time-varying minimizer and the objective function variation. In contrast to standard results in OCO, our results do not require nerither the assumption of gradient boundedness, nor that of a bounded feasible set. Numerical analyses showcase the ability of the approach to capture the dependence of the regret on the function class condition number.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23600v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabian Jakob, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>A Hamilton-Jacobi Approach for Nonlinear Model Predictive Control in Applications with Navigational Uncertainty</title>
      <link>https://arxiv.org/abs/2503.23603</link>
      <description>arXiv:2503.23603v1 Announce Type: new 
Abstract: This paper introduces a novel methodology that leverages the Hamilton-Jacobi solution to enhance non-linear model predictive control (MPC) in scenarios affected by navigational uncertainty. Using Hamilton-Jacobi-Theoretic approach, a methodology to improve trajectory tracking accuracy among uncertainties and non-linearities is formulated. This paper seeks to overcome the challenge of real-time computation of optimal control solutions for Model Predictive Control applications by leveraging the Hamilton-Jacobi solution in the vicinity of a nominal trajectory. The efficacy of the proposed methodology is validated within a chaotic system of the planar circular restricted three-body problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23603v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit Jain, Roshan T. Eapen, Puneet Singla</dc:creator>
    </item>
    <item>
      <title>Stochastic analysis of impulsive thrust uncertainties in the CR3BP</title>
      <link>https://arxiv.org/abs/2503.23628</link>
      <description>arXiv:2503.23628v1 Announce Type: new 
Abstract: This paper employs an alternate dynamical model of the circular restricted three body problem to quantify uncertainties associated with spacecraft thrusting maneuvers. A non-product quadrature scheme known as Conjugate Unscented Transform (CUT) is employed to determine the higher order system sensitivities through a computationally efficient data driven approach. Moreover, the CUT scheme, in conjunction with a sparse approximation method, is used to find an analytical representation of the time evolution of the state probability density function (pdf).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23628v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sharad Sharan, Amit Jain, Roshan T. Eapen, Puneet Singla</dc:creator>
    </item>
    <item>
      <title>Remarks on the Polyak-Lojasiewicz inequality and the convergence of gradient systems</title>
      <link>https://arxiv.org/abs/2503.23641</link>
      <description>arXiv:2503.23641v1 Announce Type: new 
Abstract: This work explores generalizations of the Polyak-Lojasiewicz inequality (PLI) and their implications for the convergence behavior of gradient flows in optimization problems. Motivated by the continuous-time linear quadratic regulator (CT-LQR) policy optimization problem -- where only a weaker version of the PLI is characterized in the literature -- this work shows that while weaker conditions are sufficient for global convergence to, and optimality of the set of critical points of the cost function, the "profile" of the gradient flow solution can change significantly depending on which "flavor" of inequality the cost satisfies. After a general theoretical analysis, we focus on fitting the CT-LQR policy optimization problem to the proposed framework, showing that, in fact, it can never satisfy a PLI in its strongest form. We follow up our analysis with a brief discussion on the difference between continuous- and discrete-time LQR policy optimization, and end the paper with some intuition on the extension of this framework to optimization problems with L1 regularization and solved through proximal gradient flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23641v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arthur Castello B. de Oliveira, Leilei Cui, Eduardo D. Sontag</dc:creator>
    </item>
    <item>
      <title>A Decomposition Approach for the Gain Function in the Feedback Particle Filter</title>
      <link>https://arxiv.org/abs/2503.23662</link>
      <description>arXiv:2503.23662v1 Announce Type: new 
Abstract: The feedback particle filter (FPF) is an innovative, control-oriented and resampling-free adaptation of the traditional particle filter (PF). In the FPF, individual particles are regulated via a feedback gain, and the corresponding gain function serves as the solution to the Poisson's equation equipped with a probability-weighted Laplacian. Owing to the fact that closed-form expressions can only be computed under specific circumstances, approximate solutions are typically indispensable. This paper is centered around the development of a novel algorithm for approximating the gain function in the FPF. The fundamental concept lies in decomposing the Poisson's equation into two equations that can be precisely solved, provided that the observation function is a polynomial. A free parameter is astutely incorporated to guarantee exact solvability. The computational complexity of the proposed decomposition method shows a linear correlation with the number of particles and the polynomial degree of the observation function. We perform comprehensive numerical comparisons between our method, the PF, and the FPF using the constant-gain approximation and the kernel-based approach. Our decomposition method outperforms the PF and the FPF with constant-gain approximation in terms of accuracy. Additionally, it has the shortest CPU time among all the compared methods with comparable performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23662v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ruoyu Wang, Huimin Miao, Xue Luo</dc:creator>
    </item>
    <item>
      <title>Joint Replenishment Strategy for Multiple Satellite Constellations with Shared Launch Opportunities</title>
      <link>https://arxiv.org/abs/2503.23666</link>
      <description>arXiv:2503.23666v2 Announce Type: new 
Abstract: This paper proposes a novel replenishment strategy that can jointly support multiple satellite constellations. In this approach, multiple constellations share launch opportunities and parking orbits to address the operational satellite failures and ensure the desired service level of the constellations. We develop an inventory management model based on parametric replenishment policies, considering the launch vehicle's capacity and the shipping size of satellites. Based on this model, we introduce two decision-making scenarios and propose their corresponding solution frameworks. We conduct two case studies to provide valuable insights into the proposed strategy and demonstrate its applicability to supply chain management for maintaining multiple satellite constellations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23666v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jaewoo Kim, Taehyun Sung, Woonam Hwang, Jaemyung Ahn</dc:creator>
    </item>
    <item>
      <title>Shannon-and Von Neumann-entropy regularizations of linear and semidefinite programs</title>
      <link>https://arxiv.org/abs/2503.23815</link>
      <description>arXiv:2503.23815v1 Announce Type: new 
Abstract: We consider the LP in standard form min {c T x : Ax = b; x $\ge$ 0} and inspired by $\epsilon$-regularization in Optimal Transport, we introduce its $\epsilon$-regularization ''min {c T x + $\epsilon$ f (x) : Ax = b; x $\ge$ 0}'' via the (convex) Boltzmann-Shannon entropy f (x) := i x i ln x i . We also provide a similar regularization for the semidefinite program ''min {Tr(C $\bullet$ X) : A(X) = b; X 0}'' but with now the so-called Von Neumann entropy, as in Quantum Optimal Transport. Importantly, both are not barriers of the LP and SDP cones respectively. We show that this problem admits an equivalent unconstrained convex problem max $\lambda$$\in$R m G$\epsilon$($\lambda$) for an explicit concave differentiable function G$\epsilon$ in dual variables $\lambda$ $\in$ R m . As $\epsilon$ goes to zero, its optimal value converges to the optimal value of the initial LP. While it resembles the log-barrier formulation of interior point algorithm for the initial LP, it has a distinguishing advantage. Namely for fixed $\lambda$, G$\epsilon$($\lambda$) is obtained as a minimization over the whole space x $\in$ R d (and not over x $\ge$ 0) to still obtain a nonnegative solution x($\lambda$) $\ge$ 0, whence an explicit form of G$\epsilon$ very useful for its unconstrained maximization over R m.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23815v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saroj Prasad Chhatoi (LAAS-POP), Jean B Lasserre (LAAS-POP, TSE-R)</dc:creator>
    </item>
    <item>
      <title>Sampled-data and event-triggered control of globally Lipschitz infinite-dimensional systems</title>
      <link>https://arxiv.org/abs/2503.23884</link>
      <description>arXiv:2503.23884v1 Announce Type: new 
Abstract: We show that if a linear infinite-dimensional system is exponentially stabilizable by compact feedback, it is also stabilizable by means of a sampled-data feedback that is fed through a globally Lipschitz nonlinearity, provided that the sector bound for the nonlinearity and the sampling time is small enough. Next we develop a switching-based event-triggered control scheme stabilizing the system with a reduced number of switching events. We demonstrate our results on an example of finite-dimensional stabilization of a Sturm-Liouville parabolic system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23884v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rami Katz, Andrii Mironchenko</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Model Order Reduction for Linear Systems</title>
      <link>https://arxiv.org/abs/2503.23922</link>
      <description>arXiv:2503.23922v1 Announce Type: new 
Abstract: In this paper, we investigate distributionally robust model order reduction for linear, discrete-time, time-invariant systems. The external input is assumed to follow an uncertain distribution within a Wasserstein ambiguity set. We begin by considering the case where the distribution is certain and formulate an optimization problem to obtain the reduced model. When the distribution is uncertain, the interaction between the reduced-order model and the distribution is modeled by a Stackelberg game. To ensure solvability, we first introduce the Gelbrich distance and demonstrate that the Stackelberg game within a Wasserstein ambiguity set is equivalent to that within a Gelbrich ambiguity set. Then, we propose a nested optimization problem to solve the Stackelberg game. Furthermore, the nested optimization problem is relaxed into a nested convex optimization problem, ensuring computational feasibility. Finally, a simulation is presented to illustrate the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23922v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Le Liu, Yu Kawano, Yangming Dou, Ming Cao</dc:creator>
    </item>
    <item>
      <title>Bi-Level Route Optimization and Path Planning with Hazard Exploration</title>
      <link>https://arxiv.org/abs/2503.24044</link>
      <description>arXiv:2503.24044v1 Announce Type: new 
Abstract: Effective risk monitoring in dynamic environments such as disaster zones requires an adaptive exploration strategy to detect hidden threats. We propose a bi-level unmanned aerial vehicle (UAV) monitoring strategy that efficiently integrates high-level route optimization with low-level path planning for known and unknown hazards. At the high level, we formulate the route optimization as a vehicle routing problem (VRP) to determine the optimal sequence for visiting known hazard locations. To strategically incorporate exploration efficiency, we introduce an edge-based centroidal Voronoi tessellation (CVT), which refines baseline routes using pseudo-nodes and allocates path budgets based on the UAV's battery capacity using a line segment Voronoi diagram. At the low level, path planning maximizes information gain within the allocated path budget by generating kinematically feasible B-spline trajectories. Bayesian inference is applied to dynamically update hazard probabilities, enabling the UAVs to prioritize unexplored regions. Simulation results demonstrate that edge-based CVT improves spatial coverage and route uniformity compared to the node-based method. Additionally, our optimized path planning consistently outperforms baselines in hazard discovery rates across a diverse set of scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24044v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jimin Choi, Grant Stagg, Cameron K. Peterson, Max Z. Li</dc:creator>
    </item>
    <item>
      <title>Riemannian Multiplicative Update for Sparse Simplex constraint using oblique rotation manifold</title>
      <link>https://arxiv.org/abs/2503.24075</link>
      <description>arXiv:2503.24075v1 Announce Type: new 
Abstract: We propose a new manifold optimization method to solve low-rank problems with sparse simplex constraints (variables are simultaneous nonnegativity, sparsity, and sum-to-1) that are beneficial in applications. The proposed approach exploits oblique rotation manifolds, rewrite the problem, and introduce a new Riemannian optimization method. Experiments on synthetic datasets compared to the standard Euclidean method show the effectiveness of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24075v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Flavia Esposito, Andersen Ang</dc:creator>
    </item>
    <item>
      <title>Distributed AC Optimal Power Flow: A Scalable Solution for Large-Scale Problems</title>
      <link>https://arxiv.org/abs/2503.24086</link>
      <description>arXiv:2503.24086v1 Announce Type: new 
Abstract: This paper introduces a novel distributed optimization framework for large-scale AC Optimal Power Flow (OPF) problems, offering both theoretical convergence guarantees and rapid convergence in practice. By integrating smoothing techniques and the Schur complement, the proposed approach addresses the scalability challenges and reduces communication overhead in distributed AC OPF. Additionally, optimal network decomposition enables efficient parallel processing under the single program multiple data (SPMD) paradigm. Extensive simulations on large-scale benchmarks across various operating scenarios indicate that the proposed framework outperforms the state-of-the-art centralized solver IPOPT on modest hardware. This paves the way for more scalable and efficient distributed optimization in future power system applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24086v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinliang Dai, Yuning Jiang, Yi Guo, Colin N. Jones, Moritz Diehl, Veit Hagenmeyer</dc:creator>
    </item>
    <item>
      <title>Forward-backward splitting in bilaterally bounded Alexandrov spaces</title>
      <link>https://arxiv.org/abs/2503.24126</link>
      <description>arXiv:2503.24126v1 Announce Type: new 
Abstract: With the goal of solving optimisation problems on non-Riemannian manifolds, such as geometrical surfaces with sharp edges, we develop and prove the convergence of a forward-backward method in Alexandrov spaces with curvature bounded both from above and from below. This bilateral boundedness is crucial for the availability of both the gradient and proximal steps, instead of just one or the other. We numerically demonstrate the behaviour of the proposed method on simple geometrical surfaces in $\mathbb{R}^3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24126v1</guid>
      <category>math.OC</category>
      <category>math.DG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heikki von Koch, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>The Influence of an Adjoint Mismatch on the Primal-Dual Douglas-Rachford Method</title>
      <link>https://arxiv.org/abs/2503.24141</link>
      <description>arXiv:2503.24141v1 Announce Type: new 
Abstract: The primal-dual Douglas-Rachford method is a well-known algorithm to solve optimization problems written as convex-concave saddle-point problems. Each iteration involves solving a linear system involving a linear operator and its adjoint. However, in practical applications it is often computationally favorable to replace the adjoint operator by a computationally more efficient approximation. This leads to an adjoint mismatch. In this paper, we analyze the convergence of the primal-dual Douglas-Rachford method under the presence of an adjoint mismatch. We provide mild conditions that guarantee the existence of a fixed point and find an upper bound on the error of the primal solution. Furthermore, we establish step sizes in the strongly convex setting that guarantee linear convergence under mild conditions. Additionally, we provide an alternative method that can also be derived from the Douglas-Rachford method and is also guaranteed to converge in this setting. Moreover, we illustrate our results both for an academic and a real-world inspired example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24141v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuele Naldi, Felix Schneppe</dc:creator>
    </item>
    <item>
      <title>Robust Feedback Optimization with Model Uncertainty: A Regularization Approach</title>
      <link>https://arxiv.org/abs/2503.24151</link>
      <description>arXiv:2503.24151v1 Announce Type: new 
Abstract: Feedback optimization optimizes the steady state of a dynamical system by implementing optimization iterations in closed loop with the plant. It relies on online measurements and limited model information, namely, the input-output sensitivity. In practice, various issues including inaccurate modeling, lack of observation, or changing conditions can lead to sensitivity mismatches, causing closed-loop sub-optimality or even instability. To handle such uncertainties, we pursue robust feedback optimization, where we optimize the closed-loop performance against all possible sensitivities lying in specific uncertainty sets. We provide tractable reformulations for the corresponding min-max problems via regularizations and characterize the online closed-loop performance through the tracking error in case of time-varying optimal solutions. Simulations on a distribution grid illustrate the effectiveness of our robust feedback optimization controller in addressing sensitivity mismatches in a non-stationary environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24151v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Winnie Chan, Zhiyu He, Keith Moffat, Saverio Bolognani, Michael Muehlebach, Florian D\"orfler</dc:creator>
    </item>
    <item>
      <title>Convexity of chance constraints for elliptical and skewed distributions with copula structures dependent on decision variables</title>
      <link>https://arxiv.org/abs/2503.24153</link>
      <description>arXiv:2503.24153v1 Announce Type: new 
Abstract: Chance constraints describe a set of given random inequalities depending on the decision vector satisfied with a large enough probability. They are widely used in decision making under uncertain data in many engineering problems. This paper aims to derive the convexity of chance constraints with row dependent elliptical and skewed random variables via a copula depending on decision vectors. We obtain best thresholds of the $r$-concavity for any real number $r$ and improve probability thresholds of the eventual convexity. We prove the eventual convexity with elliptical distributions and a Gumbel-Hougaard copula despite the copula's singularity near the origin. We determine the $\alpha$-decreasing densities of generalized hyperbolic distributions by estimating the modified Bessel functions. By applying the $\alpha$-decreasing property and a radial decomposition, we achieve the eventual convexity for three types of skewed distributions. Finally, we provide an example to illustrate the eventual convexity of a feasible set containing the origin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24153v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heng Zhang, Abdel Lisser</dc:creator>
    </item>
    <item>
      <title>A system level approach to generalised feedback Nash equilibrium seeking in partially-observed games</title>
      <link>https://arxiv.org/abs/2503.24159</link>
      <description>arXiv:2503.24159v1 Announce Type: new 
Abstract: This work proposes an algorithm for seeking generalised feedback Nash equilibria (GFNE) in noncooperative dynamic games. The focus is on cyber-physical systems with dynamics which are linear, stochastic, potentially unstable, and partially observed. We employ System Level Synthesis (SLS) to reformulate the problem as the search for an equilibrium profile of closed-loop responses to noise, which can then be used to reconstruct a stabilising output-feedback policy. Under this setup, we leverage monotone operator theory to design a GFNE-seeking algorithm capable to enforce closed-loop stability, operational constraints, and communication constraints onto the control policies. This algorithm is amenable to numerical implementation and we provide conditions for its convergence. We demonstrate our approach in a simulated experiment on the noncooperative stabilisation of a decentralised power-grid.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24159v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Otacilio B. L. Neto, Michela Mulas, Francesco Corona</dc:creator>
    </item>
    <item>
      <title>Linear Reweighted Regularization Algorithms for Graph Matching Problem</title>
      <link>https://arxiv.org/abs/2503.24329</link>
      <description>arXiv:2503.24329v1 Announce Type: new 
Abstract: The graph matching problem is a significant special case of the Quadratic Assignment Problem, with extensive applications in pattern recognition, computer vision, protein alignments and related fields. As the problem is NP-hard, relaxation and regularization techniques are frequently employed to improve tractability. However, most existing regularization terms are nonconvex, posing optimization challenges. In this paper, we propose a linear reweighted regularizer framework for solving the relaxed graph matching problem, preserving the convexity of the formulation. By solving a sequence of relaxed problems with the linear reweighted regularization term, one can obtain a sparse solution that, under certain conditions, theoretically aligns with the original graph matching problem's solution. Furthermore, we present a practical version of the algorithm by incorporating the projected gradient method. The proposed framework is applied to synthetic instances, demonstrating promising numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24329v1</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rongxuan Li</dc:creator>
    </item>
    <item>
      <title>On the number of defects in optimal quantizers on closed surfaces: the hexagonal torus</title>
      <link>https://arxiv.org/abs/2503.22680</link>
      <description>arXiv:2503.22680v1 Announce Type: cross 
Abstract: We present a strategy for proving an asymptotic upper bound on the number of defects (non-hexagonal Voronoi cells) in the $n$ generator optimal quantizer on a closed surface (i.e., compact 2-manifold without boundary). The program is based upon a general lower bound on the optimal quantization error and related upper bounds for the L\"oschian numbers $n$ (the norms of the Eisenstein integers) based upon the Goldberg-Coxeter construction. A gap lemma is used to reduce the asymptotics of the number of defects to precisely the asymptotics for the gaps between L\"oschian numbers. We apply this strategy on the hexagonal torus and prove that the number of defects is at most $O(n^{1/4})$ -- strictly fewer than surfaces with boundary -- and conjecture (based upon the number-theoretic L\"oschian gap conjecture) that it is in fact $O(\log n)$. Incidentally, the method also yields a related upper bound on the variance of the areas of the Voronoi cells. We show further that the bound on the number of defects holds in a neighborhood of the optimizers. Finally, we remark on the remaining issues for implementation on the 2-sphere.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22680v1</guid>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Edward Tisdell, Rustum Choksi, Xin Yang Lu</dc:creator>
    </item>
    <item>
      <title>Policy Optimization and Multi-agent Reinforcement Learning for Mean-variance Team Stochastic Games</title>
      <link>https://arxiv.org/abs/2503.22779</link>
      <description>arXiv:2503.22779v1 Announce Type: cross 
Abstract: We study a long-run mean-variance team stochastic game (MV-TSG), where each agent shares a common mean-variance objective for the system and takes actions independently to maximize it. MV-TSG has two main challenges. First, the variance metric is neither additive nor Markovian in a dynamic setting. Second, simultaneous policy updates of all agents lead to a non-stationary environment for each individual agent. Both challenges make dynamic programming inapplicable. In this paper, we study MV-TSGs from the perspective of sensitivity-based optimization. The performance difference and performance derivative formulas for joint policies are derived, which provide optimization information for MV-TSGs. We prove the existence of a deterministic Nash policy for this problem. Subsequently, we propose a Mean-Variance Multi-Agent Policy Iteration (MV-MAPI) algorithm with a sequential update scheme, where individual agent policies are updated one by one in a given order. We prove that the MV-MAPI algorithm converges to a first-order stationary point of the objective function. By analyzing the local geometry of stationary points, we derive specific conditions for stationary points to be (local) Nash equilibria, and further, strict local optima. To solve large-scale MV-TSGs in scenarios with unknown environmental parameters, we extend the idea of trust region methods to MV-MAPI and develop a multi-agent reinforcement learning algorithm named Mean-Variance Multi-Agent Trust Region Policy Optimization (MV-MATRPO). We derive a performance lower bound for each update of joint policies. Finally, numerical experiments on energy management in multiple microgrid systems are conducted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22779v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junkai Hu, Li Xia</dc:creator>
    </item>
    <item>
      <title>Pareto-Nash Allocations under Incomplete Information: A Model of Stable Optima</title>
      <link>https://arxiv.org/abs/2503.22825</link>
      <description>arXiv:2503.22825v1 Announce Type: cross 
Abstract: Prior literature on two-firm two-market and two-stage extended dynamic models has introduced what Guth (2016) succinctly terms a social dilemma. A state in which conglomerate firms competing in a Bertrand duopoly consider jointly optimizing profits under a tacit self-enforcing agreement to deter market entry. This theoretical article reinterprets the social dilemma highlighted by Guth (2016) not only in the context of allocation but also through the lens of competition where entry must legally be permitted even if cooperative signalling would otherwise sustain joint profitability. This study explores the significance of a sufficiency condition on each firms non-instantaneous reaction function requiring the maintenance of a stable long-run equilibrium through retaliative restraint characterized by either two negative eigenvalues or a saddle-path trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22825v1</guid>
      <category>econ.GN</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alfred A. B. Mayaki</dc:creator>
    </item>
    <item>
      <title>Representation and Stability Analysis of 1D PDEs with Periodic Boundary Conditions</title>
      <link>https://arxiv.org/abs/2503.22896</link>
      <description>arXiv:2503.22896v2 Announce Type: cross 
Abstract: PDEs with periodic boundary conditions are frequently used to model processes in large spatial environments, assuming solutions to extend periodically beyond some bounded interval. However, for 2nd order PDEs with periodic boundary conditions, the nullspace of the differential operator $\frac{\partial^2}{\partial x^2}$ is nontrivial on the PDE domain, and solutions may converge to non-stationary trajectories existing in this nullspace. To test this convergence behaviour, in this paper, it is shown how we can model these trajectories for a broad class of linear, 2nd order, 1D PDEs with periodic as well as more general boundary conditions, using the Partial Integral Equation (PIE) representation. In particular, it is first shown how any function $\mathbf{u}(t)$ in the PDE domain can be decomposed into a component defined by $\mathbf{u}_{xx}(t)$, and a component $\bar{\mathbf{u}}(t)$ existing in the nullspace of $\frac{\partial^2}{\partial x^2}$. An equivalent representation of linear PDEs is then derived as a PIE, explicitly defining the dynamics of both $\mathbf{u}_{xx}(t)$ and $\bar{\mathbf{u}}(t)$. Finally, a notion of exponential stability is defined for trajectories $\mathbf{u}^*(t)=\bar{\mathbf{u}}(t)$, and it is shown that stability of these trajectories as well as of the equilibrium $\mathbf{u}^*\equiv0$ can be tested by solving a linear operator inequality. The proposed methodology is applied to two examples, demonstrating that stability can be verified with tight bounds on the rate of exponential decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22896v2</guid>
      <category>math.AP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Declan Jagt, Sergei Chernyshenko, Matthew Peet</dc:creator>
    </item>
    <item>
      <title>Variational proof of conditional expectations</title>
      <link>https://arxiv.org/abs/2503.22947</link>
      <description>arXiv:2503.22947v1 Announce Type: cross 
Abstract: In this paper, we show that the conditional expectation of a random variable with finite second moment given a $\sigma$-algebra is the unique critical point of an energy functional in Hilbert space $L^2$. Then, we extend by density the result to every integrable random variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22947v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hugo Guadalupe Reyna Casta\~neda, Mar\'ia de los \'Angeles Sandoval-Romero</dc:creator>
    </item>
    <item>
      <title>Ensuring Safe and Smooth Control in Safety-Critical Systems via Filtered Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2503.23267</link>
      <description>arXiv:2503.23267v1 Announce Type: cross 
Abstract: In safety-critical control systems, ensuring both system safety and smooth control input variation is essential for theoretical guarantees and practical deployment. Existing Control Barrier Function (CBF) frameworks, especially High-Order CBFs (HOCBFs), effectively enforce safety constraints but often lead to nonsmooth or discontinuous control inputs that can degrade system performance or violate actuator limitations. This paper introduces Filtered Control Barrier Functions (FCBFs), a novel extension of HOCBFs that incorporates an auxiliary dynamic system-referred to as an input regularization filter-to produce Lipschitz continuous control inputs. The proposed framework ensures safety, control bounds, and smoothness simultaneously by integrating FCBFs and HOCBFs within a unified quadratic program (QP). Theoretical guarantees are provided, and simulations on a unicycle model demonstrate the effectiveness of the proposed method compared to standard and smoothness-penalized HOCBF approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23267v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Wei Xiao, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>DGSAM: Domain Generalization via Individual Sharpness-Aware Minimization</title>
      <link>https://arxiv.org/abs/2503.23430</link>
      <description>arXiv:2503.23430v1 Announce Type: cross 
Abstract: Domain generalization (DG) aims to learn models that can generalize well to unseen domains by training only on a set of source domains. Sharpness-Aware Minimization (SAM) has been a popular approach for this, aiming to find flat minima in the total loss landscape. However, we show that minimizing the total loss sharpness does not guarantee sharpness across individual domains. In particular, SAM can converge to fake flat minima, where the total loss may exhibit flat minima, but sharp minima are present in individual domains. Moreover, the current perturbation update in gradient ascent steps is ineffective in directly updating the sharpness of individual domains. Motivated by these findings, we introduce a novel DG algorithm, Decreased-overhead Gradual Sharpness-Aware Minimization (DGSAM), that applies gradual domain-wise perturbation to reduce sharpness consistently across domains while maintaining computational efficiency. Our experiments demonstrate that DGSAM outperforms state-of-the-art DG methods, achieving improved robustness to domain shifts and better performance across various benchmarks, while reducing computational overhead compared to SAM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23430v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youngjun Song, Youngsik Hwang, Jonghun Lee, Heechang Lee, Dong-Young Lim</dc:creator>
    </item>
    <item>
      <title>Accelerated Stein Variational Gradient Flow</title>
      <link>https://arxiv.org/abs/2503.23462</link>
      <description>arXiv:2503.23462v1 Announce Type: cross 
Abstract: Stein variational gradient descent (SVGD) is a kernel-based particle method for sampling from a target distribution, e.g., in generative modeling and Bayesian inference. SVGD does not require estimating the gradient of the log-density, which is called score estimation. In practice, SVGD can be slow compared to score-estimation based sampling algorithms. To design fast and efficient high-dimensional sampling algorithms, we introduce ASVGD, an accelerated SVGD, based on an accelerated gradient flow in a metric space of probability densities following Nesterov's method. We then derive a momentum-based discrete-time sampling algorithm, which evolves a set of particles deterministically. To stabilize the particles' momentum update, we also study a Wasserstein metric regularization. For the generalized bilinear kernel and the Gaussian kernel, toy numerical examples with varied target distributions demonstrate the effectiveness of ASVGD compared to SVGD and other popular sampling methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23462v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Stein, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>$p$-Adic Polynomial Regression as Alternative to Neural Network for Approximating $p$-Adic Functions of Many Variables</title>
      <link>https://arxiv.org/abs/2503.23488</link>
      <description>arXiv:2503.23488v2 Announce Type: cross 
Abstract: A method for approximating continuous functions $\mathbb{Z}_{p}^{n}\rightarrow\mathbb{Z}_{p}$ by a linear superposition of continuous functions $\mathbb{Z}_{p}\rightarrow\mathbb{Z}_{p}$ is presented and a polynomial regression model is constructed that allows approximating such functions with any degree of accuracy. A physical interpretation of such a model is given and possible methods for its training are discussed. The proposed model can be considered as a simple alternative to possible $p$-adic models based on neural network architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23488v2</guid>
      <category>math-ph</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>math.NT</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander P. Zubarev</dc:creator>
    </item>
    <item>
      <title>Bridging conformal prediction and scenario optimization</title>
      <link>https://arxiv.org/abs/2503.23561</link>
      <description>arXiv:2503.23561v1 Announce Type: cross 
Abstract: Conformal prediction and scenario optimization constitute two important classes of statistical learning frameworks to certify decisions made using data. They have found numerous applications in control theory, machine learning and robotics. Despite intense research in both areas, and apparently similar results, a clear connection between these two frameworks has not been established. By focusing on the so-called vanilla conformal prediction, we show rigorously how to choose appropriate score functions and set predictor map to recover well-known bounds on the probability of constraint violation associated with scenario programs. We also show how to treat ranking of nonconformity scores as a one-dimensional scenario program with discarded constraints, and use such connection to recover vanilla conformal prediction guarantees on the validity of the set predictor. We also capitalize on the main developments of the scenario approach, and show how we could analyze calibration conditional conformal prediction under this lens. Our results establish a theoretical bridge between conformal prediction and scenario optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23561v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Niall O'Sullivan, Licio Romao, Kostas Margellos</dc:creator>
    </item>
    <item>
      <title>An extrapolated and provably convergent algorithm for nonlinear matrix decomposition with the ReLU function</title>
      <link>https://arxiv.org/abs/2503.23832</link>
      <description>arXiv:2503.23832v1 Announce Type: cross 
Abstract: Nonlinear matrix decomposition (NMD) with the ReLU function, denoted ReLU-NMD, is the following problem: given a sparse, nonnegative matrix $X$ and a factorization rank $r$, identify a rank-$r$ matrix $\Theta$ such that $X\approx \max(0,\Theta)$. This decomposition finds application in data compression, matrix completion with entries missing not at random, and manifold learning. The standard ReLU-NMD model minimizes the least squares error, that is, $\|X - \max(0,\Theta)\|_F^2$. The corresponding optimization problem is nondifferentiable and highly nonconvex. This motivated Saul to propose an alternative model, Latent-ReLU-NMD, where a latent variable $Z$ is introduced and satisfies $\max(0,Z)=X$ while minimizing $\|Z - \Theta\|_F^2$ (``A nonlinear matrix decomposition for mining the zeros of sparse data'', SIAM J. Math. Data Sci., 2022). Our first contribution is to show that the two formulations may yield different low-rank solutions $\Theta$; in particular, we show that Latent-ReLU-NMD can be ill-posed when ReLU-NMD is not, meaning that there are instances in which the infimum of Latent-ReLU-NMD is not attained while that of ReLU-NMD is. We also consider another alternative model, called 3B-ReLU-NMD, which parameterizes $\Theta=WH$, where $W$ has $r$ columns and $H$ has $r$ rows, allowing one to get rid of the rank constraint in Latent-ReLU-NMD. Our second contribution is to prove the convergence of a block coordinate descent (BCD) applied to 3B-ReLU-NMD and referred to as BCD-NMD. Our third contribution is a novel extrapolated variant of BCD-NMD, dubbed eBCD-NMD, which we prove is also convergent under mild assumptions. We illustrate the significant acceleration effect of eBCD-NMD compared to BCD-NMD, and also show that eBCD-NMD performs well against the state of the art on synthetic and real-world data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23832v1</guid>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Gillis, Margherita Porcelli, Giovanni Seraghiti</dc:creator>
    </item>
    <item>
      <title>Certified Approximate Reachability (CARe): Formal Error Bounds on Deep Learning of Reachable Sets</title>
      <link>https://arxiv.org/abs/2503.23912</link>
      <description>arXiv:2503.23912v1 Announce Type: cross 
Abstract: Recent approaches to leveraging deep learning for computing reachable sets of continuous-time dynamical systems have gained popularity over traditional level-set methods, as they overcome the curse of dimensionality. However, as with level-set methods, considerable care needs to be taken in limiting approximation errors, particularly since no guarantees are provided during training on the accuracy of the learned reachable set. To address this limitation, we introduce an epsilon-approximate Hamilton-Jacobi Partial Differential Equation (HJ-PDE), which establishes a relationship between training loss and accuracy of the true reachable set. To formally certify this approximation, we leverage Satisfiability Modulo Theories (SMT) solvers to bound the residual error of the HJ-based loss function across the domain of interest. Leveraging Counter Example Guided Inductive Synthesis (CEGIS), we close the loop around learning and verification, by fine-tuning the neural network on counterexamples found by the SMT solver, thus improving the accuracy of the learned reachable set. To the best of our knowledge, Certified Approximate Reachability (CARe) is the first approach to provide soundness guarantees on learned reachable sets of continuous dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23912v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prashant Solanki, Nikolaus Vertovec, Yannik Schnitzer, Jasper Van Beers, Coen de Visser, Alessandro Abate</dc:creator>
    </item>
    <item>
      <title>Federated Structured Sparse PCA for Anomaly Detection in IoT Networks</title>
      <link>https://arxiv.org/abs/2503.23981</link>
      <description>arXiv:2503.23981v1 Announce Type: cross 
Abstract: Although federated learning has gained prominence as a privacy-preserving framework tailored for distributed Internet of Things (IoT) environments, current federated principal component analysis (PCA) methods lack integration of sparsity, a critical feature for robust anomaly detection. To address this limitation, we propose a novel federated structured sparse PCA (FedSSP) approach for anomaly detection in IoT networks. The proposed model uniquely integrates double sparsity regularization: (1) row-wise sparsity governed by $\ell_{2,p}$-norm with $p\in[0,1)$ to eliminate redundant feature dimensions, and (2) element-wise sparsity via $\ell_{q}$-norm with $q\in[0,1)$ to suppress noise-sensitive components. To efficiently solve this non-convex optimization problem in a distributed setting, we devise a proximal alternating minimization (PAM) algorithm with rigorous theoretical proofs establishing its convergence guarantees. Experiments on real datasets validate that incorporating structured sparsity enhances both model interpretability and detection accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23981v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Huang, Xinrong Li, Xianchao Xiu</dc:creator>
    </item>
    <item>
      <title>Deviation Between Team-Optimal Solution and Nash Equilibrium in Flow Assignment Problems</title>
      <link>https://arxiv.org/abs/2503.23991</link>
      <description>arXiv:2503.23991v1 Announce Type: cross 
Abstract: We investigate the relationship between the team-optimal solution and the Nash equilibrium (NE) to assess the impact of strategy deviation on team performance. As a working use case, we focus on a class of flow assignment problems in which each source node acts as a cooperating decision maker (DM) within a team that minimizes the team cost based on the team-optimal strategy. In practice, some selfish DMs may prioritize their own marginal cost and deviate from NE strategies, thus potentially degrading the overall performance. To quantify this deviation, we explore the deviation bound between the team-optimal solution and the NE in two specific scenarios: (i) when the team-optimal solution is unique and (ii) when multiple solutions do exist. This helps DMs analyze the factors influencing the deviation and adopting the NE strategy within a tolerable range. Furthermore, in the special case of a potential game model, we establish the consistency between the team-optimal solution and the NE. Once the consistency condition is satisfied, the strategy deviation does not alter the total cost, and DMs do not face a strategic trade-off. Finally, we validate our theoretical analysis through some simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23991v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gehui Xu, Ting Bai, Andreas A. Malikopoulos, Thomas Parisini</dc:creator>
    </item>
    <item>
      <title>Consensus on Open Multi-Agent Systems Over Graphs Sampled from Graphons</title>
      <link>https://arxiv.org/abs/2503.24025</link>
      <description>arXiv:2503.24025v1 Announce Type: cross 
Abstract: We show how graphons can be used to model and analyze open multi-agent systems, which are multi-agent systems subject to arrivals and departures, in the specific case of linear consensus. First, we analyze the case of replacements, where under the assumption of a deterministic interval between two replacements, we derive an upper bound for the disagreement in expectation. Then, we study the case of arrivals and departures, where we define a process for the evolution of the number of agents that guarantees a minimum and a maximum number of agents. Next, we derive an upper bound for the disagreement in expectation, and we establish a link with the spectrum of the expected graph used to generate the graph topologies. Finally, for stochastic block model (SBM) graphons, we prove that the computation of the spectrum of the expected graph can be performed based on a matrix whose dimension depends only on the graphon and it is independent of the number of agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24025v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Renato Vizuete, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>An ANN-Enhanced Approach for Flatness-Based Constrained Control of Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2503.24031</link>
      <description>arXiv:2503.24031v1 Announce Type: cross 
Abstract: Neural networks have proven practical for a synergistic combination of advanced control techniques. This work analyzes the implementation of rectified linear unit neural networks to achieve constrained control in differentially flat systems. Specifically, the class of flat systems enjoys the benefit of feedback linearizability, i.e., the systems can be linearized by means of a proper variable transformation. However, the price for linearizing the dynamics is that the constraint descriptions are distorted geometrically. Our results show that, by using neural networks, these constraints can be represented as a union of polytopes, enabling the use of mixed-integer programming tools to guarantee constraint satisfaction. We further analyze the integration of the characterization into efficient settings such as control Lyapunov function-based and model predictive control (MPC). Interestingly, this description also allows us to explicitly compute the solution of the MPC problem for the nonlinear system. Several examples are provided to illustrate the effectiveness of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24031v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huu-Thinh Do, Ionela Prodan, Florin Stoican</dc:creator>
    </item>
    <item>
      <title>Application of Battery Storage to Switching Predictive Control of Power Distribution Systems Including Road Heating</title>
      <link>https://arxiv.org/abs/2503.24104</link>
      <description>arXiv:2503.24104v1 Announce Type: cross 
Abstract: A road heating system is an electrical device which promotes snow melting by burying a heating cable as a thermal source underground. When integrating road heating into the power distribution system, we need to optimize the flow of electric power by appropriately integrating distributed power sources and conventional power distribution equipment. In this paper, we extend the power distribution system considered in the authors' previous study to the case where battery storage is installed. As a main result, we propose a predictive switching control that achieves the reduction of distribution loss, attenuation of voltage fluctuation, and efficient snow melting, simultaneously. We verify the effectiveness of the application of battery storage through numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24104v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiaki Kojima, Yuya Muto, Hikaru Akutsu, Rinnosuke Shima, Yoshihiko Susuki</dc:creator>
    </item>
    <item>
      <title>Value of Information-based Deceptive Path Planning Under Adversarial Interventions</title>
      <link>https://arxiv.org/abs/2503.24284</link>
      <description>arXiv:2503.24284v1 Announce Type: cross 
Abstract: Existing methods for deceptive path planning (DPP) address the problem of designing paths that conceal their true goal from a passive, external observer. Such methods do not apply to problems where the observer has the ability to perform adversarial interventions to impede the path planning agent. In this paper, we propose a novel Markov decision process (MDP)-based model for the DPP problem under adversarial interventions and develop new value of information (VoI) objectives to guide the design of DPP policies. Using the VoI objectives we propose, path planning agents deceive the adversarial observer into choosing suboptimal interventions by selecting trajectories that are of low informational value to the observer. Leveraging connections to the linear programming theory for MDPs, we derive computationally efficient solution methods for synthesizing policies for performing DPP under adversarial interventions. In our experiments, we illustrate the effectiveness of the proposed solution method in achieving deceptiveness under adversarial interventions and demonstrate the superior performance of our approach to both existing DPP methods and conservative path planning approaches on illustrative gridworld problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24284v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley A. Suttle, Jesse Milzman, Mustafa O. Karabag, Brian M. Sadler, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>On Speedups for Convex Optimization via Quantum Dynamics</title>
      <link>https://arxiv.org/abs/2503.24332</link>
      <description>arXiv:2503.24332v1 Announce Type: cross 
Abstract: We explore the potential for quantum speedups in convex optimization using discrete simulations of the Quantum Hamiltonian Descent (QHD) framework, as proposed by Leng et al., and establish the first rigorous query complexity bounds. We develop enhanced analyses for quantum simulation of Schr\"odinger operators with black-box potential via the pseudo-spectral method, providing explicit resource estimates independent of wavefunction assumptions. These bounds are applied to assess the complexity of optimization through QHD. Our findings pertain to unconstrained convex optimization in $d$ dimensions. In continuous time, we demonstrate that QHD, with suitable parameters, can achieve arbitrarily fast convergence rates. The optimization speed limit arises solely from the discretization of the dynamics, mirroring a property of the classical dynamics underlying QHD. Considering this cost, we show that a $G$-Lipschitz convex function can be optimized to an error of $\epsilon$ with $\widetilde{\mathcal{O}}(d^{1.5}G^2 R^2/\epsilon^2)$ queries. Moreover, under reasonable assumptions on the complexity of Hamiltonian simulation, $\widetilde{\Omega}(d/\epsilon^2)$ queries are necessary. Thus, QHD does not offer a speedup over classical zeroth order methods with exact oracles. However, we demonstrate that the QHD algorithm tolerates $\widetilde{\mathcal{O}}(\epsilon^3/d^{1.5}G^2 R^2)$ noise in function evaluation. We show that QHD offers a super-quadratic query advantage over all known classical algorithms tolerating this level of evaluation noise in the high-dimension regime. Additionally, we design a quantum algorithm for stochastic convex optimization that provides a super-quadratic speedup over all known classical algorithms in the high-dimension regime. To our knowledge, these results represent the first rigorous quantum speedups for convex optimization achieved through a dynamical algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24332v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shouvanik Chakrabarti, Dylan Herman, Jacob Watkins, Enrico Fontana, Brandon Augustino, Junhyung Lyle Kim, Marco Pistoia</dc:creator>
    </item>
    <item>
      <title>Faster Rates for No-Regret Learning in General Games via Cautious Optimism</title>
      <link>https://arxiv.org/abs/2503.24340</link>
      <description>arXiv:2503.24340v1 Announce Type: cross 
Abstract: We establish the first uncoupled learning algorithm that attains $O(n \log^2 d \log T)$ per-player regret in multi-player general-sum games, where $n$ is the number of players, $d$ is the number of actions available to each player, and $T$ is the number of repetitions of the game. Our results exponentially improve the dependence on $d$ compared to the $O(n\, d \log T)$ regret attainable by Log-Regularized Lifted Optimistic FTRL [Far+22c], and also reduce the dependence on the number of iterations $T$ from $\log^4 T$ to $\log T$ compared to Optimistic Hedge, the previously well-studied algorithm with $O(n \log d \log^4 T)$ regret [DFG21]. Our algorithm is obtained by combining the classic Optimistic Multiplicative Weights Update (OMWU) with an adaptive, non-monotonic learning rate that paces the learning process of the players, making them more cautious when their regret becomes too negative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24340v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3717823.3718242</arxiv:DOI>
      <dc:creator>Ashkan Soleymani, Georgios Piliouras, Gabriele Farina</dc:creator>
    </item>
    <item>
      <title>Accelerated Approximate Optimization of Multi-Commodity Flows on Directed Graphs</title>
      <link>https://arxiv.org/abs/2503.24373</link>
      <description>arXiv:2503.24373v1 Announce Type: cross 
Abstract: We provide $m^{1+o(1)}k\epsilon^{-1}$-time algorithms for computing multiplicative $(1 - \epsilon)$-approximate solutions to multi-commodity flow problems with $k$-commodities on $m$-edge directed graphs, including concurrent multi-commodity flow and maximum multi-commodity flow.
  To obtain our results, we provide new optimization tools of potential independent interest. First, we provide an improved optimization method for solving $\ell_{q, p}$-regression problems to high accuracy. This method makes $\tilde{O}_{q, p}(k)$ queries to a high accuracy convex minimization oracle for an individual block, where $\tilde{O}_{q, p}(\cdot)$ hides factors depending only on $q$, $p$, or $\mathrm{poly}(\log m)$, improving upon the $\tilde{O}_{q, p}(k^2)$ bound of [Chen-Ye, ICALP 2024]. As a result, we obtain the first almost-linear time algorithm that solves $\ell_{q, p}$ flows on directed graphs to high accuracy. Second, we present optimization tools to reduce approximately solving composite $\ell_{1, \infty}$-regression problems to solving $m^{o(1)}\epsilon^{-1}$ instances of composite $\ell_{q, p}$-regression problem. The method builds upon recent advances in solving box-simplex games [Jambulapati-Tian, NeurIPS 2023] and the area convex regularizer introduced in [Sherman, STOC 2017] to obtain faster rates for constrained versions of the problem. Carefully combining these techniques yields our directed multi-commodity flow algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.24373v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Chen, Andrei Graur, Aaron Sidford</dc:creator>
    </item>
    <item>
      <title>Collisionless and Decentralized Formation Control for Strings</title>
      <link>https://arxiv.org/abs/2102.13621</link>
      <description>arXiv:2102.13621v2 Announce Type: replace 
Abstract: A decentralized feedback controller for multi-agent systems, inspired by vehicle platooning, is proposed. The closed loop resulting from the decentralized control action has three distinctive features: the generation of collision-free trajectories, flocking of the system towards a consensus state in velocity, and asymptotic convergence to a prescribed pattern of distances between agents. For each feature, a rigorous dynamical analysis is provided, yielding a characterization of the set of parameters and initial configurations where collision avoidance, flocking, and pattern formation are guaranteed. Numerical tests assess the theoretical results presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2102.13621v2</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <category>math.DS</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Young-Pil Choi, Dante Kalise, Andr\'es A. Peters</dc:creator>
    </item>
    <item>
      <title>An inexact primal-dual method with correction step for a saddle point problem in image debluring</title>
      <link>https://arxiv.org/abs/2112.00389</link>
      <description>arXiv:2112.00389v2 Announce Type: replace 
Abstract: In this paper,we present an inexact primal-dual method with correction step for a saddle point problem by introducing the notations of inexact extended proximal operators with symmetric positive definite matrix
  $D$. Relaxing requirement on primal-dual step sizes, we prove the convergence of the proposed method. We also establish the $O(1/N)$ convergence rate of our method in the ergodic sense. Moreover, we apply our method to solve TV-L$_1$ image deblurring problems. Numerical simulation results illustrate the efficiency of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.00389v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Changjie Fang, Liliang Hu, Shenglan Chen</dc:creator>
    </item>
    <item>
      <title>Finite Approximations for Mean Field Type Multi-Agent Control and Their Near Optimality</title>
      <link>https://arxiv.org/abs/2211.09633</link>
      <description>arXiv:2211.09633v3 Announce Type: replace 
Abstract: We study a multi-agent mean field type control problem in discrete time where the agents aim to find a socially optimal strategy and where the state and action spaces for the agents are assumed to be continuous. The agents are only weakly coupled through the distribution of their state variables. The problem in its original form can be formulated as a classical Markov decision process (MDP), however, this formulation suffers from several practical difficulties. In this work, we attempt to overcome the curse of dimensionality, coordination complexity between the agents, and the necessity of perfect feedback collection from all the agents (which might be hard to do for large populations.)
  We provide several approximations: we establish the near optimality of the action and state space discretization of the agents under standard regularity assumptions for the considered formulation by constructing and studying the measure valued MDP counterpart for finite and infinite population settings. It is a well known approach to consider the infinite population problem for mean-field type models, since it provides symmetric policies for the agents which simplifies the coordination between the agents. However, the optimality analysis is harder as the state space of the measure valued infinite population MDP is continuous (even after space discretization of the agents). Therefore, as a final step, we provide further approximations for the infinite population problem by focusing on smaller sized sub-population distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09633v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Nicole Bauerle, Ali Devran Kara</dc:creator>
    </item>
    <item>
      <title>General Distribution Steering: A Sub-Optimal Solution by Convex Optimization</title>
      <link>https://arxiv.org/abs/2301.06227</link>
      <description>arXiv:2301.06227v2 Announce Type: replace 
Abstract: General distribution steering is intrinsically an infinite-dimensional problem, when the continuous distributions to steer are arbitrary. We put forward a moment representation of the primal system for control in [42]. However, the system trajectory was a predetermined one without optimization towards a design criterion, which doesn't always ensure a most satisfactory solution. In this paper, we propose an optimization approach to the general distribution steering problem of the first-order discrete-time linear system, i.e., an optimal control law for the corresponding moment system. The domain of all feasible control inputs is non-convex and has a complex topology. We obtain a subset of it by minimizing a weighted sum of squared integral distances alongside the system trajectory. The feasible domain is then proved convex, and the optimal control problem can be treated as a convex optimization or by exhaustive search, based on the type of the cost function. Algorithms of steering for continuous and discrete distributions are then put forward respectively, by adopting a realization scheme of control inputs. We also provide an explicit advantage of our proposed algorithm by truncated power moments to the prevailing Gaussian Mixture Models. Experiments on different types of cost functions are given to validate the performance of our proposed algorithm. Since the moment system is a dimension-reduced counterpart of the primal system, we call this solution a sub-optimal one to the primal general distribution steering problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06227v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guangyu Wu, Anders Lindquist</dc:creator>
    </item>
    <item>
      <title>Carbon-Aware Optimal Power Flow</title>
      <link>https://arxiv.org/abs/2308.03240</link>
      <description>arXiv:2308.03240v4 Announce Type: replace 
Abstract: To facilitate effective decarbonization of the electric power sector, this paper introduces the generic Carbon-aware Optimal Power Flow (C-OPF) method for power system decision-making that considers demand-side carbon accounting and emission management. Built upon the classic optimal power flow (OPF) model, the C-OPF method incorporates carbon emission flow equations and constraints, as well as carbon-related objectives, to jointly optimize power flow and carbon flow. In particular, this paper establishes the feasibility and solution uniqueness of the carbon emission flow equations, and proposes modeling and linearization techniques to address the issues of undetermined power flow directions and bilinear terms in the C-OPF model. Additionally, two novel carbon emission models, together with the carbon accounting schemes, for energy storage systems are developed and integrated into the C-OPF model. Numerical simulations demonstrate the characteristics and effectiveness of the C-OPF method, in comparison with OPF solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03240v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xin Chen, Andy Sun, Wenbo Shi, Na Li</dc:creator>
    </item>
    <item>
      <title>Optimal quantization with branched optimal transport distances</title>
      <link>https://arxiv.org/abs/2309.08677</link>
      <description>arXiv:2309.08677v3 Announce Type: replace 
Abstract: We consider the problem of optimal approximation of a target measure by an atomic measure with $N$ atoms, in branched optimal transport distance. This is a new branched transport version of optimal quantization problems. New difficulties arise, since in classical semi-discrete optimal transport with Wasserstein distance, the interfaces between cells associated with neighboring atoms have Voronoi structure and satisfy an explicit description. This description is missing for our problem, in which the cell interfaces are thought to have fractal boundary. We study the asymptotic behaviour of optimal quantizers for absolutely continuous measures as the number $N$ of atoms grows to infinity. We compute the limit distribution of the corresponding point clouds and show in particular a branched transport version of Zador's theorem. Moreover, we establish uniformity bounds of optimal quantizers in terms of separation distance and covering radius of the atoms, when the measure is $d$-Ahlfors regular. A crucial technical tool is the uniform in $N$ H\"older regularity of the landscape function, a branched transport analog to Kantorovich potentials in classical optimal transport.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08677v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Pegon, Mircea Petrache</dc:creator>
    </item>
    <item>
      <title>Optimization Methods Rooting in Optimal Control</title>
      <link>https://arxiv.org/abs/2312.01334</link>
      <description>arXiv:2312.01334v3 Announce Type: replace 
Abstract: In the paper, we propose solving optimization problems (OPs) and understanding the Newton method from the optimal control view. We propose a new optimization algorithm based on the optimal control problem (OCP). The algorithm features converging more rapidly than gradient descent, meanwhile, it is superior to Newton's method because it is not divergent in general and can be applied in the case of a singular Hessian matrix. These merits are supported by the convergence analysis for the algorithm in the paper. We also point out that the convergence rate of the proposed algorithm is inversely proportional to the magnitude of the control weight matrix and proportional to the control terminal time inherited from OCP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01334v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huanshui Zhang, Hongxia Wang</dc:creator>
    </item>
    <item>
      <title>Decentralized Bilevel Optimization: A Perspective from Transient Iteration Complexity</title>
      <link>https://arxiv.org/abs/2402.03167</link>
      <description>arXiv:2402.03167v3 Announce Type: replace 
Abstract: Stochastic bilevel optimization (SBO) is becoming increasingly essential in machine learning due to its versatility in handling nested structures. To address large-scale SBO, decentralized approaches have emerged as effective paradigms in which nodes communicate with immediate neighbors without a central server, thereby improving communication efficiency and enhancing algorithmic robustness. However, most decentralized SBO algorithms focus solely on asymptotic convergence rates, overlooking transient iteration complexity-the number of iterations required before asymptotic rates dominate, which results in limited understanding of the influence of network topology, data heterogeneity, and the nested bilevel algorithmic structures. To address this issue, this paper introduces D-SOBA, a Decentralized Stochastic One-loop Bilevel Algorithm framework. D-SOBA comprises two variants: D-SOBA-SO, which incorporates second-order Hessian and Jacobian matrices, and D-SOBA-FO, which relies entirely on first-order gradients. We provide a comprehensive non-asymptotic convergence analysis and establish the transient iteration complexity of D-SOBA. This provides the first theoretical understanding of how network topology, data heterogeneity, and nested bilevel structures influence decentralized SBO. Extensive experimental results demonstrate the efficiency and theoretical advantages of D-SOBA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03167v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Boao Kong, Shuchen Zhu, Songtao Lu, Xinmeng Huang, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>Inexact Restoration via random models for unconstrained noisy optimization</title>
      <link>https://arxiv.org/abs/2402.12069</link>
      <description>arXiv:2402.12069v2 Announce Type: replace 
Abstract: We study the Inexact Restoration framework with random models for minimizing functions whose evaluation is subject to errors. We propose a constrained formulation that includes well-known stochastic problems and an algorithm applicable when the evaluation of both the function and its gradient is random and a specified accuracy of such evaluations is guaranteed with sufficiently high probability. The proposed algorithm combines the Inexact Restoration framework with a trust-region methodology based on random first-order models. We analyse the properties of the algorithm and provide the expected number of iterations performed to reach an approximate first-order optimality point. Numerical experiments show that the proposed algorithm compares well with a state-of-the-art competitor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12069v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benedetta Morini, Simone Rebegoldi</dc:creator>
    </item>
    <item>
      <title>Superlinear Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2403.11115</link>
      <description>arXiv:2403.11115v2 Announce Type: replace 
Abstract: This paper proposes several novel optimization algorithms for minimizing a nonlinear objective function. The algorithms are enlightened by the optimal state trajectory of an optimal control problem closely related to the minimized objective function. They are superlinear convergent when appropriate parameters are selected as required. Unlike Newton's method, all of them can be also applied in the case of a singular Hessian matrix. More importantly, by reduction, some of them avoid calculating the inverse of the Hessian matrix or an identical dimension matrix and some of them need only the diagonal elements of the Hessian matrix. In these cases, these algorithms still outperform the gradient descent method. The merits of the proposed optimization algorithm are illustrated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11115v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongxia Wang, Yeming Xu, Ziyuan Guo, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Solving Combinatorial Pricing Problems using Embedded Dynamic Programming Models</title>
      <link>https://arxiv.org/abs/2403.12923</link>
      <description>arXiv:2403.12923v2 Announce Type: replace 
Abstract: The combinatorial pricing problem (CPP) is a bilevel problem in which the leader maximizes their revenue by imposing tolls on certain items that they can control. Based on the tolls set by the leader, the follower selects a subset of items corresponding to an optimal solution of a combinatorial optimization problem. To accomplish the leader's goal, the tolls need to be sufficiently low to discourage the follower from choosing the items offered by the competitors. In this paper, we derive a single-level reformulation for the CPP by rewriting the follower's problem as a longest path problem using a dynamic programming model, and then taking its dual and applying strong duality. We proceed to solve the reformulation in a dynamic fashion with a cutting plane method. We apply this methodology to two distinct dynamic programming models, namely, a novel formulation designated as selection diagram and the well-known decision diagram. We also produce numerical results to evaluate their performances across three different specializations of the CPP and a closely related problem that is the knapsack interdiction problem. Our results showcase the potential of the two proposed reformulations over the natural value function approach, expanding the set of tools to solve combinatorial bilevel programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12923v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Quang Minh Bui, Margarida Carvalho, Jos\'e Neto</dc:creator>
    </item>
    <item>
      <title>Adaptive Computing for Scale-up Problems</title>
      <link>https://arxiv.org/abs/2404.00053</link>
      <description>arXiv:2404.00053v2 Announce Type: replace 
Abstract: Adaptive Computing is an application-agnostic outer loop framework to strategically deploy simulations and experiments to guide decision making for scale-up analysis. Resources are allocated over successive batches, which makes the allocation adaptive to some objective such as optimization or model training. The framework enables the characterization and management of uncertainties associated with predictive models of complex systems when scale-up questions lead to significant model extrapolation. A key advancement of this framework is its integration of multi-fidelity surrogate modeling, uncertainty management, and automated orchestration of various computing and experimentation resources into a single integrated software package. This enables efficient multi-fidelity modeling across multiple computing resources by incorporating real-world constraints such as relative queue times and throughput on individual machines into the multi-fidelity sampling decision. We discuss applications of this framework to problems in the renewable energy space, including biofuels production, material synthesis, perovskite crystal growth, and building electrical loads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00053v2</guid>
      <category>math.OC</category>
      <category>physics.flu-dyn</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Patrick Griffin, Hilary Egan, Marc T. Henry de Frahan, Juliane Mueller, Deepthi Vaidhynatha, Dylan Wald, Rohit Chintala, Olga A. Doronina, Hariswaran Sitaraman, Ethan Young, Ryan King, Jibonananda Sanyal, Marc Day, Ross E. Larsen</dc:creator>
    </item>
    <item>
      <title>Distributed Fractional Bayesian Learning for Adaptive Optimization</title>
      <link>https://arxiv.org/abs/2404.11354</link>
      <description>arXiv:2404.11354v2 Announce Type: replace 
Abstract: This paper considers a distributed adaptive optimization problem, where all agents only have access to their local cost functions with a common unknown parameter, whereas they mean to collaboratively estimate the true parameter and find the optimal solution over a connected network. A general mathematical framework for such a problem has not been studied yet. We aim to provide valuable insights for addressing parameter uncertainty in distributed optimization problems and simultaneously find the optimal solution. Thus, we propose a novel Prediction while Optimization scheme, which utilizes distributed fractional Bayesian learning through weighted averaging on the log-beliefs to update the beliefs of unknown parameters, and distributed gradient descent for renewing the estimation of the optimal solution. Then under suitable assumptions, we prove that all agents' beliefs and decision variables converge almost surely to the true parameter and the optimal solution under the true parameter, respectively. We further establish a sublinear convergence rate for the belief sequence. Finally, numerical experiments are implemented to corroborate the theoretical analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11354v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaqun Yang, Jinlong Lei, Guanghui Wen, Yiguang Hong</dc:creator>
    </item>
    <item>
      <title>ADMM for Nonconvex Optimization under Minimal Continuity Assumption</title>
      <link>https://arxiv.org/abs/2405.03233</link>
      <description>arXiv:2405.03233v4 Announce Type: replace 
Abstract: This paper introduces a novel approach to solving multi-block nonconvex composite optimization problems through a proximal linearized Alternating Direction Method of Multipliers (ADMM). This method incorporates an Increasing Penalization and Decreasing Smoothing (IPDS) strategy. Distinguishing itself from existing ADMM-style algorithms, our approach (denoted IPDS-ADMM) imposes a less stringent condition, specifically requiring continuity in just one block of the objective function. IPDS-ADMM requires that the penalty increases and the smoothing parameter decreases, both at a controlled pace. When the associated linear operator is bijective, IPDS-ADMM uses an over-relaxation stepsize for faster convergence; however, when the linear operator is surjective, IPDS-ADMM uses an under-relaxation stepsize for global convergence. We devise a novel potential function to facilitate our convergence analysis and prove an oracle complexity $\mathcal{O}(\epsilon^{-3})$ to achieve an $\epsilon$-approximate critical point. To the best of our knowledge, this is the first complexity result for using ADMM to solve this class of nonsmooth nonconvex problems. Finally, some experiments on the sparse PCA problem are conducted to demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03233v4</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Inverse Particle Filter</title>
      <link>https://arxiv.org/abs/2407.16623</link>
      <description>arXiv:2407.16623v3 Announce Type: replace 
Abstract: In cognitive systems, recent emphasis has been placed on studying the cognitive processes of the subject whose behavior was the primary focus of the system's cognitive response. This approach, known as inverse cognition, arises in counter-adversarial applications and has motivated the development of inverse Bayesian filters. In this context, a cognitive adversary, such as a radar, uses a forward Bayesian filter to track its target of interest. An inverse filter is then employed to infer the adversary's estimate of the target's or defender's state. Previous studies have addressed this inverse filtering problem by introducing methods like the inverse Kalman filter (KF), inverse extended KF, and inverse unscented KF. However, these filters typically assume additive Gaussian noise models and/or rely on local approximations of non-linear dynamics at the state estimates, limiting their practical application. In contrast, this paper adopts a global filtering approach and presents the development of an inverse particle filter (I-PF). The particle filter framework employs Monte Carlo (MC) methods to approximate arbitrary posterior distributions. Moreover, under mild system-level conditions, the proposed I-PF demonstrates convergence to the optimal inverse filter. Additionally, we propose the differentiable I-PF to address scenarios where system information is unknown to the defender. Using the recursive Cramer-Rao lower bound and non-credibility index (NCI), our numerical experiments for different systems demonstrate the estimation performance and time complexity of the proposed filter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.16623v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Himali Singh, Arpan Chattopadhyay, Kumar Vijay Mishra</dc:creator>
    </item>
    <item>
      <title>Alternating Iteratively Reweighted $\ell_1$ and Subspace Newton Algorithms for Nonconvex Sparse Optimization</title>
      <link>https://arxiv.org/abs/2407.17216</link>
      <description>arXiv:2407.17216v4 Announce Type: replace 
Abstract: This paper presents a novel hybrid algorithm for minimizing the sum of a continuously differentiable loss function and a nonsmooth, possibly nonconvex, sparse regularization function. The proposed method alternates between solving a reweighted $\ell_1$-regularized subproblem and performing an inexact subspace Newton step. The reweighted $\ell_1$-subproblem allows for efficient closed-form solutions via the soft-thresholding operator, avoiding the computational overhead of proximity operator calculations. As the algorithm approaches an optimal solution, it maintains a stable support set, ensuring that nonzero components stay uniformly bounded away from zero. It then switches to a perturbed regularized Newton method, further accelerating the convergence. We prove global convergence to a critical point and, under suitable conditions, demonstrate that the algorithm exhibits local linear and quadratic convergence rates. Numerical experiments show that our algorithm outperforms existing methods in both efficiency and solution quality across various model prediction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17216v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wang, Xiangyu Yang, Yichen Zhu</dc:creator>
    </item>
    <item>
      <title>A Framework for Approximating Perturbed Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2408.09546</link>
      <description>arXiv:2408.09546v2 Announce Type: replace 
Abstract: We consider trajectory optimal control problems in which parameter uncertainty limits the applicability of control trajectories computed prior to travel. Hence, efficient trajectory adjustment is needed to ensure successful travel. However, it is often prohibitive or impossible to recalculate the optimal control in-transit due to strict time constraints or limited onboard computing resources. Thus, we propose a framework for quick and accurate trajectory approximations by using post-optimality sensitivity information. This allows the reduction of uncertain parameter space and an instantaneous approximation of the new optimal controller while using sensitivity data computed and stored pretransit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.09546v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riley Link, Ethan Ebbighausen</dc:creator>
    </item>
    <item>
      <title>Power System State Estimation by Phase Synchronization and Eigenvectors</title>
      <link>https://arxiv.org/abs/2409.12828</link>
      <description>arXiv:2409.12828v2 Announce Type: replace 
Abstract: To estimate accurate voltage phasors from inaccurate voltage magnitude and complex power measurements, the standard approach is to iteratively refine a good initial guess using the Gauss--Newton method. But the nonconvexity of the estimation makes the Gauss--Newton method sensitive to its initial guess, so human intervention is needed to detect convergence to plausible but ultimately spurious estimates. This paper makes a novel connection between the angle estimation subproblem and phase synchronization to yield two key benefits: (1) an exceptionally high quality initial guess over the angles, known as a \emph{spectral initialization}; (2) a correctness guarantee for the estimated angles, known as a \emph{global optimality certificate}. These are formulated as sparse eigenvalue-eigenvector problems, which we efficiently compute in time comparable to a few Gauss-Newton iterations. Our experiments on the complete set of Polish, PEGASE, and RTE models show, where voltage magnitudes are already reasonably accurate, that spectral initialization provides an almost-perfect single-shot estimation of $n$ angles from $2n$ moderately noisy bus power measurements (i.e. $n$ pairs of PQ measurements), whose correctness becomes guaranteed after a single Gauss--Newton iteration. For less accurate voltage magnitudes, the performance of the method degrades gracefully; even with moderate voltage magnitude errors, the estimated voltage angles remain surprisingly accurate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12828v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Iven Guzel, Richard Y. Zhang</dc:creator>
    </item>
    <item>
      <title>Nesterov acceleration in benignly non-convex landscapes</title>
      <link>https://arxiv.org/abs/2410.08395</link>
      <description>arXiv:2410.08395v2 Announce Type: replace 
Abstract: While momentum-based optimization algorithms are commonly used in the notoriously non-convex optimization problems of deep learning, their analysis has historically been restricted to the convex and strongly convex setting. In this article, we partially close this gap between theory and practice and demonstrate that virtually identical guarantees can be obtained in optimization problems with a `benign' non-convexity. We show that these weaker geometric assumptions are well justified in overparametrized deep learning, at least locally. Variations of this result are obtained for a continuous time model of Nesterov's accelerated gradient descent algorithm (NAG), the classical discrete time version of NAG, and versions of NAG with stochastic gradient estimates with purely additive noise and with noise that exhibits both additive and multiplicative scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08395v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kanan Gupta, Stephan Wojtowytsch</dc:creator>
    </item>
    <item>
      <title>Revisiting Lossless Convexification: Theoretical Guarantees for Discrete-time Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2410.09748</link>
      <description>arXiv:2410.09748v2 Announce Type: replace 
Abstract: Lossless Convexification (LCvx) is a modeling approach that transforms a class of nonconvex optimal control problems, where nonconvexity primarily arises from control constraints, into convex problems through convex relaxations. These convex problems can be solved using polynomial-time numerical methods after discretization, which converts the original infinite-dimensional problem into a finite-dimensional one. However, existing LCvx theory is limited to continuous-time optimal control problems, as the equivalence between the relaxed convex problem and the original nonconvex problem holds only in continuous time. This paper extends LCvx to discrete-time optimal control problems by classifying them into normal and long-horizon cases. For normal cases, after an arbitrarily small perturbation to the system dynamics (recursive equality constraints), applying the existing LCvx method to discrete-time problems results in optimal controls that meet the original nonconvex constraints at all but no more than $n_x - 1$ temporal grid points, where $n_x$ is the state dimension. For long-horizon cases, the existing LCvx method fails, but we resolve this issue by integrating it with a bisection search, leveraging the continuity of the value function from the relaxed convex problem to achieve similar results as in normal cases. This paper improves the theoretical foundation of LCvx, expanding its applicability to real-world discrete-time optimal control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09748v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dayou Luo, Kazuya Echigo, Beh\c{c}et A\c{c}{\i}kme\c{s}e</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Discrete-Time Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2411.01484</link>
      <description>arXiv:2411.01484v3 Announce Type: replace 
Abstract: This paper focuses on optimal control problem for a class of discrete-time nonlinear systems. In practical applications, computation time is a crucial consideration when solving nonlinear optimal control problems, especially under real-time constraints. While linearization methods are computationally efficient, their inherent low accuracy can compromise control precision and overall performance. To address this challenge, this study proposes a novel approach based on the optimal control method. Firstly, the original optimal control problem is transformed into an equivalent optimization problem, which is resolved using the Pontryagin's maximum principle, and a superlinear convergence algorithm is presented. Furthermore, to improve computation efficiency, explicit formulas for computing both the gradient and hessian matrix of the cost function are proposed. Finally, the effectiveness of the proposed algorithm is validated through simulations and experiments on a linear quadratic regulator problem and an automatic guided vehicle trajectory tracking problem, demonstrating its ability for real-time online precise control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01484v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chuanzhi Lv, Xunmin Yin, Hongdan Li, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>ADMM for Structured Fractional Minimization</title>
      <link>https://arxiv.org/abs/2411.07496</link>
      <description>arXiv:2411.07496v2 Announce Type: replace 
Abstract: This paper considers a class of structured fractional minimization problems. The numerator consists of a differentiable function, a simple nonconvex nonsmooth function, a concave nonsmooth function, and a convex nonsmooth function composed with a linear operator. The denominator is a continuous function that is either weakly convex or has a weakly convex square root. These problems are prevalent in various important applications in machine learning and data science. Existing methods, primarily based on subgradient methods and smoothing proximal gradient methods, often suffer from slow convergence and numerical stability issues. In this paper, we introduce {\sf FADMM}, the first Alternating Direction Method of Multipliers tailored for this class of problems. {\sf FADMM} decouples the original problem into linearized proximal subproblems, featuring two variants: one using Dinkelbach's parametric method ({\sf FADMM-D}) and the other using the quadratic transform method ({\sf FADMM-Q}). By introducing a novel Lyapunov function, we establish that {\sf FADMM} converges to $\epsilon$-approximate critical points of the problem within an oracle complexity of $\mathcal{O}(1/\epsilon^{3})$. Extensive experiments on synthetic and real-world datasets, including sparse Fisher discriminant analysis, robust Sharpe ratio minimization, and robust sparse recovery, demonstrate the effectiveness of our approach.
  Keywords: Fractional Minimization, Nonconvex Optimization, Proximal Linearized ADMM, Nonsmooth Optimization, Convergence Analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07496v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization Method Based On Optimal Control</title>
      <link>https://arxiv.org/abs/2411.10658</link>
      <description>arXiv:2411.10658v2 Announce Type: replace 
Abstract: In this paper, a novel distributed optimization framework has been proposed. The key idea is to convert optimization problems into optimal control problems where the objective of each agent is to design the current control input minimizing the original objective function of itself and updated size for the future time instant. Compared with the existing distributed optimization problem for optimizing a sum of convex objective functions corresponding to multiple agents, we present a distributed optimization algorithm for multi-agents system based on the results from the maximum principle. Moreover, the convergence and superlinear convergence rate are also analyzed stringently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10658v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyuan Guo, Yue Sun, Yeming Xu, Liping Zhang, Huanshui Zhang</dc:creator>
    </item>
    <item>
      <title>Optimal control under uncertainty with joint chance state constraints: almost-everywhere bounds, variance reduction, and application to (bi-)linear elliptic PDEs</title>
      <link>https://arxiv.org/abs/2412.05125</link>
      <description>arXiv:2412.05125v2 Announce Type: replace 
Abstract: We study optimal control of PDEs under uncertainty with the state variable subject to joint chance constraints. The controls are deterministic, but the states are probabilistic due to random variables in the governing equation. Joint chance constraints ensure that the random state variable meets pointwise bounds with high probability. For linear governing PDEs and elliptically distributed random parameters, we prove existence and uniqueness results for almost-everywhere state bounds. Using the spherical-radial decomposition (SRD) of the uncertain variable, we prove that when the probability is very large or small, the resulting Monte Carlo estimator for the chance constraint probability exhibits substantially reduced variance compared to the standard Monte Carlo estimator. We further illustrate how the SRD can be leveraged to efficiently compute derivatives of the probability function, and discuss different expansions of the uncertain variable in the governing equation. Numerical examples for linear and bilinear PDEs compare the performance of Monte Carlo and quasi-Monte Carlo sampling methods, examining probability estimation convergence as the number of samples increases. We also study how the accuracy of the probabilities depends on the truncation of the random variable expansion, and numerically illustrate the variance reduction of the SRD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05125v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Henrion, Georg Stadler, Florian Wechsung</dc:creator>
    </item>
    <item>
      <title>Certainty-Equivalence Model Predictive Control: Stability, Performance, and Beyond</title>
      <link>https://arxiv.org/abs/2412.10625</link>
      <description>arXiv:2412.10625v2 Announce Type: replace 
Abstract: Handling model mismatch is a common challenge in model-based controller design, particularly in model predictive control (MPC). While robust MPC is effective in managing uncertainties, its conservatism often makes it less desirable in practice. Certainty-equivalence MPC (CE-MPC), which relies on a nominal model, offers an appealing alternative due to its design simplicity and low computational requirements. Contrary to the existing analyses where MPC has access to the true model, this paper investigates CE-MPC for uncertain nonlinear systems with input constraints and parametric uncertainty. The primary contributions of the paper are two-fold. First, a novel perturbation analysis of the MPC value function is provided, without relying on the common assumption of Lipschitz continuity of the stage cost, better tailoring the popular quadratic cost and having broader applicability to value function approximation, online model learning in MPC, and performance-driven MPC design. Second, the stability and performance analysis of CE-MPC are provided, with a quantification of the suboptimality of CE-MPC compared to the infinite-horizon optimal controller with perfect model knowledge. The results provide valuable insights in how the prediction horizon and model mismatch jointly affect stability and performance. Furthermore, the general results are specialized to linear quadratic control, and a competitive ratio bound is derived, serving as the first competitive-ratio bound for MPC of uncertain linear systems with input constraints and multiplicative uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10625v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Changrui Liu, Shengling Shi, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>Optimizing Impulsive Releases in Species Competition Models</title>
      <link>https://arxiv.org/abs/2502.01879</link>
      <description>arXiv:2502.01879v2 Announce Type: replace 
Abstract: This study focuses on optimizing species release $S_2$ to control species population $S_1$ through impulsive release strategies. We investigate the conditions required to remove species $S_1$, which is equivalent to the establishment of $S_2$. The research includes a theoretical analysis that examines the positivity, existence, and uniqueness of solutions and the conditions for the global stability of the $S_1$-free solution. In addition, we formulate an optimal control problem to maximize the effectiveness of $S_2$ releases, manage the population of $S_1$, and minimize the costs associated with this intervention strategy. Numerical simulations are conducted to validate the proposed theories and allow visualization of population dynamics under various releases scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01879v2</guid>
      <category>math.OC</category>
      <category>q-bio.PE</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J\'essica C. S. Alves, Sergio M. Oliva, Christian E. Schaerer</dc:creator>
    </item>
    <item>
      <title>Feasibility Evaluation of Quadratic Programs for Constrained Control</title>
      <link>https://arxiv.org/abs/2502.12005</link>
      <description>arXiv:2502.12005v2 Announce Type: replace 
Abstract: This paper presents a computationally-efficient method for evaluating the feasibility of Quadratic Programs (QPs) for online constrained control. Based on the duality principle, we first show that the feasibility of a QP can be determined by the solution of a properly-defined Linear Program (LP). Our analysis yields a LP that can be solved more efficiently compared to the original QP problem, and more importantly, is simpler in form and can be solved more efficiently compared to existing methods that assess feasibility via LPs. The computational efficiency of the proposed method compared to existing methods for feasibility evaluation is demonstrated in comparative case studies as well as a feasible-constraint selection problem, indicating its promise for online feasibility evaluation of optimization-based controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12005v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Panagiotis Rousseas, Dimitra Panagou</dc:creator>
    </item>
    <item>
      <title>Accelerated Distributed Optimization with Compression and Error Feedback</title>
      <link>https://arxiv.org/abs/2503.08427</link>
      <description>arXiv:2503.08427v2 Announce Type: replace 
Abstract: Modern machine learning tasks often involve massive datasets and models, necessitating distributed optimization algorithms with reduced communication overhead. Communication compression, where clients transmit compressed updates to a central server, has emerged as a key technique to mitigate communication bottlenecks. However, the theoretical understanding of stochastic distributed optimization with contractive compression remains limited, particularly in conjunction with Nesterov acceleration -- a cornerstone for achieving faster convergence in optimization.
  In this paper, we propose a novel algorithm, ADEF (Accelerated Distributed Error Feedback), which integrates Nesterov acceleration, contractive compression, error feedback, and gradient difference compression. We prove that ADEF achieves the first accelerated convergence rate for stochastic distributed optimization with contractive compression in the general convex regime. Numerical experiments validate our theoretical findings and demonstrate the practical efficacy of ADEF in reducing communication costs while maintaining fast convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08427v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Jeremy Rack, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Adaptive Stochastic Gradient Descents on Manifolds with an Application on Weighted Low-Rank Approximation</title>
      <link>https://arxiv.org/abs/2503.11833</link>
      <description>arXiv:2503.11833v2 Announce Type: replace 
Abstract: We prove a convergence theorem for stochastic gradient descents on manifolds with adaptive learning rate and apply it to the weighted low-rank approximation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11833v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Peiqi Yang, Conglong Xu, Hao Wu</dc:creator>
    </item>
    <item>
      <title>Analytical Strategies and Winning Conditions for Elliptic-Orbit Target-Attacker-Defender Game</title>
      <link>https://arxiv.org/abs/2503.14252</link>
      <description>arXiv:2503.14252v3 Announce Type: replace 
Abstract: This paper proposes an analytical framework for the orbital Target-Attacker-Defender game with a non-maneuvering target along elliptic orbits. Focusing on the linear quadratic game, we derive an analytical solution to the matrix Riccati equation, which yields analytical Nash-equilibrium strategies for the game. Based on the analytical strategies, we derive the analytical form of the necessary and sufficient winning conditions for the attacker. The simulation results show good consistency between the analytical and numerical methods, exhibiting 0.004$\%$ relative error in the cost function. The analytical method achieves over 99.9$\%$ reduction in CPU time compared to the conventional numerical method, strengthening the advantage of developing the analytical strategies. Furthermore, we verify the proposed winning conditions and investigate the effects of eccentricity on the game outcomes. Our analysis reveals that for games with hovering initial states, the initial position of the defender should be constrained inside a mathematically definable set to ensure that the attacker wins the game. This constrained set further permits geometric interpretation through our proposed method. This work establishes the analytical framework for orbital Target-Attacker-Defender games, providing fundamental insights into the solution analysis of the game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14252v3</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuyue Fu, Shengping Gong, Di Wu, Peng Shi</dc:creator>
    </item>
    <item>
      <title>Stability of Schr\"odinger bridges and Sinkhorn semigroups for log-concave models</title>
      <link>https://arxiv.org/abs/2503.15963</link>
      <description>arXiv:2503.15963v3 Announce Type: replace 
Abstract: In this article we obtain several new results and developments in the study of entropic optimal transport problems (a.k.a. Schr\"odinger problems) with general reference distributions and log-concave target marginal measures. Our approach combines transportation cost inequalities
  with the theory of Riccati matrix difference equations arising in filtering and optimal control theory. This methodology is partly based on a novel entropic stability of Schr\"odinger bridges and closed form expressions of a class of discrete time algebraic Riccati equations. In the context of regularized entropic transport these techniques provide new sharp entropic map estimates. When applied to the stability of Sinkhorn semigroups, they also yield
  a series of novel contraction estimates in terms of the fixed point of Riccati equations.
  The strength of our approach is that it is applicable to a large class of models arising in machine learning and artificial intelligence algorithms. We illustrate the impact of our results in the context of regularized entropic transport, proximal samplers and diffusion generative models as well as diffusion flow matching models</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15963v3</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierre Del Moral</dc:creator>
    </item>
    <item>
      <title>A Linear Convergence Result for the Jacobi-Proximal Alternating Direction Method of Multipliers</title>
      <link>https://arxiv.org/abs/2503.18601</link>
      <description>arXiv:2503.18601v2 Announce Type: replace 
Abstract: In this paper, we analyze the convergence rate of the Jacobi-Proximal Alternating Direction Method of Multipliers (ADMM), a method initially introduced by Deng et al. for the block-structured optimization problem with linear constraint. We establish the linear convergence of the algorithm when the cost functions are strongly convex and smooth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18601v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyelin Choi, Woocheol Choi</dc:creator>
    </item>
    <item>
      <title>Risk-Aware Adaptive Control Barrier Functions for Safe Control of Nonlinear Systems under Stochastic Uncertainty</title>
      <link>https://arxiv.org/abs/2503.19205</link>
      <description>arXiv:2503.19205v2 Announce Type: replace 
Abstract: This paper addresses the challenge of ensuring safety in stochastic control systems with high-relative-degree constraints, while maintaining feasibility and mitigating conservatism in risk evaluation. Control Barrier Functions (CBFs) provide an effective framework for enforcing safety constraints in nonlinear systems. However, existing methods struggle with feasibility issues and multi-step uncertainties. To address these challenges, we introduce Risk-aware Adaptive CBFs (RACBFs), which integrate Discrete-time Auxiliary-Variable adaptive CBFs (DAVCBFs) with coherent risk measures. DAVCBFs introduce auxiliary variables to improve the feasibility of the optimal control problem, while RACBFs incorporate risk-aware formulations to balance safety and risk evaluation performance. By extending discrete-time high-order CBF constraints over multiple steps, RACBFs effectively handle multi-step uncertainties that propagate through the system dynamics. We demonstrate the effectiveness of our approach on a stochastic unicycle system, showing that RACBFs maintain safety and feasibility while reducing unnecessary conservatism compared to standard robust formulations of discrete-time CBF methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19205v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Liu, Calin A. Belta</dc:creator>
    </item>
    <item>
      <title>A parallel branch-and-bound-and-prune algorithm for irregular strip packing with discrete rotations</title>
      <link>https://arxiv.org/abs/2503.21009</link>
      <description>arXiv:2503.21009v2 Announce Type: replace 
Abstract: The irregular strip-packing problem consists of the computation of a non-overlapping placement of a set of polygons onto a rectangular strip of fixed width and the minimal length possible. Recent performance gains of the Mixed-Integer Linear Programming (MILP) solvers have encouraged the proposal of exact optimization models for nesting. The Dotted-Board (DB) MILP model solves the discrete version of the nesting problem by constraining the positions of the polygons to be on a grid of fixed points. However, its number of non-overlapping constraints grows exponentially with the number of dots and types of polygons, which encouraged the proposal of a reformulation called the DB Clique Covering (DB-CC) that sets the current state-of-the-art by significantly reducing the constraints required. However, DB-CC requires a significant preprocessing time to compute edge and vertex clique coverings. Moreover, current knowledge of the stable set polytope suggests that achieving a tighter formulation is unlikely. Thus, our hypothesis is that an ad-hoc exact algorithm requiring no preprocessing might be a better option to solve the DB model than the costly Branch-and-Cut approach. This work proposes an exact branch-and-bound-and-prune algorithm to solve the DB model from the conflict inverse graph based on ad-hoc data structures, bounding, and forward-checking for pruning the search space. We introduce two 0-1 ILP DB reformulations with discrete rotations and a new lower-bound algorithm as by-products. Our experiments show that DB-PB significantly reduces the resolution time compared to our replication of the DB-CC model. Seventeen open instances are solved up to optimality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21009v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Juan J. Lastra-D\'iaz, M. Teresa Ortu\~no</dc:creator>
    </item>
    <item>
      <title>Diffusion at Absolute Zero: Langevin Sampling using Successive Moreau Envelopes</title>
      <link>https://arxiv.org/abs/2503.22258</link>
      <description>arXiv:2503.22258v2 Announce Type: replace 
Abstract: We propose a method for sampling from Gibbs distributions of the form $\pi(x)\propto\exp(-U(x))$ by considering a family $(\pi^{t})_t$ of approximations of the target density which is such that $\pi^{t}$ exhibits favorable properties for sampling when $t$ is large, and $\pi^{t} \to \pi$ as $t \to 0$. This sequence is obtained by replacing (parts of) the potential $U$ by its Moreau envelope. Through the sequential sampling from $\pi^{t}$ for decreasing values of $t$ by a Langevin algorithm with appropriate step size, the samples are guided from a simple starting density to the more complex target quickly. We prove the ergodicity of the method as well as its convergence to the target density without assuming convexity or differentiability of the potential $U$. In addition to the theoretical analysis, we show experimental results that support the superiority of the method in terms of convergence speed and mode-coverage of multi-modal densities to current algorithms. The experiments range from one-dimensional toy-problems to high-dimensional inverse imaging problems with learned potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22258v2</guid>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andreas Habring, Alexander Falk, Martin Zach, Thomas Pock</dc:creator>
    </item>
    <item>
      <title>The Average and Essential Best Rate of Convergence of the Exact Line Search Gradient Descent Method</title>
      <link>https://arxiv.org/abs/2305.09140</link>
      <description>arXiv:2305.09140v3 Announce Type: replace-cross 
Abstract: It is very well known that when the exact line search gradient descent method is applied to a convex quadratic objective, the worst-case rate of convergence (ROC), among all seed vectors, deteriorates as the condition number of the Hessian of the objective grows. By an elegant analysis due to H. Akaike, it is generally believed -- but not proved -- that in the ill-conditioned regime the ROC for almost all initial vectors, and hence also the average ROC, is close to the worst case ROC. We complete Akaike's analysis using the theorem of center and stable manifolds. Our analysis also makes apparent the effect of an intermediate eigenvalue in the Hessian by establishing the following somewhat amusing result: In the absence of an intermediate eigenvalue, the average ROC gets arbitrarily \emph{fast} -- not slow -- as the Hessian gets increasingly ill-conditioned.
  We discuss in passing some contemporary applications of exact line search GD to polynomial optimization problems arising from imaging and data sciences. In particular, we observe that a tailored exact line search GD algorithm for a POP arising from the phase retrieval problem is only 50\% more expensive per iteration than its constant step size counterpart, while promising a ROC only matched by the optimally tuned (constant) step size which can almost never be achieved in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09140v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Yu</dc:creator>
    </item>
    <item>
      <title>ADMM Algorithms for Residual Network Training: Convergence Analysis and Parallel Implementation</title>
      <link>https://arxiv.org/abs/2310.15334</link>
      <description>arXiv:2310.15334v2 Announce Type: replace-cross 
Abstract: We propose both serial and parallel proximal (linearized) alternating direction method of multipliers (ADMM) algorithms for training residual neural networks. In contrast to backpropagation-based approaches, our methods inherently mitigate the exploding gradient issue and are well-suited for parallel and distributed training through regional updates. Theoretically, we prove that the proposed algorithms converge at an R-linear (sublinear) rate for both the iteration points and the objective function values. These results hold without imposing stringent constraints on network width, depth, or training data size. Furthermore, we theoretically analyze our parallel/distributed ADMM algorithms, highlighting their reduced time complexity and lower per-node memory consumption. To facilitate practical deployment, we develop a control protocol for parallel ADMM implementation using Python's multiprocessing and interprocess communication. Experimental results validate the proposed ADMM algorithms, demonstrating rapid and stable convergence, improved performance, and high computational efficiency. Finally, we highlight the improved scalability and efficiency achieved by our parallel ADMM training strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.15334v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jintao Xu, Yifei Li, Wenxun Xing</dc:creator>
    </item>
    <item>
      <title>Numerical analysis of a first-order computational algorithm for reaction-diffusion equations via the primal-dual hybrid gradient method</title>
      <link>https://arxiv.org/abs/2401.14602</link>
      <description>arXiv:2401.14602v2 Announce Type: replace-cross 
Abstract: In arXiv:2305.03945 [math.NA], a first-order optimization algorithm has been introduced to solve time-implicit schemes of reaction-diffusion equations. In this research, we conduct theoretical studies on this first-order algorithm equipped with a quadratic regularization term. We provide sufficient conditions under which the proposed algorithm and its time-continuous limit converge exponentially fast to a desired time-implicit numerical solution. We show both theoretically and numerically that the convergence rate is independent of the grid size, which makes our method suitable for large-scale problems. The efficiency of our algorithm has been verified via a series of numerical examples conducted on various types of reaction-diffusion equations. The choice of optimal hyperparameters as well as comparisons with some classical root-finding algorithms are also discussed in the numerical section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14602v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shu Liu, Xinzhe Zuo, Stanley Osher, Wuchen Li</dc:creator>
    </item>
    <item>
      <title>Implicit Bias and Fast Convergence Rates for Self-attention</title>
      <link>https://arxiv.org/abs/2402.05738</link>
      <description>arXiv:2402.05738v2 Announce Type: replace-cross 
Abstract: We study the fundamental optimization principles of self-attention, the defining mechanism of transformers, by analyzing the implicit bias of gradient-based optimizers in training a self-attention layer with a linear decoder in binary classification. Building on prior studies in linear logistic regression, recent findings demonstrate that the key-query matrix $W_t$ from gradient-descent (GD) converges in direction towards $W_{mm}$, which maximizes the margin between optimal and non-optimal tokens across sequences. However, this convergence is local, dependent on initial conditions, only holds asymptotically as the number of iterations increases, and leaves questions about the potential benefits of adaptive step-size rules unaddressed. To bridge this gap, we first establish scenarios for which convergence is provably \emph{global}. We then analyze two adaptive step-size strategies: normalized GD and Polyak step-size, demonstrating \emph{finite-time} convergence rates for $W_t$ to $W_{mm}$, and quantifying the sparsification rate of the attention map. These findings not only show that these strategies can accelerate parameter convergence over standard GD in a non-convex setting but also deepen the understanding of the implicit bias in self-attention, linking it more closely to the phenomena observed in linear logistic regression despite its intricate non-convex nature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05738v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhavya Vasudeva, Puneesh Deora, Christos Thrampoulidis</dc:creator>
    </item>
    <item>
      <title>Simple matrix expressions for the curvatures of Grassmannian</title>
      <link>https://arxiv.org/abs/2406.11821</link>
      <description>arXiv:2406.11821v2 Announce Type: replace-cross 
Abstract: We show that modeling a Grassmannian as symmetric orthogonal matrices $\operatorname{Gr}(k,\mathbb{R}^n) \cong\{Q \in \mathbb{R}^{n \times n} : Q^{\scriptscriptstyle\mathsf{T}} Q = I, \; Q^{\scriptscriptstyle\mathsf{T}} = Q,\; \operatorname{tr}(Q)=2k - n\}$ yields exceedingly simple matrix formulas for various curvatures and curvature-related quantities, both intrinsic and extrinsic. These include Riemann, Ricci, Jacobi, sectional, scalar, mean, principal, and Gaussian curvatures; Schouten, Weyl, Cotton, Bach, Pleba\'nski, cocurvature, nonmetricity, and torsion tensors; first, second, and third fundamental forms; Gauss and Weingarten maps; and upper and lower delta invariants. We will derive explicit, simple expressions for the aforementioned quantities in terms of standard matrix operations that are stably computable with numerical linear algebra. Many of these aforementioned quantities have never before been presented for the Grassmannian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11821v2</guid>
      <category>math.DG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zehua Lai, Lek-Heng Lim, Ke Ye</dc:creator>
    </item>
    <item>
      <title>Robust Model Predictive Control for Aircraft Intent-Aware Collision Avoidance</title>
      <link>https://arxiv.org/abs/2408.06999</link>
      <description>arXiv:2408.06999v2 Announce Type: replace-cross 
Abstract: This paper presents the use of robust model predictive control for the design of an intent-aware collision avoidance system for multi-agent aircraft engaged in horizontal maneuvering scenarios. We assume that information from other agents is accessible in the form of waypoints or destinations. Consequently, we consider that other agents follow their optimal Dubin's path--a trajectory that connects their current state to their intended state--while accounting for potential uncertainties. We propose using scenario tree model predictive control as a robust approach that demonstrates computational efficiency. We demonstrate that the proposed method can easily integrate intent information and offer a robust scheme that handles different uncertainties. The method is illustrated through simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06999v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Arash Bahari Kordabad, Andrea Da Col, Arabinda Ghosh, Sybert Stroeve, Sadegh Soudjani</dc:creator>
    </item>
    <item>
      <title>An Efficient Frequency-Based Approach for Maximal Square Detection in Binary Matrices</title>
      <link>https://arxiv.org/abs/2503.18974</link>
      <description>arXiv:2503.18974v2 Announce Type: replace-cross 
Abstract: This paper presents a novel frequency-based algorithm which solves the maximal square problem with improved practical speed performance while maintaining optimal asymptotic complexity. My approach tracks the columnar continuity of ones through an adaptive frequency vector and dynamic thresholding mechanism that eliminates the need for nested minimum operations commonly found in standard dynamic programming solutions. Theoretical analysis confirms a time complexity of O(mn) and a space complexity of O(n).Formal loop-invariant proofs verify correctness, while comprehensive benchmarking demonstrates speed improvements of 1.3-5x over standard methods in various matrix densities and sizes. This method improves algorithm design and simultaneously creates opportunities for faster spatial pattern recognition in fields like urban planning, environmental science, and medical imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18974v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Swastik Bhandari</dc:creator>
    </item>
    <item>
      <title>Local Stability and Stabilization of Quadratic-Bilinear Systems using Petersen's Lemma</title>
      <link>https://arxiv.org/abs/2503.21040</link>
      <description>arXiv:2503.21040v2 Announce Type: replace-cross 
Abstract: Quadratic-bilinear (QB) systems arise in many areas of science and engineering. In this paper, we present a scalable approach for designing locally stabilizing state-feedback control laws and certifying the local stability of QB systems. Sufficient conditions are established for local stability and stabilization based on quadratic Lyapunov functions, which also provide ellipsoidal inner-estimates for the region of attraction and region of stabilizability of an equilibrium point. Our formulation exploits Petersen's Lemma to convert the problem of certifying the sign-definiteness of the Lyapunov condition into a line search over a single scalar parameter. The resulting linear matrix inequality (LMI) conditions scale quadratically with the state dimension for both stability analysis and control synthesis, thus enabling analysis and control of QB systems with hundreds of state variables without resorting to specialized implementations. We demonstrate the approach on three benchmark problems from the existing literature. In all cases, we find our formulation yields comparable approximations of stability domains as determined by other established tools that are otherwise restricted to systems with up to tens of state variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21040v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amir Enayati Kafshgarkolaei, Maziar S. Hemati</dc:creator>
    </item>
    <item>
      <title>Efficient Learning for Entropy-Regularized Markov Decision Processes via Multilevel Monte Carlo</title>
      <link>https://arxiv.org/abs/2503.21224</link>
      <description>arXiv:2503.21224v2 Announce Type: replace-cross 
Abstract: Designing efficient learning algorithms with complexity guarantees for Markov decision processes (MDPs) with large or continuous state and action spaces remains a fundamental challenge. We address this challenge for entropy-regularized MDPs with Polish state and action spaces, assuming access to a generative model of the environment. We propose a novel family of multilevel Monte Carlo (MLMC) algorithms that integrate fixed-point iteration with MLMC techniques and a generic stochastic approximation of the Bellman operator. We quantify the precise impact of the chosen approximate Bellman operator on the accuracy of the resulting MLMC estimator. Leveraging this error analysis, we show that using a biased plain MC estimate for the Bellman operator results in quasi-polynomial sample complexity, whereas an unbiased randomized multilevel approximation of the Bellman operator achieves polynomial sample complexity in expectation. Notably, these complexity bounds are independent of the dimensions or cardinalities of the state and action spaces, distinguishing our approach from existing algorithms whose complexities scale with the sizes of these spaces. We validate these theoretical performance guarantees through numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21224v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthieu Meunier, Christoph Reisinger, Yufei Zhang</dc:creator>
    </item>
  </channel>
</rss>
