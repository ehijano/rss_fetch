<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.IT</link>
    <description>cs.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Gaussian Channel Simulation with Rotated Dithered Quantization</title>
      <link>https://arxiv.org/abs/2407.12970</link>
      <description>arXiv:2407.12970v1 Announce Type: new 
Abstract: Channel simulation involves generating a sample $Y$ from the conditional distribution $P_{Y|X}$, where $X$ is a remote realization sampled from $P_X$. This paper introduces a novel approach to approximate Gaussian channel simulation using dithered quantization. Our method concurrently simulates $n$ channels, reducing the upper bound on the excess information by half compared to one-dimensional methods. When used with higher-dimensional lattices, our approach achieves up to six times reduction on the upper bound. Furthermore, we demonstrate that the KL divergence between the distributions of the simulated and Gaussian channels decreases with the number of dimensions at a rate of $O(n^{-1})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12970v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Szymon Kobus, Lucas Theis, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Interleaved Block-Sparse Transform</title>
      <link>https://arxiv.org/abs/2407.13255</link>
      <description>arXiv:2407.13255v1 Announce Type: new 
Abstract: Low-complexity Bayes-optimal memory approximate message passing (MAMP) is an efficient signal estimation algorithm in compressed sensing and multicarrier modulation. However, achieving replica Bayes optimality with MAMP necessitates a large-scale right-unitarily invariant transformation, which is prohibitive in practical systems due to its high computational complexity and hardware costs. To solve this difficulty, this letter proposes a low-complexity interleaved block-sparse (IBS) transform, which consists of interleaved multiple low-dimensional transform matrices, aimed at reducing the hardware implementation scale while mitigating performance loss. Furthermore, an IBS cross-domain memory approximate message passing (IBS-CD-MAMP) estimator is developed, comprising a memory linear estimator in the IBS transform domain and a non-linear estimator in the source domain. Numerical results show that the IBS-CD-MAMP offers a reduced implementation scale and lower complexity with excellent performance in IBS-based compressed sensing and interleave frequency division multiplexing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13255v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Liu, Ming Wang, Shufeng Li, Yuhao Chi, Ning Wei, ZhaoYang Zhang</dc:creator>
    </item>
    <item>
      <title>Group Movable Antenna With Flexible Sparsity: Joint Array Position and Sparsity Optimization</title>
      <link>https://arxiv.org/abs/2407.13306</link>
      <description>arXiv:2407.13306v1 Announce Type: new 
Abstract: Movable antenna (MA) is a promising technology to exploit the spatial variation of wireless channel for performance enhancement, by dynamically varying the antenna position within a certain region. However, for multi-antenna communication systems, moving each antenna independently not only requires prohibitive complexity to find the optimal antenna positions, but also incurs sophisticated movement control in practice. To address this issue, this letter proposes a new MA architecture termed group MA (GMA), enabling the group movement of all elements collectively in a continuous manner, and simultaneously achieving flexible array architecture by antenna selection (AS). In this letter, we focus on the uniform sparse array based GMA, where equally spaced antenna elements are selected to achieve desired array sparsity. The array position and sparsity level are jointly optimized to maximize the sum rate of the multi-user communication system. Numerical results verify the necessity to optimize the position and sparsity of GMA, and considerable performance gain is achieved as compared to the conventional fixed-position antenna (FPA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13306v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiquan Lu, Yong Zeng, Shi Jin, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>An Algorithm for Computing the Capacity of Symmetrized KL Information for Discrete Channels</title>
      <link>https://arxiv.org/abs/2407.13436</link>
      <description>arXiv:2407.13436v1 Announce Type: new 
Abstract: Symmetrized Kullback-Leibler (KL) information (\(I_{\mathrm{SKL}}\)), which symmetrizes the traditional mutual information by integrating Lautum information, has been shown as a critical quantity in communication~\cite{aminian2015capacity} and learning theory~\cite{aminian2023information}. This paper considers the problem of computing the capacity in terms of \(I_{\mathrm{SKL}}\) for a fixed discrete channel. Such a maximization problem is reformulated into a discrete quadratic optimization with a simplex constraint. One major challenge here is the non-concavity of Lautum information, which complicates the optimization problem. Our method involves symmetrizing the KL divergence matrix and applying iterative updates to ensure a non-decreasing update while maintaining a valid probability distribution. We validate our algorithm on Binary symmetric Channels and Binomial Channels, demonstrating its consistency with theoretical values. Additionally, we explore its application in machine learning through the Gibbs channel, showcasing the effectiveness of our algorithm in finding the worst-case data distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13436v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haobo Chen, Gholamali Aminian, Yuheng Bu</dc:creator>
    </item>
    <item>
      <title>Energy-Efficient Channel Decoding for Wireless Federated Learning: Convergence Analysis and Adaptive Design</title>
      <link>https://arxiv.org/abs/2407.13703</link>
      <description>arXiv:2407.13703v1 Announce Type: new 
Abstract: One of the most critical challenges for deploying distributed learning, such as federated learning (FL), in wireless networks is the limited battery capacity of mobile devices. While it is a common belief that the major energy consumption of mobile devices comes from the uplink data transmission, this paper presents a novel finding, namely the channel decoding operation also contributes significantly to the overall energy consumption of mobile devices in FL. Motivated by this new observation, we propose an energy-efficient adaptive channel decoding scheme that leverages the intrinsic robustness of FL to model errors. In particular, the robustness is exploited to reduce the energy consumption of channel decoders at mobile devices by adaptively adjusting the number of decoding iterations. We theoretically prove that FL with communication errors can converge at the same rate as error-free communication as long as the bit error rate (BER) is properly constrained. An adaptive channel decoding scheme is then proposed to improve the energy efficiency of FL systems. Experimental results demonstrate that the proposed method maintains the same learning accuracy while reducing the channel decoding energy consumption by 20% when compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13703v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linping Qu, Yuyi Mao, Shenghui Song, Chi-Ying Tsui</dc:creator>
    </item>
    <item>
      <title>Finite de Finetti bounds in relative entropy</title>
      <link>https://arxiv.org/abs/2407.12921</link>
      <description>arXiv:2407.12921v1 Announce Type: cross 
Abstract: We review old and recent finite de Finetti theorems in total variation distance and in relative entropy, and we highlight their connections with bounds on the difference between sampling with and without replacement. We also establish two new finite de Finetti theorems for exchangeable random vectors taking values in arbitrary spaces. These bounds are tight, and they are independent of the size and the dimension of the underlying space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12921v1</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lampros Gavalakis, Oliver Johnson, Ioannis Kontoyiannis</dc:creator>
    </item>
    <item>
      <title>Adaptive Foundation Models for Online Decisions: HyperAgent with Fast Incremental Uncertainty Estimation</title>
      <link>https://arxiv.org/abs/2407.13195</link>
      <description>arXiv:2407.13195v1 Announce Type: cross 
Abstract: Foundation models often struggle with uncertainty when faced with new situations in online decision-making, necessitating scalable and efficient exploration to resolve this uncertainty. We introduce GPT-HyperAgent, an augmentation of GPT with HyperAgent for uncertainty-aware, scalable exploration in contextual bandits, a fundamental online decision problem involving natural language input. We prove that HyperAgent achieves fast incremental uncertainty estimation with $\tilde{O}(\log T)$ per-step computational complexity over $T$ periods under the linear realizable assumption. Our analysis demonstrates that HyperAgent's regret order matches that of exact Thompson sampling in linear contextual bandits, closing a significant theoretical gap in scalable exploration. Empirical results in real-world contextual bandit tasks, such as automated content moderation with human feedback, validate the practical effectiveness of GPT-HyperAgent for safety-critical decisions. Our code is open-sourced at \url{https://github.com/szrlee/GPT-HyperAgent/}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13195v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingru Li, Jiawei Xu, Zhi-Quan Luo</dc:creator>
    </item>
    <item>
      <title>The Language of Infographics: Toward Understanding Conceptual Metaphor Use in Scientific Storytelling</title>
      <link>https://arxiv.org/abs/2407.13416</link>
      <description>arXiv:2407.13416v1 Announce Type: cross 
Abstract: We apply an approach from cognitive linguistics by mapping Conceptual Metaphor Theory (CMT) to the visualization domain to address patterns of visual conceptual metaphors that are often used in science infographics. Metaphors play an essential part in visual communication and are frequently employed to explain complex concepts. However, their use is often based on intuition, rather than following a formal process. At present, we lack tools and language for understanding and describing metaphor use in visualization to the extent where taxonomy and grammar could guide the creation of visual components, e.g., infographics. Our classification of the visual conceptual mappings within scientific representations is based on the breakdown of visual components in existing scientific infographics. We demonstrate the development of this mapping through a detailed analysis of data collected from four domains (biomedicine, climate, space, and anthropology) that represent a diverse range of visual conceptual metaphors used in the visual communication of science. This work allows us to identify patterns of visual conceptual metaphor use within the domains, resolve ambiguities about why specific conceptual metaphors are used, and develop a better overall understanding of visual metaphor use in scientific infographics. Our analysis shows that ontological and orientational conceptual metaphors are the most widely applied to translate complex scientific concepts. To support our findings we developed a visual exploratory tool based on the collected database that places the individual infographics on a spatio-temporal scale and illustrates the breakdown of visual conceptual metaphors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13416v1</guid>
      <category>cs.IR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hana Pokojn\'a, Tobias Isenberg, Stefan Bruckner, Barbora Kozl\'ikov\'a, Laura Garrison</dc:creator>
    </item>
    <item>
      <title>With or Without Replacement? Improving Confidence in Fourier Imaging</title>
      <link>https://arxiv.org/abs/2407.13575</link>
      <description>arXiv:2407.13575v1 Announce Type: cross 
Abstract: Over the last few years, debiased estimators have been proposed in order to establish rigorous confidence intervals for high-dimensional problems in machine learning and data science. The core argument is that the error of these estimators with respect to the ground truth can be expressed as a Gaussian variable plus a remainder term that vanishes as long as the dimension of the problem is sufficiently high. Thus, uncertainty quantification (UQ) can be performed exploiting the Gaussian model. Empirically, however, the remainder term cannot be neglected in many realistic situations of moderately-sized dimensions, in particular in certain structured measurement scenarios such as Magnetic Resonance Imaging (MRI). This, in turn, can downgrade the advantage of the UQ methods as compared to non-UQ approaches such as the standard LASSO. In this paper, we present a method to improve the debiased estimator by sampling without replacement. Our approach leverages recent results of ours on the structure of the random nature of certain sampling schemes showing how a transition between sampling with and without replacement can lead to a weighted reconstruction scheme with improved performance for the standard LASSO. In this paper, we illustrate how this reweighted sampling idea can also improve the debiased estimator and, consequently, provide a better method for UQ in Fourier imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13575v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frederik Hoppe, Claudio Mayrink Verdun, Felix Krahmer, Marion I. Menzel, Holger Rauhut</dc:creator>
    </item>
    <item>
      <title>Non-Asymptotic Uncertainty Quantification in High-Dimensional Learning</title>
      <link>https://arxiv.org/abs/2407.13666</link>
      <description>arXiv:2407.13666v1 Announce Type: cross 
Abstract: Uncertainty quantification (UQ) is a crucial but challenging task in many high-dimensional regression or learning problems to increase the confidence of a given predictor. We develop a new data-driven approach for UQ in regression that applies both to classical regression approaches such as the LASSO as well as to neural networks. One of the most notable UQ techniques is the debiased LASSO, which modifies the LASSO to allow for the construction of asymptotic confidence intervals by decomposing the estimation error into a Gaussian and an asymptotically vanishing bias component. However, in real-world problems with finite-dimensional data, the bias term is often too significant to be neglected, resulting in overly narrow confidence intervals. Our work rigorously addresses this issue and derives a data-driven adjustment that corrects the confidence intervals for a large class of predictors by estimating the means and variances of the bias terms from training data, exploiting high-dimensional concentration phenomena. This gives rise to non-asymptotic confidence intervals, which can help avoid overestimating uncertainty in critical applications such as MRI diagnosis. Importantly, our analysis extends beyond sparse regression to data-driven predictors like neural networks, enhancing the reliability of model-based deep learning. Our findings bridge the gap between established theory and the practical applicability of such debiased methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13666v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.IV</category>
      <category>math.IT</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Frederik Hoppe, Claudio Mayrink Verdun, Hannah Laus, Felix Krahmer, Holger Rauhut</dc:creator>
    </item>
    <item>
      <title>Quasi-Fractal UCA Based N-Dimensional OAM Orthogonal Transmission</title>
      <link>https://arxiv.org/abs/2407.13683</link>
      <description>arXiv:2407.13683v1 Announce Type: cross 
Abstract: The vortex electromagnetic wave carried by multiple orthogonal orbital angular momentum (OAM) modes in the same frequency band can be applied to the field of wireless communications, which greatly increases the spectrum efficiency. The uniform circular array (UCA) structure is widely used to generate or receive vortex electromagnetic waves with multiple OAM-modes. However, the maximum number of orthogonal OAM-modes based on UCA is usually limited to the number of array-elements of the UCA antenna, leaving how to utilize more OAM-modes to achieve higher spectrum efficiency given a fixed number of array-elements as an intriguing question. In this paper, we propose an Ndimensional quasi-fractal UCA (ND QF-UCA) antenna structure in different fractal geometry layouts to break through the limits of array-elements number on OAM-modes number. We develop the N-dimensional OAM modulation (NOM) and demodulation (NOD) schemes for OAM multiplexing transmission with the OAM-modes number exceeding the array-elements number, which is beyond the traditional concept of multiple antenna based wireless communications. Then, we investigate different dimensional multiplex transmission schemes based on the corresponding QF-UCA antenna structure with various array-elements layouts. Simulation results show that our proposed schemes can obtain a higher spectrum efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13683v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyun Jin, Wenchi Cheng, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Barycentric bounds on the error exponents of quantum hypothesis exclusion</title>
      <link>https://arxiv.org/abs/2407.13728</link>
      <description>arXiv:2407.13728v1 Announce Type: cross 
Abstract: Quantum state exclusion is an operational task that has significance in studying foundational questions related to interpreting quantum theory. In such a task, one is given a system whose state is randomly selected from a finite set, and the goal is to identify a state from the set that is not the true state of the system. An error, i.e., an unsuccessful exclusion, occurs if and only if the state identified is the true state. In this paper, we study the optimal error probability of quantum state exclusion and its error exponent -- the rate at which the error probability decays asymptotically -- from an information-theoretic perspective. Our main finding is a single-letter upper bound on the error exponent of state exclusion given by the multivariate log-Euclidean Chernoff divergence, and we prove that this improves upon the best previously known upper bound. We also extend our analysis to the more complicated task of quantum channel exclusion, and we establish a single-letter and efficiently computable upper bound on its error exponent, even assuming the use of adaptive strategies. We derive both upper bounds, for state and channel exclusion, based on one-shot analysis and formulate them as a type of multivariate divergence measure called a barycentric Chernoff divergence. Moreover, our result on channel exclusion has implications in two important special cases. First, for the special case of two hypotheses, our upper bound provides the first known efficiently computable upper bound on the error exponent of symmetric binary channel discrimination. Second, for the special case of classical channels, we show that our upper bound is achievable by a nonadaptive strategy, thus solving the exact error exponent of classical channel exclusion and generalising a similar result on symmetric binary classical channel discrimination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13728v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiyuan Ji, Hemant K. Mishra, Mil\'an Mosonyi, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>Permutation Entropy for Signal Analysis</title>
      <link>https://arxiv.org/abs/2312.00964</link>
      <description>arXiv:2312.00964v3 Announce Type: replace 
Abstract: Shannon Entropy is the preeminent tool for measuring the level of uncertainty (and conversely, information content) in a random variable. In the field of communications, entropy can be used to express the information content of given signals (represented as time series) by considering random variables which sample from specified subsequences. In this paper, we will discuss how an entropy variant, the \textit{permutation entropy} can be used to study and classify radio frequency signals in a noisy environment. The permutation entropy is the entropy of the random variable which samples occurrences of permutation patterns from time series given a fixed window length, making it a function of the distribution of permutation patterns. Since the permutation entropy is a function of the relative order of data, it is (global) amplitude agnostic and thus allows for comparison between signals at different scales. This article is intended to describe a permutation patterns approach to a data driven problem in radio frequency communications research, and includes a primer on all non-permutation pattern specific background. An empirical analysis of the methods herein on radio frequency data is included. No prior knowledge of signals analysis is assumed, and permutation pattern specific notation will be included. This article serves as a self-contained introduction to the relationship between permutation patterns, entropy, and signals analysis for studying radio frequency signals and includes results on a classification task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.00964v3</guid>
      <category>cs.IT</category>
      <category>cs.DM</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bill Kay, Audun Myers, Thad Boydston, Emily Ellwein, Cameron Mackenzie, Iliana Alvarez, Erik Lentz</dc:creator>
    </item>
    <item>
      <title>Tighter Lower Bounds on Aperiodic Ambiguity Function and Their Asymptotic Achievability</title>
      <link>https://arxiv.org/abs/2402.00455</link>
      <description>arXiv:2402.00455v2 Announce Type: replace 
Abstract: This paper presents tighter lower bounds on the maximum aperiodic ambiguity function (AF) magnitude of unimodular sequences under certain delay-Doppler low ambiguity zones (LAZ). These bounds are derived by exploiting the upper and lower bounds on the Frobenius norm of the weighted auto- and cross-AF matrices, with the introduction of two weight vectors associated with the delay and Doppler shifts, respectively. As a second major contribution, we demonstrate that our derived lower bounds are asymptotically achievable with selected Chu sequence sets by analyzing their maximum auto- and cross- AF magnitudes within certain LAZ.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00455v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lingsheng Meng, Yong Liang Guan, Yao Ge, Zilong Liu, Pingzhi Fan</dc:creator>
    </item>
    <item>
      <title>Location-Driven Beamforming for RIS-Assisted Near-Field Communications</title>
      <link>https://arxiv.org/abs/2406.02898</link>
      <description>arXiv:2406.02898v2 Announce Type: replace 
Abstract: Future wireless communications are promising to support ubiquitous connections and high data rates with cost-effective devices. Benefiting from the energy-efficient elements with low cost, reconfigurable intelligent surface (RIS) emerges as a potential solution to fulfill such demands, which has the capability to flexibly manipulate the wireless signals with a tunable phase. Recently, as the operational frequency ascends to the sub-terahertz (THz) bands or higher bands for wireless communications in six-generation (6G), it becomes imperative to consider the near-field propagation in RIS-assisted communications. The challenging acquisition of channel parameters is an inherent issue for near-field RIS-assisted communications, where the complex design is essential to acquire the informative near-field channel embedded with both the angle and distance information. Hence, in this paper we systematically investigate the potential of exploiting location information for near-field RIS-assisted communications. Firstly, we present the progresses in the near-field RIS-assisted communications, which are compatible with existing wireless communications and show the potential to achieve the fine-grained localization accuracy to support location-driven scheme. Then, the Fresnel zone based model is introduced, with which the location-driven beamforming scheme and corresponding frame structure are developed. Also, we elaborate on four unique advantages for leveraging location information in RIS-assisted communications, followed by numerical simulations. Finally, several key challenges and corresponding potential solutions are pointed out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02898v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Zheng, Wenchi Cheng, Jingqing Wang, Wei Zhang</dc:creator>
    </item>
    <item>
      <title>Multi-Active-IRS-Assisted Cooperative Sensing: Cram\'{e}r-Rao Bound and Joint Beamforming Design</title>
      <link>https://arxiv.org/abs/2406.12426</link>
      <description>arXiv:2406.12426v2 Announce Type: replace 
Abstract: This paper studies the multi-intelligent reflecting surface (IRS)-assisted cooperative sensing, in which multiple active IRSs are deployed in a distributed manner to facilitate multi-view target sensing at the non-line-of-sight (NLoS) area of the base station (BS). Different from prior works employing passive IRSs, we leverage active IRSs with the capability of amplifying the reflected signals to overcome the severe multi-hop-reflection path loss in NLoS sensing. In particular, we consider two sensing setups without and with dedicated sensors equipped at active IRSs. In the first case without dedicated sensors at IRSs, we investigate the cooperative sensing at the BS, where the target's direction-of-arrival (DoA) with respect to each IRS is estimated based on the echo signals received at the BS. In the other case with dedicated sensors at IRSs, we consider that each IRS is able to receive echo signals and estimate the target's DoA with respect to itself. For both sensing setups, we first derive the closed-form Cram\'{e}r-Rao bound (CRB) for estimating target DoA. Then, the (maximum) CRB is minimized by jointly optimizing the transmit beamforming at the BS and the reflective beamforming at the multiple IRSs, subject to the constraints on the maximum transmit power at the BS, as well as the maximum amplification power and the maximum power amplification gain constraints at individual active IRSs. To tackle the resulting highly non-convex (max-)CRB minimization problems, we propose two efficient algorithms to obtain high-quality solutions for the two cases with sensing at the BS and at the IRSs, respectively, based on alternating optimization, successive convex approximation, and semi-definite relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12426v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Fang, Xianghao Yu, Jie Xu, Ying-Jun Angela Zhang</dc:creator>
    </item>
    <item>
      <title>Classical product code constructions for quantum Calderbank-Shor-Steane codes</title>
      <link>https://arxiv.org/abs/2209.13474</link>
      <description>arXiv:2209.13474v2 Announce Type: replace-cross 
Abstract: Several notions of code products are known in quantum error correction, such as hyper-graph products, homological products, lifted products, balanced products, to name a few. In this paper we introduce a new product code construction which is a natural generalisation of classical product codes to quantum codes: starting from a set of component Calderbank-Shor-Steane (CSS) codes, a larger CSS code is obtained where both $X$ parity checks and $Z$ parity checks are associated to classical product codes. We deduce several properties of product CSS codes from the properties of the component codes, including bounds to the code distance, and show that built-in redundancies in the parity checks result in so-called meta-checks which can be exploited to correct syndrome read-out errors. We then specialise to the case of single-parity-check (SPC) product codes which in the classical domain are a common choice for constructing product codes. Logical error rate simulations of a SPC $3$-fold product CSS code having parameters $[[512,174,8]]$ are shown under both a maximum likelihood decoder for the erasure channel and belief propagation decoding for depolarising noise. We compare the results with other codes of comparable length and dimension, including a code from the family of asymptotically good Tanner codes. We observe that our reference product CSS code outperforms all the other examined codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13474v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimiter Ostrev, Davide Orsucci, Francisco L\'azaro, Balazs Matuz</dc:creator>
    </item>
    <item>
      <title>Private Mean Estimation with Person-Level Differential Privacy</title>
      <link>https://arxiv.org/abs/2405.20405</link>
      <description>arXiv:2405.20405v2 Announce Type: replace-cross 
Abstract: We study person-level differentially private (DP) mean estimation in the case where each person holds multiple samples. DP here requires the usual notion of distributional stability when $\textit{all}$ of a person's datapoints can be modified. Informally, if $n$ people each have $m$ samples from an unknown $d$-dimensional distribution with bounded $k$-th moments, we show that people are necessary and sufficient to estimate the mean up to distance $\alpha$ in $\ell_2$-norm under $\varepsilon$-differential privacy (and its common relaxations). In the multivariate setting, we give computationally efficient algorithms under approximate-DP and computationally inefficient algorithms under pure DP, and our nearly matching lower bounds hold for the most permissive case of approximate DP. Our computationally efficient estimators are based on the standard clip-and-noise framework, but the analysis for our setting requires both new algorithmic techniques and new analyses. In particular, our new bounds on the tails of sums of independent, vector-valued, bounded-moments random variables may be of interest.
  \[n = \tilde \Theta\left(\frac{d}{\alpha^2 m} + \frac{d}{\alpha m^{1/2} \varepsilon} + \frac{d}{\alpha^{k/(k-1)} m \varepsilon} + \frac{d}{\varepsilon}\right)\]</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20405v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushant Agarwal, Gautam Kamath, Mahbod Majid, Argyris Mouzakis, Rose Silver, Jonathan Ullman</dc:creator>
    </item>
  </channel>
</rss>
