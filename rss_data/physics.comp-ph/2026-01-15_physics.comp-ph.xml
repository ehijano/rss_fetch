<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 02:43:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An $O(\log N)$ Monte Carlo method for periodic Coulomb systems</title>
      <link>https://arxiv.org/abs/2601.09288</link>
      <description>arXiv:2601.09288v1 Announce Type: new 
Abstract: Efficient Monte Carlo (MC) sampling of many-body systems with long-range electrostatics is often limited by the cost of per-move energy-difference evaluation under periodic boundary conditions. We present DMK-MC, an accelerated MC method that adapts the dual-space multilevel kernel-splitting (DMK) framework to single-particle Metropolis updates. DMK-MC computes the energy change and, upon acceptance, updates the stored incoming plane-wave fields with $O(1)$ work per tree level, yielding an overall $O(\log N)$ expected work per trial move for fixed accuracy. The method decomposes the Coulomb kernel into three components: a global, periodized smooth part; a multilevel sequence of smooth difference kernels whose interactions are restricted to same-level colleague boxes; and a singular residual kernel whose short-range interactions are evaluated directly. Benchmarks on uniform, highly nonuniform, and implicit-solvent electrolyte and colloidal configurations show that DMK-MC consistently outperforms a recent FMM-based $O(\log N)$ Monte Carlo method, delivering several-fold speedups at comparable tolerances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09288v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuanzhao Gao, Shidong Jiang, Jiuyang Liang, Qi Zhou</dc:creator>
    </item>
    <item>
      <title>Divergent Fluctuations from an Infrared 2D-Mode Catastrophe</title>
      <link>https://arxiv.org/abs/2601.09009</link>
      <description>arXiv:2601.09009v1 Announce Type: cross 
Abstract: Molecular simulations of interfacial polar media routinely employ periodic boundary conditions parallel to the interface. We show that this geometry injects a uniform plane mode ($q_{\parallel}=0$) that converts the plane-averaged electrostatic potential into a cumulative sum of plane-dipole increments, a random walk in $z$. Consequently, the variance of the plane-averaged potential grows linearly with depth in semi-infinite slabs and follows a parabolic Brownian-bridge profile in finite cells with both ends fixed, with an amplitude inversely proportional to the cell's lateral area. Hence, at any finite area, the variance diverges with slab thickness, a 2D-mode catastrophe. In contrast, a pure 1D chain (no lateral replication) and a fully 3D, nonperiodic medium both exhibit bounded fluctuations that saturate with distance. The mechanism is generic to any solver of Poisson's equation with 2D periodicity, so the apparent growth and ultimate divergence in potential fluctuation are artifacts of boundary conditions rather than material response, and we provide a simple scaling criterion for choosing slab sizes that keeps these artifacts under quantitative control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09009v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard G. Hennig, Clotilde S. Cucinotta</dc:creator>
    </item>
    <item>
      <title>Discrete Solution Operator Learning for Geometry-Dependent PDEs</title>
      <link>https://arxiv.org/abs/2601.09143</link>
      <description>arXiv:2601.09143v2 Announce Type: cross 
Abstract: Neural operator learning accelerates PDE solution by approximating operators as mappings between continuous function spaces. Yet in many engineering settings, varying geometry induces discrete structural changes, including topological changes, abrupt changes in boundary conditions or boundary types, and changes in the computational domain, which break the smooth-variation premise. Here we introduce Discrete Solution Operator Learning (DiSOL), a complementary paradigm that learns discrete solution procedures rather than continuous function-space operators. DiSOL factorizes the solver into learnable stages that mirror classical discretizations: local contribution encoding, multiscale assembly, and implicit solution reconstruction on an embedded grid, thereby preserving procedure-level consistency while adapting to geometry-dependent discrete structures. Across geometry-dependent Poisson, advection-diffusion, linear elasticity, as well as spatiotemporal heat conduction problems, DiSOL produces stable and accurate predictions under both in-distribution and strongly out-of-distribution geometries, including discontinuous boundaries and topological changes. These results highlight the need for procedural operator representations in geometry-dominated problems and position discrete solution operator learning as a distinct, complementary direction in scientific machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09143v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinshuai Bai, Haolin Li, Zahra Sharif Khodaei, M. H. Aliabadi, YuanTong Gu, Xi-Qiao Feng</dc:creator>
    </item>
    <item>
      <title>Great Restraining Wall in Multidimensional Collective Variable Space</title>
      <link>https://arxiv.org/abs/2506.17043</link>
      <description>arXiv:2506.17043v3 Announce Type: replace 
Abstract: Enhanced sampling methods are pivotal for exploring rare events in molecular dynamics (MD), yet face challenges in high-dimensional collective variable (CV) spaces where exhaustive sampling becomes computationally prohibitive. While techniques like metadynamics (MetaD) and path-CV enable targeted free energy surface (FES) reconstruction, they often struggle with confinement stability, hyperparameter sensitivity, and geometric flexibility. This work introduces the Great Restraining Wall (GW) method, a robust framework for efficient FES sampling within predefined CV subspaces, addressing these limitations through a novel kernel density estimation (KDE)-derived restraining potential. GW operates by constructing a bias potential that confines sampling to user defined regions ranging from multidimensional masks to 1D pathways via asymptotically half-harmonic barriers. Unlike MetaD variants requiring iterative bias deposition, GW potential is derived from a cumulative distribution function, ensuring confinement without manual hyperparameter tuning. GW provides a versatile, stable, and efficient framework for targeted FES sampling, particularly beneficial for complex biomolecular systems with intricate CV landscapes. Its integration with existing enhanced sampling protocols opens avenues for studying ligand binding, conformational transitions, and other rare events with unprecedented precision. Future work will explore GW extension to adaptive regions and machine learning-guided CV discovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17043v3</guid>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhijun Pan, Maodong Li, Dechin Chen, Yi Isaac Yang</dc:creator>
    </item>
    <item>
      <title>DDNet: A Unified Physics-Informed Deep Learning Framework for Semiconductor Device Modeling</title>
      <link>https://arxiv.org/abs/2509.08073</link>
      <description>arXiv:2509.08073v2 Announce Type: replace 
Abstract: The accurate modeling of semiconductor devices plays a critical role in the development of new technology nodes and next-generation devices. Semiconductor device designers largely rely on advanced simulation software to solve the drift-diffusion equations, a coupled system of nonlinear partial differential equations that describe carrier transport in semiconductor devices. While these tools perform well for forward modeling, they are not suitable to address inverse problems, for example, determining doping profiles, material, and geometrical parameters given a desired device performance. Meanwhile, physics-informed neural networks (PINNs) have grown in popularity in recent years thanks to their ability to efficiently and accurately solve inverse problems at minimal computational cost compared to forward problems. In this study, we introduce the Drift-Diffusion Network (DDNet), a unified physics-informed deep learning solver for the forward and inverse mesh-free solutions of the drift-diffusion equations of semiconductor device modeling. Using prototypical device configurations in one- and two spatial dimensions, we show that DDNet achieves low absolute and relative error compared to traditional simulation software while additionally solving user-defined inverse problems with minimal computational overhead. We expect that DDNet will benefit semiconductor device modeling by facilitating exploration and discovery of novel device structures across comprehensive parameter sets in a fully automated way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08073v2</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.dis-nn</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Riganti, Matteo G. C. Alasio, Enrico Bellotti, Luca Dal Negro</dc:creator>
    </item>
    <item>
      <title>Consistent Sampling and Simulation: Molecular Dynamics with Energy-Based Diffusion Models</title>
      <link>https://arxiv.org/abs/2506.17139</link>
      <description>arXiv:2506.17139v3 Announce Type: replace-cross 
Abstract: In recent years, diffusion models trained on equilibrium molecular distributions have proven effective for sampling biomolecules. Beyond direct sampling, the score of such a model can also be used to derive the forces that act on molecular systems. However, while classical diffusion sampling usually recovers the training distribution, the corresponding energy-based interpretation of the learned score is often inconsistent with this distribution, even for low-dimensional toy systems. We trace this inconsistency to inaccuracies of the learned score at very small diffusion timesteps, where the model must capture the correct evolution of the data distribution. In this regime, diffusion models fail to satisfy the Fokker-Planck equation, which governs the evolution of the score. We interpret this deviation as one source of the observed inconsistencies and propose an energy-based diffusion model with a Fokker-Planck-derived regularization term to enforce consistency. We demonstrate our approach by sampling and simulating multiple biomolecular systems, including fast-folding proteins, and by introducing a state-of-the-art transferable Boltzmann emulator for dipeptides that supports simulation and achieves improved consistency and efficient sampling. Our code, model weights, and self-contained JAX and PyTorch notebooks are available at https://github.com/noegroup/ScoreMD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17139v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Plainer, Hao Wu, Leon Klein, Stephan G\"unnemann, Frank No\'e</dc:creator>
    </item>
    <item>
      <title>Simulating acoustically-actuated flows in complex microchannels using the volume penalization technique</title>
      <link>https://arxiv.org/abs/2506.20034</link>
      <description>arXiv:2506.20034v2 Announce Type: replace-cross 
Abstract: We present a volume penalization technique for simulating acoustically-actuated flows in geometrically complex microchannels. Using a perturbation approach, the nonlinear response of an acoustically-actuated compressible Newtonian fluid moving over obstacles or flowing in a geometrically complex domain is segregated into two sub-problems: a harmonic first-order problem and a time-averaged second-order problem, where the latter utilizes forcing terms and boundary conditions arising from the first-order solution. This segregation results in two distinct volume penalized systems of equations. The no-slip boundary condition at the fluid-solid interface is enforced by prescribing a zero structure velocity for the first-order problem, while spatially varying Stokes drift -- which depends on the gradient of the first-order solution -- is prescribed as the structure velocity for the second-order problem. The harmonic first-order system is solved via MUMPS direct solver, whereas the steady state second-order system is solved iteratively using a novel projection method-based preconditioner. The preconditioned iterative solver for the second-order system is demonstrated to be highly effective and scalable with respect to increasing penalty force and grid resolution, respectively. A novel contour integration technique to evaluate the acoustic radiation force on an immersed object is also proposed. Through test cases featuring representative microfluidic geometries, we demonstrate excellent agreement between the volume penalized and body-fitted grid. We also identify suitable penalty factors and interfacial smearing widths to accurately capture the first- and second-order solutions. These results provide first-of-its-kind empirical evidence of the efficacy of the volume penalization method for simulating acoustic streaming problems that have so far been analyzed using body-fitted methods in literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20034v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khemraj Gautam Kshetri, Amneet Pal Singh Bhalla, Nitesh Nama</dc:creator>
    </item>
    <item>
      <title>Super-resolution reconstruction of turbulent flows from a single Lagrangian trajectory</title>
      <link>https://arxiv.org/abs/2509.17109</link>
      <description>arXiv:2509.17109v2 Announce Type: replace-cross 
Abstract: We studied the reconstruction of turbulent flow fields from trajectory data recorded by actively migrating Lagrangian agents. We propose a deep-learning model, track-to-flow (T2F), which employs a vision transformer as the encoder to capture the spatiotemporal features of a single agent trajectory, and a convolutional neural network as the decoder to reconstruct the flow field. To enhance the physical consistency of the T2F model, we further incorporate a physics-informed loss function inspired by the framework of physics-informed neural network (PINN), yielding a variant model referred to as T2F+PINN. We first evaluate both models in a laminar cylinder wake flow at a Reynolds number of $Re = 800$ as a proof of concept. The results show that the T2F model achieves velocity reconstruction accuracy comparable to that of existing flow reconstruction methods, while the T2F+PINN model reduces the normalised error in vorticity reconstruction relative to the T2F model. We then apply the models in a turbulent Rayleigh-B\'enard convection at a Rayleigh number of $Ra = 10^8$ and a Prandtl number of $Pr = 0.71$. The results show that the T2F model accurately reconstructs both the velocity and temperature fields, whereas the T2F+PINN model further improves the reconstruction accuracy of gradient-related physical quantities, such as temperature gradients, vorticity and the Q value, with a maximum improvement of approximately 60 % compared to the T2F model. Overall, the T2F model is better suited for reconstructing primitive flow variables, while the T2F+PINN model provides advantages in reconstructing gradient-related quantities. Our models open a promising avenue for accurate flow reconstruction from a single Lagrangian trajectory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17109v2</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/jfm.2025.11033</arxiv:DOI>
      <arxiv:journal_reference>Journal of Fluid Mechanics 2026, 1026, A46</arxiv:journal_reference>
      <dc:creator>Hua-Lin Wu, Ao Xu, Heng-Dong Xi</dc:creator>
    </item>
    <item>
      <title>Loading non-Maxwellian Velocity Distributions in Particle Simulations</title>
      <link>https://arxiv.org/abs/2510.11890</link>
      <description>arXiv:2510.11890v2 Announce Type: replace-cross 
Abstract: Numerical procedures for generating non-Maxwellian velocity distributions in particle simulations are presented. First, Monte Carlo methods for an $(r,q)$ distribution that generalizes flattop and kappa distributions are discussed. Then, two rejection methods for the regularized kappa distribution are presented, followed by a comparison in the $\kappa$ space. A simple recipe is proposed for the subtracted kappa distribution. Properties and numerical recipes for the ring and shell distributions with a finite Gaussian width are discussed. The ring and shell Maxwellians are further introduced as alternatives to the ring and shell distributions. Finally, methods for the super-Gaussian and the filled-shell distributions are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11890v2</guid>
      <category>physics.plasm-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.space-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seiji Zenitani, Shunsuke Usami, Shuichi Matsukiyo</dc:creator>
    </item>
    <item>
      <title>Learning About Learning: A Physics Path from Spin Glasses to Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2601.07635</link>
      <description>arXiv:2601.07635v2 Announce Type: replace-cross 
Abstract: The Hopfield model, originally inspired by spin-glass physics, occupies a central place at the intersection of statistical mechanics, neural networks, and modern artificial intelligence. Despite its conceptual simplicity and broad applicability -- from associative memory to near-optimal solutions of combinatorial optimization problems -- it is rarely integrated into standard undergraduate physics curricula. In this paper, we present the Hopfield model as a pedagogically rich framework that naturally unifies core topics from undergraduate statistical physics, dynamical systems, linear algebra, and computational methods. We provide a concise and illustrated theoretical introduction grounded in familiar physics concepts, analyze the model's energy function, dynamics, and pattern stability, and discuss practical aspects of simulation, including a freely available simulation code. To support instruction, we conclude with classroom-ready example problems designed to mirror research practice. By explicitly connecting fundamental physics to contemporary AI applications, this work aims to help prepare physics students to understand, apply, and critically engage with the computational tools increasingly central to research, industry, and society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07635v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <category>physics.ed-ph</category>
      <pubDate>Thu, 15 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denis D. Caprioti, Matheus Haas, Constantino F. Vasconcelos, Mauricio Girardi-Schappo</dc:creator>
    </item>
  </channel>
</rss>
