<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 05 Apr 2024 04:00:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 05 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Equivalence and Similarity Refutation for Probabilistic Programs</title>
      <link>https://arxiv.org/abs/2404.03430</link>
      <description>arXiv:2404.03430v1 Announce Type: new 
Abstract: We consider the problems of statically refuting equivalence and similarity of output distributions defined by a pair of probabilistic programs. Equivalence and similarity are two fundamental relational properties of probabilistic programs that are essential for their correctness both in implementation and in compilation. In this work, we present a new method for static equivalence and similarity refutation. Our method refutes equivalence and similarity by computing a function over program outputs whose expected value with respect to the output distributions of two programs is different. The function is computed simultaneously with an upper expectation supermartingale and a lower expectation submartingale for the two programs, which we show to together provide a formal certificate for refuting equivalence and similarity. To the best of our knowledge, our method is the first approach to relational program analysis to offer the combination of the following desirable features: (1) it is fully automated, (2) it is applicable to infinite-state probabilistic programs, and (3) it provides formal guarantees on the correctness of its results. We implement a prototype of our method and our experiments demonstrate the effectiveness of our method to refute equivalence and similarity for a number of examples collected from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03430v1</guid>
      <category>cs.PL</category>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krishnendu Chatterjee, Ehsan Kafshdar Goharshady, Petr Novotn\'y, {\DJ}or{\dj}e \v{Z}ikeli\'c</dc:creator>
    </item>
    <item>
      <title>Towards Trustworthy Automated Program Verifiers: Formally Validating Translations into an Intermediate Verification Language (extended version)</title>
      <link>https://arxiv.org/abs/2404.03614</link>
      <description>arXiv:2404.03614v1 Announce Type: new 
Abstract: Automated program verifiers are typically implemented using an intermediate verification language (IVL), such as Boogie or Why3. A verifier front-end translates the input program and specification into an IVL program, while the back-end generates proof obligations for the IVL program and employs an SMT solver to discharge them. Soundness of such verifiers therefore requires that the front-end translation faithfully captures the semantics of the input program and specification in the IVL program, and that the back-end reports success only if the IVL program is actually correct. For a verification tool to be trustworthy, these soundness conditions must be satisfied by its actual implementation, not just the program logic it uses.
  In this paper, we present a novel validation methodology that, given a formal semantics for the input language and IVL, provides formal soundness guarantees for front-end implementations. For each run of the verifier, we automatically generate a proof in Isabelle showing that the correctness of the produced IVL program implies the correctness of the input program. This proof can be checked independently from the verifier in Isabelle and can be combined with existing work on validating back-ends to obtain an end-to-end soundness result. Our methodology based on forward simulation employs several modularisation strategies to handle the large semantic gap between the input language and the IVL, as well as the intricacies of practical, optimised translations. We present our methodology for the widely-used Viper and Boogie languages. Our evaluation shows that it is effective in validating the translations performed by the existing Viper implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03614v1</guid>
      <category>cs.PL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gaurav Parthasarathy, Thibault Dardinier, Benjamin Bonneau, Peter M\"uller, Alexander J. Summers</dc:creator>
    </item>
    <item>
      <title>Amortized Analysis via Coalgebra</title>
      <link>https://arxiv.org/abs/2404.03641</link>
      <description>arXiv:2404.03641v1 Announce Type: new 
Abstract: Amortized analysis is a cost analysis technique for data structures in which cost is studied in aggregate, rather than considering the maximum cost of a single operation. Traditionally, amortized analysis has been phrased inductively, in terms of finite sequences of operations. Connecting to prior work on coalgebraic semantics for data structures, we develop the perspective that amortized analysis is naturally viewed coalgebraically in the category of algebras for a cost monad, where a morphism of coalgebras serves as a first-class generalization of potential function suitable for integrating cost and behavior. Using this simple definition, we consider amortization of other effects, such as randomization, and we compose amortization arguments in the indexed category of coalgebras. We generalize this to parallel data structure usage patterns by using coalgebras for an endoprofunctor instead of an endofunctor, combining potential using a monoidal structure on the underlying category. Finally, we adapt our discussion to the bicategorical setting, supporting imprecise amortized upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03641v1</guid>
      <category>cs.PL</category>
      <category>cs.DS</category>
      <category>math.CT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harrison Grodin, Robert Harper</dc:creator>
    </item>
    <item>
      <title>Multi-modal Learning for WebAssembly Reverse Engineering</title>
      <link>https://arxiv.org/abs/2404.03171</link>
      <description>arXiv:2404.03171v1 Announce Type: cross 
Abstract: The increasing adoption of WebAssembly (Wasm) for performance-critical and security-sensitive tasks drives the demand for WebAssembly program comprehension and reverse engineering. Recent studies have introduced machine learning (ML)-based WebAssembly reverse engineering tools. Yet, the generalization of task-specific ML solutions remains challenging, because their effectiveness hinges on the availability of an ample supply of high-quality task-specific labeled data. Moreover, previous works overlook the high-level semantics present in source code and its documentation. Acknowledging the abundance of available source code with documentation, which can be compiled into WebAssembly, we propose to learn representations of them concurrently and harness their mutual relationships for effective WebAssembly reverse engineering.
  In this paper, we present WasmRev, the first multi-modal pre-trained language model for WebAssembly reverse engineering. WasmRev is pre-trained using self-supervised learning on a large-scale multi-modal corpus encompassing source code, code documentation and the compiled WebAssembly, without requiring labeled data. WasmRev incorporates three tailored multi-modal pre-training tasks to capture various characteristics of WebAssembly and cross-modal relationships. WasmRev is only trained once to produce general-purpose representations that can broadly support WebAssembly reverse engineering tasks through few-shot fine-tuning with much less labeled data, improving data efficiency. We fine-tune WasmRev onto three important reverse engineering tasks: type recovery, function purpose identification and WebAssembly summarization. Our results show that WasmRev pre-trained on the corpus of multi-modal samples establishes a robust foundation for these tasks, achieving high task accuracy and outperforming the state-of-the-art ML methods for WebAssembly reverse engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03171v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3650212.3652141</arxiv:DOI>
      <dc:creator>Hanxian Huang, Jishen Zhao</dc:creator>
    </item>
    <item>
      <title>Model Checking Recursive Probabilistic Programs with Conditioning</title>
      <link>https://arxiv.org/abs/2404.03515</link>
      <description>arXiv:2404.03515v1 Announce Type: cross 
Abstract: We address the problem of model checking temporal logic specifications for probabilistic programs with recursive procedures, nested queries, and conditioning expressed with observe statements. We introduce probabilistic Operator Precedence Automata (pOPA), a new class of probabilistic pushdown automata suitable to model constructs and behaviors of probabilistic programs. We develop a model checking algorithm that can verify requirements expressed in a fragment of Precedence Oriented Temporal Logic (POTL$^f_\mathcal{X}$) on a pOPA in single EXPTIME. POTL$^f_\mathcal{X}$ is a temporal logic based on Operator Precedence Languages, which features modalities that interact with the context-free structure of program traces, matching procedure calls with returns or observe statements. We provide the first probabilistic model checking implementation of context-free language properties for probabilistic pushdown systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03515v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Pontiggia, Ezio Bartocci, Michele Chiari</dc:creator>
    </item>
    <item>
      <title>L2MAC: Large Language Model Automatic Computer for Extensive Code Generation</title>
      <link>https://arxiv.org/abs/2310.02003</link>
      <description>arXiv:2310.02003v4 Announce Type: replace-cross 
Abstract: Transformer-based large language models (LLMs) are constrained by the fixed context window of the underlying transformer architecture, hindering their ability to produce long and coherent outputs. Memory-augmented LLMs are a promising solution, but current approaches cannot handle long output generation tasks since they (1) only focus on reading memory and reduce its evolution to the concatenation of new memories or (2) use very specialized memories that cannot adapt to other domains. This paper presents L2MAC, the first practical LLM-based stored-program automatic computer (von Neumann architecture) framework, an LLM-based multi-agent system, for long and consistent output generation. Its memory has two components: the instruction registry, which is populated with a prompt program to solve the user-given task, and a file store, which will contain the final and intermediate outputs. Each instruction in turn is executed by a separate LLM agent, whose context is managed by a control unit capable of precise memory reading and writing to ensure effective interaction with the file store. These components enable L2MAC to generate extensive outputs, bypassing the constraints of the finite context window while producing outputs that fulfill a complex user-specified task. We empirically demonstrate that L2MAC achieves state-of-the-art performance in generating large codebases for system design tasks, significantly outperforming other coding methods in implementing the detailed user-specified task, and we provide valuable insights into the reasons for this performance gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02003v4</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Holt, Max Ruiz Luyten, Mihaela van der Schaar</dc:creator>
    </item>
  </channel>
</rss>
