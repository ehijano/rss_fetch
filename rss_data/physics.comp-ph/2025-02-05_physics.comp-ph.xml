<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Feb 2025 05:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Tadah! A Swiss Army Knife for Developing and Deployment of Machine Learning Interatomic Potentials</title>
      <link>https://arxiv.org/abs/2502.02211</link>
      <description>arXiv:2502.02211v1 Announce Type: new 
Abstract: The Tadah! code provides a versatile platform for developing and optimizing Machine Learning Interatomic Potentials (MLIPs). By integrating composite descriptors, it allows for a nuanced representation of system interactions, customized with unique cutoff functions and interaction distances. Tadah! supports Bayesian Linear Regression (BLR) and Kernel Ridge Regression (KRR) to enhance model accuracy and uncertainty management. A key feature is its hyperparameter optimization cycle, iteratively refining model architecture to improve transferability. This approach incorporates performance constraints, aligning predictions with experimental and theoretical data. Tadah! provides an interface for LAMMPS, enabling the deployment of MLIPs in molecular dynamics simulations. It is designed for broad accessibility, supporting parallel computations on desktop and HPC systems. Tadah! leverages a modular C++ codebase, utilizing both compile-time and runtime polymorphism for flexibility and efficiency. Neural network support and predefined bonding schemes are potential future developments, and Tadah! remains open to community-driven feature expansion. Comprehensive documentation and command-line tools further streamline the development and application of MLIPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02211v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Kirsz, A. Daramola, A. Hermann, H. Zong, G. J. Ackland</dc:creator>
    </item>
    <item>
      <title>A cellular automata model for particle transport in disordered systems</title>
      <link>https://arxiv.org/abs/2502.02298</link>
      <description>arXiv:2502.02298v1 Announce Type: new 
Abstract: We construct a cellular automaton (CA) model that describes the movement of a particle in a disordered system. The mathematical properties of the CA model were examined by varying the configuration of grid and determining the number of percolating paths. Through this model, we were able to develop a computer simulation that shows particle transport. Under particle hopping mechanism, with or without tunneling(or backscattering), it was found out that there is an exponential behavior of percolation probability. However, the onset of the percolation probability is shifted to a smaller value when tunneling and backscattering are present.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02298v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lander Besabe, Editha Jose, Alvin Karlo Tapia</dc:creator>
    </item>
    <item>
      <title>Physics-informed neural networks for solving moving interface flow problems using the level set approach</title>
      <link>https://arxiv.org/abs/2502.02440</link>
      <description>arXiv:2502.02440v1 Announce Type: new 
Abstract: This paper advances the use of physics-informed neural networks (PINNs) architectures to address moving interface problems via the level set method. Originally developed for other PDE-based problems, we particularly leverage PirateNet's features, including causal training, sequence-to-sequence learning, random weight factorization, and Fourier feature embeddings, and tailor them to achieve superior performance in modeling interface dynamics. Numerical experiments validate this framework on benchmark problems such as Zalesak's disk rotation and time-reversed vortex flow. We demonstrate that PINNs can efficiently solve level set problems exhibiting significant interface deformation without the need for upwind numerical stabilization, as generally required by classic discretization methods. Additionally, geometric reinitialization or mass conservation schemes have been revealed as unnecessary for accurate and efficient solutions. However, incorporating an Eikonal regularization term in the loss function with an appropriate weight can further enhance results in specific scenarios. Our results indicate that PINNs with the PirateNet architecture surpass conventional PINNs in accuracy, achieving state-of-the-art error rates of $L^2=0.14\%$ for Zalesak's disk and $L^2=0.85 \%$ for the time-reversed vortex flow problem, as compared to reference solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02440v1</guid>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mathieu Mullins, Hamza Kamil, Adil Fahsi, Azzeddine Soulaimani</dc:creator>
    </item>
    <item>
      <title>Gravity-Bench-v1: A Benchmark on Gravitational Physics Discovery for Agents</title>
      <link>https://arxiv.org/abs/2501.18411</link>
      <description>arXiv:2501.18411v1 Announce Type: cross 
Abstract: Modern science emerged from reasoning over repeatedly-observed planetary motions. We present Gravity-Bench-v1, an environment-based benchmark that challenges AI agents on tasks that parallel this historical development. Gravity-Bench-v1 evaluates agents on the discovery of physics concealed within a dynamic environment, using rigorous gravitational dynamics simulations. Gravity-Bench includes out-of-distribution cases, i.e. with physics that deviates from the real world, to evaluate true scientific generalization capabilities. Agents must plan to collect data within an experimental budget and must perform a dynamic form of data analysis and reasoning to solve tasks efficiently. Our benchmark admits an open-ended space of solutions. PhD-level solutions for each task are provided, to calibrate AI performance against human expertise. Technically at an upper-undergraduate level, our benchmark proves challenging to baseline AI agents. Gravity-Bench-v1 and planned extensions should help map out AI progress towards scientific discovery capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.18411v1</guid>
      <category>cs.AI</category>
      <category>astro-ph.IM</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nolan Koblischke, Hyunseok Jang, Kristen Menou, Mohamad Ali-Dib</dc:creator>
    </item>
    <item>
      <title>Enhancing the Computational Efficiency of the DoNOF Program through a New Orbital Sorting Scheme</title>
      <link>https://arxiv.org/abs/2502.01786</link>
      <description>arXiv:2502.01786v1 Announce Type: cross 
Abstract: This work presents a novel approach to distribute orbitals into subspaces within electron-pairing-based natural orbital functionals (NOFs). This approach modifies the coupling between weakly and strongly occupied orbitals by applying an alternating orbital sorting strategy. In contrast to the previous orbital sorting that enforced electron pairing within subspaces of contiguous orbitals, the new approach provides greater flexibility, enabling a calculation scheme where the size of the subspaces can be gradually expanded. As a consequence, one can start using subspaces of only one weakly occupied orbital (perfect pairing) and progressively enlarge their size by incorporating more weakly occupied orbitals (extended pairing) up to the maximum size allowed by the basis set. In this way, the alternate orbital sorting allows solving first a simpler problem with small subspaces and leverage its orbital solution for the more intensive problem with larger subspaces, thereby reducing the overall computational cost and improving convergence, as we observed in the DoNOF program. The efficiency provided by the new sorting approach has been validated through benchmark calculations in H2O, H2O2, and NH3. In particular, we compared three strategies: i) solving directly the calculation with the largest subspaces (one-shot strategy), as was usually done before this work, ii) starting with perfect pairing and stepwise increasing the number of orbitals in the subspaces one by one until reaching the maximum size (incremental strategy), and iii) starting with perfect pairing and transitioning directly to the maximum subspace size (two-step strategy). Our results show that the two-step approach emerges as the most effective strategy, achieving the lowest computational cost while maintaining high accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01786v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>\'Elodie Boutou, Juan Felipe Huan Lew-Yee, Jose Maria Mercero, Mario Piris</dc:creator>
    </item>
    <item>
      <title>Machine Learning-Driven Analytical Models for Threshold Displacement Energy Prediction in Materials</title>
      <link>https://arxiv.org/abs/2502.01813</link>
      <description>arXiv:2502.01813v1 Announce Type: cross 
Abstract: Understanding the behavior of materials under irradiation is crucial for the design and safety of nuclear reactors, spacecraft, and other radiation environments. The threshold displacement energy (Ed) is a critical parameter for understanding radiation damage in materials, yet its determination often relies on costly experiments or simulations. This work leverages the machine learning-based Sure Independence Screening and Sparsifying Operator (SISSO) method to derive accurate, analytical models for predicting Ed using fundamental material properties. The models outperform traditional approaches for monoatomic materials, capturing key trends with high accuracy. While predictions for polyatomic materials highlight challenges due to dataset complexity, they reveal opportunities for improvement with expanded data. This study identifies cohesive energy and melting temperature as key factors influencing Ed, offering a robust framework for efficient, data-driven predictions of radiation damage in diverse materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01813v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rosty B. Martinez Duque, Arman Duha, Mario F. Borunda</dc:creator>
    </item>
    <item>
      <title>Meta-neural Topology Optimization: Knowledge Infusion with Meta-learning</title>
      <link>https://arxiv.org/abs/2502.01830</link>
      <description>arXiv:2502.01830v1 Announce Type: cross 
Abstract: Engineers learn from every design they create, building intuition that helps them quickly identify promising solutions for new problems. Topology optimization (TO) - a well-established computational method for designing structures with optimized performance - lacks this ability to learn from experience. Existing approaches treat design tasks in isolation, starting from a "blank canvas" design for each new problem, often requiring many computationally expensive steps to converge. We propose a meta-learning strategy, termed meta-neural TO, that finds effective initial designs through a systematic transfer of knowledge between related tasks, building on the mesh-agnostic representation provided by neural reparameterization. We compare our approach against established TO methods, demonstrating efficient optimization across diverse test cases without compromising design quality. Further, we demonstrate powerful cross-resolution transfer capabilities, where initializations learned on lower-resolution discretizations lead to superior convergence in 74.1% of tasks on a higher-resolution test set, reducing the average number of iterations by 33.6% compared to standard neural TO. Remarkably, we discover that meta-learning naturally gravitates toward the strain energy patterns found in uniform density designs as effective starting points, aligning with engineering intuition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01830v1</guid>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Igor Kuszczak, Gawel Kus, Federico Bosi, Miguel A. Bessa</dc:creator>
    </item>
    <item>
      <title>Development and validation of a high-fidelity full-spectrum Monte Carlo model for the Swiss airborne gamma-ray spectrometry system</title>
      <link>https://arxiv.org/abs/2502.02102</link>
      <description>arXiv:2502.02102v1 Announce Type: cross 
Abstract: Airborne Gamma-Ray Spectrometry (AGRS) is a critical tool for radiological emergency response, enabling the rapid identification and quantification of hazardous terrestrial radionuclides over large areas. However, existing calibration methods are inherently limited to only a few gamma-ray sources, excluding most gamma-ray emitting radionuclides released in severe nuclear accidents and nuclear weapon detonations, which in turn compromise effective response and accurate risk assessments in such incidents. Here, we present a high-fidelity Monte Carlo model that overcomes these limitations, offering full-spectrum calibration of any gamma-ray source. Unlike previous approaches, our model integrates a detailed mass model of the entire aircraft and a calibrated non-proportional scintillation model, enabling accurate event-by-event prediction of the spectrometer's scintillation response to arbitrarily complex gamma-ray fields. Through a series of validation measurements in near-, mid-, and far-field scenarios, we show that the developed model not only effectively addresses the large deficiencies of previous approaches, but also achieves the accuracy and precision required to supersede traditional empirical calibration methods. These results mark a major advancement in AGRS. The developed methodology not only allows for the quantification of any gamma-ray source, but also reduces calibration time and costs, minimizes reliance on high-intensity calibration sources, and eliminates the generation of related radioactive waste. In addition, these advancements offer promising new capabilities for AGRS applications beyond emergency response, including the quantification of the cosmic-ray induced gamma-ray flux in the atmosphere and probing trace-level airborne radionuclides.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02102v1</guid>
      <category>physics.ins-det</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.geo-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Breitenmoser, Alberto Stabilini, Malgorzata Magdalena Kasprzak, Sabine Mayer</dc:creator>
    </item>
    <item>
      <title>Undamped soliton-like domain wall motion in sliding ferroelectrics</title>
      <link>https://arxiv.org/abs/2502.02137</link>
      <description>arXiv:2502.02137v1 Announce Type: cross 
Abstract: Sliding ferroelectricity, which is a unique polarity recently discovered in bilayer van der Waals materials, achieves polarization switching through in-plane interlayer sliding. The unique mechanism, combining intralayer stiffness and interlayer slipperiness, leads to wider domain walls (DWs) and faster DW motion compared to conventional ferroelectrics. Herein, using machine-learning-assisted molecular dynamics simulations and field theory analysis, we find the DW in classical sliding ferroelectric bilayer 3R-MoS2 system exhibits uniformly accelerated motion under an external field, like the Newtonian particle with undamped motion. Remarkably, DW velocity remains constant even after the external field removal, completely deviating from the velocity breakdown observed in conventional ferroelectrics. We further propose an experimental approach to validate this undamped soliton-like DW behavior in sliding ferroelectric systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02137v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubai Shi, Ri He, Hua Wang, Yuxiang Gao, Binwen Zhang, Zhicheng Zhong</dc:creator>
    </item>
    <item>
      <title>Multiscale micromagnetic / atomistic modeling of heat assisted magnetic recording</title>
      <link>https://arxiv.org/abs/2502.02236</link>
      <description>arXiv:2502.02236v1 Announce Type: cross 
Abstract: Heat-assisted magnetic recording (HAMR) is a recent advancement in magnetic recording, allowing to significantly increase the areal density capability (ADC) of hard disk drives (HDDs) compared to the perpendicular magnetic recording (PMR) technology. This is enabled by high anisotropy FePt media, which needs to be heated through its Curie temperature ($T_C$) to facilitate magnetization reversal by an electromagnetic write pole. HAMR micromagnetic modeling is therefore challenging, as it needs to be performed in proximity to and above $T_C$, where a ferromagnet has no spontaneous magnetization. An atomistic model is an optimal solution here, as it doesn't require any parameter renormalization or non-physical assumptions for modeling at any temperature. However, a full track atomistic recording model is extremely computationally expensive. Here we demonstrate a true multiscale HAMR modeling approach, combining atomistic spin dynamics modeling for high temperature regions and micromagnetic modeling for lower temperature regions, in a moving simulation window embedded within a long magnetic track. The advantages of this approach include natural emergence of $T_C$ and anisotropy distributions of FePt grains. Efficient GPU optimization of the code provides very fast running times, with a 60~nm wide track of twenty-five 20~nm - long bits being recorded in several hours on a single GPU. The effects of realistic FePt L$_{10}$ vs simple cubic crystal structure is discussed, with the latter providing further running time gains while keeping the advantages of the multiscale approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02236v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammed Gija, Alexey Dobrynin, Kevin McNeill, Mark Gubbins, Tim Mercer, Philip Bissell, Serban Lepadatu</dc:creator>
    </item>
    <item>
      <title>Burnett-level discrete Boltzmann modeling of compressible flows under force</title>
      <link>https://arxiv.org/abs/2502.02241</link>
      <description>arXiv:2502.02241v1 Announce Type: cross 
Abstract: In this paper, a Burnett-level discrete Boltzmann model (DBM) is proposed for the compressible flow in a force field, and a discrete velocity set with 25 velocities is constructed for the DBM, featuring good spatial symmetry. In the discrete Boltzmann equation, both the discrete equilibrium distribution function and the force term satisfy 25 independent moment relations and are computed with the matrix inversion method. This approach ensures high physical accuracy, computational efficiency, and ease of implementation. Through the Chapman-Enskog expansion analysis, it is demonstrated that the current DBM can recover the Burnett equations for the compressible system under force in the continuum limit. Moreover, the DBM has the capability of capturing essential thermodynamic nonequilibrium behaviors. Finally, the model is validated through five typical benchmarks, including the free falling, Sod shock tube, sound wave, thermal Couette flow, and Rayleigh-Taylor instability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02241v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suni Chen, Chuandong Lin, Demei Li, Huilin Lai</dc:creator>
    </item>
    <item>
      <title>Composition Effects on Ni/Al Reactive Multilayers: A Comprehensive Study of Mechanical Properties, Reaction Dynamics and Phase Evolution</title>
      <link>https://arxiv.org/abs/2502.02333</link>
      <description>arXiv:2502.02333v1 Announce Type: cross 
Abstract: Ni/Al reactive multilayers are promising materials for applications requiring controlled local energy release and superior mechanical performance. This study systematically investigates the impact of compositional variations, ranging from 30 to 70 at.% Ni, and bilayer thicknesses (30 nm and 50 nm) on the mechanical properties and reaction dynamics of Ni/Al multilayers. Multilayers with varying Ni-to-Al ratios were fabricated and subjected to instrumented nanoindentation testing to evaluate hardness and elastic modulus. Combustion experiments, conducted on dogbone-shaped multilayers deposited onto silicon wafers with thermal barrier coatings, characterized the reaction front's speed, temperature, and the resulting phases. The findings revealed that composition variations within this range enable precise tuning of reaction speed and temperature without significant changes in mechanical properties, while deviations in modulus and hardness at higher nickel concentrations suggest microstructural influences. Notably, phase formation in Al-rich samples deviated from equilibrium predictions, highlighting the role of kinetic factors, such as diffusion and rapid quenching, in driving non-adiabatic processes during phase evolution. Molecular dynamics simulations provided complementary atomistic insights into mechanical responses and reaction kinetics, bridging experimental observations with theoretical predictions. This integrated approach advances the understanding of Ni/Al multilayers, offering a framework for optimizing their composition and structural design to achieve tailored performance for application-specific requirements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02333v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nensi Toncich, Fabian Schwarz, Rebecca A. Gallivan, Jemma Gillon, Ralph Spolenak</dc:creator>
    </item>
    <item>
      <title>Modeling Reactions on the Solid-Liquid Interface With Next Generation Extended Lagrangian Quantum-Based Molecular Dynamics</title>
      <link>https://arxiv.org/abs/2502.02429</link>
      <description>arXiv:2502.02429v1 Announce Type: cross 
Abstract: In this work, we demonstrate how extended Lagrangian Born-Oppenheimer quantum-based molecular dynamics (XL-BOMD) can be used to simulate heterogeneous electrocatalytic reactions. In particular, we apply our framework to study the oxygen reduction reaction (ORR) mechanism on nitrogen-doped graphene in an aqueous solution. The electronic ground state and total energy of XL-BOMD are stabilized through nuclear and electronic equations of motion assisted by an integral kernel updated with low-rank approximations. A species charge analysis reveals that the XL-BOMD simulations can be used to detect electron transfer between the catalyst surface and the solvated molecular oxygen mediated by water molecules, resulting in the molecular dissociation of O$_2$. Simulations of the ORR under high electrochemical biases contribute to a larger body of work elucidating an outer-sphere ORR mechanism in which reduction occurs through water networks without direct adsorption of molecular oxygen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02429v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rae A. Corrigan Grove, Kevin G. Kleiner, Joshua D. Finkelstein, Ivana Gonzales, Michael E. Wall, Travis E. L. Jones, Anders M. N. Niklasson, Christian F. A. Negre</dc:creator>
    </item>
    <item>
      <title>Solvers for Large-Scale Electronic Structure Theory: ELPA and ELSI</title>
      <link>https://arxiv.org/abs/2502.02460</link>
      <description>arXiv:2502.02460v1 Announce Type: cross 
Abstract: In this contribution, we give an overview of the ELPA library and ELSI interface, which are crucial elements for large-scale electronic structure calculations in FHI-aims.
  ELPA is a key solver library that provides efficient solutions for both standard and generalized eigenproblems, which are central to the Kohn-Sham formalism in density functional theory (DFT). It supports CPU and GPU architectures, with full support for NVIDIA and AMD GPUs, and ongoing development for Intel GPUs. Here we also report the results of recent optimizations, leading to significant improvements in GPU performance for the generalized eigenproblem.
  ELSI is an open-source software interface layer that creates a well-defined connection between "user" electronic structure codes and "solver" libraries for the Kohn-Sham problem, abstracting the step between Hamilton and overlap matrices (as input to ELSI and the respective solvers) and eigenvalues and eigenvectors or density matrix solutions (as output to be passed back to the "user" electronic structure code). In addition to ELPA, ELSI supports solvers including LAPACK and MAGMA, the PEXSI and NTPoly libraries (which bypass an explicit eigenvalue solution), and several others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02460v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Petr Karpov, Andreas Marek, Tobias Melson, Alexander P\"oppl, Victor Wen-zhe Yu, Ben Hourahine, Alberto Garcia, William Dawson, Yi Yao, William Huhn, Jonathan Moussa, Sam Hall, Reinhard Maurer, Uthpala Herath, Konstantin Lion, Sebastian Kokott, Volker Blum</dc:creator>
    </item>
    <item>
      <title>Kinetic study of Kelvin-Helmholtz instability: Multiscale thermodynamic nonequilibrium effects and their relative importance</title>
      <link>https://arxiv.org/abs/2502.02474</link>
      <description>arXiv:2502.02474v1 Announce Type: cross 
Abstract: This study investigates the complex dynamics of thermodynamic nonequilibrium effects (TNEs) and their relative importance during the development of the Kelvin-Helmholtz instability (KHI) using high-order discrete Boltzmann models (DBMs). First, the capabilities and differences among various discrete velocity sets in capturing TNEs and distribution functions are assessed. Based on this analysis, practical guidelines for constructing discrete velocity stencils are proposed to enhance phase-space discretization and improve the robustness of high-order DBMs. At different stages of KHI and under varying initial conditions, multiscale TNEs, such as viscous stresses of different orders, emerge with distinct dominant roles. Specifically, three scenarios are identified: (i) regimes dominated by first-order TNEs, (ii) alternation between first- and second-order TNEs, and (iii) states where second-order TNEs govern the system's behavior. To quantitatively capture these transitions, criteria for TNE dominance at different orders in KHI evolution are established based on the relative thermodynamic nonequilibrium intensity. In scenarios dominated by second-order TNEs, differences between first-order and second-order models are compared in terms of macroscopic quantities, nonequilibrium effects, and moment relations, revealing the physical limitations of low-order models in capturing TNEs. Furthermore, the effectiveness, extensibility, and limitations of a representative high-order model are examined under second-order TNE-dominated conditions. To encapsulate these findings, a nonequilibrium phase diagram that visually maps the multiscale characteristics of KHI is constructed. This diagram not only provides intuitive insights into the dynamic interplay of different nonequilibrium effects but also serves as a kinetic roadmap for selecting suitable models under diverse nonequilibrium conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02474v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongyi He, Yanbiao Gan, Bin Yang, Demei Li, Huilin Lai, Aiguo Xu</dc:creator>
    </item>
    <item>
      <title>A novel hybrid approach for accurate simulation of compressible multi-component flows across all-Mach number</title>
      <link>https://arxiv.org/abs/2502.02570</link>
      <description>arXiv:2502.02570v1 Announce Type: cross 
Abstract: Numerical simulation of multi-component flow systems characterized by the simultaneous presence of pressure-velocity coupling and pressure-density coupling dominated regions remains a significant challenge in computational fluid dynamics. Thus, this work presents a novel approach that combines the Godunov-type scheme for high-speed flows with the projection solution procedure for incompressible flows to address this challenge. The proposed hybrid approach begins by splitting the inviscid flux into the advection part and the pressure part. The solution variables are first updated to their intermediate states by solving the advection part with the all-speed AUSM (Advection Upwind Splitting Method) Riemann solver. The advection flux in AUSM is modified to eliminate the pressure flux term that deteriorates the accuracy at the low Mach region. To prevent the advection flux from causing spurious velocities when surface tension is present, the pressure-velocity coupling term is modified to ensure it vanishes at material interfaces. Then, we derive the pressure Helmholtz equation to solve the final pressure and update the intermediate states to the solution variables at the next time step. The proposed hybrid approach retains the upwind property of the AUSM scheme for high Mach numbers while recovering central schemes and the standard projection solution for low Mach limits. To accurately resolve the complex flow structures including shock waves and material interfaces without numerical oscillations, a newly proposed homogenous ROUND (Reconstruction Operator on Unified Normalised-variable Diagram) reconstruction strategy is employed in this work. By simulating high-speed compressible multiphase flows and incompressible multiphase flows, this study demonstrates the ability of the proposed method to accurately handle flow regimes across all Mach numbers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02570v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xi Deng, Bin Xie, Omar K. Matar, Pierre Boivin</dc:creator>
    </item>
    <item>
      <title>Laser-induced alignment of nanoparticles and macromolecules for single-particle-imaging applications</title>
      <link>https://arxiv.org/abs/2306.05870</link>
      <description>arXiv:2306.05870v2 Announce Type: replace 
Abstract: Laser-induced alignment of particles and molecules was long envisioned to support three-dimensional structure determination using "single-molecule diffraction" with x-ray free-electron lasers [PRL 92, 198102 (2004)]. However, the alignment of isolated macromolecules has not yet been demonstrated, also because quantitative modeling is very expensive. We computationally demonstrated that the alignment of nanorods and proteins is possible with standard laser technology. We performed a comprehensive analysis on the dependence of the degree of alignment on molecular properties and experimental details, e.g., particle temperature and laser-pulse energy. Considering the polarizability anisotropy of about 150,000 proteins, our analysis revealed that most of these proteins can be aligned using realistic experimental parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.05870v2</guid>
      <category>physics.comp-ph</category>
      <category>physics.app-ph</category>
      <category>physics.bio-ph</category>
      <category>physics.chem-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1021/jacs.4c15679</arxiv:DOI>
      <dc:creator>Muhamed Amin, Jean-Michel Hartmann, Amit K. Samanta, Jochen K\"upper</dc:creator>
    </item>
    <item>
      <title>Logarithmically complex rigorous Fourier space solution to the 1D grating diffraction problem</title>
      <link>https://arxiv.org/abs/2409.07821</link>
      <description>arXiv:2409.07821v2 Announce Type: replace 
Abstract: The rigorous solution to the grating diffraction problem is a cornerstone step in many scientific fields and industrial applications ranging from the study of the fundamental properties of metasurfaces to the simulation of photolithography masks. Fourier space methods, such as the Fourier Modal Method, are established tools for the analysis of the electromagnetic properties of periodic structures, but are too computationally demanding to be directly applied to large and multiscale optical structures. This work focuses on pushing the limits of rigorous computations of periodic electromagnetic structures by adapting a powerful tensor compression technique called the Tensor Train decomposition. We have found that the millions and billions of numbers produced by standard discretization schemes are inherently excessive for storing the information about diffraction problems required for computations with a given accuracy, and we show how to adapt the TT algorithms to have a logarithmically growing amount of information to be sufficient for reliable rigorous solution of the Maxwell's equations on an example of large period multiscale 1D grating structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07821v2</guid>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2025.109530</arxiv:DOI>
      <dc:creator>Evgeniy Levdik, Alexey A. Shcherbakov</dc:creator>
    </item>
    <item>
      <title>Simulation of 24,000 Electrons Dynamics: Real-Time Time-Dependent Density Functional Theory (TDDFT) with the Real-Space Multigrids (RMG)</title>
      <link>https://arxiv.org/abs/2410.09189</link>
      <description>arXiv:2410.09189v2 Announce Type: replace 
Abstract: We present the theory, implementation, and benchmarking of a real-time time-dependent density functional theory (RT-TDDFT) module within the RMG code, designed to simulate the electronic response of molecular systems to external perturbations. Our method offers insights into non-equilibrium dynamics and excited states across a diverse range of systems, from small organic molecules to large metallic nanoparticles. Benchmarking results demonstrate excellent agreement with established TDDFT implementations and showcase the superior stability of our time-integration algorithm, enabling long-term simulations with minimal energy drift. The scalability and efficiency of RMG on massively parallel architectures allow for simulations of complex systems, such as plasmonic nanoparticles with thousands of atoms. Future extensions, including nuclear and spin dynamics, will broaden the applicability of this RT-TDDFT implementation, providing a powerful toolset for studies of photoactive materials, nanoscale devices, and other systems where real-time electronic dynamics is essential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09189v2</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1021/acs.jctc.4c01241</arxiv:DOI>
      <dc:creator>Jacek Jakowski, Wenchang Lu, Emil Briggs, David Lingerfelt, Bobby G. Sumpter, Panchapakesan Ganesh, Jerzy Bernholc</dc:creator>
    </item>
    <item>
      <title>Numerical Modeling of Oxygen Diffusion in Tissue Spheroids Undergoing Fusion Using Functional Representation and Finite Volumes</title>
      <link>https://arxiv.org/abs/2501.12095</link>
      <description>arXiv:2501.12095v3 Announce Type: replace 
Abstract: A three-dimensional cell culture called a spheroid serves as a foundational entity in a wide variety of modern tissue engineering applications, including 3D-bioprinting and preclinical drug testing. Lack of oxygen within tissue spheroids hinders metabolism of cells and eventually leads to cell death. Prevention of necrosis is crucial to success of tissue engineering methods and such prevention requires estimation of cell viability in the spheroid. We propose a novel approach for numerical modeling of diffusion in tissue spheroids during their fusion. The approach is based on numerical solutions of partial differential equations and the application of Functional Representations (FRep) framework for geometric modeling. We present modeling of oxygen diffusion based on meshes derived from the geometry of fusing spheroids, a method for selecting optimal spheroid size, and several statistics for estimating cellular viability. Our findings provide insights into oxygen diffusion in three-dimensional cell cultures thus improving the robustness of biotechnological methods that employ tissue spheroids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12095v3</guid>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine Vilinski-Mazur, Bogdan Kirillov, Oleg Rogozin, Dmitry Kolomenskiy</dc:creator>
    </item>
    <item>
      <title>Towards nonlinear thermohydrodynamic simulations via the Onsager-Regularized Lattice Boltzmann Method</title>
      <link>https://arxiv.org/abs/2501.16000</link>
      <description>arXiv:2501.16000v2 Announce Type: replace 
Abstract: We present theoretical analyses of the recently proposed Onsager-Regularized (OReg) lattice Boltzmann (LB) method [Jonnalagadda et al., Phys. Rev. E 104, 015313 (2021)] to demonstrate its ability to mitigate spurious errors associated with the insufficient isotropy of standard first-neighbor lattices without the inclusion of any external correction terms. As an illustration, we theoretically show that, with the so-called guided equilibrium, the OReg scheme inherently compensates for the insufficient lattice isotropy of the standard D2Q9 lattice by automatically adjusting the lattice viscosity; these theoretical results are verified numerically through simulations of the rotated decaying shear wave and isothermal shocktube problems. The present work lays the theoretical foundation of a generic framework which, with appropriately constrained equilibrium representations, can enable fully local, correction-free nonlinear thermohydrodynamic LB simulations on standard lattices, thereby facilitating scalable simulations of physically challenging fluid flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.16000v2</guid>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirudh Jonnalagadda, Amit Agrawal, Atul Sharma, Walter Rocchia, Sauro Succi</dc:creator>
    </item>
    <item>
      <title>Enhancing Scalability of Quantum Eigenvalue Transformation of Unitary Matrices for Ground State Preparation through Adaptive Finer Filtering</title>
      <link>https://arxiv.org/abs/2401.09091</link>
      <description>arXiv:2401.09091v4 Announce Type: replace-cross 
Abstract: Hamiltonian simulation is a domain where quantum computers have the potential to outperform their classical counterparts. One of the main challenges of such quantum algorithms is increasing the system size, which is necessary to achieve meaningful quantum advantage. In this work, we present an approach to improve the scalability of eigenspace filtering for the ground state preparation of a given Hamiltonian. Our method aims to tackle limitations introduced by a small spectral gap and high degeneracy of low energy states. It is based on an adaptive sequence of eigenspace filtering through Quantum Eigenvalue Transformation of Unitary Matrices (QETU) combined with spectrum profiling. By combining our proposed algorithm with state-of-the-art phase estimation methods, we achieved good approximations for the ground state energy with local, two-qubit gate depolarizing probability up to $10^{-4}$. To demonstrate the key results in this work, we ran simulations with the transverse-field Ising Model on classical computers using Qiskit. We compare the performance of our approach with the static implementation of QETU and show that we can consistently achieve three to four orders of magnitude improvement in the absolute error rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09091v4</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Erenay Karacan, Yanbin Chen, Christian B. Mendl</dc:creator>
    </item>
    <item>
      <title>Fast Algorithm for Quasi-2D Coulomb Systems</title>
      <link>https://arxiv.org/abs/2403.01521</link>
      <description>arXiv:2403.01521v2 Announce Type: replace-cross 
Abstract: Quasi-2D Coulomb systems are of fundamental importance and have attracted much attention in many areas nowadays. Their reduced symmetry gives rise to interesting collective behaviors, but also brings great challenges for particle-based simulations. Here, we propose a novel algorithm framework to address the $O(N^2)$ simulation complexity associated with the long-range nature of Coulomb interactions. First, we introduce an efficient Sum-of-Exponentials (SOE) approximation for the long-range kernel associated with Ewald splitting, achieving uniform convergence in terms of inter-particle distance, which reduces the complexity to $O(N^{7/5})$. We then introduce a random batch sampling method in the periodic dimensions, the stochastic approximation is proven to be both unbiased and with reduced variance via a tailored importance sampling strategy, further reducing the computational cost to $O(N)$. The performance of our algorithm is demonstrated via various numerical examples. Notably, it achieves a speedup of $2\sim 3$ orders of magnitude comparing with Ewald2D method, enabling molecular dynamics (MD) simulations with up to $10^6$ particles on a single core. The present approach is therefore well-suited for large-scale particle-based simulations of Coulomb systems under confinement, making it possible to investigate the role of Coulomb interaction in many practical situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01521v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jcp.2025.113733</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational Physics, 2025</arxiv:journal_reference>
      <dc:creator>Zecheng Gan, Xuanzhao Gao, Jiuyang Liang, Zhenli Xu</dc:creator>
    </item>
    <item>
      <title>Statistical Mechanics of Dynamical System Identification</title>
      <link>https://arxiv.org/abs/2403.01723</link>
      <description>arXiv:2403.01723v2 Announce Type: replace-cross 
Abstract: Recovering dynamical equations from observed noisy data is the central challenge of system identification. We develop a statistical mechanics approach to analyze sparse equation discovery algorithms, which typically balance data fit and parsimony via hyperparameter tuning. In this framework, statistical mechanics offers tools to analyze the interplay between complexity and fitness similarly to that of entropy and energy in physical systems. To establish this analogy, we define the hyperparameter optimization procedure as a two-level Bayesian inference problem that separates variable selection from coefficient inference and enables the computation of the posterior parameter distribution in closed form. Our approach provides uncertainty quantification, crucial in the low-data limit that is frequently encountered in real-world applications. A key advantage of employing statistical mechanical concepts, such as free energy and the partition function, is to connect the large data limit to thermodynamic limit and characterize the sparsity- and noise-induced phase transitions that delineate correct from incorrect identification. We thus provide a method for closed-loop inference, estimating the noise in a given model and checking if the model is tolerant to that noise amount. This perspective of sparse equation discovery is versatile and can be adapted to various other equation discovery algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01723v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei A. Klishin, Joseph Bakarji, J. Nathan Kutz, Krithika Manohar</dc:creator>
    </item>
    <item>
      <title>Uncertainty Propagation within Chained Models for Machine Learning Reconstruction of Neutrino-LAr Interactions</title>
      <link>https://arxiv.org/abs/2411.09864</link>
      <description>arXiv:2411.09864v3 Announce Type: replace-cross 
Abstract: Sequential or chained models are increasingly prevalent in machine learning for scientific applications, due to their flexibility and ease of development. Chained models are particularly useful when a task is separable into distinct steps with a hierarchy of meaningful intermediate representations. In reliability-critical tasks, it is important to quantify the confidence of model inferences. However, chained models pose an additional challenge for uncertainty quantification, especially when input uncertainties need to be propagated. In such cases, a fully uncertainty-aware chain of models is required, where each step accepts a probability distribution over the input space, and produces a probability distribution over the output space. In this work, we present a case study for adapting a single model within an existing chain, designed for reconstruction within neutrino-Argon interactions, developed for neutrino oscillation experiments such as MicroBooNE, ICARUS, and the future DUNE experiment. We test the performance of an input uncertainty-enabled model against an uncertainty-blinded model using a method for generating synthetic noise. By comparing these two, we assess the increase in inference quality achieved by exposing models to upstream uncertainty estimates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.09864v3</guid>
      <category>physics.data-an</category>
      <category>hep-ex</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Douglas, Aashwin Mishra, Daniel Ratner, Felix Petersen, Kazuhiro Terao</dc:creator>
    </item>
    <item>
      <title>Conditional t-independent spectral gap for random quantum circuits and implications for t-design depths</title>
      <link>https://arxiv.org/abs/2411.13739</link>
      <description>arXiv:2411.13739v2 Announce Type: replace-cross 
Abstract: A fundamental question is understanding the rate at which random quantum circuits converge to the Haar measure. One quantity which is important in establishing this rate is the spectral gap of a random quantum ensemble. In this work we establish a new bound on the spectral gap of the t-th moment of a one-dimensional brickwork architecture on N qudits. This bound is independent of both t and N, provided t does not exceed the qudit dimension q. We also show that the bound is nearly optimal. The improved spectral gaps gives large improvements to the constant factors in known results on the approximate t-design depths of the 1D brickwork, of generic circuit architectures, and of specially-constructed architectures which scramble in depth O(log N). We moreover show that the spectral gap gives the dominant epsilon-dependence of the t-design depth at small epsilon. Our spectral gap bound is obtained by bounding the N-site 1D brickwork architecture by the spectra of 3-site operators. We then exploit a block-triangular hierarchy and a global symmetry in these operators in order to efficiently bound them. The technical methods used are a qualitatively different approach for bounding spectral gaps and and have little in common with previous techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13739v2</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>James Allen, Daniel Belkin, Bryan K. Clark</dc:creator>
    </item>
    <item>
      <title>MOLPIPx: an end-to-end differentiable package for permutationally invariant polynomials in Python and Rust</title>
      <link>https://arxiv.org/abs/2411.17011</link>
      <description>arXiv:2411.17011v2 Announce Type: replace-cross 
Abstract: In this work, we present MOLPIPx, a versatile library designed to seamlessly integrate Permutationally Invariant Polynomials (PIPs) with modern machine learning frameworks, enabling the efficient development of linear models, neural networks, and Gaussian process models. These methodologies are widely employed for parameterizing potential energy surfaces across diverse molecular systems. MOLPIPx leverages two powerful automatic differentiation engines -JAX and EnzymeAD-Rust- to facilitate the efficient computation of energy gradients and higher-order derivatives, which are essential for tasks such as force field development and dynamic simulations. MOLPIPx is available at https://github.com/ChemAI-Lab/molpipx.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17011v2</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel S. Drehwald, Asma Jamali, Rodrigo A. Vargas-Hern\'andez</dc:creator>
    </item>
    <item>
      <title>Molecular tuning of excitons in four-atom-thick hybrid bilayer crystals</title>
      <link>https://arxiv.org/abs/2412.12027</link>
      <description>arXiv:2412.12027v2 Announce Type: replace-cross 
Abstract: Bilayer crystals, formed by stacking monolayers of two-dimensional (2D) crystals, create interlayer potentials that govern excitonic phenomena but are constrained by their fixed covalent lattices. Replacing one layer with an atomically thin molecular crystal overcomes this limitation, as precise control of functional groups enables tunable 2D molecular lattices and, consequently, electronic structures. Here, we report molecular tuning of lattices and excitons in four-atom-thick hybrid bilayer crystals (HBCs), synthesized as monolayers of perylene-based molecular and transition metal dichalcogenide (TMD) single crystals. In HBCs, we observe an anisotropic photoluminescence signal exhibiting characteristics of both molecular and TMD excitons, directly tuned by molecular geometry and HBC composition. Ab initio calculations reveal that this anisotropic emission arises from hybrid excitons, which inherit properties from both layers through a hybridized bilayer band structure. Our work establishes a synthetically derived, molecule-based 2D quantum materials platform with the potential for engineering interlayer potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12027v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Wed, 05 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomojit Chowdhury, Aur\'elie Champagne, Patrick Kn\"uppel, Zehra Naqvi, Mengyu Gao, Nathan Guisinger, Kin Fai Mak, Jeffrey B. Neaton, Jiwoong Park</dc:creator>
    </item>
  </channel>
</rss>
