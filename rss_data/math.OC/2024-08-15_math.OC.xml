<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Aug 2024 04:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Data Clustering and Visualization with Recursive Goemans-Williamson MaxCut Algorithm</title>
      <link>https://arxiv.org/abs/2408.07763</link>
      <description>arXiv:2408.07763v1 Announce Type: new 
Abstract: In this article, we introduce a novel recursive modification to the classical Goemans-Williamson MaxCut algorithm, offering improved performance in vectorized data clustering tasks. Focusing on the clustering of medical publications, we employ recursive iterations in conjunction with a dimension relaxation method to significantly enhance density of clustering results. Furthermore, we propose a unique vectorization technique for articles, leveraging conditional probabilities for more effective clustering. Our methods provide advantages in both computational efficiency and clustering accuracy, substantiated through comprehensive experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07763v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An Ly, Raj Sawhney, Marina Chugunova</dc:creator>
    </item>
    <item>
      <title>Data Clustering and Visualization with Recursive Max k-Cut Algorithm</title>
      <link>https://arxiv.org/abs/2408.07771</link>
      <description>arXiv:2408.07771v1 Announce Type: new 
Abstract: In this article, we continue our analysis for a novel recursive modification to the Max $k$-Cut algorithm using semidefinite programming as its basis, offering an improved performance in vectorized data clustering tasks. Using a dimension relaxation method, we use a recursion method to enhance density of clustering results. Our methods provide advantages in both computational efficiency and clustering accuracy for grouping datasets into three clusters, substantiated through comprehensive experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07771v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>An Ly, Raj Sawhney, Marina Chugunova</dc:creator>
    </item>
    <item>
      <title>Why fixing alpha in the NRTL model might be a bad idea -- Identifiability analysis of a binary Vapor-Liquid equilibrium</title>
      <link>https://arxiv.org/abs/2408.07844</link>
      <description>arXiv:2408.07844v1 Announce Type: new 
Abstract: New vapor-liquid equilibrium (VLE) data are continuously being measured and new parameter values, e.g., for the nonrandom two-liquid (NRTL) model are estimated and published. The parameter $\alpha$, the nonrandomness parameter of NRTL, is often heuristically fixed to a value in the range of 0.1 to 0.47. This can be seen as a manual application of a (subset selection) regularization method. In this work, the identifiability of the NRTL model for describing the VLE is analyzed. It is shown that fixing $\alpha$ is not always a good decision and sometimes leads to worse prediction properties of the final parameter estimates. Popular regularization techniques are compared and Generalized Orthogonalization is proposed as an alternative to this heuristic. In addition, the sequential Optimal Experimental Design and Parameter Estimation (sOED-PE) method is applied to study the influence of the regularization methods on the performance of the sOED-PE loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07844v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volodymyr Kozachynskyi, Christian Hoffmann, Erik Esche</dc:creator>
    </item>
    <item>
      <title>Monotonicity in Quadratically Regularized Linear Programs</title>
      <link>https://arxiv.org/abs/2408.07871</link>
      <description>arXiv:2408.07871v1 Announce Type: new 
Abstract: In optimal transport, quadratic regularization is a sparse alternative to entropic regularization: the solution measure tends to have small support. Computational experience suggests that the support decreases monotonically to the unregularized counterpart as the regularization parameter is relaxed. We find it useful to investigate this monotonicity more abstractly for linear programs over polytopes, regularized with the squared norm. Here, monotonicity can be stated as an invariance property of the curve mapping the regularization parameter to the solution: once the curve enters a face of the polytope, does it remain in that face forever? We show that this invariance is equivalent to a geometric property of the polytope, namely that each face contains the minimum norm point of its affine hull. Returning to the optimal transport problem and its associated Birkhoff polytope, we verify this property for low dimensions, but show that it fails for dimension $d\geq25$. As a consequence, the conjectured monotonicity of the support fails in general, even if experiments suggest that monotonicity holds for many cost matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07871v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Marcel Nutz, Andr\'es Riveros Valdevenito</dc:creator>
    </item>
    <item>
      <title>Passive Stability and Adaptive Control of Teleoperated System using Wave Variables and Predictor Techniques</title>
      <link>https://arxiv.org/abs/2408.07878</link>
      <description>arXiv:2408.07878v1 Announce Type: new 
Abstract: This paper addresses the challenge of achieving stable adaptive teleoperation and improving the convergence rate in the presence of high communication time delays. We employ a passivity-based formalism to establish stability using wave variables and wave scattering techniques, and we enhance the convergence rate by combining it with predictor-based approaches. The elevated time delay within the teleoperated communication layer is known to induce an oscillatory behavior, which reduces the convergence rate and increases the settling time in the convergence of power variables. This issue is addressed in this paper by utilizing a Smith predictor on the operator end and Minimum Jerk (MJ) predictor on the remote end. We present experimental and simulation results to demonstrate the improvements, ensuring stable teleoperation under high communication time delays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07878v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naveen Kumar Rajarajan, Sridhar Babu Mudhangulla, Olugbenga Moses Anubi</dc:creator>
    </item>
    <item>
      <title>Optimal control problems with generalized mean-field dynamics and viscosity solution to Master Bellman equation</title>
      <link>https://arxiv.org/abs/2408.08046</link>
      <description>arXiv:2408.08046v1 Announce Type: new 
Abstract: We study an optimal control problem of generalized mean-field dynamics with open-loop controls, where the coefficients depend not only on the state processes and controls, but also on the joint law of them. The value function $V$ defined in a conventional way, but it does not satisfy the Dynamic Programming Principle (DPP for short). For this reason we introduce subtly a novel value function $\vartheta$, which is closely related to the original value function $V$, such that, a description of $\vartheta$, as a solution of a partial differential equation (PDE), also characterizes $V$. We establish the DPP for $\vartheta$. By using an intrinsic notion of viscosity solutions, initially introduced in Burzoni, Ignazio, Reppen and Soner [8] and specifically tailored to our framework, we show that the value function $\vartheta$ is a viscosity solution to a Master Bellman equation on a subset of Wasserstein space of probability measures. The uniqueness of viscosity solution is proved for coefficients which depend on the time and the joint law of the control process and the controlled process. Our approach is inspired by Buckdahn, Li, Peng and Rainer [7], and leads to a generalization of the mean-field PDE in [7] to a Master Bellman equation in the case of controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08046v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rainer Buckdahn, Juan Li, Zhanxin Li</dc:creator>
    </item>
    <item>
      <title>General single-loop methods for bilevel parameter learning</title>
      <link>https://arxiv.org/abs/2408.08123</link>
      <description>arXiv:2408.08123v1 Announce Type: new 
Abstract: Bilevel optimisation is used in inverse problems for hyperparameter learning and experimental design. For instance, it can be used to find optimal regularisation parameters and forward operators, based on a set of training pairs. However, computationally, the process is costly. To reduce this cost, recently in bilevel optimisation research, especially as applied to machine learning, so-called single-loop approaches have been introduced. On each step of an outer optimisation method, such methods only take a single gradient descent step towards the solution of the inner problem. In this paper, we flexibilise the inner algorithm, to allow for methods more applicable to difficult inverse problems with nonsmooth regularisation, including primal-dual proximal splitting (PDPS). Moreover, as we have recently shown, significant performance improvements can be obtained in PDE-constrained optimisation by interweaving the steps of conventional iterative solvers (Jacobi, Gauss-Seidel, conjugate gradients) for both the PDE and its adjoint, with the steps of the optimisation method. In this paper we demonstrate how the adjoint equation in bilevel problems can also benefit from such interweaving with conventional linear system solvers. We demonstrate the performance of our proposed methods on learning the deconvolution kernel for image deblurring, and the subsampling operator for magnetic resonance imaging (MRI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08123v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ensio Suonper\"a, Tuomo Valkonen</dc:creator>
    </item>
    <item>
      <title>Kolm-Pollack Form, Translation Homotheticity and Tropical Limit of Production Technologies</title>
      <link>https://arxiv.org/abs/2408.08130</link>
      <description>arXiv:2408.08130v1 Announce Type: new 
Abstract: In this paper, we consider a new class of generalized Convex structure and we investigate their tropical limits. Some properties are pointing out such that translation homotheticity and others ones allowing to consider the case of discrete production sets that are related to some specific dual forms. Along this line a general class of mathematical programs are derived and it is shown that they can be computed using standard methods. The proposed approach allows to deal with efficiency measures (output oriented or input oriented) on continuous and discrete data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08130v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Walter Briec, St\'ephane Mussard, Paola Ravelojaona</dc:creator>
    </item>
    <item>
      <title>A technical note on finite best-worst random utility model representations</title>
      <link>https://arxiv.org/abs/2408.08165</link>
      <description>arXiv:2408.08165v1 Announce Type: new 
Abstract: This paper investigates the random utility representation of best-worst choice probabilities (picking the best and the worst alternative from an offered set). Doignon (2023) presented a complete characterization of the best-worst-choice polytope on four alternatives. Moreover, using polytope methods he showed that the Block-Marschak inequalities for best-worst choices are not sufficient for a random utility representation of best-worst choices for sets of four or more alternatives. Following the approach of Falmagne (1978), we present novel necessary and sufficient conditions for the construction of a probability measure on the set of rankings for a set of four alternatives implying a random utility representation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08165v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hans Colonius</dc:creator>
    </item>
    <item>
      <title>An Efficient Integer Programming Model for Solving the Master Planning Problem of Container Vessel Stowage</title>
      <link>https://arxiv.org/abs/2408.08224</link>
      <description>arXiv:2408.08224v1 Announce Type: new 
Abstract: A crucial role of container shipping is maximizing container uptake onto vessels, optimizing the efficiency of a fundamental part of the global supply chain. In practice, liner shipping companies include block stowage patterns that ensure that containers in above and below deck partitions of bays have the same destination. Despite preventing restows, increasing free space, and benefits for crane makespan and hydrostatics, this practical planning requirement is rarely included in stowage optimization models. In our paper, we introduce a novel 0-1 IP model that searches in the space of valid paired block stowage patterns, named template planning, which ensures sufficient vessel capacity and limits to crane makespan, trim, and bending moment. Our results show that template planning outperforms traditional allocation planning concerning optimality and runtime efficiency while preserving a sufficiently accurate representation of master planning constraints and objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08224v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaike van Twiller, Agnieszka Sivertsen, Rune M. Jensen, Kent H. Andersen</dc:creator>
    </item>
    <item>
      <title>Equivalent Characterizations of the Aubin Property for Nonlinear Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2408.08232</link>
      <description>arXiv:2408.08232v1 Announce Type: new 
Abstract: In this paper, we study the Aubin property of the Karush-Kuhn-Tucker solution mapping for the nonlinear semidefinite programming (NLSDP) problem at a locally optimal solution. In the literature, it is known that the Aubin property implies the constraint nondegeneracy by Fusek [SIAM J. Optim. 23 (2013), pp. 1041-1061] and the second-order sufficient condition by Ding et al. [SIAM J. Optim. 27 (2017), pp. 67-90]. Based on the Mordukhovich criterion, here we further prove that the strong second-order sufficient condition is also necessary for the Aubin property to hold. Consequently, several equivalent conditions including the strong regularity are established for NLSDP's Aubin property. Together with the recent progress made by Chen et al. on the equivalence between the Aubin property and the strong regularity for nonlinear second-order cone programming [arXiv:2406.13798v1 (2024)], this paper constitutes a significant step forward in characterizing the Aubin property for general non-polyhedral $C^2$-cone reducible constrained optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08232v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Chen, Ruoning Chen, Defeng Sun, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>Vibrational Control of Complex Networks</title>
      <link>https://arxiv.org/abs/2408.08263</link>
      <description>arXiv:2408.08263v1 Announce Type: new 
Abstract: The stability of complex networks, from power grids to biological systems, is crucial for their proper functioning. It is thus important to control such systems to maintain or restore their stability. Traditional approaches rely on real-time state measurements for feedback control, but this can be challenging in many real-world systems, such as the brain, due to their complex and dynamic nature. This paper utilizes vibrational control -- an open-loop strategy -- to regulate network stability. Unlike conventional methods targeting network nodes, our approach focuses on manipulating network edges through vibrational inputs. We establish sufficient graph-theoretic conditions for vibration-induced functional modifications of network edges and stabilization of network systems as a whole. Additionally, we provide methods for designing effective vibrational control inputs and validate our theoretical findings through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08263v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuzhen Qin, Fabio Pasqualetti, Danielle S. Bassett, Marcel van Gerven</dc:creator>
    </item>
    <item>
      <title>On Accelerating Large-Scale Robust Portfolio Optimization</title>
      <link>https://arxiv.org/abs/2408.07879</link>
      <description>arXiv:2408.07879v1 Announce Type: cross 
Abstract: Solving large-scale robust portfolio optimization problems is challenging due to the high computational demands associated with an increasing number of assets, the amount of data considered, and market uncertainty. To address this issue, we propose an extended supporting hyperplane approximation approach for efficiently solving a class of distributionally robust portfolio problems for a general class of additively separable utility functions and polyhedral ambiguity distribution set, applied to a large-scale set of assets. Our technique is validated using a large-scale portfolio of the S&amp;P 500 index constituents, demonstrating robust out-of-sample trading performance. More importantly, our empirical studies show that this approach significantly reduces computational time compared to traditional concave Expected Log-Growth (ELG) optimization, with running times decreasing from several thousand seconds to just a few. This method provides a scalable and practical solution to large-scale robust portfolio optimization, addressing both theoretical and practical challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07879v1</guid>
      <category>q-fin.CP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chung-Han Hsieh, Jie-Ling Lu</dc:creator>
    </item>
    <item>
      <title>Stochastic Semi-Gradient Descent for Learning Mean Field Games with Population-Aware Function Approximation</title>
      <link>https://arxiv.org/abs/2408.08192</link>
      <description>arXiv:2408.08192v1 Announce Type: cross 
Abstract: Mean field games (MFGs) model the interactions within a large-population multi-agent system using the population distribution. Traditional learning methods for MFGs are based on fixed-point iteration (FPI), which calculates best responses and induced population distribution separately and sequentially. However, FPI-type methods suffer from inefficiency and instability, due to oscillations caused by the forward-backward procedure. This paper considers an online learning method for MFGs, where an agent updates its policy and population estimates simultaneously and fully asynchronously, resulting in a simple stochastic gradient descent (SGD) type method called SemiSGD. Not only does SemiSGD exhibit numerical stability and efficiency, but it also provides a novel perspective by treating the value function and population distribution as a unified parameter. We theoretically show that SemiSGD directs this unified parameter along a descent direction to the mean field equilibrium. Motivated by this perspective, we develop a linear function approximation (LFA) for both the value function and the population distribution, resulting in the first population-aware LFA for MFGs on continuous state-action space. Finite-time convergence and approximation error analysis are provided for SemiSGD equipped with population-aware LFA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08192v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenyu Zhang, Xu Chen, Xuan Di</dc:creator>
    </item>
    <item>
      <title>Optimizing Autonomous Transfer Hub Networks: Quantifying the Potential Impact of Self-Driving Trucks</title>
      <link>https://arxiv.org/abs/2305.03119</link>
      <description>arXiv:2305.03119v2 Announce Type: replace 
Abstract: Autonomous trucks are expected to fundamentally transform the freight transportation industry. In particular, Autonomous Transfer Hub Networks (ATHNs), which combine autonomous trucks on middle miles with human-driven trucks on the first and last miles, are seen as the most likely deployment pathway for this technology. This paper presents a framework to optimize ATHN operations and evaluate the benefits of autonomous trucking. By exploiting the problem structure, this paper introduces a flow-based optimization model for this purpose that can be solved by blackbox solvers in a matter of hours. The resulting framework is easy to apply and enables the data-driven analysis of large-scale systems. The power of this approach is demonstrated on a system that spans all of the United States over a four-week horizon. The case study quantifies the potential impact of autonomous trucking and shows that ATHNs can have significant benefits over traditional transportation networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03119v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejtl.2024.100141</arxiv:DOI>
      <dc:creator>Chungjae Lee, Kevin Dalmeijer, Pascal Van Hentenryck, Peibo Zhang</dc:creator>
    </item>
    <item>
      <title>Goldstein Stationarity in Lipschitz Constrained Optimization</title>
      <link>https://arxiv.org/abs/2310.03690</link>
      <description>arXiv:2310.03690v3 Announce Type: replace 
Abstract: We prove the first convergence guarantees for a subgradient method minimizing a generic Lipschitz function over generic Lipschitz inequality constraints. No smoothness or convexity (or weak convexity) assumptions are made. Instead, we utilize a sequence of recent advances in Lipschitz unconstrained minimization, which showed convergence rates of $O(1/\delta\epsilon^3)$ towards reaching a "Goldstein" stationary point, that is, a point where an average of gradients sampled at most distance $\delta$ away has size at most $\epsilon$. We generalize these prior techniques to handle functional constraints, proposing a subgradient-type method with similar $O(1/\delta\epsilon^3)$ guarantees on reaching a Goldstein Fritz-John or Goldstein KKT stationary point, depending on whether a certain Goldstein-style generalization of constraint qualification holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03690v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Grimmer, Zhichao Jia</dc:creator>
    </item>
    <item>
      <title>Two Completely Parameter-Free Alternating Gradient Projection Algorithms for Nonconvex-(strongly) Concave Minimax Problems</title>
      <link>https://arxiv.org/abs/2407.21372</link>
      <description>arXiv:2407.21372v2 Announce Type: replace 
Abstract: Due to their importance in various emerging applications, efficient algorithms for solving minimax problems have recently received increasing attention. However, many existing algorithms require prior knowledge of the problem parameters in order to achieve optimal iteration complexity. In this paper, we propose two completely parameter-free alternating gradient projection algorithms, i.e., the PF-AGP-NSC algorithm and the PF-AGP-NC algorithm, to solve the smooth nonconvex-strongly concave and nonconvex-concave minimax problems respectively using a backtracking strategy, which does not require prior knowledge of parameters such as the Lipschtiz constant $L$ or the strongly concave constant $\mu$. Moreover, we show that the total number of gradient calls of the PF-AGP-NSC algorithm and the PF-AGP-NC algorithm to obtain an $\varepsilon$-stationary point is upper bounded by $\mathcal{O}\left( L\kappa^3\varepsilon^{-2} \right)$ and $\mathcal{O}\left( L^4\varepsilon^{-4} \right)$ respectively, where $\kappa$ is the condition number. As far as we know, the PF-AGP-NSC algorithm and the PF-AGP-NC algorithm are the first completely parameter-free algorithms for solving nonconvex-strongly concave minimax problems and nonconvex-concave minimax problems respectively. Numerical results validate the efficiency of the proposed PF-AGP algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21372v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junnan Yang, Huiling Zhang, Zi Xu</dc:creator>
    </item>
    <item>
      <title>Robust Online Selection with Uncertain Offer Acceptance</title>
      <link>https://arxiv.org/abs/2112.00842</link>
      <description>arXiv:2112.00842v2 Announce Type: replace-cross 
Abstract: Online advertising has motivated interest in online selection problems. Displaying ads to the right users benefits both the platform (e.g., via pay-per-click) and the advertisers (by increasing their reach). In practice, not all users click on displayed ads, while the platform's algorithm may miss the users most disposed to do so. This mismatch decreases the platform's revenue and the advertiser's chances to reach the right customers. With this motivation, we propose a secretary problem where a candidate may or may not accept an offer according to a known probability $p$. Because we do not know the top candidate willing to accept an offer, the goal is to maximize a robust objective defined as the minimum over integers $k$ of the probability of choosing one of the top $k$ candidates, given that one of these candidates will accept an offer. Using Markov decision process theory, we derive a linear program for this max-min objective whose solution encodes an optimal policy. The derivation may be of independent interest, as it is generalizable and can be used to obtain linear programs for many online selection models. We further relax this linear program into an infinite counterpart, which we use to provide bounds for the objective and closed-form policies. For $p \geq p^* \approx 0.6$, an optimal policy is a simple threshold rule that observes the first $p^{1/(1-p)}$ fraction of candidates and subsequently makes offers to the best candidate observed so far.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.00842v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Perez-Salazar, Mohit Singh, Alejandro Toriello</dc:creator>
    </item>
    <item>
      <title>Safe Imitation Learning of Nonlinear Model Predictive Control for Flexible Robots</title>
      <link>https://arxiv.org/abs/2212.02941</link>
      <description>arXiv:2212.02941v3 Announce Type: replace-cross 
Abstract: Flexible robots may overcome some of the industry's major challenges, such as enabling intrinsically safe human-robot collaboration and achieving a higher payload-to-mass ratio. However, controlling flexible robots is complicated due to their complex dynamics, which include oscillatory behavior and a high-dimensional state space. Nonlinear model predictive control (NMPC) offers an effective means to control such robots, but its significant computational demand often limits its application in real-time scenarios. To enable fast control of flexible robots, we propose a framework for a safe approximation of NMPC using imitation learning and a predictive safety filter. Our framework significantly reduces computation time while incurring a slight loss in performance. Compared to NMPC, our framework shows more than an eightfold improvement in computation time when controlling a three-dimensional flexible robot arm in simulation, all while guaranteeing safety constraints. Notably, our approach outperforms state-of-the-art reinforcement learning methods. The development of fast and safe approximate NMPC holds the potential to accelerate the adoption of flexible robots in industry. The project code is available at: tinyurl.com/anmpc4fr</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.02941v3</guid>
      <category>cs.RO</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shamil Mamedov, Rudolf Reiter, Seyed Mahdi Basiri Azad, Ruan Viljoen, Joschka Boedecker, Moritz Diehl, Jan Swevers</dc:creator>
    </item>
    <item>
      <title>Optimal Scalarizations for Sublinear Hypervolume Regret</title>
      <link>https://arxiv.org/abs/2307.03288</link>
      <description>arXiv:2307.03288v3 Announce Type: replace-cross 
Abstract: Scalarization is a general, parallizable technique that can be deployed in any multiobjective setting to reduce multiple objectives into one, yet some have dismissed this versatile approach because linear scalarizations cannot explore concave regions of the Pareto frontier. To that end, we aim to find simple non-linear scalarizations that provably explore a diverse set of $k$ objectives on the Pareto frontier, as measured by the dominated hypervolume. We show that hypervolume scalarizations with uniformly random weights achieves an optimal sublinear hypervolume regret bound of $O(T^{-1/k})$, with matching lower bounds that preclude any algorithm from doing better asymptotically. For the setting of multiobjective stochastic linear bandits, we utilize properties of hypervolume scalarizations to derive a novel non-Euclidean analysis to get regret bounds of $\tilde{O}( d T^{-1/2} + T^{-1/k})$, removing unnecessary $\text{poly}(k)$ dependencies. We support our theory with strong empirical performance of using non-linear scalarizations that outperforms both their linear counterparts and other standard multiobjective algorithms in a variety of natural settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03288v3</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qiuyi Zhang (Richard)</dc:creator>
    </item>
    <item>
      <title>There is No Silver Bullet: Benchmarking Methods in Predictive Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2311.07633</link>
      <description>arXiv:2311.07633v4 Announce Type: replace-cross 
Abstract: Predictive combinatorial optimization, where the parameters of combinatorial optimization (CO) are unknown at the decision-making time, is the precise modeling of many real-world applications, including energy cost-aware scheduling and budget allocation on advertising. Tackling such a problem usually involves a prediction model and a CO solver. These two modules are integrated into the predictive CO pipeline following two design principles: ``Predict-then-Optimize (PtO)'', which learns predictions by supervised training and subsequently solves CO using predicted coefficients, while the other, named ``Predict-and-Optimize (PnO)'', directly optimizes towards the ultimate decision quality and claims to yield better decisions than traditional PtO approaches. However, there lacks a systematic benchmark of both approaches, including the specific design choices at the module level, as well as an evaluation dataset that covers representative real-world scenarios. To this end, we develop a modular framework to benchmark 11 existing PtO/PnO methods on 8 problems, including a new industrial dataset for combinatorial advertising that will be released. Our study shows that PnO approaches are better than PtO on 7 out of 8 benchmarks, but there is no silver bullet found for the specific design choices of PnO. A comprehensive categorization of current approaches and integration of typical scenarios are provided under a unified benchmark. Therefore, this paper could serve as a comprehensive benchmark for future PnO approach development and also offer fast prototyping for application-focused development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07633v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haoyu Geng, Hang Ruan, Runzhong Wang, Yang Li, Yang Wang, Lei Chen, Junchi Yan</dc:creator>
    </item>
    <item>
      <title>Mean-field limits for Consensus-Based Optimization and Sampling</title>
      <link>https://arxiv.org/abs/2312.07373</link>
      <description>arXiv:2312.07373v2 Announce Type: replace-cross 
Abstract: For algorithms based on interacting particle systems that admit a mean-field description, convergence analysis is often more accessible at the mean-field level. In order to transpose convergence results obtained at the mean-field level to the finite ensemble size setting, it is desirable to show that the particle dynamics converge in an appropriate sense to the corresponding mean-field dynamics. In this paper, we prove quantitative mean-field limit results for two related interacting particle systems: Consensus-Based Optimization and Consensus-Based Sampling. Our approach extends Sznitman's classical argument: in order to circumvent issues related to the lack of global Lipschitz continuity of the coefficients, we discard an event of small probability, the contribution of which is controlled using moment estimates for the particle systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07373v2</guid>
      <category>math.PR</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolai Jurek Gerber, Franca Hoffmann, Urbain Vaes</dc:creator>
    </item>
    <item>
      <title>Reconstructing a state-independent cost function in a mean-field game model</title>
      <link>https://arxiv.org/abs/2402.09297</link>
      <description>arXiv:2402.09297v2 Announce Type: replace-cross 
Abstract: In this short note, we consider an inverse problem to a mean-field games system where we are interested in reconstructing the state-independent running cost function from observed value-function data. We provide an elementary proof of a uniqueness result for the inverse problem using the standard multilinearization technique. One of the main features of our work is that we insist that the population distribution be a probability measure, a requirement that is not enforced in some of the existing literature on theoretical inverse mean-field games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09297v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kui Ren, Nathan Soedjak, Kewei Wang, Hongyu Zhai</dc:creator>
    </item>
    <item>
      <title>When Simple is Near Optimal in Security Games</title>
      <link>https://arxiv.org/abs/2402.11209</link>
      <description>arXiv:2402.11209v3 Announce Type: replace-cross 
Abstract: Fraud is ubiquitous across applications and involve users bypassing the rule of law, often with the strategic aim of obtaining some benefit that would otherwise be unattainable within the bounds of lawful conduct. However, user fraud can be detrimental.
  To mitigate the harms of user fraud, we study the problem of policing fraud as a security game between an administrator and users. In this game, an administrator deploys $R$ security resources (e.g., police officers) across $L$ locations and levies fines against users engaging in fraud at those locations. For this security game, we study both payoff and revenue maximization administrator objectives. In both settings, we show that computing the optimal administrator strategy is NP-hard and develop natural greedy algorithm variants for the respective settings that achieve at least half the payoff or revenue as the payoff-maximizing or revenue-maximizing solutions, respectively. We also establish a resource augmentation guarantee that our proposed greedy algorithms with one extra resource, i.e., $R+1$ resources, achieve at least the same payoff (revenue) as the payoff-maximizing (revenue-maximizing) outcome with $R$ resources. Moreover, in the setting when user types are homogeneous, we develop a near-linear time algorithm for the revenue maximization problem and a polynomial time approximation scheme for the payoff maximization problem.
  Next, we present numerical experiments based on a case study of parking enforcement at Stanford University's campus, highlighting the efficacy of our algorithms in increasing parking permit earnings at the university by over \$300,000 annually. Finally, we study several model extensions, including incorporating contracts to bridge the gap between the payoff and revenue-maximizing outcomes and generalizing our model to incorporate additional constraints beyond a resource budget constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11209v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Devansh Jalota, Michael Ostrovsky, Marco Pavone</dc:creator>
    </item>
  </channel>
</rss>
