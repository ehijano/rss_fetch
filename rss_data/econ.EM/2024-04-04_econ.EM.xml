<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Apr 2024 04:01:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On Improved Semi-parametric Bounds for Tail Probability and Expected Loss</title>
      <link>https://arxiv.org/abs/2404.02400</link>
      <description>arXiv:2404.02400v1 Announce Type: new 
Abstract: We revisit the fundamental issue of tail behavior of accumulated random realizations when individual realizations are independent, and we develop new sharper bounds on the tail probability and expected linear loss. The underlying distribution is semi-parametric in the sense that it remains unrestricted other than the assumed mean and variance. Our sharp bounds complement well-established results in the literature, including those based on aggregation, which often fail to take full account of independence and use less elegant proofs. New insights include a proof that in the non-identical case, the distributions attaining the bounds have the equal range property, and that the impact of each random variable on the expected value of the sum can be isolated using an extension of the Korkine identity. We show that the new bounds not only complement the extant results but also open up abundant practical applications, including improved pricing of product bundles, more precise option pricing, more efficient insurance design, and better inventory management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02400v1</guid>
      <category>econ.EM</category>
      <category>stat.OT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaolin Li, Artem Prokhorov</dc:creator>
    </item>
    <item>
      <title>Moran's I 2-Stage Lasso: for Models with Spatial Correlation and Endogenous Variables</title>
      <link>https://arxiv.org/abs/2404.02584</link>
      <description>arXiv:2404.02584v1 Announce Type: new 
Abstract: We propose a novel estimation procedure for models with endogenous variables in the presence of spatial correlation based on Eigenvector Spatial Filtering. The procedure, called Moran's $I$ 2-Stage Lasso (Mi-2SL), uses a two-stage Lasso estimator where the Standardised Moran's I is used to set the Lasso tuning parameter. Unlike existing spatial econometric methods, this has the key benefit of not requiring the researcher to explicitly model the spatial correlation process, which is of interest in cases where they are only interested in removing the resulting bias when estimating the direct effect of covariates. We show the conditions necessary for consistent and asymptotically normal parameter estimation assuming the support (relevant) set of eigenvectors is known. Our Monte Carlo simulation results also show that Mi-2SL performs well against common alternatives in the presence of spatial correlation. Our empirical application replicates Cadena and Kovak (2016) instrumental variables estimates using Mi-2SL and shows that in that case, Mi-2SL can boost the performance of the first stage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02584v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sylvain Barde, Rowan Cherodian, Guy Tchuente</dc:creator>
    </item>
    <item>
      <title>Bayesian Bi-level Sparse Group Regressions for Macroeconomic Forecasting</title>
      <link>https://arxiv.org/abs/2404.02671</link>
      <description>arXiv:2404.02671v1 Announce Type: new 
Abstract: We propose a Machine Learning approach for optimal macroeconomic forecasting in a high-dimensional setting with covariates presenting a known group structure. Our model encompasses forecasting settings with many series, mixed frequencies, and unknown nonlinearities. We introduce in time-series econometrics the concept of bi-level sparsity, i.e. sparsity holds at both the group level and within groups, and we assume the true model satisfies this assumption. We propose a prior that induces bi-level sparsity, and the corresponding posterior distribution is demonstrated to contract at the minimax-optimal rate, recover the model parameters, and have a support that includes the support of the model asymptotically. Our theory allows for correlation between groups, while predictors in the same group can be characterized by strong covariation as well as common characteristics and patterns. Finite sample performance is illustrated through comprehensive Monte Carlo experiments and a real-data nowcasting exercise of the US GDP growth rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02671v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matteo Mogliani, Anna Simoni</dc:creator>
    </item>
    <item>
      <title>Seemingly unrelated Bayesian additive regression trees for cost-effectiveness analyses in healthcare</title>
      <link>https://arxiv.org/abs/2404.02228</link>
      <description>arXiv:2404.02228v1 Announce Type: cross 
Abstract: In recent years, theoretical results and simulation evidence have shown Bayesian additive regression trees to be a highly-effective method for nonparametric regression. Motivated by cost-effectiveness analyses in health economics, where interest lies in jointly modelling the costs of healthcare treatments and the associated health-related quality of life experienced by a patient, we propose a multivariate extension of BART applicable in regression and classification analyses with several correlated outcome variables. Our framework overcomes some key limitations of existing multivariate BART models by allowing each individual response to be associated with different ensembles of trees, while still handling dependencies between the outcomes. In the case of continuous outcomes, our model is essentially a nonparametric version of seemingly unrelated regression. Likewise, our proposal for binary outcomes is a nonparametric generalisation of the multivariate probit model. We give suggestions for easily interpretable prior distributions, which allow specification of both informative and uninformative priors. We provide detailed discussions of MCMC sampling methods to conduct posterior inference. Our methods are implemented in the R package `suBART'. We showcase their performance through extensive simulations and an application to an empirical case study from health economics. By also accommodating propensity scores in a manner befitting a causal analysis, we find substantial evidence for a novel trauma care intervention's cost-effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02228v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Esser, Mateus Maia, Andrew C. Parnell, Judith Bosmans, Hanneke van Dongen, Thomas Klausch, Keefe Murphy</dc:creator>
    </item>
    <item>
      <title>Bayesian Neural Networks for Macroeconomic Analysis</title>
      <link>https://arxiv.org/abs/2211.04752</link>
      <description>arXiv:2211.04752v4 Announce Type: replace 
Abstract: Macroeconomic data is characterized by a limited number of observations (small T), many time series (big K) but also by featuring temporal dependence. Neural networks, by contrast, are designed for datasets with millions of observations and covariates. In this paper, we develop Bayesian neural networks (BNNs) that are well-suited for handling datasets commonly used for macroeconomic analysis in policy institutions. Our approach avoids extensive specification searches through a novel mixture specification for the activation function that appropriately selects the form of nonlinearities. Shrinkage priors are used to prune the network and force irrelevant neurons to zero. To cope with heteroskedasticity, the BNN is augmented with a stochastic volatility model for the error term. We illustrate how the model can be used in a policy institution by first showing that our different BNNs produce precise density forecasts, typically better than those from other machine learning methods. Finally, we showcase how our model can be used to recover nonlinearities in the reaction of macroeconomic aggregates to financial shocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.04752v4</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Niko Hauzenberger, Florian Huber, Karin Klieber, Massimiliano Marcellino</dc:creator>
    </item>
    <item>
      <title>Uncertain Short-Run Restrictions and Statistically Identified Structural Vector Autoregressions</title>
      <link>https://arxiv.org/abs/2303.13281</link>
      <description>arXiv:2303.13281v2 Announce Type: replace 
Abstract: This study proposes a combination of a statistical identification approach with potentially invalid short-run zero restrictions. The estimator shrinks towards imposed restrictions and stops shrinkage when the data provide evidence against a restriction. Simulation results demonstrate how incorporating valid restrictions through the shrinkage approach enhances the accuracy of the statistically identified estimator and how the impact of invalid restrictions decreases with the sample size. The estimator is applied to analyze the interaction between the stock and oil market. The results indicate that incorporating stock market data into the analysis is crucial, as it enables the identification of information shocks, which are shown to be important drivers of the oil price.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13281v2</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sascha A. Keweloh</dc:creator>
    </item>
    <item>
      <title>Estimating Treatment Effects using Multiple Surrogates: The Role of the Surrogate Score and the Surrogate Index</title>
      <link>https://arxiv.org/abs/1603.09326</link>
      <description>arXiv:1603.09326v4 Announce Type: replace-cross 
Abstract: Estimating the long-term effects of treatments is of interest in many fields. A common challenge in estimating such treatment effects is that long-term outcomes are unobserved in the time frame needed to make policy decisions. One approach to overcome this missing data problem is to analyze treatments effects on an intermediate outcome, often called a statistical surrogate, if it satisfies the condition that treatment and outcome are independent conditional on the statistical surrogate. The validity of the surrogacy condition is often controversial. Here we exploit that fact that in modern datasets, researchers often observe a large number, possibly hundreds or thousands, of intermediate outcomes, thought to lie on or close to the causal chain between the treatment and the long-term outcome of interest. Even if none of the individual proxies satisfies the statistical surrogacy criterion by itself, using multiple proxies can be useful in causal inference. We focus primarily on a setting with two samples, an experimental sample containing data about the treatment indicator and the surrogates and an observational sample containing information about the surrogates and the primary outcome. We state assumptions under which the average treatment effect be identified and estimated with a high-dimensional vector of proxies that collectively satisfy the surrogacy assumption, and derive the bias from violations of the surrogacy assumption, and show that even if the primary outcome is also observed in the experimental sample, there is still information to be gained from using surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:1603.09326v4</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Susan Athey, Raj Chetty, Guido Imbens, Hyunseung Kang</dc:creator>
    </item>
    <item>
      <title>Switchback Experiments under Geometric Mixing</title>
      <link>https://arxiv.org/abs/2209.00197</link>
      <description>arXiv:2209.00197v3 Announce Type: replace-cross 
Abstract: The switchback is an experimental design that measures treatment effects by repeatedly turning an intervention on and off for a whole system. Switchback experiments are a robust way to overcome cross-unit spillover effects; however, they are vulnerable to bias from temporal carryovers. In this paper, we consider properties of switchback experiments in Markovian systems that mix at a geometric rate. We find that, in this setting, standard switchback designs suffer considerably from carryover bias: Their estimation error decays as $T^{-1/3}$ in terms of the experiment horizon $T$, whereas in the absence of carryovers a faster rate of $T^{-1/2}$ would have been possible. We also show, however, that judicious use of burn-in periods can considerably improve the situation, and enables errors that decay as $\log(T)^{1/2}T^{-1/2}$. Our formal results are mirrored in an empirical evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.00197v3</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Hu, Stefan Wager</dc:creator>
    </item>
    <item>
      <title>A Double Machine Learning Approach to Combining Experimental and Observational Data</title>
      <link>https://arxiv.org/abs/2307.01449</link>
      <description>arXiv:2307.01449v2 Announce Type: replace-cross 
Abstract: Experimental and observational studies often lack validity due to untestable assumptions. We propose a double machine learning approach to combine experimental and observational studies, allowing practitioners to test for assumption violations and estimate treatment effects consistently. Our framework tests for violations of external validity and ignorability under milder assumptions. When only one of these assumptions is violated, we provide semiparametrically efficient treatment effect estimators. However, our no-free-lunch theorem highlights the necessity of accurately identifying the violated assumption for consistent treatment effect estimation. Through comparative analyses, we show our framework's superiority over existing data fusion methods. The practical utility of our approach is further exemplified by three real-world case studies, underscoring its potential for widespread application in empirical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01449v2</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Harsh Parikh, Marco Morucci, Vittorio Orlandi, Sudeepa Roy, Cynthia Rudin, Alexander Volfovsky</dc:creator>
    </item>
  </channel>
</rss>
