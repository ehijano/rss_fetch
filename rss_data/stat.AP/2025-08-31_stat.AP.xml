<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Sep 2025 04:01:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Re-Examining the Statistical Methodology and Onomastic Claims of Gregor and Blais' Argument from Name Popularity</title>
      <link>https://arxiv.org/abs/2508.21150</link>
      <description>arXiv:2508.21150v1 Announce Type: new 
Abstract: In 2024 Gregor and Blais published a JSNT article using two different statistical methods to conclude, contra Bauckham (2017), that selected Apocryphal texts and the Babylonian Talmud "do not correspond to the distribution among first-century Palestinian Jews statistically significantly worse than the distribution in Gospels-Acts" and "the two corpora paradoxically align better in some respects". In this paper, we show that the first method is statistically invalid, and the second is the wrong tool for the job. This is in alignment with the critique of Van de Weghe and Wilson (2024) and in support of their use of the chi-squared goodness-of-fit test which established name occurrences in the Gospels and Acts, as opposed to Gregor and Blais` uniform, apocryphal, or Talmudic corpora, "fit into their historical context at least as well as those in the works of Josephus". Regarding this historical context, helpful insights are provided by Gregor and Blais regarding potential distortions within the onomastic reference distribution, and this article suggests a way forward, addressing orthographic issues, sample biases, several problems with the implementation of Gregor and Blais` inclusion criteria, and 87 new onomastic finds from ossuaries, ostraca, and documentary papyri that need to be incorporated into the lexicon. While legitimate concerns are raised by Gregor and Blais, several problems with their own onomastic datasets are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21150v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jason Wilson, Luuk van de Weghe</dc:creator>
    </item>
    <item>
      <title>Causal Analysis of Health, Education, and Economic Well-Being in India -- Evidence from the Young Lives Survey</title>
      <link>https://arxiv.org/abs/2508.21370</link>
      <description>arXiv:2508.21370v1 Announce Type: new 
Abstract: This study investigates the dynamic and potentially causal relationships among childhood health, education, and long-term economic well-being in India using longitudinal data from the Young Lives Survey. While prior research often examines these domains in isolation, we adopt an integrated empirical framework combining panel data methods, instrumental variable regression, and causal graph analysis to disentangle their interdependencies. Our analysis spans five survey rounds covering two cohorts of children tracked from early childhood to young adulthood. Results indicate strong persistence in household economic status, highlighting limited intergenerational mobility. Education, proxied by Item Response Theory-based mathematics scores, consistently emerges as the most robust predictor of future economic well-being, particularly in the younger cohort. In contrast, self-reported childhood health shows limited direct impact on either education or later wealth, though it is influenced by household economic conditions. These findings underscore the foundational role of wealth and the growing importance of cognitive achievement in shaping life trajectories. The study supports policy approaches that prioritize early investments in learning outcomes alongside targeted economic support for disadvantaged households. By integrating statistical modeling with development policy insights, this research contributes to understanding how early-life conditions shape economic opportunity in low- and middle-income contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21370v1</guid>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anushka De, Diganta Mukherjee</dc:creator>
    </item>
    <item>
      <title>Quantile Function-Based Models for Neuroimaging Classification Using Wasserstein Regression</title>
      <link>https://arxiv.org/abs/2508.21523</link>
      <description>arXiv:2508.21523v1 Announce Type: new 
Abstract: We propose a novel quantile function-based approach for neuroimaging classification using Wasserstein-Fr\'echet regression, specifically applied to the detection of mild traumatic brain injury (mTBI) based on the MEG and MRI data. Conventional neuroimaging classification methods for mTBI detection typically extract summary statistics from brain signals across the different epochs, which may result in the loss of important distributional information, such as variance, skewness, kurtosis, etc. Our approach treats complete probability density functions of epoch space results as functional response variables within a Wasserstein-Fr\'echet regression framework, thereby preserving the full distributional characteristics of epoch results from $L_{1}$ minimum norm solutions. The global Wasserstein-Fr\'echet regression model incorporating covariates (age and gender) allows us to directly compare the distributional patterns between healthy control subjects and mTBI patients. The classification procedure computes Wasserstein distances between estimated quantile functions from control and patient groups, respectively. These distances are then used as the basis for diagnostic decisions. This framework offers a statistically principled approach to improving diagnostic accuracy in mTBI detection. In practical applications, the test accuracy on unseen data from Innovision IP's dataset achieves up to 98\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21523v1</guid>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Li, Gary Green, Jian Zhang</dc:creator>
    </item>
    <item>
      <title>Does Extending Polling Hours Compensate for Bomb Threats? Evidence from the 2024 Election in Georgia, USA</title>
      <link>https://arxiv.org/abs/2508.19442</link>
      <description>arXiv:2508.19442v1 Announce Type: cross 
Abstract: At least 227~bomb threats against polling places and tabulation centers were received on the day of the 2024 US presidential election. Threats disrupted voting in the swing states of Georgia, Arizona, and Pennsylvania while law enforcement swept polling places. No bombs were found. Roughly a dozen `credible' threats were received in Georgia in DeKalb and Fulton counties, interrupting voting at eleven polling locations; there were dozens of `non-credible' threats in addition. To remediate the effect of the temporary closures of polling places, courts ordered some polling places to remain open late. Nonparametric statistical tests using turnout data from 2020 and 2024 show that this remedy may have been inadequate: in DeKalb, 2024 in-person turnout in precincts closed by threats relative to 2020 turnout in the same precincts was suppressed compared to other DeKalb polling places ($P \approx 0.01$). In Fulton, there is no statistical evidence that in-person voting was suppressed in precincts closed by bomb threats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19442v1</guid>
      <category>physics.soc-ph</category>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sequoia Andrade, Philip Stark</dc:creator>
    </item>
    <item>
      <title>Detection of collective and point anomalies at the presence of trend and seasonality</title>
      <link>https://arxiv.org/abs/2508.21128</link>
      <description>arXiv:2508.21128v1 Announce Type: cross 
Abstract: Detecting anomalies in time series data is a challenging task with broad relevance in many applications. Existing methods work effectively only under idealized conditions, typically focusing on point anomalies or assuming a constant baseline. Our approach overcomes these limitations by detecting both collective and point anomalies, while allowing for polynomial trends and seasonal patterns. We establish statistical theory demonstrating that our method accurately decomposes the time series into anomaly, trend, seasonality, and a remainder component. We further show that it estimates the number of anomalies consistently and their locations with minimal error. Simulation studies confirm its strong detection performance with finite samples, and an application to energy price data illustrates its practical utility. An R package is available on request.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21128v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiyin Zhang, Florian Pein, Idris Eckley</dc:creator>
    </item>
    <item>
      <title>Population-Scale Network Embeddings Expose Educational Divides in Network Structure Related to Right-Wing Populist Voting</title>
      <link>https://arxiv.org/abs/2508.21236</link>
      <description>arXiv:2508.21236v1 Announce Type: cross 
Abstract: Administrative registry data can be used to construct population-scale networks whose ties reflect shared social contexts between persons. With machine learning, such networks can be encoded into numerical representations -- embeddings -- that automatically capture individuals' position within the network. We created embeddings for all persons in the Dutch population from a population-scale network that represents five shared contexts: neighborhood, work, family, household, and school. To assess the informativeness of these embeddings, we used them to predict right-wing populist voting. Embeddings alone predicted right-wing populist voting above chance-level but performed worse than individual characteristics. Combining the best subset of embeddings with individual characteristics only slightly improved predictions. However, after transforming the embeddings to make their dimensions more sparse and orthogonal, we found that one embedding dimension was strongly associated with the outcome. Mapping this dimension back to the population network revealed differences in network structure related to right-wing populist voting between different school ties and achieved education levels. Our study contributes methodologically by demonstrating how population-scale network embeddings can be made interpretable, and substantively by linking structural network differences in education to right-wing populist voting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21236v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Malte L\"uken (Netherlands eScience Center, University of Amsterdam, Erasmus University Rotterdam), Javier Garcia-Bernardo (Utrecht University), Sreeparna Deb (Delft University of Technology), Flavio Hafner (Netherlands eScience Center, Erasmus University Rotterdam), Megha Khosla (Delft University of Technology)</dc:creator>
    </item>
    <item>
      <title>DynaMark: A Reinforcement Learning Framework for Dynamic Watermarking in Industrial Machine Tool Controllers</title>
      <link>https://arxiv.org/abs/2508.21797</link>
      <description>arXiv:2508.21797v1 Announce Type: cross 
Abstract: Industry 4.0's highly networked Machine Tool Controllers (MTCs) are prime targets for replay attacks that use outdated sensor data to manipulate actuators. Dynamic watermarking can reveal such tampering, but current schemes assume linear-Gaussian dynamics and use constant watermark statistics, making them vulnerable to the time-varying, partly proprietary behavior of MTCs. We close this gap with DynaMark, a reinforcement learning framework that models dynamic watermarking as a Markov decision process (MDP). It learns an adaptive policy online that dynamically adapts the covariance of a zero-mean Gaussian watermark using available measurements and detector feedback, without needing system knowledge. DynaMark maximizes a unique reward function balancing control performance, energy consumption, and detection confidence dynamically. We develop a Bayesian belief updating mechanism for real-time detection confidence in linear systems. This approach, independent of specific system assumptions, underpins the MDP for systems with linear dynamics. On a Siemens Sinumerik 828D controller digital twin, DynaMark achieves a reduction in watermark energy by 70% while preserving the nominal trajectory, compared to constant variance baselines. It also maintains an average detection delay equivalent to one sampling interval. A physical stepper-motor testbed validates these findings, rapidly triggering alarms with less control performance decline and exceeding existing benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21797v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Navid Aftabi, Abhishek Hanchate, Satish Bukkapatnam, Dan Li</dc:creator>
    </item>
    <item>
      <title>COBRA-PPM: A Causal Bayesian Reasoning Architecture Using Probabilistic Programming for Robot Manipulation Under Uncertainty</title>
      <link>https://arxiv.org/abs/2403.14488</link>
      <description>arXiv:2403.14488v4 Announce Type: replace-cross 
Abstract: Manipulation tasks require robots to reason about cause and effect when interacting with objects. Yet, many data-driven approaches lack causal semantics and thus only consider correlations. We introduce COBRA-PPM, a novel causal Bayesian reasoning architecture that combines causal Bayesian networks and probabilistic programming to perform interventional inference for robot manipulation under uncertainty. We demonstrate its capabilities through high-fidelity Gazebo-based experiments on an exemplar block stacking task, where it predicts manipulation outcomes with high accuracy (Pred Acc: 88.6%) and performs greedy next-best action selection with a 94.2% task success rate. We further demonstrate sim2real transfer on a domestic robot, showing effectiveness in handling real-world uncertainty from sensor noise and stochastic actions. Our generalised and extensible framework supports a wide range of manipulation scenarios and lays a foundation for future work at the intersection of robotics and causality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14488v4</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Cannizzaro, Michael Groom, Jonathan Routley, Robert Osazuwa Ness, Lars Kunze</dc:creator>
    </item>
    <item>
      <title>A Hybrid Artificial Intelligence Method for Estimating Flicker in Power Systems</title>
      <link>https://arxiv.org/abs/2506.13611</link>
      <description>arXiv:2506.13611v3 Announce Type: replace-cross 
Abstract: This paper introduces a novel hybrid AI method combining H filtering and an adaptive linear neuron network for flicker component estimation in power distribution systems.The proposed method leverages the robustness of the H filter to extract the voltage envelope under uncertain and noisy conditions followed by the use of ADALINE to accurately identify flicker frequencies embedded in the envelope.This synergy enables efficient time domain estimation with rapid convergence and noise resilience addressing key limitations of existing frequency domain approaches.Unlike conventional techniques this hybrid AI model handles complex power disturbances without prior knowledge of noise characteristics or extensive training.To validate the method performance we conduct simulation studies based on IEC Standard 61000 4 15 supported by statistical analysis Monte Carlo simulations and real world data.Results demonstrate superior accuracy robustness and reduced computational load compared to Fast Fourier Transform and Discrete Wavelet Transform based estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13611v3</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>stat.AP</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javad Enayati, Pedram Asef, Alexandre Benoit</dc:creator>
    </item>
    <item>
      <title>Robustness is Important: Limitations of LLMs for Data Fitting</title>
      <link>https://arxiv.org/abs/2508.19563</link>
      <description>arXiv:2508.19563v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) are being applied in a wide array of settings, well beyond the typical language-oriented use cases. In particular, LLMs are increasingly used as a plug-and-play method for fitting data and generating predictions. Prior work has shown that LLMs, via in-context learning or supervised fine-tuning, can perform competitively with many tabular supervised learning techniques in terms of predictive performance. However, we identify a critical vulnerability of using LLMs for data fitting -- making changes to data representation that are completely irrelevant to the underlying learning task can drastically alter LLMs' predictions on the same data. For example, simply changing variable names can sway the size of prediction error by as much as 82% in certain settings. Such prediction sensitivity with respect to task-irrelevant variations manifests under both in-context learning and supervised fine-tuning, for both close-weight and open-weight general-purpose LLMs. Moreover, by examining the attention scores of an open-weight LLM, we discover a non-uniform attention pattern: training examples and variable names/values which happen to occupy certain positions in the prompt receive more attention when output tokens are generated, even though different positions are expected to receive roughly the same attention. This partially explains the sensitivity in the presence of task-irrelevant variations. We also consider a state-of-the-art tabular foundation model (TabPFN) trained specifically for data fitting. Despite being explicitly designed to achieve prediction robustness, TabPFN is still not immune to task-irrelevant variations. Overall, despite LLMs' impressive predictive capabilities, currently they lack even the basic level of robustness to be used as a principled data-fitting tool.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19563v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Mon, 01 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hejia Liu, Mochen Yang, Gediminas Adomavicius</dc:creator>
    </item>
  </channel>
</rss>
