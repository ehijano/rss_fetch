<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 01:49:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>IntrinsicTimescales.jl: A Julia package to estimate intrinsic (neural) timescales (INTs) from time-series data</title>
      <link>https://arxiv.org/abs/2505.11507</link>
      <description>arXiv:2505.11507v1 Announce Type: new 
Abstract: IntrinsicTimescales.jl is a Julia package to perform estimation of intrinsic neural timescales (INTs). INTs are defined as the time window in which prior information from an ongoing stimulus can affect the processing of newly arriving information. INTs are estimated either from the autocorrelation function (ACF) or the power spectral density (PSD) of time-series data. In addition to the model-free estimates of INTs, IntrinsicTimescales.jl offers implementations of novel techniques of timescale estimation via performing parameter estimation of an Ornstein-Uhlenbeck process with adaptive approximate Bayesian computation (aABC) and automatic differentiation variational inference (ADVI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11507v1</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasir Catal, Georg Northoff</dc:creator>
    </item>
    <item>
      <title>BrainNetMLP: An Efficient and Effective Baseline for Functional Brain Network Classification</title>
      <link>https://arxiv.org/abs/2505.11538</link>
      <description>arXiv:2505.11538v1 Announce Type: new 
Abstract: Recent studies have made great progress in functional brain network classification by modeling the brain as a network of Regions of Interest (ROIs) and leveraging their connections to understand brain functionality and diagnose mental disorders. Various deep learning architectures, including Convolutional Neural Networks, Graph Neural Networks, and the recent Transformer, have been developed. However, despite the increasing complexity of these models, the performance gain has not been as salient. This raises a question: Does increasing model complexity necessarily lead to higher classification accuracy? In this paper, we revisit the simplest deep learning architecture, the Multi-Layer Perceptron (MLP), and propose a pure MLP-based method, named BrainNetMLP, for functional brain network classification, which capitalizes on the advantages of MLP, including efficient computation and fewer parameters. Moreover, BrainNetMLP incorporates a dual-branch structure to jointly capture both spatial connectivity and spectral information, enabling precise spatiotemporal feature fusion. We evaluate our proposed BrainNetMLP on two public and popular brain network classification datasets, the Human Connectome Project (HCP) and the Autism Brain Imaging Data Exchange (ABIDE). Experimental results demonstrate pure MLP-based methods can achieve state-of-the-art performance, revealing the potential of MLP-based models as more efficient yet effective alternatives in functional brain network classification. The code will be available at https://github.com/JayceonHo/BrainNetMLP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11538v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiacheng Hou, Zhenjie Song, Ercan Engin Kuruoglu</dc:creator>
    </item>
    <item>
      <title>Learning High-Order Relationships with Hypergraph Attention-based Spatio-Temporal Aggregation for Brain Disease Analysis</title>
      <link>https://arxiv.org/abs/2505.12068</link>
      <description>arXiv:2505.12068v1 Announce Type: new 
Abstract: Traditional functional connectivity based on functional magnetic resonance imaging (fMRI) can only capture pairwise interactions between brain regions. Hypergraphs, which reveal high-order relationships among multiple brain regions, have been widely used for disease analysis. However, existing methods often rely on predefined hypergraph structures, limiting their ability to model complex patterns. Moreover, temporal information, an essential component of brain high-order relationships, is frequently overlooked. To address these limitations, we propose a novel framework that jointly learns informative and sparse high-order brain structures along with their temporal dynamics. Inspired by the information bottleneck principle, we introduce an objective that maximizes information and minimizes redundancy, aiming to retain disease-relevant high-order features while suppressing irrelevant signals. Our model comprises a multi-hyperedge binary mask module for hypergraph structure learning, a hypergraph self-attention aggregation module that captures spatial features through adaptive attention across nodes and hyperedges, and a spatio-temporal low-dimensional network for extracting discriminative spatio-temporal representations for disease classification. Experiments on benchmark fMRI datasets demonstrate that our method outperforms the state-of-the-art approaches and successfully identifies meaningful high-order brain interactions. These findings provide new insights into brain network modeling and the study of neuropsychiatric disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12068v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenqi Hu, Xuerui Su, Guanliang Li, Yidi Pan, Aijing Lin</dc:creator>
    </item>
    <item>
      <title>Development of a non-wearable support robot capable of reproducing natural standing-up movements</title>
      <link>https://arxiv.org/abs/2505.12525</link>
      <description>arXiv:2505.12525v1 Announce Type: new 
Abstract: To reproduce natural standing-up motion, recent studies have emphasized the importance of coordination between the assisting robot and the human. However, many non-wearable assistive devices have struggled to replicate natural motion trajectories. While wearable devices offer better coordination with the human body, they present challenges in completely isolating mechanical and electrical hazards. To address this, we developed a novel standing-assist robot that integrates features of both wearable and non-wearable systems, aiming to achieve high coordination while maintaining safety. The device employs a four-link mechanism aligned with the human joint structure, designed to reproduce the S-shaped trajectory of the hip and the arc trajectory of the knee during natural standing-up motion. Subject-specific trajectory data were obtained using a gyroscope, and the link lengths were determined to drive the seat along the optimal path. A feedforward speed control using a stepping motor was implemented, and the reproducibility of the trajectory was evaluated based on the geometric constraints of the mechanism. A load-bearing experiment with weights fixed to the seat was conducted to assess the trajectory accuracy under different conditions. Results showed that the reproduction errors for the hip and knee trajectories remained within approximately 4 percent of the seat's total displacement, demonstrating high fidelity to the target paths. In addition, durability testing, thermal safety evaluation, and risk assessment confirmed the reliability and safety of the system for indoor use. These findings suggest that the proposed design offers a promising approach for developing assistive technologies that adapt to individual physical characteristics, with potential applications in elderly care and rehabilitation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12525v1</guid>
      <category>q-bio.NC</category>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Atsuya Kusui, Susumu Hirai, Asuka Takai</dc:creator>
    </item>
    <item>
      <title>High-dimensional structure underlying individual differences in naturalistic visual experience</title>
      <link>https://arxiv.org/abs/2505.12653</link>
      <description>arXiv:2505.12653v1 Announce Type: new 
Abstract: How do different brains create unique visual experiences from identical sensory input? While neural representations vary across individuals, the fundamental architecture underlying these differences remains poorly understood. Here, we reveal that individual visual experience emerges from a high-dimensional neural geometry across the visual cortical hierarchy. Using spectral decomposition of fMRI responses during naturalistic movie viewing, we find that idiosyncratic neural patterns persist across multiple orders of magnitude of latent dimensions. Remarkably, each dimensional range encodes qualitatively distinct aspects of individual processing, and this multidimensional neural geometry predicts subsequent behavioral differences in memory recall. These fine-grained patterns of inter-individual variability cannot be reduced to those detected by conventional intersubject correlation measures. Our findings demonstrate that subjective visual experience arises from information integrated across an expansive multidimensional manifold. This geometric framework offers a powerful new lens for understanding how diverse brains construct unique perceptual worlds from shared experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12653v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chihye Han, Michael F. Bonner</dc:creator>
    </item>
    <item>
      <title>Feedback-Driven Dynamical Model for Axonal Extension on Parallel Micropatterns</title>
      <link>https://arxiv.org/abs/2505.13361</link>
      <description>arXiv:2505.13361v1 Announce Type: new 
Abstract: Despite significant advances in understanding neuronal development, a fully quantitative framework that integrates intracellular mechanisms with environmental cues during axonal growth remains incomplete. Here, we present a unified biophysical model that captures key mechanochemical processes governing axonal extension on micropatterned substrates. In these environments, axons preferentially align with the pattern direction, form bundles, and advance at constant speed. The model integrates four core components: (i) actin-adhesion traction coupling, (ii) lateral inhibition between neighboring axons, (iii) tubulin transport from soma to the growth cone, and (4) orientation dynamics guided by the substrate anisotropy. Dynamical systems analysis reveals that the saddle-node bifurcation in the actin adhesion subsystem drives a transition to a high-traction motile state, while traction feedback shifts a pitchfork bifurcation in the signaling loop, promoting symmetry breaking and robust alignment. An exact linear solution in the tubulin transport subsystem functions as a built-in speed regulator, ensuring stable elongation rates. Simulations using experimentally inferred parameters accurately reproduce elongation speed, alignment variance, and bundle spacing. The model provides explicit design rules for enhancing axonal alignment through modulation of substrate stiffness and adhesion dynamics. By identifying key control parameters, this work enables rational design of biomaterials for neural repair and engineered tissue systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13361v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <category>q-bio.CB</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kyle Cheng, Udathari Kumarasinghe, Cristian Staii</dc:creator>
    </item>
    <item>
      <title>Self-consciousness and personal identity in quantum panprotopsychism</title>
      <link>https://arxiv.org/abs/2505.11530</link>
      <description>arXiv:2505.11530v1 Announce Type: cross 
Abstract: In previous papers, we demonstrated that an ontology of quantum mechanics, described in terms of states and events with internal phenomenal aspects (a form of panprotopsychism), is well suited to explain consciousness. We showed that the combination problems of qualities, structures and subjects in panpsychism and panprotopsychism stem from implicit hypotheses based on classical physics regarding supervenience, which are not applicable at the quantum level. Within this view, consciousness arises in entangled quantum systems coupled to the neural network of the brain. In entangled systems, the properties of individual parts disappear, giving rise to an exponential number of emergent properties and states. Here, we analyze self-consciousness as the capacity to view oneself as a subject of experience. The causal openness of quantum systems provides self-conscious beings the ability to make independent choices and decisions, reflecting a sense of self-governance and autonomy. In this context, the issue of personal identity takes a new form free from the problems of the simple view or the reductive approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11530v1</guid>
      <category>physics.hist-ph</category>
      <category>q-bio.NC</category>
      <category>quant-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rodolfo Gambini, Jorge Pullin</dc:creator>
    </item>
    <item>
      <title>Of Mice and Machines: A Comparison of Learning Between Real World Mice and RL Agents</title>
      <link>https://arxiv.org/abs/2505.12204</link>
      <description>arXiv:2505.12204v1 Announce Type: cross 
Abstract: Recent advances in reinforcement learning (RL) have demonstrated impressive capabilities in complex decision-making tasks. This progress raises a natural question: how do these artificial systems compare to biological agents, which have been shaped by millions of years of evolution? To help answer this question, we undertake a comparative study of biological mice and RL agents in a predator-avoidance maze environment. Through this analysis, we identify a striking disparity: RL agents consistently demonstrate a lack of self-preservation instinct, readily risking ``death'' for marginal efficiency gains. These risk-taking strategies are in contrast to biological agents, which exhibit sophisticated risk-assessment and avoidance behaviors. Towards bridging this gap between the biological and artificial, we propose two novel mechanisms that encourage more naturalistic risk-avoidance behaviors in RL agents. Our approach leads to the emergence of naturalistic behaviors, including strategic environment assessment, cautious path planning, and predator avoidance patterns that closely mirror those observed in biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12204v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuo Han, German Espinosa, Junda Huang, Daniel A. Dombeck, Malcolm A. MacIver, Bradly C. Stadie</dc:creator>
    </item>
    <item>
      <title>Neural Thermodynamics I: Entropic Forces in Deep and Universal Representation Learning</title>
      <link>https://arxiv.org/abs/2505.12387</link>
      <description>arXiv:2505.12387v1 Announce Type: cross 
Abstract: With the rapid discovery of emergent phenomena in deep learning and large language models, explaining and understanding their cause has become an urgent need. Here, we propose a rigorous entropic-force theory for understanding the learning dynamics of neural networks trained with stochastic gradient descent (SGD) and its variants. Building on the theory of parameter symmetries and an entropic loss landscape, we show that representation learning is crucially governed by emergent entropic forces arising from stochasticity and discrete-time updates. These forces systematically break continuous parameter symmetries and preserve discrete ones, leading to a series of gradient balance phenomena that resemble the equipartition property of thermal systems. These phenomena, in turn, (a) explain the universal alignment of neural representations between AI models and lead to a proof of the Platonic Representation Hypothesis, and (b) reconcile the seemingly contradictory observations of sharpness- and flatness-seeking behavior of deep learning optimization. Our theory and experiments demonstrate that a combination of entropic forces and symmetry breaking is key to understanding emergent phenomena in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12387v1</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liu Ziyin, Yizhou Xu, Isaac Chuang</dc:creator>
    </item>
    <item>
      <title>Recombinant dynamical systems</title>
      <link>https://arxiv.org/abs/2505.13409</link>
      <description>arXiv:2505.13409v1 Announce Type: cross 
Abstract: We describe a connectionist model that attempts to capture a notion of experience-based problem solving or task learning, whereby solutions to newly encountered problems are composed from remembered solutions to prior problems. We apply this model to the computational problem of \emph{efficient sequence generation}, a problem for which there is no obvious gradient descent procedure, and for which not all posable problem instances are solvable. Empirical tests show promising evidence of utility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13409v1</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Saul Kato</dc:creator>
    </item>
    <item>
      <title>How EEG preprocessing shapes decoding performance</title>
      <link>https://arxiv.org/abs/2410.14453</link>
      <description>arXiv:2410.14453v4 Announce Type: replace 
Abstract: EEG preprocessing varies widely between studies, but its impact on classification performance remains poorly understood. To address this gap, we analyzed seven experiments with 40 participants drawn from the public ERP CORE dataset. We systematically varied key preprocessing steps, such as filtering, referencing, baseline interval, detrending, and multiple artifact correction steps. Then we performed trial-wise binary classification (i.e., decoding) using neural networks (EEGNet), or time-resolved logistic regressions. Our findings demonstrate that preprocessing choices influenced decoding performance considerably. All artifact correction steps reduced decoding performance across experiments and models, while higher high-pass filter cutoffs consistently increased decoding performance. For EEGNet, baseline correction further increased decoding performance, and for time-resolved classifiers, linear detrending, and lower low-pass filter cutoffs increased decoding performance. The influence of other preprocessing choices was specific for each experiment or event-related potential component. The current results underline the importance of carefully selecting preprocessing steps for EEG-based decoding. While uncorrected artifacts may increase decoding performance, this comes at the expense of interpretability and model validity, as the model may exploit structured noise rather than the neural signal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14453v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roman Kessler, Alexander Enge, Michael A. Skeide</dc:creator>
    </item>
    <item>
      <title>Homogenized $\textit{C. elegans}$ Neural Activity and Connectivity Data</title>
      <link>https://arxiv.org/abs/2411.12091</link>
      <description>arXiv:2411.12091v4 Announce Type: replace 
Abstract: There is renewed interest in modeling and understanding the nervous system of the nematode $\textit{Caenorhabditis elegans}$ ($\textit{C. elegans}$), as this small model system provides a path to bridge the gap between nervous system structure (connectivity) and function (physiology). However, existing physiology datasets, whether involving passive recording or stimulation, are in distinct formats, and connectome datasets require preprocessing before analysis can commence. Here we compile and homogenize datasets of neural activity and connectivity. Our neural activity dataset is derived from 12 $\textit{C. elegans}$ neuroimaging experiments, while our connectivity dataset is compiled from 9 connectome annotations based on 3 primary electron microscopy studies and 1 signal propagation study. Physiology datasets, collected under varying protocols, measure calcium fluorescence in labeled subsets of the worm's 300 neurons. Our preprocessing pipeline standardizes these datasets by consistently ordering labeled neurons and resampling traces to a common sampling rate, yielding recordings from approximately 900 worms and 250 uniquely labeled neurons. The connectome datasets, collected from electron microscopy reconstructions, represent the entire nervous system as a graph of connections. Our collection is accessible on HuggingFace, facilitating analysis of the structure-function relationship in biology using modern neural network architectures and enabling cross-lab and cross-animal comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12091v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Quilee Simeon, Anshul Kashyap, Konrad P Kording, Edward S Boyden</dc:creator>
    </item>
    <item>
      <title>Artificial Neural Networks for Magnetoencephalography: A review of an emerging field</title>
      <link>https://arxiv.org/abs/2501.11566</link>
      <description>arXiv:2501.11566v4 Announce Type: replace 
Abstract: Magnetoencephalography (MEG) is a cutting-edge neuroimaging technique that measures the intricate brain dynamics underlying cognitive processes with an unparalleled combination of high temporal and spatial precision. MEG data analytics has always relied on advanced signal processing and mathematical and statistical tools for various tasks ranging from data cleaning to probing the signals' rich dynamics and estimating the neural sources underlying the surface-level recordings. Like in most domains, the surge in Artificial Intelligence (AI) has led to the increased use of Machine Learning (ML) methods for MEG data classification. More recently, an emerging trend in this field is using Artificial Neural Networks (ANNs) to address many MEG-related tasks. This review provides a comprehensive overview of how ANNs are being used with MEG data from three vantage points: First, we review work that employs ANNs for MEG signal classification, i.e., for brain decoding. Second, we report on work that has used ANNs as putative models of information processing in the human brain. Finally, we examine studies that use ANNs as techniques to tackle methodological questions in MEG, including artifact correction and source estimation. Furthermore, we assess the current strengths and limitations of using ANNs with MEG and discuss future challenges and opportunities in this field. Finally, by establishing a detailed portrait of the field and providing practical recommendations for the future, this review seeks to provide a helpful reference for both seasoned MEG researchers and newcomers to the field who are interested in using ANNs to enhance the exploration of the complex dynamics of the human brain with MEG.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11566v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arthur Dehgan, Hamza Abdelhedi, Vanessa Hadid, Irina Rish, Karim Jerbi</dc:creator>
    </item>
    <item>
      <title>From Bedside to Desktop: A Data Protocol for Normative Intracranial EEG and Abnormality Mapping</title>
      <link>https://arxiv.org/abs/2502.04460</link>
      <description>arXiv:2502.04460v2 Announce Type: replace 
Abstract: Normative mapping is a framework used to map population-level features of health-related variables. It is widely used in neuroscience research, but the literature lacks established protocols in modalities that do not support healthy control measurements, such as intracranial EEG (icEEG). An icEEG normative map would allow researchers to learn about population-level brain activity and enable comparison of individual data against these norms to identify abnormalities. Currently, no standardised guide exists for transforming clinical data into a normative, regional icEEG map. Papers often cite different software and numerous articles to summarise the lengthy method, making it laborious for other researchers to understand or apply the process. Our protocol seeks to remedy this gap by providing a dataflow guide and key decision points that summarise existing methods. This protocol is used heavily in published works from our own lab (twelve peer-reviewed journal publications). Briefly, we take as input, icEEG recordings and neuroimaging data from people with epilepsy who are undergoing evaluation for resective surgery. As final outputs, we obtain a normative icEEG map, comprising signal properties localised to brain regions. Optionally, we can also process new subjects through the same pipeline and obtain their z-scores (or centiles) in each brain region, for abnormality detection and localisation. To date, a single, cohesive, dataflow pipeline for generating normative icEEG maps, along with abnormality mapping, has not been created. We envisage that this dataflow guide will not only increase understanding and application of normative mapping methods, but will also improve the consistency and quality of studies in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04460v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heather Woodhouse, Sarah J. Gascoigne, Gerard Hall, Callum Simpson, Nathan Evans, Gabrielle M. Schroeder, Peter N. Taylor, Yujiang Wang</dc:creator>
    </item>
    <item>
      <title>BrainPrompt: Multi-Level Brain Prompt Enhancement for Neurological Condition Identification</title>
      <link>https://arxiv.org/abs/2504.16096</link>
      <description>arXiv:2504.16096v2 Announce Type: replace 
Abstract: Neurological conditions, such as Alzheimer's Disease, are challenging to diagnose, particularly in the early stages where symptoms closely resemble healthy controls. Existing brain network analysis methods primarily focus on graph-based models that rely solely on imaging data, which may overlook important non-imaging factors and limit the model's predictive power and interpretability. In this paper, we present BrainPrompt, an innovative framework that enhances Graph Neural Networks (GNNs) by integrating Large Language Models (LLMs) with knowledge-driven prompts, enabling more effective capture of complex, non-imaging information and external knowledge for neurological disease identification. BrainPrompt integrates three types of knowledge-driven prompts: (1) ROI-level prompts to encode the identity and function of each brain region, (2) subject-level prompts that incorporate demographic information, and (3) disease-level prompts to capture the temporal progression of disease. By leveraging these multi-level prompts, BrainPrompt effectively harnesses knowledge-enhanced multi-modal information from LLMs, enhancing the model's capability to predict neurological disease stages and meanwhile offers more interpretable results. We evaluate BrainPrompt on two resting-state functional Magnetic Resonance Imaging (fMRI) datasets from neurological disorders, showing its superiority over state-of-the-art methods. Additionally, a biomarker study demonstrates the framework's ability to extract valuable and interpretable information aligned with domain knowledge in neuroscience. The code is available at https://github.com/AngusMonroe/BrainPrompt</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16096v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiaxing Xu, Kai He, Yue Tang, Wei Li, Mengcheng Lan, Xia Dong, Yiping Ke, Mengling Feng</dc:creator>
    </item>
    <item>
      <title>Probing Human Visual Robustness with Neurally-Guided Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2405.02564</link>
      <description>arXiv:2405.02564v2 Announce Type: replace-cross 
Abstract: Humans effortlessly navigate the dynamic visual world, yet deep neural networks (DNNs), despite excelling at many visual tasks, are surprisingly vulnerable to minor image perturbations. Past theories suggest that human visual robustness arises from a representational space that evolves along the ventral visual stream (VVS) of the brain to increasingly tolerate object transformations. To test whether robustness is supported by such progression as opposed to being confined exclusively to specialized higher-order regions, we trained DNNs to align their representations with human neural responses from consecutive VVS regions while performing visual tasks. We demonstrate a hierarchical improvement in DNN robustness: alignment to higher-order VVS regions leads to greater improvement. To investigate the mechanism behind such robustness gains, we test a prominent hypothesis that attributes human robustness to the unique geometry of neural category manifolds in the VVS. We first reveal that more desirable manifold properties, specifically, smaller extent and better linear separability, indeed emerge across the human VVS. These properties can be inherited by neurally aligned DNNs and predict their subsequent robustness gains. Furthermore, we show that supervision from neural manifolds alone, via manifold guidance, is sufficient to qualitatively reproduce the hierarchical robustness improvements. Together, these results highlight the critical role of the evolving representational space across VVS in achieving robust visual inference, in part through the formation of more linearly separable category manifolds, which may in turn be leveraged to develop more robust AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02564v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenan Shao, Linjian Ma, Yiqing Zhou, Yibo Jacky Zhang, Sanmi Koyejo, Bo Li, Diane M. Beck</dc:creator>
    </item>
    <item>
      <title>A Concise Mathematical Description of Active Inference in Discrete Time</title>
      <link>https://arxiv.org/abs/2406.07726</link>
      <description>arXiv:2406.07726v4 Announce Type: replace-cross 
Abstract: In this paper we present a concise mathematical description of active inference in discrete time. The main part of the paper serves as a basic introduction to the topic, including a detailed example of the action selection mechanism. The appendix discusses the more subtle mathematical details, targeting readers who have already studied the active inference literature but struggle to make sense of the mathematical details and derivations. Throughout, we emphasize precise and standard mathematical notation, ensuring consistency with existing texts and linking all equations to widely used references on active inference. Additionally, we provide Python code that implements the action selection and learning mechanisms described in this paper and is compatible with pymdp environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.07726v4</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmp.2025.102921</arxiv:DOI>
      <arxiv:journal_reference>Journal of Mathematical Psychology 125 (2025) 102921</arxiv:journal_reference>
      <dc:creator>Jesse van Oostrum, Carlotta Langer, Nihat Ay</dc:creator>
    </item>
    <item>
      <title>Parametric PerceptNet: A bio-inspired deep-net trained for Image Quality Assessment</title>
      <link>https://arxiv.org/abs/2412.03210</link>
      <description>arXiv:2412.03210v3 Announce Type: replace-cross 
Abstract: Human vision models are at the core of image processing. For instance, classical approaches to the problem of image quality are based on models that include knowledge about human vision. However, nowadays, deep learning approaches have obtained competitive results by simply approaching this problem as regression of human decisions, and training an standard network on human-rated datasets. These approaches have the advantages of being easily adaptable to a particular problem and they fit very efficiently when data is available. However, mainly due to the excess of parameters, they have the problems of lack of interpretability, and over-fitting. Here we propose a vision model that combines the best of both worlds by using a parametric neural network architecture. We parameterize the layers to have bioplausible functionality, and provide a set of bioplausible parameters. We analyzed different versions of the model and compared it with the non-parametric version. The parametric models achieve a three orders of magnitude reduction in the number of parameters without suffering in regression performance. Furthermore, we show that the parametric models behave better during training and are easier to interpret as vision models. Interestingly, we find that, even initialized with bioplausible trained for regression using human rated datasets, which we call the feature-spreading problem. This suggests that the deep learning approach is inherently flawed, and emphasizes the need to evaluate and train models beyond regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03210v3</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jorge Vila-Tom\'as, Pablo Hern\'andez-C\'amara, Valero Laparra, Jes\'us Malo</dc:creator>
    </item>
  </channel>
</rss>
