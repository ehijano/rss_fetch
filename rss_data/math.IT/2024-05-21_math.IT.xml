<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 May 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Low Complexity Successive Cancellation Decoding of Polar Codes based on Pruning Strategy in Deletion Error Channels</title>
      <link>https://arxiv.org/abs/2405.12245</link>
      <description>arXiv:2405.12245v1 Announce Type: new 
Abstract: A novel SC decoding method of polar codes is proposed in $d$-deletion channels, where a new pruning strategy is designed to reduce decoding complexity. Considering the difference of the scenario weight distributions, pruning thresholds for each node are designed separately according to a uniform constraint on the pruning error probability, which further reduce the number of scenarios that need to be calculated during the decoding procedure. In addition, by exploiting the properties of the joint weight distribution, a simplified calculation method of thresholds is proposed. Using this simplified calculation method, the number of scenarios that required to be calculated is reduced from $(d+1)(d+2)/2$ to $d+1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12245v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Sun, Rongke Liu, Bin Dai</dc:creator>
    </item>
    <item>
      <title>Power Measurement Based Channel Estimation for IRS-Enhanced Wireless Coverage</title>
      <link>https://arxiv.org/abs/2405.12432</link>
      <description>arXiv:2405.12432v1 Announce Type: new 
Abstract: In this paper, we study an IRS-assisted coverage enhancement problem for a given region, aiming to optimize the passive reflection of the IRS for improving the average communication performance in the region by accounting for both deterministic and random channels in the environment. To this end, we first derive the closed-form expression of the average received signal power in terms of the deterministic base station (BS)-IRS-user cascaded channels over all user locations, and propose an IRS-aided coverage enhancement framework to facilitate the estimation of such deterministic channels for IRS passive reflection design. Specifically, to avoid the exorbitant overhead of estimating the cascaded channels at all possible user locations, a location selection method is first proposed to select only a set of typical user locations for channel estimation by exploiting the channel spatial correlation in the region. To estimate the deterministic cascaded channels at the selected user locations, conventional IRS channel estimation methods require additional pilot signals, which not only results in high system training overhead but also may not be compatible with the existing communication protocols. To overcome this issue, we further propose a single-layer neural network (NN)-enabled IRS channel estimation method in this paper, based on only the average received signal power measurements at each selected location corresponding to different IRS random training reflections, which can be offline implemented in current wireless systems. Numerical results demonstrate that our proposed scheme can significantly improve the coverage performance of the target region and outperform the existing power-measurement-based IRS reflection designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12432v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Sun, Lipeng Zhu, Weidong Mei, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>Hierarchical Coded Caching with Low Subpacketization and Coding Delay</title>
      <link>https://arxiv.org/abs/2405.12747</link>
      <description>arXiv:2405.12747v1 Announce Type: new 
Abstract: Coded caching scheme originally proposed by Maddah-Ali and Niesen (MN) considered a broadcast network consisting of a single server connected to a set of users each having a cache memory. Motivated by practical scenarios, Karamchandani \textit{et al.} in [16] proposed a coded caching scheme for a two-layer hierarchical network consisting of a single server connected to multiple mirror sites and each mirror site connected to a distinct set of users, in which both mirror sites and users having cache memories. Low subpacketization level coded caching schemes are desirable for practical implementations. Placement delivery array (PDA) was proposed as a tool to design coded caching schemes with reduced subpacketization level by Yan \textit{et al.} in [4]. Schemes with reduced subpacketization levels are studied extensively in the literature for single-layer networks. Kong \textit{et al.} in [17] proposed a structure called hierarchical placement delivery arrays (HPDA), which characterizes a hierarchical coded caching system and also proposed a class of HPDAs that gives low subpacketization level schemes by using two PDAs. Low subpacketization level hierarchical schemes using combinatorial $t$-designs is proposed in [20]. Apart from that there is no other existing work that discusses the subpacketization problem in a hierarchical network. This paper proposes a class of HPDA construction that gives low subpacketization level hierarchical coded caching schemes, by first constructing a new class of PDAs. Compared with the existing schemes, in cases where the system parameters and subpacketization level are the same, the proposed hierarchical scheme has a better coding delay. Further, the new class of PDAs constructed either subsumes several known PDA constructions or achieves better transmission load for the same system parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12747v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashid Ummer N. T., B. Sundar Rajan</dc:creator>
    </item>
    <item>
      <title>Continual Deep Reinforcement Learning for Decentralized Satellite Routing</title>
      <link>https://arxiv.org/abs/2405.12308</link>
      <description>arXiv:2405.12308v1 Announce Type: cross 
Abstract: This paper introduces a full solution for decentralized routing in Low Earth Orbit satellite constellations based on continual Deep Reinforcement Learning (DRL). This requires addressing multiple challenges, including the partial knowledge at the satellites and their continuous movement, and the time-varying sources of uncertainty in the system, such as traffic, communication links, or communication buffers. We follow a multi-agent approach, where each satellite acts as an independent decision-making agent, while acquiring a limited knowledge of the environment based on the feedback received from the nearby agents. The solution is divided into two phases. First, an offline learning phase relies on decentralized decisions and a global Deep Neural Network (DNN) trained with global experiences. Then, the online phase with local, on-board, and pre-trained DNNs requires continual learning to evolve with the environment, which can be done in two different ways: (1) Model anticipation, where the predictable conditions of the constellation are exploited by each satellite sharing local model with the next satellite; and (2) Federated Learning (FL), where each agent's model is merged first at the cluster level and then aggregated in a global Parameter Server. The results show that, without high congestion, the proposed Multi-Agent DRL framework achieves the same E2E performance as a shortest-path solution, but the latter assumes intensive communication overhead for real-time network-wise knowledge of the system at a centralized node, whereas ours only requires limited feedback exchange among first neighbour satellites. Importantly, our solution adapts well to congestion conditions and exploits less loaded paths. Moreover, the divergence of models over time is easily tackled by the synergy between anticipation, applied in short-term alignment, and FL, utilized for long-term alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12308v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Lozano-Cuadra, Beatriz Soret, Israel Leyva-Mayorga, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>FAdam: Adam is a natural gradient optimizer using diagonal empirical Fisher information</title>
      <link>https://arxiv.org/abs/2405.12807</link>
      <description>arXiv:2405.12807v1 Announce Type: cross 
Abstract: This paper establishes a mathematical foundation for the Adam optimizer, elucidating its connection to natural gradient descent through Riemannian and information geometry. We rigorously analyze the diagonal empirical Fisher information matrix (FIM) in Adam, clarifying all detailed approximations and advocating for the use of log probability functions as loss, which should be based on discrete distributions, due to the limitations of empirical FIM. Our analysis uncovers flaws in the original Adam algorithm, leading to proposed corrections such as enhanced momentum calculations, adjusted bias corrections, and gradient clipping. We refine the weight decay term based on our theoretical framework. Our modified algorithm, Fisher Adam (FAdam), demonstrates superior performance across diverse domains including LLM, ASR, and VQ-VAE, achieving state-of-the-art results in ASR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12807v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongseong Hwang</dc:creator>
    </item>
    <item>
      <title>Decentralized Federated Learning Over Imperfect Communication Channels</title>
      <link>https://arxiv.org/abs/2405.12894</link>
      <description>arXiv:2405.12894v1 Announce Type: cross 
Abstract: This paper analyzes the impact of imperfect communication channels on decentralized federated learning (D-FL) and subsequently determines the optimal number of local aggregations per training round, adapting to the network topology and imperfect channels. We start by deriving the bias of locally aggregated D-FL models under imperfect channels from the ideal global models requiring perfect channels and aggregations. The bias reveals that excessive local aggregations can accumulate communication errors and degrade convergence. Another important aspect is that we analyze a convergence upper bound of D-FL based on the bias. By minimizing the bound, the optimal number of local aggregations is identified to balance a trade-off with accumulation of communication errors in the absence of knowledge of the channels. With this knowledge, the impact of communication errors can be alleviated, allowing the convergence upper bound to decrease throughout aggregations. Experiments validate our convergence analysis and also identify the optimal number of local aggregations on two widely considered image classification tasks. It is seen that D-FL, with an optimal number of local aggregations, can outperform its potential alternatives by over 10% in training accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12894v1</guid>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weicai Li, Tiejun Lv, Wei Ni, Jingbo Zhao, Ekram Hossain, H. Vincent Poor</dc:creator>
    </item>
    <item>
      <title>Asymptotic analysis of sum-rate under SIC</title>
      <link>https://arxiv.org/abs/2405.12937</link>
      <description>arXiv:2405.12937v1 Announce Type: cross 
Abstract: Limitation of the cost of coordination and contention among a large number of nodes calls for grant-free approaches, exploiting physical layer techniques to solve collisions. Successive Interference Cancellation (SIC) is becoming a key building block of multiple access channel receiver, in an effort to support massive Internet of Things (IoT). In this paper, we explore the large-scale performance of SIC in a theoretical framework. A general model of a SIC receiver is stated for a shared channel with $n$ transmitters. The asymptotic sum-rate performance is characterized as $n \rightarrow \infty$, for a suitably scaled target Signal to Noise Interference Ratio (SNIR). The probability distribution of the number of correctly decoded packets is shown to tend to a deterministic distribution asymptotically for large values of $n$. The asymptotic analysis is carried out for any probability distribution of the wireless channel gain, assuming that the average received power level is same for all nodes, through power control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12937v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Baiocchi, Asmad Razzaque</dc:creator>
    </item>
    <item>
      <title>Optimal preprocessing of WiFi CSI for sensing applications</title>
      <link>https://arxiv.org/abs/2307.12126</link>
      <description>arXiv:2307.12126v2 Announce Type: replace 
Abstract: Due to its ubiquitous and contact-free nature, the use of WiFi infrastructure for performing sensing tasks has tremendous potential. However, the channel state information (CSI) measured by a WiFi receiver suffers from errors in both its gain and phase, which can significantly hinder sensing tasks. By analyzing these errors from different WiFi receivers, a mathematical model for these gain and phase errors is developed in this work. Based on these models, several theoretically justified preprocessing algorithms for correcting such errors at a receiver and, thus, obtaining clean CSI are presented. Simulation results show that at typical system parameters, the developed algorithms for cleaning CSI can reduce noise by $40$% and $200$%, respectively, compared to baseline methods for gain correction and phase correction, without significantly impacting computational cost. The superiority of the proposed methods is also validated in a real-world test bed for respiration rate monitoring (an example sensing task), where they improve the estimation signal-to-noise ratio by $20$% compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12126v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TWC.2024.3376332</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Wireless Communications (2024)</arxiv:journal_reference>
      <dc:creator>Vishnu V. Ratnam (Charlie), Hao Chen (Charlie), Hao Hsuan Chang (Charlie), Abhishek Sehgal (Charlie),  Jianzhong (Charlie),  Zhang</dc:creator>
    </item>
    <item>
      <title>A Transformation of Repairing Reed-Solomon Codes from Rack-Aware Storage Model to Homogeneous Storage Model</title>
      <link>https://arxiv.org/abs/2401.11390</link>
      <description>arXiv:2401.11390v2 Announce Type: replace 
Abstract: In this paper, we address the node repair problem of Reed-Solomon (RS) coded distributed storage systems. Specifically, to overcome the challenges of multiple-node failures of RS codes under the rack-aware storage model, we employ good polynomials to guide the placement of the conventional RS codes into racks and then propose a novel repair framework for the resultant rack-aware RS codes, which can transform its repair to that under the homogeneous storage model. As applications of our repair framework, firstly we present the repair scheme of multiple-node failures for some existing constructions, which only have non-trivial solutions for repairing a single-node failure before. Secondly, we deduce several new constructions of rack-aware RS codes supporting the repair of multiple-node failures within a single rack and across multiple racks respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11390v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yumeng Yang, Han Cai, Xiaohu Tang</dc:creator>
    </item>
    <item>
      <title>An Instance-Based Approach to the Trace Reconstruction Problem</title>
      <link>https://arxiv.org/abs/2401.14277</link>
      <description>arXiv:2401.14277v2 Announce Type: replace 
Abstract: In the trace reconstruction problem, one observes the output of passing a binary string $s \in \{0,1\}^n$ through a deletion channel $T$ times and wishes to recover $s$ from the resulting $T$ "traces." Most of the literature has focused on characterizing the hardness of this problem in terms of the number of traces $T$ needed for perfect reconstruction either in the worst case or in the average case (over input sequences $s$). In this paper, we propose an alternative, instance-based approach to the problem. We define the "Levenshtein difficulty" of a problem instance $(s,T)$ as the probability that the resulting traces do not provide enough information for correct recovery with full certainty. One can then try to characterize, for a specific $s$, how $T$ needs to scale in order for the Levenshtein difficulty to go to zero, and seek reconstruction algorithms that match this scaling for each $s$. For a class of binary strings with alternating long runs, we precisely characterize the scaling of $T$ for which the Levenshtein difficulty goes to zero. For this class, we also prove that a simple "Las Vegas algorithm" has an error probability that decays to zero with the same rate as that with which the Levenshtein difficulty tends to zero.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14277v2</guid>
      <category>cs.IT</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kayvon Mazooji, Ilan Shomorony</dc:creator>
    </item>
    <item>
      <title>Safeguarding Next Generation Multiple Access Using Physical Layer Security Techniques: A Tutorial</title>
      <link>https://arxiv.org/abs/2403.16477</link>
      <description>arXiv:2403.16477v3 Announce Type: replace 
Abstract: Driven by the ever-increasing requirements of ultra-high spectral efficiency, ultra-low latency, and massive connectivity, the forefront of wireless research calls for the design of advanced next generation multiple access schemes to facilitate provisioning of these stringent demands. This inspires the embrace of non-orthogonal multiple access (NOMA) in future wireless communication networks. Nevertheless, the support of massive access via NOMA leads to additional security threats, due to the open nature of the air interface, the broadcast characteristic of radio propagation as well as intertwined relationship among paired NOMA users. To address this specific challenge, the superimposed transmission of NOMA can be explored as new opportunities for security aware design, for example, multiuser interference inherent in NOMA can be constructively engineered to benefit communication secrecy and privacy. The purpose of this tutorial is to provide a comprehensive overview on the state-of-the-art physical layer security techniques that guarantee wireless security and privacy for NOMA networks, along with the opportunities, technical challenges, and future research trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16477v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lu Lv, Dongyang Xu, Rose Qingyang Hu, Yinghui Ye, Long Yang, Xianfu Lei, Xianbin Wang, Dong In Kim, Arumugam Nallanathan</dc:creator>
    </item>
    <item>
      <title>On predicting for non-vanishing continuous time signals</title>
      <link>https://arxiv.org/abs/2405.05566</link>
      <description>arXiv:2405.05566v2 Announce Type: replace 
Abstract: The paper establishes frequency predictability criteria and presents predictors for two-sided non-vanishing bounded continuous time signals, i.e., for signals from $L_{\infty}(\R)$ that do not necessarily vanish at $\pm\infty$. The notions of transfer functions, the spectrum gaps, bandlimitness, and high-pass filters are introduced for these signals. This allowed to obtain some frequency criteria for predictability and predictors for signals with spectrum degeneracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05566v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Dokuchaev</dc:creator>
    </item>
    <item>
      <title>An Efficient Compression Method for Sign Information of DCT Coefficients via Sign Retrieval</title>
      <link>https://arxiv.org/abs/2405.07487</link>
      <description>arXiv:2405.07487v2 Announce Type: replace 
Abstract: Compression of the sign information of discrete cosine transform coefficients is an intractable problem in image compression schemes due to the equiprobable occurrence of the sign bits. To overcome this difficulty, we propose an efficient compression method for such sign information based on phase retrieval, which is a classical signal restoration problem attempting to find the phase information of discrete Fourier transform coefficients from their magnitudes. In our compression strategy, the sign bits of all the AC components in the cosine domain are excluded from a bitstream at the encoder and are complemented at the decoder by solving a sign recovery problem, which we call sign retrieval. The experimental results demonstrate that the proposed method outperforms previous techniques for sign compression in terms of a rate-distortion criterion. Our method implemented in Python language is available from https://github.com/ctsutake/sr.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.07487v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ICIP42928.2021.9506155</arxiv:DOI>
      <arxiv:journal_reference>2021 IEEE International Conference on Image Processing</arxiv:journal_reference>
      <dc:creator>Chihiro Tsutake, Keita Takahashi, Toshiaki Fujii</dc:creator>
    </item>
    <item>
      <title>Operational Interpretation of the Sandwiched R\'enyi Divergence of Order 1/2 to 1 as Strong Converse Exponents</title>
      <link>https://arxiv.org/abs/2209.00554</link>
      <description>arXiv:2209.00554v4 Announce Type: replace-cross 
Abstract: We provide the sandwiched R\'enyi divergence of order $\alpha\in(\frac{1}{2},1)$, as well as its induced quantum information quantities, with an operational interpretation in the characterization of the exact strong converse exponents of quantum tasks. Specifically, we consider (a) smoothing of the max-relative entropy, (b) quantum privacy amplification, and (c) quantum information decoupling. We solve the problem of determining the exact strong converse exponents for these three tasks, with the performance being measured by the fidelity or purified distance. The results are given in terms of the sandwiched R\'enyi divergence of order $\alpha\in(\frac{1}{2},1)$, and its induced quantum R\'enyi conditional entropy and quantum R\'enyi mutual information. This is the first time to find the precise operational meaning for the sandwiched R\'enyi divergence with R\'enyi parameter in the interval $\alpha\in(\frac{1}{2},1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.00554v4</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math-ph</category>
      <category>math.IT</category>
      <category>math.MP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Commun. Math. Phys. 405, 2 (2024)</arxiv:journal_reference>
      <dc:creator>Ke Li, Yongsheng Yao</dc:creator>
    </item>
  </channel>
</rss>
