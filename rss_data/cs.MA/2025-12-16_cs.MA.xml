<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Dec 2025 02:40:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>How AI Agents Follow the Herd of AI? Network Effects, History, and Machine Optimism</title>
      <link>https://arxiv.org/abs/2512.11943</link>
      <description>arXiv:2512.11943v1 Announce Type: new 
Abstract: Understanding decision-making in multi-AI-agent frameworks is crucial for analyzing strategic interactions in network-effect-driven contexts. This study investigates how AI agents navigate network-effect games, where individual payoffs depend on peer participatio--a context underexplored in multi-agent systems despite its real-world prevalence. We introduce a novel workflow design using large language model (LLM)-based agents in repeated decision-making scenarios, systematically manipulating price trajectories (fixed, ascending, descending, random) and network-effect strength. Our key findings include: First, without historical data, agents fail to infer equilibrium. Second, ordered historical sequences (e.g., escalating prices) enable partial convergence under weak network effects but strong effects trigger persistent "AI optimism"--agents overestimate participation despite contradictory evidence. Third, randomized history disrupts convergence entirely, demonstrating that temporal coherence in data shapes LLMs' reasoning, unlike humans. These results highlight a paradigm shift: in AI-mediated systems, equilibrium outcomes depend not just on incentives, but on how history is curated, which is impossible for human.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11943v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Liu, Wenwen Li, Yifan Dou, Guangnan Ye</dc:creator>
    </item>
    <item>
      <title>Beyond Task Completion: An Assessment Framework for Evaluating Agentic AI Systems</title>
      <link>https://arxiv.org/abs/2512.12791</link>
      <description>arXiv:2512.12791v2 Announce Type: new 
Abstract: Recent advances in agentic AI have shifted the focus from standalone Large Language Models (LLMs) to integrated systems that combine LLMs with tools, memory, and other agents to perform complex tasks. These multi-agent architectures enable coordinated reasoning, planning, and execution across diverse domains, allowing agents to collaboratively automate complex workflows. Despite these advances, evaluation and assessment of LLM agents and the multi-agent systems they constitute remain a fundamental challenge. Although various approaches have been proposed in the software engineering literature for evaluating conventional software components, existing methods for AI-based systems often overlook the non-deterministic nature of models. This non-determinism introduces behavioral uncertainty during execution, yet existing evaluations rely on binary task completion metrics that fail to capture it. Evaluating agentic systems therefore requires examining additional dimensions, including the agent ability to invoke tools, ingest and retrieve memory, collaborate with other agents, and interact effectively with its environment. These challenges emerged during our ongoing industry collaboration with MontyCloud Inc., when we deployed an agentic system in production. These limitations surfaced during deployment, highlighting practical gaps in the current evaluation methods and the need for a systematic assessment of agent behavior beyond task outcomes. Informed by these observations and established definitions of agentic systems, we propose an end-to-end Agent Assessment Framework with four evaluation pillars encompassing LLMs, Memory, Tools, and Environment. We validate the framework on a representative Autonomous CloudOps use case, where experiments reveal behavioral deviations overlooked by conventional metrics, demonstrating its effectiveness in capturing runtime uncertainties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12791v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sreemaee Akshathala, Bassam Adnan, Mahisha Ramesh, Karthik Vaidhyanathan, Basil Muhammed, Kannan Parthasarathy</dc:creator>
    </item>
    <item>
      <title>Quantigence: A Multi-Agent AI Framework for Quantum Security Research</title>
      <link>https://arxiv.org/abs/2512.12989</link>
      <description>arXiv:2512.12989v1 Announce Type: new 
Abstract: Cryptographically Relevant Quantum Computers (CRQCs) pose a structural threat to the global digital economy. Algorithms like Shor's factoring and Grover's search threaten to dismantle the public-key infrastructure (PKI) securing sovereign communications and financial transactions. While the timeline for fault-tolerant CRQCs remains probabilistic, the "Store-Now, Decrypt-Later" (SNDL) model necessitates immediate migration to Post-Quantum Cryptography (PQC). This transition is hindered by the velocity of research, evolving NIST standards, and heterogeneous deployment environments. To address this, we present Quantigence, a theory-driven multi-agent AI framework for structured quantum-security analysis. Quantigence decomposes research objectives into specialized roles - Cryptographic Analyst, Threat Modeler, Standards Specialist, and Risk Assessor - coordinated by a supervisory agent. Using "cognitive parallelism," agents reason independently to maintain context purity while execution is serialized on resource-constrained hardware (e.g., NVIDIA RTX 2060). The framework integrates external knowledge via the Model Context Protocol (MCP) and prioritizes vulnerabilities using the Quantum-Adjusted Risk Score (QARS), a formal extension of Mosca's Theorem. Empirical validation shows Quantigence achieves a 67% reduction in research turnaround time and superior literature coverage compared to manual workflows, democratizing access to high-fidelity quantum risk assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12989v1</guid>
      <category>cs.MA</category>
      <category>cs.CR</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdulmalik Alquwayfili</dc:creator>
    </item>
    <item>
      <title>The Optimal Control Algorithm of Connected and Automated Vehicles at Roundabouts with Communication Delay</title>
      <link>https://arxiv.org/abs/2512.13056</link>
      <description>arXiv:2512.13056v1 Announce Type: new 
Abstract: Connected and automated vehicles (CAVs) rely on wireless communication to exchange state information for distributed control, making communication delays a critical factor that can affect vehicle motion and degrade control performance, particularly in high-speed scenarios. To address these challenges in the complex environment of roundabout intersections, this paper proposes a roundabout control algorithm, which takes into account the uncertainty of interactive information caused by time delays. First, to maintain the required distance between the current vehicle and its preceding and following vehicles, conflicting vehicles are identified based on the time-to-collision (TTC) in the conflict zone. To fully consider communication performance, a vehicle motion model incorporating time delays is established. According to the distributed model predictive control (DMPC) mechanism, the vehicle motion control that satisfies the roundabout constraints is determined. Second, by scheduling the sequence of vehicles entering the roundabout, a multiscale optimization objective is developed by integrating vehicle motion indicators and roundabout system indicators. Traffic density and travel time are embedded into the optimization problem to guide vehicles to enter the roundabout safely and stably. Through a variety of simulation experiments, the effectiveness of the proposed control algorithm is verified by comparing its performance with that of multiple control algorithms under different autonomous vehicle penetration rates and heavy traffic load scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13056v1</guid>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chen Huang, Ronghui Hou</dc:creator>
    </item>
    <item>
      <title>A Monad-Based Clause Architecture for Artificial Age Score (AAS) in Large Language Models</title>
      <link>https://arxiv.org/abs/2512.11835</link>
      <description>arXiv:2512.11835v1 Announce Type: cross 
Abstract: Large language models (LLMs) are often deployed as powerful yet opaque systems, leaving open how their internal memory and "self-like" behavior should be governed in a principled and auditable way. The Artificial Age Score (AAS) was previously introduced and mathematically justified through three theorems that characterise it as a metric of artificial memory aging. Building on this foundation, the present work develops an engineering-oriented, clause-based architecture that imposes law-like constraints on LLM memory and control. Twenty selected monads from Leibniz's Monadology are grouped into six bundles: ontology, dynamics, representation and consciousness, harmony and reason, body and organisation, and teleology, and each bundle is realised as an executable specification on top of the AAS kernel. Across six minimal Python implementations, these clause families are instantiated in numerical experiments acting on channel-level quantities such as recall scores, redundancy, and weights. Each implementation follows a four-step pattern: inputs and setup, clause implementation, numerical results, and implications for LLM design, emphasising that the framework is not only philosophically motivated but also directly implementable. The experiments show that the clause system exhibits bounded and interpretable behavior: AAS trajectories remain continuous and rate-limited, contradictions and unsupported claims trigger explicit penalties, and hierarchical refinement reveals an organic structure in a controlled manner. Dual views and goal-action pairs are aligned by harmony terms, and windowed drift in perfection scores separates sustained improvement from sustained degradation. Overall, the monad-based clause framework uses AAS as a backbone and provides a transparent, code-level blueprint for constraining and analyzing internal dynamics in artificial agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11835v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.NE</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seyma Yaman Kayadibi</dc:creator>
    </item>
    <item>
      <title>The Agentic Regulator: Risks for AI in Finance and a Proposed Agent-based Framework for Governance</title>
      <link>https://arxiv.org/abs/2512.11933</link>
      <description>arXiv:2512.11933v1 Announce Type: cross 
Abstract: Generative and agentic artificial intelligence is entering financial markets faster than existing governance can adapt. Current model-risk frameworks assume static, well-specified algorithms and one-time validations; large language models and multi-agent trading systems violate those assumptions by learning continuously, exchanging latent signals, and exhibiting emergent behavior. Drawing on complex adaptive systems theory, we model these technologies as decentralized ensembles whose risks propagate along multiple time-scales. We then propose a modular governance architecture. The framework decomposes oversight into four layers of "regulatory blocks": (i) self-regulation modules embedded beside each model, (ii) firm-level governance blocks that aggregate local telemetry and enforce policy, (iii) regulator-hosted agents that monitor sector-wide indicators for collusive or destabilizing patterns, and (iv) independent audit blocks that supply third-party assurance. Eight design strategies enable the blocks to evolve as fast as the models they police. A case study on emergent spoofing in multi-agent trading shows how the layered controls quarantine harmful behavior in real time while preserving innovation. The architecture remains compatible with today's model-risk rules yet closes critical observability and control gaps, providing a practical path toward resilient, adaptive AI governance in financial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11933v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.MA</category>
      <category>q-fin.GN</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eren Kurshan, Tucker Balch, David Byrd</dc:creator>
    </item>
    <item>
      <title>Value-Aware Multiagent Systems</title>
      <link>https://arxiv.org/abs/2512.12652</link>
      <description>arXiv:2512.12652v1 Announce Type: cross 
Abstract: This paper introduces the concept of value awareness in AI, which goes beyond the traditional value-alignment problem. Our definition of value awareness presents us with a concise and simplified roadmap for engineering value-aware AI. The roadmap is structured around three core pillars: (1) learning and representing human values using formal semantics, (2) ensuring the value alignment of both individual agents and multiagent systems, and (3) providing value-based explainability on behaviour. The paper presents a selection of our ongoing work on some of these topics, along with applications to real-life domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.12652v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-82039-7_3</arxiv:DOI>
      <arxiv:journal_reference>In Coordination, Organizations, Institutions, Norms, and Ethics for Governance of Multi-Agent Systems XVII. COINE 2024. LNCS, vol 15398. Springer, Cham (2025)</arxiv:journal_reference>
      <dc:creator>Nardine Osman</dc:creator>
    </item>
    <item>
      <title>Finch: Benchmarking Finance &amp; Accounting across Spreadsheet-Centric Enterprise Workflows</title>
      <link>https://arxiv.org/abs/2512.13168</link>
      <description>arXiv:2512.13168v1 Announce Type: cross 
Abstract: We introduce a finance &amp; accounting benchmark (Finch) for evaluating AI agents on real-world, enterprise-grade professional workflows -- interleaving data entry, structuring, formatting, web search, cross-file retrieval, calculation, modeling, validation, translation, visualization, and reporting. Finch is sourced from authentic enterprise workspaces at Enron (15,000 spreadsheets and 500,000 emails from 150 employees) and other financial institutions, preserving in-the-wild messiness across multimodal artifacts (text, tables, formulas, charts, code, and images) and spanning diverse domains such as budgeting, trading, and asset management.
  We propose a workflow construction process that combines LLM-assisted discovery with expert annotation: (1) LLM-assisted, expert-verified derivation of workflows from real-world email threads and version histories of spreadsheet files, and (2) meticulous expert annotation for workflows, requiring over 700 hours of domain-expert effort. This yields 172 composite workflows with 384 tasks, involving 1,710 spreadsheets with 27 million cells, along with PDFs and other artifacts, capturing the intrinsically messy, long-horizon, knowledge-intensive, and collaborative nature of real-world enterprise work.
  We conduct both human and automated evaluations of frontier AI systems including GPT 5.1, Claude Sonnet 4.5, Gemini 3 Pro, Grok 4, and Qwen 3 Max, and GPT 5.1 Pro spends 48 hours in total yet passes only 38.4% of workflows, while Claude Sonnet 4.5 passes just 25.0%. Comprehensive case studies further surface the challenges that real-world enterprise workflows pose for AI agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13168v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.IR</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyu Dong, Pengkun Zhang, Yan Gao, Xuanyu Dong, Yilin Cheng, Mingzhe Lu, Adina Yakefu, Shuxin Zheng</dc:creator>
    </item>
    <item>
      <title>Fair Coordination in Strategic Scheduling</title>
      <link>https://arxiv.org/abs/2512.13244</link>
      <description>arXiv:2512.13244v1 Announce Type: cross 
Abstract: We consider a scheduling problem of strategic agents representing jobs of different weights. Each agent has to decide on one of a finite set of identical machines to get their job processed. In contrast to the common and exclusive focus on makespan minimization, we want the outcome to be fair under strategic considerations of the agents. Two natural properties are credibility, which ensures that the assignment is a Nash equilibrium and equality, requiring that agents with equal-weight jobs are assigned to machines of equal load. We combine these two with a hierarchy of fairness properties based on envy-freeness together with several relaxations based on the idea that envy seems more justified towards agents with a higher weight. We present a complete complexity landscape for satisfiability and decision versions of these properties, alone or in combination, and study them as structural constraints under makespan optimization. For our positive results, we develop a unified algorithmic approach, where we achieve different properties by fine-tuning key subroutines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13244v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei-Chen Lee, Martin Bullinger, Alessandro Abate, Michael Wooldridge</dc:creator>
    </item>
    <item>
      <title>Fast and Robust Flocking of Protesters on Street Networks</title>
      <link>https://arxiv.org/abs/2406.01101</link>
      <description>arXiv:2406.01101v4 Announce Type: replace 
Abstract: We present a simple model of protesters scattered throughout a city who want to gather into large and mobile groups. This model relies on random walkers on a street network that follow tactics built from a set of basic rules. Our goal is to identify the most important rules for fast and robust flocking of walkers. We explore a wide set of tactics and show the central importance of a specific rule based on alignment. Other rules alone perform poorly, but our experiments show that combining alignment with them enhances flocking, and that obtained groups are then remarkably robust.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01101v4</guid>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Moinard, Matthieu Latapy</dc:creator>
    </item>
    <item>
      <title>MALLM: Multi-Agent Large Language Models Framework</title>
      <link>https://arxiv.org/abs/2509.11656</link>
      <description>arXiv:2509.11656v3 Announce Type: replace 
Abstract: Multi-agent debate (MAD) has demonstrated the ability to augment collective intelligence by scaling test-time compute and leveraging expertise. Current frameworks for multi-agent debate are often designed towards tool use, lack integrated evaluation, or provide limited configurability of agent personas, response generators, discussion paradigms, and decision protocols. We introduce MALLM (Multi-Agent Large Language Models), an open-source framework that enables systematic analysis of MAD components. MALLM offers more than 144 unique configurations of MAD, including (1) agent personas (e.g., Expert, Personality), (2) response generators (e.g., Critical, Reasoning), (3) discussion paradigms (e.g., Memory, Relay), and (4) decision protocols (e.g., Voting, Consensus). MALLM uses simple configuration files to define a debate. Furthermore, MALLM can load any textual Hugging Face dataset (e.g., MMLU-Pro, WinoGrande) and provides an evaluation pipeline for easy comparison of MAD configurations. MALLM enables researchers to systematically configure, run, and evaluate debates for their problems, facilitating the understanding of the components and their interplay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11656v3</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Becker, Lars Benedikt Kaesberg, Niklas Bauer, Jan Philip Wahle, Terry Ruas, Bela Gipp</dc:creator>
    </item>
    <item>
      <title>Climate Driven Interactions Between Malaria Transmission and Diabetes Prevalence</title>
      <link>https://arxiv.org/abs/2511.08562</link>
      <description>arXiv:2511.08562v2 Announce Type: replace 
Abstract: Climate change is intensifying infectious and chronic diseases like malaria and diabetes, respectively, especially among the vulnerable populations. Global temperatures have risen by approximately $0.6^\circ$C since 1950, extending the window of transmission for mosquito-borne infections and worsening outcomes in diabetes due to metabolic stress caused by heat. People living with diabetes have already weakened immune defenses and, therefore, are at an alarmingly increased risk of contraction of malaria. However, most models rarely include both ways of interaction in changing climate conditions. In the paper, we introduce a new compartmental epidemiological model based on synthetic data fitted to disease patterns of India from 2019 to 2021. The framework captures temperature-dependent transmission parameters, seasonal variability, and different disease dynamics between diabetic and non-diabetic groups within the three-compartment system. Model calibration using Multi-Start optimization combined with Sequential Quadratic Programming allows us to find outstanding differences between populations. The odds of malaria infection in diabetic individuals were found to be 1.8--4.0 times higher, with peak infection levels in 35--36\%, as compared to 20--21\% in the non-diabetic ones. The fitted model was able to capture well the epidemiological patterns observed, while the basic reproduction number averaged around 2.3, ranging from 0.31 to 2.75 in different seasons. Given that India's diabetic population is set to rise to about 157 million people by 2050, these findings point to a pressing need for concerted efforts toward climate-informed health strategies and monitoring systems that address both malaria and diabetes jointly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08562v2</guid>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Shivank, Anurag Singh, Fakhteh Ghanbarnejad, Ajay K Sharma</dc:creator>
    </item>
    <item>
      <title>Unsupervised Acquisition of Discrete Grammatical Categories</title>
      <link>https://arxiv.org/abs/2503.18702</link>
      <description>arXiv:2503.18702v2 Announce Type: replace-cross 
Abstract: This article presents experiments performed using a computational laboratory environment for language acquisition experiments. It implements a multi-agent system consisting of two agents: an adult language model and a daughter language model that aims to learn the mother language. Crucially, the daughter agent does not have access to the internal knowledge of the mother language model but only to the language exemplars the mother agent generates. These experiments illustrate how this system can be used to acquire abstract grammatical knowledge. We demonstrate how statistical analyses of patterns in the input data corresponding to grammatical categories yield discrete grammatical rules. These rules are subsequently added to the grammatical knowledge of the daughter language model. To this end, hierarchical agglomerative cluster analysis was applied to the utterances consecutively generated by the mother language model. It is argued that this procedure can be used to acquire structures resembling grammatical categories proposed by linguists for natural languages. Thus, it is established that non-trivial grammatical knowledge has been acquired. Moreover, the parameter configuration of this computational laboratory environment determined using training data generated by the mother language model is validated in a second experiment with a test set similarly resulting in the acquisition of non-trivial categories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.18702v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Ph. Shakouri, Crit Cremers, Niels O. Schiller</dc:creator>
    </item>
    <item>
      <title>The Traitors: Deception and Trust in Multi-Agent Language Model Simulations</title>
      <link>https://arxiv.org/abs/2505.12923</link>
      <description>arXiv:2505.12923v2 Announce Type: replace-cross 
Abstract: As AI systems increasingly assume roles where trust and alignment with human values are essential, understanding when and why they engage in deception has become a critical research priority. We introduce The Traitors, a multi-agent simulation framework inspired by social deduction games, designed to probe deception, trust formation, and strategic communication among large language model (LLM) agents under asymmetric information. A minority of agents the traitors seek to mislead the majority, while the faithful must infer hidden identities through dialogue and reasoning. Our contributions are: (1) we ground the environment in formal frameworks from game theory, behavioral economics, and social cognition; (2) we develop a suite of evaluation metrics capturing deception success, trust dynamics, and collective inference quality; (3) we implement a fully autonomous simulation platform where LLMs reason over persistent memory and evolving social dynamics, with support for heterogeneous agent populations, specialized traits, and adaptive behaviors. Our initial experiments across DeepSeek-V3, GPT-4o-mini, and GPT-4o (10 runs per model) reveal a notable asymmetry: advanced models like GPT-4o demonstrate superior deceptive capabilities yet exhibit disproportionate vulnerability to others' falsehoods. This suggests deception skills may scale faster than detection abilities. Overall, The Traitors provides a focused, configurable testbed for investigating LLM behavior in socially nuanced interactions. We position this work as a contribution toward more rigorous research on deception mechanisms, alignment challenges, and the broader social reliability of AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12923v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pedro M. P. Curvo</dc:creator>
    </item>
    <item>
      <title>AI Agents with Decentralized Identifiers and Verifiable Credentials</title>
      <link>https://arxiv.org/abs/2511.02841</link>
      <description>arXiv:2511.02841v2 Announce Type: replace-cross 
Abstract: A fundamental limitation of current LLM-based AI agents is their inability to build differentiated trust among each other at the onset of an agent-to-agent dialogue. However, autonomous and interoperable trust establishment becomes essential once agents start to operate beyond isolated environments and engage in dialogues across individual or organizational boundaries. A promising way to fill this gap in Agentic AI is to equip agents with long-lived digital identities and introduce tamper-proof and flexible identity-bound attestations of agents, provisioned by commonly trusted third parties and designed for cross-domain verifiability. This article presents a conceptual framework and a prototypical multi-agent system, where each agent is endowed with a self-sovereign digital identity. It combines a unique and ledger-anchored W3C Decentralized Identifier (DID) of an agent with a set of third-party issued W3C Verifiable Credentials (VCs). This enables agents at the start of a dialog to prove ownership of their self-controlled DIDs for authentication purposes and to establish various cross-domain trust relationships through the spontaneous exchange of their self-hosted DID-bound VCs. A comprehensive evaluation of the prototypical implementation demonstrates technical feasibility but also reveals limitations once an agent's LLM is in sole charge to control the respective security procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.02841v2</guid>
      <category>cs.CR</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandro Rodriguez Garzon, Awid Vaziry, Enis Mert Kuzu, Dennis Enrique Gehrmann, Buse Varkan, Alexander Gaballa, Axel K\"upper</dc:creator>
    </item>
    <item>
      <title>Regret Lower Bounds for Decentralized Multi-Agent Stochastic Shortest Path Problems</title>
      <link>https://arxiv.org/abs/2511.04594</link>
      <description>arXiv:2511.04594v2 Announce Type: replace-cross 
Abstract: Multi-agent systems (MAS) are central to applications such as swarm robotics and traffic routing, where agents must coordinate in a decentralized manner to achieve a common objective. Stochastic Shortest Path (SSP) problems provide a natural framework for modeling decentralized control in such settings. While the problem of learning in SSP has been extensively studied in single-agent settings, the decentralized multi-agent variant remains largely unexplored. In this work, we take a step towards addressing that gap. We study decentralized multi-agent SSPs (Dec-MASSPs) under linear function approximation, where the transition dynamics and costs are represented using linear models. Applying novel symmetry-based arguments, we identify the structure of optimal policies. Our main contribution is the first regret lower bound for this setting based on the construction of hard-to-learn instances for any number of agents, $n$. Our regret lower bound of $\Omega(\sqrt{K})$, over $K$ episodes, highlights the inherent learning difficulty in Dec-MASSPs. These insights clarify the learning complexity of decentralized control and can further guide the design of efficient learning algorithms in multi-agent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04594v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Utkarsh U. Chavan, Prashant Trivedi, Nandyala Hemachandra</dc:creator>
    </item>
    <item>
      <title>Trusted AI Agents in the Cloud</title>
      <link>https://arxiv.org/abs/2512.05951</link>
      <description>arXiv:2512.05951v2 Announce Type: replace-cross 
Abstract: AI agents powered by large language models are increasingly deployed as cloud services that autonomously access sensitive data, invoke external tools, and interact with other agents. However, these agents run within a complex multi-party ecosystem, where untrusted components can lead to data leakage, tampering, or unintended behavior. Existing Confidential Virtual Machines (CVMs) provide only per binary protection and offer no guarantees for cross-principal trust, accelerator-level isolation, or supervised agent behavior. We present Omega, a system that enables trusted AI agents by enforcing end-to-end isolation, establishing verifiable trust across all contributing principals, and supervising every external interaction with accountable provenance. Omega builds on Confidential VMs and Confidential GPUs to create a Trusted Agent Platform that hosts many agents within a single CVM using nested isolation. It also provides efficient multi-agent orchestration with cross-principal trust establishment via differential attestation, and a policy specification and enforcement framework that governs data access, tool usage, and inter-agent communication for data protection and regulatory compliance. Implemented on AMD SEV-SNP and NVIDIA H100, Omega fully secures agent state across CVM-GPU, and achieves high performance while enabling high-density, policy-compliant multi-agent deployments at cloud scale.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.05951v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Teofil Bodea, Masanori Misono, Julian Pritzi, Patrick Sabanic, Thore Sommer, Harshavardhan Unnibhavi, David Schall, Nuno Santos, Dimitrios Stavrakakis, Pramod Bhatotia</dc:creator>
    </item>
    <item>
      <title>Social welfare optimisation in well-mixed and structured populations</title>
      <link>https://arxiv.org/abs/2512.07453</link>
      <description>arXiv:2512.07453v2 Announce Type: replace-cross 
Abstract: Research on promoting cooperation among autonomous, self-regarding agents has often focused on the bi-objective optimisation problem: minimising the total incentive cost while maximising the frequency of cooperation. However, the optimal value of social welfare under such constraints remains largely unexplored. In this work, we hypothesise that achieving maximal social welfare is not guaranteed at the minimal incentive cost required to drive agents to a desired cooperative state. To address this gap, we adopt to a single-objective approach focused on maximising social welfare, building upon foundational evolutionary game theory models that examined cost efficiency in finite populations, in both well-mixed and structured population settings. Our analytical model and agent-based simulations show how different interference strategies, including rewarding local versus global behavioural patterns, affect social welfare and dynamics of cooperation. Our results reveal a significant gap in the per-individual incentive cost between optimising for pure cost efficiency or cooperation frequency and optimising for maximal social welfare. Overall, our findings indicate that incentive design, policy, and benchmarking in multi-agent systems and human societies should prioritise welfare-centric objectives over proxy targets of cost or cooperation frequency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07453v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 16 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Van An Nguyen, Vuong Khang Huynh, Ho Nam Duong, Huu Loi Bui, Hai Anh Ha, Quang Dung Le, Le Quoc Dung Ngo, Tan Dat Nguyen, Ngoc Ngu Nguyen, Hoai Thuong Nguyen, Zhao Song, Le Hong Trang, The Anh Han</dc:creator>
    </item>
  </channel>
</rss>
