<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 11 Jun 2025 04:00:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Power Domain Sparse Dimensional Constellation Multiple Access (PD-SDCMA) for Enabled Flexible PONs</title>
      <link>https://arxiv.org/abs/2506.08053</link>
      <description>arXiv:2506.08053v1 Announce Type: new 
Abstract: With the commercial deployment of 5G and the in-depth research of 6G, the demand for high-speed data services in the next-generation fiber optic access systems is growing increasingly. Passive optical networks (PONs) have become a research hotspot due to their characteristics of low loss, high bandwidth, and low cost. However, the traditional orthogonal multiple access (OMA-PON) has difficulty meeting the requirements of the next-generation PON for high spectral efficiency and flexibility. In this paper, a novel transmission technology, namely power-domain sparse dimension constellation multiple access (PD-SDCMA), is proposed for the first time. Through the signal space dimension selection strategy (S2D-strategy) in the high-dimensional signal space, the low-dimensional constellation is sparsely superimposed into the high-dimensional space, thereby reducing multi-user interference and enhancing the system capacity. PD-SDCMA supports higher-order modulation formats and more access groups, and is also compatible with the existing orthogonal frequency division multiplexing (OFDM) architecture. The simulation results show that in a 25 km single-mode fiber system, compared with PD-NOMA and 3D-NOMA, PD-SDCMA can support more users and significantly reduce BER. This technology provides an efficient and low-cost solution for the evolution of Flexible PONs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08053v1</guid>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuhao Lian, Xiao Han, Xinmao Deng</dc:creator>
    </item>
    <item>
      <title>Educators' Perceptions of Large Language Models as Tutors: Comparing Human and AI Tutors in a Blind Text-only Setting</title>
      <link>https://arxiv.org/abs/2506.08702</link>
      <description>arXiv:2506.08702v1 Announce Type: new 
Abstract: The rapid development of Large Language Models (LLMs) opens up the possibility of using them as personal tutors. This has led to the development of several intelligent tutoring systems and learning assistants that use LLMs as back-ends with various degrees of engineering. In this study, we seek to compare human tutors with LLM tutors in terms of engagement, empathy, scaffolding, and conciseness. We ask human tutors to annotate and compare the performance of an LLM tutor with that of a human tutor in teaching grade-school math word problems on these qualities. We find that annotators with teaching experience perceive LLMs as showing higher performance than human tutors in all 4 metrics. The biggest advantage is in empathy, where 80% of our annotators prefer the LLM tutor more often than the human tutors. Our study paints a positive picture of LLMs as tutors and indicates that these models can be used to reduce the load on human teachers in the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08702v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sankalan Pal Chowdhury, Terry Jingchen Zhang, Donya Rooein, Dirk Hovy, Tanja K\"aser, Mrinmaya Sachan</dc:creator>
    </item>
    <item>
      <title>Large Language Models for EEG: A Comprehensive Survey and Taxonomy</title>
      <link>https://arxiv.org/abs/2506.06353</link>
      <description>arXiv:2506.06353v1 Announce Type: cross 
Abstract: The growing convergence between Large Language Models (LLMs) and electroencephalography (EEG) research is enabling new directions in neural decoding, brain-computer interfaces (BCIs), and affective computing. This survey offers a systematic review and structured taxonomy of recent advancements that utilize LLMs for EEG-based analysis and applications. We organize the literature into four domains: (1) LLM-inspired foundation models for EEG representation learning, (2) EEG-to-language decoding, (3) cross-modal generation including image and 3D object synthesis, and (4) clinical applications and dataset management tools. The survey highlights how transformer-based architectures adapted through fine-tuning, few-shot, and zero-shot learning have enabled EEG-based models to perform complex tasks such as natural language generation, semantic interpretation, and diagnostic assistance. By offering a structured overview of modeling strategies, system designs, and application areas, this work serves as a foundational resource for future work to bridge natural language processing and neural signal analysis through language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.06353v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Naseem Babu, Jimson Mathew, A. P. Vinod</dc:creator>
    </item>
    <item>
      <title>Complex-Valued Holographic Radiance Fields</title>
      <link>https://arxiv.org/abs/2506.08350</link>
      <description>arXiv:2506.08350v1 Announce Type: cross 
Abstract: Modeling the full properties of light, including both amplitude and phase, in 3D representations is crucial for advancing physically plausible rendering, particularly in holographic displays. To support these features, we propose a novel representation that optimizes 3D scenes without relying on intensity-based intermediaries. We reformulate 3D Gaussian splatting with complex-valued Gaussian primitives, expanding support for rendering with light waves. By leveraging RGBD multi-view images, our method directly optimizes complex-valued Gaussians as a 3D holographic scene representation. This eliminates the need for computationally expensive hologram re-optimization. Compared with state-of-the-art methods, our method achieves 30x-10,000x speed improvements while maintaining on-par image quality, representing a first step towards geometrically aligned, physically plausible holographic scene representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08350v1</guid>
      <category>cs.GR</category>
      <category>cs.CV</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yicheng Zhan, Dong-Ha Shin, Seung-Hwan Baek, Kaan Ak\c{s}it</dc:creator>
    </item>
    <item>
      <title>ABC-FHE : A Resource-Efficient Accelerator Enabling Bootstrappable Parameters for Client-Side Fully Homomorphic Encryption</title>
      <link>https://arxiv.org/abs/2506.08461</link>
      <description>arXiv:2506.08461v1 Announce Type: cross 
Abstract: As the demand for privacy-preserving computation continues to grow, fully homomorphic encryption (FHE)-which enables continuous computation on encrypted data-has become a critical solution. However, its adoption is hindered by significant computational overhead, requiring 10000-fold more computation compared to plaintext processing. Recent advancements in FHE accelerators have successfully improved server-side performance, but client-side computations remain a bottleneck, particularly under bootstrappable parameter configurations, which involve combinations of encoding, encrypt, decoding, and decrypt for large-sized parameters. To address this challenge, we propose ABC-FHE, an area- and power-efficient FHE accelerator that supports bootstrappable parameters on the client side. ABC-FHE employs a streaming architecture to maximize performance density, minimize area usage, and reduce off-chip memory access. Key innovations include a reconfigurable Fourier engine capable of switching between NTT and FFT modes. Additionally, an on-chip pseudo-random number generator and a unified on-the-fly twiddle factor generator significantly reduce memory demands, while optimized task scheduling enhances the CKKS client-side processing, achieving reduced latency. Overall, ABC-FHE occupies a die area of 28.638 mm2 and consumes 5.654 W of power in 28 nm technology. It delivers significant performance improvements, achieving a 1112x speed-up in encoding and encryption execution time compared to a CPU, and 214x over the state-of-the-art client-side accelerator. For decoding and decryption, it achieves a 963x speed-up over the CPU and 82x over the state-of-the-art accelerator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08461v1</guid>
      <category>cs.AR</category>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sungwoong Yune, Hyojeong Lee, Adiwena Putra, Hyunjun Cho, Cuong Duong Manh, Jaeho Jeon, Joo-Young Kim</dc:creator>
    </item>
    <item>
      <title>Parallel FFTW on RISC-V: A Comparative Study including OpenMP, MPI, and HPX</title>
      <link>https://arxiv.org/abs/2506.08653</link>
      <description>arXiv:2506.08653v1 Announce Type: cross 
Abstract: Rapid advancements in RISC-V hardware development shift the focus from low-level optimizations to higher-level parallelization. Recent RISC-V processors, such as the SOPHON SG2042, have 64 cores. RISC-V processors with core counts comparable to the SG2042, make efficient parallelization as crucial for RISC-V as the more established processors such as x86-64. In this work, we evaluate the parallel scaling of the widely used FFTW library on RISC-V for MPI and OpenMP. We compare it to a 64-core AMD EPYC 7742 CPU side by side for different types of FFTW planning. Additionally, we investigate the effect of memory optimization on RISC-V in HPX-FFT, a parallel FFT library based on the asynchronous many-task runtime HPX using an FFTW backend. We generally observe a performance delta between the x86-64 and RISC-V chips of factor eight for double-precision 2D FFT. Effective memory optimizations in HPX-FFT on x86-64 do not translate to the RISC-V chip. FFTW with MPI shows good scaling up to 64 cores on x86-64 and RISC-V regardless of planning. In contrast, FFTW with OpenMP requires measured planning on both architectures to achieve good scaling up to 64 cores. The results of our study mark an early step on the journey to large-scale parallel applications running on RISC-V.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08653v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Strack, Christopher Taylor, Dirk Pfl\"uger</dc:creator>
    </item>
    <item>
      <title>Superposed Parameterised Quantum Circuits</title>
      <link>https://arxiv.org/abs/2506.08749</link>
      <description>arXiv:2506.08749v1 Announce Type: cross 
Abstract: Quantum machine learning has shown promise for high-dimensional data analysis, yet many existing approaches rely on linear unitary operations and shared trainable parameters across outputs. These constraints limit expressivity and scalability relative to the multi-layered, non-linear architectures of classical deep networks. We introduce superposed parameterised quantum circuits to overcome these limitations. By combining flip-flop quantum random-access memory with repeat-until-success protocols, a superposed parameterised quantum circuit embeds an exponential number of parameterised sub-models in a single circuit and induces polynomial activation functions through amplitude transformations and post-selection. We provide an analytic description of the architecture, showing how multiple parameter sets are trained in parallel while non-linear amplitude transformations broaden representational power beyond conventional quantum kernels. Numerical experiments underscore these advantages: on a 1D step-function regression a two-qubit superposed parameterised quantum circuit cuts the mean-squared error by three orders of magnitude versus a parameter-matched variational baseline; on a 2D star-shaped two-dimensional classification task, introducing a quadratic activation lifts accuracy to 81.4% and reduces run-to-run variance three-fold. These results position superposed parameterised quantum circuits as a hardware-efficient route toward deeper, more versatile parameterised quantum circuits capable of learning complex decision boundaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08749v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viktoria Patapovich, Mo Kordzanganeh, Alexey Melnikov</dc:creator>
    </item>
    <item>
      <title>Qymera: Simulating Quantum Circuits using RDBMS</title>
      <link>https://arxiv.org/abs/2506.08759</link>
      <description>arXiv:2506.08759v1 Announce Type: cross 
Abstract: Quantum circuit simulation is crucial for quantum computing such as validating quantum algorithms. We present Qymera, a system that repurposes relational database management systems (RDBMSs) for simulation by translating circuits into SQL queries, allowing quantum operations to run natively within an RDBMS. Qymera supports a wide range of quantum circuits, offering a graphical circuit builder and code-based interfaces to input circuits. With a benchmarking framework, Qymera facilitates comparison of RDBMS-based simulation against state-of-the-art simulation methods. Our demonstration showcases Qymera's end-to-end SQL-based execution, seamless integration with classical workflows, and its utility for development, benchmarking, and education in quantum computing and data management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08759v1</guid>
      <category>quant-ph</category>
      <category>cs.DB</category>
      <category>cs.ET</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3722212.3725126</arxiv:DOI>
      <dc:creator>Tim Littau, Rihan Hai</dc:creator>
    </item>
    <item>
      <title>AI as Decision-Maker: Ethics and Risk Preferences of LLMs</title>
      <link>https://arxiv.org/abs/2406.01168</link>
      <description>arXiv:2406.01168v3 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) exhibit surprisingly diverse risk preferences when acting as AI decision makers, a crucial characteristic whose origins remain poorly understood despite their expanding economic roles. We analyze 50 LLMs using behavioral tasks, finding stable but diverse risk profiles. Alignment tuning for harmlessness, helpfulness, and honesty significantly increases risk aversion, causally increasing risk aversion confirmed via comparative difference analysis: a ten percent ethics increase cuts risk appetite two to eight percent. This induced caution persists against prompts and affects economic forecasts. Alignment enhances safety but may also suppress valuable risk taking, revealing a tradeoff risking suboptimal economic outcomes. With AI models becoming more powerful and influential in economic decisions while alignment grows increasingly critical, our empirical framework serves as an adaptable and enduring benchmark to track risk preferences and monitor this crucial tension between ethical alignment and economically valuable risk-taking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01168v3</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shumiao Ouyang, Hayong Yun, Xingjian Zheng</dc:creator>
    </item>
    <item>
      <title>An Explainable Vision Transformer with Transfer Learning Combined with Support Vector Machine Based Efficient Drought Stress Identification</title>
      <link>https://arxiv.org/abs/2407.21666</link>
      <description>arXiv:2407.21666v2 Announce Type: replace-cross 
Abstract: Early detection of drought stress is critical for taking timely measures for reducing crop loss before the drought impact becomes irreversible. The subtle phenotypical and physiological changes in response to drought stress are captured by non-invasive imaging techniques and these imaging data serve as valuable resource for machine learning methods to identify drought stress. While convolutional neural networks (CNNs) are in wide use, vision transformers (ViTs) present a promising alternative in capturing long-range dependencies and intricate spatial relationships, thereby enhancing the detection of subtle indicators of drought stress. We propose an explainable deep learning pipeline that leverages the power of ViTs for drought stress detection in potato crops using aerial imagery. We applied two distinct approaches: a synergistic combination of ViT and support vector machine (SVM), where ViT extracts intricate spatial features from aerial images, and SVM classifies the crops as stressed or healthy and an end-to-end approach using a dedicated classification layer within ViT to directly detect drought stress. Our key findings explain the ViT model's decision-making process by visualizing attention maps. These maps highlight the specific spatial features within the aerial images that the ViT model focuses as the drought stress signature. Our findings demonstrate that the proposed methods not only achieve high accuracy in drought stress identification but also shedding light on the diverse subtle plant features associated with drought stress. This offers a robust and interpretable solution for drought stress monitoring for farmers to undertake informed decisions for improved crop management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21666v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 11 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aswini Kumar Patra, Ankit Varshney, Lingaraj Sahoo</dc:creator>
    </item>
  </channel>
</rss>
