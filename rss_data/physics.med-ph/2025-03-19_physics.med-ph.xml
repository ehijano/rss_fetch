<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Mar 2025 01:56:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Demonstration of a mechanical external biventricular assist device for resuscitative thoracotomy</title>
      <link>https://arxiv.org/abs/2503.14087</link>
      <description>arXiv:2503.14087v1 Announce Type: new 
Abstract: Resuscitative thoracotomy, a high-risk procedure involving open heart massage, serves as a last resort for life-threatening conditions like penetrating chest wounds, severe blunt trauma, or surgery-related cardiac arrest. However, its success rate remains low, even with highly trained specialists. This research investigates the potential of an external biventricular assist device (BiVAD). By replacing open heart massage with our BiVAD device during resuscitative thoracotomy, we aim to achieve sufficient cardiac output, maintain physiological pressure levels, and potentially improve patient survival in these critical situations. The proposed BiVAD system features a simple 3D printed patch design for direct cardiac attachment, an actuation device, and a vacuum pump. The straightforward design allows quick application in emergency situations. The BiVAD system was tested in a hydraulic mock circulation, utilizing a silicone heart. Three actuation modes were tested for proof-of-concept: manual patch actuation, standard cardiac hand massage, and utilizing full capabilities of our BiVAD patch system with actuation device operation. Overall performance was assessed on ventricular pressure and flow rate data. Focusing on achieving the optimal cardiac output of 1.5 L/min (critical for patient survival), we tested our patch system against cardiac hand massage at a fixed rate of 60 bpm. Notably, our BiVAD system not only achieved to operate in the range of required cardiac output but also significantly reduced peak pressure in both ventricles compared to standard cardiac hand massage. This initial evaluation using a silicone heart model demonstrates the potential of our BiVAD system to achieve sufficient cardiac output while reducing peak pressure compared to cardiac hand massage. Further development holds promise for effective cardiac support in resuscitative thoracotomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14087v1</guid>
      <category>physics.med-ph</category>
      <category>physics.bio-ph</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Krist\'of S\'arosi, Thomas Kummer, Thomas R\"osgen, Stijn Vandenberghe, Stefanos Demertzis, Patrick Jenny</dc:creator>
    </item>
    <item>
      <title>Positronium Imaging: first clinical images and perspectives</title>
      <link>https://arxiv.org/abs/2503.14120</link>
      <description>arXiv:2503.14120v1 Announce Type: new 
Abstract: Positronium imaging was recently proposed to image the properties of positronium atoms in the patient body. Positronium properties depend on the size of intramolecular voids and oxygen concentration; therefore, they deliver information different and complementary to the anatomic, morphological, and metabolic images. Thus far, the mean ortho-positronium lifetime imaging has been at the center of research interest. The first ex vivo and in vivo positronium lifetime images of humans have been demonstrated with the dedicated J-PET scanner enabling simultaneous registration of annihilation photons and prompt gamma from ${\beta^{+} \gamma}$ emitters. Annihilation photons are used to reconstruct the annihilation place and time while prompt gamma is used to reconstruct the time of positronium formation. This review describes recent achievements in the translation of positronium imaging into clinics. The first measurements of positronium lifetime in humans with commercial PET scanners modernized to register triple coincidences are reported. The in vivo observations of differences in ortho-positronium lifetime between tumor and healthy tissues and between different oxygen concentrations are discussed. So far, the positronium lifetime measurements in humans were completed with clinically available ${^{68}\text{Ga}}$, ${^{82}\text{Rb}}$, and ${^{124}\text{I}}$ radionuclides. Status and challenges in developing positronium imaging on a way to a clinically useful procedure are presented and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14120v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pawe{\l} Moskal, Aleksander Bilewicz, Manish Das, Bangyan Huang, Aleksander Khreptak, Szymon Parzych, Jinyi Qi, Axel Rominger, Robert Seifert, Sushil Sharma, Kuangyu Shi, William Steinberger, Rafa{\l} Walczak, Ewa St\k{e}pie\'n</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Scatter Correction Model for Micro-Focus Dual-Source Imaging Systems: Combining Ambient, Cross, and Forward Scatter</title>
      <link>https://arxiv.org/abs/2503.14386</link>
      <description>arXiv:2503.14386v1 Announce Type: new 
Abstract: Compared to single-source imaging systems, dual-source imaging systems equipped with two cross-distributed scanning beams significantly enhance temporal resolution and capture more comprehensive object scanning information. Nevertheless, the interaction between the two scanning beams introduces more complex scatter signals into the acquired projection data. Existing methods typically model these scatter signals as the sum of cross-scatter and forward scatter, with cross-scatter estimation limited to single-scatter along primary paths. Through experimental measurements on our selfdeveloped micro-focus dual-source imaging system, we observed that the peak ratio of hardware-induced ambient scatter to single-source projection intensity can even exceed 60%, a factor often overlooked in conventional models. To address this limitation, we propose a more comprehensive model that decomposes the total scatter signals into three distinct components: ambient scatter, cross-scatter, and forward scatter. Furthermore, we introduce a cross-scatter kernel superposition (xSKS) module to enhance the accuracy of cross-scatter estimation by modeling both single and multiple crossscatter events along non-primary paths. Additionally, we employ a fast object-adaptive scatter kernel superposition (FOSKS) module for efficient forward scatter estimation. In Monte Carlo (MC) simulation experiments performed on a custom-designed waterbone phantom, our model demonstrated remarkable superiority, achieving a scatter-toprimary-weighted mean absolute percentage error (SPMAPE) of 1.32%, significantly lower than the 12.99% attained by the state-of-the-art method. Physical experiments further validate the superior performance of our model in correcting scatter artifacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14386v1</guid>
      <category>physics.med-ph</category>
      <category>eess.IV</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianing Sun, Jigang Duan, Guangyin Li, Xu Jiang, Xing Zhao</dc:creator>
    </item>
    <item>
      <title>Weakly Supervised Spatial Implicit Neural Representation Learning for 3D MRI-Ultrasound Deformable Image Registration in HDR Prostate Brachytherapy</title>
      <link>https://arxiv.org/abs/2503.14395</link>
      <description>arXiv:2503.14395v1 Announce Type: new 
Abstract: Purpose: Accurate 3D MRI-ultrasound (US) deformable registration is critical for real-time guidance in high-dose-rate (HDR) prostate brachytherapy. We present a weakly supervised spatial implicit neural representation (SINR) method to address modality differences and pelvic anatomy challenges.
  Methods: The framework uses sparse surface supervision from MRI/US segmentations instead of dense intensity matching. SINR models deformations as continuous spatial functions, with patient-specific surface priors guiding a stationary velocity field for biologically plausible deformations. Validation included 20 public Prostate-MRI-US-Biopsy cases and 10 institutional HDR cases, evaluated via Dice similarity coefficient (DSC), mean surface distance (MSD), and 95% Hausdorff distance (HD95).
  Results: The proposed method achieved robust registration. For the public dataset, prostate DSC was $0.93 \pm 0.05$, MSD $0.87 \pm 0.10$ mm, and HD95 $1.58 \pm 0.37$ mm. For the institutional dataset, prostate CTV achieved DSC $0.88 \pm 0.09$, MSD $1.21 \pm 0.38$ mm, and HD95 $2.09 \pm 1.48$ mm. Bladder and rectum performance was lower due to ultrasound's limited field of view. Visual assessments confirmed accurate alignment with minimal discrepancies.
  Conclusion: This study introduces a novel weakly supervised SINR-based approach for 3D MRI-US deformable registration. By leveraging sparse surface supervision and spatial priors, it achieves accurate, robust, and computationally efficient registration, enhancing real-time image guidance in HDR prostate brachytherapy and improving treatment precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14395v1</guid>
      <category>physics.med-ph</category>
      <category>cs.CV</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jing Wang, Ruirui Liu, Yu Lei, Michael J. Baine, Tian Liu, Yang Lei</dc:creator>
    </item>
    <item>
      <title>Fast Maximum Likelihood Positioning for a Staggered Layer Scintillation PET Detector</title>
      <link>https://arxiv.org/abs/2503.13723</link>
      <description>arXiv:2503.13723v1 Announce Type: cross 
Abstract: In this study, we propose a fast implementation of a Maximum Likelihood Positioning (MLP) algorithm to estimate the energy and identify the active scintillator pixel in staggered layer scintillation detectors for PET. The staggered layer design with pixelated scintillators enables the determination of the gamma's depth of interaction and facilitates an iteration-free formulation of the MLP algorithm. The efficacy of the algorithm optimization was tested on a scintillation detector block designed for an ultra-high field BrainPET 7T, comprising three scintillator pixel layers. The three layers contain 24 x 24, 24 x 23 and 23 x 22 scintillator pixels, respectively, with a pixel pitch of 2 mm in both directions and layer thicknesses of 9, 8 and 7 mm. Calibration measurements, in combination with an automated calibration script, were used to obtain the expected counts of scintillation photons required in the MLP algorithm. Using Single-Instruction-Multiple-Data parallelization, multi-threading and optimized cache lines, a maximum processing speed of approximately 22.5 million singles per second was achieved on a platform with four Intel Xeon Platinum 8168 CPUs and 60 threads, encompassing all required processing steps. The automatic calibration failed for 1 to 15 individual scintillator pixels in approximately 10 per cent of the 120 scintillation detector blocks, necessitating manual correction. After applying the energy correction to the positioned single events, an energy resolution of of 12 +/- 2 per cent FWHM was obtained for the entire scintillation block. This value is very close to the energy resolutions measured for the individual scintillator pixels, proving that the MLP accurately identifies the scintillating pixel and that the energy correction method effectively compensates for the light collection variations of the SiPM array.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13723v1</guid>
      <category>physics.ins-det</category>
      <category>physics.med-ph</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph W. Lerche (Institute for Neuroscience and Medicine), Wenwei Bi (Institute for Neuroscience and Medicine, Department of Physics RWTH Aachen University Aachen Germany), Mirjam Schoeneck (Institute for Neuroscience and Medicine, M. Schoeneck is now with the Faculty of Medicine and Institute for Diagnostic and Interventional Radiology University Hospital Cologne Germany), Debora Niekaemper (Institute for Neuroscience and Medicine, Department of Physics RWTH Aachen University Aachen Germany), Qi Liu (Institute for Neuroscience and Medicine), Elisabeth Pfaehler (Institute for Neuroscience and Medicine), Lutz Tellmann (Institute for Neuroscience and Medicine), Juergen J. Scheins (Institute for Neuroscience and Medicine), N. Jon Shah (Institute for Neuroscience and Medicine, Institute of Neuroscience and Medicine 11, JARA - BRAIN - Translational Medicine, Department of Neurology RWTH Aachen University Aachen Germany)</dc:creator>
    </item>
    <item>
      <title>Image-Based Metrics in Ultrasound for Estimation of Global Speed-of-Sound</title>
      <link>https://arxiv.org/abs/2503.14094</link>
      <description>arXiv:2503.14094v1 Announce Type: cross 
Abstract: Accurate speed-of-sound (SoS) estimation is crucial for ultrasound image formation, yet conventional systems often rely on an assumed value for imaging. While several methods exist for SoS estimation, they typically depend on complex physical models of acoustic propagation. We propose to leverage conventional image analysis techniques and metrics, as a novel and simple approach to estimate tissue SoS. We study eleven metrics in three categories for assessing image quality, image similarity and multi-frame variation, by testing them in numerical simulations and phantom experiments. Among single-frame image quality metrics, conventional Focus and our proposed Smoothed Threshold Tenengrad metrics achieved satisfactory accuracy, however only when applied to compounded images. Image quality metrics were largely surpassed by various image comparison metrics, which exhibited errors consistently under 8 m/s even applied to a single pair of images. Particularly, Mean Square Error is a computationally efficient alternative for global estimation. Mutual Information and Correlation are found to be robust to processing small image segments, making them suitable, e.g., for multi-layer SoS estimation. The above metrics do not require access to raw channel data as they can operate on post-beamformed data, and in the case of image quality metrics they can operate on B-mode images, given that the beamforming SoS can be controlled for beamforming using a multitude of values. These image analysis based SoS estimation methods offer a computationally efficient and data-accessible alternative to conventional physics-based methods, with potential extensions to layered or local SoS imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14094v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Roman Denkin, Orcun Goksel</dc:creator>
    </item>
  </channel>
</rss>
