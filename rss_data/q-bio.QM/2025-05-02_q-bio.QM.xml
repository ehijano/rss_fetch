<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 May 2025 04:00:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Enhancing Echocardiogram Video Quality via Latent Space Editing</title>
      <link>https://arxiv.org/abs/2505.00043</link>
      <description>arXiv:2505.00043v1 Announce Type: new 
Abstract: Echocardiography (echo), or cardiac ultrasound, is the most widely used imaging modality for cardiac form and function due to its relatively low cost, rapid acquisition, and non-invasive nature. However, ultrasound acquisitions are often limited by artifacts, noise, and low-quality acquisitions that hinder diagnostic interpretation. Existing techniques for enhancing echos consist of traditional filter-based algorithms, deep-learning approaches developed on radiofrequency (RF) data, or approaches that have strong priors such as manual segmentation labels which limits both clinical applicability and scalability. To address these limitations, we introduce a data-driven approach for enhancing echo videos using a generative model trained on historical images. We learn a latent space representation for echo images using a generative model and use self-supervision from a synthetic dataset of high quality (HQ) and simulated low quality (LQ) image pairs to estimate a direction vector in the latent space from the LQ to HQ domain. In both held-out internal and external test sets, our approach resulted in echo videos with higher gCNR (0.60-0.62 vs. 0.48-0.53) and quality score (0.99-0.99 vs. 0.92-0.96) compared to original LQ videos. Furthermore, we leverage previously developed models for echo to show preservation of key clinical characteristics such as LVEF (MAE 4.74-6.82) and left ventricle segmentation (Dice 0.92-0.93), suggesting potential for future clinical use to improve the quality of echo videos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00043v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Choi, Milos Vukadinovic, Bryan He, David Ouyang</dc:creator>
    </item>
    <item>
      <title>Can a Quantum Support Vector Machine algorithm be utilized to identify Key Biomarkers from Multi-Omics data of COVID19 patients?</title>
      <link>https://arxiv.org/abs/2505.00037</link>
      <description>arXiv:2505.00037v1 Announce Type: cross 
Abstract: Identifying key biomarkers for COVID-19 from high-dimensional multi-omics data is critical for advancing both diagnostic and pathogenesis research. In this study, we evaluated the applicability of the Quantum Support Vector Machine (QSVM) algorithm for biomarker-based classification of COVID-19. Proteomic and metabolomic biomarkers from two independent datasets were ranked by importance using ridge regression and grouped accordingly. The top- and bottom-ranked biomarker sets were then used to train and evaluate both classical SVM (CSVM) and QSVM models, serving as predictive and negative control inputs, respectively. The QSVM was implemented with multiple quantum kernels, including amplitude encoding, angle encoding, the ZZ feature map, and the projected quantum kernel. Across various experimental settings, QSVM consistently achieved classification performance that was comparable to or exceeded that of CSVM, while reflecting the importance rankings by ridge regression. Although the experiments were conducted in numerical simulation, our findings highlight the potential of QSVM as a promising approach for multi-omics data analysis in biomedical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00037v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junggu Choi, Chansu Yu, Kyle L. Jung, Suan-Sin Foo, Weiqiang Chen, Suzy AA Comhair, Serpil C. Erzurum, Lara Jehi, Jae U. Jung</dc:creator>
    </item>
    <item>
      <title>Surrogate modeling of Cellular-Potts Agent-Based Models as a segmentation task using the U-Net neural network architecture</title>
      <link>https://arxiv.org/abs/2505.00316</link>
      <description>arXiv:2505.00316v1 Announce Type: cross 
Abstract: The Cellular-Potts model is a powerful and ubiquitous framework for developing computational models for simulating complex multicellular biological systems. Cellular-Potts models (CPMs) are often computationally expensive due to the explicit modeling of interactions among large numbers of individual model agents and diffusive fields described by partial differential equations (PDEs). In this work, we develop a convolutional neural network (CNN) surrogate model using a U-Net architecture that accounts for periodic boundary conditions. We use this model to accelerate the evaluation of a mechanistic CPM previously used to investigate \textit{in vitro} vasculogenesis. The surrogate model was trained to predict 100 computational steps ahead (Monte-Carlo steps, MCS), accelerating simulation evaluations by a factor of 590 times compared to CPM code execution. Over multiple recursive evaluations, our model effectively captures the emergent behaviors demonstrated by the original Cellular-Potts model of such as vessel sprouting, extension and anastomosis, and contraction of vascular lacunae. This approach demonstrates the potential for deep learning to serve as efficient surrogate models for CPM simulations, enabling faster evaluation of computationally expensive CPM of biological processes at greater spatial and temporal scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00316v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tien Comlekoglu, J. Quetzalc\'oatl Toledo-Mar\'in, Tina Comlekoglu, Douglas W. DeSimone, Shayn M. Peirce, Geoffrey Fox, James A. Glazier</dc:creator>
    </item>
    <item>
      <title>An evaluation of unconditional 3D molecular generation methods</title>
      <link>https://arxiv.org/abs/2505.00518</link>
      <description>arXiv:2505.00518v1 Announce Type: cross 
Abstract: Unconditional molecular generation is a stepping stone for conditional molecular generation, which is important in \emph{de novo} drug design. Recent unconditional 3D molecular generation methods report saturated benchmarks, suggesting it is time to re-evaluate our benchmarks and compare the latest models. We assess five recent high-performing 3D molecular generation methods (EQGAT-diff, FlowMol, GCDM, GeoLDM, and SemlaFlow), in terms of both standard benchmarks and chemical and physical validity. Overall, the best method, SemlaFlow, has a success rate of 87% in generating valid, unique, and novel molecules without post-processing and 92.4% with post-processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00518v1</guid>
      <category>physics.chem-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Buttenschoen, Yael Ziv, Garrett M. Morris, Charlotte M. Deane</dc:creator>
    </item>
    <item>
      <title>AI-Driven High-Resolution Cell Segmentation and Quantitative Analysis</title>
      <link>https://arxiv.org/abs/2505.00578</link>
      <description>arXiv:2505.00578v1 Announce Type: cross 
Abstract: Studying the growth and metabolism of microbes provides critical insights into their evolutionary adaptations to harsh environments, which are essential for microbial research and biotechnology applications. In this study, we developed an AI-driven image analysis system to efficiently segment individual cells and quantitatively analyze key cellular features. This system is comprised of four main modules. First, a denoising algorithm enhances contrast and suppresses noise while preserving fine cellular details. Second, the Segment Anything Model (SAM) enables accurate, zero-shot segmentation of cells without additional training. Third, post-processing is applied to refine segmentation results by removing over-segmented masks. Finally, quantitative analysis algorithms extract essential cellular features, including average intensity, length, width, and volume. The results show that denoising and post-processing significantly improved the segmentation accuracy of SAM in this new domain. Without human annotations, the AI-driven pipeline automatically and efficiently outlines cellular boundaries, indexes them, and calculates key cellular parameters with high accuracy. This framework will enable efficient and automated quantitative analysis of high-resolution fluorescence microscopy images to advance research into microbial adaptations to grow and metabolism that allow extremophiles to thrive in their harsh habitats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00578v1</guid>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuang Zhang, Carleton Coffin, Karyn L. Rogers, Catherine Ann Royer, Ge Wang</dc:creator>
    </item>
    <item>
      <title>Predatory dynamics in susceptible and resistant $\textit{Eriopis connexa}$ populations</title>
      <link>https://arxiv.org/abs/2505.00644</link>
      <description>arXiv:2505.00644v1 Announce Type: cross 
Abstract: The ladybird $\textit{Eriopis connexa}$ (Germar, 1824), a voracious aphid predator, faces challenges from insecticide applications, compromising biological control. As a result, there has been an increase in the number of studies analysing the resistance and susceptibility of ladybirds. Some studies have found that resistant populations exhibit distinct predation and foraging behaviour compared to susceptible ones. This study models the population dynamics of resistant and susceptible $\textit{E. connexa}$ preying on $\textit{Aphis gossypii}$ Glover, 1877 and $\textit{Myzus persicae}$ (Sulzer, 1776). We constructed a logistic model with density dependence and type-II functional response to analyse predation dynamics, incorporating bifurcation analysis on predation parameters (attack rate and handling time) and the mortality rate of susceptible ladybirds. We simulated scenarios with/without insecticide application and with/without aphid resistance. To simulate the effects of insecticide applications, the parameters related to aphids' intrinsic growth rate ($r_1$ and $r_2$) change to reflect the responses of susceptible and resistant populations. The same approach is used concerning the mortality rate of ladybirds ($d_2$ and $d_3$). Our results demonstrate that mortality, attack rate, and handling time are critical in shaping predator-prey interactions. Temporal simulations revealed fluctuating abundances, highlighting the fragility of these interactions under insecticide stress. Therefore, this study contributes to understanding the ecological implications of insecticides, which disrupt natural predation dynamics, and shows how variations in behavioural rates can impact prey control. This research demonstrated the importance of integrated strategies that balance insecticide applications with preserving natural enemies and promoting sustainable agricultural practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00644v1</guid>
      <category>q-bio.PE</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Mara Ferreira Maciel, Gabriel Rodrigues Palma, Lucas dos Anjos, Lucas Santos Canuto, Wesley Augusto Conde Godoy, Rafael de Andrade Moral</dc:creator>
    </item>
    <item>
      <title>OmicsCL: Unsupervised Contrastive Learning for Cancer Subtype Discovery and Survival Stratification</title>
      <link>https://arxiv.org/abs/2505.00650</link>
      <description>arXiv:2505.00650v1 Announce Type: cross 
Abstract: Unsupervised learning of disease subtypes from multi-omics data presents a significant opportunity for advancing personalized medicine. We introduce OmicsCL, a modular contrastive learning framework that jointly embeds heterogeneous omics modalities-such as gene expression, DNA methylation, and miRNA expression-into a unified latent space. Our method incorporates a survival-aware contrastive loss that encourages the model to learn representations aligned with survival-related patterns, without relying on labeled outcomes. Evaluated on the TCGA BRCA dataset, OmicsCL uncovers clinically meaningful clusters and achieves strong unsupervised concordance with patient survival. The framework demonstrates robustness across hyperparameter configurations and can be tuned to prioritize either subtype coherence or survival stratification. Ablation studies confirm that integrating survival-aware loss significantly enhances the predictive power of learned embeddings. These results highlight the promise of contrastive objectives for biological insight discovery in high-dimensional, heterogeneous omics data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00650v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.GN</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Atahan Karagoz</dc:creator>
    </item>
    <item>
      <title>Integrating Dynamical Systems Modeling with Spatiotemporal scRNA-seq Data Analysis</title>
      <link>https://arxiv.org/abs/2503.11347</link>
      <description>arXiv:2503.11347v2 Announce Type: replace 
Abstract: Understanding the dynamic nature of biological systems is fundamental to deciphering cellular behavior, developmental processes, and disease progression. Single-cell RNA sequencing (scRNA-seq) has provided static snapshots of gene expression, offering valuable insights into cellular states at a single time point. Recent advancements in temporally resolved scRNA-seq, spatial transcriptomics (ST), and time-series spatial transcriptomics (temporal-ST) have further revolutionized our ability to study the spatiotemporal dynamics of individual cells. These technologies, when combined with computational frameworks such as Markov chains, stochastic differential equations (SDEs), and generative models like optimal transport and Schr\"odinger bridges, enable the reconstruction of dynamic cellular trajectories and cell fate decisions. This review discusses how these dynamical system approaches offer new opportunities to model and infer cellular dynamics from a systematic perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.11347v2</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3390/e27050453</arxiv:DOI>
      <arxiv:journal_reference>Entropy-2025</arxiv:journal_reference>
      <dc:creator>Zhenyi Zhang, Yuhao Sun, Qiangwei Peng, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>Cognitive Neural Architecture Search Reveals Hierarchical Entailment</title>
      <link>https://arxiv.org/abs/2502.11141</link>
      <description>arXiv:2502.11141v2 Announce Type: replace-cross 
Abstract: Recent research has suggested that the brain is more shallow than previously thought, challenging the traditionally assumed hierarchical structure of the ventral visual pathway. Here, we demonstrate that optimizing convolutional network architectures for brain-alignment via evolutionary neural architecture search results in models with clear representational hierarchies. Despite having random weights, the identified models achieve brain-alignment scores surpassing even those of pretrained classification models - as measured by both regression and representational similarity analysis. Furthermore, through traditional supervised training, architectures optimized for alignment with late ventral regions become competitive classification models. These findings suggest that hierarchical structure is a fundamental mechanism of primate visual processing. Finally, this work demonstrates the potential of neural architecture search as a framework for computational cognitive neuroscience research that could reduce the field's reliance on manually designed convolutional networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11141v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 02 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lukas Kuhn, Sari Saba-Sadiya, Gemma Roig</dc:creator>
    </item>
  </channel>
</rss>
