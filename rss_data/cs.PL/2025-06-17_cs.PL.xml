<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 18 Jun 2025 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Optimized Execution of FreeCHR</title>
      <link>https://arxiv.org/abs/2506.14485</link>
      <description>arXiv:2506.14485v1 Announce Type: new 
Abstract: Constraint Handling Rules (CHR) is a rule-based programming language that rewrites collections of constraints. It is typically embedded into a general-purpose language. There exists a plethora of implementations for numerous host languages. However, the existing implementations often re-invent the method of embedding, which impedes maintenance and weakens assertions of correctness. To formalize and thereby unify the embedding of a ground subset of CHR into arbitrary host languages, we introduced the framework FreeCHR and proved it to be a valid representation of classical CHR. For the sake of simplicity, abstract implementations of our framework did not yet include a concrete matching algorithm nor optimizations. In this paper, we introduce an improved execution algorithm for FreeCHR. We also provide an evaluation of the algorithm via benchmarks which suggest the effectiveness of our implemented optimizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14485v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sascha Rechenberger, Thom Fr\"uhwirth</dc:creator>
    </item>
    <item>
      <title>Positive Sharing and Abstract Machines</title>
      <link>https://arxiv.org/abs/2506.14131</link>
      <description>arXiv:2506.14131v1 Announce Type: cross 
Abstract: Wu's positive $\lambda$-calculus is a recent call-by-value $\lambda$-calculus with sharing coming from Miller and Wu's study of the proof-theoretical concept of focalization. Accattoli and Wu showed that it simplifies a technical aspect of the study of sharing; namely it rules out the recurrent issue of renaming chains, that often causes a quadratic time slowdown.
  In this paper, we define the natural abstract machine for the positive $\lambda$-calculus and show that it suffers from an inefficiency: the quadratic slowdown somehow reappears when analyzing the cost of the machine. We then design an optimized machine for the positive $\lambda$-calculus, which we prove efficient. The optimization is based on a new slicing technique which is dual to the standard structure of machine environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14131v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Beniamino Accattoli, Claudio Sacerdoti Coen, Jui-Hsuan Wu</dc:creator>
    </item>
    <item>
      <title>Guaranteed Guess: A Language Modeling Approach for CISC-to-RISC Transpilation with Testing Guarantees</title>
      <link>https://arxiv.org/abs/2506.14606</link>
      <description>arXiv:2506.14606v1 Announce Type: cross 
Abstract: The hardware ecosystem is rapidly evolving, with increasing interest in translating low-level programs across different instruction set architectures (ISAs) in a quick, flexible, and correct way to enhance the portability and longevity of existing code. A particularly challenging class of this transpilation problem is translating between complex- (CISC) and reduced- (RISC) hardware architectures, due to fundamental differences in instruction complexity, memory models, and execution paradigms. In this work, we introduce GG (Guaranteed Guess), an ISA-centric transpilation pipeline that combines the translation power of pre-trained large language models (LLMs) with the rigor of established software testing constructs. Our method generates candidate translations using an LLM from one ISA to another, and embeds such translations within a software-testing framework to build quantifiable confidence in the translation. We evaluate our GG approach over two diverse datasets, enforce high code coverage (&gt;98%) across unit tests, and achieve functional/semantic correctness of 99% on HumanEval programs and 49% on BringupBench programs, respectively. Further, we compare our approach to the state-of-the-art Rosetta 2 framework on Apple Silicon, showcasing 1.73x faster runtime performance, 1.47x better energy efficiency, and 2.41x better memory usage for our transpiled code, demonstrating the effectiveness of GG for real-world CISC-to-RISC translation tasks. We will open-source our codes, data, models, and benchmarks to establish a common foundation for ISA-level code translation research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14606v1</guid>
      <category>cs.CL</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmed Heakl, Sarim Hashmi, Chaimaa Abi, Celine Lee, Abdulrahman Mahmoud</dc:creator>
    </item>
    <item>
      <title>A Performance Model for Warp Specialization Kernels</title>
      <link>https://arxiv.org/abs/2506.11209</link>
      <description>arXiv:2506.11209v2 Announce Type: replace 
Abstract: This paper presents a performance model tailored for warp specialization kernels, focusing on factors such as warp size, tilling size, input matrix size, memory bandwidth, and thread divergence. Our model offers accurate predictions of execution time by leveraging differential equations validated through simulations and experiments. The insights gained from this model not only enhance our understanding of warp specialization techniques but also have practical implications for optimizing GPU-accelerated applications through compiler optimizations, kernel parameter tuning, and algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11209v2</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengyang Liu, Vinod Grover</dc:creator>
    </item>
    <item>
      <title>Qwerty: A Basis-Oriented Quantum Programming Language</title>
      <link>https://arxiv.org/abs/2404.12603</link>
      <description>arXiv:2404.12603v2 Announce Type: replace-cross 
Abstract: Quantum computers have leaped from the theoretical realm into a race to large-scale implementations. This is due to the promise of revolutionary speedups, where achieving such speedup requires designing an algorithm that harnesses the structure of a problem using quantum mechanics. Yet many quantum programming languages today require programmers to reason at a low level of physics notation and quantum gate circuitry. This presents a significant barrier to entry for programmers who have not yet built up an intuition about quantum gate semantics, and it can prove to be tedious even for those who have. In this paper, we present Qwerty, a new quantum programming language that allows programmers to manipulate qubits more expressively than gates and trace programs without bra-ket notation. Due to its novel basis type and easy interoperability with Python, Qwerty is a powerful framework for high-level quantum-classical computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12603v2</guid>
      <category>quant-ph</category>
      <category>cs.PL</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin J. Adams, Sharjeel Khan, Arjun S. Bhamra, Ryan R. Abusaada, Jeffrey S. Young, Thomas M. Conte</dc:creator>
    </item>
    <item>
      <title>Controllable and Reliable Knowledge-Intensive Task-Oriented Conversational Agents with Declarative Genie Worksheets</title>
      <link>https://arxiv.org/abs/2407.05674</link>
      <description>arXiv:2407.05674v3 Announce Type: replace-cross 
Abstract: Large Language Models can carry out human-like conversations in diverse settings, responding to user requests for tasks and knowledge. However, existing conversational agents implemented with LLMs often struggle with hallucination, following instructions with conditional logic, and integrating knowledge from different sources. These shortcomings compromise the agents' effectiveness, rendering them unsuitable for deployment. To address these challenges, we introduce Genie, a programmable framework for creating knowledge-intensive task-oriented conversational agents. Genie can handle involved interactions and answer complex queries. Unlike LLMs, it delivers reliable, grounded responses through advanced dialogue state management and supports controllable agent policies via its declarative specification -- Genie Worksheet. This is achieved through an algorithmic runtime system that implements the developer-supplied policy, limiting LLMs to (1) parse user input using a succinct conversational history, and (2) generate responses according to supplied context. Agents built with Genie outperform SOTA methods on complex logic dialogue datasets. We conducted a user study with 62 participants on three real-life applications: restaurant reservations with Yelp, as well as ticket submission and course enrollment for university students. Genie agents with GPT-4 Turbo outperformed the GPT-4 Turbo agents with function calling, improving goal completion rates from 21.8% to 82.8% across three real-world tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05674v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <pubDate>Wed, 18 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harshit Joshi, Shicheng Liu, James Chen, Robert Weigle, Monica S. Lam</dc:creator>
    </item>
  </channel>
</rss>
