<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Dec 2024 02:42:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Fixed Point Iteration Technique for Proving Correctness of Slicing for Probabilistic Programs</title>
      <link>https://arxiv.org/abs/2412.07086</link>
      <description>arXiv:2412.07086v1 Announce Type: new 
Abstract: When proving the correctness of a method for slicing probabilistic programs, it was previously discovered by the authors that for a fixed point iteration to work one needs a non-standard starting point for the iteration.
  This paper presents and explores this technique in a general setting; it states the lemmas that must be established to use the technique to prove the correctness of a program transformation, and sketches how to apply the technique to slicing of probabilistic programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07086v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Torben Amtoft, Anindya Banerjee</dc:creator>
    </item>
    <item>
      <title>Real-Time Performance Optimization of Travel Reservation Systems Using AI and Microservices</title>
      <link>https://arxiv.org/abs/2412.06874</link>
      <description>arXiv:2412.06874v1 Announce Type: cross 
Abstract: The rapid growth of the travel industry has increased the need for real-time optimization in reservation systems that could take care of huge data and transaction volumes. This study proposes a hybrid framework that ut folds an Artificial Intelligence and a Microservices approach for the performance optimization of the system. The AI algorithms forecast demand patterns, optimize the allocation of resources, and enhance decision-making driven by Microservices architecture, hence decentralizing system components for scalability, fault tolerance, and reduced downtime. The model provided focuses on major problems associated with the travel reservation systems such as latency of systems, load balancing and data consistency. It endows the systems with predictive models based on AI improved ability to forecast user demands. Microservices would also take care of different scales during uneven traffic patterns. Hence, both aspects ensure better handling of peak loads and spikes while minimizing delays and ensuring high service quality. A comparison was made between traditional reservation models, which are monolithic and the new model of AI-Microservices. Comparatively, the analysis results state that there is a drastic improvement in processing times where the system uptime and resource utilization proved the capability of AI and the microservices in transforming the travel industry in terms of reservation. This research work focused on AI and Microservices towards real-time optimization, providing critical insight into how to move forward with practical recommendations for upgrading travel reservation systems with this technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06874v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Biman Barua, M. Shamim Kaiser</dc:creator>
    </item>
    <item>
      <title>PyraNet: A Multi-Layered Hierarchical Dataset for Verilog</title>
      <link>https://arxiv.org/abs/2412.06947</link>
      <description>arXiv:2412.06947v1 Announce Type: cross 
Abstract: Recently, there has been a growing interest in leveraging Large Language Models for Verilog code generation. However, the current quality of the generated Verilog code remains suboptimal. This is largely due to the absence of well-defined, well-organized datasets with high-quality samples, as well as a lack of innovative fine-tuning methods and models specifically trained on Verilog. In this paper, we introduce a novel open-source dataset and a corresponding fine-tuning technique, which utilizes a multi-layered structure that we refer to as PyraNet. Our experiments demonstrate that employing the proposed dataset and fine-tuning approach leads to a more accurate fine-tuned model, producing syntactically and functionally correct Verilog code. The evaluation results show improvements by up-to $32.6\%$ in comparison to the CodeLlama-7B baseline model and up-to $16.7\%$ in comparison to the state-of-the-art models using VerilogEval evaluation platform.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06947v1</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bardia Nadimi, Ghali Omar Boutaib, Hao Zheng</dc:creator>
    </item>
    <item>
      <title>Phaedrus: Exploring Dynamic Application Behavior with Lightweight Generative Models and Large-Language Models</title>
      <link>https://arxiv.org/abs/2412.06994</link>
      <description>arXiv:2412.06994v1 Announce Type: cross 
Abstract: Application profiling is an indispensable technique for many software development tasks, such as code optimization and memory management, where optimization decisions are tailored to specific program profiles. Unfortunately, modern applications codebases exhibit highly variant behavior across different inputs, creating challenges for conventional profiling approaches that rely on a single execution instance. In this paper, we propose \textbf{Phaedrus}, a new \textit{compiler-assisted deep learning framework} designed to predict dynamic program behaviors across varied execution scenarios, specifically focusing on dynamic function call prediction.
  Traditional profile-guided optimization methods struggle with the input-dependent variability of modern applications, where profiling on different inputs yields divergent application behaviors. To address this, Phaedrus proposes two new approaches: \textit{Application Profile Generalization}, which uses generative models trained on compressed and augmented \textit{Whole Program Path} (WPP) profiles to predict application behavior under unseen inputs, and \textit{Application Behavior Synthesis}, a profile-less approach where Large Language Models (LLMs) directly infer dynamic functions based on source code \&amp; static compiler analysis, bypassing the need for traditional profiling. Our experiments show that \textit{Phaedrus} can achieve upto $10^7X$ reduction in WPP profile sizes, can predict dynamic hot functions that cover upto 85-99\% of the execution time, along with an average of \textbf{13.46\%} (upto \textbf{65\%}) reduction in application binary size reduction, without profiles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06994v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bodhisatwa Chatterjee, Neeraj Jadhav, Sharjeel Khan, Santosh Pande</dc:creator>
    </item>
    <item>
      <title>Formally Verifiable Generated ASN.1/ACN Encoders and Decoders: A Case Study</title>
      <link>https://arxiv.org/abs/2412.07235</link>
      <description>arXiv:2412.07235v1 Announce Type: cross 
Abstract: We propose a verified executable Scala backend for ASN1SCC, a compiler for ASN.1/ACN. ASN.1 is a language for describing data structures widely employed in ground and space telecommunications. ACN can be used along ASN.1 to describe complex binary formats and legacy protocols. To avoid error-prone and time-consuming manual writing of serializers, we show how to port an ASN.1/ACN code generator to generate Scala code. We then enhance the generator to emit not only the executable code but also strong enough pre-conditions, post-conditions, and lemmas for inductive proofs. This allowed us to verify the resulting generated annotated code using Stainless, a program verifier for Scala. The properties we prove include the absence of runtime errors, such as out-of-bound accesses or divisions by zero. For the base library, we also prove the invertibility of the decoding and encoding functions, showing that decoding yields the encoded value back. Furthermore, our system automatically inserts invertibility proofs for arbitrary records in the generated code, proving over 300'000 verification conditions. We establish key steps towards such proofs for sums and arrays as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07235v1</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mario Bucev, Samuel Chassot, Simon Felix, Filip Schramka, Viktor Kun\v{c}ak</dc:creator>
    </item>
    <item>
      <title>Completeness in static analysis by abstract interpretation, a personal point of view</title>
      <link>https://arxiv.org/abs/2211.09572</link>
      <description>arXiv:2211.09572v3 Announce Type: replace 
Abstract: Static analysis by abstract interpretation is generally designed to be "sound", that is, it should not claim to establish properties that do not hold-in other words, not provide "false negatives" about possible bugs. A rarer requirement is that it should be "complete", meaning that it should be able to infer certain properties if they hold. This paper describes a number of practical issues and questions related to completeness that I have come across over the years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.09572v3</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-981-19-9601-6_6</arxiv:DOI>
      <arxiv:journal_reference>Vincenzo Arceri; Agostino Cortesi; Pietro Ferrara; Martina Olliaro. Challenges of Software Verification, 238, Springer Nature Singapore, pp.93-108, 2023, Intelligent Systems Reference Library, 978-981-19-9600-9</arxiv:journal_reference>
      <dc:creator>David Monniaux (VERIMAG - IMAG)</dc:creator>
    </item>
    <item>
      <title>SECOMP: Formally Secure Compilation of Compartmentalized C Programs</title>
      <link>https://arxiv.org/abs/2401.16277</link>
      <description>arXiv:2401.16277v5 Announce Type: replace 
Abstract: Undefined behavior in C often causes devastating security vulnerabilities. One practical mitigation is compartmentalization, which allows developers to structure large programs into mutually distrustful compartments with clearly specified privileges and interactions. In this paper we introduce SECOMP, a compiler for compartmentalized C code that comes with machine-checked proofs guaranteeing that the scope of undefined behavior is restricted to the compartments that encounter it and become dynamically compromised. These guarantees are formalized as the preservation of safety properties against adversarial contexts, a secure compilation criterion similar to full abstraction, and this is the first time such a strong criterion is proven for a mainstream programming language. To achieve this we extend the languages of the CompCert verified C compiler with isolated compartments that can only interact via procedure calls and returns, as specified by cross-compartment interfaces. We adapt the passes and optimizations of CompCert as well as their correctness proofs to this compartment-aware setting. We then use compiler correctness as an ingredient in a larger secure compilation proof that involves several proof engineering novelties, needed to scale formally secure compilation up to a C compiler.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16277v5</guid>
      <category>cs.PL</category>
      <category>cs.CR</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emy Thibault, Roberto Blanco, Dongjae Lee, Sven Argo, Arthur Azevedo de Amorim, A\"ina Linn Georges, Catalin Hritcu, Andrew Tolmach</dc:creator>
    </item>
  </channel>
</rss>
