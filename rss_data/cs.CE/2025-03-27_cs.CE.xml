<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Mar 2025 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>General Method for Conversion Between Multimode Network Parameters</title>
      <link>https://arxiv.org/abs/2503.20298</link>
      <description>arXiv:2503.20298v1 Announce Type: new 
Abstract: Different types of network parameters have been used in electronics since long ago. The most typical network parameters, but not the only ones, are $S$, $T$, $ABCD$, $Z$, $Y$ , and $h$ that relate input and output signals in different ways. There exist practical formulas for conversion between them. Due to the development of powerful software tools that can deal efficiently and accurately with higher-order modes in each port, researchers need conversion rules between multimode network parameters. However, the usual way to get each conversion rule is just developing cumbersome algebraic manipulations which, at the end, are useful only for some specific conversion. Here, we propose a general algebraic method to obtain any conversion rule between different multimode network parameters. It is based on the assumption of a state vector space and each conversion rule between network parameters can be interpreted as a simple change of basis. This procedure explains any conversion between multimode network parameters under the same algebraic steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20298v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Zhuravlev, Juan D. Baena</dc:creator>
    </item>
    <item>
      <title>Technical Note: Continuum Theory of Mixture for Three-phase Thermomechanical Model of Fiber-reinforced Aerogel Composites</title>
      <link>https://arxiv.org/abs/2503.20713</link>
      <description>arXiv:2503.20713v1 Announce Type: new 
Abstract: We present a thermodynamically consistent three-phase model for the coupled thermal transport and mechanical deformation of ceramic aerogel porous composite materials, which is formulated via continuum mixture theory. The composite comprises a solid silica skeleton, a gaseous fluid phase, and dispersed solid fibers. The thermal transport model incorporates the effects of meso- and macro-pore size variations due to the Knudsen effect, achieved by upscaling phonon transport relations to derive constitutive equations for the fluid thermal conductivity. The mechanical model captures solid-solid and solid-fluid interactions through momentum exchange between phases. A mixed finite element formulation is employed to solve the multiphase model, and numerical studies are conducted to analyze key features of the computational model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20713v1</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pratyush Kumar Singh, Danial Faghihi</dc:creator>
    </item>
    <item>
      <title>Lossy Compression of Scientific Data: Applications Constrains and Requirements</title>
      <link>https://arxiv.org/abs/2503.20031</link>
      <description>arXiv:2503.20031v1 Announce Type: cross 
Abstract: Increasing data volumes from scientific simulations and instruments (supercomputers, accelerators, telescopes) often exceed network, storage, and analysis capabilities. The scientific community's response to this challenge is scientific data reduction. Reduction can take many forms, such as triggering, sampling, filtering, quantization, and dimensionality reduction. This report focuses on a specific technique: lossy compression. Lossy compression retains all data points, leveraging correlations and controlled reduced accuracy. Quality constraints, especially for quantities of interest, are crucial for preserving scientific discoveries. User requirements also include compression ratio and speed. While many papers have been published on lossy compression techniques and reference datasets are shared by the community, there is a lack of detailed specifications of application needs that can guide lossy compression researchers and developers. This report fills this gap by reporting on the requirements and constraints of nine scientific applications covering a large spectrum of domains (climate, combustion, cosmology, fusion, light sources, molecular dynamics, quantum circuit simulation, seismology, and system logs). The report also details key lossy compression technologies (SZ, ZFP, MGARD, LC, SPERR, DCTZ, TEZip, LibPressio), discussing their history, principles, error control, hardware support, features, and impact. By presenting both application needs and compression technologies, the report aims to inspire new research to fill existing gaps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20031v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.CE</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Franck Cappello, Allison Baker, Ebru Bozda, Martin Burtscher, Kyle Chard, Sheng Di, Paul Christopher O Grady, Peng Jiang, Shaomeng Li, Erik Lindahl, Peter Lindstrom, Magnus Lundborg, Kai Zhao, Xin Liang, Masaru Nagaso, Kento Sato, Amarjit Singh, Seung Woo Son, Dingwen Tao, Jiannan Tian, Robert Underwood, Kazutomo Yoshii, Danylo Lykov, Yuri Alexeev, Kyle Gerard Felker</dc:creator>
    </item>
    <item>
      <title>Solving 2-D Helmholtz equation in the rectangular, circular, and elliptical domains using neural networks</title>
      <link>https://arxiv.org/abs/2503.20222</link>
      <description>arXiv:2503.20222v1 Announce Type: cross 
Abstract: Physics-informed neural networks offered an alternate way to solve several differential equations that govern complicated physics. However, their success in predicting the acoustic field is limited by the vanishing-gradient problem that occurs when solving the Helmholtz equation. In this paper, a formulation is presented that addresses this difficulty. The problem of solving the two-dimensional Helmholtz equation with the prescribed boundary conditions is posed as an unconstrained optimization problem using trial solution method. According to this method, a trial neural network that satisfies the given boundary conditions prior to the training process is constructed using the technique of transfinite interpolation and the theory of R-functions. This ansatz is initially applied to the rectangular domain and later extended to the circular and elliptical domains. The acoustic field predicted from the proposed formulation is compared with that obtained from the two-dimensional finite element methods. Good agreement is observed in all three domains considered. Minor limitations associated with the proposed formulation and their remedies are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20222v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jsv.2025.119022</arxiv:DOI>
      <arxiv:journal_reference>Journal of Sound and Vibration, 607, 119022, 2025</arxiv:journal_reference>
      <dc:creator>D. Veerababu, Prasanta K. Ghosh</dc:creator>
    </item>
    <item>
      <title>Dynamic Learning and Productivity for Data Analysts: A Bayesian Hidden Markov Model Perspective</title>
      <link>https://arxiv.org/abs/2503.20233</link>
      <description>arXiv:2503.20233v1 Announce Type: cross 
Abstract: Data analysts are essential in organizations, transforming raw data into insights that drive decision-making and strategy. This study explores how analysts' productivity evolves on a collaborative platform, focusing on two key learning activities: writing queries and viewing peer queries. While traditional research often assumes static models, where performance improves steadily with cumulative learning, such models fail to capture the dynamic nature of real-world learning. To address this, we propose a Hidden Markov Model (HMM) that tracks how analysts transition between distinct learning states based on their participation in these activities.
  Using an industry dataset with 2,001 analysts and 79,797 queries, this study identifies three learning states: novice, intermediate, and advanced. Productivity increases as analysts advance to higher states, reflecting the cumulative benefits of learning. Writing queries benefits analysts across all states, with the largest gains observed for novices. Viewing peer queries supports novices but may hinder analysts in higher states due to cognitive overload or inefficiencies. Transitions between states are also uneven, with progression from intermediate to advanced being particularly challenging. This study advances understanding of into dynamic learning behavior of knowledge worker and offers practical implications for designing systems, optimizing training, enabling personalized learning, and fostering effective knowledge sharing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20233v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.HC</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Yin</dc:creator>
    </item>
    <item>
      <title>A Pretraining-Finetuning Computational Framework for Material Homogenization</title>
      <link>https://arxiv.org/abs/2404.07943</link>
      <description>arXiv:2404.07943v2 Announce Type: replace 
Abstract: Homogenization is a fundamental tool for studying multiscale physical phenomena. Traditional numerical homogenization methods, heavily reliant on finite element analysis, demand significant computational resources, especially for complex geometries, materials, and high-resolution problems. To address these challenges, we propose PreFine-Homo, a novel numerical homogenization framework comprising two phases: pretraining and fine-tuning. In the pretraining phase, a Fourier Neural Operator (FNO) is trained on large datasets to learn the mapping from input geometries and material properties to displacement fields. In the fine-tuning phase, the pretrained predictions serve as initial solutions for iterative algorithms, drastically reducing the number of iterations needed for convergence. The pretraining phase of PreFine-Homo delivers homogenization results up to 1000 times faster than conventional methods, while the fine-tuning phase further enhances accuracy. Moreover, the fine-tuning phase grants PreFine-Homo unlimited generalization capabilities, enabling continuous learning and improvement as data availability increases. We validate PreFine-Homo by predicting the effective elastic tensor for 3D periodic materials, specifically Triply Periodic Minimal Surfaces (TPMS). The results demonstrate that PreFine-Homo achieves high precision, exceptional efficiency, robust learning capabilities, and strong extrapolation ability, establishing it as a powerful tool for multiscale homogenization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07943v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizheng Wang, Xiang Li, Ziming Yan, Shuaifeng Ma, Jinshuai Bai, Bokai Liu, Timon Rabczuk, Yinghua Liu</dc:creator>
    </item>
    <item>
      <title>optipoly: A Python package for boxed-constrained multi-variable polynomial cost functions optimization</title>
      <link>https://arxiv.org/abs/2411.05689</link>
      <description>arXiv:2411.05689v2 Announce Type: replace 
Abstract: In this paper, a new python package (optipoly) is described that solves box-constrained optimization problem over multivariate polynomial cost functions. The principle of the algorithm is described before its performance is compared to three general purpose NLP solvers implemented in the state-of-the-art Gekko and scipy packages. The comparison show statistically better best solution provided by the algorithm with significantly less computation times. The package will be shortly made freely and easily available through the simple (pip install) process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05689v2</guid>
      <category>cs.CE</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mazen Alamir</dc:creator>
    </item>
    <item>
      <title>Assessing Consistency and Reproducibility in the Outputs of Large Language Models: Evidence Across Diverse Finance and Accounting Tasks</title>
      <link>https://arxiv.org/abs/2503.16974</link>
      <description>arXiv:2503.16974v2 Announce Type: replace-cross 
Abstract: This study provides the first comprehensive assessment of consistency and reproducibility in Large Language Model (LLM) outputs in finance and accounting research. We evaluate how consistently LLMs produce outputs given identical inputs through extensive experimentation with 50 independent runs across five common tasks: classification, sentiment analysis, summarization, text generation, and prediction. Using three OpenAI models (GPT-3.5-turbo, GPT-4o-mini, and GPT-4o), we generate over 3.4 million outputs from diverse financial source texts and data, covering MD&amp;As, FOMC statements, finance news articles, earnings call transcripts, and financial statements. Our findings reveal substantial but task-dependent consistency, with binary classification and sentiment analysis achieving near-perfect reproducibility, while complex tasks show greater variability. More advanced models do not consistently demonstrate better consistency and reproducibility, with task-specific patterns emerging. LLMs significantly outperform expert human annotators in consistency and maintain high agreement even where human experts significantly disagree. We further find that simple aggregation strategies across 3-5 runs dramatically improve consistency. We also find that aggregation may come with an additional benefit of improved accuracy for sentiment analysis when using newer models. Simulation analysis reveals that despite measurable inconsistency in LLM outputs, downstream statistical inferences remain remarkably robust. These findings address concerns about what we term "G-hacking," the selective reporting of favorable outcomes from multiple Generative AI runs, by demonstrating that such risks are relatively low for finance and accounting tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16974v2</guid>
      <category>q-fin.GN</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Julian Junyan Wang, Victor Xiaoqi Wang</dc:creator>
    </item>
  </channel>
</rss>
