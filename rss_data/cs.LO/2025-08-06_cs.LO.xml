<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 07 Aug 2025 01:30:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>When are two algorithms the same? Towards addressing Hilbert's 24th problem</title>
      <link>https://arxiv.org/abs/2508.02764</link>
      <description>arXiv:2508.02764v1 Announce Type: new 
Abstract: The informal question of when two theorem proofs are "essentially the same" goes back to David Hilbert, who considered adding it (or something largely equivalent) to his famous list of open problems, but eventually decided to leave it out. Given that the notion of a formal proof is closely related to that of a (computer) program, i.e. a recursive function, it may be useful to ask the same question with regard to programs instead. Here we propose a minimalistic approach to this question within Recursion Theory, building heavily on the use of Kolmogorov Complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02764v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantin Doubrovinski</dc:creator>
    </item>
    <item>
      <title>Intensional FOL over Belnap's Billatice for Strong-AI Robotics</title>
      <link>https://arxiv.org/abs/2508.02774</link>
      <description>arXiv:2508.02774v1 Announce Type: new 
Abstract: AGI (Strong AI) aims to create intelligent robots that are quasi indistinguishable from the human mind. Like a child, the AGI robot would have to learn through input and experiences, constantly progressing and advancing its abilities over time. The AGI robot would require an intelligence more close to human's intelligence: it would have a self-aware consciousness that has the ability to solve problems, learn, and plan. Based on this approach an Intensional many-sorted First-order Logic (IFOL), as an extension of a standard FOL with Tarskian's semantics, is proposed in order to avoid the problems of standard 2-valued FOL with paradoxes (inconsistent formulae) and a necessity for robots to work with incomplete (unknown) knowledge as well. This is a more sophisticated version of IFOL with the same syntax but different semantics, able to deal with truth-ordering and knowledge-ordering as well, based on the well known Belnap's billatice with four truth-values that extend the set of classical two truth-values.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02774v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zoran Majkic</dc:creator>
    </item>
    <item>
      <title>Analysis of logics with arithmetic</title>
      <link>https://arxiv.org/abs/2508.03574</link>
      <description>arXiv:2508.03574v1 Announce Type: new 
Abstract: We present new results on finite satisfiability of logics with counting and arithmetic. This includes tight bounds on the complexity for two-variable logic with counting and cardinality comparisons between unary formulas, and also on logics with so-called local Presburger quantifiers. In the process, we provide simpler proofs of some key prior results on finite satisfiability and semi-linearity of the spectrum for these logics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03574v1</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Benedikt, Chia-Hsuan Lu, Tony Tan</dc:creator>
    </item>
    <item>
      <title>Bridging LLMs and Symbolic Reasoning in Educational QA Systems: Insights from the XAI Challenge at IJCNN 2025</title>
      <link>https://arxiv.org/abs/2508.01263</link>
      <description>arXiv:2508.01263v1 Announce Type: cross 
Abstract: The growing integration of Artificial Intelligence (AI) into education has intensified the need for transparency and interpretability. While hackathons have long served as agile environments for rapid AI prototyping, few have directly addressed eXplainable AI (XAI) in real-world educational contexts. This paper presents a comprehensive analysis of the XAI Challenge 2025, a hackathon-style competition jointly organized by Ho Chi Minh City University of Technology (HCMUT) and the International Workshop on Trustworthiness and Reliability in Neurosymbolic AI (TRNS-AI), held as part of the International Joint Conference on Neural Networks (IJCNN 2025). The challenge tasked participants with building Question-Answering (QA) systems capable of answering student queries about university policies while generating clear, logic-based natural language explanations. To promote transparency and trustworthiness, solutions were required to use lightweight Large Language Models (LLMs) or hybrid LLM-symbolic systems. A high-quality dataset was provided, constructed via logic-based templates with Z3 validation and refined through expert student review to ensure alignment with real-world academic scenarios. We describe the challenge's motivation, structure, dataset construction, and evaluation protocol. Situating the competition within the broader evolution of AI hackathons, we argue that it represents a novel effort to bridge LLMs and symbolic reasoning in service of explainability. Our findings offer actionable insights for future XAI-centered educational systems and competitive research initiatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01263v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long S. T. Nguyen, Khang H. N. Vo, Thu H. A. Nguyen, Tuan C. Bui, Duc Q. Nguyen, Thanh-Tung Tran, Anh D. Nguyen, Minh L. Nguyen, Fabien Baldacci, Thang H. Bui, Emanuel Di Nardo, Angelo Ciaramella, Son H. Le, Ihsan Ullah, Lorenzo Di Rocco, Tho T. Quan</dc:creator>
    </item>
    <item>
      <title>Optimal Simultaneous Byzantine Agreement, Common Knowledge and Limited Information Exchange</title>
      <link>https://arxiv.org/abs/2508.03418</link>
      <description>arXiv:2508.03418v1 Announce Type: cross 
Abstract: In order to develop solutions that perform actions as early as possible, analysis of distributed algorithms using epistemic logic has generally concentrated on ``full information protocols'', which may be inefficient with respect to space and computation time. The paper reconsiders the epistemic analysis of the problem of Simultaneous Byzantine Agreement with respect to weaker, but more practical, exchanges of information. The paper first clarifies some issues concerning both the specification of this problem and the knowledge based program characterizing its solution, concerning the distinction between the notions of ``nonfaulty'' and ``not yet failed'', on which there are variances in the literature. It is then shown that, when implemented relative to a given failure model and an information exchange protocol satisfying certain conditions, this knowledge based program yields a protocol that is optimal relative to solutions using the same information exchange. Conditions are also identified under which this implementation is also an optimum, but an example is provided that shows this does not hold in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03418v1</guid>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ron van der Meyden</dc:creator>
    </item>
    <item>
      <title>Difference-restriction algebras with operators</title>
      <link>https://arxiv.org/abs/2508.03432</link>
      <description>arXiv:2508.03432v1 Announce Type: cross 
Abstract: We exhibit an adjunction between a category of abstract algebras of partial functions that we call difference-restriction algebras and a category of Hausdorff \'etale spaces. Difference-restriction algebras are those algebras isomorphic to a collection of partial functions closed under relative complement and domain restriction. Our adjunction generalises the adjunction between the category of generalised Boolean algebras and the category of Hausdorff spaces. We define the finitary compatible completion of a difference-restriction algebra and show that the monad induced by our adjunction yields the finitary compatible completion of any difference-restriction algebra. As a corollary, the adjunction restricts to a duality between the finitarily compatibly complete difference-restriction algebras and the locally compact zero-dimensional Hausdorff \'etale spaces, generalising the duality between generalised Boolean algebras and locally compact zero-dimensional Hausdorff spaces. We then extend these adjunction, duality, and completion results to difference-restriction algebras equipped with arbitrary additional compatibility preserving operators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03432v1</guid>
      <category>math.LO</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'elia Borlido, Ganna Kudryavtseva, Brett McLean</dc:creator>
    </item>
    <item>
      <title>Effective AGM Belief Contraction: A Journey beyond the Finitary Realm (Technical Report)</title>
      <link>https://arxiv.org/abs/2409.09171</link>
      <description>arXiv:2409.09171v2 Announce Type: replace 
Abstract: Despite significant efforts towards extending the AGM paradigm of belief change beyond finitary logics, the computational aspects of AGM have remained almost untouched. We investigate the computability of AGM contraction on non-finitary logics, and show an intriguing negative result: there are infinitely many uncomputable AGM contraction functions in such logics. Drastically, we also show that the current de facto standard strategies to control computability, which rely on restricting the space of epistemic states, fail: uncomputability remains in all non-finitary cases. Motivated by this disruptive result, we propose new approaches to controlling computability beyond the finitary realm. Using Linear Temporal Logic (LTL) as a case study, we identify an infinite class of fully-rational AGM contraction functions that are computable by design. We use B\"uchi automata to construct such functions, and to represent and reason about LTL beliefs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09171v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Klumpp, Jandson S. Ribeiro</dc:creator>
    </item>
    <item>
      <title>Deciding subspace reachability problems with application to Skolem's Problem</title>
      <link>https://arxiv.org/abs/2410.06528</link>
      <description>arXiv:2410.06528v2 Announce Type: replace 
Abstract: The higher-dimensional version of Kannan and Lipton's Orbit Problem asks whether it is decidable if a target subspace can be reached from a starting point under repeated application of a linear transformation. Similarly, the continuous analog of the Orbit Problem asks if a flow induced by a linear system of differential equations ever reaches some specified subspace. The decidability of both problems remains open, and in fact the problems generalize the discrete and continuous versions of Skolem's Problem. The object of this paper is to communicate a geometric perspective of the discrete and continuous Orbit Problems, alternate to the traditional and highly technical algebraic and number-theoretic approaches to the problem. We derive a simple decision procedure capable of deciding a certain class of instances of the Orbit Problem, and, as an application, we obtain alternate proofs to a number of results using elementary geometric arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06528v2</guid>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Everett</dc:creator>
    </item>
    <item>
      <title>Cobblestone: A Divide-and-Conquer Approach for Automating Formal Verification</title>
      <link>https://arxiv.org/abs/2410.19940</link>
      <description>arXiv:2410.19940v3 Announce Type: replace 
Abstract: Formal verification using proof assistants, such as Coq, is an effective way of improving software quality, but requires significant effort and expertise. Machine learning can automatically synthesize proofs, but such tools are able to prove only a fraction of desired software properties. We introduce Cobblestone, a divide-and-conquer approach for proof synthesis. Cobblestone uses a large language model (LLM) to generate potential proofs, uses those proofs to break the problem into simpler parts, automatically identifies which of those parts were successfully proven, and iterates on the remaining parts to build a correct proof that is guaranteed to be sound, despite the reliance on unsound LLMs. We evaluate Cobblestone on four benchmarks of open-source Coq projects, controlling for training data leakage. Fully automatically, Cobblestone outperforms state-of-the-art non-LLM tools, and proves many theorems that other LLM-based tools cannot, and on many benchmarks, outperforms them. Each Cobblestone run costs only $1.25 and takes 14.7 minutes, on average. Cobblestone can also be used with external input, from a user or another tool, providing a proof structure or relevant lemmas. Evaluated with such an oracle, Cobblestone proves up to 58% of theorems. Overall, our research shows that tools can make use of partial progress and external input to more effectively automate formal verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19940v3</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saketh Ram Kasibatla, Arpan Agarwal, Yuriy Brun, Sorin Lerner, Talia Ringer, Emily First</dc:creator>
    </item>
    <item>
      <title>A Myhill-Nerode Theorem for Generalized Automata, with Applications to Pattern Matching and Compression</title>
      <link>https://arxiv.org/abs/2302.06506</link>
      <description>arXiv:2302.06506v3 Announce Type: replace-cross 
Abstract: The model of generalized automata, introduced by Eilenberg in 1974, allows representing a regular language more concisely than conventional automata by allowing edges to be labeled not only with characters, but also strings. Giammaresi and Montalbano introduced a notion of determinism for generalized automata [STACS 1995]. While generalized deterministic automata retain many properties of conventional deterministic automata, the uniqueness of a minimal generalized deterministic automaton is lost.
  In the first part of the paper, we show that the lack of uniqueness can be explained by introducing a set $ \mathcal{W(A)} $ associated with a generalized automaton $ \mathcal{A} $. In this way, we derive for the first time a full Myhill-Nerode theorem for generalized automata, which contains the textbook Myhill-Nerode theorem for conventional automata as a degenerate case. In the second part of the paper, we show that the set $ \mathcal{W(A)} $ leads to applications for pattern matching and data compression. We show that a Wheeler generalized automata can be stored using $ \mathfrak{e} \log \sigma (1 + o(1)) + O(e) $ bits so that pattern matching queries can be solved in $ O(m \log \log \sigma) $ time, where $ \mathfrak{e} $ is the total length of all edge labels, $ e $ is the number of edges, $ \sigma $ is the size of the alphabet and $ m $ is the length of the pattern.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.06506v3</guid>
      <category>cs.FL</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nicola Cotumaccio</dc:creator>
    </item>
    <item>
      <title>Set-Based Training for Neural Network Verification</title>
      <link>https://arxiv.org/abs/2401.14961</link>
      <description>arXiv:2401.14961v4 Announce Type: replace-cross 
Abstract: Neural networks are vulnerable to adversarial attacks, i.e., small input perturbations can significantly affect the outputs of a neural network. Therefore, to ensure safety of neural networks in safety-critical environments, the robustness of a neural network must be formally verified against input perturbations, e.g., from noisy sensors. To improve the robustness of neural networks and thus simplify the formal verification, we present a novel set-based training procedure in which we compute the set of possible outputs given the set of possible inputs and compute for the first time a gradient set, i.e., each possible output has a different gradient. Therefore, we can directly reduce the size of the output enclosure by choosing gradients toward its center. Small output enclosures increase the robustness of a neural network and, at the same time, simplify its formal verification. The latter benefit is due to the fact that a larger size of propagated sets increases the conservatism of most verification methods. Our extensive evaluation demonstrates that set-based training produces robust neural networks with competitive performance, which can be verified using fast (polynomial-time) verification algorithms due to the reduced output set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14961v4</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lukas Koller, Tobias Ladner, Matthias Althoff</dc:creator>
    </item>
    <item>
      <title>HypRL: Reinforcement Learning of Control Policies for Hyperproperties</title>
      <link>https://arxiv.org/abs/2504.04675</link>
      <description>arXiv:2504.04675v4 Announce Type: replace-cross 
Abstract: Reward shaping in multi-agent reinforcement learning (MARL) for complex tasks remains a significant challenge. Existing approaches often fail to find optimal solutions or cannot efficiently handle such tasks. We propose HYPRL, a specification-guided reinforcement learning framework that learns control policies w.r.t. hyperproperties expressed in HyperLTL. Hyperproperties constitute a powerful formalism for specifying objectives and constraints over sets of execution traces across agents. To learn policies that maximize the satisfaction of a HyperLTL formula $\phi$, we apply Skolemization to manage quantifier alternations and define quantitative robustness functions to shape rewards over execution traces of a Markov decision process with unknown transitions. A suitable RL algorithm is then used to learn policies that collectively maximize the expected reward and, consequently, increase the probability of satisfying $\phi$. We evaluate HYPRL on a diverse set of benchmarks, including safety-aware planning, Deep Sea Treasure, and the Post Correspondence Problem. We also compare with specification-driven baselines to demonstrate the effectiveness and efficiency of HYPRL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.04675v4</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tzu-Han Hsu, Arshia Rafieioskouei, Borzoo Bonakdarpour</dc:creator>
    </item>
    <item>
      <title>Consistency-based Abductive Reasoning over Perceptual Errors of Multiple Pre-trained Models in Novel Environments</title>
      <link>https://arxiv.org/abs/2505.19361</link>
      <description>arXiv:2505.19361v2 Announce Type: replace-cross 
Abstract: The deployment of pre-trained perception models in novel environments often leads to performance degradation due to distributional shifts. Although recent artificial intelligence approaches for metacognition use logical rules to characterize and filter model errors, improving precision often comes at the cost of reduced recall. This paper addresses the hypothesis that leveraging multiple pre-trained models can mitigate this recall reduction. We formulate the challenge of identifying and managing conflicting predictions from various models as a consistency-based abduction problem, building on the idea of abductive learning (ABL) but applying it to test-time instead of training. The input predictions and the learned error detection rules derived from each model are encoded in a logic program. We then seek an abductive explanation--a subset of model predictions--that maximizes prediction coverage while ensuring the rate of logical inconsistencies (derived from domain constraints) remains below a specified threshold. We propose two algorithms for this knowledge representation task: an exact method based on Integer Programming (IP) and an efficient Heuristic Search (HS). Through extensive experiments on a simulated aerial imagery dataset featuring controlled, complex distributional shifts, we demonstrate that our abduction-based framework outperforms individual models and standard ensemble baselines, achieving, for instance, average relative improvements of approximately 13.6\% in F1-score and 16.6\% in accuracy across 15 diverse test datasets when compared to the best individual model. Our results validate the use of consistency-based abduction as an effective mechanism to robustly integrate knowledge from multiple imperfect models in challenging, novel scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19361v2</guid>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Leiva, Noel Ngu, Joshua Shay Kricheli, Aditya Taparia, Ransalu Senanayake, Paulo Shakarian, Nathaniel Bastian, John Corcoran, Gerardo Simari</dc:creator>
    </item>
    <item>
      <title>Modeling Deontic Modal Logic in the s(CASP) Goal-directed Predicate Answer Set Programming System</title>
      <link>https://arxiv.org/abs/2507.05519</link>
      <description>arXiv:2507.05519v5 Announce Type: replace-cross 
Abstract: We consider the problem of implementing deontic modal logic. We show how (deontic) modal operators can be expressed elegantly using default negation (negation-as-failure) and strong negation present in answer set programming (ASP). We propose using global constraints of ASP to represent obligations and impermissibilities of deontic modal logic. We show that our proposed representation results in the various paradoxes of deontic modal logic being elegantly resolved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05519v5</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Wed, 06 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gopal Gupta, Abhiramon Rajasekharan, Alexis R. Tudor, Elmer Salazar, Joaqu\'in Arias</dc:creator>
    </item>
  </channel>
</rss>
