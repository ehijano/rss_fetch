<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 05:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Design for Dynamic Fitness: Archetypes of urban water systems</title>
      <link>https://arxiv.org/abs/2601.17147</link>
      <description>arXiv:2601.17147v1 Announce Type: new 
Abstract: In an era of accelerating change, urban water infrastructure systems increasingly operate outside of their design conditions, putting new pressure on systems' institutional designs to weather emerging challenges. Water management institutions must therefore be designed to exhibit dynamic fitness, defined by anticipatory capacity and responsiveness. However, we do not yet understand the specific features of institutional design that enable dynamic fitness, especially in relation to the diverse biophysical characteristics of systems that such fitness is contingent upon. We advance research on dynamic fitness in the context of urban water supply systems by drawing on 35-year data sets of stressors and responses for 16 U.S. urban water utilities using archetype analysis. Here we find that institutional archetypes capable of coping with higher biophysical complexity invest in both information processing capacity and response diversity. While dynamic fitness comes at a cost, balance between information processing capacity and response diversity promotes efficiency, which can be expanded through polycentric regional institutional structures that facilitate information sharing. Lastly, careful consideration should be given to tradeoffs across levels of governance, as institutional structures that facilitate dynamic fitness at the utility level may reduce the control and flexibility of higher levels of governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17147v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Margaret Garcia, Aaron Deslatte, Elizabeth A. Koebele, George Hornberger, John M. Anderies, Sara Alonso Vicario, Koorosh Azizi, Jesse Barnes, Adam Wiechman</dc:creator>
    </item>
    <item>
      <title>Information Design and Mechanism Design: An Integrated Framework</title>
      <link>https://arxiv.org/abs/2601.17267</link>
      <description>arXiv:2601.17267v1 Announce Type: new 
Abstract: We develop an integrated framework for information design and mechanism design in screening environments with quasilinear utility. Using the tools of majorization theory and quantile functions, we show that both information design and mechanism design problems reduce to maximizing linear functionals subject to majorization constraints. For mechanism design, the designer chooses allocations weakly majorized by the exogenous inventory. For information design, the designer chooses information structures that are majorized by the prior distribution. When the designer can choose both the mechanism and the information structure simultaneously, then the joint optimization problem becomes bilinear with two majorization constraints. We show that pooling of values and associated allocations is always optimal in this case. Our approach unifies classic results in auction theory and screening, extends them to information design settings, and provides new insights into the welfare effects of jointly optimizing allocation and information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17267v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dirk Bergemann, Tibor Heumann, Stephen Morris</dc:creator>
    </item>
    <item>
      <title>Pass-through with Price Dispersion</title>
      <link>https://arxiv.org/abs/2601.17964</link>
      <description>arXiv:2601.17964v1 Announce Type: new 
Abstract: How do cost shocks pass through to prices in markets with price dispersion? Pass-through analysis typically assumes a single equilibrium price, but empirical studies consistently document substantial price variation, even for homogeneous products. This paper develops a tractable framework that decomposes the pass-through problem into two distinct tiers. The first is a competition layer where consumers' \textit{consideration sets} determine equilibrium distributions of normalized margins. The second is a curvature layer where demand elasticity determines how these margins translate into prices and pass-through rates. The key theoretical innovation is showing that the strategic pricing game with arbitrary downward-sloping demand is order-isomorphic to a baseline unit-demand game once reformulated in terms of normalized effective margins. This decomposition yields closed-form pass-through formulas, robust bounds across demand specifications, and clear comparative statics linking market structure to incidence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17964v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brian C. Albrecht, Mark Whitmeyer</dc:creator>
    </item>
    <item>
      <title>The Cost of Inflation</title>
      <link>https://arxiv.org/abs/2601.18544</link>
      <description>arXiv:2601.18544v1 Announce Type: new 
Abstract: Empirical evidence suggests that there is little to no correlation between the rate of inflation and the size of price change. Economists have hitherto taken this to mean that monetary shocks do not generate much deviation in relative prices and therefore inflation does not hurt the economy by impeding the workings of the price system. This paper presents a production network model of inflationary dynamics in which it is well possible for inflation to have near-zero correlation with the size of price change yet cause significant distortion of relative prices. The relative price distortion caused by inflation critically depends on the spectral gap, degree distribution, and assortativity of the production network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18544v1</guid>
      <category>econ.TH</category>
      <category>cs.SI</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vipin P Veetil</dc:creator>
    </item>
    <item>
      <title>Optimal Use of Preferences in Artificial Intelligence Algorithms</title>
      <link>https://arxiv.org/abs/2601.18732</link>
      <description>arXiv:2601.18732v1 Announce Type: new 
Abstract: Machine learning systems embed preferences either in training losses or through post-processing of calibrated predictions. Applying information design methods from Strack and Yang (2024), this paper provides decision problem agnostic conditions under which separation training preference free and applying preferences ex post is optimal. Unlike prior work that requires specifying downstream objectives, the welfare results here apply uniformly across decision problems. The key primitive is a diminishing-value-of-information condition: relative to a fixed (normalised) preference-free loss, preference embedding makes informativeness less valuable at the margin, inducing a mean-preserving contraction of learned posteriors. Because the value of information is convex in beliefs, preference-free training weakly dominates for any expected utility decision problem. This provides theoretical foundations for modular AI pipelines that learn calibrated probabilities and implement asymmetric costs through downstream decision rules. However, separation requires users to implement optimal decision rules. When cognitive constraints bind, as documented in human AI decision-making, preference embedding can dominate by automating threshold computation. These results provide design guidance: preserve optionality through post-processing when objectives may shift; embed preferences when decision-stage frictions dominate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18732v1</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joshua S. Gans</dc:creator>
    </item>
    <item>
      <title>When Is Self-Disclosure Optimal? Incentives and Governance of AI-Generated Content</title>
      <link>https://arxiv.org/abs/2601.18654</link>
      <description>arXiv:2601.18654v1 Announce Type: cross 
Abstract: Generative artificial intelligence (Gen-AI) is reshaping content creation on digital platforms by reducing production costs and enabling scalable output of varying quality. In response, platforms have begun adopting disclosure policies that require creators to label AI-generated content, often supported by imperfect detection and penalties for non-compliance. This paper develops a formal model to study the economic implications of such disclosure regimes. We compare a non-disclosure benchmark, in which the platform alone detects AI usage, with a mandatory self-disclosure regime in which creators strategically choose whether to disclose or conceal AI use under imperfect enforcement. The model incorporates heterogeneous creators, viewer discounting of AI-labeled content, trust penalties following detected non-disclosure, and endogenous enforcement. The analysis shows that disclosure is optimal only when both the value of AI-generated content and its cost-saving advantage are intermediate. As AI capability improves, the platform's optimal enforcement strategy evolves from strict deterrence to partial screening and eventual deregulation. While disclosure reliably increases transparency, it reduces aggregate creator surplus and can suppress high-quality AI content when AI is technologically advanced. Overall, the results characterize disclosure as a strategic governance instrument whose effectiveness depends on technological maturity and trust frictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18654v1</guid>
      <category>cs.CY</category>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Wu (James),  Zhe (James),  Zhang, Amit Mehra</dc:creator>
    </item>
    <item>
      <title>Optimal Decision Mechanisms for Committees: Acquitting the Guilty</title>
      <link>https://arxiv.org/abs/2407.07293</link>
      <description>arXiv:2407.07293v2 Announce Type: replace 
Abstract: A group of privately informed agents chooses between two alternatives. How should the decision rule be designed if agents are known to be biased in favor of one of the options? We address this question by considering the Condorcet Jury Setting as a mechanism design problem. Applications include the optimal decision mechanisms for boards of directors, political committees, and trial juries.
  While we allow for any kind of mechanism, the optimal mechanism is a voting mechanism. In the terminology of the trial jury example: When jurors (agents) are more eager to convict than the lawmaker (principal), then the defendant should be convicted if and only if neither too many nor too few jurors vote to convict.
  This kind of mechanism accords with a judicial procedure from ancient Jewish law.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07293v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deniz Kattwinkel, Alexander Winter</dc:creator>
    </item>
    <item>
      <title>Inattention to States and Characteristics</title>
      <link>https://arxiv.org/abs/2508.05939</link>
      <description>arXiv:2508.05939v2 Announce Type: replace 
Abstract: We introduce a rational inattention model which produces a unique, interior, weighted multinomial logit conditional choice probability for an agent who acquires costly information about the hedonic characteristics (e.g. whether an insurance contract has high coverage) of their choices and about their payoff-relevant states (e.g. their risk of incurring a loss).
  As usual, the objective is to choose a joint distribution subject to one marginal constraint (``Bayes plausibility''). We approach the problem by re-writing it in terms of an inner problem of maximizing over \textit{two} constraints and an outer problem of choosing the ``optimal constraint.'' The inner problem is a Schr\"odinger bridge problem. The outer problem is strictly concave.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05939v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chris Engh</dc:creator>
    </item>
    <item>
      <title>The core of Shapley-Scarf markets with full preferences</title>
      <link>https://arxiv.org/abs/2511.21158</link>
      <description>arXiv:2511.21158v3 Announce Type: replace 
Abstract: We examine core concepts in the classical model of Shapley and Scarf (1974) under full preferences. Among the standard concepts, the strong core may be empty, whereas the nonempty weak core may be overly large and contain inefficient elements. Our main findings are: (1) The exclusion core of Balbuzanov and Kotowski (2019) -- a recent concept outperforming standard concepts in complex environments under strict preferences -- can also be empty, yet it is more often nonempty than the strong core. (2) We introduce two new core concepts, respectively built on the exclusion core and the strong core. Both are nonempty and Pareto efficient, and coincide with the strong core whenever it is nonempty. (3) These core concepts are ordered by set inclusion, with the strong core as the smallest and the weak core as the largest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21158v3</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jun Zhang</dc:creator>
    </item>
    <item>
      <title>The incompatibility of the Condorcet winner and loser criteria with positive involvement and resolvability</title>
      <link>https://arxiv.org/abs/2601.10506</link>
      <description>arXiv:2601.10506v3 Announce Type: replace 
Abstract: We prove that there is no preferential voting method satisfying the Condorcet winner and loser criteria, positive involvement (if a candidate $x$ wins in an initial preference profile, then adding a voter who ranks $x$ uniquely first cannot cause $x$ to lose), and $n$-voter resolvability (if $x$ initially ties for winning, then $x$ can be made the unique winner by adding some set of up to $n$ voters). This impossibility theorem holds for any positive integer $n$. In a previous note, we proved an analogous result assuming an additional axiom of ordinal margin invariance, which we now show is unnecessary for an impossibility theorem, at least if the desired voting method is defined for five-candidate elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10506v3</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday</dc:creator>
    </item>
    <item>
      <title>Capital Games and Growth Equilibria</title>
      <link>https://arxiv.org/abs/2510.00472</link>
      <description>arXiv:2510.00472v2 Announce Type: replace-cross 
Abstract: We introduce capital games, which generalize the definition of standard games to incorporate dynamics. In capital games, payoffs are in units of capital which are not assumed to be units of utility. The dynamics allow us to infer player utilities from their individual payoffs and linearizable capital dynamics under the assumption that players aim to maximize the time-average growth rate of their capital.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00472v2</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Abramowitz</dc:creator>
    </item>
    <item>
      <title>Collective intelligence in science: direct elicitation of diverse information from experts with unknown information structure</title>
      <link>https://arxiv.org/abs/2601.14047</link>
      <description>arXiv:2601.14047v2 Announce Type: replace-cross 
Abstract: Suppose we need a deep collective analysis of an open scientific problem: there is a complex scientific hypothesis and a large online group of mutually unrelated experts with relevant private information of a diverse and unpredictable nature. This information may be results of experts' individual experiments, original reasoning of some of them, results of AI systems they use, etc. We propose a simple mechanism based on a self-resolving play-money prediction market entangled with a chat. We show that such a system can easily be brought to an equilibrium where participants directly share their private information on the hypothesis through the chat and trade as if the market were resolved in accordance with the truth of the hypothesis. This approach will lead to efficient aggregation of relevant information in a completely interpretable form even if the ground truth cannot be established and experts initially know nothing about each other and cannot perform complex Bayesian calculations. Finally, by rewarding the experts with some real assets proportionally to the play money they end up with, we can get an innovative way to fund large-scale collaborative studies of any type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14047v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>econ.TH</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexey V. Osipov, Nikolay N. Osipov</dc:creator>
    </item>
  </channel>
</rss>
