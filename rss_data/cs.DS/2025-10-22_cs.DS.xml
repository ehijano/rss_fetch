<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 01:41:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Assignment-Routing Optimization with Cutting-Plane Subtour Elimination: Solver and Benchmark Dataset</title>
      <link>https://arxiv.org/abs/2510.17888</link>
      <description>arXiv:2510.17888v1 Announce Type: new 
Abstract: We study a joint routing-assignment optimization problem in which a set of items must be paired one-to-one with a set of placeholders while simultaneously determining a Hamiltonian cycle that visits every node exactly once. Both the assignment and routing decisions are optimized jointly to minimize the total travel cost. In this work, we propose a method to solve this problem using an exact MIP formulation with Gurobi, including cutting-plane subtour elimination. With analysis of the computational complexity and through extensive experiments, we analyze the computational limitations of this approach as the problem size grows and reveal the challenges associated with the need for more efficient algorithms for larger instances. The dataset, formulations, and experimental results provided here can serve as benchmarks for future studies in this research area. GitHub repository: https://github.com/QL-YUAN/Joint-Assignment-Routing-Optimization</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17888v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qilong Yuan</dc:creator>
    </item>
    <item>
      <title>Online Randomness Extraction: Simulating Barely Random Algorithms in the Random Order Arrival Model</title>
      <link>https://arxiv.org/abs/2510.18049</link>
      <description>arXiv:2510.18049v1 Announce Type: new 
Abstract: Interest in the random order model (ROM) leads us to initiate a study of utilizing random-order arrivals to extract random bits with the goal of de-randomizing algorithms. Besides producing simple algorithms, simulating random bits through random arrivals enhances our understanding of the comparative strength of randomized online algorithms (with adversarial input sequence) and deterministic algorithms in the ROM. We consider three $1$-bit randomness extraction processes. Our best extraction process returns a bit with a worst-case bias of $2 - \sqrt{2} \approx 0.585$ and operates under the mild assumption that there exist at least two distinct items in the input. We motivate the applicability of this process by using it to simulate a number of barely random algorithms for weighted interval selection (single-length arbitrary weights, as well as monotone, C-benevolent and D-benevolent weighted instances), the proportional and general knapsack problems, binary string guessing, and unweighted job throughput scheduling.
  It is well known that there are many applications where a deterministic ROM algorithm significantly outperforms any randomized online algorithm (in terms of competitive ratios). The classic example is that of the secretary problem. We ask the following fundamental question: Is there any application for which a randomized algorithm outperforms any deterministic ROM algorithm? Motivated by this question, we view our randomness extraction applications as a constructive approach towards understanding the relation between randomized online algorithms and deterministic ROM algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18049v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Borodin, Christodoulos Karavasilis, David Zhang</dc:creator>
    </item>
    <item>
      <title>Fast Agnostic Learners in the Plane</title>
      <link>https://arxiv.org/abs/2510.18057</link>
      <description>arXiv:2510.18057v1 Announce Type: new 
Abstract: We investigate the computational efficiency of agnostic learning for several fundamental geometric concept classes in the plane. While the sample complexity of agnostic learning is well understood, its time complexity has received much less attention. We study the class of triangles and, more generally, the class of convex polygons with $k$ vertices for small $k$, as well as the class of convex sets in a square. We present a proper agnostic learner for the class of triangles that has optimal sample complexity and runs in time $\tilde O({\epsilon^{-6}})$, improving on the algorithm of Dobkin and Gunopulos (COLT `95) that runs in time $\tilde O({\epsilon^{-10}})$. For 4-gons and 5-gons, we improve the running time from $O({\epsilon^{-12}})$, achieved by Fischer and Kwek (eCOLT `96), to $\tilde O({\epsilon^{-8}})$ and $\tilde O({\epsilon^{-10}})$, respectively.
  We also design a proper agnostic learner for convex sets under the uniform distribution over a square with running time $\tilde O({\epsilon^{-5}})$, improving on the previous $\tilde O(\epsilon^{-8})$ bound at the cost of slightly higher sample complexity. Notably, agnostic learning of convex sets in $[0,1]^2$ under general distributions is impossible because this concept class has infinite VC-dimension. Our agnostic learners use data structures and algorithms from computational geometry and their analysis relies on tools from geometry and probabilistic combinatorics. Because our learners are proper, they yield tolerant property testers with matching running times. Our results raise a fundamental question of whether a gap between the sample and time complexity is inherent for agnostic learning of these and other natural concept classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18057v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Talya Eden, Ludmila Glinskih, Sofya Raskhodnikova</dc:creator>
    </item>
    <item>
      <title>A Generalization of Distance Domination</title>
      <link>https://arxiv.org/abs/2510.18066</link>
      <description>arXiv:2510.18066v1 Announce Type: new 
Abstract: Expanding on the graph theoretic ideas of k-component order connectivity and distance-l domination, we present a quadratic-complexity algorithm that finds a tree's minimum failure-set cardinality, i.e., the minimum cardinality any subset of the tree's vertices must have so that all clusters of vertices further away than some l do not exceed a cardinality threshold. Applications of solutions to the expanded problems include choosing service center locations so that no large neighborhoods are excluded from service, while reducing the redundancy inherent in distance domination problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18066v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alicia Muth, E. Dov Neimand</dc:creator>
    </item>
    <item>
      <title>Fingerprint Filters Are Optimal</title>
      <link>https://arxiv.org/abs/2510.18129</link>
      <description>arXiv:2510.18129v1 Announce Type: new 
Abstract: Dynamic filters are data structures supporting approximate membership queries to a dynamic set $S$ of $n$ keys, allowing a small false-positive error rate $\varepsilon$, under insertions and deletions to the set $S$. Essentially all known constructions for dynamic filters use a technique known as fingerprinting. This technique, which was first introduced by Carter et al. in 1978, inherently requires $$\log \binom{n \varepsilon^{-1}}{n} = n \log \varepsilon^{-1} + n \log e - o(n)$$ bits of space when $\varepsilon = o(1)$. Whether or not this bound is optimal for all dynamic filters (rather than just for fingerprint filters) has remained for decades as one of the central open questions in the area. We resolve this question by proving a sharp lower bound of $n \log \varepsilon^{-1} + n \log e - o(n)$ bits for $\varepsilon = o(1)$, regardless of operation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18129v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>William Kuszmaul, Jingxun Liang, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>A Simpler Exponential-Time Approximation Algorithm for MAX-k-SAT</title>
      <link>https://arxiv.org/abs/2510.18164</link>
      <description>arXiv:2510.18164v1 Announce Type: new 
Abstract: We present an extremely simple polynomial-space exponential-time $(1-\varepsilon)$-approximation algorithm for MAX-k-SAT that is (slightly) faster than the previous known polynomial-space $(1-\varepsilon)$-approximation algorithms by Hirsch (Discrete Applied Mathematics, 2003) and Escoffier, Paschos and Tourniaire (Theoretical Computer Science, 2014). Our algorithm repeatedly samples an assignment uniformly at random until finding an assignment that satisfies a large enough fraction of clauses. Surprisingly, we can show the efficiency of this simpler approach by proving that in any instance of MAX-k-SAT (or more generally any instance of MAXCSP), an exponential number of assignments satisfy a fraction of clauses close to the optimal value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18164v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harry Buhrman, Sevag Gharibian, Zeph Landau, Fran\c{c}ois Le Gall, Norbert Schuch, Suguru Tamaki</dc:creator>
    </item>
    <item>
      <title>Coloring Graphs with Few Colors in the Streaming Model</title>
      <link>https://arxiv.org/abs/2510.18177</link>
      <description>arXiv:2510.18177v1 Announce Type: new 
Abstract: We study graph coloring problems in the streaming model, where the goal is to process an $n$-vertex graph whose edges arrive in a stream, using a limited space that is smaller than the trivial $O(n^2)$ bound. While prior work has largely focused on coloring graphs with a large number of colors, we explore the opposite end of the spectrum: deciding whether the input graph can be colored using only a few, say, a constant number of colors. We are interested in each of the adversarial, random order, or dynamic streams.
  Our work lays the foundation for this new direction by establishing upper and lower bounds on space complexity of key variants of the problem. Some of our main results include:
  - Adversarial: for distinguishing between $q$- vs $2^{\Omega(q)}$-colorable graphs, lower bounds of $n^{2-o(1)}$ space for $q$ up to $(\log{n})^{1/2-o(1)}$, and $n^{1+\Omega(1/\log\log{n})}$ space for $q$ further up to $(\log{n})^{1-o(1)}$.
  - Random order: for distinguishing between $q$- vs $q^t$-colorable graphs for $q,t \geq 2$, an upper bound of $\tilde{O}(n^{1+1/t})$ space. Specifically, distinguishing between $q$-colorable graphs vs ones that are not even poly$(q)$-colorable can be done in $n^{1+o(1)}$ space unlike in adversarial streams. Although, distinguishing between $q$-colorable vs $\Omega(q^2)$-colorable graphs requires $\Omega(n^2)$ space even in random order streams for constant $q$.
  - Dynamic: for distinguishing between $q$- vs $q \cdot t$-colorable graphs for any $q \geq 3$ and $t \geq 1$, nearly optimal upper and lower bounds of $\tilde{\Theta}(n^2/t^2)$ space.
  We develop several new technical tools along the way: cluster packing graphs, a generalization of Ruzsa-Szemer\'edi graphs; a player elimination framework based on cluster packing graphs; and new edge and vertex sampling lemmas tailored to graph coloring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18177v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Janani Sundaresan, Helia Yazdanyar</dc:creator>
    </item>
    <item>
      <title>Nearly Space-Optimal Graph and Hypergraph Sparsification in Insertion-Only Data Streams</title>
      <link>https://arxiv.org/abs/2510.18180</link>
      <description>arXiv:2510.18180v1 Announce Type: new 
Abstract: We study the problem of graph and hypergraph sparsification in insertion-only data streams. The input is a hypergraph $H=(V, E, w)$ with $n$ nodes, $m$ hyperedges, and rank $r$, and the goal is to compute a hypergraph $\widehat{H}$ that preserves the energy of each vector $x \in \mathbb{R}^n$ in $H$, up to a small multiplicative error. In this paper, we give a streaming algorithm that achieves a $(1+\varepsilon)$-approximation, using $\frac{rn}{\varepsilon^2} \log^2 n \log r \cdot\text{poly}(\log \log m)$ bits of space, matching the sample complexity of the best known offline algorithm up to $\text{poly}(\log \log m)$ factors. Our approach also provides a streaming algorithm for graph sparsification that achieves a $(1+\varepsilon)$-approximation, using $\frac{n}{\varepsilon^2} \log n \cdot\text{poly}(\log\log n)$ bits of space, improving the current bound by $\log n$ factors. Furthermore, we give a space-efficient streaming algorithm for min-cut approximation. Along the way, we present an online algorithm for $(1+\varepsilon)$-hypergraph sparsification, which is optimal up to poly-logarithmic factors. As a result, we achieve $(1+\varepsilon)$-hypergraph sparsification in the sliding window model, with space optimal up to poly-logarithmic factors. Lastly, we give an adversarially robust algorithm for hypergraph sparsification using $\frac{n}{\varepsilon^2} \cdot\text{poly}(r, \log n, \log r, \log \log m)$ bits of space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18180v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincent Cohen-Addad, David P. Woodruff, Shenghao Xie, Samson Zhou</dc:creator>
    </item>
    <item>
      <title>Static Retrieval Revisited: To Optimality and Beyond</title>
      <link>https://arxiv.org/abs/2510.18237</link>
      <description>arXiv:2510.18237v1 Announce Type: new 
Abstract: In the static retrieval problem, a data structure must answer retrieval queries mapping a set of $n$ keys in a universe $[U]$ to $v$-bit values. Information-theoretically, retrieval data structures can use as little as $nv$ bits of space. For small value sizes $v$, it is possible to achieve $O(1)$ query time while using space $nv + o(n)$ bits -- whether or not such a result is possible for larger values of $v$ (e.g., $v = \Theta(\log n)$) has remained open.
  In this paper, we obtain a tight lower bound (as well as matching upper bounds) for the static retrieval problem. In the case where values are large, we show that there is actually a significant tension between time and space. It is not possible, for example, to get $O(1)$ query time using $nv + o(n)$ bits of space, when $v = \Theta(\log n)$ (and assuming the word RAM model with $O(\log n)$-bit words).
  At first glance, our lower bound would seem to render retrieval unusable in many settings that aim to achieve very low redundancy. However, our second result offers a way around this: We show that, whenever a retrieval data structure $D_1$ is stored along with another data structure $D_2$ (whose size is similar to or larger than the size of $D_1$), it is possible to implement the combined data structure $D_1 \cup D_2$ so that queries to $D_1$ take $O(1)$ time, operations on $D_2$ take the same asymptotic time as if $D_2$ were stored on its own, and the total space is $nv + \mathrm{Space}(D_2) + n^{0.67}$ bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18237v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Hu, William Kuszmaul, Jingxun Liang, Huacheng Yu, Junkai Zhang, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Minimum $s$--$t$ Cuts with Fewer Cut Queries</title>
      <link>https://arxiv.org/abs/2510.18274</link>
      <description>arXiv:2510.18274v1 Announce Type: new 
Abstract: We study the problem of computing a minimum $s$--$t$ cut in an unweighted, undirected graph via \emph{cut queries}. In this model, the input graph is accessed through an oracle that, given a subset of vertices $S \subseteq V$, returns the size of the cut $(S, V \setminus S)$.
  This line of work was initiated by Rubinstein, Schramm, and Weinberg (ITCS 2018), who gave a randomized algorithm that computes a minimum $s$--$t$ cut using $\widetilde{O}(n^{5/3})$ queries, thereby showing that one can avoid spending $\widetilde{\Theta}(n^2)$ queries required to learn the entire graph. A recent result by Anand, Saranurak, and Wang (SODA 2025) also matched this upper bound via a deterministic algorithm based on blocking flows.
  In this work, we present a new randomized algorithm that improves the cut-query complexity to $\widetilde{O}(n^{8/5})$. At the heart of our approach is a query-efficient subroutine that incrementally reveals the graph edge-by-edge while increasing the maximum $s$--$t$ flow in the learned subgraph at a rate faster than classical augmenting-path methods. Notably, our algorithm is simple, purely combinatorial, and can be naturally interpreted as a recursive greedy procedure.
  As a further consequence, we obtain a \emph{deterministic} and \emph{combinatorial} two-party communication protocol for computing a minimum $s$--$t$ cut using $\widetilde{O}(n^{11/7})$ bits of communication. This improves upon the previous best bound of $\widetilde{O}(n^{5/3})$, which was obtained via reductions from the aforementioned cut-query algorithms. In parallel, it has been observed that an $\widetilde{O}(n^{3/2})$-bit randomized protocol can be achieved via continuous optimization techniques; however, these methods are fundamentally different from our combinatorial approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18274v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yonggang Jiang, Danupon Nanongkai, Pachara Sawettamalya</dc:creator>
    </item>
    <item>
      <title>Uniformity Testing under User-Level Local Privacy</title>
      <link>https://arxiv.org/abs/2510.18379</link>
      <description>arXiv:2510.18379v1 Announce Type: new 
Abstract: We initiate the study of distribution testing under \emph{user-level} local differential privacy, where each of $n$ users contributes $m$ samples from the unknown underlying distribution. This setting, albeit very natural, is significantly more challenging that the usual locally private setting, as for the same parameter $\varepsilon$ the privacy guarantee must now apply to a full batch of $m$ data points. While some recent work consider distribution \emph{learning} in this user-level setting, nothing was known for even the most fundamental testing task, uniformity testing (and its generalization, identity testing).
  We address this gap, by providing (nearly) sample-optimal user-level LDP algorithms for uniformity and identity testing. Motivated by practical considerations, our main focus is on the private-coin, symmetric setting, which does not require users to share a common random seed nor to have been assigned a globally unique identifier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18379v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.DM</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement L. Canonne, Abigail Gentle, Vikrant Singhal</dc:creator>
    </item>
    <item>
      <title>Odd and Even Harder Problems on Cycle-Factors</title>
      <link>https://arxiv.org/abs/2510.18393</link>
      <description>arXiv:2510.18393v1 Announce Type: new 
Abstract: For a graph (undirected, directed, or mixed), a cycle-factor is a collection of vertex-disjoint cycles covering the entire vertex set. Cycle-factors subject to parity constraints arise naturally in the study of structural graph theory and algorithmic complexity. In this work, we study four variants of the problem of finding a cycle-factor subject to parity constraints: (1) all cycles are odd, (2) all cycles are even, (3) at least one cycle is odd, and (4) at least one cycle is even. These variants are considered in the undirected, directed, and mixed settings. We show that all but the fourth problem are NP-complete in all settings, while the complexity of the fourth one remains open for the directed and undirected cases. We also show that in mixed graphs, even deciding the existence of any cycle factor is NP-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18393v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian H\"orsch, Csaba Kir\'aly, Mirabel Mendoza-Cadena, Gyula Pap, Eszter Szab\'o, Yutaro Yamaguchi</dc:creator>
    </item>
    <item>
      <title>LatticeHashForest: An Efficient Data Structure for Repetitive Data and Operations</title>
      <link>https://arxiv.org/abs/2510.18496</link>
      <description>arXiv:2510.18496v1 Announce Type: new 
Abstract: Analysis of entire programs as a single unit, or whole-program analysis, involves propagation of large amounts of information through the control flow of the program. This is especially true for pointer analysis, where, unless significant compromises are made in the precision of the analysis, there is a combinatorial blowup of information. One of the key problems we observed in our own efforts is that a lot of duplicate data was being propagated, and many low-level data structure operations were repeated a large number of times.
  We present what we consider to be a novel and generic data structure, LatticeHashForest (LHF), to store and operate on such information in a manner that eliminates a majority of redundant computations and duplicate data in scenarios similar to those encountered in compilers and program optimization. LHF differs from similar work in this vein, such as hash-consing, ZDDs, and BDDs, by not only providing a way to efficiently operate on large, aggregate structures, but also modifying the elements of such structures in a manner that they can be deduplicated immediately. LHF also provides a way to perform a nested construction of elements such that they can be deduplicated at multiple levels, cutting down the need for additional, nested computations.
  We provide a detailed structural description, along with an abstract model of this data structure. An entire C++ implementation of LHF is provided as an artifact along with evaluations of LHF using examples and benchmark programs. We also supply API documentation and a user manual for users to make independent applications of LHF. Our main use case in the realm of pointer analysis shows memory usage reduction to an almost negligible fraction, and speedups beyond 4x for input sizes approaching 10 million when compared to other implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18496v1</guid>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>cs.OS</category>
      <category>cs.PL</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anamitra Ghorui, Uday P. Khedker</dc:creator>
    </item>
    <item>
      <title>An optimal algorithm for average distance in typical regular graphs</title>
      <link>https://arxiv.org/abs/2510.18722</link>
      <description>arXiv:2510.18722v1 Announce Type: new 
Abstract: We design a deterministic algorithm that, given $n$ points in a \emph{typical} constant degree regular~graph, queries $O(n)$ distances to output a constant factor approximation to the average distance among those points, thus answering a question posed in~\cite{MN14}. Our algorithm uses the method of~\cite{MN14} to construct a sequence of constant degree graphs that are expanders with respect to certain nonpositively curved metric spaces, together with a new rigidity theorem for metric transforms of nonpositively curved metric spaces. The fact that our algorithm works for typical (uniformly random) constant degree regular graphs rather than for all constant degree graphs is unavoidable, thanks to the following impossibility result that we obtain: For every fixed $k\in \N$, the approximation factor of any algorithm for average distance that works for all constant degree graphs and queries $o(n^{1+1/k})$ distances must necessarily be at least $2(k+1)$. This matches the upper bound attained by the algorithm that was designed for general finite metric spaces in~\cite{BGS}. Thus, any algorithm for average distance in constant degree graphs whose approximation guarantee is less than $4$ must query $\Omega(n^2)$ distances, any such algorithm whose approximation guarantee is less than $6$ must query $\Omega(n^{3/2})$ distances, any such algorithm whose approximation guarantee less than $8$ must query $\Omega(n^{4/3})$ distances, and so forth, and furthermore there exist algorithms achieving those parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18722v1</guid>
      <category>cs.DS</category>
      <category>math.MG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexandros Eskenazis, Manor Mendel, Assaf Naor</dc:creator>
    </item>
    <item>
      <title>Revisiting RFID Missing Tag Identification</title>
      <link>https://arxiv.org/abs/2510.18285</link>
      <description>arXiv:2510.18285v1 Announce Type: cross 
Abstract: We revisit the problem of missing tag identification in RFID networks by making three contributions. Firstly, we quantitatively compare and gauge the existing propositions spanning over a decade on missing tag identification. We show that the expected execution time of the best solution in the literature is $\Theta \left(N+\frac{(1-\alpha)^2(1-\delta)^2}{ \epsilon^2}\right)$, where $\delta$ and $\epsilon$ are parameters quantifying the required identification accuracy, $N$ denotes the number of tags in the system, among which $\alpha N$ tags are missing. Secondly, we analytically establish the expected execution time lower-bound for any missing tag identification algorithm as $\Theta\left(\frac{N}{\log N}+\frac{(1-\delta)^2(1-\alpha)^2}{\epsilon^2 \log \frac{(1-\delta)(1-\alpha)}{\epsilon}}\right)$, thus giving the theoretical performance limit. Thirdly, we develop a novel missing tag identification algorithm by leveraging a tree structure with the expected execution time of $\Theta \left(\frac{\log\log N}{\log N}N+\frac{(1-\alpha)^2(1-\delta)^2}{ \epsilon^2}\right)$, reducing the time overhead by a factor of up to $\log N$ over the best algorithm in the literature. The key technicality in our design is a novel data structure termed as collision-partition tree (CPT), built on a subset of bits in tag pseudo-IDs, leading to more balanced tree structure and reducing the time complexity in parsing the entire tree.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18285v1</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/INFOCOM48880.2022.9796971</arxiv:DOI>
      <arxiv:journal_reference>IEEE Conference on Computer Communications, London, United Kingdom, 2022, pp. 710-719</arxiv:journal_reference>
      <dc:creator>Kanghuai Liu, Lin Chen, Jihong Yu, Junyi Huang, Shiyuan Liu</dc:creator>
    </item>
    <item>
      <title>Distributed Interactive Proofs for Planarity with Log-Star Communication</title>
      <link>https://arxiv.org/abs/2510.18592</link>
      <description>arXiv:2510.18592v1 Announce Type: cross 
Abstract: We provide new communication-efficient distributed interactive proofs for planarity. The notion of a \emph{distributed interactive proof (DIP)} was introduced by Kol, Oshman, and Saxena (PODC 2018). In a DIP, the \emph{prover} is a single centralized entity whose goal is to prove a certain claim regarding an input graph $G$. To do so, the prover communicates with a distributed \emph{verifier} that operates concurrently on all $n$ nodes of $G$. A DIP is measured by the amount of prover-verifier communication it requires. Namely, the goal is to design a DIP with a small number of interaction rounds and a small \emph{proof size}, i.e., a small amount of communication per round. Our main result is an $O(\log ^{*}n)$-round DIP protocol for embedded planarity and planarity with a proof size of $O(1)$ and $O(\lceil\log \Delta/\log ^{*}n\rceil)$, respectively. In fact, this result can be generalized as follows. For any $1\leq r\leq \log^{*}n$, there exists an $O(r)$-round protocol for embedded planarity and planarity with a proof size of $O(\log ^{(r)}n)$ and $O(\log ^{(r)}n+\log \Delta /r)$, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18592v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Gil, Merav Parter</dc:creator>
    </item>
    <item>
      <title>Undirected Multicast Network Coding Gaps via Locally Decodable Codes</title>
      <link>https://arxiv.org/abs/2510.18737</link>
      <description>arXiv:2510.18737v1 Announce Type: cross 
Abstract: The network coding problem asks whether data throughput in a network can be increased using coding (compared to treating bits as commodities in a flow). While it is well-known that a network coding advantage exists in directed graphs, the situation in undirected graphs is much less understood -- in particular, despite significant effort, it is not even known whether network coding is helpful at all for unicast sessions.
  In this paper we study the multi-source multicast network coding problem in undirected graphs. There are $k$ sources broadcasting each to a subset of nodes in a graph of size $n$. The corresponding combinatorial problem is a version of the Steiner tree packing problem, and the network coding question asks whether the multicast coding rate exceeds the tree-packing rate.
  We give the first super-constant bound to this problem, demonstrating an example with a coding advantage of $\Omega(\log k)$. In terms of graph size, we obtain a lower bound of $2^{\tilde{\Omega}(\sqrt{\log \log n})}$. We also obtain an upper bound of $O(\log n)$ on the gap.
  Our main technical contribution is a new reduction that converts locally-decodable codes in the low-error regime into multicast coding instances. This gives rise to a new family of explicitly constructed graphs, which may have other applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18737v1</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Braverman, Zhongtian He</dc:creator>
    </item>
    <item>
      <title>Simple Sublinear Algorithms for $(\Delta+1)$ Vertex Coloring via Asymmetric Palette Sparsification</title>
      <link>https://arxiv.org/abs/2502.17629</link>
      <description>arXiv:2502.17629v3 Announce Type: replace 
Abstract: The palette sparsification theorem (PST) of Assadi, Chen, and Khanna (SODA 2019) states that in every graph $G$ with maximum degree $\Delta$, sampling a list of $O(\log{n})$ colors from $\{1,\ldots,\Delta+1\}$ for every vertex independently and uniformly, with high probability, allows for finding a $(\Delta+1)$ vertex coloring of $G$ by coloring each vertex only from its sampled list. PST naturally leads to a host of sublinear algorithms for $(\Delta+1)$ vertex coloring, including in semi-streaming, sublinear time, and MPC models, which are all proven to be nearly optimal, and in the case of the former two are the only known sublinear algorithms for this problem.
  While being a quite natural and simple-to-state theorem, PST suffers from two drawbacks. Firstly, all its known proofs require technical arguments that rely on sophisticated graph decompositions and probabilistic arguments. Secondly, finding the coloring of the graph from the sampled lists in an efficient manner requires a considerably complicated algorithm.
  We show that a natural weakening of PST addresses both these drawbacks while still leading to sublinear algorithms of similar quality (up to polylog factors). In particular, we prove an asymmetric palette sparsification theorem (APST) that allows for list sizes of the vertices to have different sizes and only bounds the average size of these lists. The benefit of this weaker requirement is that we can now easily show the graph can be $(\Delta+1)$ colored from the sampled lists using the standard greedy coloring algorithm. This way, we can recover nearly-optimal bounds for $(\Delta+1)$ vertex coloring in all the aforementioned models using algorithms that are much simpler to implement and analyze.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17629v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sepehr Assadi, Helia Yazdanyar</dc:creator>
    </item>
    <item>
      <title>Optimal mass estimation in the conditional sampling model</title>
      <link>https://arxiv.org/abs/2503.12518</link>
      <description>arXiv:2503.12518v4 Announce Type: replace 
Abstract: The conditional sampling model, introduced by Cannone, Ron and Servedio (SODA 2014, SIAM J. Comput. 2015) and independently by Chakraborty, Fischer, Goldhirsh and Matsliah (ITCS 2013, SIAM J. Comput. 2016), is a common framework for a number of studies concerning strengthened models of distribution testing. A core task in these investigations is that of estimating the mass of individual elements. The above mentioned works, and the improvement of Kumar, Meel and Pote (AISTATS 2025), provided polylogarithmic algorithms for this task.
  In this work we shatter the polylogarithmic barrier, and provide an estimator for the mass of individual elements that uses only $O(\log \log N) + O(\mathrm{poly}(1/\varepsilon))$ conditional samples. We complement this result with an $\Omega(\log\log N)$ lower bound.
  We then show that our mass estimator provides an improvement (and in some cases a unifying framework) for a number of related tasks, such as testing by learning of any label-invariant property, and distance estimation between two (unknown) distribution. By considering some known lower bounds, this also shows that the full power of the conditional model is indeed required for the doubly-logarithmic upper bound.
  Finally, we exponentially improve the previous lower bound on testing by learning of label-invariant properties from double-logarithmic to $\Omega(\log N)$ conditional samples, whereas our testing by learning algorithm provides an upper bound of $O(\mathrm{poly}(1/\varepsilon)\cdot\log N \log \log N)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12518v4</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomer Adar, Eldar Fischer, Amit Levi</dc:creator>
    </item>
    <item>
      <title>Does block size matter in randomized block Krylov low-rank approximation?</title>
      <link>https://arxiv.org/abs/2508.06486</link>
      <description>arXiv:2508.06486v2 Announce Type: replace 
Abstract: We study the problem of computing a rank-$k$ approximation of a matrix using randomized block Krylov iteration. Prior work has shown that, for block size $b = 1$ or $b = k$, a $(1 + \varepsilon)$-factor approximation to the best rank-$k$ approximation can be obtained after $\tilde O(k/\sqrt{\varepsilon})$ matrix-vector products with the target matrix. On the other hand, when $b$ is between $1$ and $k$, the best known bound on the number of matrix-vector products scales with $b(k-b)$, which could be as large as $O(k^2)$. Nevertheless, in practice, the performance of block Krylov methods is often optimized by choosing a block size $1 \ll b \ll k$. We resolve this theory-practice gap by proving that randomized block Krylov iteration produces a $(1 + \varepsilon)$-factor approximate rank-$k$ approximation using $\tilde O(k/\sqrt{\varepsilon})$ matrix-vector products for any block size $1\le b\le k$. Our analysis relies on new bounds for the minimum singular value of a random block Krylov matrix, which may be of independent interest. Similar bounds are central to recent breakthroughs on faster algorithms for sparse linear systems [Peng &amp; Vempala, SODA 2021; Nie, STOC 2022].</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06486v2</guid>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen, Ethan N. Epperly, Raphael A. Meyer, Christopher Musco, Akash Rao</dc:creator>
    </item>
    <item>
      <title>A Gentle Wakeup Call: Symmetry Breaking with Less Collision Cost</title>
      <link>https://arxiv.org/abs/2508.11006</link>
      <description>arXiv:2508.11006v2 Announce Type: replace 
Abstract: The wakeup problem addresses the fundamental challenge of symmetry breaking. Initially, n devices share a time-slotted multiple access channel, which models wireless communication. A transmission succeeds if exactly one device sends in a slot; if two or more transmit, a collision occurs and none succeed. The goal is to achieve a single successful transmission efficiently.
  Prior work on wakeup primarily analyzes latency -- the number of slots until the first success. However, in many modern systems, each collision incurs a nontrivial delay, C, which prior analyses neglect. Consequently, although existing algorithms achieve polylogarithmic-in-n latency, they still suffer a delay of \Omega(C) due to collisions.
  Here, we design and analyze a randomized wakeup algorithm, Aim-High. When C is sufficiently large with respect to n, Aim-High has expected latency and expected total cost of collisions that are nearly O(\sqrt{C}); otherwise, both quantities are O(poly{\log n}). Finally, for a well-studied class of algorithms, we establish a trade-off between latency and expected total cost of collisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11006v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umesh Biswas, Maxwell Young</dc:creator>
    </item>
    <item>
      <title>The Art of the Fugue: Minimizing Interleaving in Collaborative Text Editing</title>
      <link>https://arxiv.org/abs/2305.00583</link>
      <description>arXiv:2305.00583v3 Announce Type: replace-cross 
Abstract: Most existing algorithms for replicated lists, which are widely used in collaborative text editors, suffer from a problem: when two users concurrently insert text at the same position in the document, the merged outcome may interleave the inserted text passages, resulting in corrupted and potentially unreadable text. The problem has gone unnoticed for decades, and it affects both CRDTs and Operational Transformation. This paper defines maximal non-interleaving, our new correctness property for replicated lists. We introduce two related CRDT algorithms, Fugue and FugueMax, and prove that FugueMax satisfies maximal non-interleaving. We also implement our algorithms and demonstrate that Fugue offers performance comparable to state-of-the-art CRDT libraries for text editing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00583v3</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPDS.2025.3611880</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Parallel and Distributed Systems, vol. 36, no. 11, pp. 2425-2437, Nov. 2025</arxiv:journal_reference>
      <dc:creator>Matthew Weidner, Martin Kleppmann</dc:creator>
    </item>
    <item>
      <title>Changing Base Without Losing Pace: A GPU-Efficient Alternative to MatMul in DNNs</title>
      <link>https://arxiv.org/abs/2503.12211</link>
      <description>arXiv:2503.12211v3 Announce Type: replace-cross 
Abstract: Modern AI relies on huge matrix multiplications (MatMuls), whose computation poses a scalability problem for inference and training. We propose an alternative, GPU native bilinear operator to MatMuls in neural networks, which offers a three-way tradeoff between: speed, accuracy and parameter count. In particular, this operator requires substantially fewer FLOPs to evaluate ($\ll n^3$), yet increases the parameter count compared to MatMul ($\gg n^2$). We call this operator Strassen-Tile (STL). The key idea behind STL is a local learnable change-of-basis, applied on tiles of the weight and activation matrices, followed by an element-wise product between the tiles, implemented simultaneously via MatMul. The key technical question we study is how to optimize the change-of-basis of a given layer, which is a highly non-convex problem. We show that theory-backed initializations (inspired by fast matrix and polynomial multiplication) lead to substantially better accuracy than random SGD initialization. This phenomenon motivates further algorithmic study of STL optimization in DNNs. Our experiments demonstrate that STL can approximate 4x4 MatMul of tiles while reducing FLOPs by a factor of 2.66, and can improve Imagenet-1K accuracy of SoTA T2T-ViT-7 (4.3M parameters) while lowering FLOPs. Even with non-CUDA optimized PyTorch code, STL achieves wall-clock speedups in the compute-bound regime. These results, together with its theoretical grounds, suggest STL as a promising building block for scalable and cost-efficient AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.12211v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nir Ailon, Akhiad Bercovich, Yahel Uffenheimer, Omri Weinstein</dc:creator>
    </item>
    <item>
      <title>The Power of Matching for Online Fractional Hedonic Games</title>
      <link>https://arxiv.org/abs/2505.06163</link>
      <description>arXiv:2505.06163v2 Announce Type: replace-cross 
Abstract: We study coalition formation in the framework of fractional hedonic games (FHGs). The objective is to maximize social welfare in an online model where agents arrive one by one and must be assigned to coalitions immediately and irrevocably. A recurrent theme in online coalition formation is that online matching algorithms, where coalitions are restricted to size at most $2$, yield good competitive ratios. For example, computing maximal matchings achieves the optimal competitive ratio for general online FHGs. However, this ratio is bounded only if agents' valuations are themselves bounded.
  We identify optimal algorithms with constant competitive ratios in two related settings, independent of the range of agent valuations. First, under random agent arrival, we present an asymptotically optimal $(\frac{1}{3}-\frac 1n)$-competitive algorithm, where $n$ is the number of agents. This result builds on our identification of an optimal matching algorithm in a general model of online matching with edge weights and an unknown number of agents. In this setting, we also achieve an asymptotically optimal competitive ratio of $\frac{1}{3}-\frac 1n$. Second, when agents arrive in an arbitrary order but algorithms are allowed to irrevocably and entirely dissolve coalitions, we show that another matching-based algorithm achieves an optimal competitive ratio of $\frac{1}{6 + 4\sqrt{2}}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06163v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bullinger, Ren\'e Romen, Alexander Schlenga</dc:creator>
    </item>
    <item>
      <title>Fair Minimum Labeling: Efficient Temporal Network Activations for Reachability and Equity</title>
      <link>https://arxiv.org/abs/2510.03899</link>
      <description>arXiv:2510.03899v2 Announce Type: replace-cross 
Abstract: Balancing resource efficiency and fairness is critical in networked systems that support modern learning applications. We introduce the Fair Minimum Labeling (FML) problem: the task of designing a minimum-cost temporal edge activation plan that ensures each group of nodes in a network has sufficient access to a designated target set, according to specified coverage requirements. FML captures key trade-offs in systems where edge activations incur resource costs and equitable access is essential, such as distributed data collection, update dissemination in edge-cloud systems, and fair service restoration in critical infrastructure. We show that FML is NP-hard and $\Omega(\log |V|)$-hard to approximate, where $V$ is the set of nodes, and we present probabilistic approximation algorithms that match this bound, achieving the best possible guarantee for the activation cost. We demonstrate the practical utility of FML in a fair multi-source data aggregation task for training a shared model. Empirical results show that FML enforces group-level fairness with substantially lower activation cost than baseline heuristics, underscoring its potential for building resource-efficient, equitable temporal reachability in learning-integrated networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03899v2</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 22 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lutz Oettershagen, Othon Michail</dc:creator>
    </item>
  </channel>
</rss>
