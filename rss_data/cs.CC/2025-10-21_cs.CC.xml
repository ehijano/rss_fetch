<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 Oct 2025 01:46:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Deterministic Hardness of Approximation of Unique-SVP and GapSVP in $\ell_p$ norms for $p&gt;2$</title>
      <link>https://arxiv.org/abs/2510.16991</link>
      <description>arXiv:2510.16991v1 Announce Type: new 
Abstract: We establish deterministic hardness of approximation results for the Shortest Vector Problem in $\ell_p$ norm ($\mathsf{SVP}_p$) and for Unique-SVP ($\mathsf{uSVP}_p$) for all $p &gt; 2$. Previously, no deterministic hardness results were known, except for $\ell_\infty$.
  For every $p &gt; 2$, we prove constant-ratio hardness: no polynomial-time algorithm approximates $\mathsf{SVP}_p$ or $\mathsf{uSVP}_p$ within a ratio of $\sqrt{2} - o(1)$, assuming $\textsf{3SAT} \notin \text{DTIME}(2^{O(n^{2/3}\log n)})$, and, $\textsf{Unambiguous-3SAT} \notin \text{DTIME}(2^{O(n^{2/3}\log n)})$.
  We also show that for any $\varepsilon &gt; 0$ there exists $p_\varepsilon &gt; 2$ such that for every $p \ge p_\varepsilon$: no polynomial-time algorithm approximates $\mathsf{SVP}_p$ within a ratio of $2^{(\log n)^{1- \varepsilon}}$, assuming $\text{NP} \nsubseteq \text{DTIME}(n^{(\log n)^\varepsilon})$; and within a ratio of $n^{1/(\log\log(n))^\varepsilon}$, assuming $\text{NP} \nsubseteq \text{SUBEXP}$. This improves upon [Haviv, Regev, Theory of Computing 2012], which obtained similar inapproximation ratios under randomized reductions. We obtain analogous results for $\mathsf{uSVP}_p$ under the assumptions $\textsf{Unambiguous-3SAT} \not\subseteq \text{DTIME}(n^{(\log n)^\varepsilon})$ and $\textsf{Unambiguous-3SAT} \not\subseteq \text{SUBEXP}$, improving the previously known $1+o(1)$ [Stephens-Davidowitz, Approx 2016].
  Strengthening the hardness of $\textsf{uSVP}$ has direct cryptographic impact. By the reduction of Lyubashevsky and Micciancio [Lyubashevsky, Micciancio, CRYPTO 2009], hardness for $\gamma$-$\mathsf{uSVP}_p$ carries over to ${\frac{1}{\gamma}}$-$\mathsf{BDD}_p$ (Bounded Distance Decoding). Thus, understanding the hardness of $\textsf{uSVP}$ improves worst-case guarantees for two core problems that underpin security in lattice-based cryptography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16991v1</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yahli Hecht, Muli Safra</dc:creator>
    </item>
    <item>
      <title>The Parameterized Complexity of Computing the VC-Dimension</title>
      <link>https://arxiv.org/abs/2510.17451</link>
      <description>arXiv:2510.17451v1 Announce Type: new 
Abstract: The VC-dimension is a fundamental and well-studied measure of the complexity of a set system (or hypergraph) that is central to many areas of machine learning. We establish several new results on the complexity of computing the VC-dimension. In particular, given a hypergraph $\mathcal{H}=(\mathcal{V},\mathcal{E})$, we prove that the naive $2^{\mathcal{O}(|\mathcal{V}|)}$-time algorithm is asymptotically tight under the Exponential Time Hypothesis (ETH). We then prove that the problem admits a 1-additive fixed-parameter approximation algorithm when parameterized by the maximum degree of $\mathcal{H}$ and a fixed-parameter algorithm when parameterized by its dimension, and that these are essentially the only such exploitable structural parameters. Lastly, we consider a generalization of the problem, formulated using graphs, which captures the VC-dimension of both set systems and graphs. We show that it is fixed-parameter tractable parameterized by the treewidth of the graph (which, in the case of set systems, applies to the treewidth of its incidence graph). In contrast with closely related problems whose dependency on the treewidth is necessarily double-exponential (assuming the ETH), our algorithm has a relatively low dependency on the treewidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17451v1</guid>
      <category>cs.CC</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>math.CO</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florent Foucaud, Harmender Gahlawat, Fionn Mc Inerney, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>Unifying the Landscape of Super-Logarithmic Dynamic Cell-Probe Lower Bounds</title>
      <link>https://arxiv.org/abs/2510.17717</link>
      <description>arXiv:2510.17717v1 Announce Type: new 
Abstract: We prove a general translation theorem for converting one-way communication lower bounds over a product distribution to dynamic cell-probe lower bounds.
  Specifically, we consider a class of problems considered in [Pat10] where:
  1. $S_1, \ldots, S_m \in \{0, 1\}^n$ are given and publicly known.
  2. $T \in \{0, 1\}^n$ is a sequence of updates, each taking $t_u$ time.
  3. For a given $Q \in [m]$, we must output $f(S_Q, T)$ in $t_q$ time. Our main result shows that for a "hard" function $f$, for which it is difficult to obtain a non-trivial advantage over random guessing with one-way communication under some product distribution over $S_Q$ and $T$ (for example, a uniform distribution), then the above explicit dynamic cell-probe problem must have $\max \{ t_u, t_q \} \geq \tilde{\Omega}(\log^{3/2}(n))$ if $m = \Omega(n^{0.99})$. This result extends and unifies the super-logarithmic dynamic data structure lower bounds from [LWY20] and [LY25] into a more general framework.
  From a technical perspective, our approach merges the cell-sampling and chronogram techniques developed in [LWY20] and [LY25] with the new static data structure lower bound methods from [KW20] and [Ko25], thereby merging all known state-of-the-art cell-probe lower-bound techniques into one.
  As a direct consequence of our method, we establish a super-logarithmic lower bound against the Multiphase Problem [Pat10] for the case where the data structure outputs the Inner Product (mod 2) of $S_Q$ and $T$. We suspect further applications of this general method towards showing super-logarithmic dynamic cell-probe lower bounds. We list some example applications of our general method, including a novel technique for a one-way communication lower bound against small-advantage protocols for a product distribution using average min-entropy, which could be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17717v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Young Kun Ko</dc:creator>
    </item>
    <item>
      <title>Efficient and Privacy-Preserving Binary Dot Product via Multi-Party Computation</title>
      <link>https://arxiv.org/abs/2510.16331</link>
      <description>arXiv:2510.16331v1 Announce Type: cross 
Abstract: Striking a balance between protecting data privacy and enabling collaborative computation is a critical challenge for distributed machine learning. While privacy-preserving techniques for federated learning have been extensively developed, methods for scenarios involving bitwise operations, such as tree-based vertical federated learning (VFL), are still underexplored. Traditional mechanisms, including Shamir's secret sharing and multi-party computation (MPC), are not optimized for bitwise operations over binary data, particularly in settings where each participant holds a different part of the binary vector. This paper addresses the limitations of existing methods by proposing a novel binary multi-party computation (BiMPC) framework. The BiMPC mechanism facilitates privacy-preserving bitwise operations, with a particular focus on dot product computations of binary vectors, ensuring the privacy of each individual bit. The core of BiMPC is a novel approach called Dot Product via Modular Addition (DoMA), which uses regular and modular additions for efficient binary dot product calculation. To ensure privacy, BiMPC uses random masking in a higher field for linear computations and a three-party oblivious transfer (triot) protocol for non-linear binary operations. The privacy guarantees of the BiMPC framework are rigorously analyzed, demonstrating its efficiency and scalability in distributed settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16331v1</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fatemeh Jafarian Dehkordi, Elahe Vedadi, Alireza Feizbakhsh, Yasaman Keshtkarjahromi, Hulya Seferoglu</dc:creator>
    </item>
    <item>
      <title>Exact Quantum Circuit Optimization is co-NQP-hard</title>
      <link>https://arxiv.org/abs/2510.16420</link>
      <description>arXiv:2510.16420v1 Announce Type: cross 
Abstract: As quantum computing resources remain scarce and error rates high, minimizing the resource consumption of quantum circuits is essential for achieving practical quantum advantage. Here we consider the natural problem of, given a circuit $C$, computing an equivalent circuit $C'$ that minimizes a quantum resource type, expressed as the count or depth of (i) arbitrary gates, or (ii) non-Clifford gates, or (iii) superposition gates, or (iv) entanglement gates. We show that, when $C$ is expressed over any gate set that can implement the H and TOF gates exactly, each of the above optimization problems is hard for $\text{co-NQP}$, and hence outside the Polynomial Hierarchy, unless the Polynomial Hierarchy collapses. This strengthens recent results in the literature which established an $\text{NP}$-hardness lower bound, and tightens the gap to the corresponding $\text{NP}^\text{NQP}$ upper bound known for cases (i)-(iii) over Clifford+T and (i)-(iv) over H+TOF circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16420v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adam Husted Kjelstr{\o}m, Andreas Pavlogiannis, Jaco van de Pol</dc:creator>
    </item>
    <item>
      <title>Prior Makes It Possible: From Sublinear Graph Algorithms to LLM Test-Time Methods</title>
      <link>https://arxiv.org/abs/2510.16609</link>
      <description>arXiv:2510.16609v1 Announce Type: cross 
Abstract: Test-time augmentation, such as Retrieval-Augmented Generation (RAG) or tool use, critically depends on an interplay between a model's parametric knowledge and externally retrieved information. However, the theoretical underpinnings of this relationship remain poorly understood. Specifically, it is not clear how much pre-training knowledge is required to answer queries with a small number of augmentation steps, which is a desirable property in practice. To address this question, we formulate multi-step reasoning as an $s$-$t$ connectivity problem on a knowledge graph. We represent a model's pre-training parametric knowledge as a partial, potentially noisy subgraph. We view augmentation as querying an oracle for true edges that augment the model's knowledge. Then, we characterize the necessary and sufficient number of augmentation steps for the model to generate an accurate answer given partial prior knowledge. One key result shows a phase transition: if the prior knowledge graph over $n$ vertices is disconnected into small components, then finding a path via augmentation is inefficient and requires $\Omega(\sqrt{n})$ queries. On the other hand, once the density of correct knowledge surpasses a threshold, forming a giant component, we can find paths with an expected constant number of queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16609v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avrim Blum, Daniel Hsu, Cyrus Rashtchian, Donya Saless</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Quantum Algorithms for Computing (Coarse) Correlated Equilibria of General-Sum Games</title>
      <link>https://arxiv.org/abs/2510.16782</link>
      <description>arXiv:2510.16782v1 Announce Type: cross 
Abstract: Computing Nash equilibria of zero-sum games in classical and quantum settings is extensively studied. For general-sum games, computing Nash equilibria is PPAD-hard and the computing of a more general concept called correlated equilibria has been widely explored in game theory. In this paper, we initiate the study of quantum algorithms for computing $\varepsilon$-approximate correlated equilibria (CE) and coarse correlated equilibria (CCE) in multi-player normal-form games. Our approach utilizes quantum improvements to the multi-scale Multiplicative Weight Update (MWU) method for CE calculations, achieving a query complexity of $\tilde{O}(m\sqrt{n})$ for fixed $\varepsilon$. For CCE, we extend techniques from quantum algorithms for zero-sum games to multi-player settings, achieving query complexity $\tilde{O}(m\sqrt{n}/\varepsilon^{2.5})$. Both algorithms demonstrate a near-optimal scaling in the number of players $m$ and actions $n$, as confirmed by our quantum query lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16782v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tongyang Li, Xinzhao Wang, Yexin Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient derandomization of differentially private counting queries</title>
      <link>https://arxiv.org/abs/2510.16959</link>
      <description>arXiv:2510.16959v2 Announce Type: cross 
Abstract: Differential privacy for the 2020 census required an estimated 90 terabytes of randomness [GL20], an amount which may be prohibitively expensive or entirely infeasible to generate. Motivated by these practical concerns, [CSV25] initiated the study of the randomness complexity of differential privacy, and in particular, the randomness complexity of $d$ counting queries. This is the task of outputting the number of entries in a dataset that satisfy predicates $\mathcal{P}_1, \dots, \mathcal{P}_d$ respectively. They showed the rather surprising fact that though any reasonably accurate, $\varepsilon$-differentially private mechanism for one counting query requires $1-O(\varepsilon)$ bits of randomness in expectation, there exists a fairly accurate mechanism for $d$ counting queries which requires only $O(\log d)$ bits of randomness in expectation.
  The mechanism of [CSV25] is inefficient (not polynomial time) and relies on a combinatorial object known as rounding schemes. Here, we give a polynomial time mechanism which achieves nearly the same randomness complexity versus accuracy tradeoff as that of [CSV25]. Our construction is based on the following simple observation: after a randomized shift of the answer to each counting query, the answer to many counting queries remains the same regardless of whether we add noise to that coordinate or not. This allows us to forgo the step of adding noise to the result of many counting queries. Our mechanism does not make use of rounding schemes. Therefore, it provides a different -- and, in our opinion, clearer -- insight into the origins of the randomness savings that can be obtained by batching $d$ counting queries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16959v2</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Surendra Ghentiyala</dc:creator>
    </item>
    <item>
      <title>Counterfactual Explanations for Integer Optimization Problems</title>
      <link>https://arxiv.org/abs/2510.17624</link>
      <description>arXiv:2510.17624v1 Announce Type: cross 
Abstract: Counterfactual explanations (CEs) offer a human-understandable way to explain decisions by identifying specific changes to the input parameters of a base or present model that would lead to a desired change in the outcome. For optimization models, CEs have primarily been studied in limited contexts and little research has been done on CEs for general integer optimization problems. In this work, we address this gap. We first show that the general problem of constructing a CE is $\Sigma_2^p$-complete even for binary integer programs with just a single mutable constraint. Second, we propose solution algorithms for several of the most tractable special cases: (i) mutable objective parameters, (ii) a single mutable constraint, (iii) mutable right-hand-side, and (iv) all input parameters can be modified. We evaluate our approach using classical knapsack problem instances, focusing on cases with mutable constraint parameters. Our results show that our methods are capable of finding optimal CEs for small instances involving up to 40 items within a few hours.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17624v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felix Engelhardt, Jannis Kurtz, \c{S}. \.Ilker Birbil, Ted Ralphs</dc:creator>
    </item>
    <item>
      <title>On the formalization of the notion of a concurrent algorithm</title>
      <link>https://arxiv.org/abs/2410.17821</link>
      <description>arXiv:2410.17821v3 Announce Type: replace 
Abstract: Previous papers give accounts of quests for satisfactory formalizations of the classical informal notion of an algorithm and the contemporary informal notion of an interactive algoritm. In this paper, an attempt is made to generalize the results of the former quest to the contemporary informal notion of a concurrent algorithm. The notion of a concurrent proto-algorithm is introduced. The thought is that concurrent algorithms are equivalence classes of concurrent proto-algorithms under an appropriate equivalence relation. Three equivalence relations are defined. Two of them are deemed to be bounds for an appropriate equivalence relation and the third is likely an appropriate one. The connection between concurrency and non-determinism in the presented setting is also addressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17821v3</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>A parameterized linear formulation of the integer hull</title>
      <link>https://arxiv.org/abs/2501.02347</link>
      <description>arXiv:2501.02347v3 Announce Type: replace 
Abstract: Let $A \in \mathbb{Z}^{m \times n}$ be an integer matrix with components bounded by $\Delta$ in absolute value. Cook et al.~(1986) have shown that there exists a universal matrix $B \in \mathbb{Z}^{m' \times n}$ with the following property: For each $b \in \mathbb{Z}^m$, there exists $t \in \mathbb{Z}^{m'}$ such that the integer hull of the polyhedron $P = \{ x \in \mathbb{R}^n \colon Ax \leq b\}$ is described by $P_I = \{ x \in \mathbb{R}^n \colon Bx \leq t\}$. Our \emph{main result} is that $t$ is an \emph{affine} function of $b$ as long as $b$ is from a fixed equivalence class of the lattice $D \cdot \mathbb{Z}^m$. Here $D \in \mathbb{N}$ is a number that depends on $n$ and $\Delta$ only. Furthermore, $D$ as well as the matrix $B$ can be computed in time depending on $\Delta$ and $n$ only. An application of this result is the solution of an open problem posed by Cslovjecsek et al.~(SODA 2024) concerning the complexity of \emph{2-stage-stochastic integer programming} problems. The main tool of our proof is the classical theory of \emph{Chv\'atal-Gomory cutting planes} and the \emph{elementary closure} of rational polyhedra.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02347v3</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Friedrich Eisenbrand, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>Polynomial time classical versus quantum algorithms for representation theoretic multiplicities</title>
      <link>https://arxiv.org/abs/2502.20253</link>
      <description>arXiv:2502.20253v2 Announce Type: replace 
Abstract: Littlewood-Richardson, Kronecker and plethysm coefficients are fundamental multiplicities of interest in Representation Theory and Algebraic Combinatorics. Determining a combinatorial interpretation for the Kronecker and plethysm coefficients is a major open problem, and prompts the consideration of their computational complexity. Recently it was shown that they behave relatively well with respect to quantum computation, and for some large families there are polynomial time quantum algorithms [Larocca,Havlicek, arXiv:2407.17649] (also [BCGHZ,arXiv:2302.11454]). In this paper we show that for many of those cases the Kronecker and plethysm coefficients can also be computed in polynomial time via classical algorithms, thereby refuting some of the conjectures in [LH24]. This vastly limits the cases in which the desired super-polynomial quantum speedup could be achieved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.20253v2</guid>
      <category>cs.CC</category>
      <category>math.CO</category>
      <category>math.RT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Greta Panova</dc:creator>
    </item>
    <item>
      <title>Psi-Turing Machines: Bounded Introspection for Complexity Barriers and Oracle Separations</title>
      <link>https://arxiv.org/abs/2510.08577</link>
      <description>arXiv:2510.08577v2 Announce Type: replace 
Abstract: We introduce Psi-Turing Machines (Psi-TM): classical Turing machines equipped with a constant-depth introspection interface $ \iota $ and an explicit per-step information budget $ B(d,n)=c\,d\log_2 n $. With the interface frozen, we develop an information-theoretic lower-bound toolkit: Budget counting, $ \Psi $-Fooling, and $ \Psi $-Fano, with worked examples $ L_k $ and $ L_k^{\mathrm{phase}} $. We prove an oracle-relative separation $ P^{\Psi} \neq NP^{\Psi} $ and a strict depth hierarchy, reinforced by an Anti-Simulation Hook that rules out polynomial emulation of $ \iota_k $ using many calls to $ \iota_{k-1} $ under the budget regime. We also present two independent platforms (Psi-decision trees and interface-constrained circuits IC-AC$^{0}$/IC-NC$^{1}$) and bridges that transfer bounds among machine, tree, and circuit with explicit poly/log losses. The model preserves classical computational power outside $ \iota $ yet enables precise oracle-aware statements about barriers (relativization; partial/conditional progress on natural proofs and proof complexity). The aim is a standardized minimal introspection interface with clearly accounted information budgets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.08577v2</guid>
      <category>cs.CC</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rafig Huseynzade</dc:creator>
    </item>
    <item>
      <title>The Complexity of Recognizing Facets for the Knapsack Polytope</title>
      <link>https://arxiv.org/abs/2211.03311</link>
      <description>arXiv:2211.03311v3 Announce Type: replace-cross 
Abstract: The complexity class DP is the class of all languages that are the intersection of a language in NP and a language in coNP. It was conjectured that recognizing a facet for the knapsack polytope is DP-complete. We provide a positive answer to this conjecture. Moreover, despite the \DP-hardness of the recognition problem, we give a polynomial time algorithm for deciding if an inequality with a fixed number of distinct coefficients defines a facet of a knapsack polytope.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03311v3</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rui Chen, Haoran Zhu</dc:creator>
    </item>
    <item>
      <title>The Complexity of Symmetric Equilibria in Min-Max Optimization and Team Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2502.08519</link>
      <description>arXiv:2502.08519v4 Announce Type: replace-cross 
Abstract: We consider the problem of computing stationary points in min-max optimization, with a particular focus on the special case of computing Nash equilibria in (two-)team zero-sum games.
  We first show that computing $\epsilon$-Nash equilibria in $3$-player \emph{adversarial} team games -- wherein a team of $2$ players competes against a \emph{single} adversary -- is \textsf{CLS}-complete, resolving the complexity of Nash equilibria in such settings. Our proof proceeds by reducing from \emph{symmetric} $\epsilon$-Nash equilibria in \emph{symmetric}, identical-payoff, two-player games, by suitably leveraging the adversarial player so as to enforce symmetry -- without disturbing the structure of the game. In particular, the class of instances we construct comprises solely polymatrix games, thereby also settling a question left open by Hollender, Maystre, and Nagarajan (2024). We also provide some further results concerning equilibrium computation in adversarial team games.
  Moreover, we establish that computing \emph{symmetric} (first-order) equilibria in \emph{symmetric} min-max optimization is \textsf{PPAD}-complete, even for quadratic functions. Building on this reduction, we further show that computing symmetric $\epsilon$-Nash equilibria in symmetric, $6$-player ($3$ vs. $3$) team zero-sum games is also \textsf{PPAD}-complete, even for $\epsilon = \text{poly}(1/n)$. As an immediate corollary, this precludes the existence of symmetric dynamics -- which includes many of the algorithms considered in the literature -- converging to stationary points. Finally, we prove that computing a \emph{non-symmetric} $\text{poly}(1/n)$-equilibrium in symmetric min-max optimization is \textsf{FNP}-hard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08519v4</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ioannis Anagnostides, Ioannis Panageas, Tuomas Sandholm, Jingming Yan</dc:creator>
    </item>
    <item>
      <title>A Knapsack by Any Other Name: Presentation impacts LLM performance on NP-hard problems</title>
      <link>https://arxiv.org/abs/2502.13776</link>
      <description>arXiv:2502.13776v2 Announce Type: replace-cross 
Abstract: To investigate the effect of problem presentation on LLMs' ability to solve optimization problems, we introduce the dataset of Everyday Hard Optimization Problems (EHOP), a collection of NP-hard problems expressed in natural language. EHOP includes problem formulations that could be found in computer science textbooks (e.g., graph coloring), versions that are dressed up as problems that could arise in real life (e.g., party planning), and variants with inverted rules. We find that state-of-the-art LLMs, across multiple prompting strategies, systematically solve textbook problems more accurately than their real-life and inverted counterparts. While reasoning models are more capable, they nonetheless show high variance across problem presentations, suggesting they lack a truly robust reasoning mechanism. We argue that this constitutes evidence that LLMs are still heavily dependent on what was seen in training and struggle to generalize to novel problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13776v2</guid>
      <category>cs.CL</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Duchnowski, Ellie Pavlick, Alexander Koller</dc:creator>
    </item>
    <item>
      <title>Subgradient Method for System Identification with Non-Smooth Objectives</title>
      <link>https://arxiv.org/abs/2503.16673</link>
      <description>arXiv:2503.16673v2 Announce Type: replace-cross 
Abstract: This paper investigates a subgradient-based algorithm to solve the system identification problem for linear time-invariant systems with non-smooth objectives. This is essential for robust system identification in safety-critical applications. While existing work provides theoretical exact recovery guarantees using optimization solvers, the design of fast learning algorithms with convergence guarantees for practical use remains unexplored. We analyze the subgradient method in this setting, where the optimization problems to be solved evolve over time as new measurements are collected, and we establish linear convergence to the ground-truth system for both the best and Polyak step sizes after a burn-in period. We further characterize sublinear convergence of the iterates under constant and diminishing step sizes, which require only minimal information and thus offer broad applicability. Finally, we compare the time complexity of standard solvers with the subgradient algorithm and support our findings with experimental results. This is the first work to analyze subgradient algorithms for system identification with non-smooth objectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16673v2</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Baturalp Yalcin, Jihun Kim, Javad Lavaei</dc:creator>
    </item>
    <item>
      <title>Structural Origin and the Minimal Syntax of NP-Hardness: Analysis of SAT from Syntactic Generativity and Compositional Collapse</title>
      <link>https://arxiv.org/abs/2509.22995</link>
      <description>arXiv:2509.22995v2 Announce Type: replace-cross 
Abstract: The Boolean satisfiability problem (SAT) holds a central place in computational complexity theory as the first shown NP-complete problem. Due to this role, SAT is often used as the benchmark for polynomial-time reductions: if a problem can be reduced to SAT, it is at least as hard as SAT, and hence considered NP-complete. However, the CDF framework offers a structural inversion of this traditional view. Rather than treating SAT as merely a representative of NP-completeness, we investigate whether the syntactic structure of SAT itself -- especially in its 3SAT form -- is the source of semantic explosion and computational intractability observed in NP problems. In other words, SAT is not just the yardstick of NP-completeness, but may be the structural archetype that induces NP-type complexity. This reframing suggests that the P vs NP question is deeply rooted not only in computational resource limits, but in the generative principles of problem syntax, with 3SAT capturing the recursive and non-local constructions that define the boundary between tractable and intractable problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22995v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Tue, 21 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yumiko Nishiyama</dc:creator>
    </item>
  </channel>
</rss>
