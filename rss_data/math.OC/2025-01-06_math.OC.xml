<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 07 Jan 2025 03:19:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Classification and Feasibility Assessment of Infinitely Many Iso-Impulse Three-Dimensional Trajectories</title>
      <link>https://arxiv.org/abs/2501.01583</link>
      <description>arXiv:2501.01583v1 Announce Type: new 
Abstract: In two-body dynamics, it is proven that for a sufficiently long flight time, generating infinitely many iso-impulse solutions is possible by solving a number of $\Delta v$-allocation problems analytically. A distinct feature of these solutions is the existence of two impulse anchor positions (APs) that correspond to the locations of the impulses on time-free, phase-free, base solutions. In this paper, the existence and utility of three-impulse base solutions are investigated and their complete solution spaces are characterized and analyzed. Since two- and three-impulse base solutions exist, a question arises: How many APs should base solutions have? A strategy is developed for choosing base solutions, which offers a certificate for $\Delta v$ optimality of general three-dimensional time-fixed rendezvous solutions. Simultaneous allocation of $\Delta v$ at two and three APs is formulated, which allows for generating $\Delta v$-optimal solutions while satisfying a constraint on individual impulses such that $\Delta v \leq \Delta v_\text{max}$. All iso-impulse solutions are classified in four layers: 1) base solutions, 2) feasible solution spaces, 3) solution families, and 4) solution envelopes. The method enables us to characterize the complete solution space of minimum-$\Delta v$, iso-impulse, three-dimensional trajectories under the nonlinear two-body dynamics. To illustrate the utility of the method, interplanetary and geocentric problems are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01583v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keziban Saloglu, Ehsan Taheri</dc:creator>
    </item>
    <item>
      <title>Viscosity Solutions of Fully second-order HJB Equations in the Wasserstein Space</title>
      <link>https://arxiv.org/abs/2501.01612</link>
      <description>arXiv:2501.01612v1 Announce Type: new 
Abstract: In this paper, we show that the value functions of mean field control problems with common noise are the unique viscosity solutions to fully second-order Hamilton-Jacobi-Bellman equations, in a Crandall-Lions-like framework. We allow the second-order derivative in measure to be state-dependent and thus infinite-dimensional, rather than derived from a finite-dimensional operator, hence the term ''fully''. Our argument leverages the construction of smooth approximations from particle systems developed by Cosso, Gozzi, Kharroubi, Pham, and Rosestolato [Trans. Amer. Math. Soc., 2023], and the compactness argument via penalization of measure moments in Soner and Yan [Appl. Math. Optim., 2024]. Our work addresses unbounded dynamics and state-dependent common noise volatility, and to our knowledge, this is the first result of its kind in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01612v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erhan Bayraktar, Hang Cheung, Ibrahim Ekren, Jinniao Qiu, Ho Man Tai, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Beyond Non-Degeneracy: Revisiting Certainty Equivalent Heuristic for Online Linear Programming</title>
      <link>https://arxiv.org/abs/2501.01716</link>
      <description>arXiv:2501.01716v1 Announce Type: new 
Abstract: The Certainty Equivalent heuristic (CE) is a widely-used algorithm for various dynamic resource allocation problems in OR and OM. Despite its popularity, existing theoretical guarantees of CE are limited to settings satisfying restrictive fluid regularity conditions, particularly, the non-degeneracy conditions, under the widely held belief that the violation of such conditions leads to performance deterioration and necessitates algorithmic innovation beyond CE.
  In this work, we conduct a refined performance analysis of CE within the general framework of online linear programming. We show that CE achieves uniformly near-optimal regret (up to a polylogarithmic factor in $T$) under only mild assumptions on the underlying distribution, without relying on any fluid regularity conditions. Our result implies that, contrary to prior belief, CE effectively beats the curse of degeneracy for a wide range of problem instances with continuous conditional reward distributions, highlighting the distinction of the problem's structure between discrete and non-discrete settings. Our explicit regret bound interpolates between the mild $(\log T)^2$ regime and the worst-case $\sqrt{T}$ regime with a parameter $\beta$ quantifying the minimal rate of probability accumulation of the conditional reward distributions, generalizing prior findings in the multisecretary setting.
  To achieve these results, we develop novel algorithmic analytical techniques. Drawing tools from the empirical processes theory, we establish strong concentration analysis of the solutions to random linear programs, leading to improved regret analysis under significantly relaxed assumptions. These techniques may find potential applications in broader online decision-making contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01716v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yilun Chen, Wenjia Wang</dc:creator>
    </item>
    <item>
      <title>Constrained Pricing in Choice-based Revenue Management</title>
      <link>https://arxiv.org/abs/2501.01764</link>
      <description>arXiv:2501.01764v1 Announce Type: new 
Abstract: We consider a dynamic pricing problem in network revenue management where customer behavior is predicted by a choice model, i.e., the multinomial logit (MNL) model. The problem, even in the static setting (i.e., customer demand remains unchanged over time), is highly non-concave in prices. Existing studies mostly rely on the observation that the objective function is concave in terms of purchasing probabilities, implying that the static pricing problem with linear constraints on purchasing probabilities can be efficiently solved. However, this approach is limited in handling constraints on prices, noting that such constraints could be highly relevant in some real business considerations. To address this limitation, in this work, we consider a general pricing problem that involves constraints on both prices and purchasing probabilities. To tackle the non-concavity challenge, we develop an approximation mechanism that allows solving the constrained static pricing problem through bisection and mixed-integer linear programming (MILP). We further extend the approximation method to the dynamic pricing context. Our approach involves a resource decomposition method to address the curse of dimensionality of the dynamic problem, as well as a MILP approach to solving sub-problems to near-optimality. Numerical results based on generated instances of various sizes indicate the superiority of our approximation approach in both static and dynamic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01764v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Shao, Tien Mai, Shih-Fen Cheng</dc:creator>
    </item>
    <item>
      <title>On extending the class of convex functions</title>
      <link>https://arxiv.org/abs/2501.01854</link>
      <description>arXiv:2501.01854v1 Announce Type: new 
Abstract: In this brief note, it is shown that the function p^TW log(p) is convex in p if W is a diagonally dominant positive definite M-matrix. The techniques used to prove convexity are well-known in linear algebra and essentially involves factoring the Hessian in a way that is amenable to martix analysis. Using similar techniques, two classes of convex homogeneous polynomials is derived - namely, p^TW p2 and (p^k)^TW p^k - the latter also happen to be SOS-convex. Lastly, usign the same techniques, it is also shown that the function p^TW ep is convex over the positive reals only if W is a non-negative diagonal matrix. Discussions regarding the utility of these functions and examples accompany the results presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01854v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shravan Mohan</dc:creator>
    </item>
    <item>
      <title>Evaluation of Rail Decarbonization Alternatives: Framework and Application</title>
      <link>https://arxiv.org/abs/2501.01614</link>
      <description>arXiv:2501.01614v1 Announce Type: cross 
Abstract: The Northwestern University Freight Rail Infrastructure and Energy Network Decarbonization (NUFRIEND) framework is a comprehensive industry-oriented tool for simulating the deployment of new energy technologies including biofuels, e-fuels, battery-electric, and hydrogen locomotives. By classifying fuel types into two categories based on deployment requirements, the associated optimal charging/fueling facility location and sizing problem are solved with a five-step framework. Life cycle analyses (LCA) and techno-economic analyses (TEA) are used to estimate carbon reduction, capital investments, cost of carbon reduction, and operational impacts, enabling sensitivity analysis with operational and technological parameters. The framework is illustrated on lower-carbon drop-in fuels as well as battery-electric technology deployments for US Eastern and Western Class I railroad networks. Drop-in fuel deployments are modeled as admixtures with diesel in existing locomotives, while battery-electric deployments are shown for varying technology penetration levels and locomotive ranges. When mixed in a 50 percent ratio with diesel, results show biodiesel's capacity to reduce emissions at 36 percent with a cost of 0.13 USD per kilogram of CO2 reduced, while e-fuels offer a 50 percent emissions reduction potential at a cost of 0.22 USD per kilogram of CO2 reduced. Battery-electric results for 50 percent deployment over all ton-miles highlight the value of future innovations in battery energy densities as scenarios assuming 800-mile range locomotives show an estimated emissions reduction of 46 percent with a cost of 0.06 USD per kilogram of CO2 reduced, compared to 16 percent emissions reduction at a cost of 0.11 USD per kilogram of CO2 reduced for 400-mile range locomotives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01614v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1177/03611981231170182</arxiv:DOI>
      <arxiv:journal_reference>Transportation Research Record 2678.1 (2024): 102-121</arxiv:journal_reference>
      <dc:creator>Adrian Hernandez, Max TM Ng, Nazib Siddique, Pablo L. Durango-Cohen, Amgad Elgowainy, Hani S. Mahmassani, Michael Wang, Yan Zhou</dc:creator>
    </item>
    <item>
      <title>Equity Impacts of Public Transit Network Redesign with Shared Autonomous Mobility Services</title>
      <link>https://arxiv.org/abs/2501.01615</link>
      <description>arXiv:2501.01615v1 Announce Type: cross 
Abstract: This study examines the equity impacts of integrating shared autonomous mobility services (SAMS) into transit system redesign. Using the Greater Chicago area as a case study, we compare two optimization objectives in multimodal transit network redesign: minimizing total generalized costs (equity-agnostic) versus prioritizing service in low-income areas (equity-focused). We evaluate the achieved accessibility of clustered zones with redesigned transit networks under two objectives, compared to driving and the existing transit network. The transit access gaps across zones and between transit and driving are found to be generally reduced with the introduction of SAMS, but less so with the subsequent improved infrastructure under budget. Differential improvement in equity is seen across suburbs and areas of the city, reflecting the disparity in current transit access and improvement potential. In particular, SAMS bridges the transit access gaps in suburban and city areas currently underserved by transit. The City of Chicago, which is also disproportionately home to vulnerable populations, offers an avenue to improve vertical equity. These findings demonstrate that SAMS can enhance both horizontal and vertical equity in transit systems, particularly when equity is explicitly incorporated into the design objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01615v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Max T. M. Ng, Meredith Raymer, Hani S. Mahmassani, Omer Verbas, Taner Cokyasar</dc:creator>
    </item>
    <item>
      <title>Optimal Fiducial Marker Placement for Satellite Proximity Operations Using Observability Gramians</title>
      <link>https://arxiv.org/abs/2501.01704</link>
      <description>arXiv:2501.01704v1 Announce Type: cross 
Abstract: This paper investigates optimal fiducial marker placement on the surface of a satellite performing relative proximity operations with an observer satellite. The absolute and relative translation and attitude equations of motion for the satellite pair are modeled using dual quaternions. The observability of the relative dual quaternion system is analyzed using empirical observability Gramian methods. The optimal placement of a fiducial marker set, in which each marker gives simultaneous optical range and attitude measurements, is determined for the pair of satellites. A geostationary flyby between the observing body (chaser) and desired (target) satellites is numerically simulated and the optimal fiducial placement sets of five and ten on the surface of the desired satellite are solved. It is shown that the optimal solution maximizes the distance between fiducial markers and selects marker locations that are most sensitive to measuring changes in the state during the nonlinear trajectory, despite being visible for less time than other candidate marker locations. Definitions and properties of quaternions and dual quaternions, and parallels between the two, are presented alongside the relative motion model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01704v1</guid>
      <category>eess.SY</category>
      <category>cs.CV</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas B. Andrews, Kristi A. Morgansen</dc:creator>
    </item>
    <item>
      <title>Sensor Placement on a Cantilever Beam Using Observability Gramians</title>
      <link>https://arxiv.org/abs/2501.01726</link>
      <description>arXiv:2501.01726v1 Announce Type: cross 
Abstract: Working from an observability characterization based on output energy sensitivity to changes in initial conditions, we derive both analytical and empirical observability Gramian tools for a class of continuum material systems. Using these results, optimal sensor placement is calculated for an Euler-Bernoulli cantilever beam for the following cases: analytical observability for the continuum system and analytical observability for a finite number of modes. Error covariance of an Unscented Kalman Filter is determined for both cases and compared to randomly placed sensors to demonstrate effectiveness of the techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01726v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CDC51059.2022.9992639</arxiv:DOI>
      <dc:creator>Natalie L. Brace, Nicholas B. Andrews, Jeremy Upsal, Kristi A. Morgansen</dc:creator>
    </item>
    <item>
      <title>An integral transformation approach to differential games: a climate model application</title>
      <link>https://arxiv.org/abs/2501.01749</link>
      <description>arXiv:2501.01749v1 Announce Type: cross 
Abstract: We develop an Integral Transformation Method (ITM) for the study of suitable optimal control and differential game models. This allows for a solution to such dynamic problems to be found through solving a family of optimization problems parametrized by time. The method is quite flexible, and it can be used in several economic applications where the state equation and the objective functional are linear in a state variable. We illustrate the ITM in the context of a two-country integrated assessment climate model. We characterize emissions, consumption, transfers, and welfare by computing the Nash equilibria of the associated dynamic game. We then compare them to efficiency benchmarks. Further, we apply the ITM in a robust control setup, where we investigate how (deep) uncertainty affects climate outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01749v1</guid>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raouf Boucekkine, Giorgio Fabbri, Salvatore Federico, Fausto Gozzi, Ted Loch-Temzelides, Cristiano Ricci</dc:creator>
    </item>
    <item>
      <title>Compressed sensing for inverse problems II: applications to deconvolution, source recovery, and MRI</title>
      <link>https://arxiv.org/abs/2501.01929</link>
      <description>arXiv:2501.01929v1 Announce Type: cross 
Abstract: This paper extends the sample complexity theory for ill-posed inverse problems developed in a recent work by the authors [`Compressed sensing for inverse problems and the sample complexity of the sparse Radon transform', J. Eur. Math. Soc., to appear], which was originally focused on the sparse Radon transform. We demonstrate that the underlying abstract framework, based on infinite-dimensional compressed sensing and generalized sampling techniques, can effectively handle a variety of practical applications. Specifically, we analyze three case studies: (1) The reconstruction of a sparse signal from a finite number of pointwise blurred samples; (2) The recovery of the (sparse) source term of an elliptic partial differential equation from finite samples of the solution; and (3) A moderately ill-posed variation of the classical sensing problem of recovering a wavelet-sparse signal from finite Fourier samples, motivated by magnetic resonance imaging. For each application, we establish rigorous recovery guarantees by verifying the key theoretical requirements, including quasi-diagonalization and coherence bounds. Our analysis reveals that careful consideration of balancing properties and optimized sampling strategies can lead to improved reconstruction performance. The results provide a unified theoretical foundation for compressed sensing approaches to inverse problems while yielding practical insights for specific applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.01929v1</guid>
      <category>math.FA</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni S. Alberti, Alessandro Felisi, Matteo Santacesaria, S. Ivan Trapasso</dc:creator>
    </item>
    <item>
      <title>Using second-order information in gradient sampling methods for nonsmooth optimization</title>
      <link>https://arxiv.org/abs/2210.04579</link>
      <description>arXiv:2210.04579v4 Announce Type: replace 
Abstract: In this article, we introduce a novel concept for second-order information of a nonsmooth function inspired by the Goldstein eps-subdifferential. It comprises the coefficients of all existing second-order Taylor expansions in an eps-ball around a given point. Based on this concept, we define a model of the objective as the maximum of these Taylor expansions, and derive a sampling scheme for its approximation in practice. Minimization of this model induces a simple descent method, for which we show convergence for the case where the objective is convex or of max-type. While we do not prove any rate of convergence of this method, numerical experiments suggest superlinear behavior with respect to the number of oracle calls of the objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.04579v4</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bennet Gebken</dc:creator>
    </item>
    <item>
      <title>Lifting partial smoothing to solve HJB equations and stochastic control problems</title>
      <link>https://arxiv.org/abs/2306.06016</link>
      <description>arXiv:2306.06016v2 Announce Type: replace 
Abstract: We study a family of stochastic control problems arising in typical applications (such as boundary control and control of delay equations with delay in the control) with the ultimate aim of finding solutions of the associated HJB equations, regular enough to find optimal feedback controls. These problems are difficult to treat since the underlying transition semigroups do not possess good smoothing properties nor the so-called "structure condition" which typically allows to apply the backward equations approach. In the papers [14], [15], and, more recently, [16] we studied such problems developing new partial smoothing techniques which allowed us to obtain the required regularity in the case when the cost functional is independent of the state variable. This is a somehow strong restriction which is not verified in most applications. In this paper (which can be considered a continuation of the research of the above papers) we develop a new approach to overcome this restriction. We extend the partial smoothing result to a wider class of functions which depend on the whole trajectory of the underlying semigroup and we use this as a key tool to improve our regularity result for the HJB equation. The fact that such class depends on trajectories requires a nontrivial technical work as we have to lift the original transition semigroup to a space of trajectories, defining a new "high-level" environment where our problems can be solved.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06016v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fausto Gozzi, Federica Masiero</dc:creator>
    </item>
    <item>
      <title>On Averaging and Extrapolation for Gradient Descent</title>
      <link>https://arxiv.org/abs/2402.12493</link>
      <description>arXiv:2402.12493v3 Announce Type: replace 
Abstract: This work considers the effect of averaging, and more generally extrapolation, of the iterates of gradient descent in smooth convex optimization. After running the method, rather than reporting the final iterate, one can report either a convex combination of the iterates (averaging) or a generic combination of the iterates (extrapolation). For several common stepsize sequences, including recently developed accelerated periodically long stepsize schemes, we show averaging cannot improve gradient descent's worst-case performance and is, in fact, strictly worse than simply returning the last iterate. In contrast, we prove a conceptually simple and computationally cheap extrapolation scheme strictly improves the worst-case convergence rate: when initialized at the origin, reporting $(1+1/\sqrt{16N\log(N)})x_N$ rather than $x_N$ improves the best possible worst-case performance by the same amount as conducting $O(\sqrt{N/\log(N)})$ more gradient steps. Our analysis and characterizations of the best-possible convergence guarantees are computer-aided, using performance estimation problems. Numerically, we find similar (small) benefits from such simple extrapolation for a range of gradient methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12493v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alan Luner, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Regularized Benders Decomposition for High Performance Capacity Expansion Models</title>
      <link>https://arxiv.org/abs/2403.02559</link>
      <description>arXiv:2403.02559v2 Announce Type: replace 
Abstract: We consider electricity capacity expansion models, which optimize investment and retirement decisions by minimizing both investment and operation costs. In order to provide credible support for planning and policy decisions, these models need to include detailed operations and time-coupling constraints, consider multiple possible realizations of weather-related parameters and demand data, and allow modeling of discrete investment and retirement decisions. Such requirements result in large-scale mixed-integer optimization problems that are intractable with off-the-shelf solvers. Hence, practical solution approaches often rely on carefully designed abstraction techniques to find the best compromise between reduced computational burden and model accuracy. Benders decomposition offers scalable approaches to leverage distributed computing resources and enable models with both high resolution and computational performance. In this study, we implement a tailored Benders decomposition method for large-scale capacity expansion models with multiple planning periods, stochastic operational scenarios, time-coupling policy constraints, and multi-day energy storage and reservoir hydro resources. Using multiple case studies, we also evaluate several level-set regularization schemes to accelerate convergence. We find that a regularization scheme that selects planning decisions in the interior of the feasible set shows superior performance compared to previously published methods, enabling high-resolution, mixed-integer planning problems with unprecedented computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02559v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Pecci, Jesse D. Jenkins</dc:creator>
    </item>
    <item>
      <title>Deciding Bank Interest Rates -- A Major-Minor Impulse Control Mean-Field Game Perspective</title>
      <link>https://arxiv.org/abs/2411.14481</link>
      <description>arXiv:2411.14481v2 Announce Type: replace 
Abstract: Deciding bank interest rates has been a long-standing challenge in finance. It is crucial to ensure that the selected rates balance market share and profitability. However, traditional approaches typically focus on the interest rate changes of individual banks, often neglecting the interactions with other banks in the market. This work proposes a novel framework that models the interest rate problem as a major-minor mean field game within the context of an interbank game. To incorporate the complex interactions between banks, we utilize mean-field theory and employ impulsive control to model the overhead in rate adjustments. Ultimately, we solve this optimal control problem using a new deep Q-network method, which iterates the parameterized action value functions for major and minor players and updates the networks in a Fictitious Play way. Our proposed algorithm converges, offering a solution that enables the analysis of strategies for major and minor players in the market under the Nash Equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.14481v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Chen, Nicholas Martin, Po-Yu Chen, Xiaozhen Wang, Zhenjie Ren, Francois Buet-Golfouse</dc:creator>
    </item>
    <item>
      <title>Decoupled Functional Central Limit Theorems for Two-Time-Scale Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2412.17070</link>
      <description>arXiv:2412.17070v2 Announce Type: replace-cross 
Abstract: In two-time-scale stochastic approximation (SA), two iterates are updated at different rates, governed by distinct step sizes, with each update influencing the other. Previous studies have demonstrated that the convergence rates of the error terms for these updates depend solely on their respective step sizes, a property known as decoupled convergence. However, a functional version of this decoupled convergence has not been explored. Our work fills this gap by establishing decoupled functional central limit theorems for two-time-scale SA, offering a more precise characterization of its asymptotic behavior. To achieve these results, we leverage the martingale problem approach and establish tightness as a crucial intermediate step. Furthermore, to address the interdependence between different time scales, we introduce an innovative auxiliary sequence to eliminate the primary influence of the fast-time-scale update on the slow-time-scale update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17070v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 06 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuze Han, Xiang Li, Jiadong Liang, Zhihua Zhang</dc:creator>
    </item>
  </channel>
</rss>
