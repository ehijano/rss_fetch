<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Jun 2024 01:54:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optical-computing-enabled Network: A New Dawn for Optical-layer Intelligence?</title>
      <link>https://arxiv.org/abs/2406.00162</link>
      <description>arXiv:2406.00162v1 Announce Type: new 
Abstract: Inspired by the renaissance of optical computing recently, this poster presents a disruptive outlook on the possibility of seamless integration between optical communications and optical computing infrastructures, paving the way for achieving optical-layer intelligence and consequently boosting the capacity efficiency. This entails a paradigm shift in optical node architecture from the currently used optical-bypass to a novel one, entitled, optical-computing-enabled mode, where in addition to the traditional add-drop and cross-connect functionalities, optical nodes are upgraded to account for optical-computing capabilities between the lightpath entities directly at the optical layer. A preliminary study focusing on the optical aggregation operation is examined and early simulation results indicate a promising spectral saving enabled by the optical-computing-enabled mode compared with the optical-bypass one.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00162v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3663408.366582</arxiv:DOI>
      <dc:creator>Dao Thanh Hai, Minh Nguyen, Isaac Woungang</dc:creator>
    </item>
    <item>
      <title>A Survey on the Use of Partitioning in IoT-Edge-AI Applications</title>
      <link>https://arxiv.org/abs/2406.00301</link>
      <description>arXiv:2406.00301v1 Announce Type: new 
Abstract: Centralized clouds processing the large amount of data generated by Internet-of-Things (IoT) can lead to unacceptable latencies for the end user. Against this backdrop, Edge Computing (EC) is an emerging paradigm that can address the shortcomings of traditional centralized Cloud Computing (CC). Its use is associated with improved performance, productivity, and security. Some of its use cases include smart grids, healthcare Augmented Reality (AR)/Virtual Reality (VR). EC uses servers strategically placed near end users, reducing latency and proving to be particularly well-suited for time-sensitive IoT applications. It is expected to play a pivotal role in 6G and Industry 5.0. Within the IoT-edge environment, artificial intelligence (AI) plays an important role in automating decision and control, including but not limited to resource allocation activities, drawing inferences from large volumes of data, and enabling powerful security mechanisms. The use cases in the IoT-Edge-cloud environment tend to be complex resulting in large AI models, big datasets, and complex computations. This has led to researchers proposing techniques that partition data, tasks, models, or hybrid to achieve speed, efficiency, and accuracy of processing. This survey comprehensively explores the IoT-Edge-AI environment, application cases, and the partitioning techniques used. We categorize partitioning techniques and compare their performance. The survey concludes by identifying open research challenges in this domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00301v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guoxing Yao, Lav Gupta</dc:creator>
    </item>
    <item>
      <title>Toward 6G Optical Fronthaul: A Survey on Enabling Technologies and Research Perspectives</title>
      <link>https://arxiv.org/abs/2406.00308</link>
      <description>arXiv:2406.00308v1 Announce Type: new 
Abstract: The anticipated launch of the Sixth Generation (6G) of mobile technology by 2030 will mark a significant milestone in the evolution of wireless communication, ushering in a new era with advancements in technology and applications. 6G is expected to deliver ultra-high data rates and almost instantaneous communications, with three-dimensional coverage for everything, everywhere, and at any time. In the 6G Radio Access Networks (RANs) architecture, the Fronthaul connects geographically distributed Remote Units (RUs) to Distributed/Digital Units (DUs)pool. Among all possible solutions for implementing 6G fronthaul, optical technologies will remain crucial in supporting the 6G fronthaul, as they offer high-speed, low-latency, and reliable transmission capabilities to meet the 6G strict requirements. This survey provides an explanation of the 5G and future 6G optical fronthaul concept and presents a comprehensive overview of the current state of the art and future research directions in 6G optical fronthaul, highlighting the key technologies and research perspectives fundamental in designing fronthaul networks for 5G and future 6G. Additionally, it examines the benefits and drawbacks of each optical technology and its potential applications in 6G fronthaul networks. This paper aims to serve as a comprehensive resource for researchers and industry professionals about the current state and future prospects of 6G optical fronthaul technologies, facilitating the development of robust and efficient wireless networks of the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00308v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/COMST.2024.3408090</arxiv:DOI>
      <dc:creator>Abdulhalim Fayad, Tibor Cinkler, Jacek Rak</dc:creator>
    </item>
    <item>
      <title>Location Privacy in B5G/6G: Systematization of Knowledge</title>
      <link>https://arxiv.org/abs/2406.00359</link>
      <description>arXiv:2406.00359v1 Announce Type: new 
Abstract: As we transition into the era of B5G/6G networks, the promise of seamless, high-speed connectivity brings unprecedented opportunities and challenges. Among the most critical concerns is the preservation of location privacy, given the enhanced precision and pervasive connectivity of these advanced networks. This paper systematically reviews the state of knowledge on location privacy in B5G/6G networks, highlighting the architectural advancements and infrastructural complexities that contribute to increased privacy risks. The urgency of studying these technologies is underscored by the rapid adoption of B5G/6G and the growing sophistication of location tracking methods. We evaluate current and emerging privacy-preserving mechanisms, exploring the implications of sophisticated tracking methods and the challenges posed by the complex network infrastructures. Our findings reveal the effectiveness of various mitigation strategies and emphasize the important role of physical layer security. Additionally, we propose innovative approaches, including decentralized authentication systems and the potential of satellite communications, to enhance location privacy. By addressing these challenges, this paper provides a comprehensive perspective on preserving user privacy in the rapidly evolving landscape of modern communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00359v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Hannah B. Pasandi, Faith Parastar</dc:creator>
    </item>
    <item>
      <title>Optimizing Age of Information in Random Access Networks: A Second-Order Approach for Active/Passive Users</title>
      <link>https://arxiv.org/abs/2406.00491</link>
      <description>arXiv:2406.00491v1 Announce Type: new 
Abstract: In this paper, we study the moments of the Age of Information (AoI) for both active and passive users in a random access network. In this network, active users broadcast sensing data, while passive users detect in-band radio activities from out-of-network devices, such as jammers. Collisions occur when multiple active users transmit simultaneously. Passive users can detect radio activities only when no active user transmits. Each active user's transmission behavior follows a Markov process. We aim to minimize the weighted sum of any moments of AoI for both user types. To achieve this, we employ a second-order analysis of system behavior. Specifically, we characterize an active user's transmission Markov process using its mean and temporal variance. We show that any moment of the AoI can be approximated by a function of these two parameters. This insight enables us to analyze and optimize the transmission Markov process for active users. We apply this strategy to two different random access models. Simulation results show that policies derived from this strategy outperform other baseline policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00491v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siqi Fan, Yuxin Zhong, I-Hong Hou, Clement K Kam</dc:creator>
    </item>
    <item>
      <title>Throughput and Link Utilization Improvement in Satellite Networks: A Learning-Enabled Approach</title>
      <link>https://arxiv.org/abs/2406.00723</link>
      <description>arXiv:2406.00723v1 Announce Type: new 
Abstract: Satellite networks provide communication services to global users with an uneven geographical distribution. In densely populated regions, Inter-satellite links (ISLs) often experience congestion, blocking traffic from other links and leading to low link utilization and throughput. In such cases, delay-tolerant traffic can be withheld by moving satellites and carried to navigate congested areas, thereby mitigating link congestion in densely populated regions. Through rational store-and-forward decision-making, link utilization and throughput can be improved. Building on this foundation, this letter centers its focus on learning-based decision-making for satellite traffic. First, a link load prediction method based on topology isomorphism is proposed. Then, a Markov decision process (MDP) is formulated to model store-and-forward decision-making. To generate store-and-forward policies, we propose reinforcement learning algorithms based on value iteration and Q-Learning. Simulation results demonstrate that the proposed method improves throughput and link utilization while consuming less than 20$\%$ of the time required by constraint-based routing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00723v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu</dc:creator>
    </item>
    <item>
      <title>Semantic Communications: the New Paradigm Behind Beyond 5G Technologies</title>
      <link>https://arxiv.org/abs/2406.00754</link>
      <description>arXiv:2406.00754v1 Announce Type: new 
Abstract: Each generation of cellular networks is characterized by its distinct capabilities and innovations, which reflect the significant milestones reached with each new release. 5G has made substantial progress through the deployment of advanced encoding and modulation techniques, nearly reaching the Shannon physical capacity limit. In light of the requirements of Beyond-5G technologies, there is the need of a paradigm shift in the development of communication systems.
  Recent developments in the realm of Artificial Intelligence (AI) have enabled the deployment of tools with high abstraction capabilities, relevant for feature extraction processes and End-to-End system optimization tasks. In this context, Semantic Communications has emerged as a novel information transmission system, with AI as one of the core components in its implementation. This communication paradigm relies on the extraction and transmission of the "semantic meaning" of the source information using AI techniques, diverging from the conventional systems that primarily focus on ensuring the successful reception of the transmitted bits.
  The purpose of this survey is to provide a comprehensive overview of the fundamental concepts underlying Semantic Communications, including Shannon's Information Theory, classical and modern theories of semantic information, and an examination of the framework and system design of Semantic Communications. Additionally, recent implementations are reviwed, including the analysis of Semantic Communications systems according to the information object transmitted and the objective of the information transmission. Moreover, an in-depth study of prototypes and demonstrations are presented, supporting the viability of the Semantic Communications systems. Finally, some of the most relevant open challenges are detailed, highlighting open research questions to be pursued in Semantic Communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00754v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriella Fernandes, H\'elder Fontes, Rui Campos</dc:creator>
    </item>
    <item>
      <title>Experimental comparison of 5G SDR platforms: srsRAN x OpenAirInterface</title>
      <link>https://arxiv.org/abs/2406.01485</link>
      <description>arXiv:2406.01485v1 Announce Type: new 
Abstract: A Software-Defined Radio (SDR) platform is a communication system that implements as software functions that are typically implemented in dedicated hardware. One of its main advantages is the flexibility to test and deploy radio communication networks in a fast and cheap way. In the context of the Fifth Generation (5G) of wireless cellular networks, there are open source SDR platforms available online. Two of the most popular SDR platforms are srsRAN and OpenAirInterface. This paper presents these two platforms, the characteristics of the networks created by them, the possibilities of changes in their interfaces and configurations, and also their limits. Moreover, in this paper, we also evaluate and compare both platforms in an experimental setup deployed in a laboratory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01485v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruan P. Alves, Joao Guilherme A. da S. Alves, Mikael R. Camelo, Wilker O. de Feitosa, Victor F. Monteiro, Fco. Rodrigo P. Cavalcanti</dc:creator>
    </item>
    <item>
      <title>Comparison of 5G Performance Post-Merger between Two Network Operators Using Field Tests in Urban Areas</title>
      <link>https://arxiv.org/abs/2406.01048</link>
      <description>arXiv:2406.01048v1 Announce Type: cross 
Abstract: In late Q1/2023, DTAC and TRUE officially completed their merger. Consequently, this study was initiated to ascertain whether their respective 5G networks had been seamlessly integrated several months following the merger. The investigation involved conducting drive tests along two predefined routes within the urban areas of Bangkok, employing the G-NetTrack Pro tool for testing and data collection. Additionally, stationary tests were conducted in two crowded places using an application called Speedtest. Subsequently, an array of Quality of Service (QoS) metrics, including Reference Signal Received Power (RSRP), Reference Signal Received Quality (RSRQ), Signal to Noise Ratio (SNR), Download (DL), Upload (UL) speeds, and latency, were meticulously analyzed and presented. The findings of this study unveiled that, despite the successful completion of the DTAC and TRUE merger from a business standpoint, the technical integration of their respective 5G networks had not been finalized, although there were no significant differences between DTAC and TRUE for DL (p-value = 0.542) and UL (p-value = 0.090). Notably, significant differences were found between DTAC and TRUE for four metrics, including RSRP, RSRQ, SNR, and latency (p-values &lt; 0.05). Remarkably, roaming functionalities were still operational between the two networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01048v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Surachai Chatchalermpu, Therdpong Daengsi, Pakkasit Sriamorntrakul, Kritphon Phanrattanachai</dc:creator>
    </item>
    <item>
      <title>Is Universal Broadband Service Impossible?</title>
      <link>https://arxiv.org/abs/2204.11300</link>
      <description>arXiv:2204.11300v3 Announce Type: replace 
Abstract: Broadband Internet service is widely expected to be the fundamental universal service for the 21st century. But more than a decade of national and international struggles to close the digital divide between broadband haves and have nots suggest that reaching global universality will be a very difficult task. This paper argues that the strong guarantees made by the current broadband paradigm - low latency and constant availability - are unnecessary obstacles to its adoption as an affordable and universal digital service. We show that there is nonetheless a plausible strategy for deploying a Basic Broadband service that does not require such guarantees and is able to offer, at reasonable cost, almost all the critical and valuable services and applications currently delivered over low latency broadband, synchronous telepresence excepted.</description>
      <guid isPermaLink="false">oai:arXiv.org:2204.11300v3</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Micah Beck, Terry Moore</dc:creator>
    </item>
    <item>
      <title>Implementing Reinforcement Learning Datacenter Congestion Control in NVIDIA NICs</title>
      <link>https://arxiv.org/abs/2207.02295</link>
      <description>arXiv:2207.02295v5 Announce Type: replace 
Abstract: As communication protocols evolve, datacenter network utilization increases. As a result, congestion is more frequent, causing higher latency and packet loss. Combined with the increasing complexity of workloads, manual design of congestion control (CC) algorithms becomes extremely difficult. This calls for the development of AI approaches to replace the human effort. Unfortunately, it is currently not possible to deploy AI models on network devices due to their limited computational capabilities. Here, we offer a solution to this problem by building a computationally-light solution based on a recent reinforcement learning CC algorithm [arXiv:2207.02295]. We reduce the inference time of RL-CC by x500 by distilling its complex neural network into decision trees. This transformation enables real-time inference within the $\mu$-sec decision-time requirement, with a negligible effect on quality. We deploy the transformed policy on NVIDIA NICs in a live cluster. Compared to popular CC algorithms used in production, RL-CC is the only method that performs well on all benchmarks tested over a large range of number of flows. It balances multiple metrics simultaneously: bandwidth, latency, and packet drops. These results suggest that data-driven methods for CC are feasible, challenging the prior belief that handcrafted heuristics are necessary to achieve optimal performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.02295v5</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/CCGrid57682.2023.00039</arxiv:DOI>
      <dc:creator>Benjamin Fuhrer, Yuval Shpigelman, Chen Tessler, Shie Mannor, Gal Chechik, Eitan Zahavi, Gal Dalal</dc:creator>
    </item>
    <item>
      <title>Jasper: Scalable and Fair Multicast for Financial Exchanges in the Cloud</title>
      <link>https://arxiv.org/abs/2402.09527</link>
      <description>arXiv:2402.09527v5 Announce Type: replace 
Abstract: Financial exchanges have recently shown an interest in migrating to the public cloud for scalability, elasticity, and cost savings. However, financial exchanges often have strict network requirements that can be difficult to meet on the cloud. Notably, market participants (MPs) trade based on market data about different activities in the market. Exchanges often use switch multicast to disseminate market data to MPs. However, if one MP receives market data earlier than another, that MP would have an unfair advantage. To prevent this, financial exchanges often equalize exchange-to-MP cable lengths to provide near-simultaneous reception of market data at MPs.
  As a cloud tenant, however, building a fair multicast service is challenging because of the lack of switch support for multicast, high latency variance, and the lack of native mechanisms for simultaneous data delivery in the cloud. Jasper introduces a solution that creates an overlay multicast tree within a cloud region that minimizes latency and latency variations through hedging, leverages recent advancements in clock synchronization to achieve simultaneous delivery, and addresses various sources of latency through an optimized DPDK/eBPF implementation -- while scaling to a thousand receivers. Jasper outperforms a prior system, CloudEx, and a commercial multicast solution provided by Amazon Web Services. We present different deployment models and their performance impact. A deployment model where MPs and the exchange do not have to trust each other is realized using confidential computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09527v5</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Haseeb, Jinkun Geng, Ulysses Butler, Xiyu Hao, Daniel Duclos-Cavalcanti, Anirudh Sivaraman</dc:creator>
    </item>
    <item>
      <title>Sensing Performance of the IEEE 802.11bf Protocol and Its Impact on Data Communication</title>
      <link>https://arxiv.org/abs/2403.19825</link>
      <description>arXiv:2403.19825v2 Announce Type: replace 
Abstract: Wi-Fi sensing has been used to detect and track movements in an environment, resulting in the emergence of several innovative applications. Wi-Fi sensing can detect movement and locate objects by analyzing variations in the Wi-Fi signal due to its interaction with moving objects. Until recently, Wi-Fi sensing has been primarily available through proprietary solutions, which has limited its adoption. However, the recent initiative by the IEEE to develop the IEEE 802.11bf standard promises to make the adoption of Wi-Fi sensing widespread. Although Wi-Fi sensing procedures in communication standards can be overhead, there is currently a lack of literature exploring the sensing performance of Wi-Fi sensing procedures specified in the IEEE 802.11bf standard and its impact on data communication. Therefore, this paper presents a comprehensive evaluation of the sensing performance of the IEEE 802.11bf protocol and its impact on data communication in different configurations. Our findings expose the limitations of specific configurations and pave the way to provide guidance on efficient operating configurations of an IEEE 802.11bf network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19825v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anirudha Sahoo, Tanguy Ropitault, Steve Blandino, Nada Golmie</dc:creator>
    </item>
    <item>
      <title>PACP: Priority-Aware Collaborative Perception for Connected and Autonomous Vehicles</title>
      <link>https://arxiv.org/abs/2404.06891</link>
      <description>arXiv:2404.06891v2 Announce Type: replace 
Abstract: Surrounding perceptions are quintessential for safe driving for connected and autonomous vehicles (CAVs), where the Bird's Eye View has been employed to accurately capture spatial relationships among vehicles. However, severe inherent limitations of BEV, like blind spots, have been identified. Collaborative perception has emerged as an effective solution to overcoming these limitations through data fusion from multiple views of surrounding vehicles. While most existing collaborative perception strategies adopt a fully connected graph predicated on fairness in transmissions, they often neglect the varying importance of individual vehicles due to channel variations and perception redundancy. To address these challenges, we propose a novel Priority-Aware Collaborative Perception (PACP) framework to employ a BEV-match mechanism to determine the priority levels based on the correlation between nearby CAVs and the ego vehicle for perception. By leveraging submodular optimization, we find near-optimal transmission rates, link connectivity, and compression metrics. Moreover, we deploy a deep learning-based adaptive autoencoder to modulate the image reconstruction quality under dynamic channel conditions. Finally, we conduct extensive studies and demonstrate that our scheme significantly outperforms the state-of-the-art schemes by 8.27% and 13.60%, respectively, in terms of utility and precision of the Intersection over Union.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06891v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengru Fang, Senkang Hu, Haonan An, Yuang Zhang, Jingjing Wang, Hangcheng Cao, Xianhao Chen, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>Accelerating Graph Neural Networks via Edge Pruning for Power Allocation in Wireless Networks</title>
      <link>https://arxiv.org/abs/2305.12639</link>
      <description>arXiv:2305.12639v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) have recently emerged as a promising approach to tackling power allocation problems in wireless networks. Since unpaired transmitters and receivers are often spatially distant, the distance-based threshold is proposed to reduce the computation time by excluding or including the channel state information in GNNs. In this paper, we are the first to introduce a neighbour-based threshold approach to GNNs to reduce the time complexity. Furthermore, we conduct a comprehensive analysis of both distance-based and neighbour-based thresholds and provide recommendations for selecting the appropriate value in different communication channel scenarios. We design the corresponding neighbour-based Graph Neural Networks (N-GNN) with the aim of allocating transmit powers to maximise the network throughput. Our results show that our proposed N-GNN offer significant advantages in terms of reducing time complexity while preserving strong performance and generalisation capacity. Besides, we show that by choosing a suitable threshold, the time complexity is reduced from O(|V|^2) to O(|V|), where |V| is the total number of transceiver pairs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12639v2</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/GCWkshps58843.2023.10465155</arxiv:DOI>
      <arxiv:journal_reference>2023 IEEE Globecom Workshops (GC Workshops)</arxiv:journal_reference>
      <dc:creator>Lili Chen, Jingge Zhu, Jamie Evans</dc:creator>
    </item>
    <item>
      <title>How Can We Train Deep Learning Models Across Clouds and Continents? An Experimental Study</title>
      <link>https://arxiv.org/abs/2306.03163</link>
      <description>arXiv:2306.03163v4 Announce Type: replace-cross 
Abstract: This paper aims to answer the question: Can deep learning models be cost-efficiently trained on a global market of spot VMs spanning different data centers and cloud providers? To provide guidance, we extensively evaluate the cost and throughput implications of training in different zones, continents, and clouds for representative CV, NLP, and ASR models. To expand the current training options further, we compare the scalability potential for hybrid-cloud scenarios by adding cloud resources to on-premise hardware to improve training throughput. Finally, we show how leveraging spot instance pricing enables a new cost-efficient way to train models with multiple cheap VMs, trumping both more centralized and powerful hardware and even on-demand cloud offerings at competitive prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.03163v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Erben, Ruben Mayer, Hans-Arno Jacobsen</dc:creator>
    </item>
    <item>
      <title>Goal-oriented Estimation of Multiple Markov Sources in Resource-constrained Systems</title>
      <link>https://arxiv.org/abs/2311.07346</link>
      <description>arXiv:2311.07346v3 Announce Type: replace-cross 
Abstract: This paper investigates goal-oriented communication for remote estimation of multiple Markov sources in resource-constrained networks. An agent decides the updating times of the sources and transmits the packet to a remote destination over an unreliable channel with delay. The destination is tasked with source reconstruction for actuation. We utilize the metric \textit{cost of actuation error} (CAE) to capture the state-dependent actuation costs. We aim for a sampling policy that minimizes the long-term average CAE subject to an average resource constraint. We formulate this problem as an average-cost constrained Markov Decision Process (CMDP) and relax it into an unconstrained problem by utilizing \textit{Lyapunov drift} techniques. Then, we propose a low-complexity \textit{drift-plus-penalty} (DPP) policy for systems with known source/channel statistics and a Lyapunov optimization-based deep reinforcement learning (LO-DRL) policy for unknown environments. Our policies significantly reduce the number of uninformative transmissions by exploiting the timing of the important information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07346v3</guid>
      <category>eess.SY</category>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiping Luo, Nikolaos Pappas</dc:creator>
    </item>
    <item>
      <title>X-CBA: Explainability Aided CatBoosted Anomal-E for Intrusion Detection System</title>
      <link>https://arxiv.org/abs/2402.00839</link>
      <description>arXiv:2402.00839v2 Announce Type: replace-cross 
Abstract: The effectiveness of Intrusion Detection Systems (IDS) is critical in an era where cyber threats are becoming increasingly complex. Machine learning (ML) and deep learning (DL) models provide an efficient and accurate solution for identifying attacks and anomalies in computer networks. However, using ML and DL models in IDS has led to a trust deficit due to their non-transparent decision-making. This transparency gap in IDS research is significant, affecting confidence and accountability. To address, this paper introduces a novel Explainable IDS approach, called X-CBA, that leverages the structural advantages of Graph Neural Networks (GNNs) to effectively process network traffic data, while also adapting a new Explainable AI (XAI) methodology. Unlike most GNN-based IDS that depend on labeled network traffic and node features, thereby overlooking critical packet-level information, our approach leverages a broader range of traffic data through network flows, including edge attributes, to improve detection capabilities and adapt to novel threats. Through empirical testing, we establish that our approach not only achieves high accuracy with 99.47% in threat detection but also advances the field by providing clear, actionable explanations of its analytical outcomes. This research also aims to bridge the current gap and facilitate the broader integration of ML/DL technologies in cybersecurity defenses by offering a local and global explainability solution that is both precise and interpretable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00839v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiymet Kaya, Elif Ak, Sumeyye Bas, Berk Canberk, Sule Gunduz Oguducu</dc:creator>
    </item>
    <item>
      <title>Analysis of Asynchronous Protocols for Entanglement Distribution in Quantum Networks</title>
      <link>https://arxiv.org/abs/2405.02406</link>
      <description>arXiv:2405.02406v2 Announce Type: replace-cross 
Abstract: The distribution of entanglement in quantum networks is typically approached under idealized assumptions such as perfect synchronization and centralized control, while classical communication is often neglected. However, these assumptions prove impractical in large-scale networks. In this paper, we present a pragmatic perspective by exploring two minimal asynchronous protocols: a parallel scheme generating entanglement independently at the link level, and a sequential scheme extending entanglement iteratively from one party to the other. Our analysis incorporates non-uniform repeater spacings and classical communications and accounts for quantum memory decoherence. We evaluate network performance using metrics such as entanglement bit rate, end-to-end fidelity, and secret key rate for entanglement-based quantum key distribution. Our findings suggest the sequential scheme's superiority due to comparable performance with the parallel scheme, coupled with simpler implementation. Additionally, we impose a cutoff strategy to improve performance by discarding attempts with prolonged memory idle time, effectively eliminating low-quality entanglement links. Finally, we apply our methods to the real-world topology of SURFnet and report the performance as a function of memory coherence time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02406v2</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shahrooz Pouryousef, Hassan Shapourian, Don Towsley</dc:creator>
    </item>
    <item>
      <title>Optimizing Information Freshness in IoT Systems with Update Rate Constraints: A Token-Based Approach</title>
      <link>https://arxiv.org/abs/2405.04431</link>
      <description>arXiv:2405.04431v2 Announce Type: replace-cross 
Abstract: In Internet of Things (IoT) status update systems, where information is sampled and subsequently transmitted from a source to a destination node, the imperative necessity lies in maintaining the timeliness of information and updating the system with optimal frequency. Optimizing information freshness in resource-limited status update systems often involves Constrained Markov Decision Process (CMDP) problems with update rate constraints. Solving CMDP problems, especially with multiple constraints, is a challenging task. To address this, we present a token-based approach that transforms CMDP into an unconstrained MDP, simplifying the solution process. We apply this approach to systems with one and two update rate constraints for optimizing Age of Incorrect Information (AoII) and Age of Information (AoI) metrics, respectively, and explore the analytical and numerical aspects. Additionally, we introduce an iterative triangle bisection method for solving the CMDP problems with two constraints, comparing its results with the token-based MDP approach. Our findings show that the token-based approach yields superior performance over baseline policies, converging to the optimal policy as the maximum number of tokens increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04431v2</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erfan Delfani, Nikolaos Pappas</dc:creator>
    </item>
  </channel>
</rss>
