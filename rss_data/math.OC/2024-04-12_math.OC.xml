<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Apr 2024 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Well-posedness for integro-differential sweeping processes of Volterra type</title>
      <link>https://arxiv.org/abs/2404.07279</link>
      <description>arXiv:2404.07279v1 Announce Type: new 
Abstract: In this paper, we study the well-posedness of integro-differential sweeping processes of Volterra type. Using new enhanced versions of Gronwall's inequality, a reparametrization technique, and a fixed point argument for history-dependent operators, we obtain the existence of solutions and provide a fully continuous dependence result for the integro-differential sweeping process. The paper ends with an application to projected dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07279v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilio Vilches</dc:creator>
    </item>
    <item>
      <title>Nash Equilibrium Seeking for Noncooperative Duopoly Games via Event-Triggered Control</title>
      <link>https://arxiv.org/abs/2404.07287</link>
      <description>arXiv:2404.07287v1 Announce Type: new 
Abstract: This paper proposes a novel approach for locally stable convergence to Nash equilibrium in duopoly noncooperative games based on a distributed event-triggered control scheme. The proposed approach employs extremum seeking, with sinusoidal perturbation signals applied to estimate the Gradient (first derivative) of unknown quadratic payoff functions. This is the first instance of noncooperative games being tackled in a model-free fashion integrated with the event-triggered methodology. Each player evaluates independently the deviation between the corresponding current state variable and its last broadcasted value to update the player action, while they preserve control performance under limited bandwidth of the actuation paths and still guarantee stability for the closed-loop dynamics. In particular, the stability analysis is carried out using time-scaling technique, Lyapunov's direct method and averaging theory for discontinuous systems. We quantify the size of the ultimate small residual sets around the Nash equilibrium and illustrate the theoretical results numerically on an example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07287v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor Hugo Pereira Rodrigues, Tiago Roux Oliveira, Miroslav Krsti\'c, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Schr\"odinger's bridges with stopping: Steering of stochastic flows towards spatio-temporal marginals</title>
      <link>https://arxiv.org/abs/2404.07402</link>
      <description>arXiv:2404.07402v1 Announce Type: new 
Abstract: The purpose of the present work is to expand substantially the type of control and estimation problems that can be addressed following the paradigm of Schr\"odinger bridges, by incorporating stopping (freezing) of a given stochastic flow. Specifically, in the context of estimation, we seek the most likely evolution realizing prescribed spatio-temporal marginals of stopped particles. In the context of control, we seek the control action directing the stochastic flow toward spatio-temporal probabilistic constraints. To this end, we derive a new Schr\"odinger system of coupled, in space and time, partial differential equations to construct the solution of the proposed problem. Further, we show that a Fortet-Sinkhorn type of algorithm is, once again, available to attain the associated bridge. A key feature of the framework is that the obtained bridge retains the Markovian structure in the prior process, and thereby, the corresponding control action takes the form of state feedback.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07402v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asmaa Eldesoukey, Olga Movilla Miangolarra, Tryphon T. Georgiou</dc:creator>
    </item>
    <item>
      <title>A Proximal-Gradient Method for Constrained Optimization</title>
      <link>https://arxiv.org/abs/2404.07460</link>
      <description>arXiv:2404.07460v1 Announce Type: new 
Abstract: We present a new algorithm for solving optimization problems with objective functions that are the sum of a smooth function and a (potentially) nonsmooth regularization function, and nonlinear equality constraints. The algorithm may be viewed as an extension of the well-known proximal-gradient method that is applicable when constraints are not present. To account for nonlinear equality constraints, we combine a decomposition procedure for computing trial steps with an exact merit function for determining trial step acceptance. Under common assumptions, we show that both the proximal parameter and merit function parameter eventually remain fixed, and then prove a worst-case complexity result for the maximum number of iterations before an iterate satisfying approximate first-order optimality conditions for a given tolerance is computed. Our preliminary numerical results indicate that our approach has great promise, especially in terms of returning approximate solutions that are structured (e.g., sparse solutions when a one-norm regularizer is used).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07460v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yutong Dai, Xiaoyi Qu, Daniel P. Robinson</dc:creator>
    </item>
    <item>
      <title>A continuous-time violation-free multi-agent optimization algorithm and its applications to safe distributed control</title>
      <link>https://arxiv.org/abs/2404.07571</link>
      <description>arXiv:2404.07571v1 Announce Type: new 
Abstract: In this work, we propose a continuous-time distributed optimization algorithm with guaranteed zero coupling constraint violation and apply it to safe distributed control in the presence of multiple control barrier functions (CBF). The optimization problem is defined over a network that collectively minimizes a separable cost function with coupled linear constraints. An equivalent optimization problem with auxiliary decision variables and a decoupling structure is proposed. A sensitivity analysis demonstrates that the subgradient information can be computed using local information. This then leads to a subgradient algorithm for updating the auxiliary variables. A case with sparse coupling constraints is further considered, and it is shown to have better memory and communication efficiency. For the specific case of a CBF-induced time-varying quadratic program (QP), an update law is proposed that achieves finite-time convergence. Numerical results involving a static resource allocation problem and a safe coordination problem for a multi-agent system demonstrate the efficiency and effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07571v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiao Tan, Changxin Liu, Karl H. Johansson, Dimos V. Dimarogonas</dc:creator>
    </item>
    <item>
      <title>Achieving violation-free distributed optimization under coupling constraints</title>
      <link>https://arxiv.org/abs/2404.07609</link>
      <description>arXiv:2404.07609v1 Announce Type: new 
Abstract: Constraint satisfaction is a critical component in a wide range of engineering applications, including but not limited to safe multi-agent control and economic dispatch in power systems. This study explores violation-free distributed optimization techniques for problems characterized by separable objective functions and coupling constraints. First, we incorporate auxiliary decision variables together with a network-dependent linear mapping to each coupling constraint. For the reformulated problem, we show that the projection of its feasible set onto the space of primal variables is identical to that of the original problem, which is the key to achieving all-time constraint satisfaction. Upon treating the reformulated problem as a min-min optimization problem with respect to auxiliary and primal variables, we demonstrate that the gradients in the outer minimization problem have a locally computable closed-form. Then, two violation-free distributed optimization algorithms are developed and their convergence under reasonable assumptions is analyzed. Finally, the proposed algorithm is applied to implement a control barrier function based controller in a distributed manner, and the results verify its effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07609v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changxin Liu, Xiao Tan, Xuyang Wu, Dimos V. Dimarogonas, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Optimal State Equation for the Control of a Diffusion with Two Distinct Dynamics</title>
      <link>https://arxiv.org/abs/2404.07618</link>
      <description>arXiv:2404.07618v1 Announce Type: new 
Abstract: We consider a class of stochastic control problems which has been widely used in optimal foraging theory. The state processes have two distinct dynamics, characterized by two pairs of drift and diffusion coefficients, depending on whether it takes values bigger or smaller than a threshold value. Adopting a perturbation type approach, we find an expression for potential measure of the optimal state process. We then obtain an expression for the transition density of the optimal state process by inverting the associated Laplace transform. Properties including the stationary distribution of the optimal state process are discussed. Finally, the expression of the value function is given for this class stochastic control problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07618v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Zengjing Chen, Panyu Wu, Xiaowen Zhou</dc:creator>
    </item>
    <item>
      <title>Scenario Reduction with Guarantees for Stochastic Optimal Control of Linear Systems</title>
      <link>https://arxiv.org/abs/2404.07746</link>
      <description>arXiv:2404.07746v1 Announce Type: new 
Abstract: Scenario reduction algorithms can be an effective means to provide a tractable description of the uncertainty in optimal control problems. However, they might significantly compromise the performance of the controlled system. In this paper, we propose a method to compensate for the effect of scenario reduction on stochastic optimal control problems for chance-constrained linear systems with additive uncertainty. We consider a setting in which the uncertainty has a discrete distribution, where the number of possible realizations is large. We then propose a reduction algorithm with a problem-dependent loss function, and we define sufficient conditions on the stochastic optimal control problem to ensure out-of-sample guarantees (i.e., against the original distribution of the uncertainty) for the controlled system in terms of performance and chance constraint satisfaction. Finally, we demonstrate the effectiveness of the approach on a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07746v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Cordiano, Bart De Schutter</dc:creator>
    </item>
    <item>
      <title>Problem-Driven Scenario Reduction Framework for Power System Stochastic Operation</title>
      <link>https://arxiv.org/abs/2404.07810</link>
      <description>arXiv:2404.07810v1 Announce Type: new 
Abstract: Scenario reduction (SR) aims to identify a small yet representative scenario set to depict the underlying uncertainty, which is critical to scenario-based stochastic optimization (SBSO) of power systems. Existing SR techniques commonly aim to achieve statistical approximation to the original scenario set. However, SR and SBSO are commonly considered into two distinct and decoupled processes, which cannot guarantee a superior approximation of the original optimality. Instead, this paper incorporates the SBSO problem structure into the SR process and introduces a novel problem-driven scenario reduction framework. Specifically, we transform the original scenario set in distribution space into the decision applicability between scenarios in problem space. Subsequently, the SR process, embedded by a distinctive problem-driven distance metric, is rendered as a mixed-integer linear programming formulation to obtain the representative scenario set while minimizing the optimality gap. Furthermore, ex-ante and ex-post problem-driven evaluation indices are proposed to evaluate the performance of SR. A two-stage stochastic economic dispatch problem with renewable generation and energy storage validates the effectiveness of the proposed framework. Numerical experiments demonstrate that the proposed framework significantly outperforms existing SR methods by identifying salient (e.g., worst-case) scenarios, and achieving an optimality gap of less than 0.1% within acceptable computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07810v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yingrui Zhuang, Lin Cheng, Ning Qi, Mads R. Almassalkhi, Feng Liu</dc:creator>
    </item>
    <item>
      <title>Flexible-step MPC for Switched Linear Systems with No Quadratic Common Lyapunov Function</title>
      <link>https://arxiv.org/abs/2404.07870</link>
      <description>arXiv:2404.07870v1 Announce Type: new 
Abstract: In this paper, we develop a systematic method for constructing a generalized discrete-time control Lyapunov function for the flexible-step Model Predictive Control (MPC) scheme, recently introduced in [3], when restricted to the class of linear systems. Specifically, we show that a set of Linear Matrix Inequalities (LMIs) can be used for this purpose, demonstrating its tractability. The main consequence of this LMI formulation is that, when combined with flexible-step MPC, we can effectively stabilize switched control systems, for which no quadratic common Lyapunov function exists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07870v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annika F\"urnsinn, Christian Ebenbauer, Bahman Gharesifard</dc:creator>
    </item>
    <item>
      <title>Data-driven methods for quantitative imaging</title>
      <link>https://arxiv.org/abs/2404.07886</link>
      <description>arXiv:2404.07886v1 Announce Type: new 
Abstract: In the field of quantitative imaging, the image information at a pixel or voxel in an underlying domain entails crucial information about the imaged matter. This is particularly important in medical imaging applications, such as quantitative Magnetic Resonance Imaging (qMRI), where quantitative maps of biophysical parameters can characterize the imaged tissue and thus lead to more accurate diagnoses. Such quantitative values can also be useful in subsequent, automatized classification tasks in order to discriminate normal from abnormal tissue, for instance. The accurate reconstruction of these quantitative maps is typically achieved by solving two coupled inverse problems which involve a (forward) measurement operator, typically ill-posed, and a physical process that links the wanted quantitative parameters to the reconstructed qualitative image, given some underlying measurement data. In this review, by considering qMRI as a prototypical application, we provide a mathematically-oriented overview on how data-driven approaches can be employed in these inverse problems eventually improving the reconstruction of the associated quantitative maps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07886v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guozhi Dong, Moritz Flaschel, Michael Hinterm\"uller, Kostas Papafitsoros, Clemens Sirotenko, Karsten Tabelow</dc:creator>
    </item>
    <item>
      <title>Optimal Control for Linear Systems with $L^1$-norm Cost</title>
      <link>https://arxiv.org/abs/2404.07913</link>
      <description>arXiv:2404.07913v1 Announce Type: new 
Abstract: We study $L^1$-optimal stabilization of linear systems with finite and infinite horizons. Main results concern the existence, uniqueness and structure of optimal solutions, and the robustness of optimal cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07913v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrei Agrachev, Bettina Kazandjian</dc:creator>
    </item>
    <item>
      <title>Existence of Optimal Stationary Singular Controls and Mean Field Game Equilibria</title>
      <link>https://arxiv.org/abs/2404.07945</link>
      <description>arXiv:2404.07945v1 Announce Type: new 
Abstract: In this paper, we examine the stationary relaxed singular control problem within a multi-dimensional framework for a single agent, as well as its Mean Field Game (MFG) equivalent. We demonstrate that optimal relaxed controls exist for both maximization and minimization cases. These relaxed controls are defined by random measures across the state and control spaces, with the state process described as a solution to the associated martingale problem. By leveraging findings from [Kurtz-Stockbridge 2001], we establish the equivalence between the martingale problem and the stationary forward equation. This allows us to reformulate the relaxed control problem into a linear programming problem within the measure space. We prove the sequential compactness of these measures, thereby confirming the feasibility of achieving an optimal solution. Subsequently, our focus shifts to Mean Field Games. Drawing on insights from the single-agent problem and employing Kakutani--Glicksberg--Fan fixed point theorem, we derive the existence of a mean field game equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07945v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Cohen, Chuhao Sun</dc:creator>
    </item>
    <item>
      <title>Closed-Loop Model Identification and MPC-based Navigation of Quadcopters: A Case Study of Parrot Bebop 2</title>
      <link>https://arxiv.org/abs/2404.07267</link>
      <description>arXiv:2404.07267v1 Announce Type: cross 
Abstract: The growing potential of quadcopters in various domains, such as aerial photography, search and rescue, and infrastructure inspection, underscores the need for real-time control under strict safety and operational constraints. This challenge is compounded by the inherent nonlinear dynamics of quadcopters and the on-board computational limitations they face. This paper aims at addressing these challenges. First, this paper presents a comprehensive procedure for deriving a linear yet efficient model to describe the dynamics of quadrotors, thereby reducing complexity without compromising efficiency. Then, this paper develops a steady-state-aware Model Predictive Control (MPC) to effectively navigate quadcopters, while guaranteeing constraint satisfaction at all times. The main advantage of the steady-state-aware MPC is its low computational complexity, which makes it an appropriate choice for systems with limited computing capacity, like quadcopters. This paper considers Parrot Bebop 2 as the running example, and experimentally validates and evaluates the proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07267v1</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohsen Amiri, Mehdi Hosseinzadeh</dc:creator>
    </item>
    <item>
      <title>Gradient Networks</title>
      <link>https://arxiv.org/abs/2404.07361</link>
      <description>arXiv:2404.07361v1 Announce Type: cross 
Abstract: Directly parameterizing and learning gradients of functions has widespread significance, with specific applications in optimization, generative modeling, and optimal transport. This paper introduces gradient networks (GradNets): novel neural network architectures that parameterize gradients of various function classes. GradNets exhibit specialized architectural constraints that ensure correspondence to gradient functions. We provide a comprehensive GradNet design framework that includes methods for transforming GradNets into monotone gradient networks (mGradNets), which are guaranteed to represent gradients of convex functions. We establish the approximation capabilities of the proposed GradNet and mGradNet. Our results demonstrate that these networks universally approximate the gradients of (convex) functions. Furthermore, these networks can be customized to correspond to specific spaces of (monotone) gradient functions, including gradients of transformed sums of (convex) ridge functions. Our analysis leads to two distinct GradNet architectures, GradNet-C and GradNet-M, and we describe the corresponding monotone versions, mGradNet-C and mGradNet-M. Our empirical results show that these architectures offer efficient parameterizations and outperform popular methods in gradient field learning tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07361v1</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shreyas Chaudhari, Srinivasa Pranav, Jos\'e M. F. Moura</dc:creator>
    </item>
    <item>
      <title>Data-Driven Portfolio Management for Motion Pictures Industry: A New Data-Driven Optimization Methodology Using a Large Language Model as the Expert</title>
      <link>https://arxiv.org/abs/2404.07434</link>
      <description>arXiv:2404.07434v1 Announce Type: cross 
Abstract: Portfolio management is one of the unresponded problems of the Motion Pictures Industry (MPI). To design an optimal portfolio for an MPI distributor, it is essential to predict the box office of each project. Moreover, for an accurate box office prediction, it is critical to consider the effect of the celebrities involved in each MPI project, which was impossible with any precedent expert-based method. Additionally, the asymmetric characteristic of MPI data decreases the performance of any predictive algorithm. In this paper, firstly, the fame score of the celebrities is determined using a large language model. Then, to tackle the asymmetric character of MPI's data, projects are classified. Furthermore, the box office prediction takes place for each class of projects. Finally, using a hybrid multi-attribute decision-making technique, the preferability of each project for the distributor is calculated, and benefiting from a bi-objective optimization model, the optimal portfolio is designed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07434v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Alipour-Vaezi, Kwok-Leung Tsui</dc:creator>
    </item>
    <item>
      <title>Safe subspace screening for the adaptive nuclear norm regularized trace regression</title>
      <link>https://arxiv.org/abs/2404.07459</link>
      <description>arXiv:2404.07459v1 Announce Type: cross 
Abstract: Matrix form data sets arise in many areas, so there are lots of works about the matrix regression models. One special model of these models is the adaptive nuclear norm regularized trace regression, which has been proven have good statistical performances. In order to accelerate the computation of this model, we consider the technique called screening rule. According to matrix decomposition and optimal condition of the model, we develop a safe subspace screening rule that can be used to identify inactive subspace of the solution decomposition and reduce the dimension of the solution. To evaluate the efficiency of the safe subspace screening rule, we embed this result into the alternating direction method of multipliers algorithm under a sequence of the tuning parameters. Under this process, each solution under the tuning parameter provides a matrix decomposition space. Then, the safe subspace screening rule is applied to eliminate inactive subspace, reduce the solution dimension and accelerate the computation process. Some numerical experiments are implemented on simulation data sets and real data sets, which illustrate the efficiency of our screening rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07459v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pan Shang, Lingchen Kong</dc:creator>
    </item>
    <item>
      <title>Control of the Schr\"{o}dinger equation in $\mathbb{R}^3$: The critical case</title>
      <link>https://arxiv.org/abs/2404.07749</link>
      <description>arXiv:2404.07749v1 Announce Type: cross 
Abstract: This article deals with the $\dot{H}^{1}$--level exact controllability for the defocusing critical nonlinear Schr\"{o}dinger equation in $\mathbb{R}^3$. Firstly, we show the problem under consideration to be well-posed using Strichartz estimates. Moreover, through the Hilbert uniqueness method, we prove the linear Schr\"{o}dinger equation to be controllable. Finally, we use a perturbation argument and show local exact controllability for the critical nonlinear Schr\"{o}dinger equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07749v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Pablo Braz e Silva (UFPE), Roberto de A. Capistrano-Filho (UFPE), Jackellyny Dassy do Nascimento Carvalho (UFPE), David dos Santos Ferreira (IELC)</dc:creator>
    </item>
    <item>
      <title>A Novel Optimization-Based Collision Avoidance For Autonomous On-Orbit Assembly</title>
      <link>https://arxiv.org/abs/2404.07916</link>
      <description>arXiv:2404.07916v1 Announce Type: cross 
Abstract: The collision avoidance constraints are prominent as non-convex, non-differentiable, and challenging when defined in optimization-based motion planning problems. To overcome these issues, this paper presents a novel non-conservative collision avoidance technique using the notion of convex optimization to establish the distance between robotic spacecraft and space structures for autonomous on-orbit assembly operations. The proposed technique defines each ellipsoidal- and polyhedral-shaped object as the union of convex compact sets, each represented non-conservatively by a real-valued convex function. Then, the functions are introduced as a set of constraints to a convex optimization problem to produce a new set of differentiable constraints resulting from the optimality conditions. These new constraints are later fed into an optimal control problem to enforce collision avoidance where the motion planning for the autonomous on-orbit assembly takes place. Numerical experiments for two assembly scenarios in tight environments are presented to demonstrate the capability and effectiveness of the proposed technique. The results show that this framework leads to optimal non-conservative trajectories for robotic spacecraft in tight environments. Although developed for autonomous on-orbit assembly, this technique could be used for any generic motion planning problem where collision avoidance is crucial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07916v1</guid>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siavash Tavana, Sepideh Faghihi, Anton de Ruiter, Krishna Dev Kumar</dc:creator>
    </item>
    <item>
      <title>Lyapunov-stable Neural Control for State and Output Feedback: A Novel Formulation for Efficient Synthesis and Verification</title>
      <link>https://arxiv.org/abs/2404.07956</link>
      <description>arXiv:2404.07956v1 Announce Type: cross 
Abstract: Learning-based neural network (NN) control policies have shown impressive empirical performance in a wide range of tasks in robotics and control. However, formal (Lyapunov) stability guarantees over the region-of-attraction (ROA) for NN controllers with nonlinear dynamical systems are challenging to obtain, and most existing approaches rely on expensive solvers such as sums-of-squares (SOS), mixed-integer programming (MIP), or satisfiability modulo theories (SMT). In this paper, we demonstrate a new framework for learning NN controllers together with Lyapunov certificates using fast empirical falsification and strategic regularizations. We propose a novel formulation that defines a larger verifiable region-of-attraction (ROA) than shown in the literature, and refines the conventional restrictive constraints on Lyapunov derivatives to focus only on certifiable ROAs. The Lyapunov condition is rigorously verified post-hoc using branch-and-bound with scalable linear bound propagation-based NN verification techniques. The approach is efficient and flexible, and the full training and verification procedure is accelerated on GPUs without relying on expensive solvers for SOS, MIP, nor SMT. The flexibility and efficiency of our framework allow us to demonstrate Lyapunov-stable output feedback control with synthesized NN-based controllers and NN-based observers with formal stability guarantees, for the first time in literature. Source code at https://github.com/Verified-Intelligence/Lyapunov_Stable_NN_Controllers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.07956v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lujie Yang, Hongkai Dai, Zhouxing Shi, Cho-Jui Hsieh, Russ Tedrake, Huan Zhang</dc:creator>
    </item>
    <item>
      <title>Aerial Base Station Placement via Propagation Radio Maps</title>
      <link>https://arxiv.org/abs/2301.04966</link>
      <description>arXiv:2301.04966v5 Announce Type: replace 
Abstract: The deployment of aerial base stations (ABSs) on unmanned aerial vehicles (UAVs) presents a promising solution for extending cellular connectivity to areas where terrestrial infrastructure is overloaded, damaged, or absent. A pivotal challenge in this domain is to decide the locations of a set of ABSs to effectively serve ground-based users. Most existing approaches oversimplify this problem by assuming that the channel gain between two points is a function of solely distance and, sometimes, also the elevation angle. In turn, this paper leverages propagation radio maps to account for arbitrary air-to-ground channel gains. This methodology enables the identification of an approximately minimal set of locations where ABSs need to be deployed to ensure that all ground terminals achieve a target service rate, while adhering to backhaul capacity limitations and avoiding designated no-fly zones. Relying on a convex relaxation technique and the alternating direction method of multipliers (ADMM), this paper puts forth a solver whose computational complexity scales linearly with the number of ground terminals. Convergence is established analytically and an extensive set of simulations corroborate the merits of the proposed scheme relative to conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.04966v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Romero, Pham Q. Viet, Raju Shrestha</dc:creator>
    </item>
    <item>
      <title>Regularized methods via cubic model subspace minimization for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2306.14290</link>
      <description>arXiv:2306.14290v3 Announce Type: replace 
Abstract: Adaptive cubic regularization methods for solving nonconvex problems need the efficient computation of the trial step, involving the minimization of a cubic model. We propose a new approach in which this model is minimized in a low dimensional subspace that, in contrast to classic approaches, is reused for a number of iterations. Whenever the trial step produced by the low-dimensional minimization process is unsatisfactory, we employ a regularized Newton step whose regularization parameter is a by-product of the model minimization over the low-dimensional subspace. We show that the worst-case complexity of classic cubic regularized methods is preserved, despite the possible regularized Newton steps. We focus on the large class of problems for which (sparse) direct linear system solvers are available and provide several experimental results showing the very large gains of our new approach when compared to standard implementations of adaptive cubic regularization methods based on direct linear solvers. Our first choice as projection space for the low-dimensional model minimization is the polynomial Krylov subspace; nonetheless, we also explore the use of rational Krylov subspaces in case where the polynomial ones lead to less competitive numerical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14290v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefania Bellavia, Davide Palitta, Margherita Porcelli, Valeria Simoncini</dc:creator>
    </item>
    <item>
      <title>Global convergence of a BFGS-type algorithm for nonconvex multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2307.08429</link>
      <description>arXiv:2307.08429v2 Announce Type: replace 
Abstract: We propose a modified BFGS algorithm for multiobjective optimization problems with global convergence, even in the absence of convexity assumptions on the objective functions. Furthermore, we establish the superlinear convergence of the method under usual conditions. Our approach employs Wolfe step sizes and ensures that the Hessian approximations are updated and corrected at each iteration to address the lack of convexity assumption. Numerical results shows that the introduced modifications preserve the practical efficiency of the BFGS method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.08429v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10589-024-00571-x</arxiv:DOI>
      <dc:creator>L. F. Prudente, D. R. Souza</dc:creator>
    </item>
    <item>
      <title>An adaptively inexact first-order method for bilevel optimization with application to hyperparameter learning</title>
      <link>https://arxiv.org/abs/2308.10098</link>
      <description>arXiv:2308.10098v2 Announce Type: replace 
Abstract: Various tasks in data science are modeled utilizing the variational regularization approach, where manually selecting regularization parameters presents a challenge. The difficulty gets exacerbated when employing regularizers involving a large number of hyperparameters. To overcome this challenge, bilevel learning can be employed to learn such parameters from data. However, neither exact function values nor exact gradients with respect to the hyperparameters are attainable, necessitating methods that only rely on inexact evaluation of such quantities. State-of-the-art inexact gradient-based methods a priori select a sequence of the required accuracies and cannot identify an appropriate step size since the Lipschitz constant of the hypergradient is unknown. In this work, we propose an algorithm with backtracking line search that only relies on inexact function evaluations and hypergradients and show convergence to a stationary point. Furthermore, the proposed algorithm determines the required accuracy dynamically rather than manually selected before running it. Our numerical experiments demonstrate the efficiency and feasibility of our approach for hyperparameter estimation on a range of relevant problems in imaging and data science such as total variation and field of experts denoising and multinomial logistic regression. Particularly, the results show that the algorithm is robust to its own hyperparameters such as the initial accuracies and step size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.10098v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Sadegh Salehi, Subhadip Mukherjee, Lindon Roberts, Matthias J. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>Lagrangian Relaxation for Continuous-Time Optimal Control of Coupled Hydrothermal Power Systems Including Storage Capacity and a Cascade of Hydropower Systems with Time Delays</title>
      <link>https://arxiv.org/abs/2311.00794</link>
      <description>arXiv:2311.00794v2 Announce Type: replace 
Abstract: This work considers a short-term, continuous time setting characterized by a coupled power supply system controlled exclusively by a single provider and comprising a cascade of hydropower systems (dams), fossil fuel power stations, and a storage capacity modeled by a single large battery. Cascaded hydropower generators introduce time-delay effects in the state dynamics, which are modeled with differential equations, making it impossible to use classical dynamic programming. We address this issue by introducing a novel Lagrangian relaxation technique over continuous-time constraints, constructing a nearly optimal policy efficiently. This approach yields a convex, nonsmooth optimization dual problem to recover the optimal Lagrangian multipliers, which is numerically solved using a limited memory bundle method. At each step of the dual optimization, we need to solve an optimization subproblem. Given the current values of the Lagrangian multipliers, the time delays are no longer active, and we can solve a corresponding nonlinear Hamilton--Jacobi--Bellman (HJB) Partial Differential Equation (PDE) for the optimization subproblem. The HJB PDE solver provides both the current value of the dual function and its subgradient, and is trivially parallelizable over the state space for each time step. To handle the infinite-dimensional nature of the Lagrange multipliers, we design an adaptive refinement strategy to control the duality gap. Furthermore, we use a penalization technique for the constructed admissible primal solution to smooth the controls while achieving a sufficiently small duality gap. Numerical results based on the Uruguayan power system demonstrate the efficiency of the proposed mathematical models and numerical approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00794v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiheb Ben Hammouda, Eliza Rezvanova, Erik von Schwerin, Ra\'ul Tempone</dc:creator>
    </item>
    <item>
      <title>Ex Post Conditions for the Exactness of Optimal Power Flow Conic Relaxations</title>
      <link>https://arxiv.org/abs/2311.07781</link>
      <description>arXiv:2311.07781v2 Announce Type: replace 
Abstract: Convex relaxations of the optimal power flow (OPF) problem provide an efficient alternative to solving the intractable alternating current (AC) optimal power flow. The conic subset of OPF convex relaxations, in particular, greatly accelerate resolution while leading to high-quality approximations that are exact in several scenarios. However, the sufficient conditions guaranteeing exactness are stringent, e.g., requiring radial topologies. In this short communication, we present two equivalent ex post conditions for the exactness of any conic relaxation of the OPF. These rely on obtaining either a rank-1 voltage matrix or self-coherent cycles. Instead of relying on sufficient conditions a priori, satisfying one of the presented ex post conditions acts as an exactness certificate for the computed solution. The operator can therefore obtain an optimality guarantee when solving a conic relaxation even when a priori exactness requirements are not met. Finally, we present numerical examples from the MATPOWER library where the ex post conditions hold even though the exactness sufficient conditions do not, thereby illustrating the use of the conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07781v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jean-Luc Lupien, Antoine Lesage-Landry</dc:creator>
    </item>
    <item>
      <title>On the $O(\frac{\sqrt{d}}{T^{1/4}})$ Convergence Rate of RMSProp and Its Momentum Extension Measured by $\ell_1$ Norm</title>
      <link>https://arxiv.org/abs/2402.00389</link>
      <description>arXiv:2402.00389v2 Announce Type: replace 
Abstract: Although adaptive gradient methods have been extensively used in deep learning, their convergence rates proved in the literature are all slower than that of SGD, particularly with respect to their dependence on the dimension. This paper considers the classical RMSProp and its momentum extension and establishes the convergence rate of $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_1\right]\leq O(\frac{\sqrt{d}C}{T^{1/4}})$ measured by $\ell_1$ norm without the bounded gradient assumption, where $d$ is the dimension of the optimization variable, $T$ is the iteration number, and $C$ is a constant identical to that appeared in the optimal convergence rate of SGD. Our convergence rate matches the lower bound with respect to all the coefficients except the dimension $d$. Since $\|x\|_2\ll\|x\|_1\leq\sqrt{d}\|x\|_2$ for problems with extremely large $d$, our convergence rate can be considered to be analogous to the $\frac{1}{T}\sum_{k=1}^T E\left[\|\nabla f(x^k)\|_2\right]\leq O(\frac{C}{T^{1/4}})$ rate of SGD in the ideal case of $\|\nabla f(x)\|_1=\varTheta(\sqrt{d}\|\nabla f(x)\|_2)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00389v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huan Li, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>Tight error bounds for log-determinant cones without constraint qualifications</title>
      <link>https://arxiv.org/abs/2403.07295</link>
      <description>arXiv:2403.07295v2 Announce Type: replace 
Abstract: In this paper, without requiring any constraint qualifications, we establish tight error bounds for the log-determinant cone, which is the closure of the hypograph of the perspective function of the log-determinant function. This error bound is obtained using the recently developed framework based on one-step facial residual functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07295v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Lin, Scott B. Lindstrom, Bruno F. Louren\c{c}o, Ting Kei Pong</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Traveling Purchaser Problems</title>
      <link>https://arxiv.org/abs/2404.02476</link>
      <description>arXiv:2404.02476v2 Announce Type: replace 
Abstract: The traveling purchaser problem (TPP) is an important combinatorial optimization problem with broad applications. Due to the coupling between routing and purchasing, existing works on TPPs commonly address route construction and purchase planning simultaneously, which, however, leads to exact methods with high computational cost and heuristics with sophisticated design but limited performance. In sharp contrast, we propose a novel approach based on deep reinforcement learning (DRL), which addresses route construction and purchase planning separately, while evaluating and optimizing the solution from a global perspective. The key components of our approach include a bipartite graph representation for TPPs to capture the market-product relations, and a policy network that extracts information from the bipartite graph and uses it to sequentially construct the route. One significant benefit of our framework is that we can efficiently construct the route using the policy network, and once the route is determined, the associated purchasing plan can be easily derived through linear programming, while, leveraging DRL, we can train the policy network to optimize the global solution objective. Furthermore, by introducing a meta-learning strategy, the policy network can be trained stably on large-sized TPP instances, and generalize well across instances of varying sizes and distributions, even to much larger instances that are never seen during training. Experiments on various synthetic TPP instances and the TPPLIB benchmark demonstrate that our DRL-based approach can significantly outperform well-established TPP heuristics, reducing the optimality gap by 40%-90%, and also showing an advantage in runtime, especially on large-sized instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02476v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haofeng Yuan, Rongping Zhu, Wanlu Yang, Shiji Song, Keyou You, Yuli Zhang</dc:creator>
    </item>
    <item>
      <title>Elementary Analysis of Policy Gradient Methods</title>
      <link>https://arxiv.org/abs/2404.03372</link>
      <description>arXiv:2404.03372v2 Announce Type: replace 
Abstract: Projected policy gradient under the simplex parameterization, policy gradient and natural policy gradient under the softmax parameterization, are fundamental algorithms in reinforcement learning. There have been a flurry of recent activities in studying these algorithms from the theoretical aspect. Despite this, their convergence behavior is still not fully understood, even given the access to exact policy evaluations. In this paper, we focus on the discounted MDP setting and conduct a systematic study of the aforementioned policy optimization methods. Several novel results are presented, including 1) global linear convergence of projected policy gradient for any constant step size, 2) sublinear convergence of softmax policy gradient for any constant step size, 3) global linear convergence of softmax natural policy gradient for any constant step size, 4) global linear convergence of entropy regularized softmax policy gradient for a wider range of constant step sizes than existing result, 5) tight local linear convergence rate of entropy regularized natural policy gradient, and 6) a new and concise local quadratic convergence rate of soft policy iteration without the assumption on the stationary distribution under the optimal policy. New and elementary analysis techniques have been developed to establish these results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03372v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiacai Liu, Wenye Li, Ke Wei</dc:creator>
    </item>
    <item>
      <title>The turnpike property for high-dimensional interacting agent systems in discrete time</title>
      <link>https://arxiv.org/abs/2404.06134</link>
      <description>arXiv:2404.06134v2 Announce Type: replace 
Abstract: We investigate the interior turnpike phenomenon for discrete-time multi-agent optimal control problems. While for continuous systems the turnpike property has been established, we focus here on first-order discretizations of such systems. It is shown that the resulting time-discrete system inherits the turnpike property with estimates of the same type as in the continuous case. In particular, we prove that the discrete time optimal control problem is strictly dissipative and the cheap control assumption holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06134v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Gugat, Michael Herty, Jiehong Liu, Chiara Segala</dc:creator>
    </item>
    <item>
      <title>Peak Time-Windowed Risk Estimation of Stochastic Processes</title>
      <link>https://arxiv.org/abs/2404.06961</link>
      <description>arXiv:2404.06961v2 Announce Type: replace 
Abstract: This paper develops a method to upper-bound extreme-values of time-windowed risks for stochastic processes. Examples of such risks include the maximum average or 90% quantile of the current along a transmission line in any 5-minute window. This work casts the time-windowed risk analysis problem as an infinite-dimensional linear program in occupation measures. In particular, we employ the coherent risk measures of the mean and the expected shortfall (conditional value at risk) to define the maximal time-windowed risk along trajectories. The infinite-dimensional linear program must then be truncated into finite-dimensional optimization problems, such as by using the moment-sum of squares hierarchy of semidefinite programs. The infinite-dimensional linear program will have the same optimal value as the original nonconvex risk estimation task under compactness and regularity assumptions, and the sequence of semidefinite programs will converge to the true value under additional properties of algebraic characterization. The scheme is demonstrated for risk analysis of example stochastic processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06961v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Niklas Schmid, Matteo Tacchi, Didier Henrion, Roy S. Smith</dc:creator>
    </item>
    <item>
      <title>Demystifying Why Local Aggregation Helps: Convergence Analysis of Hierarchical SGD</title>
      <link>https://arxiv.org/abs/2010.12998</link>
      <description>arXiv:2010.12998v4 Announce Type: replace-cross 
Abstract: Hierarchical SGD (H-SGD) has emerged as a new distributed SGD algorithm for multi-level communication networks. In H-SGD, before each global aggregation, workers send their updated local models to local servers for aggregations. Despite recent research efforts, the effect of local aggregation on global convergence still lacks theoretical understanding. In this work, we first introduce a new notion of "upward" and "downward" divergences. We then use it to conduct a novel analysis to obtain a worst-case convergence upper bound for two-level H-SGD with non-IID data, non-convex objective function, and stochastic gradient. By extending this result to the case with random grouping, we observe that this convergence upper bound of H-SGD is between the upper bounds of two single-level local SGD settings, with the number of local iterations equal to the local and global update periods in H-SGD, respectively. We refer to this as the "sandwich behavior". Furthermore, we extend our analytical approach based on "upward" and "downward" divergences to study the convergence for the general case of H-SGD with more than two levels, where the "sandwich behavior" still holds. Our theoretical results provide key insights of why local aggregation can be beneficial in improving the convergence of H-SGD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2010.12998v4</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiayi Wang, Shiqiang Wang, Rong-Rong Chen, Mingyue Ji</dc:creator>
    </item>
    <item>
      <title>Neural Hilbert Ladders: Multi-Layer Neural Networks in Function Space</title>
      <link>https://arxiv.org/abs/2307.01177</link>
      <description>arXiv:2307.01177v2 Announce Type: replace-cross 
Abstract: To characterize the function space explored by neural networks (NNs) is an important aspect of learning theory. In this work, noticing that a multi-layer NN generates implicitly a hierarchy of reproducing kernel Hilbert spaces (RKHSs) - named a neural Hilbert ladder (NHL) - we define the function space as an infinite union of RKHSs, which generalizes the existing Barron space theory of two-layer NNs. We then establish several theoretical properties of the new space. First, we prove a correspondence between functions expressed by L-layer NNs and those belonging to L-level NHLs. Second, we prove generalization guarantees for learning an NHL with a controlled complexity measure. Third, we derive a non-Markovian dynamics of random fields that governs the evolution of the NHL which is induced by the training of multi-layer NNs in an infinite-width mean-field limit. Fourth, we show examples of depth separation in NHLs under the ReLU activation function. Finally, we perform numerical experiments to illustrate the feature learning aspect of NN training through the lens of NHLs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.01177v2</guid>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Journal of Machine Learning Research, 25(109):1-65, 2024</arxiv:journal_reference>
      <dc:creator>Zhengdao Chen</dc:creator>
    </item>
    <item>
      <title>TOPPQuad: Dynamically-Feasible Time Optimal Path Parametrization for Quadrotors</title>
      <link>https://arxiv.org/abs/2309.11637</link>
      <description>arXiv:2309.11637v2 Announce Type: replace-cross 
Abstract: Planning time-optimal trajectories for quadrotors in cluttered environments is a challenging, non-convex problem. This paper addresses minimizing the traversal time of a given collision-free geometric path without violating bounds on individual motor thrusts of the vehicle. Previous approaches have either relied on convex relaxations that do not guarantee dynamic feasibility, or have generated overly conservative time parametrizations. We propose TOPPQuad, a time-optimal path parameterization algorithm for quadrotors which explicitly incorporates quadrotor rigid body dynamics and constraints such as bounds on inputs (including motor speeds) and state of the vehicle (including the pose, linear and angular velocity and acceleration). We demonstrate the ability of the planner to generate faster trajectories that respect hardware constraints of the robot compared to several planners with relaxed notions of dynamic feasibility. We also demonstrate how TOPPQuad can be used to plan trajectories for quadrotors that utilize bidirectional motors. Overall, the proposed approach paves a way towards maximizing the efficacy of autonomous micro aerial vehicles while ensuring their safety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11637v2</guid>
      <category>cs.RO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katherine Mao, Igor Spasojevic, M. Ani Hsieh, Vijay Kumar</dc:creator>
    </item>
    <item>
      <title>Quantum speedups for linear programming via interior point methods</title>
      <link>https://arxiv.org/abs/2311.03215</link>
      <description>arXiv:2311.03215v2 Announce Type: replace-cross 
Abstract: We describe a quantum algorithm based on an interior point method for solving a linear program with $n$ inequality constraints on $d$ variables. The algorithm explicitly returns a feasible solution that is $\varepsilon$-close to optimal, and runs in time $\sqrt{n} \cdot \mathrm{poly}(d,\log(n),\log(1/\varepsilon))$ which is sublinear for tall linear programs (i.e., $n \gg d$). Our algorithm speeds up the Newton step in the state-of-the-art interior point method of Lee and Sidford [FOCS~'14]. This requires us to efficiently approximate the Hessian and gradient of the barrier function, and these are our main contributions.
  To approximate the Hessian, we describe a quantum algorithm for the \emph{spectral approximation} of $A^T A$ for a tall matrix $A \in \mathbb R^{n \times d}$. The algorithm uses leverage score sampling in combination with Grover search, and returns a $\delta$-approximation by making $O(\sqrt{nd}/\delta)$ row queries to $A$. This generalizes an earlier quantum speedup for graph sparsification by Apers and de Wolf~[FOCS~'20]. To approximate the gradient, we use a recent quantum algorithm for multivariate mean estimation by Cornelissen, Hamoudi and Jerbi [STOC '22]. While a naive implementation introduces a dependence on the condition number of the Hessian, we avoid this by pre-conditioning our random variable using our quantum algorithm for spectral approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03215v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Apers, Sander Gribling</dc:creator>
    </item>
    <item>
      <title>Automatic nonlinear MPC approximation with closed-loop guarantees</title>
      <link>https://arxiv.org/abs/2312.10199</link>
      <description>arXiv:2312.10199v2 Announce Type: replace-cross 
Abstract: Safety guarantees are vital in many control applications, such as robotics. Model predictive control (MPC) provides a constructive framework for controlling safety-critical systems, but is limited by its computational complexity. We address this problem by presenting a novel algorithm that automatically computes an explicit approximation to nonlinear MPC schemes while retaining closed-loop guarantees. Specifically, the problem can be reduced to a function approximation problem, which we then tackle by proposing ALKIA-X, the Adaptive and Localized Kernel Interpolation Algorithm with eXtrapolated reproducing kernel Hilbert space norm. ALKIA-X is a non-iterative algorithm that ensures numerically well-conditioned computations, a fast-to-evaluate approximating function, and the guaranteed satisfaction of any desired bound on the approximation error. Hence, ALKIA-X automatically computes an explicit function that approximates the MPC, yielding a controller suitable for safety-critical systems and high sampling rates. We apply ALKIA-X to approximate two nonlinear MPC schemes, demonstrating reduced computational demand and applicability to realistic problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10199v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdullah Tokmak, Christian Fiedler, Melanie N. Zeilinger, Sebastian Trimpe, Johannes K\"ohler</dc:creator>
    </item>
    <item>
      <title>Approximation of sea surface velocity field by fitting surrogate two-dimensional flow to scattered measurements</title>
      <link>https://arxiv.org/abs/2401.12746</link>
      <description>arXiv:2401.12746v3 Announce Type: replace-cross 
Abstract: In this paper, a rapid approximation method is introduced to estimate the sea surface velocity field based on scattered measurements. The method uses a simplified two-dimensional flow model as a surrogate model, which mimics the real submesoscale flow. The proposed approach treats the interpolation of the flow velocities as an optimization problem, aiming to fit the flow model to the scattered measurements. To ensure consistency between the simulated velocity field and the measured values, the boundary conditions in the numerical simulations are adjusted during the optimization process. Additionally, the relevance of quantity and quality of the scattered measurements is assessed, emphasizing the importance of the measurement locations within the domain as well as explaining how these measurements contribute to the accuracy and reliability of the sea surface velocity field approximation. The proposed methodology has been successfully tested in both synthetic and real-world scenarios, leveraging measurements obtained from GPS drifters and HF-radar systems. The adaptability of this approach for different domains, measurement types and conditions implies that it is suitable for real-world submesoscale scenarios where only an approximation of the sea surface velocity field is sufficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12746v3</guid>
      <category>physics.flu-dyn</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Karlo Jakac, Luka Lan\v{c}a, Ante Sikirica, Stefan Ivi\'c</dc:creator>
    </item>
    <item>
      <title>FedADMM-InSa: An Inexact and Self-Adaptive ADMM for Federated Learning</title>
      <link>https://arxiv.org/abs/2402.13989</link>
      <description>arXiv:2402.13989v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) is a promising framework for learning from distributed data while maintaining privacy. The development of efficient FL algorithms encounters various challenges, including heterogeneous data and systems, limited communication capacities, and constrained local computational resources. Recently developed FedADMM methods show great resilience to both data and system heterogeneity. However, they still suffer from performance deterioration if the hyperparameters are not carefully tuned. To address this issue, we propose an inexact and self-adaptive FedADMM algorithm, termed FedADMM-InSa. First, we design an inexactness criterion for the clients' local updates to eliminate the need for empirically setting the local training accuracy. This inexactness criterion can be assessed by each client independently based on its unique condition, thereby reducing the local computational cost and mitigating the undesirable straggle effect. The convergence of the resulting inexact ADMM is proved under the assumption of strongly convex loss functions. Additionally, we present a self-adaptive scheme that dynamically adjusts each client's penalty parameter, enhancing algorithm robustness by mitigating the need for empirical penalty parameter choices for each client. Extensive numerical experiments on both synthetic and real-world datasets are conducted. As validated by some numerical tests, our proposed algorithm can reduce the clients' local computational load significantly and also accelerate the learning process compared to the vanilla FedADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.13989v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongcun Song, Ziqi Wang, Enrique Zuazua</dc:creator>
    </item>
    <item>
      <title>Error bounds for particle gradient descent, and extensions of the log-Sobolev and Talagrand inequalities</title>
      <link>https://arxiv.org/abs/2403.02004</link>
      <description>arXiv:2403.02004v2 Announce Type: replace-cross 
Abstract: We prove non-asymptotic error bounds for particle gradient descent (PGD)~(Kuntz et al., 2023), a recently introduced algorithm for maximum likelihood estimation of large latent variable models obtained by discretizing a gradient flow of the free energy. We begin by showing that, for models satisfying a condition generalizing both the log-Sobolev and the Polyak--{\L}ojasiewicz inequalities (LSI and P{\L}I, respectively), the flow converges exponentially fast to the set of minimizers of the free energy. We achieve this by extending a result well-known in the optimal transport literature (that the LSI implies the Talagrand inequality) and its counterpart in the optimization literature (that the P{\L}I implies the so-called quadratic growth condition), and applying it to our new setting. We also generalize the Bakry--\'Emery Theorem and show that the LSI/P{\L}I generalization holds for models with strongly concave log-likelihoods. For such models, we further control PGD's discretization error, obtaining non-asymptotic error bounds. While we are motivated by the study of PGD, we believe that the inequalities and results we extend may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02004v2</guid>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rocco Caprio, Juan Kuntz, Samuel Power, Adam M. Johansen</dc:creator>
    </item>
    <item>
      <title>The sticky particle dynamics of the 1D pressureless Euler-alignment system as a gradient flow</title>
      <link>https://arxiv.org/abs/2403.19020</link>
      <description>arXiv:2403.19020v2 Announce Type: replace-cross 
Abstract: We show how the sticky dynamics for the one-dimensional pressureless Euler-alignment system can be obtained as an $L^2$-gradient flow of a convex functional. This is analogous to the Lagrangian evolution introduced by Natile and Savar\'{e} for the pressureless Euler system, and by Brenier et al. for the corresponding system with a self-interacting force field. Our Lagrangian evolution can be seen as the limit of sticky particle Cucker-Smale dynamics, similar to the solutions obtained by Leslie and Tan from a corresponding scalar balance law, and provides us with a uniquely determined distributional solution of the original system in the space of probability measures with quadratic moments and corresponding square-integrable velocities. Moreover, we show that the gradient flow also provides an entropy solution to the balance law of Leslie and Tan, and how their results on cluster formation follow naturally from (non-)convexity properties of the so-called natural velocity of the flow.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19020v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sondre Tesdal Galtung</dc:creator>
    </item>
    <item>
      <title>The Sample Complexity of Gradient Descent in Stochastic Convex Optimization</title>
      <link>https://arxiv.org/abs/2404.04931</link>
      <description>arXiv:2404.04931v2 Announce Type: replace-cross 
Abstract: We analyze the sample complexity of full-batch Gradient Descent (GD) in the setup of non-smooth Stochastic Convex Optimization. We show that the generalization error of GD, with common choice of hyper-parameters, can be $\tilde \Theta(d/m + 1/\sqrt{m})$, where $d$ is the dimension and $m$ is the sample size. This matches the sample complexity of \emph{worst-case} empirical risk minimizers. That means that, in contrast with other algorithms, GD has no advantage over naive ERMs. Our bound follows from a new generalization bound that depends on both the dimension as well as the learning rate and number of iterations. Our bound also shows that, for general hyper-parameters, when the dimension is strictly larger than number of samples, $T=\Omega(1/\epsilon^4)$ iterations are necessary to avoid overfitting. This resolves an open problem by Schlisserman et al.23 and Amir er Al.21, and improves over previous lower bounds that demonstrated that the sample size must be at least square root of the dimension.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04931v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Roi Livni</dc:creator>
    </item>
  </channel>
</rss>
