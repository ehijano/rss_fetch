<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Oct 2024 04:01:36 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Formalizing MLTL Formula Progression in Isabelle/HOL</title>
      <link>https://arxiv.org/abs/2410.03465</link>
      <description>arXiv:2410.03465v1 Announce Type: new 
Abstract: Mission-time Linear Temporal Logic (MLTL) is rapidly increasing in popularity as a specification logic, e.g., for runtime verification, model checking, and other formal methods, driving a need for a larger tool base for analysis of this logic. To that end, we formalize formula progression for MLTL in the theorem prover Isabelle/HOL. As groundwork, we first formalize the syntax and semantics for MLTL as well as a verified library of key properties, including useful custom induction rules. We envision this library as being useful for future formalizations involving MLTL and as serving as a reference point for theoretical work using or developing MLTL. We then formalize the algorithm and correctness theorems for formula progression, following the literature. Along the way, we identify and fix several errors and gaps in the source material. A main motivation for our work is tool validation; we ensure the executability of our algorithms by using Isabelle's built-in functionality to generate a code export. This enables both a formal basis for correctly evaluating MLTL formulas and for automatically generating provably correct benchmarks for evaluating tools that reason about MLTL.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03465v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Katherine Kosaian, Zili Wang, Elizabeth Sloan, Kristin Rozier</dc:creator>
    </item>
    <item>
      <title>A Diagrammatic Algebra for Program Logics</title>
      <link>https://arxiv.org/abs/2410.03561</link>
      <description>arXiv:2410.03561v1 Announce Type: new 
Abstract: Tape diagrams provide a convenient notation for arrows of rig categories, i.e., categories equipped with two monoidal products, $\oplus$ and $\otimes$, where $\otimes$ distributes over $\oplus $. In this work, we extend tape diagrams with traces over $\oplus$ in order to deal with iteration in imperative programming languages. More precisely, we introduce Kleene-Cartesian bicategories, namely rig categories where the monoidal structure provided by $\otimes$ is a cartesian bicategory, while the one provided by $\oplus$ is what we name a Kleene bicategory. We show that the associated language of tape diagrams is expressive enough to deal with imperative programs and the corresponding laws provide a proof system that is at least as powerful as the one of Hoare logic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03561v1</guid>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Filippo Bonchi, Alessandro Di Giorgio, Elena Di Lavore</dc:creator>
    </item>
    <item>
      <title>Enriching Ontologies with Disjointness Axioms using Large Language Models</title>
      <link>https://arxiv.org/abs/2410.03235</link>
      <description>arXiv:2410.03235v1 Announce Type: cross 
Abstract: Ontologies often lack explicit disjointness declarations between classes, despite their usefulness for sophisticated reasoning and consistency checking in Knowledge Graphs. In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms. Our approach aims at leveraging the implicit knowledge embedded in LLMs, using prompt engineering to elicit this knowledge for classifying ontological disjointness. We validate our methodology on the DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs, when guided by effective prompt strategies, can reliably identify disjoint class relationships, thus streamlining the process of ontology completion without extensive manual input. For comprehensive disjointness enrichment, we propose a process that takes logical relationships between disjointness and subclass statements into account in order to maintain satisfiability and reduce the number of calls to the LLM. This work provides a foundation for future applications of LLMs in automated ontology enhancement and offers insights into optimizing LLM performance through strategic prompt design. Our code is publicly available on GitHub at https://github.com/n28div/llm-disjointness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03235v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elias Crum, Antonio De Santis, Manon Ovide, Jiaxin Pan, Alessia Pisu, Nicolas Lazzari, Sebastian Rudolph</dc:creator>
    </item>
    <item>
      <title>A Multimodal Framework for Deepfake Detection</title>
      <link>https://arxiv.org/abs/2410.03487</link>
      <description>arXiv:2410.03487v1 Announce Type: cross 
Abstract: The rapid advancement of deepfake technology poses a significant threat to digital media integrity. Deepfakes, synthetic media created using AI, can convincingly alter videos and audio to misrepresent reality. This creates risks of misinformation, fraud, and severe implications for personal privacy and security. Our research addresses the critical issue of deepfakes through an innovative multimodal approach, targeting both visual and auditory elements. This comprehensive strategy recognizes that human perception integrates multiple sensory inputs, particularly visual and auditory information, to form a complete understanding of media content. For visual analysis, a model that employs advanced feature extraction techniques was developed, extracting nine distinct facial characteristics and then applying various machine learning and deep learning models. For auditory analysis, our model leverages mel-spectrogram analysis for feature extraction and then applies various machine learning and deep learningmodels. To achieve a combined analysis, real and deepfake audio in the original dataset were swapped for testing purposes and ensured balanced samples. Using our proposed models for video and audio classification i.e. Artificial Neural Network and VGG19, the overall sample is classified as deepfake if either component is identified as such. Our multimodal framework combines visual and auditory analyses, yielding an accuracy of 94%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03487v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Journal of Electrical Systems, 20(10s) (2024). https://journal.esrgroups.org/jes/article/view/6126</arxiv:journal_reference>
      <dc:creator>Kashish Gandhi, Prutha Kulkarni, Taran Shah, Piyush Chaudhari, Meera Narvekar, Kranti Ghag</dc:creator>
    </item>
    <item>
      <title>A characterization of efficiently compilable constraint languages</title>
      <link>https://arxiv.org/abs/2311.10040</link>
      <description>arXiv:2311.10040v2 Announce Type: replace 
Abstract: A central task in knowledge compilation is to compile a CNF-SAT instance into a succinct representation format that allows efficient operations such as testing satisfiability, counting, or enumerating all solutions. Useful representation formats studied in this area range from ordered binary decision diagrams (OBDDs) to circuits in decomposable negation normal form (DNNFs).
  While it is known that there exist CNF formulas that require exponential size representations, the situation is less well studied for other types of constraints than Boolean disjunctive clauses. The constraint satisfaction problem (CSP) is a powerful framework that generalizes CNF-SAT by allowing arbitrary sets of constraints over any finite domain. The main goal of our work is to understand for which type of constraints (also called the constraint language) it is possible to efficiently compute representations of polynomial size. We answer this question completely and prove two tight characterizations of efficiently compilable constraint languages, depending on whether target format is structured.
  We first identify the combinatorial property of ``strong blockwise decomposability'' and show that if a constraint language has this property, we can compute DNNF representations of linear size. For all other constraint languages we construct families of CSP-instances that provably require DNNFs of exponential size. For a subclass of ``strong uniformly blockwise decomposable'' constraint languages we obtain a similar dichotomy for structured DNNFs. In fact, strong (uniform) blockwise decomposability even allows efficient compilation into multi-valued analogs of OBDDs and FBDDs, respectively. Thus, we get complete characterizations for all knowledge compilation classes between O(B)DDs and DNNFs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10040v2</guid>
      <category>cs.LO</category>
      <category>cs.CC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christoph Berkholz, Stefan Mengel, Hermann Wilhelm</dc:creator>
    </item>
    <item>
      <title>Proof Theory and Decision Procedures for Deontic STIT Logics</title>
      <link>https://arxiv.org/abs/2402.03148</link>
      <description>arXiv:2402.03148v2 Announce Type: replace 
Abstract: This paper provides a set of cut-free complete sequent-style calculi for deontic STIT ('See To It That') logics used to formally reason about choice-making, obligations, and norms in a multi-agent setting. We leverage these calculi to write a proof-search algorithm deciding deontic, multi-agent STIT logics with (un)limited choice and introduce a loop-checking mechanism to ensure the termination of the algorithm. Despite the acknowledged potential for deontic reasoning in the context of autonomous, multi-agent scenarios, this work is the first to provide a syntactic decision procedure for this class of logics. Our proof-search procedure is designed to provide verifiable witnesses/certificates of the (in)validity of formulae, which permits an analysis of the (non)theoremhood of formulae and act as explanations thereof. We show how the proof system and decision algorithm can be used to automate normative reasoning tasks such as duty checking (viz. determining an agent's obligations relative to a given knowledge base), compliance checking (viz. determining if a choice, considered by an agent as potential conduct, complies with the given knowledge base), and joint fulfillment checking (viz. determining whether under a specified factual context an agent can jointly fulfill all their duties).</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03148v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim S. Lyon, Kees van Berkel</dc:creator>
    </item>
    <item>
      <title>The equational theory of the Weihrauch lattice with (iterated) composition</title>
      <link>https://arxiv.org/abs/2408.14999</link>
      <description>arXiv:2408.14999v2 Announce Type: replace 
Abstract: We study the equational theory of the Weihrauch lattice with composition and iterations, meaning the collection of equations between terms built from variables, the lattice operations $\sqcup$, $\sqcap$, the composition operator $\star$ and its iteration $(-)^\diamond$ , which are true however we substitute (slightly extended) Weihrauch degrees for the variables. We characterize them using B\"uchi games on finite graphs and give a complete axiomatization that derives them. The term signature and the axiomatization are reminiscent of Kleene algebras, except that we additionally have meets and the lattice operations do not fully distributes over composition. The game characterization also implies that it is decidable whether an equation is universally valid. We give some complexity bounds; in particular, the problem is Pspace-hard in general and we conjecture that it is solvable in Pspace.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14999v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>C\'ecilia Pradic</dc:creator>
    </item>
    <item>
      <title>Fair Asynchronous Session Subtyping</title>
      <link>https://arxiv.org/abs/2101.08181</link>
      <description>arXiv:2101.08181v5 Announce Type: replace-cross 
Abstract: Session types are widely used as abstractions of asynchronous message passing systems. Refinement for such abstractions is crucial as it allows improvements of a given component without compromising its compatibility with the rest of the system. In the context of session types, the most general notion of refinement is asynchronous session subtyping, which allows message emissions to be anticipated w.r.t. a bounded amount of message consumptions. In this paper we investigate the possibility to anticipate emissions w.r.t. an unbounded amount of consumptions: to this aim we propose to consider fair compliance over asynchronous session types and fair refinement as the relation that preserves it. This allows us to propose a novel variant of session subtyping that leverages the notion of controllability from service contract theory and that is a sound characterisation of fair refinement. In addition, we show that both fair refinement and our novel subtyping are undecidable. We also present a sound algorithm which deals with examples that feature potentially unbounded buffering. Finally, we present an implementation of our algorithm and an empirical evaluation of it on synthetic benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2101.08181v5</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Bravetti, Julien Lange, Gianluigi Zavattaro</dc:creator>
    </item>
    <item>
      <title>The Existential Theory of the Reals with Summation Operators</title>
      <link>https://arxiv.org/abs/2405.04697</link>
      <description>arXiv:2405.04697v2 Announce Type: replace-cross 
Abstract: To characterize the computational complexity of satisfiability problems for probabilistic and causal reasoning within the Pearl's Causal Hierarchy, arXiv:2305.09508 [cs.AI] introduce a new natural class, named succ-$\exists$R. This class can be viewed as a succinct variant of the well-studied class $\exists$R based on the Existential Theory of the Reals (ETR). Analogously to $\exists$R, succ-$\exists$R is an intermediate class between NEXP and EXPSPACE, the exponential versions of NP and PSPACE. The main contributions of this work are threefold. Firstly, we characterize the class succ-$\exists$R in terms of nondeterministic real RAM machines and develop structural complexity theoretic results for real RAMs, including translation and hierarchy theorems. Notably, we demonstrate the separation of $\exists$R and succ-$\exists$R. Secondly, we examine the complexity of model checking and satisfiability of fragments of existential second-order logic and probabilistic independence logic. We show succ-$\exists$R- completeness of several of these problems, for which the best-known complexity lower and upper bounds were previously NEXP-hardness and EXPSPACE, respectively. Thirdly, while succ-$\exists$R is characterized in terms of ordinary (non-succinct) ETR instances enriched by exponential sums and a mechanism to index exponentially many variables, in this paper, we prove that when only exponential sums are added, the corresponding class $\exists$R^{\Sigma} is contained in PSPACE. We conjecture that this inclusion is strict, as this class is equivalent to adding a VNP-oracle to a polynomial time nondeterministic real RAM. Conversely, the addition of exponential products to ETR, yields PSPACE. Additionally, we study the satisfiability problem for probabilistic reasoning, with the additional requirement of a small model and prove that this problem is complete for $\exists$R^{\Sigma}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04697v2</guid>
      <category>cs.CC</category>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Markus Bl\"aser, Julian D\"orfler, Maciej Liskiewicz, Benito van der Zander</dc:creator>
    </item>
    <item>
      <title>Towards Verifying Exact Conditions for Implementations of Density Functional Approximations</title>
      <link>https://arxiv.org/abs/2408.05316</link>
      <description>arXiv:2408.05316v3 Announce Type: replace-cross 
Abstract: Density Functional Theory (DFT) is used extensively in the computation of electronic properties of matter, with various applications. Approximating the exchange-correlation (XC) functional is the key to the Kohn-Sham DFT approach, the basis of most DFT calculations. The choice of this density functional approximation (DFA) depends crucially on the particular system under study, which has resulted in the development of hundreds of DFAs. Though the exact density functional is not known, researchers have discovered analytical properties of this exact functional. Furthermore, these exact conditions are used when designing DFAs. We present XCVerifier, the first approach for verifying whether a DFA implementation satisfies the DFT exact conditions. XCVerifier was evaluated on five DFAs from the popular Libxc library and seven exact conditions from recent work. XCVerifier was able to verify or find violations for a majority of the DFA/condition pairs, demonstrating the feasibility of using formal methods to verify DFA implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05316v3</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LO</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sameerah Helal, Zhe Tao, Cindy Rubio-Gonz\'alez, Francois Gygi, Aditya V. Thakur</dc:creator>
    </item>
  </channel>
</rss>
