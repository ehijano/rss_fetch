<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 01 Nov 2024 04:00:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Abstract Continuation Semantics for Multiparty Interactions in Process Calculi based on CCS</title>
      <link>https://arxiv.org/abs/2410.23761</link>
      <description>arXiv:2410.23761v1 Announce Type: new 
Abstract: We develop denotational and operational semantics designed with continuations for process calculi based on CCS extended with mechanisms offering support for multiparty interactions. We investigate the abstractness of this continuation semantics. We show that our continuation-based denotational models are weakly abstract with respect to the corresponding operational models.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23761v1</guid>
      <category>cs.PL</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.410.2</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 410, 2024, pp. 18-37</arxiv:journal_reference>
      <dc:creator>Eneia Nicolae Todoran (Dept. of Computer Science, Technical University of Cluj-Napoca), Gabriel Ciobanu (Academia Europaea)</dc:creator>
    </item>
    <item>
      <title>Linear and non-linear relational analyses for Quantum Program Optimization</title>
      <link>https://arxiv.org/abs/2410.23493</link>
      <description>arXiv:2410.23493v1 Announce Type: cross 
Abstract: The phase folding optimization is a circuit optimization used in many quantum compilers as a fast and effective way of reducing the number of high-cost gates in a quantum circuit. However, existing formulations of the optimization rely on an exact, linear algebraic representation of the circuit, restricting the optimization to being performed on straightline quantum circuits or basic blocks in a larger quantum program.
  We show that the phase folding optimization can be re-cast as an \emph{affine relation analysis}, which allows the direct application of classical techniques for affine relations to extend phase folding to quantum \emph{programs} with arbitrarily complicated classical control flow including nested loops and procedure calls. Through the lens of relational analysis, we show that the optimization can be powered-up by substituting other classical relational domains, particularly ones for \emph{non-linear} relations which are useful in analyzing circuits involving classical arithmetic. To increase the precision of our analysis and infer non-linear relations from gate sets involving only linear operations -- such as Clifford+$T$ -- we show that the \emph{sum-over-paths} technique can be used to extract precise symbolic transition relations for straightline circuits. Our experiments show that our methods are able to generate and use non-trivial loop invariants for quantum program optimization, as well as achieve some optimizations of common circuits which were previously attainable only by hand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23493v1</guid>
      <category>quant-ph</category>
      <category>cs.PL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Matthew Amy, Joseph Lunderville</dc:creator>
    </item>
    <item>
      <title>Syno: Structured Synthesis for Neural Operators</title>
      <link>https://arxiv.org/abs/2410.23745</link>
      <description>arXiv:2410.23745v1 Announce Type: cross 
Abstract: The desires for better prediction accuracy and higher execution performance in neural networks never end. Neural architecture search (NAS) and tensor compilers are two popular techniques to optimize these two goals, but they are both limited to composing or optimizing existing manually designed operators rather than coming up with completely new designs. In this work, we explore the less studied direction of neural operator synthesis, which aims to automatically and efficiently discover novel neural operators with better accuracy and/or speed. We develop an end-to-end framework Syno, to realize practical neural operator synthesis. Syno makes use of a novel set of fine-grained primitives defined on tensor dimensions, which ensure various desired properties to ease model training, and also enable expression canonicalization techniques to avoid redundant candidates during search. Syno further adopts a novel guided synthesis flow to obtain valid operators matched with the specified input/output dimension sizes, and leverages efficient stochastic tree search algorithms to quickly explore the design space. We demonstrate that Syno discovers better operators with an average of $2.06\times$ speedup and less than $1\%$ accuracy loss, even on NAS-optimized models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23745v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>cs.PL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongqi Zhuo, Zhengyuan Su, Chenggang Zhao, Mingyu Gao</dc:creator>
    </item>
    <item>
      <title>Leveraging Slither and Interval Analysis to build a Static Analysis Tool</title>
      <link>https://arxiv.org/abs/2410.23766</link>
      <description>arXiv:2410.23766v1 Announce Type: cross 
Abstract: Even though much progress has been made in identifying and mitigating smart contract vulnerabilities, we often hear about coding or design issues leading to great financial losses. This paper presents our progress toward finding defects that are sometimes not detected or completely detected by state-of-the-art analysis tools. Although it is still in its incipient phase, we developed a working solution built on top of Slither that uses interval analysis to evaluate the contract state during the execution of each instruction. To improve the accuracy of our results, we extend interval analysis by also considering the constraints imposed by specific instructions. We present the current solution architecture in detail and show how it could be extended to other static analysis techniques, including how it can be integrated with other third-party tools. Our current benchmarks contain examples of smart contracts that highlight the potential of this approach to detect certain code defects. </description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23766v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.410.10</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 410, 2024, pp. 150-166</arxiv:journal_reference>
      <dc:creator>Stefan-Claudiu Susan (Alexandru Ioan Cuza University of Iasi, Department of Computer Science, Iasi, Romania)</dc:creator>
    </item>
    <item>
      <title>A Type System for Data Flow and Alias Analysis in ReScript</title>
      <link>https://arxiv.org/abs/2410.23984</link>
      <description>arXiv:2410.23984v1 Announce Type: cross 
Abstract: ReScript is a strongly typed language that targets JavaScript, as an alternative to gradually typed languages, such as TypeScript. In this paper, we present a sound type system for data-flow analysis for a subset of the ReScript language, more specifically for a lambda-calculus with mutability and pattern matching. The type system is a local analysis that collects information about variables that are used at each program point as well as alias information. </description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23984v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.410.8</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 410, 2024, pp. 116-132</arxiv:journal_reference>
      <dc:creator>Nicky Ask Lund (Department of Computer Science, Aalborg University), Hans H\"uttel (Department of Computer Science, University of Copenhagen)</dc:creator>
    </item>
    <item>
      <title>Synthetic Programming Elicitation for Text-to-Code in Very Low-Resource Programming and Formal Languages</title>
      <link>https://arxiv.org/abs/2406.03636</link>
      <description>arXiv:2406.03636v4 Announce Type: replace 
Abstract: Recent advances in large language models (LLMs) for code applications have demonstrated remarkable zero-shot fluency and instruction following on challenging code related tasks ranging from test case generation to self-repair. Unsurprisingly, however, models struggle to compose syntactically valid programs in programming languages unrepresented in pre-training, referred to as very low-resource Programming Languages (VLPLs). VLPLs appear in crucial settings, including domain-specific languages for internal tools, tool-chains for legacy languages, and formal verification frameworks. Inspired by a technique called natural programming elicitation, we propose designing an intermediate language that LLMs "naturally" know how to use and which can be automatically compiled to a target VLPL. When LLMs generate code that lies outside of this intermediate language, we use compiler techniques to repair the code into programs in the intermediate language. Overall, we introduce \emph{synthetic programming elicitation and compilation} (SPEAC), an approach that enables LLMs to generate syntactically valid code even for VLPLs. We empirically evaluate the performance of SPEAC in a case study for the UCLID5 formal verification language and find that, compared to existing retrieval and fine-tuning baselines, SPEAC produces syntactically correct programs more frequently and without sacrificing semantic correctness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03636v4</guid>
      <category>cs.PL</category>
      <category>cs.LG</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Federico Mora, Justin Wong, Haley Lepe, Sahil Bhatia, Karim Elmaaroufi, George Varghese, Joseph E. Gonzalez, Elizabeth Polgreen, Sanjit A. Seshia</dc:creator>
    </item>
    <item>
      <title>Programming of Cellular Automata in C and C++</title>
      <link>https://arxiv.org/abs/2410.10022</link>
      <description>arXiv:2410.10022v3 Announce Type: replace 
Abstract: This study explores running times of different ways to program cellular automata in C and C++, i.e. looping through arrays by different means, the effect of structures and objects, and the choice of data structure (array versus vector in C++) and compiler (GNU gcc versus Apple clang). Using arrays instead of vectors, using pointers instead of array indices, using C instead of C++, and using structures and objects instead of primitive data types has little to negligible effects on the running time. Also, the choice of compiler has only a minor effect, except for simple update functions, in which case clang seems to find better ways to optimise it, especially for index-based access. If one is interested in multi-state cellular automata, structures and objects can be used without loss of performance in C and C++, respectively. The study supports the recommendation from practice to use vector in C++ and adds to it the use of index-based access for cellular automata. Future studies might investigate Apple's Metal shader or compiler optimisation, especially with respect to the update function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.10022v3</guid>
      <category>cs.PL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Patrik Christen</dc:creator>
    </item>
    <item>
      <title>Target-Aware Implementation of Real Expressions</title>
      <link>https://arxiv.org/abs/2410.14025</link>
      <description>arXiv:2410.14025v3 Announce Type: replace 
Abstract: New low-precision accelerators, vector instruction sets, and library functions make maximizing accuracy and performance of numerical code increasingly challenging. Two lines of work$\unicode{x2013}$traditional compilers and numerical compilers$\unicode{x2013}$attack this problem from opposite directions. Traditional compiler backends optimize for specific target environments but are limited in their ability to balance performance and accuracy. Numerical compilers trade off accuracy and performance, or even improve both, but ignore the target environment. We join aspects of both to produce Chassis, a target-aware numerical compiler.
  Chassis compiles mathematical expressions to operators from a target description, which lists the real expressions each operator approximates and estimates its cost and accuracy. Chassis then uses an iterative improvement loop to optimize for speed and accuracy. Specifically, a new instruction selection modulo equivalence algorithm efficiently searches for faster target-specific programs, while a new cost-opportunity heuristic supports iterative improvement. We demonstrate Chassis' capabilities on 9 different targets, including hardware ISAs, math libraries, and programming languages. Chassis finds better accuracy and performance trade-offs than both Clang (by 3.5x) or Herbie (by up to 2.0x) by leveraging low-precision accelerators, accuracy-optimized numerical helper functions, and library subcomponents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14025v3</guid>
      <category>cs.PL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Brett Saiki, Jackson Brough, Jonas Regehr, Jes\'us Ponce, Varun Pradeep, Aditya Akhileshwaran, Zachary Tatlock, Pavel Panchekha</dc:creator>
    </item>
    <item>
      <title>A Distribution Semantics for Probabilistic Term Rewriting</title>
      <link>https://arxiv.org/abs/2410.15081</link>
      <description>arXiv:2410.15081v3 Announce Type: replace 
Abstract: Probabilistic programming is becoming increasingly popular thanks to its ability to specify problems with a certain degree of uncertainty. In this work, we focus on term rewriting, a well-known computational formalism. In particular, we consider systems that combine traditional rewriting rules with probabilities. Then, we define a distribution semantics for such systems that can be used to model the probability of reducing a term to some value. We also show how to compute a set of "explanations" for a given reduction, which can be used to compute its probability. Finally, we illustrate our approach with several examples and outline a couple of extensions that may prove useful to improve the expressive power of probabilistic rewrite systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15081v3</guid>
      <category>cs.PL</category>
      <category>cs.AI</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Germ\'an Vidal</dc:creator>
    </item>
    <item>
      <title>Coding Reliable LLM-based Integrated Task and Knowledge Agents with GenieWorksheets</title>
      <link>https://arxiv.org/abs/2407.05674</link>
      <description>arXiv:2407.05674v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) present an opportunity to create automated assistants that can help users navigate complex tasks. However, existing approaches have limitations in handling conditional logic, integrating knowledge sources, and consistently following instructions. Researchers and industry professionals often employ ad hoc pipelines to construct conversational agents. These pipelines aim to maintain context, address failure cases, and minimize hallucinations, yet frequently fail to achieve these objectives. To this end, we present Genie - a programmable framework for creating task-oriented conversational agents that are designed to handle complex user interactions and knowledge queries. Unlike LLMs, Genie provides reliable grounded responses, with controllable agent policies through its expressive specification, Genie Worksheet. In contrast to dialog trees, it is resilient to diverse user queries, helpful with knowledge sources, and offers ease of programming policies through its declarative paradigm. The agents built using Genie outperforms the state-of-the-art method on complex logic domains in STARV2 dataset by up to 20.5%. Additionally, through a real-user study involving 62 participants, we show that Genie beats the GPT-4 with function calling baseline by 21.1%, 20.1%, and 61% on execution accuracy, dialogue act accuracy, and goal completion rate, respectively, on three diverse real-world domains</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05674v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.PL</category>
      <pubDate>Fri, 01 Nov 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harshit Joshi, Shicheng Liu, James Chen, Robert Weigle, Monica S. Lam</dc:creator>
    </item>
  </channel>
</rss>
