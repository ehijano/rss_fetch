<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Formal Analysis of Iterated TDD</title>
      <link>https://arxiv.org/abs/2407.12839</link>
      <description>arXiv:2407.12839v1 Announce Type: new 
Abstract: In this paper we formally analyze the software methodology called (iterated) Test Driven Development (TDD). We formally define Specification, Software, Testing, Equivalence Partitions, Coupling, to argue about the nature of the software development in terms of TDD. We formalize Iterative TDD and find a context in which iterated TDD ``provably produce'' ``provably correct code'' from ``specifications'' while being stable in terms of iterated code churns. We demonstrate that outside this context iterated TDD will exhibit chaotic behavior, implying unpredictable messy amount of code churn. We argue that the research finding of ``ineffective'' iterated TDD found by earlier researches are due to missing this context, while the findings of ``effective'' iterated TDD is due to accidentally falling into the context or simply placebo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12839v1</guid>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hemil Ruparel, Nabarun Mondal</dc:creator>
    </item>
    <item>
      <title>$\mu$Drive: User-Controlled Autonomous Driving</title>
      <link>https://arxiv.org/abs/2407.13201</link>
      <description>arXiv:2407.13201v1 Announce Type: new 
Abstract: Autonomous Vehicles (AVs) rely on sophisticated Autonomous Driving Systems (ADSs) to provide passengers a satisfying and safe journey. The individual preferences of riders plays a crucial role in shaping the perception of safety and comfort while they are in the car. Existing ADSs, however, lack mechanisms to systematically capture and integrate rider preferences into their planning modules. To bridge this gap, we propose $\mu$Drive, an event-based Domain-Specific Language (DSL) designed for specifying autonomous vehicle behaviour. $\mu$Drive enables users to express their preferences through rules triggered by contextual events, such as encountering obstacles or navigating complex traffic situations. These rules dynamically adjust the parameter settings of the ADS planning module, facilitating seamless integration of rider preferences into the driving plan. In our evaluation, we demonstrate the feasibility and efficacy of $\mu$Drive by integrating it with the Apollo ADS framework. Our findings show that users can effectively influence Apollo's planning through $\mu$Drive, assisting ADS in achieving improved compliance with traffic regulations. The response time for $\mu$Drive commands remains consistently at the second or millisecond level. This suggests that $\mu$Drive may help pave the way to more personalizsed and user-centric AV experiences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13201v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kun Wang, Christopher M. Poskitt, Yang Sun, Jun Sun, Jingyi Wang, Peng Cheng, Jiming Chen</dc:creator>
    </item>
    <item>
      <title>A data-flow oriented software architecture for heterogeneous marine data streams</title>
      <link>https://arxiv.org/abs/2407.13231</link>
      <description>arXiv:2407.13231v1 Announce Type: new 
Abstract: Marine in-situ data is collected by sensors mounted on fixed or mobile systems deployed into the ocean. This type of data is crucial both for the ocean industries and public authorities, e.g., for monitoring and forecasting the state of marine ecosystems and/or climate changes. Various public organizations have collected, managed, and openly shared in-situ marine data in the past decade. Recently, initiatives like the Ocean Decade Corporate Data Group have incentivized the sharing of marine data of public interest from private companies aiding in ocean management. However, there is no clear understanding of the impact of data quality in the engineering of systems, as well as on how to manage and exploit the collected data.
  In this paper, we propose main architectural decisions and a data flow-oriented component and connector view for marine in-situ data streams. Our results are based on a longitudinal empirical software engineering process, and driven by knowledge extracted from the experts in the marine domain from public and private organizations, and challenges identified in the literature. The proposed software architecture is instantiated and exemplified in a prototype implementation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13231v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keila Lima, Ngoc-Thanh Nguyen, Rogardt Heldal, Lars Michael Kristensen, Tosin Daniel Oyetoyan, Patrizio Pelliccione, Eric Knauss</dc:creator>
    </item>
    <item>
      <title>The role of slicing in test-driven development</title>
      <link>https://arxiv.org/abs/2407.13258</link>
      <description>arXiv:2407.13258v1 Announce Type: new 
Abstract: Test-driven development (TDD) is a widely used agile practice. However, very little is known with certainty about TDD's underlying foundations, i.e., the way TDD works. In this paper, we propose a theoretical framework for TDD, with the following characteristics: 1) Each TDD cycle represents a vertical slice of a (probably also small) user story, 2) vertical slices are captured using contracts, implicit in the developers' minds, and 3) the code created during a TDD cycle is a sliced-based specification of a code oracle, using the contracts as slicing pre/post-conditions. We have checked the connections among TDD, contracts, and slices using a controlled experiment conducted in the industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13258v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oscar Dieste, Ayse Tosun, Sira Vegas, Adrian Santos, Fernando Uyaguari, Jarno Kyykka, Natalia Juristo</dc:creator>
    </item>
    <item>
      <title>Identifying Smart Contract Security Issues in Code Snippets from Stack Overflow</title>
      <link>https://arxiv.org/abs/2407.13271</link>
      <description>arXiv:2407.13271v1 Announce Type: new 
Abstract: Smart contract developers frequently seak solutions to developmental challenges on Q&amp;A platforms such as Stack Overflow (SO). Although community responses often provide viable solutions, the embedded code snippets can also contain hidden vulnerabilities. Integrating such code directly into smart contracts may make them susceptible to malicious attacks. We conducted an online survey and received 74 responses from smart contract developers. The results of this survey indicate that the majority (86.4%) of participants do not sufficiently consider security when reusing SO code snippets. Despite the existence of various tools designed to detect vulnerabilities in smart contracts, these tools are typically developed for analyzing fully-completed smart contracts and thus are ineffective for analyzing typical code snippets as found on SO. We introduce SOChecker, the first tool designed to identify potential vulnerabilities in incomplete SO smart contract code snippets. SOChecker first leverages a fine-tuned Llama2 model for code completion, followed by the application of symbolic execution methods for vulnerability detection. Our experimental results, derived from a dataset comprising 897 code snippets collected from smart contract-related SO posts, demonstrate that SOChecker achieves an F1 score of 68.2%, greatly surpassing GPT-3.5 and GPT-4 (20.9% and 33.2% F1 Scores respectively). Our findings underscore the need to improve the security of code snippets from Q&amp;A websites.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13271v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachi Chen, Chong Chen, Jiang Hu, John Grundy, Yanlin Wang, Ting Chen, Zibin Zheng</dc:creator>
    </item>
    <item>
      <title>AI-Assisted SQL Authoring at Industry Scale</title>
      <link>https://arxiv.org/abs/2407.13280</link>
      <description>arXiv:2407.13280v1 Announce Type: new 
Abstract: SqlCompose is a tool that uses generative AI to assist with data analytics tasks, specifically SQL queries. It addresses the challenges of SQL being declarative, having formal table schemas, and often being written in a non-linear manner. The authors develop an internal SQL benchmark to test the performance of the Public Llama model and find that it performs well, with a BLEU score of 53% for single-line predictions and 24% for multi-line predictions. They then fine-tune the Llama model on their internal data and database schemas, resulting in a substantial improvement in performance. They also develop a fill-in-the-middle model, SqlComposeFIM, which is aware of the context before and after the line(s) that need to be completed, and this model outperforms the other two models by 35 percentage points. Additionally, they measure how often the models get the correct table names and find that SqlComposeFIM is able to do this 75% of the time, a major improvement over the other two models. The authors also roll out SqlComposeFIM at Meta and receive positive feedback from users, including completing tedious or repetitive SQL clauses, suggesting boilerplate coding, and help in eliminating the need to remember difficult SQL syntax. However, some users report table and column name hallucinations, which has been reduced with the release of SqlComposeFIM. Overall, the SqlCompose models consistently outperform public and internal LLMs despite their smaller size, providing early indications that smaller specialist models can outperform larger general purpose models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13280v1</guid>
      <category>cs.SE</category>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandra Maddila, Negar Ghorbani, Kosay Jabre, Vijayaraghavan Murali, Edwin Kim, Parth Thakkar, Nikolay Pavlovich Laptev, Olivia Harman, Diana Hsu, Rui Abreu, Peter C. Rigby</dc:creator>
    </item>
    <item>
      <title>Scikit-fingerprints: easy and efficient computation of molecular fingerprints in Python</title>
      <link>https://arxiv.org/abs/2407.13291</link>
      <description>arXiv:2407.13291v1 Announce Type: new 
Abstract: In this work, we present \textit{scikit-fingerprints}, a Python package for computation of molecular fingerprints for applications in chemoinformatics. Our library offers an industry-standard scikit-learn interface, allowing intuitive usage and easy integration with machine learning pipelines. It is also highly optimized, featuring parallel computation that enables efficient processing of large molecular datasets. Currently, \textit{scikit-fingerprints} stands as the most feature-rich library in the Python ecosystem, offering over 30 molecular fingerprints. Our library simplifies chemoinformatics tasks based on molecular fingerprints, including molecular property prediction and virtual screening. It is also flexible, highly efficient, and fully open source.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13291v1</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jakub Adamczyk, Piotr Ludynia</dc:creator>
    </item>
    <item>
      <title>Streaming Technologies and Serialization Protocols: Empirical Performance Analysis</title>
      <link>https://arxiv.org/abs/2407.13494</link>
      <description>arXiv:2407.13494v1 Announce Type: new 
Abstract: Efficiently streaming high-volume data is essential for real-time data analytics, visualization, and AI and machine learning model training. Various streaming technologies and serialization protocols have been developed to meet different streaming needs. Together, they perform differently across various tasks and datasets. Therefore, when developing a streaming system, it can be challenging to make an informed decision on the suitable combination, as we encountered when implementing streaming for the UKAEA's MAST data or SKA's radio astronomy data. This study addresses this gap by proposing an empirical study of widely used data streaming technologies and serialization protocols. We introduce an extensible and open-source software framework to benchmark their efficiency across various performance metrics. Our findings reveal significant performance differences and trade-offs between these technologies. These insights can help in choosing suitable streaming and serialization solutions for contemporary data challenges. We aim to provide the scientific community and industry professionals with the knowledge to optimize data streaming for better data utilization and real-time analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13494v1</guid>
      <category>cs.SE</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Samuel Jackson, Nathan Cummings, Saiful Khan</dc:creator>
    </item>
    <item>
      <title>Designing Software with Complex Configurations</title>
      <link>https://arxiv.org/abs/2407.13633</link>
      <description>arXiv:2407.13633v1 Announce Type: new 
Abstract: In this paper I discuss how can lightweight formal methods be used to specify and verify software with complex configurations (for example, distributed protocols that work on specific network configurations). More specifically, I briefly present two popular formal methods - TLA+ and Alloy - and discuss the pros and cons of both in this particular context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13633v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alcino Cunha</dc:creator>
    </item>
    <item>
      <title>COMCAT: Leveraging Human Judgment to Improve Automatic Documentation and Summarization</title>
      <link>https://arxiv.org/abs/2407.13648</link>
      <description>arXiv:2407.13648v1 Announce Type: new 
Abstract: Software maintenance constitutes a substantial portion of the total lifetime costs of software, with a significant portion attributed to code comprehension. Software comprehension is eased by documentation such as comments that summarize and explain code. We present COMCAT, an approach to automate comment generation by augmenting Large Language Models (LLMs) with expertise-guided context to target the annotation of source code with comments that improve comprehension. Our approach enables the selection of the most relevant and informative comments for a given snippet or file containing source code. We develop the COMCAT pipeline to comment C/C++ files by (1) automatically identifying suitable locations in which to place comments, (2) predicting the most helpful type of comment for each location, and (3) generating a comment based on the selected location and comment type. In a human subject evaluation, we demonstrate that COMCAT-generated comments significantly improve developer code comprehension across three indicative software engineering tasks by up to 12% for 87% of participants. In addition, we demonstrate that COMCAT-generated comments are at least as accurate and readable as human-generated comments and are preferred over standard ChatGPT-generated comments for up to 92% of snippets of code. Furthermore, we develop and release a dataset containing source code snippets, human-written comments, and human-annotated comment categories. COMCAT leverages LLMs to offer a significant improvement in code comprehension across a variety of human software engineering tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13648v1</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Skyler Grandel (Vanderbilt University), Scott Thomas Andersen (Universidad Nacional Aut\`onoma de M\`exico), Yu Huang (Vanderbilt University), Kevin Leach (Vanderbilt University)</dc:creator>
    </item>
    <item>
      <title>CoDefeater: Using LLMs To Find Defeaters in Assurance Cases</title>
      <link>https://arxiv.org/abs/2407.13717</link>
      <description>arXiv:2407.13717v1 Announce Type: new 
Abstract: Constructing assurance cases is a widely used, and sometimes required, process toward demonstrating that safety-critical systems will operate safely in their planned environment. To mitigate the risk of errors and missing edge cases, the concept of defeaters - arguments or evidence that challenge claims in an assurance case - has been introduced. Defeaters can provide timely detection of weaknesses in the arguments, prompting further investigation and timely mitigations. However, capturing defeaters relies on expert judgment, experience, and creativity and must be done iteratively due to evolving requirements and regulations. This paper proposes CoDefeater, an automated process to leverage large language models (LLMs) for finding defeaters. Initial results on two systems show that LLMs can efficiently find known and unforeseen feasible defeaters to support safety analysts in enhancing the completeness and confidence of assurance cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13717v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Usman Gohar, Michael C. Hunter, Robyn R. Lutz, Myra B. Cohen</dc:creator>
    </item>
    <item>
      <title>SimClone: Detecting Tabular Data Clones using Value Similarity</title>
      <link>https://arxiv.org/abs/2407.12802</link>
      <description>arXiv:2407.12802v1 Announce Type: cross 
Abstract: Data clones are defined as multiple copies of the same data among datasets. Presence of data clones between datasets can cause issues such as difficulties in managing data assets and data license violations when using datasets with clones to build AI software. However, detecting data clones is not trivial. Majority of the prior studies in this area rely on structural information to detect data clones (e.g., font size, column header). However, tabular datasets used to build AI software are typically stored without any structural information. In this paper, we propose a novel method called SimClone for data clone detection in tabular datasets without relying on structural information. SimClone method utilizes value similarities for data clone detection. We also propose a visualization approach as a part of our SimClone method to help locate the exact position of the cloned data between a dataset pair. Our results show that our SimClone outperforms the current state-of-the-art method by at least 20\% in terms of both F1-score and AUC. In addition, SimClone's visualization component helps identify the exact location of the data clone in a dataset with a Precision@10 value of 0.80 in the top 20 true positive predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12802v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xu Yang (Jack), Gopi Krishnan Rajbahadur (Jack), Dayi Lin (Jack), Shaowei Wang (Jack), Zhen Ming (Jack),  Jiang</dc:creator>
    </item>
    <item>
      <title>High-Quality Tabular Data Generation using Post-Selected VAE</title>
      <link>https://arxiv.org/abs/2407.13016</link>
      <description>arXiv:2407.13016v1 Announce Type: cross 
Abstract: Synthetic tabular data is becoming a necessity as concerns about data privacy intensify in the world. Tabular data can be useful for testing various systems, simulating real data, analyzing the data itself or building predictive models. Unfortunately, such data may not be available due to confidentiality issues. Previous techniques, such as TVAE (Xu et al., 2019) or OCTGAN (Kim et al., 2021), are either unable to handle particularly complex datasets, or are complex in themselves, resulting in inferior run time performance. This paper introduces PSVAE, a new simple model that is capable of producing high-quality synthetic data in less run time. PSVAE incorporates two key ideas: loss optimization and post-selection. Along with these ideas, the proposed model compensates for underrepresented categories and uses a modern activation function, Mish (Misra, 2019).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13016v1</guid>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volodymyr Shulakov</dc:creator>
    </item>
    <item>
      <title>Exploring Robot Trajectory Planning -- A Comparative Analysis of Algorithms And Software Implementations in Dynamic Environments</title>
      <link>https://arxiv.org/abs/2407.13330</link>
      <description>arXiv:2407.13330v1 Announce Type: cross 
Abstract: Trajectory Planning is a crucial word in Modern &amp; Advanced Robotics. It's a way of generating a smooth and feasible path for the robot to follow over time. The process primarily takes several factors to generate the path, such as velocity, acceleration and jerk. The process deals with how the robot can follow a desired motion path in a suitable environment. This trajectory planning is extensively used in Automobile Industrial Robot, Manipulators, and Mobile Robots. Trajectory planning is a fundamental component of motion control systems. To perform tasks like pick and place operations, assembly, welding, painting, path following, and obstacle avoidance. This paper introduces a comparative analysis of trajectory planning algorithms and their key software elements working strategy in complex and dynamic environments. Adaptability and real-time analysis are the most common problems in trajectory planning. The paper primarily focuses on getting a better understanding of these unpredictable environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13330v1</guid>
      <category>cs.RO</category>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arunabh Bora</dc:creator>
    </item>
    <item>
      <title>Empirical Analysis of Sri Lankan Mobile Health Ecosystem: A Precursor to an Effective Stakeholder Engagement</title>
      <link>https://arxiv.org/abs/2407.13415</link>
      <description>arXiv:2407.13415v1 Announce Type: cross 
Abstract: Sri Lanka recently passed its first privacy legislation covering a wide range of sectors, including health. As a precursor for effective stakeholder engagement in the health domain to understand the most effective way to implement legislation in healthcare, we have analyzed 41 popular mobile apps and web portals. We found that 78% of the tested systems have third-party domains receiving sensitive health data with minimal visibility to the consumers. We discuss how this will create potential issues in preparing for the new privacy legislation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13415v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kenneth Thilakarathna, Sachintha Pitigala, Jayantha Fernando, Primal Wijesekera</dc:creator>
    </item>
    <item>
      <title>Scaling Granite Code Models to 128K Context</title>
      <link>https://arxiv.org/abs/2407.13739</link>
      <description>arXiv:2407.13739v1 Announce Type: cross 
Abstract: This paper introduces long-context Granite code models that support effective context windows of up to 128K tokens. Our solution for scaling context length of Granite 3B/8B code models from 2K/4K to 128K consists of a light-weight continual pretraining by gradually increasing its RoPE base frequency with repository-level file packing and length-upsampled long-context data. Additionally, we also release instruction-tuned models with long-context support which are derived by further finetuning the long context base models on a mix of permissively licensed short and long-context instruction-response pairs. While comparing to the original short-context Granite code models, our long-context models achieve significant improvements on long-context tasks without any noticeable performance degradation on regular code completion benchmarks (e.g., HumanEval). We release all our long-context Granite code models under an Apache 2.0 license for both research and commercial use.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13739v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.SE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matt Stallone, Vaibhav Saxena, Leonid Karlinsky, Bridget McGinn, Tim Bula, Mayank Mishra, Adriana Meza Soria, Gaoyuan Zhang, Aditya Prasad, Yikang Shen, Saptha Surendran, Shanmukha Guttula, Hima Patel, Parameswaran Selvam, Xuan-Hong Dang, Yan Koyfman, Atin Sood, Rogerio Feris, Nirmit Desai, David D. Cox, Ruchir Puri, Rameswar Panda</dc:creator>
    </item>
    <item>
      <title>Teaching Code LLMs to Use Autocompletion Tools in Repository-Level Code Generation</title>
      <link>https://arxiv.org/abs/2401.06391</link>
      <description>arXiv:2401.06391v3 Announce Type: replace 
Abstract: Code large language models (LLMs) face limitations in repository-level code generation due to their lack of awareness of repository-level dependencies (e.g., user-defined attributes), resulting in dependency errors such as undefined-variable and no-member errors. In this work, we introduce ToolGen, an approach that integrates autocompletion tools into the code LLM generation process to address these dependencies. ToolGen comprises two main phases: Trigger Insertion and Model Fine-tuning (Offline), and Tool-integrated Code Generation (Online). During the offline phase, ToolGen augments functions within a given code corpus with a special mark token, indicating positions to trigger autocompletion tools. These augmented functions, along with their corresponding docstrings, are then used to fine-tune a selected code LLM. In the online phase, ToolGen iteratively generates functions by predicting tokens step-by-step using the fine-tuned LLM. Whenever a mark token is encountered, ToolGen invokes the autocompletion tool to suggest code completions and selects the most appropriate one.
  We conduct comprehensive experiments to evaluate ToolGen's effectiveness in repository-level code generation. To facilitate this evaluation, we create a benchmark comprising 671 real-world code repositories and introduce two new dependency-based metrics: Dependency Coverage and Static Validity Rate. The results demonstrate that ToolGen significantly improves Dependency Coverage by 31.4% to 39.1% and Static Validity Rate by 44.9% to 57.7% across the three LLMs, while maintaining competitive or improved performance in widely recognized similarity metrics such as BLEU-4, CodeBLEU, Edit Similarity, and Exact Match. On the CoderEval dataset, ToolGen achieves improvements of 40.0% and 25.0% in Pass@1 for CodeT5 and CodeLlama, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06391v3</guid>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chong Wang, Jian Zhang, Yebo Feng, Tianlin Li, Weisong Sun, Yang Liu, Xin Peng</dc:creator>
    </item>
    <item>
      <title>Runtime Verification and Field-based Testing for ROS-Based Robotic Systems</title>
      <link>https://arxiv.org/abs/2404.11498</link>
      <description>arXiv:2404.11498v2 Announce Type: replace 
Abstract: Robotic systems are becoming pervasive and adopted in increasingly many domains, such as manufacturing, healthcare, and space exploration. To this end, engineering software has emerged as a crucial discipline for building maintainable and reusable robotic systems. Robotics software engineering research has received increasing attention, fostering autonomy as a fundamental goal. However, robotics developers are still challenged trying to achieve this goal given that simulation is not able to deliver solutions to realistically emulate real-world phenomena. Robots also need to operate in unpredictable and uncontrollable environments, which require safe and trustworthy self-adaptation capabilities implemented in software. Typical techniques to address the challenges are runtime verification, field-based testing, and mitigation techniques that enable fail-safe solutions. However, there is no clear guidance to architect ROS-based systems to enable and facilitate runtime verification and field-based testing. This paper aims to fill in this gap by providing guidelines that can help developers and QA teams when developing, verifying or testing their robots in the field. These guidelines are carefully tailored to address the challenges and requirements of testing robotics systems in real-world scenarios. We conducted a literature review on studies addressing runtime verification and field-based testing for robotic systems, mined ROS-based application repositories, and validated the applicability, clarity, and usefulness via two questionnaires with 55 answers. We contribute 20 guidelines formulated for researchers and practitioners in robotic software engineering. Finally, we map our guidelines to open challenges thus far in runtime verification and field-based testing for ROS-based systems and, we outline promising research directions in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11498v2</guid>
      <category>cs.SE</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Caldas, Juan Antonio Pinera Garcia, Matei Schiopu, Patrizio Pelliccione, Genaina Rodrigues, Thorsten Berger</dc:creator>
    </item>
    <item>
      <title>Model Provenance via Model DNA</title>
      <link>https://arxiv.org/abs/2308.02121</link>
      <description>arXiv:2308.02121v3 Announce Type: replace-cross 
Abstract: Understanding the life cycle of the machine learning (ML) model is an intriguing area of research (e.g., understanding where the model comes from, how it is trained, and how it is used). This paper focuses on a novel problem within this field, namely Model Provenance (MP), which concerns the relationship between a target model and its pre-training model and aims to determine whether a source model serves as the provenance for a target model. This is an important problem that has significant implications for ensuring the security and intellectual property of machine learning models but has not received much attention in the literature. To fill in this gap, we introduce a novel concept of Model DNA which represents the unique characteristics of a machine learning model. We utilize a data-driven and model-driven representation learning method to encode the model's training data and input-output information as a compact and comprehensive representation (i.e., DNA) of the model. Using this model DNA, we develop an efficient framework for model provenance identification, which enables us to identify whether a source model is a pre-training model of a target model. We conduct evaluations on both computer vision and natural language processing tasks using various models, datasets, and scenarios to demonstrate the effectiveness of our approach in accurately identifying model provenance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.02121v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Mu, Yu Wang, Yehong Zhang, Jiaqi Zhang, Hui Wang, Yang Xiang, Yue Yu</dc:creator>
    </item>
  </channel>
</rss>
