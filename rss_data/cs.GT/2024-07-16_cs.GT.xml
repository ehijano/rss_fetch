<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 04:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Conditions for Altruistic Perversity in Two-Strategy Population Games</title>
      <link>https://arxiv.org/abs/2407.11250</link>
      <description>arXiv:2407.11250v1 Announce Type: new 
Abstract: Self-interested behavior from individuals can collectively lead to poor societal outcomes. These outcomes can seemingly be improved through the actions of altruistic agents, which benefit other agents in the system. However, it is known in specific contexts that altruistic agents can actually induce worse outcomes compared to a fully selfish population -- a phenomenon we term altruistic perversity. This paper provides a holistic investigation into the necessary conditions that give rise to altruistic perversity. In particular, we study the class of two-strategy population games where one sub-population is altruistic and the other is selfish. We find that a population game can admit altruistic perversity only if the associated social welfare function is convex and the altruistic population is sufficiently large. Our results are a first step in establishing a connection between properties of nominal agent interactions and the potential impacts from altruistic behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11250v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Colton Hill, Philip N. Brown, Keith Paarporn</dc:creator>
    </item>
    <item>
      <title>Bidding efficiently in Simultaneous Ascending Auctions with incomplete information using Monte Carlo Tree Search and determinization</title>
      <link>https://arxiv.org/abs/2407.11715</link>
      <description>arXiv:2407.11715v1 Announce Type: new 
Abstract: For decades, Simultaneous Ascending Auction (SAA) has been the most widely used mechanism for spectrum auctions, and it has recently gained popularity for allocating 5G licenses in many countries. Despite its relatively simple rules, SAA introduces a complex strategic game with an unknown optimal bidding strategy. Given the high stakes involved, with billions of euros sometimes on the line, developing an efficient bidding strategy is of utmost importance. In this work, we extend our previous method, a Simultaneous Move Monte-Carlo Tree Search (SM-MCTS) based algorithm named $SMS^{\alpha}$ to incomplete information framework. For this purpose, we compare three determinization approaches which allow us to rely on complete information SM-MCTS. This algorithm addresses, in incomplete framework, the four key strategic issues of SAA: the exposure problem, the own price effect, budget constraints, and the eligibility management problem. Through extensive numerical experiments on instances of realistic size with an uncertain framework, we show that $SMS^{\alpha}$ largely outperforms state-of-the-art algorithms by achieving higher expected utility while taking less risks, no matter which determinization method is chosen.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11715v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandre Pacaud, Aur\'elien Bechler, Marceau Coupechoux</dc:creator>
    </item>
    <item>
      <title>Faster and Smaller Solutions of Obliging Games</title>
      <link>https://arxiv.org/abs/2407.11856</link>
      <description>arXiv:2407.11856v1 Announce Type: new 
Abstract: Obliging games have been introduced in the context of the game perspective on reactive synthesis in order to enforce a degree of cooperation between the to-be-synthesized system and the environment. Previous approaches to the analysis of obliging games have been small-step in the sense that they have been based on a reduction to standard (non-obliging) games in which single moves correspond to single moves in the original (obliging) game. Here, we propose a novel, large-step view on obliging games, reducing them to standard games in which single moves encode long-term behaviors in the original game. This not only allows us to give a meaningful definition of the environment winning in obliging games, but also leads to significantly improved bounds on both strategy sizes and the solution runtime for obliging games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11856v1</guid>
      <category>cs.GT</category>
      <category>cs.FL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Hausmann, Nir Piterman</dc:creator>
    </item>
    <item>
      <title>Price Competition in Linear Fisher Markets: Stability, Equilibrium and Personalization</title>
      <link>https://arxiv.org/abs/2407.11869</link>
      <description>arXiv:2407.11869v1 Announce Type: new 
Abstract: Linear Fisher market is one of the most fundamental economic models. The market is traditionally examined on the basis of individual's price-taking behavior. However, this assumption breaks in markets such as online advertising and e-commerce, where several oligopolists dominate the market and are able to compete with each other via strategic actions. Motivated by this, we study the price competition among sellers in linear Fisher markets. From an algorithmic game-theoretic perspective, we establish a model to analyze behaviors of buyers and sellers that are driven by utility-maximizing purposes and also constrained by computational tractability. The main economic observation is the role played by personalization: the classic benchmark market outcome, namely competitive equilibrium, remains to be a steady-state if every buyer must be treated "equally"; however, sellers have the incentive to personalize, and as a result the market would become more unpredictable and less efficient. In addition, we build a series of algorithmic and complexity results along the road to justify our modeling choices and reveal market structures. We find interesting connections between our model and other computational problems such as stable matching, network flow, etc. We believe these results and techniques are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11869v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juncheng Li, Pingzhong Tang</dc:creator>
    </item>
    <item>
      <title>Proportional Dynamics in Linear Fisher Markets with Auto-bidding: Convergence, Incentives and Fairness</title>
      <link>https://arxiv.org/abs/2407.11872</link>
      <description>arXiv:2407.11872v1 Announce Type: new 
Abstract: Proportional dynamics, originated from peer-to-peer file sharing systems, models a decentralized price-learning process in Fisher markets. Previously, items in the dynamics operate independently of one another, and each is assumed to belong to a different seller. In this paper, we show how it can be generalized to the setting where each seller brings multiple items and buyers allocate budgets at the granularity of sellers rather than individual items. The generalized dynamics consistently converges to the competitive equilibrium, and interestingly relates to the auto-bidding paradigm currently popular in online advertising auction markets. In contrast to peer-to-peer networks, the proportional rule is not imposed as a protocol in auto-bidding markets. Regarding this incentive concern, we show that buyers have a strong tendency to follow the rule, but it is easy for sellers to profitably deviate (given buyers' commitment to the rule). Based on this observation, we further study the seller-side deviation game and show that it admits a unique pure Nash equilibrium. Though it is generally different from the competitive equilibrium, we show that it attains a good fairness guarantee as long as the market is competitive enough and not severely monopolized.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11872v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juncheng Li, Pingzhong Tang</dc:creator>
    </item>
    <item>
      <title>Strategic Littlestone Dimension: Improved Bounds on Online Strategic Classification</title>
      <link>https://arxiv.org/abs/2407.11619</link>
      <description>arXiv:2407.11619v1 Announce Type: cross 
Abstract: We study the problem of online binary classification in settings where strategic agents can modify their observable features to receive a positive classification. We model the set of feasible manipulations by a directed graph over the feature space, and assume the learner only observes the manipulated features instead of the original ones. We introduce the Strategic Littlestone Dimension, a new combinatorial measure that captures the joint complexity of the hypothesis class and the manipulation graph. We demonstrate that it characterizes the instance-optimal mistake bounds for deterministic learning algorithms in the realizable setting. We also achieve improved regret in the agnostic setting by a refined agnostic-to-realizable reduction that accounts for the additional challenge of not observing agents' original features. Finally, we relax the assumption that the learner knows the manipulation graph, instead assuming their knowledge is captured by a family of graphs. We derive regret bounds in both the realizable setting where all agents manipulate according to the same graph within the graph family, and the agnostic setting where the manipulation graphs are chosen adversarially and not consistently modeled by a single graph in the family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11619v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Saba Ahmadi, Kunhe Yang, Hanrui Zhang</dc:creator>
    </item>
    <item>
      <title>Continuous Social Networks</title>
      <link>https://arxiv.org/abs/2407.11710</link>
      <description>arXiv:2407.11710v1 Announce Type: cross 
Abstract: We develop an extension of the classical model of DeGroot (1974) to a continuum of agents when they interact among them according to a DiKernel $W$. We show that, under some regularity assumptions, the continuous model is the limit case of the discrete one. We provide some applications of this result. First, we establish a canonical way to reduce the dimensionality of matrices by comparing matrices of different dimensions in the space of DiKernels. Then, we develop a model of Lobby Competition where two lobbies compete to bias the opinion of a continuum of agents. We give sufficient conditions for the existence of a Nash Equilibrium. Furthermore, we establish the conditions under which a Nash Equilibrium of the game induce an $\varepsilon$-Nash Equilibrium of the discretization of the game. Finally, we put forward some elements for the characterization of equilibrium strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11710v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juli\'an Chitiva, Xavier Venel</dc:creator>
    </item>
    <item>
      <title>Map of Elections</title>
      <link>https://arxiv.org/abs/2407.11889</link>
      <description>arXiv:2407.11889v1 Announce Type: cross 
Abstract: Our main contribution is the introduction of the map of elections framework. A map of elections consists of three main elements: (1) a dataset of elections (i.e., collections of ordinal votes over given sets of candidates), (2) a way of measuring similarities between these elections, and (3) a representation of the elections in the 2D Euclidean space as points, so that the more similar two elections are, the closer are their points. In our maps, we mostly focus on datasets of synthetic elections, but we also show an example of a map over real-life ones. To measure similarities, we would have preferred to use, e.g., the isomorphic swap distance, but this is infeasible due to its high computational complexity. Hence, we propose polynomial-time computable positionwise distance and use it instead. Regarding the representations in 2D Euclidean space, we mostly use the Kamada-Kawai algorithm, but we also show two alternatives.
  We develop the necessary theoretical results to form our maps and argue experimentally that they are accurate and credible. Further, we show how coloring the elections in a map according to various criteria helps in analyzing results of a number of experiments. In particular, we show colorings according to the scores of winning candidates or committees, running times of ILP-based winner determination algorithms, and approximation ratios achieved by particular algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11889v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stanis{\l}aw Szufa</dc:creator>
    </item>
    <item>
      <title>Fair Division with Bounded Sharing: Binary and Non-Degenerate Valuations</title>
      <link>https://arxiv.org/abs/1912.00459</link>
      <description>arXiv:1912.00459v2 Announce Type: replace 
Abstract: A set of objects is to be divided fairly among agents with different tastes, modeled by additive utility-functions. An agent is allowed to share a bounded number of objects between two or more agents in order to attain fairness.
  The paper studies various notions of fairness, such as proportionality, envy-freeness, equitability, and consensus. We analyze the run-time complexity of finding a fair allocation with a given number of sharings under several restrictions on the agents' valuations, such as: binary generalized-binary and non-degenerate.</description>
      <guid isPermaLink="false">oai:arXiv.org:1912.00459v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Bismuth, Ivan Bliznets, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Ensure Differential Privacy and Convergence Accuracy in Consensus Tracking and Aggregative Games with Coupling Constraints</title>
      <link>https://arxiv.org/abs/2210.16395</link>
      <description>arXiv:2210.16395v4 Announce Type: replace 
Abstract: We address differential privacy for fully distributed aggregative games with shared coupling constraints. By co-designing the generalized Nash equilibrium (GNE) seeking mechanism and the differential-privacy noise injection mechanism, we propose the first GNE seeking algorithm that can ensure both provable convergence to the GNE and rigorous epsilon-differential privacy, even with the number of iterations tending to infinity. As a basis of the co-design, we also propose a new consensus-tracking algorithm that can achieve rigorous epsilon-differential privacy while maintaining accurate tracking performance, which, to our knowledge, has not been achieved before. To facilitate the convergence analysis, we also establish a general convergence result for stochastically-perturbed nonstationary fixed-point iteration processes, which lie at the core of numerous optimization and variational problems. Numerical simulation results confirm the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.16395v4</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongqiang Wang</dc:creator>
    </item>
    <item>
      <title>New Guarantees for Learning Revenue Maximizing Menus of Lotteries and Two-Part Tariffs</title>
      <link>https://arxiv.org/abs/2302.11700</link>
      <description>arXiv:2302.11700v3 Announce Type: replace 
Abstract: We advance a recently flourishing line of work at the intersection of learning theory and computational economics by studying the learnability of two classes of mechanisms prominent in economics, namely menus of lotteries and two-part tariffs. The former is a family of randomized mechanisms designed for selling multiple items, known to achieve revenue beyond deterministic mechanisms, while the latter is designed for selling multiple units (copies) of a single item with applications in real-world scenarios such as car or bike-sharing services. We focus on learning high-revenue mechanisms of this form from buyer valuation data in both distributional settings, where we have access to buyers' valuation samples up-front, and the more challenging and less-studied online settings, where buyers arrive one-at-a-time and no distributional assumption is made about their values. We provide a suite of results with regard to these two families of mechanisms. We provide the first online learning algorithms for menus of lotteries and two-part tariffs with strong regret-bound guarantees. Since the space of parameters is infinite and the revenue functions have discontinuities, the known techniques do not readily apply. However, we are able to provide a reduction to online learning over a finite number of experts, in our case, a finite number of parameters. Furthermore, in the limited buyers type case, we show a reduction to online linear optimization, which allows us to obtain no-regret guarantees by presenting buyers with menus that correspond to a barycentric spanner. In addition, we provide algorithms with improved running times over prior work for the distributional settings. Finally, we demonstrate how techniques from the recent literature in data-driven algorithm design are insufficient for our studied problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.11700v3</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Florina Balcan, Hedyeh Beyhaghi</dc:creator>
    </item>
    <item>
      <title>Learning in Repeated Multi-Unit Pay-As-Bid Auctions</title>
      <link>https://arxiv.org/abs/2307.15193</link>
      <description>arXiv:2307.15193v2 Announce Type: replace 
Abstract: Motivated by Carbon Emissions Trading Schemes, Treasury Auctions, and Procurement Auctions, which all involve the auctioning of homogeneous multiple units, we consider the problem of learning how to bid in repeated multi-unit pay-as-bid auctions. In each of these auctions, a large number of (identical) items are to be allocated to the largest submitted bids, where the price of each of the winning bids is equal to the bid itself. The problem of learning how to bid in pay-as-bid auctions is challenging due to the combinatorial nature of the action space. We overcome this challenge by focusing on the offline setting, where the bidder optimizes their vector of bids while only having access to the past submitted bids by other bidders. We show that the optimal solution to the offline problem can be obtained using a polynomial time dynamic programming (DP) scheme. We leverage the structure of the DP scheme to design online learning algorithms with polynomial time and space complexity under full information and bandit feedback settings. We achieve an upper bound on regret of $O(M\sqrt{T\log |\mathcal{B}|})$ and $O(M\sqrt{|\mathcal{B}|T\log |\mathcal{B}|})$ respectively, where $M$ is the number of units demanded by the bidder, $T$ is the total number of auctions, and $|\mathcal{B}|$ is the size of the discretized bid space. We accompany these results with a regret lower bound, which match the linear dependency in $M$. Our numerical results suggest that when all agents behave according to our proposed no regret learning algorithms, the resulting market dynamics mainly converge to a welfare maximizing equilibrium where bidders submit uniform bids. Lastly, our experiments demonstrate that the pay-as-bid auction consistently generates significantly higher revenue compared to its popular alternative, the uniform price auction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15193v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rigel Galgana, Negin Golrezaei</dc:creator>
    </item>
    <item>
      <title>Fair Interventions in Weighted Congestion Games</title>
      <link>https://arxiv.org/abs/2311.16760</link>
      <description>arXiv:2311.16760v2 Announce Type: replace 
Abstract: In this work we study the power and limitations of fair interventions in weighted congestion games. Specifically, we focus on interventions that aim at improving the equilibrium quality (price of anarchy) and are fair in a suitably defined sense. Within this setting, we provide three key contributions. First, we show that no fair intervention can reduce the price of anarchy below a given factor depending solely on the class of latencies considered. Interestingly, this lower bound is unconditional, i.e., it applies regardless of how much computation interventions are allowed to use. Second, we design a taxation mechanism that is fair and achieves a price of anarchy matching this unconditional lower bound, all the while being polynomial-time computable. Third, we show that no intervention (fair or not) can achieve a better approximation if polynomial computability is required. We do so by proving that the minimum social cost is NP-hard to minimize below a factor identical to the one previously introduced. In doing so, our work shows that the algorithm proposed by Makarychev and Sviridenko (Journal of the ACM, 2018) to tackle optimization problems with a "diseconomy of scale" is optimal, and provide a novel way to derandomize its solution via equilibrium computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16760v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Miriam Fischer, Martin Gairing, Dario Paccagnan</dc:creator>
    </item>
    <item>
      <title>Strategizing against Q-learners: A Control-theoretical Approach</title>
      <link>https://arxiv.org/abs/2403.08906</link>
      <description>arXiv:2403.08906v3 Announce Type: replace 
Abstract: In this paper, we explore the susceptibility of the independent Q-learning algorithms (a classical and widely used multi-agent reinforcement learning method) to strategic manipulation of sophisticated opponents in normal-form games played repeatedly. We quantify how much strategically sophisticated agents can exploit naive Q-learners if they know the opponents' Q-learning algorithm. To this end, we formulate the strategic actors' interactions as a stochastic game (whose state encompasses Q-function estimates of the Q-learners) as if the Q-learning algorithms are the underlying dynamical system. We also present a quantization-based approximation scheme to tackle the continuum state space and analyze its performance for two competing strategic actors and a single strategic actor both analytically and numerically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.08906v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2024.3416240</arxiv:DOI>
      <arxiv:journal_reference>IEEE Control Systems Letters 8 (2024) 1733-1738</arxiv:journal_reference>
      <dc:creator>Yuksel Arslantas, Ege Yuceel, Muhammed O. Sayin</dc:creator>
    </item>
    <item>
      <title>Opponent Indifference in Rating Systems: A Theoretical Case for Sonas</title>
      <link>https://arxiv.org/abs/2209.03950</link>
      <description>arXiv:2209.03950v3 Announce Type: replace-cross 
Abstract: In competitive games, it is common to assign each player a real number rating signifying their skill level. A rating system is a procedure by which player ratings are adjusted upwards each time they win, or downwards each time they lose. Many matchmaking systems give players some control over their opponent's rating; for example, a player might be able to selectively initiate matches against opponents whose ratings are publicly visible, or abort a match without penalty before it begins but after glimpsing their opponent's rating. It is natural to ask whether one can design a rating system that does not incentivize a rating-maximizing player to act strategically, seeking matches against opponents of one rating over another. We show the following:
  - The full version of this "opponent indifference" property is unfortunately too strong to be feasible. Although it is satisfied by some rating systems, these systems lack certain desirable expressiveness properties, suggesting that they are not suitable to capture most games of interest.
  - However, there is a natural relaxation, roughly requiring indifference between any two opponents who are "reasonably evenly matched" with the choosing player. We prove that this relaxed variant of opponent indifference, which we call $P$ opponent indifference, is viable. In fact, a certain strong version of $P$ opponent indifference precisely characterizes the rating system Sonas, which was originally proposed for its empirical predictive accuracy on the outcomes of high-level chess matches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03950v3</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Greg Bodwin, Forest Zhang</dc:creator>
    </item>
    <item>
      <title>A Single Online Agent Can Efficiently Learn Mean Field Games</title>
      <link>https://arxiv.org/abs/2405.03718</link>
      <description>arXiv:2405.03718v2 Announce Type: replace-cross 
Abstract: Mean field games (MFGs) are a promising framework for modeling the behavior of large-population systems. However, solving MFGs can be challenging due to the coupling of forward population evolution and backward agent dynamics. Typically, obtaining mean field Nash equilibria (MFNE) involves an iterative approach where the forward and backward processes are solved alternately, known as fixed-point iteration (FPI). This method requires fully observed population propagation and agent dynamics over the entire spatial domain, which could be impractical in some real-world scenarios. To overcome this limitation, this paper introduces a novel online single-agent model-free learning scheme, which enables a single agent to learn MFNE using online samples, without prior knowledge of the state-action space, reward function, or transition dynamics. Specifically, the agent updates its policy through the value function (Q), while simultaneously evaluating the mean field state (M), using the same batch of observations. We develop two variants of this learning scheme: off-policy and on-policy QM iteration. We prove that they efficiently approximate FPI, and a sample complexity guarantee is provided. The efficacy of our methods is confirmed by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03718v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyu Zhang, Xu Chen, Xuan Di</dc:creator>
    </item>
    <item>
      <title>Are Large Language Models Strategic Decision Makers? A Study of Performance and Bias in Two-Player Non-Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2407.04467</link>
      <description>arXiv:2407.04467v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) have been increasingly used in real-world settings, yet their strategic abilities remain largely unexplored. Game theory provides a good framework for assessing the decision-making abilities of LLMs in interactions with other agents. Although prior studies have shown that LLMs can solve these tasks with carefully curated prompts, they fail when the problem setting or prompt changes. In this work we investigate LLMs' behaviour in strategic games, Stag Hunt and Prisoner Dilemma, analyzing performance variations under different settings and prompts. Our results show that the tested state-of-the-art LLMs exhibit at least one of the following systematic biases: (1) positional bias, (2) payoff bias, or (3) behavioural bias. Subsequently, we observed that the LLMs' performance drops when the game configuration is misaligned with the affecting biases. Performance is assessed based on the selection of the correct action, one which agrees with the prompted preferred behaviours of both players. Alignment refers to whether the LLM's bias aligns with the correct action. For example, GPT-4o's average performance drops by 34% when misaligned. Additionally, the current trend of "bigger and newer is better" does not hold for the above, where GPT-4o (the current best-performing LLM) suffers the most substantial performance drop. Lastly, we note that while chain-of-thought prompting does reduce the effect of the biases on most models, it is far from solving the problem at the fundamental level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.04467v2</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Herr, Fernando Acero, Roberta Raileanu, Mar\'ia P\'erez-Ortiz, Zhibin Li</dc:creator>
    </item>
  </channel>
</rss>
