<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.LO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.LO</link>
    <description>cs.LO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.LO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Sep 2024 01:59:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Non-Cartesian Guarded Recursion with Daggers</title>
      <link>https://arxiv.org/abs/2409.14591</link>
      <description>arXiv:2409.14591v1 Announce Type: new 
Abstract: Guarded recursion is a framework allowing for a formalisation of streams in classical programming languages. The latter take their semantics in cartesian closed categories. However, some programming paradigms do not take their semantics in a cartesian setting; this is the case for concurrency, reversible and quantum programming for example. In this paper, we focus on reversible programming through the prism of dagger categories, which are categories that contain an involutive operator on morphisms. After presenting classical guarded recursion, we show how to introduce this framework into dagger categories. Given a dagger category, we build categories shown to be suitable for guarded recursion in multiple ways, via enrichment and fixed point theorems. Finally, we show that our construction is suitable as a model of reversible programming languages, such as symmetric pattern-matching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14591v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>math.CT</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Louis Lemonnier</dc:creator>
    </item>
    <item>
      <title>Syntax and semantics of multi-adjoint normal logic programming</title>
      <link>https://arxiv.org/abs/2409.14901</link>
      <description>arXiv:2409.14901v2 Announce Type: new 
Abstract: Multi-adjoint logic programming is a general framework with interesting features, which involves other positive logic programming frameworks such as monotonic and residuated logic programming, generalized annotated logic programs, fuzzy logic programming and possibilistic logic programming. One of the most interesting extensions of this framework is the possibility of considering a negation operator in the logic programs, which will improve its flexibility and the range of real applications.
  This paper introduces multi-adjoint normal logic programming, which is an extension of multi-adjoint logic programming including a negation operator in the underlying lattice. Beside the introduction of the syntax and semantics of this paradigm, we will provide sufficient conditions for the existence of stable models defined on a convex compact set of a euclidean space. Finally, we will consider a particular algebraic structure in which sufficient conditions can be given in order to ensure the unicity of stable models of multi-adjoint normal logic programs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14901v2</guid>
      <category>cs.LO</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.fss.2017.12.009</arxiv:DOI>
      <arxiv:journal_reference>Fuzzy Sets and Systems 345 (2018) 41-62</arxiv:journal_reference>
      <dc:creator>M. Eugenia Cornejo, David Lobo, Jes\'us Medina</dc:creator>
    </item>
    <item>
      <title>Space-time process algebra with asynchronous communication</title>
      <link>https://arxiv.org/abs/2409.15120</link>
      <description>arXiv:2409.15120v1 Announce Type: new 
Abstract: We introduce a process algebra that concerns the timed behaviour of distributed systems with a known spatial distribution. This process algebra provides a communication mechanism that deals with the fact that a datum sent at one point in space can only be received at another point in space at the point in time that the datum reaches that point in space. The integration operator used in related process algebras to model such a communication mechanism is absent from this process algebra. This is considered an advantage because, being a variable-binding operator, the integration operator does not really fit an algebraic approach and is not founded on established metatheory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15120v1</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>J. A. Bergstra, C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>Proof Automation with Large Language Models</title>
      <link>https://arxiv.org/abs/2409.14274</link>
      <description>arXiv:2409.14274v1 Announce Type: cross 
Abstract: Interactive theorem provers such as Coq are powerful tools to formally guarantee the correctness of software. However, using these tools requires significant manual effort and expertise. While Large Language Models (LLMs) have shown promise in automatically generating informal proofs in natural language, they are less effective at generating formal proofs in interactive theorem provers. In this paper, we conduct a formative study to identify common mistakes made by LLMs when asked to generate formal proofs. By analyzing 520 proof generation errors made by GPT-3.5, we found that GPT-3.5 often identified the correct high-level structure of a proof, but struggled to get the lower-level details correct. Based on this insight, we propose PALM, a novel generate-then-repair approach that first prompts an LLM to generate an initial proof and then leverages targeted symbolic methods to iteratively repair low-level problems. We evaluate PALM on a large dataset that includes more than 10K theorems. Our results show that PALM significantly outperforms other state-of-the-art approaches, successfully proving 76.6% to 180.4% more theorems. Moreover, PALM proves 1270 theorems beyond the reach of existing approaches. We also demonstrate the generalizability of PALM across different LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14274v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (ASE 2024)</arxiv:journal_reference>
      <dc:creator>Minghai Lu, Benjamin Delaware, Tianyi Zhang</dc:creator>
    </item>
    <item>
      <title>On logic and generative AI</title>
      <link>https://arxiv.org/abs/2409.14465</link>
      <description>arXiv:2409.14465v1 Announce Type: cross 
Abstract: A hundred years ago, logic was almost synonymous with foundational studies. The ongoing AI revolution raises many deep foundational problems involving neuroscience, philosophy, computer science, and logic. The goal of the following dialog is to provoke young logicians with a taste for foundations to notice the foundational problems raised by the AI revolution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14465v1</guid>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Bulletin of the EATCS 143, June 2024</arxiv:journal_reference>
      <dc:creator>Yuri Gurevich, Andreas Blass</dc:creator>
    </item>
    <item>
      <title>Snakes can be fooled into thinking they live in a tree</title>
      <link>https://arxiv.org/abs/2409.14525</link>
      <description>arXiv:2409.14525v1 Announce Type: cross 
Abstract: We construct a finitely generated group which is not virtually free, yet has decidable snake tiling problem. This shows that either a long-standing conjecture by Ballier and Stein (the characterization of groups with decidable domino problem as those virtually free ones) is false, or a question by Aubrun and Bitar has a positive answer (there exists a group for which the domino and snake problems are of different difficulty).</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14525v1</guid>
      <category>math.GR</category>
      <category>cs.LO</category>
      <category>math.DS</category>
      <category>math.LO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurent Bartholdi, Ville Salo</dc:creator>
    </item>
    <item>
      <title>Minimalistic System Modelling: Behaviours, Interfaces, and Local Reasoning</title>
      <link>https://arxiv.org/abs/2401.16109</link>
      <description>arXiv:2401.16109v2 Announce Type: replace 
Abstract: The infrastructure upon which the functioning of society depends is composed of complex ecosystems of systems. Consequently, we must reason about the properties of such ecosystems, which requires that we construct models of them. There are very many approaches to systems modelling, typically building on complex structural and dynamic frameworks. Our purpose here is to explore a modelling framework based on minimal assumptions, starting from a primitive notion of behaviour, and to show that such an approach allows the recovery of the key ideas, including a generalized CAP theorem, required for effective modelling of and reasoning about ecosystems of systems. We establish a logic of behaviours and use it to express local reasoning principles for the compositional structure of systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.16109v2</guid>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Didier Galmiche, Timo Lang, David Pym</dc:creator>
    </item>
    <item>
      <title>Traffic Scenario Logic: A Spatial-Temporal Logic for Modeling and Reasoning of Urban Traffic Scenarios</title>
      <link>https://arxiv.org/abs/2405.13715</link>
      <description>arXiv:2405.13715v2 Announce Type: replace 
Abstract: Formal representations of traffic scenarios can be used to generate test cases for the safety verification of autonomous driving. However, most existing methods are limited to highway or highly simplified intersection scenarios due to the intricacy and diversity of traffic scenarios. In response, we propose Traffic Scenario Logic (TSL), which is a spatial-temporal logic designed for modeling and reasoning of urban pedestrian-free traffic scenarios. TSL provides a formal representation of the urban road network that can be derived from OpenDRIVE, i.e., the de facto industry standard of high-definition maps for autonomous driving, enabling the representation of a broad range of traffic scenarios without discretization approximations. We implemented the reasoning of TSL using Telingo, i.e., a solver for temporal programs based on the Answer Set Programming, and tested it on different urban road layouts. Demonstrations show the effectiveness of TSL in test scenario generation and its potential value in areas like decision-making and control verification of autonomous driving. The code for TSL reasoning is opened.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13715v2</guid>
      <category>cs.LO</category>
      <category>cs.AI</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruolin Wang, Yuejiao Xu, Jianmin Ji</dc:creator>
    </item>
    <item>
      <title>Conditional and Modal Reasoning in Large Language Models</title>
      <link>https://arxiv.org/abs/2401.17169</link>
      <description>arXiv:2401.17169v3 Announce Type: replace-cross 
Abstract: The reasoning abilities of large language models (LLMs) are the topic of a growing body of research in AI and cognitive science. In this paper, we probe the extent to which twenty-five LLMs are able to distinguish logically correct inferences from logically fallacious ones. We focus on inference patterns involving conditionals (e.g., 'If Ann has a queen, then Bob has a jack') and epistemic modals (e.g., 'Ann might have an ace', 'Bob must have a king'). These inferences have been of special interest to logicians, philosophers, and linguists, since they play a central role in the fundamental human ability to reason about distal possibilities. Assessing LLMs on these inferences is thus highly relevant to the question of how much the reasoning abilities of LLMs match those of humans. Among the LLMs we tested, all but the GPT-4 model family often make basic mistakes with conditionals, though zero-shot chain-of-thought prompting helps them make fewer mistakes. Moreover, even the GPT-4 family displays logically inconsistent judgments across inference patterns involving epistemic modals, and almost all models give answers to certain complex conditional inferences widely discussed in the literature that do not match human judgments. These results highlight gaps in basic logical reasoning in today's LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17169v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wesley H. Holliday, Matthew Mandelkern, Cedegao E. Zhang</dc:creator>
    </item>
  </channel>
</rss>
