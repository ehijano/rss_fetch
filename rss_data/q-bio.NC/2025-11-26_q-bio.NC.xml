<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 02:41:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Human-computer interactions predict mental health</title>
      <link>https://arxiv.org/abs/2511.20179</link>
      <description>arXiv:2511.20179v1 Announce Type: new 
Abstract: Scalable assessments of mental illness, the leading driver of disability worldwide, remain a critical roadblock toward accessible and equitable care. Here, we show that human-computer interactions encode multiple dimensions of self-reported mental health and their changes over time.
  We introduce MAILA, a MAchine-learning framework for Inferring Latent mental states from digital Activity. We trained MAILA to predict 1.3 million mental-health self-reports from 20,000 cursor and touchscreen recordings recorded in 9,000 online participants. The dataset includes 2,000 individuals assessed longitudinally, 1,500 diagnosed with depression, and 500 with obsessive-compulsive disorder. MAILA tracks dynamic mental states along three orthogonal dimensions, generalizes across contexts, and achieves near-ceiling accuracy when predicting group-level mental health. The model translates from general to clinical populations, identifies individuals living with mental illness, and captures signatures of psychological function that are not conveyed by language.
  Our results demonstrate how everyday human-computer interactions can power passive, reliable, dynamic, and maximally scalable mental health assessments. The ability to decode mental states at zero marginal cost sets new benchmarks for precision medicine and public health, while raising important questions about privacy, agency, and autonomy online.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20179v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Veith Weilnhammer, Jefferson Ortega, David Whitney</dc:creator>
    </item>
    <item>
      <title>MIMIC-MJX: Neuromechanical Emulation of Animal Behavior</title>
      <link>https://arxiv.org/abs/2511.20532</link>
      <description>arXiv:2511.20532v1 Announce Type: new 
Abstract: The primary output of the nervous system is movement and behavior. While recent advances have democratized pose tracking during complex behavior, kinematic trajectories alone provide only indirect access to the underlying control processes. Here we present MIMIC-MJX, a framework for learning biologically-plausible neural control policies from kinematics. MIMIC-MJX models the generative process of motor control by training neural controllers that learn to actuate biomechanically-realistic body models in physics simulation to reproduce real kinematic trajectories. We demonstrate that our implementation is accurate, fast, data-efficient, and generalizable to diverse animal body models. Policies trained with MIMIC-MJX can be utilized to both analyze neural control strategies and simulate behavioral experiments, illustrating its potential as an integrative modeling framework for neuroscience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20532v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charles Y. Zhang (Harvard University), Yuanjia Yang (Salk Institute for Biological Studies), Aidan Sirbu (Mila), Elliott T. T. Abe (University of Washington), Emil W\"arnberg (Harvard University), Eric J. Leonardis (Salk Institute for Biological Studies), Diego E. Aldarondo (Harvard University), Adam Lee (Harvard University), Aaditya Prasad (Massachusetts Institute of Technology), Jason Foat (Salk Institute for Biological Studies), Kaiwen Bian (Salk Institute for Biological Studies), Joshua Park (Salk Institute for Biological Studies), Rusham Bhatt (Salk Institute for Biological Studies), Hutton Saunders (Salk Institute for Biological Studies), Akira Nagamori (Salk Institute for Biological Studies), Ayesha R. Thanawalla (Salk Institute for Biological Studies), Kee Wui Huang (Salk Institute for Biological Studies), Fabian Plum (Imperial College London), Hendrik K. Beck (Imperial College London), Steven W. Flavell (Massachusetts Institute of Technology), David Labonte (Imperial College London), Blake A. Richards (Mila), Bingni W. Brunton (University of Washington), Eiman Azim (Salk Institute for Biological Studies), Bence P. \"Olveczky (Harvard University), Talmo D. Pereira (Salk Institute for Biological Studies)</dc:creator>
    </item>
    <item>
      <title>Modeling Bioelectric State Transitions in Glial Cells: An ASAL-Inspired Computational Approach to Glioblastoma Initiation</title>
      <link>https://arxiv.org/abs/2511.19520</link>
      <description>arXiv:2511.19520v1 Announce Type: cross 
Abstract: Understanding how glioblastoma (GBM) emerges from initially healthy glial tissue requires models that integrate bioelectrical, metabolic, and multicellular dynamics. This work introduces an ASAL-inspired agent-based framework that simulates bioelectric state transitions in glial cells as a function of mitochondrial efficiency (Meff), ion-channel conductances, gap-junction coupling, and ROS dynamics. Using a 64x64 multicellular grid over 60,000 simulation steps, we show that reducing Meff below a critical threshold (~0.6) drives sustained depolarization, ATP collapse, and elevated ROS, reproducing key electrophysiological signatures associated with GBM. We further apply evolutionary optimization (genetic algorithms and MAP-Elites) to explore resilience, parameter sensitivity, and the emergence of tumor-like attractors. Early evolutionary runs converge toward depolarized, ROS-dominated regimes characterized by weakened electrical coupling and altered ionic transport. These results highlight mitochondrial dysfunction and disrupted bioelectric signaling as sufficient drivers of malignant-like transitions and provide a computational basis for probing the bioelectrical origins of oncogenesis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19520v1</guid>
      <category>physics.bio-ph</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wiktoria Agata Pawlak</dc:creator>
    </item>
    <item>
      <title>When Should Neural Data Inform Welfare? A Critical Framework for Policy Uses of Neuroeconomics</title>
      <link>https://arxiv.org/abs/2511.19548</link>
      <description>arXiv:2511.19548v1 Announce Type: cross 
Abstract: Neuroeconomics promises to ground welfare analysis in neural and computational evidence about how people value outcomes, learn from experience and exercise self-control. At the same time, policy and commercial actors increasingly invoke neural data to justify paternalistic regulation, "brain-based" interventions and new welfare measures. This paper asks under what conditions neural data can legitimately inform welfare judgements for policy rather than merely describing behaviour. I develop a non-empirical, model-based framework that links three levels: neural signals, computational decision models and normative welfare criteria. Within an actor-critic reinforcement-learning model, I formalise the inference path from neural activity to latent values and prediction errors and then to welfare claims. I show that neural evidence constrains welfare judgements only when the neural-computational mapping is well validated, the decision model identifies "true" interests versus context-dependent mistakes, and the welfare criterion is explicitly specified and defended. Applying the framework to addiction, neuromarketing and environmental policy, I derive a Neuroeconomic Welfare Inference Checklist for regulators and for designers of NeuroAI systems. The analysis treats brains and artificial agents as value-learning systems while showing that internal reward signals, whether biological or artificial, are computational quantities and cannot be treated as welfare measures without an explicit normative model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19548v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>econ.GN</category>
      <category>q-bio.NC</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Yiven (Louis),  Zhu</dc:creator>
    </item>
    <item>
      <title>While recognizing actions, LMMs struggle to detect core interaction events</title>
      <link>https://arxiv.org/abs/2511.20162</link>
      <description>arXiv:2511.20162v1 Announce Type: cross 
Abstract: Large multi-modal models (LMMs) show increasing performance in realistic visual tasks for images and, more recently, for videos. For example, given a video sequence, such models are able to describe in detail objects, the surroundings and dynamic actions. In this study, we explored the extent to which these models ground their semantic understanding in the actual visual input. Specifically, given sequences of hands interacting with objects, we asked models when and where the interaction begins or ends. For this purpose, we introduce a first of its kind, large-scale dataset with more than 20K annotated interactions on videos from the Something-Something-V2 dataset. 250 AMTurk human annotators labeled core interaction events, particularly when and where objects and agents become attached ('contact') or detached ('release'). We asked two LMMs (Qwen-2.5VL and GPT-4o) to locate these events in short videos, each with a single event. The results show that although the models can reliably name the target objects, identify the action and provide coherent reasoning, they consistently fail to identify the frame where the interaction begins or ends and cannot localize the event within the scene. Our findings suggest that in struggling to pinpoint the moment and location of physical contact that defines the interaction, the models lack the perceptual grounding required for deeper understanding of dynamic scenes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20162v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Harari, Michael Sidorov, Liel David, Chen Shterental, Abrham Kahsay Gebreselasie, Muhammad Haris Khan</dc:creator>
    </item>
    <item>
      <title>Mechano-chemical modeling of glia initiated secondary injury of neurons under mechanical load</title>
      <link>https://arxiv.org/abs/2511.20392</link>
      <description>arXiv:2511.20392v1 Announce Type: cross 
Abstract: Traumatic Brain Injury (TBI) results from an impact or concussion to the head with the injury being specifically characterized through pathological degradation at various biological length scales. Following injury, various mechanical modeling techniques have been proposed in the literature that seek to quantify neuronal-scale to tissue-scale metrics of brain damage. Broadly, the two categories of degradation encompass physiological deterioration of neurons and upregulation of chemical entities such as neurotransmitters which causes initiation of downstream pathophysiological effects. Despite the many contributing pathways, in this work, we delineate and model a potential glia-initiated injury pathway that leads to secondary injury. The goal of this work is to demonstrate a continuum framework which models the multiphysics of mechano-chemical interactions underlying TBI. Using a coupled PDE (partial differential equation) formulation and FEM (finite element method) discretization, the framework highlights evolution of field variables which spatio-temporally resolve mechanical metrics and chemical species across neuronal clusters. The modeling domain encompasses microglia, neurons and the extracellular matrix. The continuum framework used to model the mechano-chemical interactions assumes a three dimensional viscoelastic network to capture the mechanical response underlying proteins constituting the neuron microstructure and advection-diffusion equations modeling spatio-temporal evolution of chemical species. We use this framework to numerically estimate key concentrations of chemical species produced by the strain field. In this work, we identify key biomarkers within the labyrinth of molecular pathways and build a framework that captures the core mechano-chemical interactions. This framework is an attempt to quantify secondary injury and thus assist in developing targeted TBI treatments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20392v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Debabrata Auddya, Shiva Rudraraju</dc:creator>
    </item>
    <item>
      <title>Deep learning and whole-brain networks for biomarker discovery: modeling the dynamics of brain fluctuations in resting-state and cognitive tasks</title>
      <link>https://arxiv.org/abs/2412.19329</link>
      <description>arXiv:2412.19329v2 Announce Type: replace 
Abstract: Background: Brain network models offer insights into brain dynamics, but the utility of model-derived bifurcation parameters as biomarkers remains underexplored. Objective: This study evaluates bifurcation parameters from a whole-brain network model as biomarkers for distinguishing brain states associated with resting-state and task-based cognitive conditions. Methods: Synthetic BOLD signals were generated using a supercritical Hopf brain network model to train deep learning models for bifurcation parameter prediction. Inference was performed on Human Connectome Project data, including both resting-state and task-based conditions. Statistical analyses assessed the separability of brain states based on bifurcation parameter distributions. Results: Bifurcation parameter distributions differed significantly across task and resting-state conditions ($p &lt; 0.0001$ for all but one comparison). Task-based brain states exhibited higher bifurcation values compared to rest. Conclusion: Bifurcation parameters effectively differentiate cognitive and resting states, warranting further investigation as biomarkers for brain state characterization and neurological disorder assessment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19329v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41598-025-24702-4</arxiv:DOI>
      <arxiv:journal_reference>Sci Rep 15, 41005 (2025)</arxiv:journal_reference>
      <dc:creator>Facundo Roffet, Gustavo Deco, Claudio Delrieux, Gustavo Patow</dc:creator>
    </item>
    <item>
      <title>A Novel Brain-Computer Interface Architecture: The Brain-Muscle-Hand Interface for replicating the motor pathway</title>
      <link>https://arxiv.org/abs/2506.02013</link>
      <description>arXiv:2506.02013v2 Announce Type: replace 
Abstract: Myoelectric interfaces enable intuitive and natural control by decoding residual muscle activity, providing an effective pathway for motor restoration in individuals with preserved musculature. However, in patients with severe muscular atrophy or high-level spinal cord injury, the absence of reliable muscle activity renders myoelectric control infeasible. In such cases, motor brain-computer interfaces (BCIs) offer an alternative route. However, conventional brain-computer interface systems rely mainly on noisy cortical signals and classification-based decoding algorithms, which often result in low signal fidelity, limited controllability, and unstable real-time performance. Inspired by the motor pathway--an evolutionarily optimized system that filters, integrates, and transmits motor commands from the brain to the muscles--this study proposes the Brain-Muscle-Hand Interface (BMHI). BMHI decodes cortical EEG signals to reconstruct muscle-level EMG activity, functionally substituting for the muscles and enabling regression-based, continuous, and natural control via a myoelectric interface. To validate this architecture, we performed offline verification, comparative analysis, and online control experiments. Results demonstrate that: (1) the BMHI achieves a prediction accuracy of 0.79; (2) compared with conventional end-to-end brain-hand interfaces, it reduces training time by approximately eighteenfold while improving decoding accuracy; and (3) in online operation, the BMHI enables stable and efficient manipulation of both a virtual hand and a robotic arm. Compared with conventional BCIs, the BMHI, by replicating the motor pathway, enables continuous, stable, and naturally intuitive control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02013v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sun Ye, Zuo Cuiming, Zhang Rui, Shi Bin, Pang Yajing, Gao Lingyun, Zhao Bowei, Wang Jing, Yao Dezhong, Liu Gang</dc:creator>
    </item>
    <item>
      <title>Coevolutionary balance of resting-state brain networks in autism</title>
      <link>https://arxiv.org/abs/2507.09045</link>
      <description>arXiv:2507.09045v2 Announce Type: replace 
Abstract: Autism spectrum disorder (ASD) involves atypical brain organization, yet the large-scale functional principles underlying these alterations remain incompletely understood. Here we examine whether coevolutionary balance-a network-level energy measure derived from signed interactions and nodal activity states-captures disruptions in resting-state functional connectivity in autistic adults. Using ABIDE I resting-state fMRI data, we constructed whole-brain networks by combining binarized fALFF activity with signed functional correlations and quantified their coevolutionary energy. Compared with matched typically developing adults, the ASD group showed a characteristic redistribution of coevolutionary energy, with more negative global energy but higher (less negative) energy within the default mode network and altered energy in its interactions with dorsal attention and salience networks, indicating a reorganization rather than a uniform loss of balance in intrinsic network organization. These effects replicated across validation analyses with null models designed to disrupt link or node structure. Coevolutionary energy also showed modest but significant associations with ADI-R social and communication scores. Finally, incorporating coevolutionary features into a leakage-safe machine-learning classifier supported above-chance ASD versus typically developing (TD) discrimination on a held-out test set. These findings suggest that coevolutionary balance offers a compact, interpretable descriptor of altered resting-state network dynamics in autism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.09045v2</guid>
      <category>q-bio.NC</category>
      <category>physics.bio-ph</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. Rezaei Afshar, H. Pouretemad, G. Reza Jafari</dc:creator>
    </item>
    <item>
      <title>Effect of Dopamine in Enhancement of SNR of Cortico-Striatal-Thalamo-Cortical Loop Spiking</title>
      <link>https://arxiv.org/abs/2511.14466</link>
      <description>arXiv:2511.14466v2 Announce Type: replace 
Abstract: In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop have been investigated. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14466v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Barati, Ali Nayerifar, Mehdi Fardmanesh</dc:creator>
    </item>
    <item>
      <title>DecNefLab: A Modular and Interpretable Simulation Framework for Decoded Neurofeedback</title>
      <link>https://arxiv.org/abs/2511.14555</link>
      <description>arXiv:2511.14555v2 Announce Type: replace 
Abstract: Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.
  We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.
  We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.
  In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14555v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alexander Olza, Roberto Santana, David Soto</dc:creator>
    </item>
    <item>
      <title>Mesoscale tissue properties and electric fields in brain stimulation -- bridging the macroscopic and microscopic scales</title>
      <link>https://arxiv.org/abs/2511.16465</link>
      <description>arXiv:2511.16465v2 Announce Type: replace-cross 
Abstract: Accurate simulations of electric fields (E-fields) in brain stimulation depend on tissue conductivity representations that link macroscopic assumptions with underlying microscopic tissue structure. Mesoscale conductivity variations can produce meaningful changes in E-fields and neural activation thresholds but remain largely absent from standard macroscopic models. Recent microscopic models have suggested substantial local E-field perturbations and could, in principle, inform mesoscale conductivity. However, the quantitative validity of microscopic models is limited by fixation-related tissue distortion and incomplete extracellular-space reconstruction. We outline approaches that bridge macro- and microscales to derive consistent mesoscale conductivity distributions, providing a foundation for accurate multiscale models of E-fields and neural activation in brain stimulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16465v2</guid>
      <category>physics.bio-ph</category>
      <category>physics.app-ph</category>
      <category>physics.med-ph</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boshuo Wang, Torge Worbs, Minhaj A. Hussain, Aman S. Aberra, Axel Thielscher, Warren M. Grill, Angel V. Peterchev</dc:creator>
    </item>
  </channel>
</rss>
