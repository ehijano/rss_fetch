<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Sep 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Comparison of Epilepsy Induced by Ischemic Hypoxic Brain Injury and Hypoglycemic Brain Injury using Multilevel Fusion of Data Features</title>
      <link>https://arxiv.org/abs/2409.02957</link>
      <description>arXiv:2409.02957v1 Announce Type: cross 
Abstract: The study aims to investigate the similarities and differences in the brain damage caused by Hypoxia-Ischemia (HI), Hypoglycemia, and Epilepsy. Hypoglycemia poses a significant challenge in improving glycemic regulation for insulin-treated patients, while HI brain disease in neonates is associated with low oxygen levels. The study examines the possibility of using a combination of medical data and Electroencephalography (EEG) measurements to predict outcomes over a two-year period. The study employs a multilevel fusion of data features to enhance the accuracy of the predictions. Therefore this paper suggests a hybridized classification model for Hypoxia-Ischemia and Hypoglycemia, Epilepsy brain injury (HCM-BI). A Support Vector Machine is applied with clinical details to define the Hypoxia-Ischemia outcomes of each infant. The newborn babies are assessed every two years again to know the neural development results. A selection of four attributes is derived from the Electroencephalography records, and SVM does not get conclusions regarding the classification of diseases. The final feature extraction of the EEG signal is optimized by the Bayesian Neural Network (BNN) to get the clear health condition of Hypoglycemia and Epilepsy patients. Through monitoring and assessing physical effects resulting from Electroencephalography, The Bayesian Neural Network (BNN) is used to extract the test samples with the most log data and to report hypoglycemia and epilepsy Keywords- Hypoxia-Ischemia , Hypoglycemia , Epilepsy , Multilevel Fusion of Data Features , Bayesian Neural Network (BNN) , Support Vector Machine (SVM)</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02957v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <arxiv:DOI>10.54216/FPA.100106</arxiv:DOI>
      <arxiv:journal_reference>Fusion: Practice and Applications Volume 10 , Issue 1 , PP: 100-115, 2023</arxiv:journal_reference>
      <dc:creator>Sameer Kadem, Noor Sami, Ahmed Elaraby, Shahad Alyousif, Mohammed Jalil, M. Altaee, Muntather Almusawi, A. Ghany Ismaeel, Ali Kamil Kareem, Massila Kamalrudin, Adnan Allwi ftaiet</dc:creator>
    </item>
    <item>
      <title>Inverse decision-making using neural amortized Bayesian actors</title>
      <link>https://arxiv.org/abs/2409.03710</link>
      <description>arXiv:2409.03710v1 Announce Type: cross 
Abstract: Bayesian observer and actor models have provided normative explanations for many behavioral phenomena in perception, sensorimotor control, and other areas of cognitive science and neuroscience. They attribute behavioral variability and biases to different interpretable entities such as perceptual and motor uncertainty, prior beliefs, and behavioral costs. However, when extending these models to more complex tasks with continuous actions, solving the Bayesian decision-making problem is often analytically intractable. Moreover, inverting such models to perform inference over their parameters given behavioral data is computationally even more difficult. Therefore, researchers typically constrain their models to easily tractable components, such as Gaussian distributions or quadratic cost functions, or resort to numerical methods. To overcome these limitations, we amortize the Bayesian actor using a neural network trained on a wide range of different parameter settings in an unsupervised fashion. Using the pre-trained neural network enables performing gradient-based Bayesian inference of the Bayesian actor model's parameters. We show on synthetic data that the inferred posterior distributions are in close alignment with those obtained using analytical solutions where they exist. Where no analytical solution is available, we recover posterior distributions close to the ground truth. We then show that identifiability problems between priors and costs can arise in more complex cost functions. Finally, we apply our method to empirical data and show that it explains systematic individual differences of behavioral patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03710v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dominik Straub, Tobias F. Niehues, Jan Peters, Constantin A. Rothkopf</dc:creator>
    </item>
    <item>
      <title>Dynamics of Supervised and Reinforcement Learning in the Non-Linear Perceptron</title>
      <link>https://arxiv.org/abs/2409.03749</link>
      <description>arXiv:2409.03749v1 Announce Type: cross 
Abstract: The ability of a brain or a neural network to efficiently learn depends crucially on both the task structure and the learning rule. Previous works have analyzed the dynamical equations describing learning in the relatively simplified context of the perceptron under assumptions of a student-teacher framework or a linearized output. While these assumptions have facilitated theoretical understanding, they have precluded a detailed understanding of the roles of the nonlinearity and input-data distribution in determining the learning dynamics, limiting the applicability of the theories to real biological or artificial neural networks. Here, we use a stochastic-process approach to derive flow equations describing learning, applying this framework to the case of a nonlinear perceptron performing binary classification. We characterize the effects of the learning rule (supervised or reinforcement learning, SL/RL) and input-data distribution on the perceptron's learning curve and the forgetting curve as subsequent tasks are learned. In particular, we find that the input-data noise differently affects the learning speed under SL vs. RL, as well as determines how quickly learning of a task is overwritten by subsequent learning. Additionally, we verify our approach with real data using the MNIST dataset. This approach points a way toward analyzing learning dynamics for more-complex circuit architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.03749v1</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Schmid, James M. Murray</dc:creator>
    </item>
    <item>
      <title>Ordinal Characterization of Similarity Judgments</title>
      <link>https://arxiv.org/abs/2310.07543</link>
      <description>arXiv:2310.07543v2 Announce Type: replace 
Abstract: Characterizing judgments of similarity within a perceptual or semantic domain, and making inferences about the underlying structure of this domain from these judgments, has an increasingly important role in cognitive and systems neuroscience. We present a new framework for this purpose that makes limited assumptions about how perceptual distances are converted into similarity judgments. The approach starts from a dataset of empirical judgments of relative similarities: the fraction of times that a subject chooses one of two comparison stimuli to be more similar to a reference stimulus. These empirical judgments provide Bayesian estimates of underling choice probabilities. From these estimates, we derive indices that characterize the set of judgments in three ways: compatibility with a symmetric dis-similarity, compatibility with an ultrametric space, and compatibility with an additive tree. Each of the indices is derived from rank-order relationships among the choice probabilities that, as we show, are necessary and sufficient for local consistency with the three respective characteristics. We illustrate this approach with simulations and example psychophysical datasets of dis-similarity judgments in several visual domains and provide code that implements the analyses at https://github.com/jvlab/simrank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07543v2</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan D. Victor, Guillermo Aguilar, Suniyya A. Waraich</dc:creator>
    </item>
    <item>
      <title>Role of Data-driven Regional Growth Model in Shaping Brain Folding Patterns</title>
      <link>https://arxiv.org/abs/2408.17334</link>
      <description>arXiv:2408.17334v2 Announce Type: replace 
Abstract: The surface morphology of the developing mammalian brain is crucial for understanding brain function and dysfunction. Computational modeling offers valuable insights into the underlying mechanisms for early brain folding. Recent findings indicate significant regional variations in brain tissue growth, while the role of these variations in cortical development remains unclear. In this study, we unprecedently explored how regional cortical growth affects brain folding patterns using computational simulation. We first developed growth models for typical cortical regions using machine learning (ML)-assisted symbolic regression, based on longitudinal real surface expansion and cortical thickness data from prenatal and infant brains derived from over 1,000 MRI scans of 735 pediatric subjects with ages ranging from 29 post-menstrual weeks to 24 months. These models were subsequently integrated into computational software to simulate cortical development with anatomically realistic geometric models. We comprehensively quantified the resulting folding patterns using multiple metrics such as mean curvature, sulcal depth, and gyrification index. Our results demonstrate that regional growth models generate complex brain folding patterns that more closely match actual brains structures, both quantitatively and qualitatively, compared to conventional uniform growth models. Growth magnitude plays a dominant role in shaping folding patterns, while growth trajectory has a minor influence. Moreover, multi-region models better capture the intricacies of brain folding than single-region models. Our results underscore the necessity and importance of incorporating regional growth heterogeneity into brain folding simulations, which could enhance early diagnosis and treatment of cortical malformations and neurodevelopmental disorders such as cerebral palsy and autism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17334v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CE</category>
      <category>cs.SC</category>
      <category>q-bio.TO</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jixin Hou, Zhengwang Wu, Xianyan Chen, Li Wang, Dajiang Zhu, Tianming Liu, Gang Li, Xianqiao Wang</dc:creator>
    </item>
    <item>
      <title>The generalized Hierarchical Gaussian Filter</title>
      <link>https://arxiv.org/abs/2305.10937</link>
      <description>arXiv:2305.10937v2 Announce Type: replace-cross 
Abstract: Hierarchical Bayesian models of perception and learning feature prominently in contemporary cognitive neuroscience where, for example, they inform computational concepts of mental disorders. This includes predictive coding and hierarchical Gaussian filtering (HGF), which differ in the nature of hierarchical representations. Predictive coding assumes that higher levels in a given hierarchy influence the state (value) of lower levels. In HGF, however, higher levels determine the rate of change at lower levels. Here, we extend the space of generative models underlying HGF to include a form of nonlinear hierarchical coupling between state values akin to predictive coding and artificial neural networks in general. We derive the update equations corresponding to this generalization of HGF and conceptualize them as connecting a network of (belief) nodes where parent nodes either predict the state of child nodes or their rate of change. This enables us to (1) create modular architectures with generic computational steps in each node of the network, and (2) disclose the hierarchical message passing implied by generalized HGF models and to compare this to comparable schemes under predictive coding. We find that the algorithmic architecture instantiated by the generalized HGF is largely compatible with that of predictive coding but extends it with some unique predictions which arise from precision and volatility related computations. Our developments enable highly flexible implementations of hierarchical Bayesian models for empirical data analysis and are available as open source software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.10937v2</guid>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Fri, 06 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lilian Aline Weber, Peter Thestrup Waade, Nicolas Legrand, Anna Hedvig M{\o}ller, Klaas Enno Stephan, Christoph Mathys</dc:creator>
    </item>
  </channel>
</rss>
