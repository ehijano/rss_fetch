<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 11 Apr 2025 01:42:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Faster Algorithms for Reverse Shortest Path in Unit-Disk Graphs and Related Geometric Optimization Problems: Improving the Shrink-and-Bifurcate Technique</title>
      <link>https://arxiv.org/abs/2504.06434</link>
      <description>arXiv:2504.06434v1 Announce Type: new 
Abstract: In a series of papers, Avraham, Filtser, Kaplan, Katz, and Sharir (SoCG'14), Kaplan, Katz, Saban, and Sharir (ESA'23), and Katz, Saban, and Sharir (ESA'24) studied a class of geometric optimization problems -- including reverse shortest path in unweighted and weighted unit-disk graphs, discrete Fr\'{e}chet distance with one-sided shortcuts, and reverse shortest path in visibility graphs on 1.5-dimensional terrains -- for which standard parametric search does not work well due to a lack of efficient parallel algorithms for the corresponding decision problems. The best currently known algorithms for all the above problems run in $O^*(n^{6/5})=O^*(n^{1.2})$ time (ignoring subpolynomial factors), and they were obtained using a technique called \emph{shrink-and-bifurcate}. We improve the running time to $\tilde{O}(n^{8/7}) \approx O(n^{1.143})$ for these problems. Furthermore, specifically for reverse shortest path in unweighted unit-disk graphs, we improve the running time further to $\tilde{O}(n^{9/8})=\tilde{O}(n^{1.125})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06434v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timothy M. Chan, Zhengcheng Huang</dc:creator>
    </item>
    <item>
      <title>Single-Source Shortest Path Problem in Weighted Disk Graphs</title>
      <link>https://arxiv.org/abs/2504.06534</link>
      <description>arXiv:2504.06534v1 Announce Type: new 
Abstract: In this paper, we present efficient algorithms for the single-source shortest path problem in weighted disk graphs. A disk graph is the intersection graph of a family of disks in the plane. Here, the weight of an edge is defined as the Euclidean distance between the centers of the disks corresponding to the endpoints of the edge. Given a family of $n$ disks in the plane whose radii lie in $[1,\Psi]$ and a source disk, we can compute a shortest path tree from a source vertex in the weighted disk graph in $O(n\log^2 n \log \Psi)$ time. Moreover, in the case that the radii of disks are arbitrarily large, we can compute a shortest path tree from a source vertex in the weighted disk graph in $O(n\log^4 n)$ time. This improves the best-known algorithm running in $O(n\log^6 n)$ time presented in ESA'23.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06534v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shinwoo An, Eunjin Oh, Jie Xue</dc:creator>
    </item>
    <item>
      <title>Handling LP-Rounding for Hierarchical Clustering and Fitting Distances by Ultrametrics</title>
      <link>https://arxiv.org/abs/2504.06700</link>
      <description>arXiv:2504.06700v1 Announce Type: new 
Abstract: We consider the classic correlation clustering problem in the hierarchical setting. Given a complete graph $G=(V,E)$ and $\ell$ layers of input information, where the input of each layer consists of a nonnegative weight and a labeling of the edges with either + or -, this problem seeks to compute for each layer a partition of $V$ such that the partition for any non-top layer subdivides the partition in the upper-layer and the weighted number of disagreements over the layers is minimized.
  Hierarchical correlation clustering is a natural formulation of the classic problem of fitting distances by ultrametrics, which is further known as numerical taxonomy in the literature. While single-layer correlation clustering received wide attention since it was introduced and major progress evolved in the past three years, few is known for this problem in the hierarchical setting. The lack of understanding and adequate tools is reflected in the large approximation ratio known for this problem originating from 2021.
  In this work we make both conceptual and technical contributions towards the hierarchical clustering problem. We present a simple paradigm that greatly facilitates LP-rounding in hierarchical clustering, illustrated with an algorithm providing a significantly improved approximation guarantee of 25.7846 for the hierarchical correlation clustering problem. Our techniques reveal surprising new properties of the formulation presented and subsequently used in previous works for hierarchical clustering over the past two decades. This provides an interpretation on the core problem in hierarchical clustering as the problem of finding cuts with prescribed properties regarding average distances.
  We further illustrate this perspective by showing that a direct application of the techniques gives a simple alternative to the state-of-the-art result for the ultrametric violation distance problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06700v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hyung-Chan An, Mong-Jen Kao, Changyeol Lee, Mu-Ting Lee</dc:creator>
    </item>
    <item>
      <title>Matching and Edge Cover in Temporal Graphs</title>
      <link>https://arxiv.org/abs/2504.06762</link>
      <description>arXiv:2504.06762v1 Announce Type: new 
Abstract: Temporal graphs are a special class of graphs for which a temporal component is added to edges, that is, each edge possesses a set of times at which it is available and can be traversed. Many classical problems on graphs can be translated to temporal graphs, and the results may differ. In this paper, we define the Temporal Edge Cover and Temporal Matching problems and show that they are NP-complete even when fixing the lifetime or when the underlying graph is a tree. We then describe two FPT algorithms, with parameters lifetime and treewidth, that solve the two problems. We also find lower bounds for the approximation of the two problems and give two approximation algorithms which match these bounds. Finally, we discuss the differences between the problems in the temporal and the static framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06762v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lapo Cioni, Riccardo Dondi, Andrea Marino, Jason Schoeters, Ana Silva</dc:creator>
    </item>
    <item>
      <title>Grouping Strategies on Two-Phase Methods for Bi-objective Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2504.06869</link>
      <description>arXiv:2504.06869v1 Announce Type: new 
Abstract: Two-phase methods are commonly used to solve bi-objective combinatorial optimization problems. In the first phase, all extreme supported nondominated points are generated through a dichotomic search. This phase also allows the identification of search zones that may contain other nondominated points. The second phase focuses on exploring these search zones to locate the remaining points, which typically accounts for most of the computational cost. Ranking algorithms are frequently employed to explore each zone individually, but this approach leads to redundancies, causing multiple visits to the same solutions. To mitigate these redundancies, we propose several strategies that group adjacent zones, allowing a single run of the ranking algorithm for the entire group. Additionally, we explore an implicit grouping approach based on a new concept of coverage. Our experiments on the Bi-Objective Spanning Tree Problem demonstrate the beneficial impact of these grouping strategies when combined with coverage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06869v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe O. Mota, Lu\'is Paquete, Daniel Vanderpooten</dc:creator>
    </item>
    <item>
      <title>Coreset Strikes Back: Improved Parameterized Approximation Schemes for (Constrained) k-Median/Means</title>
      <link>https://arxiv.org/abs/2504.06980</link>
      <description>arXiv:2504.06980v1 Announce Type: new 
Abstract: Algorithmic scatter dimension is a notion of metric spaces introduced recently by Abbasi et al. (FOCS 2023), which unifies many well-known metric spaces, including continuous Euclidean space, bounded doubling space, planar and bounded treewidth metrics. Recently, Bourneuf and Pilipczuk (SODA 2025) showed that metrics induced by graphs from any fixed proper minor closed graph class have bounded scatter dimension. Abbasi et al. presented a unified approach to obtain EPASes (i.e., $(1+\epsilon)$-approximations running in time FPT in $k$ and $\epsilon$) for $k$-Clustering in metrics of bounded scatter dimension. However, a seemingly inherent limitation of their approach was that it could only handle clustering objectives where each point was assigned to the closest chosen center. They explicitly asked, if there exist EPASes for constrained $k$-Clustering in metrics of bounded scatter dimension.
  We present a unified framework which yields EPASes capacitated and fair $k$-Median/Means in metrics of bounded algorithmic scatter dimension. Our framework exploits coresets for such constrained clustering problems in a novel manner, and notably requires only coresets of size $(k\log n/\epsilon)^{O(1)}$, which are usually constuctible even in general metrics. Note that due to existing lower bounds it is impossible to obtain such an EPAS for Capacitated $k$-Center, thus essentially answering the complete spectrum of the question.
  Our results on capacitated and fair $k$-Median/Means provide the first EPASes for these problems in broad families of metric spaces. Earlier such results were only known in continuous Euclidean spaces due to Cohen-Addad &amp; Li, (ICALP 2019), and Bandyapadhyay, Fomin &amp; Simonov, (ICALP 2021; JCSS 2024), respectively. Along the way, we obtain faster EPASes for uncapacitated $k$-Median/Means, improving upon the running time of the algorithm by Abbasi et al.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06980v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sujoy Bhore, Ameet Gadekar, Tanmay Inamdar</dc:creator>
    </item>
    <item>
      <title>Flexible Graph Similarity Computation With A Proactive Optimization Strategy</title>
      <link>https://arxiv.org/abs/2504.06533</link>
      <description>arXiv:2504.06533v1 Announce Type: cross 
Abstract: Graph Edit Distance (GED) is an important similarity measure in graph retrieval, which quantifies the minimum cost of transforming one graph into another through edit operations, and offers flexibility by allowing customizable operation costs. Recent learning-based approaches approximate GEDs with the distances between representations in vector spaces. However, these methods often struggle with varying operation costs due to neglecting the impact of these costs on determining optimal graph mappings. Furthermore, they rely on isolated node distances as guidance, necessitating inefficient reactive refinements of mappings. To address these issues, we propose Graph Edit Network (GEN), a novel learning-based approach for flexible GED computation. By identifying the limitations of existing methods in capturing flexibility of GED, we introduce a principled yet simple solution that incorporates the operation costs before establishing mappings. To improve matching efficiency, we propose a strategy that proactively optimizes guidance from a graph perspective. This strategy initializes guidance as each node's alignment difficulty and captures the interdependencies between matches within and across graphs through a difficulty propagation mechanism, enabling more informed decisions. As a result, GEN selects optimal matches in a single step, minimizing the need for costly refinements. Results on real-world and synthetic datasets demonstrate the effectiveness, time efficiency, and adaptability of GEN, achieving up to 37.8\% error reduction and 72.7\% inference time reduction compared with state-of-the-art models, while performing robustly under varying cost settings and graph sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06533v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhouyang Liu, Ning Liu, Yixin Chen, Jiezhong He, Dongsheng Li</dc:creator>
    </item>
    <item>
      <title>Mixed-Precision in High-Order Methods: the Impact of Floating-Point Precision on the ADER-DG Algorithm</title>
      <link>https://arxiv.org/abs/2504.06889</link>
      <description>arXiv:2504.06889v1 Announce Type: cross 
Abstract: We present a mixed-precision implementation of the high-order discontinuous Galerkin method with ADER time stepping (ADER-DG) for solving hyperbolic systems of partial differential equations (PDEs) in the hyperbolic PDE engine ExaHyPE. The implementation provides a simple API extension for specifying the numerical precision for individual kernels, and thus allows for testing the effect of low and mixed precision on the accuracy of the solution. To showcase this, we study the impact of precision on the overall convergence order and actual accuracy of the method as achieved for four common hyperbolic PDE systems and five relevant scenarios that feature an analytic solution. For all scenarios, we also assess how sensitive each kernel of the ADER-DG algorithm is to using double, single or even half precision. This addresses the question where thoughtful adoption of mixed precision can mitigate hurtful effects of low precision on the overall simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.06889v1</guid>
      <category>math.NA</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marc Marot-Lassauzaie, Michael Bader</dc:creator>
    </item>
    <item>
      <title>A Global Analysis of the Primal-Dual Method for Pliable Families</title>
      <link>https://arxiv.org/abs/2308.15714</link>
      <description>arXiv:2308.15714v4 Announce Type: replace 
Abstract: We study a core algorithmic problem in network design called ${F}$-augmentation that involves increasing the connectivity of a given family of cuts ${F}$. Over 30 years ago, Williamson et al. (STOC `93) provided a 2-approximation primal-dual algorithm when ${F}$ is a so-called uncrossable family but extending their results to families that are non-uncrossable has remained a challenging question.
  In this paper, we introduce the novel concept of the crossing density of a set family and show how this opens up a completely new approach to analyzing primal-dual algorithms. We study pliable families, a strict generalization of uncrossable families introduced by Bansal et al. (ICALP `23), and provide the first approximation algorithm for ${F}$-augmentation of general pliable families.
  We also improve on the results in Bansal et al. (ICALP `23) by providing a 6-approximation algorithm for the ${F}$-augmentation problem when ${F}$ is a family of near min-cuts. This immediately improves approximation factors for the Capacitated Network Design Problem.
  Finally, we study the $(p,3)$-flexible graph connectivity problem. By carefully analyzing the structure of feasible solutions and using the techniques developed in this paper, we provide the first constant factor approximation algorithm for this problem exhibiting an 12-approximation algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15714v4</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ishan Bansal</dc:creator>
    </item>
    <item>
      <title>Understanding the Cluster LP for Correlation Clustering</title>
      <link>https://arxiv.org/abs/2404.17509</link>
      <description>arXiv:2404.17509v2 Announce Type: replace 
Abstract: In the classic Correlation Clustering problem introduced by Bansal, Blum, and Chawla~(FOCS 2002), the input is a complete graph where edges are labeled either $+$ or $-$, and the goal is to find a partition of the vertices that minimizes the sum of the +edges across parts plus the sum of the -edges within parts. In recent years, Chawla, Makarychev, Schramm and Yaroslavtsev~(STOC 2015) gave a 2.06-approximation by providing a near-optimal rounding of the standard LP, and Cohen-Addad, Lee, Li, and Newman~(FOCS 2022, 2023) finally bypassed the integrality gap of 2 for this LP giving a $1.73$-approximation for the problem.
  In order to create a simple and unified framework for Correlation Clustering similar to those for {\em typical} approximate optimization tasks, we propose the {\em cluster LP} as a strong linear program that might tightly capture the approximability of Correlation Clustering. It unifies all the previous relaxations for the problem.
  We demonstrate the power of the cluster LP by presenting a simple rounding algorithm, and providing two analyses, one analytically proving a 1.49-approximation and the other solving a factor-revealing SDP to show a 1.437-approximation. Both proofs introduce principled methods by which to analyze the performance of the algorithm, resulting in a significantly improved approximation guarantee.
  Finally, we prove an integrality gap of $4/3$ for the cluster LP, showing our 1.437-upper bound cannot be drastically improved. Our gap instance directly inspires an improved NP-hardness of approximation with a ratio $24/23 \approx 1.042$; no explicit hardness ratio was known before.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17509v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3618260.3649749</arxiv:DOI>
      <dc:creator>Nairen Cao, Vincent Cohen-Addad, Euiwoong Lee, Shi Li, Alantha Newman, Lukas Vogl</dc:creator>
    </item>
    <item>
      <title>Locally Stationary Distributions: A Framework for Analyzing Slow-Mixing Markov Chains</title>
      <link>https://arxiv.org/abs/2405.20849</link>
      <description>arXiv:2405.20849v3 Announce Type: replace 
Abstract: Many natural Markov chains fail to mix to their stationary distribution in polynomially many steps. Often, this slow mixing is inevitable since it is computationally intractable to sample from their stationary measure.
  Nevertheless, Markov chains can be shown to always converge quickly to measures that are locally stationary, i.e., measures that don't change over a small number of steps. These locally stationary measures are analogous to local minima in continuous optimization, while stationary measures correspond to global minima.
  While locally stationary measures can be statistically far from stationary measures, do they enjoy provable theoretical guarantees that have algorithmic implications? We study this question in this work and demonstrate three algorithmic applications of locally stationary measures:
  1. We show that Glauber dynamics on the hardcore model can be used to find independent sets of size $\Omega\left(\frac{\log d}{d} \cdot n\right)$ in triangle-free graphs of degree at most $d$.
  2. Let $W$ be a symmetric real matrix with bounded spectral diameter and $v$ be a unit vector. Given the matrix $M = \lambda vv^\top + W$ with a planted rank-one spike along vector $v$, for sufficiently large constant $\lambda$, Glauber dynamics on the Ising model defined by $M$ samples vectors $x \in \{\pm 1\}^n$ that have constant correlation with the vector $v$.
  3. Let $M = A_{\mathbf{G}} - \frac{d}{n}\mathbf{1}\mathbf{1}^\top$ be a centered version of the adjacency matrix where the graph $\mathbf{G}$ is drawn from a sparse 2-community stochastic block model. We show that for sufficiently large constant signal-to-noise ratio, Glauber dynamics on the Ising model defined by $M$ samples vectors $x \in \{\pm 1\}^n$ that have constant correlation with the hidden community vector $\mathbf{\sigma}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20849v3</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuikui Liu, Sidhanth Mohanty, Prasad Raghavendra, Amit Rajaraman, David X. Wu</dc:creator>
    </item>
    <item>
      <title>Concurrent Composition for Differentially Private Continual Mechanisms</title>
      <link>https://arxiv.org/abs/2411.03299</link>
      <description>arXiv:2411.03299v2 Announce Type: replace 
Abstract: Many intended uses of differential privacy involve a $\textit{continual mechanism}$ that is set up to run continuously over a long period of time, making more statistical releases as either queries come in or the dataset is updated. In this paper, we give the first general treatment of privacy against $\textit{adaptive}$ adversaries for mechanisms that support dataset updates and a variety of queries, all arbitrarily interleaved. It also models a very general notion of neighboring, that includes both event-level and user-level privacy.
  We prove several $\textit{concurrent}$ composition theorems for continual mechanisms, which ensure privacy even when an adversary can interleave queries and dataset updates to the different composed mechanisms. Previous concurrent composition theorems for differential privacy were only for the case when the dataset is static, with no adaptive updates. Moreover, we also give the first interactive and continual generalizations of the "parallel composition theorem" for noninteractive differential privacy. Specifically, we show that the analogue of the noninteractive parallel composition theorem holds if either there are no adaptive dataset updates or each of the composed mechanisms satisfies pure differential privacy, but it fails to hold for composing approximately differentially private mechanisms with dataset updates.
  We then formalize a set of general conditions on a continual mechanism $M$ that runs multiple continual sub-mechanisms such that the privacy guarantees of $M$ follow directly using the above concurrent composition theorems on the sub-mechanisms, without further privacy loss. This enables us to give a simpler and more modular privacy analysis of a recent continual histogram mechanism of Henzinger, Sricharan, and Steiner. In the case of approximate DP, ours is the first proof showing that its privacy holds against adaptive adversaries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03299v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monika Henzinger, Roodabeh Safavi, Salil Vadhan</dc:creator>
    </item>
  </channel>
</rss>
