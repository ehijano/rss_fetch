<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Jul 2025 01:24:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>EEG-fused Digital Twin Brain for Autonomous Driving in Virtual Scenarios</title>
      <link>https://arxiv.org/abs/2507.12263</link>
      <description>arXiv:2507.12263v1 Announce Type: new 
Abstract: Current methodologies typically integrate biophysical brain models with functional magnetic resonance imaging(fMRI) data - while offering millimeter-scale spatial resolution (0.5-2 mm^3 voxels), these approaches suffer from limited temporal resolution (&gt;0.5 Hz) for tracking rapid neural dynamics during continuous tasks. Conversely, Electroencephalogram (EEG) provides millisecond-scale temporal precision (&lt;=1 ms sampling rate) for real-time guidance of continuous task execution, albeit constrained by low spatial resolution. To reconcile these complementary modalities, we present a generalizable Bayesian inference framework that integrates high-spatial-resolution structural MRI(sMRI) with high-temporal-resolution EEG to construct a biologically realistic digital twin brain(DTB) model. The framework establishes voxel-wise mappings between millisecond-scale EEG and sMRI-derived spiking networks, while demonstrating its translational potential through a brain-inspired autonomous driving simulation. Our EEG-DTB model achieves capabilities: (1) Biologically-plausible EEG signal generation (0.88 resting-state,0.60 task-state correlation), with simulated signals in task-state yielding steering predictions outperforming both chance and empirical signals (p&lt;0.05); (2) Successful autonomous driving in the CARLA simulator using decoded steering angles. The proposed approach pioneers a new paradigm for studying sensorimotor integration and for mechanistic studies of perception-action cycles and the development of brain-inspired control systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12263v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yubo Hou, Zhengxin Zhang, Ziyi Wang, Wenlian Lu, Jianfeng Feng, Taiping Zeng</dc:creator>
    </item>
    <item>
      <title>Spontaneous Spatial Cognition Emerges during Egocentric Video Viewing through Non-invasive BCI</title>
      <link>https://arxiv.org/abs/2507.12417</link>
      <description>arXiv:2507.12417v1 Announce Type: new 
Abstract: Humans possess a remarkable capacity for spatial cognition, allowing for self-localization even in novel or unfamiliar environments. While hippocampal neurons encoding position and orientation are well documented, the large-scale neural dynamics supporting spatial representation, particularly during naturalistic, passive experience, remain poorly understood. Here, we demonstrate for the first time that non-invasive brain-computer interfaces (BCIs) based on electroencephalography (EEG) can decode spontaneous, fine-grained egocentric 6D pose, comprising three-dimensional position and orientation, during passive viewing of egocentric video. Despite EEG's limited spatial resolution and high signal noise, we find that spatially coherent visual input (i.e., continuous and structured motion) reliably evokes decodable spatial representations, aligning with participants' subjective sense of spatial engagement. Decoding performance further improves when visual input is presented at a frame rate of 100 ms per image, suggesting alignment with intrinsic neural temporal dynamics. Using gradient-based backpropagation through a neural decoding model, we identify distinct EEG channels contributing to position -- and orientation specific -- components, revealing a distributed yet complementary neural encoding scheme. These findings indicate that the brain's spatial systems operate spontaneously and continuously, even under passive conditions, challenging traditional distinctions between active and passive spatial cognition. Our results offer a non-invasive window into the automatic construction of egocentric spatial maps and advance our understanding of how the human mind transforms everyday sensory experience into structured internal representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12417v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <category>eess.SP</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Weichen Dai, Yuxuan Huang, Li Zhu, Dongjun Liu, Yu Zhang, Qibin Zhao, Andrzej Cichocki, Fabio Babiloni, Ke Li, Jianyu Qiu, Gangyong Jia, Wanzeng Kong, Qing Wu</dc:creator>
    </item>
    <item>
      <title>Foundation Models for Brain Signals: A Critical Review of Current Progress and Future Directions</title>
      <link>https://arxiv.org/abs/2507.11783</link>
      <description>arXiv:2507.11783v1 Announce Type: cross 
Abstract: Patterns of electrical brain activity recorded via electroencephalography (EEG) offer immense value for scientific and clinical investigations. The inability of supervised EEG encoders to learn robust EEG patterns and their over-reliance on expensive signal annotations have sparked a transition towards general-purpose self-supervised EEG encoders, i.e., EEG foundation models (EEG-FMs), for robust and scalable EEG feature extraction. However, the real-world readiness of early EEG-FMs and the rubric for long-term research progress remain unclear. A systematic and comprehensive review of first-generation EEG-FMs is therefore necessary to understand the current state-of-the-art and identify key directions for future EEG-FMs. To that end, this study reviews 10 early EEG-FMs and presents a critical synthesis of their methodology, empirical findings, and outstanding research gaps. We find that most EEG-FMs adopt a sequence-based modeling scheme that relies on transformer-based backbones and the reconstruction of masked sequences for self-supervision. However, model evaluations remain heterogeneous and largely limited, making it challenging to assess their practical off-the-shelf utility. In addition to adopting standardized and realistic evaluations, future work should demonstrate more substantial scaling effects and make principled and trustworthy choices throughout the EEG representation learning pipeline. We believe that developing benchmarks, software tools, technical methodologies, and applications in collaboration with domain experts may further advance the translational utility and real-world adoption of EEG-FMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11783v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gayal Kuruppu, Neeraj Wagh, Yogatheesan Varatharajah</dc:creator>
    </item>
    <item>
      <title>Graph Representations for Reading Comprehension Analysis using Large Language Model and Eye-Tracking Biomarker</title>
      <link>https://arxiv.org/abs/2507.11972</link>
      <description>arXiv:2507.11972v1 Announce Type: cross 
Abstract: Reading comprehension is a fundamental skill in human cognitive development. With the advancement of Large Language Models (LLMs), there is a growing need to compare how humans and LLMs understand language across different contexts and apply this understanding to functional tasks such as inference, emotion interpretation, and information retrieval. Our previous work used LLMs and human biomarkers to study the reading comprehension process. The results showed that the biomarkers corresponding to words with high and low relevance to the inference target, as labeled by the LLMs, exhibited distinct patterns, particularly when validated using eye-tracking data. However, focusing solely on individual words limited the depth of understanding, which made the conclusions somewhat simplistic despite their potential significance. This study used an LLM-based AI agent to group words from a reading passage into nodes and edges, forming a graph-based text representation based on semantic meaning and question-oriented prompts. We then compare the distribution of eye fixations on important nodes and edges. Our findings indicate that LLMs exhibit high consistency in language understanding at the level of graph topological structure. These results build on our previous findings and offer insights into effective human-AI co-learning strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11972v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuhong Zhang, Jialu Li, Shilai Yang, Yuchen Xu, Gert Cauwenberghs, Tzyy-Ping Jung</dc:creator>
    </item>
    <item>
      <title>Modeling Higher-Order Interactions in Sparse and Heavy-Tailed Neural Population Activity</title>
      <link>https://arxiv.org/abs/2308.13257</link>
      <description>arXiv:2308.13257v3 Announce Type: replace 
Abstract: Neurons process sensory stimuli efficiently, showing sparse yet highly variable ensemble spiking activity involving structured higher-order interactions. Notably, while neural populations are mostly silent, they occasionally exhibit highly synchronous activity, resulting in sparse and heavy-tailed spike-count distributions. However, its mechanistic origin - specifically, what types of nonlinear properties in individual neurons induce such population-level patterns - remains unclear. In this study, we derive sufficient conditions under which the joint activity of homogeneous binary neurons generates sparse and widespread population firing rate distributions in infinitely large networks. We then propose a subclass of exponential family distributions that satisfy this condition. This class incorporates structured higher-order interactions with alternating signs and shrinking magnitudes, along with a base-measure function that offsets distributional concentration, giving rise to parameter-dependent sparsity and heavy-tailed population firing rate distributions. Analysis of recurrent neural networks that recapitulate these distributions reveals that individual neurons possess threshold-like nonlinearity followed by supralinear activation that jointly facilitates sparse and synchronous population activity. These nonlinear features resemble those in modern Hopfield networks, suggesting a connection between widespread population activity and the network's memory capacity. The theory establishes sparse and heavy-tailed distributions for binary patterns, forming a foundation for developing energy-efficient spike-based learning machines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13257v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulises Rodr\'iguez-Dom\'inguez, Hideaki Shimazaki</dc:creator>
    </item>
    <item>
      <title>Neural field equations with time-periodic external inputs and some applications to visual processing</title>
      <link>https://arxiv.org/abs/2407.17294</link>
      <description>arXiv:2407.17294v2 Announce Type: replace 
Abstract: The aim of this work is to present a mathematical framework for the study of flickering inputs in visual processing tasks. When combined with geometric patterns, these inputs influence and induce interesting psychophysical phenomena, such as the MacKay and the Billock-Tsou effects, where the subjects perceive specific afterimages typically modulated by the flickering frequency. Due to the symmetry-breaking structure of the inputs, classical bifurcation theory and multi-scale analysis techniques are not very effective in our context. We thus take an approach based on the input-output framework of control theory for Amari-type neural fields. This allows us to prove that, when driven by periodic inputs, the dynamics converge to a periodic state. Moreover, we study under which assumptions these nonlinear dynamics can be effectively linearised, and in this case we present a precise approximation of the integral kernel for short-range excitatory and long-range inhibitory neuronal interactions. Finally, for inputs concentrated at the center of the visual field with a flickering background, we directly relate the width of the illusory contours appearing in the afterimage with both the flickering frequency and the strength of the inhibition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.17294v2</guid>
      <category>q-bio.NC</category>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Virginia Bolelli, Dario Prandi</dc:creator>
    </item>
    <item>
      <title>Efficient and faithful reconstruction of dynamical attractors using homogeneous differentiators</title>
      <link>https://arxiv.org/abs/2506.17079</link>
      <description>arXiv:2506.17079v2 Announce Type: replace 
Abstract: Reconstructing the attractors of complex nonlinear dynamical systems from available measurements is key to analyse and predict their time evolution. Existing attractor reconstruction methods typically rely on topological embedding and may produce poor reconstructions, which differ significantly from the actual attractor, because measurements are corrupted by noise and often available only for some of the state variables and/or their combinations, and the time series are often relatively short. Here, we propose the use of Homogeneous Differentiators (HD) to effectively de-noise measurements and more faithfully reconstruct attractors of nonlinear systems. Homogeneous Differentiators are supported by rigorous theoretical guarantees about their de-noising capabilities, and their results can be fruitfully combined with time-delay embedding, differential embedding and functional observability. We apply our proposed HD-based methodology to simulated dynamical models of increasing complexity, from the Lorenz system to the Hindmarsh-Rose model and the Epileptor model for neural dynamics, as well as to empirical data of EEG recordings. In the presence of corrupting noise of various types, we obtain drastically improved quality and resolution of the reconstructed attractors, as well as significantly reduced computational time, which can be orders of magnitude lower than that of alternative methods. Our tests show the flexibility and effectiveness of Homogeneous Differentiators and suggest that they can become the tool of choice for preprocessing noisy signals and reconstructing attractors of highly nonlinear dynamical systems from both theoretical models and real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17079v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uros Sutulovic, Daniele Proverbio, Rami Katz, Giulia Giordano</dc:creator>
    </item>
    <item>
      <title>System 0/1/2/3: Quad-process theory for multi-timescale embodied collective cognitive systems</title>
      <link>https://arxiv.org/abs/2503.06138</link>
      <description>arXiv:2503.06138v3 Announce Type: replace-cross 
Abstract: This paper introduces the System 0/1/2/3 framework as an extension of dual-process theory, employing a quad-process model of cognition. Expanding upon System 1 (fast, intuitive thinking) and System 2 (slow, deliberative thinking), we incorporate System 0, which represents pre-cognitive embodied processes, and System 3, which encompasses collective intelligence and symbol emergence. We contextualize this model within Bergson's philosophy by adopting multi-scale time theory to unify the diverse temporal dynamics of cognition. System 0 emphasizes morphological computation and passive dynamics, illustrating how physical embodiment enables adaptive behavior without explicit neural processing. Systems 1 and 2 are explained from a constructive perspective, incorporating neurodynamical and AI viewpoints. In System 3, we introduce collective predictive coding to explain how societal-level adaptation and symbol emergence operate over extended timescales. This comprehensive framework ranges from rapid embodied reactions to slow-evolving collective intelligence, offering a unified perspective on cognition across multiple timescales, levels of abstraction, and forms of human intelligence. The System 0/1/2/3 model provides a novel theoretical foundation for understanding the interplay between adaptive and cognitive processes, thereby opening new avenues for research in cognitive science, AI, robotics, and collective intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06138v3</guid>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tadahiro Taniguchi, Yasushi Hirai, Masahiro Suzuki, Shingo Murata, Takato Horii, Kazutoshi Tanaka</dc:creator>
    </item>
    <item>
      <title>A Group Theoretic Analysis of the Symmetries Underlying Base Addition and Their Learnability by Neural Networks</title>
      <link>https://arxiv.org/abs/2507.10678</link>
      <description>arXiv:2507.10678v2 Announce Type: replace-cross 
Abstract: A major challenge in the use of neural networks both for modeling human cognitive function and for artificial intelligence is the design of systems with the capacity to efficiently learn functions that support radical generalization. At the roots of this is the capacity to discover and implement symmetry functions. In this paper, we investigate a paradigmatic example of radical generalization through the use of symmetry: base addition. We present a group theoretic analysis of base addition, a fundamental and defining characteristic of which is the carry function -- the transfer of the remainder, when a sum exceeds the base modulus, to the next significant place. Our analysis exposes a range of alternative carry functions for a given base, and we introduce quantitative measures to characterize these. We then exploit differences in carry functions to probe the inductive biases of neural networks in symmetry learning, by training neural networks to carry out base addition using different carries, and comparing efficacy and rate of learning as a function of their structure. We find that even simple neural networks can achieve radical generalization with the right input format and carry function, and that learnability is closely correlated with carry function structure. We then discuss the relevance this has for cognitive science and machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10678v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 17 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cutter Dawes, Simon Segert, Kamesh Krishnamurthy, Jonathan D. Cohen</dc:creator>
    </item>
  </channel>
</rss>
