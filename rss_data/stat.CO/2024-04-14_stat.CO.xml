<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Apr 2024 04:00:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Exponentially Weighted Moving Models</title>
      <link>https://arxiv.org/abs/2404.08136</link>
      <description>arXiv:2404.08136v1 Announce Type: new 
Abstract: An exponentially weighted moving model (EWMM) for a vector time series fits a new data model each time period, based on an exponentially fading loss function on past observed data. The well known and widely used exponentially weighted moving average (EWMA) is a special case that estimates the mean using a square loss function. For quadratic loss functions EWMMs can be fit using a simple recursion that updates the parameters of a quadratic function. For other loss functions, the entire past history must be stored, and the fitting problem grows in size as time increases. We propose a general method for computing an approximation of EWMM, which requires storing only a window of a fixed number of past samples, and uses an additional quadratic term to approximate the loss associated with the data before the window. This approximate EWMM relies on convex optimization, and solves problems that do not grow with time. We compare the estimates produced by our approximation with the estimates from the exact EWMM method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08136v1</guid>
      <category>stat.CO</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Luxenberg, Stephen Boyd</dc:creator>
    </item>
    <item>
      <title>A Distributed Approach for Persistent Homology Computation on a Large Scale</title>
      <link>https://arxiv.org/abs/2404.08245</link>
      <description>arXiv:2404.08245v1 Announce Type: cross 
Abstract: Persistent homology (PH) is a powerful mathematical method to automatically extract relevant insights from images, such as those obtained by high-resolution imaging devices like electron microscopes or new-generation telescopes. However, the application of this method comes at a very high computational cost, that is bound to explode more because new imaging devices generate an ever-growing amount of data. In this paper we present PixHomology, a novel algorithm for efficiently computing $0$-dimensional PH on 2D images, optimizing memory and processing time. By leveraging the Apache Spark framework, we also present a distributed version of our algorithm with several optimized variants, able to concurrently process large batches of astronomical images. Finally, we present the results of an experimental analysis showing that our algorithm and its distributed version are efficient in terms of required memory, execution time, and scalability, consistently outperforming existing state-of-the-art PH computation tools when used to process large datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08245v1</guid>
      <category>cs.DC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Riccardo Ceccaroni, Lorenzo Di Rocco, Umberto Ferraro Petrillo, Pierpaolo Brutti</dc:creator>
    </item>
    <item>
      <title>confintROB Package: Confindence Intervals in robust linear mixed models</title>
      <link>https://arxiv.org/abs/2404.08426</link>
      <description>arXiv:2404.08426v1 Announce Type: cross 
Abstract: Statistical inference is a major scientific endeavor for many researchers. In terms of inferential methods implemented to mixed-effects models, significant progress has been made in the R software. However, these advances primarily concern classical estimators (ML, REML) and mainly focus on fixed effects. In the confintROB package, we have implemented various bootstrap methods for computing confidence intervals (CIs) not only for fixed effects but also for variance components. These methods can be implemented with the widely used lmer function from the lme4 package, as well as with the rlmer function from the robustlmm package and the varComprob function from the robustvarComp package. These functions implement robust estimation methods suitable for data with outliers. The confintROB package implements the Wald method for fixed effects, whereas for both fixed effects and variance components, two bootstrap methods are implemented: the parametric bootstrap and the wild bootstrap. Moreover, the confintROB package can obtain both the percentile and the bias-corrected accelerated versions of CIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08426v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mason Fabio, Koller Manuel, Cantoni Eva, Ghisletta Paolo</dc:creator>
    </item>
    <item>
      <title>Decoding AI: The inside story of data analysis in ChatGPT</title>
      <link>https://arxiv.org/abs/2404.08480</link>
      <description>arXiv:2404.08480v1 Announce Type: cross 
Abstract: As a result of recent advancements in generative AI, the field of Data Science is prone to various changes. This review critically examines the Data Analysis (DA) capabilities of ChatGPT assessing its performance across a wide range of tasks. While DA provides researchers and practitioners with unprecedented analytical capabilities, it is far from being perfect, and it is important to recognize and address its limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08480v1</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ozan Evkaya, Miguel de Carvalho</dc:creator>
    </item>
    <item>
      <title>Towards a turnkey approach to unbiased Monte Carlo estimation of smooth functions of expectations</title>
      <link>https://arxiv.org/abs/2403.20313</link>
      <description>arXiv:2403.20313v2 Announce Type: replace-cross 
Abstract: Given a smooth function $f$, we develop a general approach to turn Monte Carlo samples with expectation $m$ into an unbiased estimate of $f(m)$. Specifically, we develop estimators that are based on randomly truncating the Taylor series expansion of $f$ and estimating the coefficients of the truncated series. We derive their properties and propose a strategy to set their tuning parameters -- which depend on $m$ -- automatically, with a view to make the whole approach simple to use. We develop our methods for the specific functions $f(x)=\log x$ and $f(x)=1/x$, as they arise in several statistical applications such as maximum likelihood estimation of latent variable models and Bayesian inference for un-normalised models. Detailed numerical studies are performed for a range of applications to determine how competitive and reliable the proposed approach is.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20313v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Chopin, Francesca R. Crucinio, Sumeetpal S. Singh</dc:creator>
    </item>
  </channel>
</rss>
