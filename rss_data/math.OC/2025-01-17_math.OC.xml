<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Jan 2025 05:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Stochastic Optimal Control of Prosumers in a District Heating System</title>
      <link>https://arxiv.org/abs/2501.09088</link>
      <description>arXiv:2501.09088v1 Announce Type: new 
Abstract: We consider a network of residential heating systems in which several prosumers satisfy their heating and hot water demand using solar thermal collectors and services of a central producer. Overproduction of heat can either be stored in a local thermal storage or sold to the network. Our focus is the minimization of the prosumers expected discounted total cost from purchasing and selling thermal energy and running the system. This decision making problem under uncertainty about the future production and consumption of thermal energy is formulated as a stochastic optimal control problem and solved with dynamic programming techniques. We present numerical results for the value function and the optimal control.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09088v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maalvlad\'edon Ganet Som\'e</dc:creator>
    </item>
    <item>
      <title>Least-Squares Problem Over Probability Measure Space</title>
      <link>https://arxiv.org/abs/2501.09097</link>
      <description>arXiv:2501.09097v1 Announce Type: new 
Abstract: In this work, we investigate the variational problem $$\rho_x^\ast = \text{argmin}_{\rho_x} D(G\#\rho_x, \rho_y)\,, $$ where $D$ quantifies the difference between two probability measures, and ${G}$ is a forward operator that maps a variable $x$ to $y=G(x)$. This problem can be regarded as an analogue of its counterpart in linear spaces (e.g., Euclidean spaces), $\text{argmin}_x \|G(x) - y\|^2$. Similar to how the choice of norm $\|\cdot\|$ influences the optimizer in $\mathbb R^d$ or other linear spaces, the minimizer in the probabilistic variational problem also depends on the choice of $D$. Our findings reveal that using a $\phi$-divergence for $D$ leads to the recovery of a conditional distribution of $\rho_y$, while employing the Wasserstein distance results in the recovery of a marginal distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09097v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qin Li, Li Wang, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Extended Triangle Inequalities for Nonconvex Box-Constrained Quadratic Programming</title>
      <link>https://arxiv.org/abs/2501.09150</link>
      <description>arXiv:2501.09150v1 Announce Type: new 
Abstract: Let $\rm{Box}_n = \{x \in \mathbb{R}^n : 0 \leq x \leq e \}$, and let $\rm{QPB}_n$ denote the convex hull of $\{(1, x')'(1, x') : x \in \rm{Box}_n\}$. The quadratic programming problem $\min\{x'Q x + q'x : x \in \rm{Box}_n\}$ where $Q$ is not positive semidefinite (PSD), is equivalent to a linear optimization problem over $\rm{QPB}_n$ and could be efficiently solved if a tractable characterization of $\rm{QPB}_n$ was available. It is known that $\rm{QPB}_2$ can be represented using a PSD constraint combined with constraints generated using the reformulation-linearization technique (RLT). The triangle (TRI) inequalities are also valid for $\rm{QPB}_3$, but the PSD, RLT and TRI constraints together do not fully characterize $\rm{QPB}_3$. In this paper we describe new valid linear inequalities for $\rm{QPB}_n$, $n \geq 3$ based on strengthening the approximation of $\rm{QPB}_3$ given by the PSD, RLT and TRI constraints. These new inequalities are generated in a systematic way using a known disjunctive characterization for $\rm{QPB}_3$. We also describe a conic strengthening of the linear inequalities that incorporates second-order cone constraints. We show computationally that the new inequalities and their conic strengthenings obtain exact solutions for some nonconvex box-constrained instances that are not solved exactly using the PSD, RLT and TRI constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09150v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kurt M. Anstreicher, Diane Puges</dc:creator>
    </item>
    <item>
      <title>Formalising the intentional stance 2: a coinductive approach</title>
      <link>https://arxiv.org/abs/2501.09173</link>
      <description>arXiv:2501.09173v1 Announce Type: new 
Abstract: Given a stochastic process with inputs and outputs, how might its behaviour be related to pursuit of a goal? We model this using 'transducers', objects that capture only the external behaviour of a system and not its internal state. A companion paper summarises our results for cognitive scientists; the current paper gives formal definitions and proofs.
  To formalise the concept of a system that behaves as if it were pursuing a goal, we consider what happens when a transducer (a 'policy') is coupled to another transducer that comes equipped with a success condition (a 'teleo-environment'). An optimal policy is identified with a transducer that behaves as if it were perfectly rational in the pursuit of a goal; our framework also allows us to model constrained rationality.
  Optimal policies obey a version of Bellman's principle: a policy that's optimal in one time step will again be optimal in the next time step, but with respect to a different teleo-environment (obtained from the original one by a modified version of Bayesian filtering). This property sometimes also applies to the bounded-rational case; we give a sufficient condition.
  A policy is deterministic if and only if there exists a teleo-environment for which it is uniquely optimal among the set of all policies; we relate this to classical representation theorems from decision theory. This result need not hold in the bounded-rational case; we give an example related to the absent-minded driver problem. The formalism is defined using coinduction, following the style proposed by Czajka.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09173v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.PR</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon McGregor,  timorl, Nathaniel Virgo</dc:creator>
    </item>
    <item>
      <title>Estimation-Aware Trajectory Optimization with Set-Valued Measurement Uncertainties</title>
      <link>https://arxiv.org/abs/2501.09192</link>
      <description>arXiv:2501.09192v1 Announce Type: new 
Abstract: In this paper, we present an optimization-based framework for generating estimation-aware trajectories in scenarios where measurement (output) uncertainties are state-dependent and set-valued. The framework leverages the concept of regularity for set-valued output maps. Specifically, we demonstrate that, for output-regular maps, one can utilize a set-valued observability measure that is concave with respect to finite-horizon state trajectories. By maximizing this measure, optimized estimation-aware trajectories can be designed for a broad class of systems, including those with locally linearized dynamics. To illustrate the effectiveness of the proposed approach, we provide a representative example in the context of trajectory planning for vision-based estimation. We present an estimation-aware trajectory for an uncooperative target-tracking problem that uses a machine learning (ML)-based estimation module on an ego-satellite.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09192v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Deole, Mehran Mesbahi</dc:creator>
    </item>
    <item>
      <title>A Dynamic Unmanned Aerial Vehicle Routing Framework for Urban Traffic Monitoring</title>
      <link>https://arxiv.org/abs/2501.09249</link>
      <description>arXiv:2501.09249v1 Announce Type: new 
Abstract: Unmanned Aerial Vehicles (UAVs) have great potential in urban traffic monitoring due to their rapid speed, cost-effectiveness, and extensive field-of-view, while being unconstrained by traffic congestion. However, their limited flight duration presents critical challenges in sustainable recharging strategies and efficient route planning in long-term monitoring tasks. Additionally, existing approaches for long-term monitoring often neglect the evolving nature of urban traffic networks. In this study, we introduce a novel dynamic UAV routing framework for long-term, network-wide urban traffic monitoring, leveraging existing ground vehicles as mobile charging stations without disrupting their operations. To address the complexity of long-term monitoring scenarios involving multiple flights, we decompose the problem into manageable single-flight tasks, in which each flight is modeled as a Team Arc Orienteering Problem with Decreasing Profits with the objective to collectively maximize the spatiotemporal network coverage. Between flights, we adaptively update the edge weights to incorporate real-time traffic changes and revisit intervals. We validate our framework through extensive microscopic simulations in a modified Sioux Falls network under various scenarios. Comparative results demonstrate that our model outperforms three baseline approaches, especially when historical information is incomplete or absent. Moreover, we show that our monitoring framework can capture network-wide traffic trends and construct accurate Macroscopic Fundamental Diagrams (MFDs). These findings demonstrate the effectiveness of the proposed dynamic UAV routing framework, underscoring its suitability for efficient and reliable long-term traffic monitoring. Our approach's adaptability and high accuracy in capturing the MFD highlight its potential in network-wide traffic control and management applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09249v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yumeng Bai, Yiheng Feng</dc:creator>
    </item>
    <item>
      <title>Control Barrier Function-Based Safety Filters: Characterization of Undesired Equilibria, Unbounded Trajectories, and Limit Cycles</title>
      <link>https://arxiv.org/abs/2501.09289</link>
      <description>arXiv:2501.09289v1 Announce Type: new 
Abstract: This paper focuses on safety filters designed based on Control Barrier Functions (CBFs): these are modifications of a nominal stabilizing controller typically utilized in safety-critical control applications to render a given subset of states forward invariant. The paper investigates the dynamical properties of the closed-loop systems, with a focus on characterizing undesirable behaviors that may emerge due to the use of CBF-based filters. These undesirable behaviors include unbounded trajectories, limit cycles, and undesired equilibria, which can be locally stable and even form a continuum. Our analysis offer the following contributions: (i) conditions under which trajectories remain bounded and (ii) conditions under which limit cycles do not exist; (iii) we show that undesired equilibria can be characterized by solving an algebraic equation, and (iv) we provide examples that show that asymptotically stable undesired equilibria can exist for a large class of nominal controllers and design parameters of the safety filter (even for convex safe sets). Further, for the specific class of planar systems, (v) we provide explicit formulas for the total number of undesired equilibria and the proportion of saddle points and asymptotically stable equilibria, and (vi) in the case of linear planar systems, we present an exhaustive analysis of their global stability properties. Examples throughout the paper illustrate the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09289v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pol Mestres, Yiting Chen, Emiliano Dall'anese, Jorge Cort\'es</dc:creator>
    </item>
    <item>
      <title>The Effective Generalized Moment Problem</title>
      <link>https://arxiv.org/abs/2501.09385</link>
      <description>arXiv:2501.09385v1 Announce Type: new 
Abstract: We establish new convergence rates for the moment-sum-of-squares (Moment-SOS) relaxations for the Generalized Moment Problem (GMP). These bounds, which adapt to the geometry of the underlying semi-algebraic set, apply to both the convergence of optima, and to the convergence in Hausdorff distance between the relaxation feasibility set and the GMP feasibility set. This research extends previous works limited to specific problems in polynomial optimization, volume computation and optimal control. We complement our theoretical analysis with an application: minimal rank symmetric tensor decomposition. In the examples, we formulate the problem as a GMP, solve using Moment-SOS relaxation, and apply the theoretical results to observe a convergence rate of the relaxations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09385v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas Gamertsfelder, Bernard Mourrain</dc:creator>
    </item>
    <item>
      <title>Mid-term bio-economic optimization of multi-species fisheries</title>
      <link>https://arxiv.org/abs/2501.09452</link>
      <description>arXiv:2501.09452v1 Announce Type: new 
Abstract: In this paper, we analyze the dynamics of a multi-species fisheries system in the presence of harvesting. We solve the problem of finding the optimal harvesting strategy for a mid-term horizon with a fixed final stock of each species, while maximizing the expected present value of total revenues. The problem is formulated as an optimal control problem. For its solution, we combine techniques derived from Pontryagin's Maximum Principle, cyclic coordinate descent and the shooting method. The algorithm we develop can solve problems both with inter-species competition and with predator-prey behaviors. Several numerical examples are presented to illustrate the different possibilities of the method and a study of the dependence of the behavior on some parameters is performed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09452v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.apm.2018.09.032</arxiv:DOI>
      <arxiv:journal_reference>Applied Mathematical Modelling, Volume 66, February 2019, Pages 548-561</arxiv:journal_reference>
      <dc:creator>L. Bayon, P. Fortuny Ayuso, P. J. Garcia-Nieto, J. A. Otero, P. M. Suarez, C. Tasis</dc:creator>
    </item>
    <item>
      <title>Optimal taxes and subsidies to incentivize modal shift for inner-city freight transport</title>
      <link>https://arxiv.org/abs/2501.09467</link>
      <description>arXiv:2501.09467v1 Announce Type: new 
Abstract: With increasing freight demands for inner-city transport, shifting freight from road to scheduled line services such as buses, metros, trams, and barges is a sustainable solution. Public authorities typically impose economic policies, including road taxes and subsidies for scheduled line services, to achieve this modal shift. This study models such a policy using a bi-level approach: at the upper level, authorities set road taxes and scheduled line subsidies, while at the lower level, freight forwarders arrange transportation via road or a combination of road and scheduled lines. We prove that fully subsidizing the scheduled line is an optimal and budget-efficient policy. Due to its computational complexity, we solve the problem heuristically using a bi-section algorithm for the upper level and an Adaptive Large Neighbourhood Search for the lower level. Our results show that optimally setting subsidy and tax can reduce the driving distance by up to 12.5\% and substantially increase modal shift, albeit at a higher operational cost due to increased taxes. Furthermore, increased scheduled line frequency and decreased geographical scatteredness of freight orders increase modal shift. For the partial subsidy policy, we found that an additional budget provides a better trade-off between minimizing distance and transportation costs than solely increasing the subsidy level. In a Berlin, Germany, case study, we find that we can achieve up to 2.9\% reduction in driven distance due to 23.2\% scheduled line usage, which amounts to an increase of multiple orders of magnitude, despite only using a few stations for transshipment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09467v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krissada Tundulyasaree, Layla Martin, Rolf N. van Lieshout, Tom Van Woensel</dc:creator>
    </item>
    <item>
      <title>Proximal Quasi-Newton Method for Composite Optimization over the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2501.09516</link>
      <description>arXiv:2501.09516v1 Announce Type: new 
Abstract: In this paper, we consider the composite optimization problems over the Stiefel manifold. A successful method to solve this class of problems is the proximal gradient method proposed by Chen et al. Motivated by the proximal Newton-type techniques in the Euclidean space, we present a Riemannian proximal quasi-Newton method, named ManPQN, to solve the composite optimization problems. The global convergence of the ManPQN method is proved and iteration complexity for obtaining an $\epsilon$-stationary point is analyzed. Under some mild conditions, we also establish the local linear convergence result of the ManPQN method. Numerical results are encouraging, which shows that the proximal quasi-Newton technique can be used to accelerate the proximal gradient method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09516v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinsi Wang, Wei Hong Yang</dc:creator>
    </item>
    <item>
      <title>Rates of (T-)asymptotic regularity of the generalized Krasnoselskii-Mann-type iteration</title>
      <link>https://arxiv.org/abs/2501.09523</link>
      <description>arXiv:2501.09523v1 Announce Type: new 
Abstract: In this paper we use proof mining methods to compute rates of ($T$-)asymptotic regularity of the generalized Krasnoselskii-Mann-type iteration associated to a nonexpansive mapping $T:X\to X$ in a uniformly convex normed space $X$. For special choices of the parameter sequences, we obtain quadratic rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09523v1</guid>
      <category>math.OC</category>
      <category>math.LO</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paulo Firmino, Laurentiu Leustean</dc:creator>
    </item>
    <item>
      <title>A Multi-agent System for Hybrid Optimization</title>
      <link>https://arxiv.org/abs/2501.09563</link>
      <description>arXiv:2501.09563v1 Announce Type: new 
Abstract: Optimization problems in process engineering, including design and operation, can often pose challenges to many solvers: multi-modal, non-smooth, and discontinuous models often with large computational requirements. In such cases, the optimization problem is often treated as a black box in which only the value of the objective function is required, sometimes with some indication of the measure of the violation of the constraints. Such problems have traditionally been tackled through the use of direct search and meta-heuristic methods. The challenge, then, is to determine which of these methods or combination of methods should be considered to make most effective use of finite computational resources.
  This paper presents a multi-agent system for optimization which enables a set of solvers to be applied simultaneously to an optimization problem, including different instantiations of any solver. The evaluation of the optimization problem model is controlled by a scheduler agent which facilitates cooperation and competition between optimization methods. The architecture and implementation of the agent system is described in detail, including the solver, model evaluation, and scheduler agents. A suite of direct search and meta-heuristic methods has been developed for use with this system. Case studies from process systems engineering applications are presented and the results show the potential benefits of automated cooperation between different optimization solvers and motivates the implementation of competition between solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09563v1</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eric S. Fraga, Veerawat Udomvorakulchai, Miguel Pineda, Lazaros G. Papageorgiou</dc:creator>
    </item>
    <item>
      <title>Faces of homogeneous cones and applications to homogeneous chordality</title>
      <link>https://arxiv.org/abs/2501.09581</link>
      <description>arXiv:2501.09581v1 Announce Type: new 
Abstract: A convex cone $\mathcal{K}$ is said to be homogeneous if its group of automorphisms acts transitively on its relative interior. Important examples of homogeneous cones include symmetric cones and cones of positive semidefinite (PSD) matrices that follow a sparsity pattern given by a homogeneous chordal graph. Our goal in this paper is to elucidate the facial structure of homogeneous cones and make it as transparent as the faces of the PSD matrices. We prove that each face of a homogeneous cone $\mathcal{K}$ is mapped by an automorphism of $\mathcal{K}$ to one of its finitely many so-called principal faces. Furthermore, constructing such an automorphism can be done algorithmically by making use of a generalized Cholesky decomposition. Among other consequences, we give a proof that homogeneous cones are projectionally exposed, which strengthens the previous best result that they are amenable. Using our results, we will carefully analyze the facial structure of cones of PSD matrices satisfying homogeneous chordality and discuss consequences for the corresponding family of PSD completion problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09581v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Gouveia, Masaru Ito, Bruno F. Louren\c{c}o</dc:creator>
    </item>
    <item>
      <title>A Simplification Method for Inequality Constraints in Integer Binary Encoding HOBO Formulations</title>
      <link>https://arxiv.org/abs/2501.09670</link>
      <description>arXiv:2501.09670v1 Announce Type: new 
Abstract: This study proposes a novel method for simplifying inequality constraints in Higher-Order Binary Optimization (HOBO) formulations. The proposed method addresses challenges associated with Quadratic Unconstrained Binary Optimization (QUBO) formulations, specifically the increased computational complexity and reduced solution accuracy caused by the introduction of slack variables and the resulting growth in auxiliary qubits. By efficiently integrating constraints, the method enhances the computational efficiency and accuracy of both quantum and classical solvers. The effectiveness of the proposed approach is demonstrated through numerical experiments applied to combinatorial optimization problems. The results indicate that this method expands the applicability of quantum algorithms to high-dimensional problems and improves the practicality of classical optimization solvers for optimization problems involving inequality constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09670v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuichiro Minato</dc:creator>
    </item>
    <item>
      <title>Distributionally Fair Peer-to-Peer Electricity Trading</title>
      <link>https://arxiv.org/abs/2501.09713</link>
      <description>arXiv:2501.09713v1 Announce Type: new 
Abstract: Peer-to-peer energy trading platforms enable direct electricity exchanges between peers who belong to the same energy community. In a semi-decentralized system, a community manager adheres to grid restrictions while optimizing social welfare. However, with no further supervision, some peers can be discriminated against from participating in the electricity trades. To solve this issue, this paper proposes an optimization-based mechanism to enable distributionally fair peer-to-peer electricity trading. For the implementation of our mechanism, peers are grouped by energy poverty level. The proposed model aims to redistribute the electricity trades to minimize the maximum Wasserstein distance among the transaction distributions linked to the groups while limiting the sacrifice level with a predefined parameter. We demonstrate the effectiveness of our proposal using the IEEE 33-bus distribution grid, simulating an energy community with 1600 peers. Results indicate that up to 70.1% of unfairness can be eliminated by using our proposed model, even achieving a full elimination when including a non-profit community photovoltaic plant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09713v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Estibalitz Ruiz Irusta, Juan M. Morales</dc:creator>
    </item>
    <item>
      <title>Random Subspace Cubic-Regularization Methods, with Applications to Low-Rank Functions</title>
      <link>https://arxiv.org/abs/2501.09734</link>
      <description>arXiv:2501.09734v1 Announce Type: new 
Abstract: We propose and analyze random subspace variants of the second-order Adaptive Regularization using Cubics (ARC) algorithm. These methods iteratively restrict the search space to some random subspace of the parameters, constructing and minimizing a local model only within this subspace. Thus, our variants only require access to (small-dimensional) projections of first- and second-order problem derivatives and calculate a reduced step inexpensively. Under suitable assumptions, the ensuing methods maintain the optimal first-order, and second-order, global rates of convergence of (full-dimensional) cubic regularization, while showing improved scalability both theoretically and numerically, particularly when applied to low-rank functions. When applied to the latter, our adaptive variant naturally adapts the subspace size to the true rank of the function, without knowing it a priori.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09734v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Coralia Cartis, Zhen Shao, Edward Tansley</dc:creator>
    </item>
    <item>
      <title>Gradient Descent Converges Linearly to Flatter Minima than Gradient Flow in Shallow Linear Networks</title>
      <link>https://arxiv.org/abs/2501.09137</link>
      <description>arXiv:2501.09137v1 Announce Type: cross 
Abstract: We study the gradient descent (GD) dynamics of a depth-2 linear neural network with a single input and output. We show that GD converges at an explicit linear rate to a global minimum of the training loss, even with a large stepsize -- about $2/\textrm{sharpness}$. It still converges for even larger stepsizes, but may do so very slowly. We also characterize the solution to which GD converges, which has lower norm and sharpness than the gradient flow solution. Our analysis reveals a trade off between the speed of convergence and the magnitude of implicit regularization. This sheds light on the benefits of training at the ``Edge of Stability'', which induces additional regularization by delaying convergence and may have implications for training more complex models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09137v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pierfrancesco Beneventano, Blake Woodworth</dc:creator>
    </item>
    <item>
      <title>Reducing real-time complexity via sub-control Lyapunov functions: from theory to experiments</title>
      <link>https://arxiv.org/abs/2501.09143</link>
      <description>arXiv:2501.09143v1 Announce Type: cross 
Abstract: The techniques to design control Lyapunov functions (CLF), along with a proper stabilizing feedback, possibly in the presence of constraints, often provide control laws that are too complex for proper implementation online, especially when an optimization problem is involved. In this work, we show how to acquire an alternative, computationally attractive feedback. Given a nominal CLF and a nominal state feedback, we say that a different positive definite function is a Sub-control Lyapunov function (SCLF) if its Lyapunov derivative is negative-definite and bounded above by the Lyapunov derivative of the nominal function with the nominal control. It turns out that if we consider a family of basis functions, then a SCLF can be computed by linear programming, with an infinite number of constraints. The idea is that although the offline computational burden to achieve the new controller and solve the linear program is considerable, the online computational burden is drastically reduced. Comprehensive simulations and experiments on drone control are conducted to demonstrate the effectiveness of the study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09143v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Huu-Thinh Do, Franco Blanchini, Stefano Miani, Ionela Prodan</dc:creator>
    </item>
    <item>
      <title>On the convergence of noisy Bayesian Optimization with Expected Improvement</title>
      <link>https://arxiv.org/abs/2501.09262</link>
      <description>arXiv:2501.09262v1 Announce Type: cross 
Abstract: Expected improvement (EI) is one of the most widely-used acquisition functions in Bayesian optimization (BO). Despite its proven success in applications for decades, important open questions remain on the theoretical convergence behaviors and rates for EI. In this paper, we contribute to the convergence theories of EI in three novel and critical area. First, we consider objective functions that are under the Gaussian process (GP) prior assumption, whereas existing works mostly focus on functions in the reproducing kernel Hilbert space (RKHS). Second, we establish the first asymptotic error bound and its corresponding rate for GP-EI with noisy observations under the GP prior assumption. Third, by investigating the exploration and exploitation of the non-convex EI function, we prove improved error bounds for both the noise-free and noisy cases. The improved noiseless bound is extended to the RKHS assumption as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09262v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyi Wang, Haowei Wang, Cosmin G. Petra, Nai-Yuan Chiang</dc:creator>
    </item>
    <item>
      <title>On a Variant of the Minimum Path Cover Problem in Acyclic Digraphs: Computational Complexity Results and Exact Method</title>
      <link>https://arxiv.org/abs/2501.09560</link>
      <description>arXiv:2501.09560v1 Announce Type: cross 
Abstract: The Minimum Path Cover (MPC) problem consists of finding a minimum-cardinality set of node-disjoint paths that cover all nodes in a given graph. We explore a variant of the MPC problem on acyclic digraphs (DAGs) where, given a subset of arcs, each path within the MPC should contain at least one arc from this subset. We prove that the feasibility problem is strongly NP-hard on arbitrary DAGs, but the problem can be solved in polynomial time when the DAG is the transitive closure of a path.
  Given that the problem may not always be feasible, our solution focuses on covering a maximum number of nodes with a minimum number of node-disjoint paths, such that each path includes at least one arc from the predefined subset of arcs. This paper introduces and investigates two integer programming formulations for this problem. We propose several valid inequalities to enhance the linear programming relaxations, employing them as cutting planes in a branch-and-cut approach. The procedure is implemented and tested on a wide range of instances, including real-world instances derived from an airline crew scheduling problem, demonstrating the effectiveness of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09560v1</guid>
      <category>cs.DM</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nour ElHouda Tellache, Roberto Baldacci</dc:creator>
    </item>
    <item>
      <title>Convergence of a Deep BSDE solver with jumps</title>
      <link>https://arxiv.org/abs/2501.09727</link>
      <description>arXiv:2501.09727v1 Announce Type: cross 
Abstract: We study the error arising in the numerical approximation of FBSDEs and related PIDEs by means of a deep learning-based method. Our results focus on decoupled FBSDEs with jumps and extend the seminal work of HAn and Long (2020) analyzing the numerical error of the deep BSDE solver proposed in E et al. (2017). We provide a priori and a posteriori error estimates for the finite and infinite activity case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09727v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>q-fin.CP</category>
      <category>q-fin.PR</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Gnoatto, Katharina Oberpriller, Athena Picarelli</dc:creator>
    </item>
    <item>
      <title>Tensor-based Dinkelbach method for computing generalized tensor eigenvalues and its applications</title>
      <link>https://arxiv.org/abs/2501.09735</link>
      <description>arXiv:2501.09735v1 Announce Type: cross 
Abstract: In this paper, we propose a novel tensor-based Dinkelbach--Type method for computing extremal tensor generalized eigenvalues. We show that the extremal tensor generalized eigenvalue can be reformulated as a critical subproblem of the classical Dinkelbach--Type method, which can subsequently be expressed as a multilinear optimization problem (MOP). The MOP is solved under a spherical constraint using an efficient proximal alternative minimization method, in which we rigorously establish the global convergence. Additionally, the equivalent MOP is reformulated as an unconstrained optimization problem, allowing for the analysis of the Kurdyka-Lojasiewicz (KL) exponent and providing an explicit expression for the convergence rate of the proposed algorithm. Preliminary numerical experiments on solving extremal tensor generalized eigenvalues and minimizing high-order trust-region subproblems are provided, validating the efficacy and practical utility of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Haibin Chen, Wenqi Zhu, Coralia Cartis</dc:creator>
    </item>
    <item>
      <title>OPM, a collection of Optimization Problems in Matlab</title>
      <link>https://arxiv.org/abs/2112.05636</link>
      <description>arXiv:2112.05636v2 Announce Type: replace 
Abstract: OPM is a small collection of CUTEst unconstrained and bound-constrained nonlinear optimization problems, which can be used in Matlab for testing optimization algorithms directly (i.e. without installing additional software).</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.05636v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gratton, Philippe L. Toint</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Nonconvex-Nonconcave Minimax Optimization: Primal-Dual Balancing and Iteration Complexity Analysis</title>
      <link>https://arxiv.org/abs/2209.10825</link>
      <description>arXiv:2209.10825v4 Announce Type: replace 
Abstract: Nonconvex-nonconcave minimax optimization has gained widespread interest over the last decade. However, most existing works focus on variants of gradient descent-ascent (GDA) algorithms, which are only applicable to smooth nonconvex-concave settings. To address this limitation, we propose a novel algorithm named smoothed proximal linear descent-ascent (smoothed PLDA), which can effectively handle a broad range of structured nonsmooth nonconvex-nonconcave minimax problems. Specifically, we consider the setting where the primal function has a nonsmooth composite structure and the dual function possesses the Kurdyka-Lojasiewicz (KL) property with exponent $\theta \in [0,1)$. We introduce a novel convergence analysis framework for smoothed PLDA, the key components of which are our newly developed nonsmooth primal error bound and dual error bound. Using this framework, we show that smoothed PLDA can find both $\epsilon$-game-stationary points and $\epsilon$-optimization-stationary points of the problems of interest in $\mathcal{O}(\epsilon^{-2\max\{2\theta,1\}})$ iterations. Furthermore, when $\theta \in [0,\frac{1}{2}]$, smoothed PLDA achieves the optimal iteration complexity of $\mathcal{O}(\epsilon^{-2})$. To further demonstrate the effectiveness and wide applicability of our analysis framework, we show that certain max-structured problem possesses the KL property with exponent $\theta=0$ under mild assumptions. As a by-product, we establish algorithm-independent quantitative relationships among various stationarity concepts, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.10825v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajin Li, Linglingzhi Zhu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>First-Order Methods for Nonsmooth Nonconvex Functional Constrained Optimization with or without Slater Points</title>
      <link>https://arxiv.org/abs/2212.00927</link>
      <description>arXiv:2212.00927v4 Announce Type: replace 
Abstract: Constrained optimization problems where both the objective and constraints may be nonsmooth and nonconvex arise across many learning and data science settings. In this paper, we show for any Lipschitz, weakly convex objectives and constraints, a simple first-order method finds a feasible, $\epsilon$-stationary point at a convergence rate of $O(\epsilon^{-4})$ without relying on compactness or Constraint Qualification (CQ). When CQ holds, this convergence is measured by approximately satisfying the Karush-Kuhn-Tucker conditions. When CQ fails, we guarantee the attainment of weaker Fritz-John conditions. As an illustrative example, our method stably converges on piecewise quadratic SCAD regularized problems despite frequent violations of constraint qualification. The considered algorithm is similar to those of "Quadratically regularized subgradient methods for weakly convex optimization with weakly convex constraints" by Ma et al. and "Stochastic first-order methods for convex and nonconvex functional constrained optimization" by Boob et al. (whose guarantees further assume compactness and CQ), iteratively taking inexact proximal steps, computed via an inner loop applying a switching subgradient method to a strongly convex constrained subproblem. Our non-Lipschitz analysis of the switching subgradient method appears to be new and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.00927v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhichao Jia, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>Second-order methods for quartically-regularised cubic polynomials, with applications to high-order tensor methods</title>
      <link>https://arxiv.org/abs/2308.15336</link>
      <description>arXiv:2308.15336v2 Announce Type: replace 
Abstract: There has been growing interest in high-order tensor methods for nonconvex optimization, with adaptive regularization, as they possess better/optimal worst-case evaluation complexity globally and faster convergence asymptotically. These algorithms crucially rely on repeatedly minimizing nonconvex multivariate Taylor-based polynomial sub-problems, at least locally. Finding efficient techniques for the solution of these sub-problems, beyond the second-order case, has been an open question. This paper proposes a second-order method, Quadratic Quartic Regularisation (QQR), for efficiently minimizing nonconvex quartically-regularized cubic polynomials, such as the AR$p$ sub-problem [3] with $p=3$. Inspired by [35], QQR approximates the third-order tensor term by a linear combination of quadratic and quartic terms, yielding (possibly nonconvex) local models that are solvable to global optimality. In order to achieve accuracy $\epsilon$ in the first-order criticality of the sub-problem in finitely many iterations, we show that the error in the QQR method decreases either linearly or by at least $\mathcal{O}(\epsilon^{4/3})$ for locally convex iterations, while in the nonconvex case, by at least $\mathcal{O}(\epsilon)$; thus improving, on these types of iterations, the general cubic-regularization bound. Preliminary numerical experiments indicate that two QQR variants perform competitively with state-of-the-art approaches such as ARC (also known as AR$p$ with $p=2$), achieving either a lower objective value or iteration counts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15336v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Coralia Cartis, Wenqi Zhu</dc:creator>
    </item>
    <item>
      <title>Uses of Sub-sample Estimates to Reduce Errors in Stochastic Optimization Models</title>
      <link>https://arxiv.org/abs/2310.07052</link>
      <description>arXiv:2310.07052v2 Announce Type: replace 
Abstract: Optimization software enables the solution of problems with millions of variables and associated parameters. These parameters are, however, often uncertain and represented with an analytical description of the parameter's distribution or with some form of sample. With large numbers of such parameters, optimization of the resulting model is often driven by mis-specifications or extreme sample characteristics, resulting in solutions that are far from a true optimum. This paper describes how asymptotic convergence results may not be useful in large-scale problems and how the optimization of problems based on sub-sample estimates may achieve improved results over models using full-sample solution estimates. A motivating example and numerical results from a portfolio optimization problem demonstrate the potential improvement. A theoretical analysis also provides insight into the structure of problems where sub-sample optimization may be most beneficial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07052v2</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John R. Birge</dc:creator>
    </item>
    <item>
      <title>Heavy Ball Momentum for Non-Strongly Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.06930</link>
      <description>arXiv:2403.06930v2 Announce Type: replace 
Abstract: When considering the minimization of a quadratic or strongly convex function, it is well known that first-order methods involving an inertial term weighted by a constant-in-time parameter are particularly efficient (see Polyak [32], Nesterov [28], and references therein). By setting the inertial parameter according to the condition number of the objective function, these methods guarantee a fast exponential decay of the error. We prove that this type of schemes (which are later called Heavy Ball schemes) is relevant in a relaxed setting, i.e. for composite functions satisfying a quadratic growth condition. In particular, we adapt V-FISTA, introduced by Beck in [10] for strongly convex functions, to this broader class of functions. To the authors' knowledge, the resulting worst-case convergence rates are faster than any other in the literature, including those of FISTA restart schemes. No assumption on the set of minimizers is required and guarantees are also given in the non-optimal case, i.e. when the condition number is not exactly known. This analysis follows the study of the corresponding continuous-time dynamical system (Heavy Ball with friction system), for which new convergence results of the trajectory are shown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.06930v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Fran\c{c}ois Aujol, Charles Dossal, Hippolyte Labarri\`ere, Aude Rondepierre</dc:creator>
    </item>
    <item>
      <title>Distributed Riemannian Stochastic Gradient Tracking Algorithm on the Stiefel Manifold</title>
      <link>https://arxiv.org/abs/2405.16900</link>
      <description>arXiv:2405.16900v2 Announce Type: replace 
Abstract: This paper focus on investigating the distributed Riemannian stochastic optimization problem on the Stiefel manifold for multi-agent systems, where all the agents work collaboratively to optimize a function modeled by the average of their expectation-valued local costs. Each agent only processes its own local cost function and communicate with neighboring agents to achieve optimal results while ensuring consensus. Since the local Riemannian gradient in stochastic regimes cannot be directly calculated, we will estimate the gradient by the average of a variable number of sampled gradient, which however brings about noise to the system. We then propose a distributed Riemannian stochastic optimization algorithm on the Stiefel manifold by combining the variable sample size gradient approximation method with the gradient tracking dynamic. It is worth noticing that the suitably chosen increasing sample size plays an important role in improving the algorithm efficiency, as it reduces the noise variance. In an expectation-valued sense, the iterates of all agents are proved to converge to a stationary point (or neighborhood) with fixed step sizes. We further establish the convergence rate of the iterates for the cases when the sample size is exponentially increasing, polynomial increasing, or a constant, respectively. Finally, numerical experiments are implemented to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16900v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jishu Zhao, Xi Wang, Jinlong Lei</dc:creator>
    </item>
    <item>
      <title>Cislunar Constellation Design for Space Situational Awareness with Time-Expanded p-Median Problem</title>
      <link>https://arxiv.org/abs/2408.06238</link>
      <description>arXiv:2408.06238v2 Announce Type: replace 
Abstract: Driven by the surmounting interest for a dedicated infrastructure in cislunar space, this work considers the satellite constellation design for cislunar space situational awareness (CSSA). We propose a linear programming (LP)-based formulation that simultaneously tackles the constellation design and sensor-tasking subproblems surrounding CSSA. Our approach generates constellation designs that provide coverage with considerations for the field-of-view of observers. We propose a time-expanded p-Median problem (TE-p-MP) which considers the optimal placement of p space-based observers into discretized locations based on orbital slots along libration point orbits, simultaneously with observer pointing directions across discretized time. We further develop a Lagrangian method for the TE-p-MP, where a relaxed problem with an analytical solution is derived, and customized heuristics leveraging the orbital structure of candidate observer locations are devised. The performance of the proposed formulation is demonstrated with several case studies for CSSA constellations monitoring the cislunar Cone of Shame and a periodic time-varying transit window for low-energy transfers located in the Earth-Moon L2 neck region. The proposed problem formulation, along with the Lagrangian method, is demonstrated to enable a fast assessment of near-optimal CSSA constellations, equipping decision-makers with a critical technique for exploring the design trade space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06238v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuri Shimane, Kento Tomita, Koki Ho</dc:creator>
    </item>
    <item>
      <title>Convergence and Bound Computation for Chance Constrained Distributionally Robust Models using Sample Approximation</title>
      <link>https://arxiv.org/abs/2408.12018</link>
      <description>arXiv:2408.12018v3 Announce Type: replace 
Abstract: This paper considers a distributionally robust chance constraint model with a general ambiguity set. We show that a sample based approximation of this model converges under suitable sufficient conditions. We also show that upper and lower bounds on the optimal value of the model can be estimated statistically. Specific ambiguity sets are discussed as examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12018v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiaqi Lei, Sanjay Mehrotra</dc:creator>
    </item>
    <item>
      <title>Safe Control and Learning Using the Generalized Action Governor</title>
      <link>https://arxiv.org/abs/2211.12628</link>
      <description>arXiv:2211.12628v2 Announce Type: replace-cross 
Abstract: This article introduces a general framework for safe control and learning based on the generalized action governor (AG). The AG is a supervisory scheme for augmenting a nominal closed-loop system with the ability of strictly handling prescribed safety constraints. In the first part of this article, we present a generalized AG methodology and analyze its key properties in a general setting. Then, we introduce tailored AG design approaches derived from the generalized methodology for linear and discrete systems. Afterward, we discuss the application of the generalized AG to facilitate safe online learning, which aims at safely evolving control parameters using real-time data to enhance control performance in uncertain systems. We present two safe learning algorithms based on, respectively, reinforcement learning and data-driven Koopman operator-based control integrated with the generalized AG to exemplify this application. Finally, we illustrate the developments with a numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12628v2</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Li, Yutong Li, Ilya Kolmanovsky, Anouck Girard, H. Eric Tseng, Dimitar Filev</dc:creator>
    </item>
    <item>
      <title>Sparsity-Aware Distributed Learning for Gaussian Processes with Linear Multiple Kernel</title>
      <link>https://arxiv.org/abs/2309.08201</link>
      <description>arXiv:2309.08201v3 Announce Type: replace-cross 
Abstract: Gaussian processes (GPs) stand as crucial tools in machine learning and signal processing, with their effectiveness hinging on kernel design and hyper-parameter optimization. This paper presents a novel GP linear multiple kernel (LMK) and a generic sparsity-aware distributed learning framework to optimize the hyper-parameters. The newly proposed grid spectral mixture product (GSMP) kernel is tailored for multi-dimensional data, effectively reducing the number of hyper-parameters while maintaining good approximation capability. We further demonstrate that the associated hyper-parameter optimization of this kernel yields sparse solutions. To exploit the inherent sparsity of the solutions, we introduce the Sparse LInear Multiple Kernel Learning (SLIM-KL) framework. The framework incorporates a quantized alternating direction method of multipliers (ADMM) scheme for collaborative learning among multiple agents, where the local optimization problem is solved using a distributed successive convex approximation (DSCA) algorithm. SLIM-KL effectively manages large-scale hyper-parameter optimization for the proposed kernel, simultaneously ensuring data privacy and minimizing communication costs. Theoretical analysis establishes convergence guarantees for the learning framework, while experiments on diverse datasets demonstrate the superior prediction performance and efficiency of our proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08201v3</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Cornelius Suwandi, Zhidi Lin, Feng Yin, Zhiguo Wang, Sergios Theodoridis</dc:creator>
    </item>
    <item>
      <title>Wasserstein Gradient Flows for Moreau Envelopes of f-Divergences in Reproducing Kernel Hilbert Spaces</title>
      <link>https://arxiv.org/abs/2402.04613</link>
      <description>arXiv:2402.04613v3 Announce Type: replace-cross 
Abstract: Commonly used $f$-divergences of measures, e.g., the Kullback-Leibler divergence, are subject to limitations regarding the support of the involved measures. A remedy is regularizing the $f$-divergence by a squared maximum mean discrepancy (MMD) associated with a characteristic kernel $K$. We use the kernel mean embedding to show that this regularization can be rewritten as the Moreau envelope of some function on the associated reproducing kernel Hilbert space. Then, we exploit well-known results on Moreau envelopes in Hilbert spaces to analyze the MMD-regularized $f$-divergences, particularly their gradients. Subsequently, we use our findings to analyze Wasserstein gradient flows of MMD-regularized $f$-divergences. We provide proof-of-the-concept numerical examples for flows starting from empirical measures. Here, we cover $f$-divergences with infinite and finite recession constants. Lastly, we extend our results to the tight variational formulation of $f$-divergences and numerically compare the resulting flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04613v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktor Stein, Sebastian Neumayer, Nicolaj Rux, Gabriele Steidl</dc:creator>
    </item>
    <item>
      <title>Actuation manifold from snapshot data</title>
      <link>https://arxiv.org/abs/2403.03653</link>
      <description>arXiv:2403.03653v2 Announce Type: replace-cross 
Abstract: We propose a data-driven methodology to learn a low-dimensional manifold of controlled flows. The starting point is resolving snapshot flow data for a representative ensemble of actuations. Key enablers for the actuation manifold are isometric mapping as encoder and a combination of a neural network and a k-nearest-neighbour interpolation as decoder. This methodology is tested for the fluidic pinball, a cluster of three parallel cylinders perpendicular to the oncoming uniform flow. The centres of these cylinders are the vertices of an equilateral triangle pointing upstream. The flow is manipulated by constant rotation of the cylinders, i.e. described by three actuation parameters. The Reynolds number based on a cylinder diameter is chosen to be 30. The unforced flow yields statistically symmetric periodic shedding represented by a one-dimensional limit cycle. The proposed methodology yields a five-dimensional manifold describing a wide range of dynamics with small representation error. Interestingly, the manifold coordinates automatically unveil physically meaningful parameters. Two of them describe the downstream periodic vortex shedding. The other three describe the near-field actuation, i.e. the strength of boat-tailing, the Magnus effect and forward stagnation point. The manifold is shown to be a key enabler for control-oriented flow estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03653v2</guid>
      <category>physics.flu-dyn</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1017/jfm.2024.593</arxiv:DOI>
      <arxiv:journal_reference>J. Fluid Mech. 996 (2024) A26</arxiv:journal_reference>
      <dc:creator>Luigi Marra, Guy Y. Cornejo Maceda, Andrea Meil\'an-Vila, Vanesa Guerrero, Salma Rashwan, Bernd R. Noack, Stefano Discetti, Andrea Ianiro</dc:creator>
    </item>
    <item>
      <title>Thermal Bootstrap of Matrix Quantum Mechanics</title>
      <link>https://arxiv.org/abs/2410.04262</link>
      <description>arXiv:2410.04262v2 Announce Type: replace-cross 
Abstract: We implement a bootstrap method that combines Schwinger-Dyson equations, thermal inequalities, and semidefinite relaxations of matrix logarithm in the ungauged one-matrix quantum mechanics, at finite rank N as well as in the large N limit, and determine finite temperature observables that interpolate between available analytic results in the low and high temperature limits respectively. We also obtain bootstrap bounds on thermal phase transition as well as preliminary results in the ungauged two-matrix quantum mechanics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.04262v2</guid>
      <category>hep-th</category>
      <category>cond-mat.str-el</category>
      <category>math.OC</category>
      <pubDate>Fri, 17 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minjae Cho, Barak Gabai, Joshua Sandor, Xi Yin</dc:creator>
    </item>
  </channel>
</rss>
