<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Aug 2024 04:00:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 02 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Condorcet's Jury Theorem with Abstention</title>
      <link>https://arxiv.org/abs/2408.00317</link>
      <description>arXiv:2408.00317v1 Announce Type: new 
Abstract: The well-known Condorcet's Jury theorem posits that the majority rule selects the best alternative among two available options with probability one, as the population size increases to infinity. We study this result under an asymmetric two-candidate setup, where supporters of both candidates may have different participation costs.
  When the decision to abstain is fully rational i.e., when the vote pivotality is the probability of a tie, the only equilibrium outcome is a trivial equilibrium where all voters except those with zero voting cost, abstain. We propose and analyze a more practical, boundedly rational model where voters overestimate their pivotality, and show that under this model, non-trivial equilibria emerge where the winning probability of both candidates is bounded away from one.
  We show that when the pivotality estimate strongly depends on the margin of victory, victory is not assured to any candidate in any non-trivial equilibrium, regardless of population size and in contrast to Condorcet's assertion. Whereas, under a weak dependence on margin, Condorcet's Jury theorem is restored.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00317v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganesh Ghalme, Reshef Meir</dc:creator>
    </item>
    <item>
      <title>Counterclockwise Dissipativity, Potential Games and Evolutionary Nash Equilibrium Learning</title>
      <link>https://arxiv.org/abs/2408.00647</link>
      <description>arXiv:2408.00647v1 Announce Type: new 
Abstract: We use system-theoretic passivity methods to study evolutionary Nash equilibria learning in large populations of agents engaged in strategic, non-cooperative interactions. The agents follow learning rules (rules for short) that capture their strategic preferences and a payoff mechanism ascribes payoffs to the available strategies. The population's aggregate strategic profile is the state of an associated evolutionary dynamical system. Evolutionary Nash equilibrium learning refers to the convergence of this state to the Nash equilibria set of the payoff mechanism. Most approaches consider memoryless payoff mechanisms, such as potential games. Recently, methods using $\delta$-passivity and equilibrium independent passivity (EIP) have introduced dynamic payoff mechanisms. However, $\delta$-passivity does not hold when agents follow rules exhibiting ``imitation" behavior, such as in replicator dynamics. Conversely, EIP applies to the replicator dynamics but not to $\delta$-passive rules. We address this gap using counterclockwise dissipativity (CCW). First, we prove that continuous memoryless payoff mechanisms are CCW if and only if they are potential games. Subsequently, under (possibly dynamic) CCW payoff mechanisms, we establish evolutionary Nash equilibrium learning for any rule within a convex cone spanned by imitation rules and continuous $\delta$-passive rules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00647v1</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nuno C. Martins, Jair Cert\'orio, Matthew S. Hankins</dc:creator>
    </item>
    <item>
      <title>A Policy-Gradient Approach to Solving Imperfect-Information Games with Iterate Convergence</title>
      <link>https://arxiv.org/abs/2408.00751</link>
      <description>arXiv:2408.00751v1 Announce Type: new 
Abstract: Policy gradient methods have become a staple of any single-agent reinforcement learning toolbox, due to their combination of desirable properties: iterate convergence, efficient use of stochastic trajectory feedback, and theoretically-sound avoidance of importance sampling corrections. In multi-agent imperfect-information settings (extensive-form games), however, it is still unknown whether the same desiderata can be guaranteed while retaining theoretical guarantees. Instead, sound methods for extensive-form games rely on approximating counterfactual values (as opposed to Q values), which are incompatible with policy gradient methodologies. In this paper, we investigate whether policy gradient can be safely used in two-player zero-sum imperfect-information extensive-form games (EFGs). We establish positive results, showing for the first time that a policy gradient method leads to provable best-iterate convergence to a regularized Nash equilibrium in self-play.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00751v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingyang Liu, Gabriele Farina, Asuman Ozdaglar</dc:creator>
    </item>
    <item>
      <title>Learning in Multi-Objective Public Goods Games with Non-Linear Utilities</title>
      <link>https://arxiv.org/abs/2408.00682</link>
      <description>arXiv:2408.00682v1 Announce Type: cross 
Abstract: Addressing the question of how to achieve optimal decision-making under risk and uncertainty is crucial for enhancing the capabilities of artificial agents that collaborate with or support humans. In this work, we address this question in the context of Public Goods Games. We study learning in a novel multi-objective version of the Public Goods Game where agents have different risk preferences, by means of multi-objective reinforcement learning. We introduce a parametric non-linear utility function to model risk preferences at the level of individual agents, over the collective and individual reward components of the game. We study the interplay between such preference modelling and environmental uncertainty on the incentive alignment level in the game. We demonstrate how different combinations of individual preferences and environmental uncertainties sustain the emergence of cooperative patterns in non-cooperative environments (i.e., where competitive strategies are dominant), while others sustain competitive patterns in cooperative environments (i.e., where cooperative strategies are dominant).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.00682v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicole Orzan, Erman Acar, Davide Grossi, Patrick Mannion, Roxana R\u{a}dulescu</dc:creator>
    </item>
    <item>
      <title>Resolving social dilemmas with minimal reward transfer</title>
      <link>https://arxiv.org/abs/2310.12928</link>
      <description>arXiv:2310.12928v3 Announce Type: replace 
Abstract: Social dilemmas present a significant challenge in multi-agent cooperation because individuals are incentivised to behave in ways that undermine socially optimal outcomes. Consequently, self-interested agents often avoid collective behaviour. In response, we formalise social dilemmas and introduce a novel metric, the general self-interest level, to quantify the disparity between individual and group rationality in such scenarios. This metric represents the maximum proportion of their individual rewards that agents can retain while ensuring that a social welfare optimum becomes a dominant strategy. Our approach diverges from traditional concepts of altruism, instead focusing on strategic reward redistribution. By transferring rewards among agents in a manner that aligns individual and group incentives, rational agents will maximise collective welfare while pursuing their own interests. We provide an algorithm to compute efficient transfer structures for an arbitrary number of agents, and introduce novel multi-player social dilemma games to illustrate the effectiveness of our method. This work provides both a descriptive tool for analysing social dilemmas and a prescriptive solution for resolving them via efficient reward transfer contracts. Applications include mechanism design, where we can assess the impact on collaborative behaviour of modifications to models of environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12928v3</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Richard Willis, Yali Du, Joel Z Leibo, Michael Luck</dc:creator>
    </item>
    <item>
      <title>Reputational Algorithm Aversion</title>
      <link>https://arxiv.org/abs/2402.15418</link>
      <description>arXiv:2402.15418v3 Announce Type: replace-cross 
Abstract: People are often reluctant to incorporate information produced by algorithms into their decisions, a phenomenon called ``algorithm aversion''. This paper shows how algorithm aversion arises when the choice to follow an algorithm conveys information about a human's ability. I develop a model in which workers make forecasts of an uncertain outcome based on their own private information and an algorithm's signal. Low-skill workers receive worse information than the algorithm and hence should always follow the algorithm's signal, while high-skill workers receive better information than the algorithm and should sometimes override it. However, due to reputational concerns, low-skill workers inefficiently override the algorithm to increase the likelihood they are perceived as high-skill. The model provides a fully rational microfoundation for algorithm aversion that aligns with the broad concern that AI systems will displace many types of workers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15418v3</guid>
      <category>econ.TH</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Weitzner</dc:creator>
    </item>
    <item>
      <title>Structural and Algorithmic Results for Stable Cycles and Partitions in the Roommates Problem</title>
      <link>https://arxiv.org/abs/2406.00437</link>
      <description>arXiv:2406.00437v2 Announce Type: replace-cross 
Abstract: In the Stable Roommates problem, we seek a stable matching of the agents into pairs, in which no two agents have an incentive to deviate from their assignment. It is well known that a stable matching is unlikely to exist, but a stable partition always does and provides a succinct certificate for the unsolvability of an instance. Furthermore, apart from being a useful structural tool to study the problem, every stable partition corresponds to a stable half-matching, which has applications, for example, in sports scheduling and time-sharing.
  We establish new structural results for stable partitions and show how to enumerate all stable partitions and the cycles included in such structures efficiently. We also adapt optimality criteria from stable matchings to stable partitions and give complexity and approximability results for the problems of computing such "fair" and "optimal" stable partitions.
  Through this research, we contribute to a deeper understanding of stable partitions from a combinatorial point of view, as well as the computational complexity of computing "fair" or "optimal" stable half-matchings in practice, closing the gap between integral and fractional stable matchings and paving the way for further applications of stable partitions to unsolvable instances and computationally hard stable matching problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00437v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
  </channel>
</rss>
