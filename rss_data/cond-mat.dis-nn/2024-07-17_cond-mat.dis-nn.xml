<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cond-mat.dis-nn updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cond-mat.dis-nn</link>
    <description>cond-mat.dis-nn updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cond-mat.dis-nn" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Discrete generative diffusion models without stochastic differential equations: a tensor network approach</title>
      <link>https://arxiv.org/abs/2407.11133</link>
      <description>arXiv:2407.11133v1 Announce Type: cross 
Abstract: Diffusion models (DMs) are a class of generative machine learning methods that sample a target distribution by transforming samples of a trivial (often Gaussian) distribution using a learned stochastic differential equation. In standard DMs, this is done by learning a ``score function'' that reverses the effect of adding diffusive noise to the distribution of interest. Here we consider the generalisation of DMs to lattice systems with discrete degrees of freedom, and where noise is added via Markov chain jump dynamics. We show how to use tensor networks (TNs) to efficiently define and sample such ``discrete diffusion models'' (DDMs) without explicitly having to solve a stochastic differential equation. We show the following: (i) by parametrising the data and evolution operators as TNs, the denoising dynamics can be represented exactly; (ii) the auto-regressive nature of TNs allows to generate samples efficiently and without bias; (iii) for sampling Boltzmann-like distributions, TNs allow to construct an efficient learning scheme that integrates well with Monte Carlo. We illustrate this approach to study the equilibrium of two models with non-trivial thermodynamics, the $d=1$ constrained Fredkin chain and the $d=2$ Ising model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11133v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Causer, Grant M. Rotskoff, Juan P. Garrahan</dc:creator>
    </item>
    <item>
      <title>Magnetic skin effect in Pb(Fe$_{1/2}$Nb$_{1/2}$)O$_3$</title>
      <link>https://arxiv.org/abs/2407.11227</link>
      <description>arXiv:2407.11227v1 Announce Type: cross 
Abstract: Relaxor-ferroelectrics display exceptional dielectric properties resulting from the underlying random dipolar fields induced by strong chemical inhomogeneity. An unusual structural aspect of relaxors is a skin-effect where the near-surface region in single crystals exhibit structures and critical phenomena that differ from the bulk. Relaxors are unique in that this skin effect extends over a macroscopic lengthscale of $\sim$ 100$\mu$m whereas usual surface layers only extend over a few unit cells (or $\sim$ nm). We present a muon spectroscopy study of Pb(Fe$_{1/2}$Nb$_{1/2}$)O$_{3}$ (PFN) which displays ferroelectric order, including many relaxor-like dielectric properties such as a frequency broadened dielectric response, and antiferromagnetism with spatially short-range polar correlations and hence can be termed a multiferroic. In terms of the magnetic behavior determined by the Fe$^{3+}$ ($S=5/2$, $L\approx0$) ions, PFN has been characterized as a unique example of a "cluster spin-glass". We use variable momentum muon spectroscopy to study the depth dependence of the slow magnetic relaxations in a large 1 cm$^{3}$ crystal of PFN. Zero-field positive muon spin relaxation is parameterized using a stretched exponential, indicative of a distribution of relaxation rates of the Fe$^{3+}$ spins. This bandwidth of frequencies changes as a function of muon momentum, indicative of a change in the Fe$^{3+}$ relaxation rates as a function of muon implantation depth in our single crystal. Using negative muon elemental analysis, we find small-to-no measurable change in the Fe$^{3+}$/Nb$^{5+}$ concentration with depth implying that chemical concentration alone cannot account for the change in the relaxational dynamics. PFN displays an analogous magnetic skin effect reported to exist in the structural properties of relaxor-ferroelectrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11227v1</guid>
      <category>cond-mat.str-el</category>
      <category>cond-mat.dis-nn</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. Giles-Donovan, A. D. Hillier, K. Ishida, B. V. Hampshire, S. R. Giblin, B. Roessli, P. M. Gehring, G. Xu, X. Li, H. Luo, S. Cochran, C. Stock</dc:creator>
    </item>
    <item>
      <title>Using recurrent neural networks to predict aspects of 3-D structure of folded copolymer sequences</title>
      <link>https://arxiv.org/abs/2407.11493</link>
      <description>arXiv:2407.11493v1 Announce Type: cross 
Abstract: The neural network techniques are developed for artificial sequences based on approximate models of proteins. We only encode the hydrophobicity of the amino acid side chains without attempting to model the secondary structure. We use our approach to obtain a large set of sequences with known 3-D structures for training the neural network. By employing recurrent neural networks we describe a way to augment a neural network to deal with sequences of realistic length and long-distant interactions between the sequence regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11493v1</guid>
      <category>cond-mat.soft</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Il Nuovo Cimento D, 20 (12bis), pp. 2565-2574 (1998).ISSN 0392-6737</arxiv:journal_reference>
      <dc:creator>R. G. Reilly, M. -T. Kechadi, Yu. A. Kuznetsov, E. G. Timoshenko, K. A. Dawson</dc:creator>
    </item>
    <item>
      <title>Evaluating the transport properties of interface-type, analog memristors</title>
      <link>https://arxiv.org/abs/2402.10358</link>
      <description>arXiv:2402.10358v2 Announce Type: replace 
Abstract: Interface-type, analog memristors have quite a reputation for real-time applications in edge sensorics, edge computing, and neuromorphic computing. The n-type conducting BiFeO3 (BFO) is such an interface-type, analog memristor which is also nonlinear and can therefore not only store, but also process data in the same memristor cell without data transfer between the data storage unit and the data processing unit. Here we present a physical memristor model which describes the hysteretic current-voltage curves of the BFO memristor in the small and large current-voltage range. Extracted internal state variables are reconfigured by the ion drift in the two write branches and are determining the electron transport in the two read branches. Simulation of electronic circuits with the BFO interface-type, analog memristors was not possible so far because previous physical memristor models have not captured the full range of internal state variables. We show quantitative agreement between modeled and experimental current-voltage curves exemplarily of three different BFO memristors in the small and large current-voltage ranges. Extracted dynamic and static internal state variables in the two full write branches and in the two full read branches, respectively, can be used for simulating electronic circuits with BFO memristors, e.g. in edge sensorics, edge computing, and neuromorphic computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10358v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.app-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sahitya V. Vegesna, Venkata Rao Rayapati, Heidemarie Schmidt</dc:creator>
    </item>
    <item>
      <title>Effects of forward disorder on quasi-1D superconductors</title>
      <link>https://arxiv.org/abs/2403.12597</link>
      <description>arXiv:2403.12597v2 Announce Type: replace 
Abstract: We study the competition between disorder and singlet superconductivity in a quasi-1d system. We investigate the applicability of the Anderson theorem, namely that time-reversal conserving (non-magnetic) disorder does not impact the critical temperature, by opposition to time-reversal breaking disorder (magnetic). To do so we examine a quasi-1d system of spin 1/2 fermions with attractive interactions and forward scattering disorder using field theory (bosonization). By computing the superconducting critical temperature ($T_c$), we find that for non-magnetic disorder the Anderson theorem also holds in the quasi-1D geometry. On the contrary, magnetic disorder has an impact on the critical temperature, that we investigate by deriving renormalization group (RG) equations describing the competition between the disorder and the interactions. Computing the critical temperature as a function of disorder strength, we see that different regimes arise depending on the strength of interactions. We discuss possible platforms where to observe this in cold atoms and condensed matter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12597v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.quant-gas</category>
      <category>cond-mat.str-el</category>
      <category>cond-mat.supr-con</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/PhysRevResearch.6.023291</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. Research 6, 023291 (2024)</arxiv:journal_reference>
      <dc:creator>Giacomo Morpurgo, Thierry Giamarchi</dc:creator>
    </item>
    <item>
      <title>Representing Arbitrary Ground States of Toric Code by Restricted Boltzmann Machine</title>
      <link>https://arxiv.org/abs/2407.01451</link>
      <description>arXiv:2407.01451v2 Announce Type: replace 
Abstract: We systematically analyze the representability of toric code ground states by Restricted Boltzmann Machine with only local connections between hidden and visible neurons. This analysis is pivotal for evaluating the model's capability to represent diverse ground states, thus enhancing our understanding of its strengths and weaknesses. Subsequently, we modify the Restricted Boltzmann Machine to accommodate arbitrary ground states by introducing essential non-local connections efficiently. The new model is not only analytically solvable but also demonstrates efficient and accurate performance when solved using machine learning techniques. Then we generalize our the model from $Z_2$ to $Z_n$ toric code and discuss future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01451v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.str-el</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>quant-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Penghua Chen, Bowen Yan, Shawn X. Cui</dc:creator>
    </item>
    <item>
      <title>A replica analysis of under-bagging</title>
      <link>https://arxiv.org/abs/2404.09779</link>
      <description>arXiv:2404.09779v3 Announce Type: replace-cross 
Abstract: Under-bagging (UB), which combines under-sampling and bagging, is a popular ensemble learning method for training classifiers on an imbalanced data. Using bagging to reduce the increased variance caused by the reduction in sample size due to under-sampling is a natural approach. However, it has recently been pointed out that in generalized linear models, naive bagging, which does not consider the class imbalance structure, and ridge regularization can produce the same results. Therefore, it is not obvious whether it is better to use UB, which requires an increased computational cost proportional to the number of under-sampled data sets, when training linear models. Given such a situation, in this study, we heuristically derive a sharp asymptotics of UB and use it to compare with several other popular methods for learning from imbalanced data, in the scenario where a linear classifier is trained from a two-component mixture data. The methods compared include the under-sampling (US) method, which trains a model using a single realization of the under-sampled data, and the simple weighting (SW) method, which trains a model with a weighted loss on the entire data. It is shown that the performance of UB is improved by increasing the size of the majority class while keeping the size of the minority fixed, even though the class imbalance can be large, especially when the size of the minority class is small. This is in contrast to US, whose performance is almost independent of the majority class size. In this sense, bagging and simple regularization differ as methods to reduce the variance increased by under-sampling. On the other hand, the performance of SW with the optimal weighting coefficients is almost equal to UB, indicating that the combination of reweighting and regularization may be similar to UB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09779v3</guid>
      <category>stat.ML</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Takashi Takahashi</dc:creator>
    </item>
  </channel>
</rss>
