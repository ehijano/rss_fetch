<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Rapid and Accurate Changepoint Detection of Power System Forced Oscillations</title>
      <link>https://arxiv.org/abs/2511.15812</link>
      <description>arXiv:2511.15812v1 Announce Type: new 
Abstract: This paper describes a new approach for using changepoint detection (CPD) to estimate the starting and stopping times of a forced oscillation (FO) in measured power system data. As with a previous application of CPD to this problem, the pruned exact linear time (PELT) algorithm is used. However, instead of allowing PELT to automatically tune its penalty parameter, a method of manually providing it is presented that dramatically reduces computation time without sacrificing accuracy. Additionally, the new algorithm requires fewer input parameters and provides a formal, data-driven approach to setting the minimum FO segment length to consider as troublesome for an electromechanical mode meter. A low-order ARMAX representation of the minniWECC model is used to test the approach, where a 98\% reduction in computation time is enjoyed with high estimation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15812v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luke Dosiek, Akaash Karn, Frank Liu</dc:creator>
    </item>
    <item>
      <title>EEG Emotion Recognition Through Deep Learning</title>
      <link>https://arxiv.org/abs/2511.15902</link>
      <description>arXiv:2511.15902v1 Announce Type: new 
Abstract: An advanced emotion classification model was developed using a CNN-Transformer architecture for emotion recognition from EEG brain wave signals, effectively distinguishing among three emotional states, positive, neutral and negative. The model achieved a testing accuracy of 91%, outperforming traditional models such as SVM, DNN, and Logistic Regression. Training was conducted on a custom dataset created by merging data from SEED, SEED-FRA, and SEED-GER repositories, comprising 1,455 samples with EEG recordings labeled according to emotional states. The combined dataset represents one of the largest and most culturally diverse collections available. Additionally, the model allows for the reduction of the requirements of the EEG apparatus, by leveraging only 5 electrodes of the 62. This reduction demonstrates the feasibility of deploying a more affordable consumer-grade EEG headset, thereby enabling accessible, at-home use, while also requiring less computational power. This advancement sets the groundwork for future exploration into mood changes induced by media content consumption, an area that remains underresearched. Integration into medical, wellness, and home-health platforms could enable continuous, passive emotional monitoring, particularly beneficial in clinical or caregiving settings where traditional behavioral cues, such as facial expressions or vocal tone, are diminished, restricted, or difficult to interpret, thus potentially transforming mental health diagnostics and interventions...</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15902v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Roman Dolgopolyi, Antonis Chatzipanagiotou</dc:creator>
    </item>
    <item>
      <title>Integrated Coexistence for Satellite and Terrestrial Networks with Multistatic ISAC</title>
      <link>https://arxiv.org/abs/2511.15947</link>
      <description>arXiv:2511.15947v1 Announce Type: new 
Abstract: Tightly integrated low earth orbit (LEO) satellite communications and terrestrial integrated sensing and communication (ISAC) are expected to be key novel aspects of the 6G era. Spectrum sharing between satellite and terrestrial cellular networks may, however, cause severe interference. This paper introduces a cooperation framework for integrated coexistence between satellite and terrestrial networks where the terrestrial network also deploys multistatic ISAC. Unlike prior works that assume ideal channel state information (CSI) acquisition, the proposed approach develops a practical structure consisting of pre-optimization and refinement stages that leverages the predictability of satellite CSI. In addition, a co-design of terrestrial beamforming and satellite power allocation utilizing a weighted minimum mean-squared error algorithm is proposed, and a target-radar association method designed for multistatic ISAC is presented. Simulation results show that the proposed approach significantly enhances the performance of these integrated networks. Furthermore, it is confirmed that the overall performance approaches the interference-free benchmark as the number of spot beams and radar receivers increases, demonstrating the feasibility of spectral coexistence between the two networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15947v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeongju Jee, Jeffrey G. Andrews</dc:creator>
    </item>
    <item>
      <title>Joint Admission Control and Power Minimization in IRS-assisted Networks</title>
      <link>https://arxiv.org/abs/2511.16000</link>
      <description>arXiv:2511.16000v1 Announce Type: new 
Abstract: Joint admission control and power minimization are critical challenges in intelligent reflecting surface (IRS)-assisted networks. Traditional methods often rely on \( l_1 \)-norm approximations and alternating optimization (AO) techniques, which suffer from high computational complexity and lack robust convergence guarantees. To address these limitations, we propose a sigmoid-based approximation of the \( l_0 \)-norm AC indicator, enabling a more efficient and tractable reformulation of the problem. Additionally, we introduce a penalty dual decomposition (PDD) algorithm to jointly optimize beamforming and admission control, ensuring convergence to a stationary solution. This approach reduces computational complexity and supports distributed implementation. Moreover, it outperforms existing methods by achieving lower power consumption, accommodating more users, and reducing computational time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16000v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCOMM.2025.3528041</arxiv:DOI>
      <arxiv:journal_reference>IEEE Communications Letters, vol. 29, no. 3, pp. 512-516, March 2025</arxiv:journal_reference>
      <dc:creator>Weijie Xiong, Jingran Lin, Zhiling Xiao, Qiang Li, Yuhan Zhang</dc:creator>
    </item>
    <item>
      <title>UT-OSANet: A Multimodal Deep Learning model for Evaluating and Classifying Obstructive Sleep Apnea</title>
      <link>https://arxiv.org/abs/2511.16169</link>
      <description>arXiv:2511.16169v1 Announce Type: new 
Abstract: Obstructive sleep apnea (OSA) is a highly prevalent sleep disorder that is associated with increased risks of cardiovascular morbidity and all-cause mortality. While existing diagnostic approaches can roughly classify OSA severity or detect isolated respiratory events, they lack the precision and comprehensiveness required for high resolution, event level diagnosis. Here, we present UT OSANet, a deep learning based model designed as a event level, multi scenario diagnostic tool for OSA. This model facilitates detailed identification of events associated with OSA, including apnea, hypopnea, oxygen desaturation, and arousal. Moreover, the model employs flexibly adjustable input modalities such as electroencephalography (EEG), airflow, and SpO 2. It utilizes a random masked modality combination training strategy, allowing it to comprehend cross-modal relationships while sustaining consistent performance across varying modality conditions. This model was trained and evaluated utilizing 9,021 polysomnography (PSG) recordings from five independent datasets. achieving sensitivities up to 0.93 and macro F1 scores of 0.84, 0.85 across home, clinical, and research scenarios. This model serves as an event-level, multi-scenario diagnostic instrument for real-world applications of OSA, while also establishing itself as a means to deepen the mechanistic comprehension of respiratory processes in sleep disorders and their extensive health implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16169v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijian Wang, Xiaoyu Bao, Chenhao Zhao, Jihui Zhang, Sizhi Ai, Yuanqing Li</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Rydberg Array Reuse: Modeling and Receiver Design for Sparse Channels</title>
      <link>https://arxiv.org/abs/2511.16260</link>
      <description>arXiv:2511.16260v1 Announce Type: new 
Abstract: Rydberg atomic quantum receivers have been seen as novel radio frequency measurements and the high sensitivity to a large range of frequencies makes it attractive for communications reception. However, current implementations of Rydberg array antennas predominantly rely on simple stacking of multiple single-antenna units. While conceptually straightforward, this approach leads to substantial system bulkiness due to the unique requirements of atomic sensors, particularly the need for multiple spatially separated laser setups, rendering such designs both impractical for real-world applications and challenging to fabricate. This limitation underscores the critical need for developing multiplexed Rydberg sensor array architectures. In the domain of conventional RF array antennas, hybrid analog-digital beamforming has emerged as a pivotal architecture for large-scale millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems, as it substantially reduces the hardware complexity associated with fully-digital beamforming while closely approaching its performance. Drawing inspiration from this methodology, we conduct a systematic study in this work on the design principles, equivalent modeling, and precoding strategies for low-complexity multiplexed Rydberg array, an endeavor crucial to enabling practical and scalable quantum-enhanced communication systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16260v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hao Wu, Shanchi Wu, Xinyuan Yao, Rui Ni, Chen Gong</dc:creator>
    </item>
    <item>
      <title>Dynamic Multiple-Parameter Joint Time-Vertex Fractional Fourier Transform and its Intelligent Filtering Methods</title>
      <link>https://arxiv.org/abs/2511.16277</link>
      <description>arXiv:2511.16277v1 Announce Type: new 
Abstract: Dynamic graph signal processing provides a principled framework for analyzing time-varying data defined on irregular graph domains. However, existing joint time-vertex transforms such as the joint time-vertex fractional Fourier transform assign only one fractional order to the spatial domain and another one to the temporal domain, thereby restricting their capacity to model the complex and continuously varying dynamics of graph signals. To address this limitation, we propose a novel dynamic multiple-parameter joint time-vertex fractional Fourier transform (DMPJFRFT) framework, which introduces time-varying fractional parameters to achieve adaptive spectral modeling of dynamic graph structures. By assigning distinct fractional orders to each time step, the proposed transform enables dynamic and flexible representation of spatio-temporal signal evolution in the joint time-vertex spectral domain. Theoretical properties of the DMPJFRFT are systematically analyzed, and two filtering approaches: a gradient descent-based method and a neural network-based method, are developed for dynamic signal restoration. Experimental results on dynamic graph and video datasets demonstrate that the proposed framework effectively captures temporal topology variations and achieves superior performance in denoising and deblurring tasks compared with some state-of-the-art graph-based transforms and neural networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16277v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Manjun Cui, Ziqi Yan, Yangfan He, Zhichao Zhang</dc:creator>
    </item>
    <item>
      <title>Revealing computation-communication trade-off in Segmented Pinching Antenna System (PASS)</title>
      <link>https://arxiv.org/abs/2511.16327</link>
      <description>arXiv:2511.16327v1 Announce Type: new 
Abstract: A joint communication and computation (JCC) framework using segmented pinching antenna system (PASS) is proposed, where both the communication bit streams and computation data are simultaneously transmitted via uplink communications. The segmented PASS design is used to yield the tractable uplink transmission, and to mitigate large-scale path loss and in-waveguide loss. Based on three operating protocols, namely segment selection (SS), segment aggregation (SA), and segment multiplexing (SM), the joint transmit and receive beamforming problem is formulated: 1) The mean square error (MSE) minimization problem is formulated for computation-oriented cases. To address this problem, a low-complexity alternating optimization-minimum mean square error (AO-MMSE) algorithm is developed. This problem is decomposed into receiver-side and transmitter-side MSE subproblems that are iteratively optimized by MMSE receivers to obtain the closed-form solutions. It is mathematically proved that the segmented JCC-PASS framework significantly outperforms the conventional PASS for the average in-waveguide propagation gain. 2) The weighted sum rate (WSR) maximization problem is formulated for communication-oriented cases. To solve the decomposed receiver-side and transmitter-side MSE subproblems, the AO-weighted minimum mean square error (AO-WMMSE) algorithm is further developed. An auxiliary weight variable is introduced to linearize the WSR function and is alternatively optimized based on WMMSE to derive the closed-form solutions. Simulation results demonstrate that: i) The proposed JCC-PASS framework achieves up to 70.65% and 45.32% reductions in MSE compared with conventional MIMO and conventional PASS, and ii) it reaches 87.70% and 51.35% improvements in WSR compared with conventional MIMO and conventional PASS, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16327v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deqiao Gan, Xiaoxia Xu, Xiaohu Ge, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>VersaPants: A Loose-Fitting Textile Capacitive Sensing System for Lower-Body Motion Capture</title>
      <link>https://arxiv.org/abs/2511.16346</link>
      <description>arXiv:2511.16346v1 Announce Type: new 
Abstract: We present VersaPants, the first loose-fitting, textile-based capacitive sensing system for lower-body motion capture, built on the open-hardware VersaSens platform. By integrating conductive textile patches and a compact acquisition unit into a pair of pants, the system reconstructs lower-body pose without compromising comfort. Unlike IMU-based systems that require user-specific fitting or camera-based methods that compromise privacy, our approach operates without fitting adjustments and preserves user privacy. VersaPants is a custom-designed smart garment featuring 6 capacitive channels per leg. We employ a lightweight Transformer-based deep learning model that maps capacitance signals to joint angles, enabling embedded implementation on edge platforms. To test our system, we collected approximately 3.7 hours of motion data from 11 participants performing 16 daily and exercise-based movements. The model achieves a mean per-joint position error (MPJPE) of 11.96 cm and a mean per-joint angle error (MPJAE) of 12.3 degrees across the hip, knee, and ankle joints, indicating the model's ability to generalize to unseen users and movements. A comparative analysis of existing textile-based deep learning architectures reveals that our model achieves competitive reconstruction performance with up to 22 times fewer parameters and 18 times fewer FLOPs, enabling real-time inference at 42 FPS on a commercial smartwatch without quantization. These results position VersaPants as a promising step toward scalable, comfortable, and embedded motion-capture solutions for fitness, healthcare, and wellbeing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16346v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Deniz Kasap (\'Ecole Polytechnique F\'ed\'erale de Lausanne), Taraneh Aminosharieh Najafi (\'Ecole Polytechnique F\'ed\'erale de Lausanne), J\'er\^ome Paul R\'emy Thevenot (\'Ecole Polytechnique F\'ed\'erale de Lausanne), Jonathan Dan (\'Ecole Polytechnique F\'ed\'erale de Lausanne), Stefano Albini (\'Ecole Polytechnique F\'ed\'erale de Lausanne), David Atienza (\'Ecole Polytechnique F\'ed\'erale de Lausanne)</dc:creator>
    </item>
    <item>
      <title>Neural Positioning Without External Reference</title>
      <link>https://arxiv.org/abs/2511.16352</link>
      <description>arXiv:2511.16352v1 Announce Type: new 
Abstract: Channel state information (CSI)-based user equipment (UE) positioning with neural networks -- referred to as neural positioning -- is a promising approach for accurate off-device UE localization. Most existing methods train their neural networks with ground-truth position labels obtained from external reference positioning systems, which requires costly hardware and renders label acquisition difficult in large areas. In this work, we propose a novel neural positioning pipeline that avoids the need for any external reference positioning system. Our approach trains the positioning network only using CSI acquired off-device and relative displacement commands executed on commercial off-the-shelf (COTS) robot platforms, such as robotic vacuum cleaners -- such an approach enables inexpensive training of accurate neural positioning functions over large areas. We evaluate our method in three real-world scenarios, ranging from small line-of-sight (LoS) areas to larger non-line-of-sight (NLoS) environments, using CSI measurements acquired in IEEE 802.11 Wi-Fi and 5G New Radio (NR) systems. Our experiments demonstrate that the proposed neural positioning pipeline achieves UE localization accuracies close to state-of-the-art methods that require externally acquired high-precision ground-truth position labels for training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16352v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Till-Yannic M\"uller, Frederik Zumegen, Reinhard Wiesmayr, Emre G\"on\"ulta\c{s}, Christoph Studer</dc:creator>
    </item>
    <item>
      <title>Reasoning Meets Representation: Envisioning Neuro-Symbolic Wireless Foundation Models</title>
      <link>https://arxiv.org/abs/2511.16369</link>
      <description>arXiv:2511.16369v1 Announce Type: new 
Abstract: Recent advances in Wireless Physical Layer Foundation Models (WPFMs) promise a new paradigm of universal Radio Frequency (RF) representations. However, these models inherit critical limitations found in deep learning such as the lack of explainability, robustness, adaptability, and verifiable compliance with physical and regulatory constraints. In addition, the vision for an AI-native 6G network demands a level of intelligence that is deeply embedded into the systems and is trustworthy. In this vision paper, we argue that the neuro-symbolic paradigm, which integrates data-driven neural networks with rule- and logic-based symbolic reasoning, is essential for bridging this gap. We envision a novel Neuro-Symbolic framework that integrates universal RF embeddings with symbolic knowledge graphs and differentiable logic layers. This hybrid approach enables models to learn from large datasets while reasoning over explicit domain knowledge, enabling trustworthy, generalizable, and efficient wireless AI that can meet the demands of future networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16369v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jaron Fontaine, Mohammad Cheraghinia, John Strassner, Adnan Shahid, Eli De Poorter</dc:creator>
    </item>
    <item>
      <title>3-20 GHz Wideband Tightly-Coupled Dual-Polarized Vivaldi Antenna Array</title>
      <link>https://arxiv.org/abs/2511.16472</link>
      <description>arXiv:2511.16472v1 Announce Type: new 
Abstract: Very wideband apertures are needed in positioning, sensing, spectrum monitoring, and modern spread spectrum, e.g., frequency hopping systems. Vivaldi antennas are one of the prominent choices for the aforementioned systems due to their natural wideband characteristics. Furthermore, tightly-coupled antenna arrays have been researched in the recent years to extend the lower band edge of compact arrays by taking advantage of the strong mutual coupling between the elements especially with dipole elements, but not with dual-polarized Vivaldi antennas. This paper presents a novel tightly-coupled dual-polarized antipodal Vivaldi antenna (TC-AVA) with -6 dB impedance bandwidth of 3 to 20 GHz. The tight coupling by overlapping the Vivaldi leaves is shown to extend the lower band edge from 3.75 to 3 GHz and 2.75 GHz, an improvement of 20% to 25% for both polarizations, compared with an isolated antipodal Vivaldi element.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16472v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.23919/EuCAP63536.2025.10999668</arxiv:DOI>
      <arxiv:journal_reference>2025 19th European Conference on Antennas and Propagation (EuCAP)</arxiv:journal_reference>
      <dc:creator>Niko Lindvall, Mikko Heino, Mikko Valkama</dc:creator>
    </item>
    <item>
      <title>TFCDiff: Robust ECG Denoising via Time-Frequency Complementary Diffusion</title>
      <link>https://arxiv.org/abs/2511.16627</link>
      <description>arXiv:2511.16627v1 Announce Type: new 
Abstract: Ambulatory electrocardiogram (ECG) readings are prone to mixed noise from physical activities, including baseline wander (BW), muscle artifact (MA), and electrode motion artifact (EM). Developing a method to remove such complex noise and reconstruct high-fidelity signals is clinically valuable for diagnostic accuracy. However, denoising of multi-beat ECG segments remains understudied and poses technical challenges. To address this, we propose Time-Frequency Complementary Diffusion (TFCDiff), a novel approach that operates in the Discrete Cosine Transform (DCT) domain and uses the DCT coefficients of noisy signals as conditioning input. To refine waveform details, we incorporate Temporal Feature Enhancement Mechanism (TFEM) to reinforce temporal representations and preserve key physiological information. Comparative experiments on a synthesized dataset demonstrate that TFCDiff achieves state-of-the-art performance across five evaluation metrics. Furthermore, TFCDiff shows superior generalization on the unseen SimEMG Database, outperforming all benchmark models. Notably, TFCDiff processes raw 10-second sequences and maintains robustness under flexible random mixed noise (fRMN), enabling plug-and-play deployment in wearable ECG monitors for high-motion scenarios. Source code is available at https://github.com/Miroircivil/TFCDiff.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16627v1</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pengxin Li, Yimin Zhou, Jie Min, Yirong Wang, Wei Liang, Wang Li</dc:creator>
    </item>
    <item>
      <title>A Generalized Weighted Overlap-Add (WOLA) Filter Bank for Improved Subband System Identification</title>
      <link>https://arxiv.org/abs/2511.15766</link>
      <description>arXiv:2511.15766v1 Announce Type: cross 
Abstract: This paper addresses the challenges in short-time Fourier transform (STFT) domain subband adaptive filtering, in particular, subband system identification. Previous studies in this area have primarily focused on setups with subband filtering at a downsampled rate, implemented using the weighted overlap-add (WOLA) filter bank, popular in audio and speech-processing for its reduced complexity. However, this traditional approach imposes constraints on the subband filters when transformed to their full-rate representation. This paper makes three key contributions. First, it introduces a generalized WOLA filter bank that repositions subband filters before the downsampling operation, eliminating the constraints on subband filters inherent in the conventional WOLA filter bank. Second, it investigates the mean square error (MSE) performance of the generalized WOLA filter bank for full-band system identification, establishing analytical ties between the order of subband filters, the full-band system impulse response length, the decimation factor, and the prototype filters. Third, to address the increased computational complexity of the generalized WOLA, the paper proposes a low-complexity implementation termed per-tone weighted overlap-add (PT-WOLA), which maintains computational complexity on par with conventional WOLA. Analytical and empirical evidence demonstrates that the proposed generalized WOLA filter bank significantly enhances the performance of subband system identification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15766v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TSP.2025.3614849</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Signal Processing, vol. 73, pp. 4155-4169, year 2025</arxiv:journal_reference>
      <dc:creator>Mohit Sharma (Department of Electrical Engineering), Robbe Van Rompaey (Nokia Bell Labs, Antwerp, Belgium), Wouter Lanneer (Nokia Bell Labs, Antwerp, Belgium), Marc Moonen (Department of Electrical Engineering)</dc:creator>
    </item>
    <item>
      <title>Attention-Based Feature Online Conformal Prediction for Time Series</title>
      <link>https://arxiv.org/abs/2511.15838</link>
      <description>arXiv:2511.15838v1 Announce Type: cross 
Abstract: Online conformal prediction (OCP) wraps around any pre-trained predictor to produce prediction sets with coverage guarantees that hold irrespective of temporal dependencies or distribution shifts. However, standard OCP faces two key limitations: it operates in the output space using simple nonconformity (NC) scores, and it treats all historical observations uniformly when estimating quantiles. This paper introduces attention-based feature OCP (AFOCP), which addresses both limitations through two key innovations. First, AFOCP operates in the feature space of pre-trained neural networks, leveraging learned representations to construct more compact prediction sets by concentrating on task-relevant information while suppressing nuisance variation. Second, AFOCP incorporates an attention mechanism that adaptively weights historical observations based on their relevance to the current test point, effectively handling non-stationarity and distribution shifts. We provide theoretical guarantees showing that AFOCP maintains long-term coverage while provably achieving smaller prediction intervals than standard OCP under mild regularity conditions. Extensive experiments on synthetic and real-world time series datasets demonstrate that AFOCP consistently reduces the size of prediction intervals by as much as $88\%$ as compared to OCP, while maintaining target coverage levels, validating the benefits of both feature-space calibration and attention-based adaptive weighting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15838v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meiyi Zhu, Caili Guo, Chunyan Feng, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>L-JacobiNet and S-JacobiNet: An Analysis of Adaptive Generalization, Stabilization, and Spectral Domain Trade-offs in GNNs</title>
      <link>https://arxiv.org/abs/2511.16081</link>
      <description>arXiv:2511.16081v1 Announce Type: cross 
Abstract: Spectral GNNs, like ChebyNet, are limited by heterophily and over-smoothing due to their static, low-pass filter design. This work investigates the "Adaptive Orthogonal Polynomial Filter" (AOPF) class as a solution. We introduce two models operating in the [-1, 1] domain: 1) `L-JacobiNet`, the adaptive generalization of `ChebyNet` with learnable alpha, beta shape parameters, and 2) `S-JacobiNet`, a novel baseline representing a LayerNorm-stabilized static `ChebyNet`. Our analysis, comparing these models against AOPFs in the [0, infty) domain (e.g., `LaguerreNet`), reveals critical, previously unknown trade-offs. We find that the [0, infty) domain is superior for modeling heterophily, while the [-1, 1] domain (Jacobi) provides superior numerical stability at high K (K&gt;20). Most significantly, we discover that `ChebyNet`'s main flaw is stabilization, not its static nature. Our static `S-JacobiNet` (ChebyNet+LayerNorm) outperforms the adaptive `L-JacobiNet` on 4 out of 5 benchmark datasets, identifying `S-JacobiNet` as a powerful, overlooked baseline and suggesting that adaptation in the [-1, 1] domain can lead to overfitting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16081v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huseyin Goksu</dc:creator>
    </item>
    <item>
      <title>HybSpecNet: A Critical Analysis of Architectural Instability in Hybrid-Domain Spectral GNNs</title>
      <link>https://arxiv.org/abs/2511.16101</link>
      <description>arXiv:2511.16101v1 Announce Type: cross 
Abstract: Spectral Graph Neural Networks offer a principled approach to graph filtering but face a fundamental "Stability-vs-Adaptivity" trade-off. This trade-off is dictated by the choice of spectral domain. Filters in the finite [-1, 1] domain (e.g., ChebyNet) are numerically stable at high polynomial degrees (K) but are static and low-pass, causing them to fail on heterophilic graphs. Conversely, filters in the semi-infinite [0, infty) domain (e.g., KrawtchoukNet) are highly adaptive and achieve SOTA results on heterophily by learning non-low-pass responses. However, as we demonstrate, these adaptive filters can also suffer from numerical instability, leading to catastrophic performance collapse at high K. In this paper, we propose to resolve this trade-off by designing a hybrid-domain GNN, HybSpecNet, which combines a stable `ChebyNet` branch with an adaptive `KrawtchoukNet` branch. We first demonstrate that a "naive" hybrid architecture, which fuses the branches via concatenation, successfully unifies performance at low K, achieving strong results on both homophilic and heterophilic benchmarks. However, we then prove that this naive architecture fails the stability test. Our K-ablation experiments show that this architecture catastrophically collapses at K=25, exactly mirroring the collapse of its unstable `KrawtchoukNet` branch. We identify this critical finding as "Instability Poisoning," where `NaN`/`Inf` gradients from the adaptive branch destroy the training of the model. Finally, we propose and validate an advanced architecture that uses "Late Fusion" to completely isolate the gradient pathways. We demonstrate that this successfully solves the instability problem, remaining perfectly stable up to K=30 while retaining its SOTA performance across all graph types. This work identifies a critical architectural pitfall in hybrid GNN design and provides the robust architectural solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16101v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huseyin Goksu</dc:creator>
    </item>
    <item>
      <title>SUNAC: Source-aware Unified Neural Audio Codec</title>
      <link>https://arxiv.org/abs/2511.16126</link>
      <description>arXiv:2511.16126v1 Announce Type: cross 
Abstract: Neural audio codecs (NACs) provide compact representations that can be leveraged in many downstream applications, in particular large language models. Yet most NACs encode mixtures of multiple sources in an entangled manner, which may impede efficient downstream processing in applications that need access to only a subset of the sources (e.g., analysis of a particular type of sound, transcription of a given speaker, etc). To address this, we propose a source-aware codec that encodes individual sources directly from mixtures, conditioned on source type prompts. This enables user-driven selection of which source(s) to encode, including separately encoding multiple sources of the same type (e.g., multiple speech signals). Experiments show that our model achieves competitive resynthesis and separation quality relative to a cascade of source separation followed by a conventional NAC, with lower computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16126v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryo Aihara, Yoshiki Masuyama, Francesco Paissan, Fran\c{c}ois G. Germain, Gordon Wichern, Jonathan Le Roux</dc:creator>
    </item>
    <item>
      <title>Variational Quantum Integrated Sensing and Communication</title>
      <link>https://arxiv.org/abs/2511.16597</link>
      <description>arXiv:2511.16597v1 Announce Type: cross 
Abstract: The integration of sensing and communication functionalities within a common system is one of the main innovation drivers for next-generation networks. In this paper, we introduce a quantum integrated sensing and communication (QISAC) protocol that leverages entanglement in quantum carriers of information to enable both superdense coding and quantum sensing. The proposed approach adaptively optimizes encoding and quantum measurement via variational circuit learning, while employing classical machine learning-based decoders and estimators to process the measurement outcomes. Numerical results for qudit systems demonstrate that the proposed QISAC protocol can achieve a flexible trade-off between classical communication rate and accuracy of parameter estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16597v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivana Nikoloska, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>CardioLab: Laboratory Values Estimation from Electrocardiogram Features - An Exploratory Study</title>
      <link>https://arxiv.org/abs/2407.18629</link>
      <description>arXiv:2407.18629v3 Announce Type: replace 
Abstract: Laboratory value represents a cornerstone of medical diagnostics, but suffers from slow turnaround times, and high costs and only provides information about a single point in time. The continuous estimation of laboratory values from non-invasive data such as electrocardiogram (ECG) would therefore mark a significant frontier in healthcare monitoring. Despite its potential, this domain remains relatively underexplored. In this preliminary study, we used a publicly available dataset (MIMIC-IV-ECG) to investigate the feasibility of inferring laboratory values from ECG features and patient demographics using tree-based models (XGBoost). We define the prediction task as a binary problem of whether the lab value falls into low or high abnormalities. We assessed model performance with AUROC. Our findings demonstrate promising results in the estimation of laboratory values related to different organ systems. While further research and validation are warranted to fully assess the clinical utility and generalizability of the approach, our findings lay the groundwork for future investigations for laboratory value estimation using ECG data. Such advancements hold promise for revolutionizing predictive healthcare applications, offering faster, non-invasive, and more affordable means of patient monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18629v3</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Miguel Lopez Alcaraz, Nils Strodthoff</dc:creator>
    </item>
    <item>
      <title>Estimation of Cardiac and Non-cardiac Diagnosis from Electrocardiogram Features</title>
      <link>https://arxiv.org/abs/2408.17329</link>
      <description>arXiv:2408.17329v2 Announce Type: replace 
Abstract: Ensuring timely and accurate diagnosis of medical conditions is paramount for effective patient care. Electrocardiogram (ECG) signals are fundamental for evaluating a patient's cardiac health and are readily available. Despite this, little attention has been given to the remarkable potential of ECG data in detecting non-cardiac conditions. In our study, we used publicly available datasets (MIMIC-IV-ECG-ICD and ECG-VIEW II) to investigate the feasibility of inferring general diagnostic conditions from ECG features. To this end, we trained a tree-based model (XGBoost) based on ECG features and basic demographic features to estimate a wide range of diagnoses, encompassing both cardiac and non-cardiac conditions. Our results demonstrate the reliability of estimating 23 cardiac as well as 21 non-cardiac conditions above 0.7 AUROC in a statistically significant manner across a wide range of physiological categories. Our findings underscore the predictive potential of ECG data in identifying well-known cardiac conditions. However, even more striking, this research represents a pioneering effort in systematically expanding the scope of ECG-based diagnosis to conditions not traditionally associated with the cardiac system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.17329v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Miguel Lopez Alcaraz, Nils Strodthoff</dc:creator>
    </item>
    <item>
      <title>Explainable machine learning for neoplasms diagnosis via electrocardiograms: an externally validated study</title>
      <link>https://arxiv.org/abs/2412.07737</link>
      <description>arXiv:2412.07737v2 Announce Type: replace 
Abstract: Background: Neoplasms are a major cause of mortality globally, where early diagnosis is essential for improving outcomes. Current diagnostic methods are often invasive, expensive, and inaccessible in resource-limited settings. This study explores the potential of electrocardiogram (ECG) data, a widely available and non-invasive tool for diagnosing neoplasms through cardiovascular changes linked to neoplastic presence.
  Methods: A diagnostic pipeline combining tree-based machine learning models with Shapley value analysis for explainability was developed. The model was trained and internally validated on a large dataset and externally validated on an independent cohort to ensure robustness and generalizability. Key ECG features contributing to predictions were identified and analyzed.
  Results: The model achieved high diagnostic accuracy in both internal testing and external validation cohorts. Shapley value analysis highlighted significant ECG features, including novel predictors. The approach is cost-effective, scalable, and suitable for resource-limited settings, offering insights into cardiovascular changes associated with neoplasms and their therapies.
  Conclusions: This study demonstrates the feasibility of using ECG signals and machine learning for non-invasive neoplasm diagnosis. By providing interpretable insights into cardio-neoplasm interactions, this method addresses gaps in diagnostics and supports integration into broader diagnostic and therapeutic frameworks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07737v2</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1186/s40959-025-00370-1</arxiv:DOI>
      <dc:creator>Juan Miguel Lopez Alcaraz, Wilhelm Haverkamp, Nils Strodthoff</dc:creator>
    </item>
    <item>
      <title>Low-Complexity Frequency-Dependent Linearizers Based on Parallel Bias-Modulus and Bias-ReLU Operations</title>
      <link>https://arxiv.org/abs/2412.16210</link>
      <description>arXiv:2412.16210v2 Announce Type: replace 
Abstract: This paper introduces low-complexity frequency-dependent (memory) linearizers designed to suppress nonlinear distortion in analog-to-digital interfaces. Two different linearizers are considered, based on nonlinearity models which correspond to sampling before and after the nonlinearity operations, respectively. The proposed linearizers are inspired by convolutional neural networks but have an order-of-magnitude lower implementation complexity compared to existing neural-network-based linearizer schemes. The proposed linearizers can also outperform the traditional parallel Hammerstein (as well as Wiener) linearizers even when the nonlinearities have been generated through a Hammerstein model. Further, a design procedure is proposed in which the linearizer parameters are obtained through matrix inversion. This eliminates the need for costly and time-consuming iterative nonconvex optimization which is traditionally associated with neural network training. The design effectively handles a wide range of wideband multi-tone signals and filtered white noise. Examples demonstrate significant signal-to-noise-and-distortion ratio (SNDR) improvements of some $20$--$30$ dB, as well as a lower implementation complexity than the Hammerstein linearizers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16210v2</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deijany Rodriguez Linares, H{\aa}kan Johansson</dc:creator>
    </item>
    <item>
      <title>CSI-Bench: A Large-Scale In-the-Wild Dataset for Multi-task WiFi Sensing</title>
      <link>https://arxiv.org/abs/2505.21866</link>
      <description>arXiv:2505.21866v2 Announce Type: replace 
Abstract: WiFi sensing has emerged as a compelling contactless modality for human activity monitoring by capturing fine-grained variations in Channel State Information (CSI). Its ability to operate continuously and non-intrusively while preserving user privacy makes it particularly suitable for health monitoring. However, existing WiFi sensing systems struggle to generalize in real-world settings, largely due to datasets collected in controlled environments with homogeneous hardware and fragmented, session-based recordings that fail to reflect continuous daily activity.
  We present CSI-Bench, a large-scale, in-the-wild benchmark dataset collected using commercial WiFi edge devices across 26 diverse indoor environments with 35 real users. Spanning over 461 hours of effective data, CSI-Bench captures realistic signal variability under natural conditions. It includes task-specific datasets for fall detection, breathing monitoring, localization, and motion source recognition, as well as a co-labeled multitask dataset with joint annotations for user identity, activity, and proximity. To support the development of robust and generalizable models, CSI-Bench provides standardized evaluation splits and baseline results for both single-task and multi-task learning. CSI-Bench offers a foundation for scalable, privacy-preserving WiFi sensing systems in health and broader human-centric applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21866v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guozhen Zhu, Yuqian Hu, Weihang Gao, Wei-Hsiang Wang, Beibei Wang, K. J. Ray Liu</dc:creator>
    </item>
    <item>
      <title>Theoretical Guarantees for AOA-based Localization: Consistency and Asymptotic Efficiency</title>
      <link>https://arxiv.org/abs/2507.07647</link>
      <description>arXiv:2507.07647v2 Announce Type: replace 
Abstract: We study the problem of signal source localization using angle of arrival (AOA) measurements. We begin by presenting verifiable geometric conditions for sensor deployment that ensure the model's asymptotic localizability. Then we establish the consistency and asymptotic efficiency of the maximum likelihood (ML) estimator. However, obtaining the ML estimator is challenging due to its association with a non-convex optimization problem. To address this, we propose an asymptotically efficient two-step estimator that matches the ML estimator's asymptotic properties while achieving low computational complexity (linear in the number of measurements). The primary challenge lies in obtaining a consistent estimator in the first step. To achieve this, we construct a linear least squares problem through algebraic operations on the measurement nonlinear model to first obtain a biased closed-form solution. We then eliminate the bias using the data to yield an asymptotically unbiased and consistent estimator. In the second step, we perform a single Gauss-Newton iteration using the preliminary consistent estimator as the initial value, achieving the same asymptotic properties as the ML estimator. Finally, simulation results demonstrate the superior performance of the proposed two-step estimator for large sample sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.07647v2</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shenghua Hu, Guangyang Zeng, Wenchao Xue, Haitao Fang, Biqiang Mu</dc:creator>
    </item>
    <item>
      <title>Depression diagnosis from patient interviews using multimodal machine learning</title>
      <link>https://arxiv.org/abs/2508.19390</link>
      <description>arXiv:2508.19390v2 Announce Type: replace 
Abstract: Background: Depression is a major public health concern, affecting an estimated five percent of the global population. Early and accurate diagnosis is essential to initiate effective treatment, yet recognition remains challenging in many clinical contexts. Speech, language, and behavioral cues collected during patient interviews may provide objective markers that support clinical assessment.
  Methods: We developed a diagnostic approach that integrates features derived from patient interviews, including speech patterns, linguistic characteristics, and structured clinical information. Separate models were trained for each modality and subsequently combined through multimodal fusion to reflect the complexity of real-world psychiatric assessment. Model validity was assessed with established performance metrics, and further evaluated using calibration and decision-analytic approaches to estimate potential clinical utility.
  Results: The multimodal model achieved superior diagnostic accuracy compared to single-modality models, with an AUROC of 0.88 and a macro F1-score of 0.75. Importantly, the fused model demonstrated good calibration and offered higher net clinical benefit compared to baseline strategies, highlighting its potential to assist clinicians in identifying patients with depression more reliably.
  Conclusion: Multimodal analysis of patient interviews using machine learning may serve as a valuable adjunct to psychiatric evaluation. By combining speech, language, and clinical features, this approach provides a robust framework that could enhance early detection of depressive disorders and support evidence-based decision-making in mental healthcare.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19390v2</guid>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jana Weber, Marcel Weber, Juan Miguel Lopez Alcaraz</dc:creator>
    </item>
    <item>
      <title>Credible Uncertainty Quantification under Noise and System Model Mismatch</title>
      <link>https://arxiv.org/abs/2509.03311</link>
      <description>arXiv:2509.03311v4 Announce Type: replace 
Abstract: State estimators often provide self-assessed uncertainty metrics, such as covariance matrices, whose credibility is critical for downstream tasks. However, these self-assessments can be misleading due to underlying modeling violations like noise model mismatch (NMM) or system model misspecification (SMM). This letter addresses this problem by developing a unified, multi-metric framework that integrates noncredibility index (NCI), negative log-likelihood (NLL), and energy score (ES) metrics, featuring an empirical location test (ELT) to detect system model bias and a directional probing technique that uses the metrics' asymmetric sensitivities to distinguish NMM from SMM. Monte Carlo simulations reveal that the proposed method achieves excellent diagnosis accuracy (80-100%) and significantly outperforms single-metric diagnosis methods. The effectiveness of the proposed method is further validated on a real-world UWB positioning dataset. This framework provides a practical tool for turning patterns of credibility indicators into actionable diagnoses of model deficiencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03311v4</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Penggao Ya, Li-Ta Hsu, Rui Sun</dc:creator>
    </item>
    <item>
      <title>Gamma-Based Statistical Modeling for Extended Target Detection in mmWave Automotive Radar</title>
      <link>https://arxiv.org/abs/2509.26573</link>
      <description>arXiv:2509.26573v3 Announce Type: replace 
Abstract: Millimeter-wave (mmWave) radar systems, owing to their large bandwidth, provide fine range resolution that enables the observation of multiple scatterers originating from a single automotive target, commonly referred to as an extended target. Conventional CFAR-based detection algorithms typically treat these scatterers as independent detections, thereby discarding the spatial scattering structure intrinsic to the target. To preserve this scattering spread, this paper proposes a Range-Doppler (RD) segment framework designed to encapsulate the typical scattering profile of an automobile. The statistical characterization of the segment is performed using Maximum Likelihood Estimation (MLE) and posterior density modeling based on the Gamma distribution, facilitated through Gibbs Markov Chain Monte Carlo (MCMC) sampling. A skewness-based test statistic, derived from the estimated statistical model, is introduced for binary hypothesis classification of extended targets. Additionally, the paper presents a detection pipeline that incorporates Intersection over Union (IoU) and segment centering based on peak response, optimized to work within a single dwell. Extensive evaluations using both simulated and real-world datasets demonstrate the effectiveness of the proposed approach, underscoring its suitability for automotive radar applications through improved detection accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26573v3</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinay Kulkarni, V. V. Reddy</dc:creator>
    </item>
    <item>
      <title>Recent Advances in Discrete Speech Tokens: A Review</title>
      <link>https://arxiv.org/abs/2502.06490</link>
      <description>arXiv:2502.06490v3 Announce Type: replace-cross 
Abstract: The rapid advancement of speech generation technologies in the era of large language models (LLMs) has established discrete speech tokens as a foundational paradigm for speech representation. These tokens, characterized by their discrete, compact, and concise nature, are not only advantageous for efficient transmission and storage, but also inherently compatible with the language modeling framework, enabling seamless integration of speech into text-dominated LLM architectures. Current research categorizes discrete speech tokens into two principal classes: acoustic tokens and semantic tokens, each of which has evolved into a rich research domain characterized by unique design philosophies and methodological approaches. This survey systematically synthesizes the existing taxonomy and recent innovations in discrete speech tokenization, conducts a critical examination of the strengths and limitations of each paradigm, and presents systematic experimental comparisons across token types. Furthermore, we identify persistent challenges in the field and propose potential research directions, aiming to offer actionable insights to inspire future advancements in the development and application of discrete speech tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06490v3</guid>
      <category>eess.AS</category>
      <category>cs.AI</category>
      <category>cs.MM</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiwei Guo, Zhihan Li, Hankun Wang, Bohan Li, Chongtian Shao, Hanglei Zhang, Chenpeng Du, Xie Chen, Shujie Liu, Kai Yu</dc:creator>
    </item>
    <item>
      <title>To Trust or Not to Trust: On Calibration in ML-based Resource Allocation for Wireless Networks</title>
      <link>https://arxiv.org/abs/2507.17494</link>
      <description>arXiv:2507.17494v3 Announce Type: replace-cross 
Abstract: In next-generation communications and networks, machine learning (ML) models are expected to deliver not only accurate predictions but also well-calibrated confidence scores that reflect the true likelihood of correct decisions. This paper studies the calibration performance of an ML-based outage predictor within a single-user, multi-resource allocation framework. We first establish key theoretical properties of this system's outage probability (OP) under perfect calibration. Importantly, we show that as the number of resources grows, the OP of a perfectly calibrated predictor approaches the expected output conditioned on it being below the classification threshold. In contrast, when only one resource is available, the system's OP equals the model's overall expected output. We then derive the OP conditions for a perfectly calibrated predictor. These findings guide the choice of the classification threshold to achieve a desired OP, helping system designers meet specific reliability requirements. We also demonstrate that post-processing calibration cannot improve the system's minimum achievable OP, as it does not introduce new information about future channel states. Additionally, we show that well-calibrated models are part of a broader class of predictors that necessarily improve OP. In particular, we establish a monotonicity condition that the accuracy-confidence function must satisfy for such improvement to occur. To demonstrate these theoretical properties, we conduct a rigorous simulation-based analysis using post-processing calibration techniques: Platt scaling and isotonic regression. As part of this framework, the predictor is trained using an outage loss function specifically designed for this system. Furthermore, this analysis is performed on Rayleigh fading channels with temporal correlation captured by Clarke's 2D model, which accounts for receiver mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17494v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rashika Raina, Nidhi Simmons, David E. Simmons, Michel Daoud Yacoub, Trung Q. Duong</dc:creator>
    </item>
    <item>
      <title>Bayesian Learning for Pilot Decontamination in Cell-Free Massive MIMO</title>
      <link>https://arxiv.org/abs/2508.11791</link>
      <description>arXiv:2508.11791v2 Announce Type: replace-cross 
Abstract: Pilot contamination (PC) arises when the pilot sequences assigned to user equipments (UEs) are not mutually orthogonal, eventually due to their reuse. In this work, we propose a novel expectation propagation (EP)-based joint channel estimation and data detection (JCD) algorithm specifically designed to mitigate the effects of PC in the uplink of cell-free massive multiple-input multiple-output (CF-MaMIMO) systems. This modified bilinear-EP algorithm is distributed, scalable, demonstrates strong robustness to PC, and outperforms state-of-the-art Bayesian learning algorithms. Through a comprehensive performance evaluation, we assess the performance of Bayesian learning algorithms for different pilot sequences and observe that the use of non-orthogonal pilots can lead to better performance compared to shared orthogonal sequences. Motivated by this analysis, we introduce a new metric to quantify PC at the UE level. We show that the performance of the considered algorithms degrades monotonically with respect to this metric, providing a valuable theoretical and practical tool for understanding and managing PC via iterative JCD algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.11791v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/WSA65299.2025.11202775</arxiv:DOI>
      <arxiv:journal_reference>2025 28th International Workshop on Smart Antennas (WSA)</arxiv:journal_reference>
      <dc:creator>Christian Forsch, Zilu Zhao, Dirk Slock, Laura Cottatellucci</dc:creator>
    </item>
    <item>
      <title>A digital SRAM-based compute-in-memory macro for weight-stationary dynamic matrix multiplication in Transformer attention score computation</title>
      <link>https://arxiv.org/abs/2511.12152</link>
      <description>arXiv:2511.12152v2 Announce Type: replace-cross 
Abstract: Compute-in-memory (CIM) techniques are widely employed in energy-efficient artificial intelligent (AI) processors. They alleviate power and latency bottlenecks caused by extensive data movements between compute and storage units. This work proposes a digital CIM macro to compute Transformer attention. To mitigate dynamic matrix multiplication that is unsuitable for the common weight-stationary CIM paradigm, we reformulate the attention score computation process based on a combined QK-weight matrix, so that inputs can be directly fed to CIM cells to obtain the score results. Moreover, the involved binomial matrix multiplication operation is decomposed into 4 groups of bit-serial shifting and additions, without costly physical multipliers in the CIM. We maximize the energy efficiency of the CIM circuit through zero-value bit-skipping, data-driven word line activation, read-write separate 6T cells and bit-alternating 14T/28T adders. The proposed CIM macro was implemented using a 65-nm process. It occupied only 0.35 mm2 area, and delivered a 42.27 GOPS peak performance with 1.24 mW power consumption at a 1.0 V power supply and a 100 MHz clock frequency, resulting in 34.1 TOPS/W energy efficiency and 120.77 GOPS/mm2 area efficiency. When compared to the CPU and GPU, our CIM macro is 25x and 13x more energy efficient on practical tasks, respectively. Compared with other Transformer-CIMs, our design exhibits at least 7x energy efficiency and at least 2x area efficiency improvements when scaled to the same technology node, showcasing its potential for edge-side intelligent applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12152v2</guid>
      <category>cs.AR</category>
      <category>eess.SP</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianyi Yu, Tengxiao Wang, Yuxuan Wang, Xiang Fu, Ying Wang, Fei Qiao, Liyuan Liu, Cong Shi</dc:creator>
    </item>
  </channel>
</rss>
