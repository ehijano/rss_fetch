<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 02:53:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>EF2X Exists For Four Agents</title>
      <link>https://arxiv.org/abs/2412.00254</link>
      <description>arXiv:2412.00254v1 Announce Type: new 
Abstract: We study the fair allocation of indivisible goods among a group of agents, aiming to limit the envy between any two agents. The central open problem in this literature, which has proven to be extremely challenging, is regarding the existence of an EFX allocation, i.e., an allocation such that any envy from some agent i toward another agent j would vanish if we were to remove any single good from the bundle allocated to j. When the agents' valuations are additive, which has been the main focus of prior works, Chaudhury et al. [2024] showed that an EFX allocation is guaranteed to exist for all instances involving up to three agents. Subsequently, Berger et al. [2022] extended this guarantee to nice-cancelable valuations and Akrami et al. [2023] to MMS-feasible valuations. However, the existence of EFX allocations for instances involving four agents remains open, even for additive valuations. We contribute to this literature by focusing on EF2X, a relaxation of EFX which requires that any envy toward some agent vanishes if any two of the goods allocated to that agent were to be removed. Our main result shows that EF2X allocations are guaranteed to exist for any instance with four agents, even for the class of cancelable valuations, which is more general than additive. Our proof is constructive, proposing an algorithm that computes such an allocation in pseudopolynomial time. Furthermore, for instances involving three agents we provide an algorithm that computes an EF2X allocation in polynomial time, in contrast to EFX, for which the fastest known algorithm for three agents is only pseudopolynomial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00254v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Ashuri, Vasilis Gkatzelis, Alkmini Sgouritsa</dc:creator>
    </item>
    <item>
      <title>Mechanism design with multi-armed bandit</title>
      <link>https://arxiv.org/abs/2412.00345</link>
      <description>arXiv:2412.00345v1 Announce Type: new 
Abstract: A popular approach of automated mechanism design is to formulate a linear program (LP) whose solution gives a mechanism with desired properties. We analytically derive a class of optimal solutions for such an LP that gives mechanisms achieving standard properties of efficiency, incentive compatibility, strong budget balance (SBB), and individual rationality (IR), where SBB and IR are satisfied in expectation. Notably, our solutions are represented by an exponentially smaller number of essential variables than the original variables of LP. Our solutions, however, involve a term whose exact evaluation requires solving a certain optimization problem exponentially many times as the number of players, $N$, grows. We thus evaluate this term by modeling it as the problem of estimating the mean reward of the best arm in multi-armed bandit (MAB), propose a Probably and Approximately Correct estimator, and prove its asymptotic optimality by establishing a lower bound on its sample complexity. This MAB approach reduces the number of times the optimization problem is solved from exponential to $O(N\,\log N)$. Numerical experiments show that the proposed approach finds mechanisms that are guaranteed to achieve desired properties with high probability for environments with up to 128 players, which substantially improves upon the prior work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00345v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takayuki Osogami, Hirota Kinoshita, Segev Wasserkrug</dc:creator>
    </item>
    <item>
      <title>Simultaneously Satisfying MXS and EFL</title>
      <link>https://arxiv.org/abs/2412.00358</link>
      <description>arXiv:2412.00358v1 Announce Type: new 
Abstract: The two standard fairness notions in the resource allocation literature are proportionality and envy-freeness. If there are n agents competing for the available resources, then proportionality requires that each agent receives at least a 1/n fraction of their total value for the set of resources. On the other hand, envy-freeness requires that each agent weakly prefers the resources allocated to them over those allocated to any other agent. Each of these notions has its own benefits, but it is well known that neither one of the two is always achievable when the resources being allocated are indivisible. As a result, a lot of work has focused on satisfying fairness notions that relax either proportionality or envy-freeness. In this paper, we focus on MXS (a relaxation of proportionality) and EFL (a relaxation of envy-freeness). Each of these notions was previously shown to be achievable on its own [Barman et al.,2018, Caragiannis et al., 2023], and our main result is an algorithm that computes allocations that simultaneously satisfy both, combining the benefits of approximate proportionality and approximate envy-freeness. In fact, we prove this for any instance involving agents with valuation functions that are restricted MMS-feasible, which are more general than additive valuations. Also, since every EFL allocation directly satisfies other well-studied fairness notions like EF1, 1/2-EFX, 1/2-GMMS, and 2/3-PMMS, and every MXS allocation satisfies 4/7-MMS, the allocations returned by our algorithm simultaneously satisfy a wide variety of fairness notions and are, therefore, universally fair [Amanatidis et al., 2020].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00358v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arash Ashuri, Vasilis Gkatzelis</dc:creator>
    </item>
    <item>
      <title>Incentive-Driven Task Offloading and Collaborative Computing in Device-Assisted MEC Networks</title>
      <link>https://arxiv.org/abs/2412.00370</link>
      <description>arXiv:2412.00370v1 Announce Type: new 
Abstract: Edge computing (EC), positioned near end devices, holds significant potential for delivering low-latency, energy-efficient, and secure services. This makes it a crucial component of the Internet of Things (IoT). However, the increasing number of IoT devices and emerging services place tremendous pressure on edge servers (ESs). To better handle dynamically arriving heterogeneous tasks, ESs and IoT devices with idle resources can collaborate in processing tasks. Considering the selfishness and heterogeneity of IoT devices and ESs, we propose an incentive-driven multi-level task allocation framework. Specifically, we categorize IoT devices into task IoT devices (TDs), which generate tasks, and auxiliary IoT devices (ADs), which have idle resources. We use a bargaining game to determine the initial offloading decision and the payment fee for each TD, as well as a double auction to incentivize ADs to participate in task processing. Additionally, we develop a priority-based inter-cell task scheduling algorithm to address the uneven distribution of user tasks across different cells. Finally, we theoretically analyze the performance of the proposed framework. Simulation results demonstrate that our proposed framework outperforms benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00370v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Li, Xing Zhang, Bo Lei, Qianying Zhao, Min Wei, Zheyan Qu, Wenbo Wang</dc:creator>
    </item>
    <item>
      <title>FairSort: Learning to Fair Rank for Personalized Recommendations in Two-Sided Platforms</title>
      <link>https://arxiv.org/abs/2412.00424</link>
      <description>arXiv:2412.00424v1 Announce Type: new 
Abstract: Traditional recommendation systems focus on maximizing user satisfaction by suggesting their favorite items. This user-centric approach may lead to unfair exposure distribution among the providers. On the contrary, a provider-centric design might become unfair to the users. Therefore, this paper proposes a re-ranking model FairSort\footnote{\textbf{Reproducibility:}The code and datasets are available at \url{https://github.com/13543024276/FairSort}} to find a trade-off solution among user-side fairness, provider-side fairness, and personalized recommendations utility. Previous works habitually treat this issue as a knapsack problem, incorporating both-side fairness as constraints.
  In this paper, we adopt a novel perspective, treating each recommendation list as a runway rather than a knapsack. In this perspective, each item on the runway gains a velocity and runs within a specific time, achieving re-ranking for both-side fairness. Meanwhile, we ensure the Minimum Utility Guarantee for personalized recommendations by designing a Binary Search approach. This can provide more reliable recommendations compared to the conventional greedy strategy based on the knapsack problem. We further broaden the applicability of FairSort, designing two versions for online and offline recommendation scenarios. Theoretical analysis and extensive experiments on real-world datasets indicate that FairSort can ensure more reliable personalized recommendations while considering fairness for both the provider and user.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00424v1</guid>
      <category>cs.GT</category>
      <category>cs.IR</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guoli Wu, Zhiyong Feng, Shizhan Chen, Hongyue Wu, Xiao Xue, Jianmao Xiao, Guodong Fan, Hongqi Chen, Jingyu Li</dc:creator>
    </item>
    <item>
      <title>Rethinking Strategic Mechanism Design In The Age Of Large Language Models: New Directions For Communication Systems</title>
      <link>https://arxiv.org/abs/2412.00495</link>
      <description>arXiv:2412.00495v1 Announce Type: new 
Abstract: This paper explores the application of large language models (LLMs) in designing strategic mechanisms -- including auctions, contracts, and games -- for specific purposes in communication networks. Traditionally, strategic mechanism design in telecommunications has relied on human expertise to craft solutions based on game theory, auction theory, and contract theory. However, the evolving landscape of telecom networks, characterized by increasing abstraction, emerging use cases, and novel value creation opportunities, calls for more adaptive and efficient approaches. We propose leveraging LLMs to automate or semi-automate the process of strategic mechanism design, from intent specification to final formulation. This paradigm shift introduces both semi-automated and fully-automated design pipelines, raising crucial questions about faithfulness to intents, incentive compatibility, algorithmic stability, and the balance between human oversight and artificial intelligence (AI) autonomy. The paper discusses potential frameworks, such as retrieval-augmented generation (RAG)-based systems, to implement LLM-driven mechanism design in communication networks contexts. We examine key challenges, including LLM limitations in capturing domain-specific constraints, ensuring strategy proofness, and integrating with evolving telecom standards. By providing an in-depth analysis of the synergies and tensions between LLMs and strategic mechanism design within the IoT ecosystem, this work aims to stimulate discussion on the future of AI-driven information economic mechanisms in telecommunications and their potential to address complex, dynamic network management scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00495v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ismail Lotfi, Nouf Alabbasi, Omar Alhussein</dc:creator>
    </item>
    <item>
      <title>Designing Optimal Mechanisms to Locate Facilities with Insufficient Capacity for Bayesian Agents</title>
      <link>https://arxiv.org/abs/2412.00563</link>
      <description>arXiv:2412.00563v1 Announce Type: new 
Abstract: In this paper, we study the Facility Location Problem with Scarce Resources (FLPSR) under the assumption that agents' type follow a probability distribution. In the FLPSR, the objective is to identify the optimal locations for one or more capacitated facilities to maximize Social Welfare (SW), defined as the sum of the utilities of all agents. The total capacity of the facilities, however, is not enough to accommodate all the agents, who thus compete in a First-Come-First-Served game to determine whether they get accommodated and what their utility is. The main contribution of this paper ties Optimal Transport theory to the problem of determining the best truthful mechanism for the FLPSR tailored to the agents' type distributions. Owing to this connection, we identify the mechanism that maximizes the expected SW as the number of agents goes to infinity. For the case of a single facility, we show that an optimal mechanism always exists. We examine three classes of probability distributions and characterize the optimal mechanism either analytically represent the optimal mechanism or provide a routine to numerically compute it. We then extend our results to the case in which we have two capacitated facilities to place. While we initially assume that agents are independent and identically distributed, we show that our techniques are applicable to scenarios where agents are not identically distributed. Finally, we validate our findings through several numerical experiments, including: (i) deriving optimal mechanisms for the class of beta distributions, (ii) assessing the Bayesian approximation ratio of these mechanisms for small numbers of agents, and (iii) assessing how quickly the expected SW attained by the mechanism converges to its limit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00563v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gennaro Auricchio, Jie Zhang</dc:creator>
    </item>
    <item>
      <title>Quantifying Core Stability Relaxations in Hedonic Games</title>
      <link>https://arxiv.org/abs/2412.01666</link>
      <description>arXiv:2412.01666v1 Announce Type: new 
Abstract: We study relationships between different relaxed notions of core stability in hedonic games, which are a class of coalition formation games. Our unified approach applies to a newly introduced family of hedonic games, called $\alpha$-hedonic games, which contains previously studied variants such as fractional and additively separable hedonic games. In particular, we derive an upper bound on the maximum factor with which a blocking coalition of a certain size can improve upon an outcome in which no deviating coalition of size at most $q$ exists. Counterintuitively, we show that larger blocking coalitions might sometimes have lower improvement factors. We discuss the tightness conditions of our bound, as well as its implications on the price of anarchy of core relaxations. Our general result has direct implications for several well-studied classes of hedonic games, allowing us to prove two open conjectures by Fanelli et al. (2021) for fractional hedonic games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01666v1</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tom Demeulemeester, Jannik Peters</dc:creator>
    </item>
    <item>
      <title>Condorcet-Consistent Choice Among Three Candidates</title>
      <link>https://arxiv.org/abs/2411.19857</link>
      <description>arXiv:2411.19857v1 Announce Type: cross 
Abstract: A voting rule is a Condorcet extension if it returns a candidate that beats every other candidate in pairwise majority comparisons whenever one exists. Condorcet extensions have faced criticism due to their susceptibility to variable-electorate paradoxes, especially the reinforcement paradox (Young and Levenglick, 1978) and the no-show paradox (Moulin, 1988). In this paper, we investigate the susceptibility of Condorcet extensions to these paradoxes for the case of exactly three candidates. For the reinforcement paradox, we establish that it must occur for every Condorcet extension when there are at least eight voters and demonstrate that certain refinements of maximin, a voting rule originally proposed by Condorcet (1785), are immune to this paradox when there are at most seven voters. For the no-show paradox, we prove that the only homogeneous Condorcet extensions immune to it are refinements of maximin. We also provide axiomatic characterizations of maximin and two of its refinements, Nanson's rule and leximin, highlighting their suitability for three-candidate elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19857v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Brandt, Chris Dong, Dominik Peters</dc:creator>
    </item>
    <item>
      <title>Bandit Learning in Matching Markets: Utilitarian and Rawlsian Perspectives</title>
      <link>https://arxiv.org/abs/2412.00301</link>
      <description>arXiv:2412.00301v1 Announce Type: cross 
Abstract: Two-sided matching markets have demonstrated significant impact in many real-world applications, including school choice, medical residency placement, electric vehicle charging, ride sharing, and recommender systems. However, traditional models often assume that preferences are known, which is not always the case in modern markets, where preferences are unknown and must be learned. For example, a company may not know its preference over all job applicants a priori in online markets. Recent research has modeled matching markets as multi-armed bandit (MAB) problem and primarily focused on optimizing matching for one side of the market, while often resulting in a pessimal solution for the other side. In this paper, we adopt a welfarist approach for both sides of the market, focusing on two metrics: (1) Utilitarian welfare and (2) Rawlsian welfare, while maintaining market stability. For these metrics, we propose algorithms based on epoch Explore-Then-Commit (ETC) and analyze their regret bounds. Finally, we conduct simulated experiments to evaluate both welfare and market stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00301v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Duohan Zhang</dc:creator>
    </item>
    <item>
      <title>Extreme Points in Multi-Dimensional Screening</title>
      <link>https://arxiv.org/abs/2412.00649</link>
      <description>arXiv:2412.00649v1 Announce Type: cross 
Abstract: This paper characterizes extreme points of the set of incentive-compatible mechanisms for screening problems with linear utility. Extreme points are exhaustive mechanisms, meaning their menus cannot be scaled and translated to make additional feasibility constraints binding. In problems with one-dimensional types, extreme points admit a tractable description with a tight upper bound on their menu size. In problems with multi-dimensional types, every exhaustive mechanism can be transformed into an extreme point by applying an arbitrarily small perturbation. For mechanisms with a finite menu, this perturbation displaces the menu items into general position. Generic exhaustive mechanisms are extreme points with an uncountable menu. Similar results hold in applications to delegation, veto bargaining, and monopoly problems, where we consider mechanisms that are unique maximizers for specific classes of objective functionals. The proofs involve a novel connection between menus of extreme points and indecomposable convex bodies, first studied by Gale (1954).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00649v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Patrick Lahr, Axel Niemeyer</dc:creator>
    </item>
    <item>
      <title>Remote Estimation Games with Random Walk Processes: Stackelberg Equilibrium</title>
      <link>https://arxiv.org/abs/2412.00679</link>
      <description>arXiv:2412.00679v1 Announce Type: cross 
Abstract: Remote estimation is a crucial element of real time monitoring of a stochastic process. While most of the existing works have concentrated on obtaining optimal sampling strategies, motivated by malicious attacks on cyber-physical systems, we model sensing under surveillance as a game between an attacker and a defender. This introduces strategic elements to conventional remote estimation problems. Additionally, inspired by increasing detection capabilities, we model an element of information leakage for each player. Parameterizing the game in terms of uncertainty on each side, information leakage, and cost of sampling, we consider the Stackelberg Equilibrium (SE) concept where one of the players acts as the leader and the other one as the follower. By focusing our attention on stationary probabilistic sampling policies, we characterize the SE of this game and provide simulations to show the efficacy of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00679v1</guid>
      <category>cs.IT</category>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atahan Dokme, Raj Kiriti Velicheti, Melih Bastopcu, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Incentivizing Truthful Collaboration in Heterogeneous Federated Learning</title>
      <link>https://arxiv.org/abs/2412.00980</link>
      <description>arXiv:2412.00980v1 Announce Type: cross 
Abstract: It is well-known that Federated Learning (FL) is vulnerable to manipulated updates from clients. In this work we study the impact of data heterogeneity on clients' incentives to manipulate their updates. We formulate a game in which clients may upscale their gradient updates in order to ``steer'' the server model to their advantage. We develop a payment rule that disincentivizes sending large gradient updates, and steers the clients towards truthfully reporting their gradients. We also derive explicit bounds on the clients' payments and the convergence rate of the global model, which allows us to study the trade-off between heterogeneity, payments and convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00980v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitar Chakarov, Nikita Tsoy, Kristian Minchev, Nikola Konstantinov</dc:creator>
    </item>
    <item>
      <title>Inferring Short-Sightedness in Dynamic Noncooperative Games</title>
      <link>https://arxiv.org/abs/2412.01017</link>
      <description>arXiv:2412.01017v1 Announce Type: cross 
Abstract: Dynamic game theory is an increasingly popular tool for modeling multi-agent, e.g. human-robot, interactions. Game-theoretic models presume that each agent wishes to minimize a private cost function that depends on others' actions. These games typically evolve over a fixed time horizon, which specifies the degree to which all agents care about the distant future. In practical settings, however, decision-makers may vary in their degree of short-sightedness. We conjecture that quantifying and estimating each agent's short-sightedness from online data will enable safer and more efficient interactions with other agents. To this end, we frame this inference problem as an inverse dynamic game. We consider a specific parametrization of each agent's objective function that smoothly interpolates myopic and farsighted planning. Games of this form are readily transformed into parametric mixed complementarity problems; we exploit the directional differentiability of solutions to these problems with respect to their hidden parameters in order to solve for agents' short-sightedness. We conduct several experiments simulating human behavior at a real-world crosswalk. The results of these experiments clearly demonstrate that by explicitly inferring agents' short-sightedness, we can recover more accurate game-theoretic models, which ultimately allow us to make better predictions of agents' behavior. Specifically, our results show up to a 30% more accurate prediction of myopic behavior compared to the baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01017v1</guid>
      <category>cs.RO</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cade Armstrong, Ryan Park, Xinjie Liu, Kushagra Gupta, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Practical Performative Policy Learning with Strategic Agents</title>
      <link>https://arxiv.org/abs/2412.01344</link>
      <description>arXiv:2412.01344v1 Announce Type: cross 
Abstract: This paper studies the performative policy learning problem, where agents adjust their features in response to a released policy to improve their potential outcomes, inducing an endogenous distribution shift. There has been growing interest in training machine learning models in strategic environments, including strategic classification and performative prediction. However, existing approaches often rely on restrictive parametric assumptions: micro-level utility models in strategic classification and macro-level data distribution maps in performative prediction, severely limiting scalability and generalizability. We approach this problem as a complex causal inference task, relaxing parametric assumptions on both micro-level agent behavior and macro-level data distribution. Leveraging bounded rationality, we uncover a practical low-dimensional structure in distribution shifts and construct an effective mediator in the causal path from the deployed model to the shifted data. We then propose a gradient-based policy optimization algorithm with a differentiable classifier as a substitute for the high-dimensional distribution map. Our algorithm efficiently utilizes batch feedback and limited manipulation patterns. Our approach achieves high sample efficiency compared to methods reliant on bandit feedback or zero-order optimization. We also provide theoretical guarantees for algorithmic convergence. Extensive and challenging experiments on high-dimensional settings demonstrate our method's practical efficacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01344v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianyi Chen, Ying Chen, Bo Li</dc:creator>
    </item>
    <item>
      <title>Towards Type Agnostic Cyber Defense Agents</title>
      <link>https://arxiv.org/abs/2412.01542</link>
      <description>arXiv:2412.01542v1 Announce Type: cross 
Abstract: With computing now ubiquitous across government, industry, and education, cybersecurity has become a critical component for every organization on the planet. Due to this ubiquity of computing, cyber threats have continued to grow year over year, leading to labor shortages and a skills gap in cybersecurity. As a result, many cybersecurity product vendors and security organizations have looked to artificial intelligence to shore up their defenses. This work considers how to characterize attackers and defenders in one approach to the automation of cyber defense -- the application of reinforcement learning. Specifically, we characterize the types of attackers and defenders in the sense of Bayesian games and, using reinforcement learning, derive empirical findings about how to best train agents that defend against multiple types of attackers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01542v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Erick Galinkin, Emmanouil Pountrourakis, Spiros Mancoridis</dc:creator>
    </item>
    <item>
      <title>Proportional Participatory Budgeting with Projects Interaction</title>
      <link>https://arxiv.org/abs/2106.05360</link>
      <description>arXiv:2106.05360v2 Announce Type: replace 
Abstract: Participatory budgeting (PB) is a democratic process for allocating funds to projects based on the votes of community members. PB outcomes are commonly evaluated for how they reflect voters preferences (e.g., social welfare) and the extent to which they are fair (e.g., proportionality). Due to practical and computational reasons, voters are usually asked to report their preferences over projects separately, possibly neglecting important dependencies among projects, which causes the outcome to no longer be proportional and achieve lower satisfaction. This work is the first to suggest a polynomial-time aggregation method capable of guaranteeing proportional outcomes under substitution dependencies. The method is a variant of the Method of Equal Shares, and we further provide another variation that can guarantee a more relaxed notion of proportionality for any type of dependency, and is FPT rather than polynomial. Through simulations, we demonstrate that these aggregation methods achieve, on average, higher social welfare than their counterparts that ignore the dependencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2106.05360v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roy Fairstein, Reshef Meir, Kobi Gal</dc:creator>
    </item>
    <item>
      <title>On the stability of the logit dynamics in population games</title>
      <link>https://arxiv.org/abs/2307.03507</link>
      <description>arXiv:2307.03507v2 Announce Type: replace 
Abstract: We study the asymptotic stability of the logit evolutionary dynamics in population games, possibly with multiple heterogenous populations. For general population games, we prove that, on the one hand, strict Nash equilibria are asymptotically stable under the logit dynamics for low enough noise levels, on the other hand, a globally exponentially stable logit equilibrium exists for sufficiently large noise levels. This suggests the emergence of bifurcations in population games admitting multiple strict Nash equilibria, as observed in numerous examples. We then provide sufficient conditions on the population game structure for the existence of globally asymptotically stable logit equilibria for every noise level. The considered class of monotone separable games finds applications, e.g., in routing games on series compositions of networks with parallel routes when there are multiple populations of users that differ in the reward functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03507v2</guid>
      <category>cs.GT</category>
      <category>math.DS</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonardo Cianfanelli, Giacomo Como</dc:creator>
    </item>
    <item>
      <title>No-Regret Learning and Equilibrium Computation in Quantum Games</title>
      <link>https://arxiv.org/abs/2310.08473</link>
      <description>arXiv:2310.08473v3 Announce Type: replace 
Abstract: As quantum processors advance, the emergence of large-scale decentralized systems involving interacting quantum-enabled agents is on the horizon. Recent research efforts have explored quantum versions of Nash and correlated equilibria as solution concepts of strategic quantum interactions, but these approaches did not directly connect to decentralized adaptive setups where agents possess limited information. This paper delves into the dynamics of quantum-enabled agents within decentralized systems that employ no-regret algorithms to update their behaviors over time. Specifically, we investigate two-player quantum zero-sum games and polymatrix quantum zero-sum games, showing that no-regret algorithms converge to separable quantum Nash equilibria in time-average. In the case of general multi-player quantum games, our work leads to a novel solution concept, that of the {separable} quantum coarse correlated equilibria (QCCE), as the convergent outcome of the time-averaged behavior no-regret algorithms, offering a natural solution concept for decentralized quantum systems. Finally, we show that computing QCCEs can be formulated as a semidefinite program and establish the existence of entangled (i.e., non-separable) QCCEs, which are unlearnable via the current paradigm of no-regret learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.08473v3</guid>
      <category>cs.GT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wayne Lin, Georgios Piliouras, Ryann Sim, Antonios Varvitsiotis</dc:creator>
    </item>
    <item>
      <title>Equitable Core Imputations via a New Adaptation of The Primal-Dual Framework</title>
      <link>https://arxiv.org/abs/2402.11437</link>
      <description>arXiv:2402.11437v4 Announce Type: replace 
Abstract: The classic paper of Shapley and Shubik \cite{Shapley1971assignment} characterized the core of the assignment game. We observe that a sub-coalition consisting of one player (or a set of players from the same side of the bipartition) can make zero profit, and therefore its profit under a core imputation can be an arbitrary amount. Hence an arbitrary core imputation makes {\em no fairness guarantee at the level of individual agents}. Can this deficiency be addressed by picking a ``good'' core imputation?
  To arrive at an appropriate solution concept, we give specific criteria for picking a special core imputation, and we undertake a detailed comparison of four solution concepts. Leximin and leximax core imputations come out as clear winners; we define these to be {\em equitable core imputations}. These imputations achieve ``fairness'' in different ways: whereas leximin tries to make poor agents more rich, leximax tries to make rich agents less rich.
  We give combinatorial strongly polynomial algorithms for computing these imputations via a novel adaptation of the classical primal-dual paradigm. The ``engine'' driving them involves insights into core imputations obtained via complementarity. It will not be surprising if our work leads to new uses of this powerful technique. Furthermore, we expect more work on computing the leximin and leximax core imputations of other natural games, in addition to the recent follow-up work \cite{Leximin-max}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11437v4</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay V. Vazirani</dc:creator>
    </item>
    <item>
      <title>GPU-Accelerated Counterfactual Regret Minimization</title>
      <link>https://arxiv.org/abs/2408.14778</link>
      <description>arXiv:2408.14778v5 Announce Type: replace 
Abstract: Counterfactual regret minimization is a family of algorithms of no-regret learning dynamics capable of solving large-scale imperfect information games. We propose implementing this algorithm as a series of dense and sparse matrix and vector operations, thereby making it highly parallelizable for a graphical processing unit, at a cost of higher memory usage. Our experiments show that our implementation performs up to about 401.2 times faster than OpenSpiel's Python implementation and, on an expanded set of games, up to about 203.6 times faster than OpenSpiel's C++ implementation and the speedup becomes more pronounced as the size of the game being solved grows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14778v5</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juho Kim</dc:creator>
    </item>
    <item>
      <title>Computational Complexity of Envy-free and Exchange-stable Seat Arrangement Problems on Grid Graphs</title>
      <link>https://arxiv.org/abs/2411.10719</link>
      <description>arXiv:2411.10719v2 Announce Type: replace 
Abstract: The Seat Arrangement Problem is a problem of finding a desirable seat arrangement for given preferences of agents and a seat graph that represents a configuration of seats. In this paper, we consider decision problems of determining if an envy-free arrangement exists and an exchange-stable arrangement exists, when a seat graph is an $\ell \times m$ grid graph. When $\ell=1$, the seat graph is a path of length $m$ and both problems have been known to be NP-complete. In this paper, we extend it and show that both problems are NP-complete for any integer $\ell \geq 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10719v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sota Kawase, Shuichi Miyazaki</dc:creator>
    </item>
    <item>
      <title>Fair Combinatorial Auction for Blockchain Trade Intents: Being Fair without Knowing What is Fair</title>
      <link>https://arxiv.org/abs/2408.12225</link>
      <description>arXiv:2408.12225v2 Announce Type: replace-cross 
Abstract: Blockchain trade intent auctions currently intermediate approximately USD 5 billion monthly. Due to production complementarities, the auction is combinatorial: when multiple trade intents from different traders are auctioned off simultaneously, a bidder (here called solver) can generate additional efficiencies by winning a batch of multiple trade intents. However, sharing these additional efficiencies between traders is problematic: because of market frictions and fees (solvers' private information), the auctioneer does not know how much each trader would have received had its trade been auctioned off individually. We formalize this problem and study the most commonly used auction formats: batch auctions and multiple simultaneous auctions. We also propose a novel fair combinatorial auction that combines batch auction and multiple simultaneous auctions: solvers submit individual-trade bids and batched bids, but batched bids are considered only if they are better for all traders relative to the outcome of the simultaneous auctions constructed using the individual-trade bids. We find a trade-off between the fairness guarantees provided in equilibrium by the auction (i.e., the minimum each trader can expect to receive) and the expected value of the assets returned to the traders. Also, the amount that each trader receives in the equilibrium of the fair combinatorial auction may be higher or lower than what they receive in the equilibrium of the simultaneous auctions used as a benchmark for fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.12225v2</guid>
      <category>econ.TH</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Canidio, Felix Henneke</dc:creator>
    </item>
  </channel>
</rss>
