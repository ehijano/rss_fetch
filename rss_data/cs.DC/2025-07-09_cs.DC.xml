<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 10 Jul 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Designing Parallel Algorithms for Community Detection using Arachne</title>
      <link>https://arxiv.org/abs/2507.06471</link>
      <description>arXiv:2507.06471v1 Announce Type: new 
Abstract: The rise of graph data in various fields calls for efficient and scalable community detection algorithms. In this paper, we present parallel implementations of two widely used algorithms: Label Propagation and Louvain, specifically designed to leverage the capabilities of Arachne which is a Python-accessible, open-source framework for large-scale graph analysis. Our implementations achieve substantial speedups over existing Python-based tools like NetworkX and igraph, which lack efficient parallelization, and are competitive with parallel frameworks such as NetworKit. Experimental results show that Arachne-based methods outperform these baselines, achieving speedups of up to 710x over NetworkX, 75x over igraph, and 12x over NetworKit. Additionally, we analyze the scalability of our implementation under varying thread counts, demonstrating how different phases contribute to overall performance gains of the parallel Louvain algorithm. Arachne, including our community detection implementation, is open-source and available at https://github.com/Bears-R-Us/arkouda-njit .</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06471v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fuhuan Li, Zhihui Du, David A. Bader</dc:creator>
    </item>
    <item>
      <title>Nexus: Taming Throughput-Latency Tradeoff in LLM Serving via Efficient GPU Sharing</title>
      <link>https://arxiv.org/abs/2507.06608</link>
      <description>arXiv:2507.06608v1 Announce Type: new 
Abstract: Current prefill-decode (PD) disaggregation is typically deployed at the level of entire serving engines, assigning separate GPUs to handle prefill and decode phases. While effective at reducing latency, this approach demands more hardware. To improve GPU utilization, Chunked Prefill mixes prefill and decode requests within the same batch, but introduces phase interference between prefill and decode.
  While existing PD disaggregation solutions separate the phases across GPUs, we ask: can the same decoupling be achieved within a single serving engine? The key challenge lies in managing the conflicting resource requirements of prefill and decode when they share the same hardware. In this paper, we first show that chunked prefill requests cause interference with decode requests due to their distinct requirements for GPU resources. Second, we find that GPU resources exhibit diminishing returns. Beyond a saturation point, increasing GPU allocation yields negligible latency improvements. This insight enables us to split a single GPU's resources and dynamically allocate them to prefill and decode on the fly, effectively disaggregating the two phases within the same GPU.
  Across a range of models and workloads, our system Nexus achieves up to 2.2x higher throughput, 20x lower TTFT, and 2.5x lower TBT than vLLM. It also outperforms SGLang with up to 2x higher throughput, 2x lower TTFT, and 1.7x lower TBT, and achieves 1.4x higher throughput than vLLM-disaggregation using only half the number of GPUs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06608v1</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxiang Shi, Colin Cai, Junjia Du, Zhanda Zhu, Xingda Wei, Zhihao Jia</dc:creator>
    </item>
    <item>
      <title>Towards Efficient and Scalable Distributed Vector Search with RDMA</title>
      <link>https://arxiv.org/abs/2507.06653</link>
      <description>arXiv:2507.06653v1 Announce Type: new 
Abstract: Similarity-based vector search facilitates many important applications such as search and recommendation but is limited by the memory capacity and bandwidth of a single machine due to large datasets and intensive data read. In this paper, we present CoTra, a system that scales up vector search for distributed execution. We observe a tension between computation and communication efficiency, which is the main challenge for good scalability, i.e., handling the local vectors on each machine independently blows up computation as the pruning power of vector index is not fully utilized, while running a global index over all machines introduces rich data dependencies and thus extensive communication. To resolve such tension, we leverage the fact that vector search is approximate in nature and robust to asynchronous execution. In particular, we run collaborative vector search over the machines with algorithm-system co-designs including clustering-based data partitioning to reduce communication, asynchronous execution to avoid communication stall, and task push to reduce network traffic. To make collaborative search efficient, we introduce a suite of system optimizations including task scheduling, communication batching, and storage format. We evaluate CoTra on real datasets and compare with four baselines. The results show that when using 16 machines, the query throughput of CoTra scales to 9.8-13.4x over a single machine and is 2.12-3.58x of the best-performing baseline at 0.95 recall@10.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06653v1</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangyu Zhi, Meng Chen, Xiao Yan, Baotong Lu, Hui Li, Qianxi Zhang, Qi Chen, James Cheng</dc:creator>
    </item>
    <item>
      <title>Phantom Subgroup Poisoning: Stealth Attacks on Federated Recommender Systems</title>
      <link>https://arxiv.org/abs/2507.06258</link>
      <description>arXiv:2507.06258v1 Announce Type: cross 
Abstract: Federated recommender systems (FedRec) have emerged as a promising solution for delivering personalized recommendations while safeguarding user privacy. However, recent studies have demonstrated their vulnerability to poisoning attacks. Existing attacks typically target the entire user group, which compromises stealth and increases the risk of detection. In contrast, real-world adversaries may prefer to prompt target items to specific user subgroups, such as recommending health supplements to elderly users. Motivated by this gap, we introduce Spattack, the first targeted poisoning attack designed to manipulate recommendations for specific user subgroups in the federated setting. Specifically, Spattack adopts a two-stage approximation-and-promotion strategy, which first simulates user embeddings of target/non-target subgroups and then prompts target items to the target subgroups. To enhance the approximation stage, we push the inter-group embeddings away based on contrastive learning and augment the target group's relevant item set based on clustering. To enhance the promotion stage, we further propose to adaptively tune the optimization weights between target and non-target subgroups. Besides, an embedding alignment strategy is proposed to align the embeddings between the target items and the relevant items. We conduct comprehensive experiments on three real-world datasets, comparing Spattack against seven state-of-the-art poisoning attacks and seven representative defense mechanisms. Experimental results demonstrate that Spattack consistently achieves strong manipulation performance on the specific user subgroup, while incurring minimal impact on non-target users, even when only 0.1\% of users are malicious. Moreover, Spattack maintains competitive overall recommendation performance and exhibits strong resilience against existing mainstream defenses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06258v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.IR</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bo Yan, Yurong Hao, Dingqi Liu, Huabin Sun, Pengpeng Qiao, Wei Yang Bryan Lim, Yang Cao, Chuan Shi</dc:creator>
    </item>
    <item>
      <title>FedPhD: Federated Pruning with Hierarchical Learning of Diffusion Models</title>
      <link>https://arxiv.org/abs/2507.06449</link>
      <description>arXiv:2507.06449v1 Announce Type: cross 
Abstract: Federated Learning (FL), as a distributed learning paradigm, trains models over distributed clients' data. FL is particularly beneficial for distributed training of Diffusion Models (DMs), which are high-quality image generators that require diverse data. However, challenges such as high communication costs and data heterogeneity persist in training DMs similar to training Transformers and Convolutional Neural Networks. Limited research has addressed these issues in FL environments. To address this gap and challenges, we introduce a novel approach, FedPhD, designed to efficiently train DMs in FL environments. FedPhD leverages Hierarchical FL with homogeneity-aware model aggregation and selection policy to tackle data heterogeneity while reducing communication costs. The distributed structured pruning of FedPhD enhances computational efficiency and reduces model storage requirements in clients. Our experiments across multiple datasets demonstrate that FedPhD achieves high model performance regarding Fr\'echet Inception Distance (FID) scores while reducing communication costs by up to $88\%$. FedPhD outperforms baseline methods achieving at least a $34\%$ improvement in FID, while utilizing only $56\%$ of the total computation and communication resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06449v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianyu Long, Qiyuan Wang, Christos Anagnostopoulos, Daning Bi</dc:creator>
    </item>
    <item>
      <title>A Single Merging Suffices: Recovering Server-based Learning Performance in Decentralized Learning</title>
      <link>https://arxiv.org/abs/2507.06542</link>
      <description>arXiv:2507.06542v1 Announce Type: cross 
Abstract: Decentralized learning provides a scalable alternative to traditional parameter-server-based training, yet its performance is often hindered by limited peer-to-peer communication. In this paper, we study how communication should be scheduled over time, including determining when and how frequently devices synchronize. Our empirical results show that concentrating communication budgets in the later stages of decentralized training markedly improves global generalization. Surprisingly, we uncover that fully connected communication at the final step, implemented by a single global merging, is sufficient to match the performance of server-based training. We further show that low communication in decentralized learning preserves the \textit{mergeability} of local models throughout training. Our theoretical contributions, which explains these phenomena, are first to establish that the globally merged model of decentralized SGD can converge faster than centralized mini-batch SGD. Technically, we novelly reinterpret part of the discrepancy among local models, which were previously considered as detrimental noise, as constructive components that accelerate convergence. This work challenges the common belief that decentralized learning generalizes poorly under data heterogeneity and limited communication, while offering new insights into model merging and neural network loss landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06542v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tongtian Zhu, Tianyu Zhang, Mingze Wang, Zhanpeng Zhou, Can Wang</dc:creator>
    </item>
    <item>
      <title>SlimCaching: Edge Caching of Mixture-of-Experts for Distributed Inference</title>
      <link>https://arxiv.org/abs/2507.06567</link>
      <description>arXiv:2507.06567v1 Announce Type: cross 
Abstract: Mixture-of-Experts (MoE) models improve the scalability of large language models (LLMs) by activating only a small subset of relevant experts per input. However, the sheer number of expert networks in an MoE model introduces a significant storage burden for an edge device. To address this challenge, we consider a scenario where experts are dispersed within an edge network for distributed inference. Based on the popular Top-$K$ expert selection strategy, we formulate a latency minimization problem by optimizing expert caching on edge servers under storage constraints. When $K=1$, the problem reduces to a monotone submodular maximization problem with knapsack constraints, for which we design a greedy-based algorithm with a $(1 - 1/e)$-approximation guarantee. For the general case where $K\geq1$, expert co-activation within the same MoE layer introduces non-submodularity, causing greedy methods to be ineffective. To tackle this issue, we propose a successive greedy decomposition method to decompose the original problem into a series of subproblems, with each being solved by a dynamic programming approach. Furthermore, we design an accelerated algorithm based on the max-convolution technique to obtain the approximate solution with a provable guarantee in polynomial time. Simulation results on various MoE models demonstrate that our method significantly reduces inference latency compared to existing baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06567v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qian Chen, Xianhao Chen, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>DICE: Data Influence Cascade in Decentralized Learning</title>
      <link>https://arxiv.org/abs/2507.06931</link>
      <description>arXiv:2507.06931v1 Announce Type: cross 
Abstract: Decentralized learning offers a promising approach to crowdsource data consumptions and computational workloads across geographically distributed compute interconnected through peer-to-peer networks, accommodating the exponentially increasing demands. However, proper incentives are still in absence, considerably discouraging participation. Our vision is that a fair incentive mechanism relies on fair attribution of contributions to participating nodes, which faces non-trivial challenges arising from the localized connections making influence ``cascade'' in a decentralized network. To overcome this, we design the first method to estimate \textbf{D}ata \textbf{I}nfluence \textbf{C}ascad\textbf{E} (DICE) in a decentralized environment. Theoretically, the framework derives tractable approximations of influence cascade over arbitrary neighbor hops, suggesting the influence cascade is determined by an interplay of data, communication topology, and the curvature of loss landscape. DICE also lays the foundations for applications including selecting suitable collaborators and identifying malicious behaviors. Project page is available at https://raiden-zhu.github.io/blog/2025/DICE/.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06931v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tongtian Zhu, Wenhao Li, Can Wang, Fengxiang He</dc:creator>
    </item>
    <item>
      <title>Accelerated Spatio-Temporal Bayesian Modeling for Multivariate Gaussian Processes</title>
      <link>https://arxiv.org/abs/2507.06938</link>
      <description>arXiv:2507.06938v1 Announce Type: cross 
Abstract: Multivariate Gaussian processes (GPs) offer a powerful probabilistic framework to represent complex interdependent phenomena. They pose, however, significant computational challenges in high-dimensional settings, which frequently arise in spatial-temporal applications. We present DALIA, a highly scalable framework for performing Bayesian inference tasks on spatio-temporal multivariate GPs, based on the methodology of integrated nested Laplace approximations. Our approach relies on a sparse inverse covariance matrix formulation of the GP, puts forward a GPU-accelerated block-dense approach, and introduces a hierarchical, triple-layer, distributed memory parallel scheme. We showcase weak scaling performance surpassing the state-of-the-art by two orders of magnitude on a model whose parameter space is 8$\times$ larger and measure strong scaling speedups of three orders of magnitude when running on 496 GH200 superchips on the Alps supercomputer. Applying DALIA to air pollution data from northern Italy over 48 days, we showcase refined spatial resolutions over the aggregated pollutant measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.06938v1</guid>
      <category>stat.CO</category>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lisa Gaedke-Merzh\"auser, Vincent Maillou, Fernando Rodriguez Avellaneda, Olaf Schenk, Mathieu Luisier, Paula Moraga, Alexandros Nikolaos Ziogas, H{\aa}vard Rue</dc:creator>
    </item>
    <item>
      <title>Fine-tuning Multimodal Transformers on Edge: A Parallel Split Learning Approach</title>
      <link>https://arxiv.org/abs/2502.06355</link>
      <description>arXiv:2502.06355v3 Announce Type: replace 
Abstract: Multimodal transformers integrate diverse data types like images, audio, and text, advancing tasks such as audio-visual understanding and image-text retrieval; yet their high parameterization limits deployment on resource-constrained edge devices. Split Learning (SL), which partitions models at a designated cut-layer to offload compute-intensive operations to the server, offers a promising approach for distributed training of multimodal transformers, though its application remains underexplored. We present MPSL, a parallel SL approach for computational efficient fine-tuning of multimodal transformers in a distributed manner, while eliminating label sharing, client synchronization, and per-client sub-model management. MPSL employs lightweight client-side tokenizers and a unified modality-agnostic encoder, allowing flexible adaptation to task-specific needs. Our evaluation across 7 multimodal datasets demonstrates that MPSL matches or outperforms Federated Learning, reduces client-side computations by 250x, and achieves superior scalability in communication cost with model growth. Through extensive analysis, we highlight task suitability, trade-offs, and scenarios where MPSL excels, inspiring further exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06355v3</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timo Fudala, Vasileios Tsouvalas, Nirvana Meratnia</dc:creator>
    </item>
    <item>
      <title>Towards Enterprise-Ready Computer Using Generalist Agent</title>
      <link>https://arxiv.org/abs/2503.01861</link>
      <description>arXiv:2503.01861v3 Announce Type: replace 
Abstract: This paper presents our ongoing work toward developing an enterprise-ready Computer Using Generalist Agent (CUGA) system. Our research highlights the evolutionary nature of building agentic systems suitable for enterprise environments. By integrating state-of-the-art agentic AI techniques with a systematic approach to iterative evaluation, analysis, and refinement, we have achieved rapid and cost-effective performance gains, notably reaching a new state-of-the-art performance on the WebArena and AppWorld benchmarks. We detail our development roadmap, the methodology and tools that facilitated rapid learning from failures and continuous system refinement, and discuss key lessons learned and future challenges for enterprise adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01861v3</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sami Marreed, Alon Oved, Avi Yaeli, Segev Shlomov, Ido Levy, Offer Akrabi, Aviad Sela, Asaf Adi, Nir Mashkif</dc:creator>
    </item>
    <item>
      <title>iDynamics: A Novel Framework for Evaluating Microservice Scheduling Policies under Controllable Dynamics in Cloud-Edge Continuum</title>
      <link>https://arxiv.org/abs/2503.16029</link>
      <description>arXiv:2503.16029v3 Announce Type: replace 
Abstract: Designing and evaluating microservice scheduling policies is challenging, particularly under dynamic conditions such as complex call-graph dependencies and varying cross-node networking conditions. Moreover, deploying such systems in real-world cloud-edge environments to evaluate scheduling strategies is often impractical due to complexity, cost, and limited accessibility. This highlights the need for an emulation framework that can faithfully emulate the characteristics of the cloud-edge continuum. These characteristics include dynamic topology changes, latency-sensitive service chains, and varying networking conditions, all of which must be accurately modeled for meaningful evaluation. In this work, iDynamics addresses these challenges by providing a configurable and extensible framework that captures the essential dynamics of running microservice applications in cloud-edge environments, enabling systematic development and testing of microservice scheduling strategies. The framework comprises modular components, such as the Graph Dynamics Analyzer, Networking Dynamics Manager, and Scheduling Policy Extender. This enables fine-grained environmental control and facilitates systematic comparisons of different scheduling strategies. Extensive experiments on a real cloud-edge testbed demonstrate that iDynamics effectively captures diverse dynamic scenarios encountered in microservice deployments, offering a robust solution for designing and evaluating different policies under realistic and controllable conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16029v3</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Chen, Muhammed Tawfiqul Islam, Maria Rodriguez Read, Rajkumar Buyya</dc:creator>
    </item>
    <item>
      <title>Silent Failures in Stateless Systems: Rethinking Anomaly Detection for Serverless Computing</title>
      <link>https://arxiv.org/abs/2507.04969</link>
      <description>arXiv:2507.04969v2 Announce Type: replace 
Abstract: Serverless computing has redefined cloud application deployment by abstracting infrastructure and enabling on-demand, event-driven execution, thereby enhancing developer agility and scalability. However, maintaining consistent application performance in serverless environments remains a significant challenge. The dynamic and transient nature of serverless functions makes it difficult to distinguish between benign and anomalous behavior, which in turn undermines the effectiveness of traditional anomaly detection methods. These conventional approaches, designed for stateful and long-running services, struggle in serverless settings where executions are short-lived, functions are isolated, and observability is limited.
  In this first comprehensive vision paper on anomaly detection for serverless systems, we systematically explore the unique challenges posed by this paradigm, including the absence of persistent state, inconsistent monitoring granularity, and the difficulty of correlating behaviors across distributed functions. We further examine a range of threats that manifest as anomalies, from classical Denial-of-Service (DoS) attacks to serverless-specific threats such as Denial-of-Wallet (DoW) and cold start amplification. Building on these observations, we articulate a research agenda for next-generation detection frameworks that address the need for context-aware, multi-source data fusion, real-time, lightweight, privacy-preserving, and edge-cloud adaptive capabilities.
  Through the identification of key research directions and design principles, we aim to lay the foundation for the next generation of anomaly detection in cloud-native, serverless ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04969v2</guid>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chanh Nguyen, Erik Elmroth, Monowar Bhuyan</dc:creator>
    </item>
    <item>
      <title>Integrating Odeint Time Stepping into OpenFPM for Distributed and GPU Accelerated Numerical Solvers</title>
      <link>https://arxiv.org/abs/2309.05331</link>
      <description>arXiv:2309.05331v2 Announce Type: replace-cross 
Abstract: We present a software implementation integrating the time-integration library Odeint from Boost with the OpenFPM framework for scalable scientific computing. This enables compact and scalable codes for multi-stage, multi-step, and adaptive explicit time integration on distributed-memory parallel computers and on Graphics Processing Units (GPUs). The present implementation is based on extending OpenFPM's metaprogramming system to Odeint data types. This makes the time-integration methods from Odeint available in a concise template-expression language for numerical simulations distributed and parallelized using OpenFPM. We benchmark the present software for exponential and sigmoidal dynamics and present application examples to the 3D Gray-Scott reaction-diffusion problem and the "dam break" problem from fluid mechanics. We find a strong-scaling efficiency of 80% on up to 512 CPU cores and a five-fold speedup on a single GPU.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05331v2</guid>
      <category>cs.MS</category>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhinav Singh, Landfried Kraatz, Serhii Yaskovets, Pietro Incardona, Ivo F. Sbalzarini</dc:creator>
    </item>
    <item>
      <title>Multi-objective methods in Federated Learning: A survey and taxonomy</title>
      <link>https://arxiv.org/abs/2502.03108</link>
      <description>arXiv:2502.03108v2 Announce Type: replace-cross 
Abstract: The Federated Learning paradigm facilitates effective distributed machine learning in settings where training data is decentralized across multiple clients. As the popularity of the strategy grows, increasingly complex real-world problems emerge, many of which require balancing conflicting demands such as fairness, utility, and resource consumption. Recent works have begun to recognise the use of a multi-objective perspective in answer to this challenge. However, this novel approach of combining federated methods with multi-objective optimisation has never been discussed in the broader context of both fields. In this work, we offer a first clear and systematic overview of the different ways the two fields can be integrated. We propose a first taxonomy on the use of multi-objective methods in connection with Federated Learning, providing a targeted survey of the state-of-the-art and proposing unambiguous labels to categorise contributions. Given the developing nature of this field, our taxonomy is designed to provide a solid basis for further research, capturing existing works while anticipating future additions. Finally, we outline open challenges and possible directions for further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03108v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria Hartmann, Gr\'egoire Danoy, Pascal Bouvry</dc:creator>
    </item>
    <item>
      <title>New Distributed Interactive Proofs for Planarity: A Matter of Left and Right</title>
      <link>https://arxiv.org/abs/2505.00338</link>
      <description>arXiv:2505.00338v3 Announce Type: replace-cross 
Abstract: We provide new distributed interactive proofs (DIP) for planarity and related graph families. The notion of a \emph{distributed interactive proof} (DIP) was introduced by Kol, Oshman, and Saxena (PODC 2018). In this setting, the verifier consists of $n$ nodes connected by a communication graph $G$. The prover is a single entity that communicates with all nodes by short messages. The goal is to verify that the graph $G$ satisfies a certain property (e.g., planarity) in a small number of rounds, and with a small communication bound, denoted as the \emph{proof size}.
  Prior work by Naor, Parter and Yogev (SODA 2020) presented a DIP for planarity that uses three interaction rounds and a proof size of $O(\log n)$. Feuilloley et al.\ (PODC 2020) showed that the same can be achieved with a single interaction round and without randomization, by providing a proof labeling scheme with a proof size of $O(\log n)$. In a subsequent work, Bousquet, Feuilloley, and Pierron (OPODIS 2021) achieved the same bound for related graph families such as outerplanarity, series-parallel graphs, and graphs of treewidth at most $2$. In this work, we design new DIPs that use exponentially shorter proofs compared to the state-of-the-art bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00338v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Thu, 10 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuval Gil, Merav Parter</dc:creator>
    </item>
  </channel>
</rss>
