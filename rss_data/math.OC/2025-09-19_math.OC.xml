<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Sep 2025 04:01:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Nonmonotone Trust-Region Methods for Optimization of Set-Valued Mapping of Finite Cardinality</title>
      <link>https://arxiv.org/abs/2509.14426</link>
      <description>arXiv:2509.14426v1 Announce Type: new 
Abstract: Non-monotone trust-region methods are known to provide additional benefits for scalar and multi-objective optimization, such as enhancing the probability of convergence and improving the speed of convergence. For optimization of set-valued maps, non-monotone trust-region methods have not yet been explored and investigated to see if they show similar benefits. Thus, in this article, we propose two non-monotone trust-region schemes--max-type and average-type for set-valued optimization. Using these methods, the aim is to find \emph{K}-critical points for a non-convex unconstrained set optimization problem through vectorization and oriented-distance scalarization. The main modification in the existing trust region method for set optimization occurs in reduction ratios, where max-type uses the maximum over function values from the last few iterations, and avg-type uses an exponentially weighted moving average of successive previous function values till the current iteration. Under appropriate assumptions, we show the global convergence of the proposed methods. To verify their effectiveness, we numerically compare their performance with the existing trust region method, steepest descent method, and conjugate gradient method using performance profile in terms of three metrics: number of non-convergence, number of iterations, and computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14426v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Suprova Ghosh, Debdas Ghosh, Zai-Yun Peng, Xian-Jun Lon</dc:creator>
    </item>
    <item>
      <title>Should We Relax Stability in Matching Markets?</title>
      <link>https://arxiv.org/abs/2509.14475</link>
      <description>arXiv:2509.14475v1 Announce Type: new 
Abstract: Centralized assignment markets have historically relied on Deferred-Acceptance (DA) algorithms, which do not incorporate multiple objectives into the assignment. In this work, we propose an optimization-based many-to-one assignment algorithm that explores the trade-offs between minimizing the number of blocking pairs in the match and other important objectives. In order to scale to high-dimensional problems, we develop an algorithm using inverse optimization to obtain the optimal cost vector that implicitly optimizes for stability. This is empirically tested on two application areas for which the DA algorithm is widely used: school assignment and medical residency match. Computational tests on a simulated Boston Public Schools (BPS) match show that this method effectively reduces transportation cost and increases number of students receiving an offer in the first round of match at the expense of a small percentage of blocking pairs. Similar improvement in the number of couples matched to the same location is observed in a synthetic residency match.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14475v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Carol Gao</dc:creator>
    </item>
    <item>
      <title>A Time-Inconsistent Stochastic Optimal Control Problem in an Infinite Time Horizon</title>
      <link>https://arxiv.org/abs/2509.14495</link>
      <description>arXiv:2509.14495v1 Announce Type: new 
Abstract: This paper is concerned with a time-inconsistent stochastic optimal control problem in an infinite time horizon with a non-degenerate diffusion in the state equation. A major assumption is that people become rational after a large time. Under such a condition, the problem in an infinite time horizon can be decomposed into two parts: a non-autonomous time-consistent problem in an infinite time horizon and a time-inconsistent problem in a finite time horizon. Then an equilibrium strategy will be constructed. Both Bolza type problem and recursive cost problem are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14495v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingmeng Wei, Jiongmin Yong</dc:creator>
    </item>
    <item>
      <title>Sequential test sampling for stochastic derivative-free optimization</title>
      <link>https://arxiv.org/abs/2509.14505</link>
      <description>arXiv:2509.14505v1 Announce Type: new 
Abstract: In many derivative-free optimization algorithms, a sufficient decrease condition decides whether to accept a trial step in each iteration. This condition typically requires that the potential objective function value decrease of the trial step, i.e., the true reduction in the objective function value that would be achieved by moving from the current point to the trial point, be larger than a multiple of the squared stepsize. When the objective function is stochastic, evaluating such a condition accurately can require a large estimation cost. In this paper, we frame the evaluation of the sufficient decrease condition in a stochastic setting as a hypothesis test problem and solve it through a sequential hypothesis test. The two hypotheses considered in the problem correspond to accepting or rejecting the trial step. This test sequentially collects noisy sample observations of the potential decrease until their sum crosses either a lower or an upper boundary depending on the noise variance and the stepsize. When the noise of observations is Gaussian, we derive a novel sample size result, showing that the effort to evaluate the condition explicitly depends on the potential decrease, and that the sequential test terminates early whenever the sufficient decrease condition is away from satisfaction. Furthermore, when the potential decrease is~$\Theta(\delta^r)$ for some~$r\in(0,2]$, the expected sample size decreases from~$\Theta(\delta^{-4})$ to~$O(\delta^{-2-r})$. We apply this sequential test sampling framework to probabilistic-descent direct search. To analyze its convergence rate, we extend a renewal-reward supermartingale-based convergence rate analysis framework to an arbitrary probability threshold. By doing so, we are able to show that probabilistic-descent direct search has an iteration complexity of $O(n/\epsilon^2)$ for gradient norm...</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14505v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anjie Ding, Francesco Rinaldi, Luis Nunes Vicente</dc:creator>
    </item>
    <item>
      <title>Data-Driven Contextual Optimization with Gaussian Mixtures: Flow-Based Generalization, Robust Models, and Multistage Extensions</title>
      <link>https://arxiv.org/abs/2509.14557</link>
      <description>arXiv:2509.14557v1 Announce Type: new 
Abstract: Contextual optimization enhances decision quality by leveraging side information to improve predictions of uncertain parameters. However, existing approaches face significant challenges when dealing with multimodal or mixtures of distributions. The inherent complexity of such structures often precludes an explicit functional relationship between the contextual information and the uncertain parameters, limiting the direct applicability of parametric models. Conversely, while non-parametric models offer greater representational flexibility, they are plagued by the "curse of dimensionality," leading to unsatisfactory performance in high-dimensional problems. To address these challenges, this paper proposes a novel contextual optimization framework based on Gaussian Mixture Models (GMMs). This model naturally bridges the gap between parametric and non-parametric approaches, inheriting the favorable sample complexity of parametric models while retaining the expressiveness of non-parametric schemes. By employing normalizing flows, we further relax the GM assumption and extend our framework to arbitrary distributions. Finally, inspired by the structural properties of GMMs, we design a novel GMM-based solution scheme for multistage stochastic optimization problems with Markovian uncertainty. This method exhibits significantly better sample complexity compared to traditional approaches, offering a powerful methodology for solving long-horizon, high-dimensional multistage problems. We demonstrate the effectiveness of our framework through extensive numerical experiments on a series of operations management problems. The results show that our proposed approach consistently outperforms state-of-the-art methods, underscoring its practical value for complex decision-making problems under uncertainty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14557v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>YoungChul Yoon, Grani A. Hanasusanto, Yijie Wang</dc:creator>
    </item>
    <item>
      <title>Simple linesearch-free first-order methods for nonconvex optimization</title>
      <link>https://arxiv.org/abs/2509.14670</link>
      <description>arXiv:2509.14670v1 Announce Type: new 
Abstract: This paper presents an auto-conditioned proximal gradient method for nonconvex optimization. The method determines the stepsize using an estimation of local curvature and does not require any prior knowledge of problem parameters and any linesearch procedures. Its convergence analysis is carried out in a simple manner without assuming the convexity, unlike previous studies. We also provide convergence analysis in the presence of the Kurdyka--\L ojasiewicz property, adaptivity to the weak smoothness, and the extension to the Bregman proximal gradient method. Furthermore, the auto-conditioned stepsize strategy is also applied to the conditional gradient (Frank--Wolfe) method and the Riemannian gradient method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14670v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shotaro Yagishita, Masaru Ito</dc:creator>
    </item>
    <item>
      <title>Multi-Vehicle Guidance for Formation Flight on Libration Point Orbits</title>
      <link>https://arxiv.org/abs/2509.14730</link>
      <description>arXiv:2509.14730v1 Announce Type: new 
Abstract: The multiple spacecraft guidance problem for proximity flight in libration point orbit is considered. A nonlinear optimal control problem with continuous-time path constraints enforcing minimum separation between each spacecraft is formulated. The path constraints are enforced via an isoperimetric reformulation, and the problem is solved via a sequential convex programming. The proposed approach does not necessitate specific dynamic system structures to provide continuous-time guarantees for minimum separation within a fuel-optimal solution. The optimal control problem is deployed within a model predictive control scheme and demonstrated in the ephemeris model dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14730v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuri Shimane, Purnanand Elango, Avishai Weiss</dc:creator>
    </item>
    <item>
      <title>Limit theory for mean-field control problems with common noise adapted controls</title>
      <link>https://arxiv.org/abs/2509.14734</link>
      <description>arXiv:2509.14734v1 Announce Type: new 
Abstract: We consider a mean-field control problem in which admissible controls are required to be adapted to the common noise filtration. The main objective is to show how the mean-field control problem can be approximates by time consistent centralized finite population problems in which the central planner has full information on all agents' states and gives an identical signal to all agents. We also aim at establishing the optimal convergence rate. In a first general path-dependent setting, we only prove convergence by using weak convergence techniques of probability measures on the canonical space. Next, when only the drift coefficient is controlled, we obtain a backward SDE characterization of the value process, based on which a convergence rate is established in terms of the Wasserstein distance between the original measure and the empirical one induced by the particles. It requires Lipschitz continuity conditions in the Wasserstein sense. The convergence rate is optimal. In a Markovian setting and under convexity conditions on the running reward function, we next prove uniqueness of the optimal control and provide regularity results on the value function, and then deduce the optimal weak convergence rate in terms of the number of particles. Finally, we apply these results to the study of a classical optimal control problem with partial observation, leading to an original approximation method by particle systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14734v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruno Bouchard, Xiaolu Tan</dc:creator>
    </item>
    <item>
      <title>On the Multiary Algebraic Formulation of an Idempotent Symmetric Limit Convex Structure</title>
      <link>https://arxiv.org/abs/2509.14843</link>
      <description>arXiv:2509.14843v1 Announce Type: new 
Abstract: In [14], B-convexity was defined as an appropriate Painlev\'e-Kuratowski limit of linear convexities. More recently, an alternative algebraic formulation over the entire Euclidean vector space was proposed in [9] and [10]. The issue with the definition presented in [14] is that it was not developed from an algebraic perspective, but rather as the upper limit of a sequence of generalized convex polytopes whose form was not explicitly given. In this paper, we build on recent work and provide an algebraic formulation for these limiting polytopes. Consequently, we deduce a multiary algebraic form of B-convexity that involves an idempotent, non-associative algebraic structure, extending the formalism proposed in [9] to an arbitrary number of points. Among other things, we demonstrate that these limiting polytopes do not satisfy the idempotent symmetrical convex structure defined in [9]. In the context of this formalism, we derive a general separation result in Rn by approximating convex sets by polytopes. We conclude by clarifying some points regarding the external representation of polytopes proposed in [11] and analyze the structure of the polytopes that arise in this context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14843v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Walter Briec</dc:creator>
    </item>
    <item>
      <title>Graph-Aware Learning Rates for Decentralized Optimization</title>
      <link>https://arxiv.org/abs/2509.14854</link>
      <description>arXiv:2509.14854v1 Announce Type: new 
Abstract: We propose an adaptive step-size rule for decentralized optimization. Choosing a step-size that balances convergence and stability is challenging. This is amplified in the decentralized setting as agents observe only local (possibly stochastic) gradients and global information (like smoothness) is unavailable. We derive a step-size rule from first principles. The resulting formulation reduces to the well-known Polyak's rule in the single-agent setting, and is suitable for use with stochastic gradients. The method is parameter free, apart from requiring the optimal objective value, which is readily available in many applications. Numerical simulations demonstrate that the performance is comparable to the optimally fine-tuned step-size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14854v1</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Fainman, Stefan Vlaski</dc:creator>
    </item>
    <item>
      <title>Ramsey model of optimal growth with Allee effect</title>
      <link>https://arxiv.org/abs/2509.14876</link>
      <description>arXiv:2509.14876v1 Announce Type: new 
Abstract: For the Ramsey model of economic growth, which describes the optimal allocation of consumption and saving over time, we assume the population dynamics to follow the Allee effect. The so-called Allee threshold separates two regimes from each other. If starting below the threshold, the population decreases to zero. Above this threshold, it gradually saturates. We show that the corresponding consumption per capita stabilizes at two different levels accordingly. As for our main result, the consumption per capita performs in the long run better if the population becomes extinct, rather then it advances the saturation level. This is in line with our previous results on the capital per capita for the underlying Solow-Swan model of economic growth with the Allee effect. However, the comparison of consumption-to-capital ratios at the both steady states crucially depends on the curvature of the production function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14876v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zihan Wang, Vladimir Shikhman</dc:creator>
    </item>
    <item>
      <title>Deadbeat Robust Model Predictive Control for Linear Parameter-Varying Systems</title>
      <link>https://arxiv.org/abs/2509.14885</link>
      <description>arXiv:2509.14885v1 Announce Type: new 
Abstract: The concept of Deadbeat Robust Model Predictive Control (DRMPC) is to completely extinguish the effect of external disturbances within the first few steps of the prediction horizon. The benefit is that the remaining dynamics of the system can be planned with certainty. This means it is not necessary to employ a Robust Positive Invariant (RPI) set as a terminal condition, which is often complex or even intractable to compute. Recent work has shown that it is possible to obtain full system theoretic guarantees in the case of linear systems, including recursive feasibility of all constraints and input-to-state stability. This paper extends this contribution to linear time-varying (LTV) or parameter-varying systems (LPV) systems with bounded parametric uncertainty and additive disturbances. Full system-theoretic guarantees can also be provided for these cases. Numerical simulation results demonstrate that the performance of the proposed LPV-DRMPC scheme, with the origin as the terminal set and a slightly increased prediction horizon, is almost comparable to that of other LPV-MPC schemes with an RPI terminal set constraint, despite a lower computational complexity. Besides avoiding the computation of RPI terminal sets, LPV-DRMPC allows to shift a significant portion of the computations offline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14885v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georg Schildbach, Hossam S. Abbas</dc:creator>
    </item>
    <item>
      <title>Consensus, polarization, and optimization of the mean value in a nonlinear model of opinion dynamics</title>
      <link>https://arxiv.org/abs/2509.14918</link>
      <description>arXiv:2509.14918v1 Announce Type: new 
Abstract: This paper investigates some aspects of a recently proposed nonlinear mathematical model of opinion dynamics. The main objective is to identify the network structures that maximize the average equilibrium opinion (HMO). We prove that consensus is not generally attainable for populations with heterogeneous convictions, and that the highest mean does not necessarily correspond to consensus. Our analysis includes a necessary and sufficient condition for achieving the HMO, description of an algorithm for constructing optimal connectivity matrices, and strategies for pruning agents when heterogeneity obstructs mean optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14918v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David N. Reynolds, Pedro J. Torres</dc:creator>
    </item>
    <item>
      <title>On Finite- and Fixed-Time Stabilization of Abstract Nonlinear Systems with Well-Posedness Guarantees</title>
      <link>https://arxiv.org/abs/2509.14376</link>
      <description>arXiv:2509.14376v1 Announce Type: cross 
Abstract: This paper addresses the problem of stabilization for infinite-dimensional systems. In particular, we design nonlinear stabilizers for both linear and nonlinear abstract systems. We focus on two classes of systems: the first class comprises linear abstract systems subject to matched perturbations, while the second class encompasses fully nonlinear abstract systems. Our main objective is to synthesize state-feedback controllers that guarantee finite- or fixed-time stability of the closed-loop system, along with possible estimation of the settling time. For the first class, the presence of persistent perturbations introduces significant challenges in the well-posedness analysis, particularly due to the discontinuous nature of the control law. To address this, we employ maximal monotone operator theory to rigorously establish the existence and uniqueness of solutions, extending classical results from continuous abstract systems. For the second class, which includes nonlinearities, we further show that the proposed feedback law ensures fixed-time stability and well-posedness of the closed-loop system, again using maximal monotone theory. The results provide a unified framework for robust, finite /fixed-time stabilization in the presence of discontinuities and nonlinearities in infinite-dimensional settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14376v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kamal Fenza, Moussa Labbadi, Mohamed Ouzahra</dc:creator>
    </item>
    <item>
      <title>UTOPY: Unrolling Algorithm Learning via Fidelity Homotopy for Inverse Problems</title>
      <link>https://arxiv.org/abs/2509.14394</link>
      <description>arXiv:2509.14394v1 Announce Type: cross 
Abstract: Imaging Inverse problems aim to reconstruct an underlying image from undersampled, coded, and noisy observations. Within the wide range of reconstruction frameworks, the unrolling algorithm is one of the most popular due to the synergistic integration of traditional model-based reconstruction methods and modern neural networks, providing an interpretable and highly accurate reconstruction. However, when the sensing operator is highly ill-posed, gradient steps on the data-fidelity term can hinder convergence and degrade reconstruction quality. To address this issue, we propose UTOPY, a homotopy continuation formulation for training the unrolling algorithm. Mainly, this method involves using a well-posed (synthetic) sensing matrix at the beginning of the unrolling network optimization. We define a continuation path strategy to transition smoothly from the synthetic fidelity to the desired ill-posed problem. This strategy enables the network to progressively transition from a simpler, well-posed inverse problem to the more challenging target scenario. We theoretically show that, for projected gradient descent-like unrolling models, the proposed continuation strategy generates a smooth path of unrolling solutions. Experiments on compressive sensing and image deblurring demonstrate that our method consistently surpasses conventional unrolled training, achieving up to 2.5 dB PSNR improvement in reconstruction performance. Source code at</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14394v1</guid>
      <category>eess.IV</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roman Jacome, Romario Gualdr\'on-Hurtado, Leon Suarez-Rodriguez, Henry Arguello</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization with Topology-Independent Communication</title>
      <link>https://arxiv.org/abs/2509.14488</link>
      <description>arXiv:2509.14488v1 Announce Type: cross 
Abstract: Distributed optimization requires nodes to coordinate, yet full synchronization scales poorly. When $n$ nodes collaborate through $m$ pairwise regularizers, standard methods demand $\mathcal{O}(m)$ communications per iteration. This paper proposes randomized local coordination: each node independently samples one regularizer uniformly and coordinates only with nodes sharing that term. This exploits partial separability, where each regularizer $G_j$ depends on a subset $S_j \subseteq \{1,\ldots,n\}$ of nodes. For graph-guided regularizers where $|S_j|=2$, expected communication drops to exactly 2 messages per iteration. This method achieves $\tilde{\mathcal{O}}(\varepsilon^{-2})$ iterations for convex objectives and under strong convexity, $\mathcal{O}(\varepsilon^{-1})$ to an $\varepsilon$-solution and $\mathcal{O}(\log(1/\varepsilon))$ to a neighborhood. Replacing the proximal map of the sum $\sum_j G_j$ with the proximal map of a single randomly selected regularizer $G_j$ preserves convergence while eliminating global coordination. Experiments validate both convergence rates and communication efficiency across synthetic and real-world datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14488v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Lin, Yao Kuang, Ahmet Alacaoglu, Michael P. Friedlander</dc:creator>
    </item>
    <item>
      <title>LiMuon: Light and Fast Muon Optimizer for Large Models</title>
      <link>https://arxiv.org/abs/2509.14562</link>
      <description>arXiv:2509.14562v1 Announce Type: cross 
Abstract: Large models recently are widely applied in artificial intelligence, so efficient training of large models has received widespread attention. More recently, a useful Muon optimizer is specifically designed for matrix-structured parameters of large models. Although some works have begun to studying Muon optimizer, the existing Muon and its variants still suffer from high sample complexity or high memory for large models. To fill this gap, we propose a light and fast Muon (LiMuon) optimizer for training large models, which builds on the momentum-based variance reduced technique and randomized Singular Value Decomposition (SVD). Our LiMuon optimizer has a lower memory than the current Muon and its variants. Moreover, we prove that our LiMuon has a lower sample complexity of $O(\epsilon^{-3})$ for finding an $\epsilon$-stationary solution of non-convex stochastic optimization under the smooth condition. Recently, the existing convergence analysis of Muon optimizer mainly relies on the strict Lipschitz smooth assumption, while some artificial intelligence tasks such as training large language models (LLMs) do not satisfy this condition. We also proved that our LiMuon optimizer has a sample complexity of $O(\epsilon^{-3})$ under the generalized smooth condition. Numerical experimental results on training DistilGPT2 and ViT models verify efficiency of our LiMuon optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14562v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Feihu Huang, Yuning Luo, Songcan Chen</dc:creator>
    </item>
    <item>
      <title>Online reinforcement learning via sparse Gaussian mixture model Q-functions</title>
      <link>https://arxiv.org/abs/2509.14585</link>
      <description>arXiv:2509.14585v1 Announce Type: cross 
Abstract: This paper introduces a structured and interpretable online policy-iteration framework for reinforcement learning (RL), built around the novel class of sparse Gaussian mixture model Q-functions (S-GMM-QFs). Extending earlier work that trained GMM-QFs offline, the proposed framework develops an online scheme that leverages streaming data to encourage exploration. Model complexity is regulated through sparsification by Hadamard overparametrization, which mitigates overfitting while preserving expressiveness. The parameter space of S-GMM-QFs is naturally endowed with a Riemannian manifold structure, allowing for principled parameter updates via online gradient descent on a smooth objective. Numerical tests show that S-GMM-QFs match the performance of dense deep RL (DeepRL) methods on standard benchmarks while using significantly fewer parameters, and maintain strong performance even in low-parameter-count regimes where sparsified DeepRL methods fail to generalize.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14585v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minh Vu, Konstantinos Slavakis</dc:creator>
    </item>
    <item>
      <title>Lower Bounds for the Shadiness Constant of Finite-Dimensional Normed Spaces</title>
      <link>https://arxiv.org/abs/2509.14819</link>
      <description>arXiv:2509.14819v1 Announce Type: cross 
Abstract: By the Hahn-Banach theorem, every normed space admits rank-one projections with operator norm one. However, this is not true for higher rank projections. Bosznay and Garay showed that for every $d \geq 3$ there exist $d$-dimensional normed spaces $X$ for which all projections of rank $k$, with $2 \leq k \leq d-1$, have norm larger than or equal to some constant $c&gt;1$. We call the maximal such constant the shadiness constant of $X$. Although constructing such spaces is not difficult, few explicit estimates of their shadiness constants exist. We show how optimization techniques can provide provable lower bounds for these shadiness constants. As an application, we construct a $3$-dimensional normed space whose unit ball is a polytope with $12$ vertices, with shadiness constant at least $1.01$. Furthermore we show that there is no shady norm on $\mathbb{R}^3$ whose unit ball is a polytope with $10$ or fewer vertices, thereby confirming a conjecture by Bosznay and Garay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14819v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeremias Epperlein</dc:creator>
    </item>
    <item>
      <title>Stochastic Adaptive Gradient Descent Without Descent</title>
      <link>https://arxiv.org/abs/2509.14969</link>
      <description>arXiv:2509.14969v1 Announce Type: cross 
Abstract: We introduce a new adaptive step-size strategy for convex optimization with stochastic gradient that exploits the local geometry of the objective function only by means of a first-order stochastic oracle and without any hyper-parameter tuning. The method comes from a theoretically-grounded adaptation of the Adaptive Gradient Descent Without Descent method to the stochastic setting. We prove the convergence of stochastic gradient descent with our step-size under various assumptions, and we show that it empirically competes against tuned baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14969v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jean-Fran\c{c}ois Aujol, J\'er\'emie Bigot, Camille Castera</dc:creator>
    </item>
    <item>
      <title>On Uniformly Time-Varying Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2509.15037</link>
      <description>arXiv:2509.15037v1 Announce Type: cross 
Abstract: This paper investigates the design of a subclass of time-varying Control Barrier Functions (CBFs), specifically that of uniformly time-varying CBFs. Leveraging the fact that CBFs encode a system's dynamic capabilities relative to a state constraint, we decouple the design of uniformly time-varying CBFs into a time-invariant and a time-varying component. We characterize the subclass of time-invariant CBFs that yield a uniformly time-varying CBF when combined with a specific type of time-varying function. A detailed analysis of those conditions under which the time-varying function preserves the CBF property of the time-invariant component is provided. These conditions allow for selecting the time-varying function such that diverse variations in the state constraints can be captured while avoiding the redesign of the time-invariant component. From a technical point of view, the analysis requires the derivation of novel relations for comparison functions, not previously reported in the literature. We further relax the requirements on the time-varying function, showing that forward invariance can still be ensured even when the uniformly time-varying value function does not strictly constitute a CBF. Finally, we discuss how existing CBF construction methods can be applied to design suitable time-invariant CBFs, and demonstrate the effectiveness of the approach through detailed numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15037v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adrian Wiltz, Dimos V. Dimarogonas</dc:creator>
    </item>
    <item>
      <title>Geometric optimization for quantum communication</title>
      <link>https://arxiv.org/abs/2509.15106</link>
      <description>arXiv:2509.15106v1 Announce Type: cross 
Abstract: Determining the ultimate limits of quantum communication, such as the quantum capacity of a channel and the distillable entanglement of a shared state, remains a central challenge in quantum information theory, primarily due to the phenomenon of superadditivity. This work develops Riemannian optimization methods to establish significantly tighter, computable two-sided bounds on these fundamental quantities. For upper bounds, our method systematically searches for state and channel extensions that minimize known information-theoretic bounds. We achieve this by parameterizing the space of all possible extensions as a Stiefel manifold, enabling a universal search that overcomes the limitations of ad-hoc constructions. Combined with an improved upper bound on the one-way distillable entanglement based on a refined continuity bound on quantum conditional entropy, our approach yields new state-of-the-art upper bounds on the quantum capacity of the qubit depolarizing channel for large values of the depolarizing parameter, strictly improving the previously best-known bounds. For lower bounds, we introduce Riemannian optimization methods to compute multi-shot coherent information. We establish lower bounds on the one-way distillable entanglement by parameterizing quantum instruments on the unitary manifold, and on the quantum capacity by parameterizing code states with a product of unitary manifolds. Numerical results for noisy entangled states and different channels demonstrate that our methods successfully unlock superadditive gains, improving previous results. Together, these findings establish Riemannian optimization as a principled and powerful tool for navigating the complex landscape of quantum communication limits. Furthermore, we prove that amortization does not enhance the channel coherent information, thereby closing a potential avenue for improving capacity lower bounds in general.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15106v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengkai Zhu, Hongyu Mao, Kun Fang, Xin Wang</dc:creator>
    </item>
    <item>
      <title>Coercive quadratic converse ISS Lyapunov theorems for linear analytic systems</title>
      <link>https://arxiv.org/abs/2303.15093</link>
      <description>arXiv:2303.15093v2 Announce Type: replace 
Abstract: We derive converse Lyapunov theorems for input-to-state stability (ISS) of linear infinite-dimensional analytic systems. We show that input-to-state stability of a linear system does not imply existence of a coercive quadratic ISS Lyapunov function, even if the input operator is bounded. If, however, the semigroup is similar to a contraction semigroup on a Hilbert space, then a quadratic ISS Lyapunov function always exists for any input operator that is bounded, or more generally, $p$-admissible with $p&lt;2$. The constructions are semi-explicit and, in the case of self-adjoint generators, coincide with the canonical Lyapunov function being the norm squared. Finally, we construct a family of non-coercive ISS Lyapunov functions for analytic ISS systems under weaker assumptions on $B$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.15093v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrii Mironchenko, Felix Schwenninger</dc:creator>
    </item>
    <item>
      <title>Electric Vehicle Fleet and Charging Infrastructure Planning</title>
      <link>https://arxiv.org/abs/2306.10178</link>
      <description>arXiv:2306.10178v4 Announce Type: replace 
Abstract: We study electric vehicle (EV) fleet and charging infrastructure planning in a spatial setting. With customer requests arriving continuously at rate $\lambda$ throughout the day, we determine the minimum number of vehicles and chargers for a target service level, along with matching and charging policies. While non-EV systems require extra $\Theta(\lambda^{2/3})$ vehicles due to pickup times, EV systems differ. Charging increases nominal capacity, enabling pickup time reductions and allowing for an extra fleet requirement of only $\Theta(\lambda^{\nu})$ for $\nu \in (1/2, 2/3]$, depending on charging infrastructure and battery pack sizes. We propose the Power-of-$d$ dispatching policy, which achieves this performance by selecting the closest vehicle with the highest battery level from $d$ options. We extend our results to accommodate time-varying demand patterns and discuss conditions for transitioning between EV and non-EV capacity planning. Extensive simulations verify our scaling results, insights, and policy effectiveness while also showing the viability of low-range, low-cost fleets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10178v4</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sushil Mahavir Varma, Francisco Castro, Siva Theja Maguluri</dc:creator>
    </item>
    <item>
      <title>Greedy Newton: Newton's Method with Exact Line Search</title>
      <link>https://arxiv.org/abs/2401.06809</link>
      <description>arXiv:2401.06809v2 Announce Type: replace 
Abstract: {A defining characteristic of Newton's method is local superlinear convergence within a neighbourhood of a strict local minimum. However, outside this neighborhood Newton's method can converge slowly or even diverge. A common approach to dealing with non-convergence is using a step size that is set by an Armijo backtracking line search. With suitable initialization the line-search preserves local superlinear convergence, but may give sub-optimal progress when not near a solution. In this work we consider Newton's method under an exact line search, which we call ``greedy Newton'' (GN). We show that this leads to an improved global convergence rate, while retaining a local superlinear convergence rate. We empirically show that GN may work better than backtracking Newton by allowing significantly larger step sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06809v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11590-025-02220-6</arxiv:DOI>
      <dc:creator>Betty Shea, Mark Schmidt</dc:creator>
    </item>
    <item>
      <title>Directional descent</title>
      <link>https://arxiv.org/abs/2408.14308</link>
      <description>arXiv:2408.14308v2 Announce Type: replace 
Abstract: We identity the optimal non-infinitesimal direction of descent for a convex function. An algorithm is developed that can theoretically minimize a subset of (non-convex) functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.14308v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew J. Young</dc:creator>
    </item>
    <item>
      <title>Lossless Convexification for Linear Systems with Piecewise Linear Controls</title>
      <link>https://arxiv.org/abs/2411.18004</link>
      <description>arXiv:2411.18004v2 Announce Type: replace 
Abstract: Lossless Convexification (LCvx) is a convexification technique that transforms a class of nonconvex optimal control problems$\unicode{x2013}$where the nonconvexity arises from a lower bound on the control norm$\unicode{x2013}$into equivalent convex problems, with the goal being to apply fast polynomial-time solvers. However, to solve these infinite-dimensional problems in practice, they must first be converted into finite-dimensional problems, and it remains an open challenge to ensure the theoretical guarantees of LCvx are maintained across this discretization step. Prior work has proven guarantees for piecewise constant controls, but these methods do not extend to piecewise linear controls, which are more relevant to real world applications.
  In this work, we present an algorithm that extends LCvx guarantees to piecewise linear controls. Under mild assumptions, our algorithm provably finds a solution violating the nonconvex constraints along at most $2n_x + 2$ trajectory "edges" using $O(\log(\Delta\rho/\varepsilon))$ solver calls (where $n_x$ is the state space dimension and $\Delta\rho = \rho_{\max} - \rho_{\min}$ is the difference in our control norm bounds). A key feature is the perturbation of the control norm lower bound and the addition of rate constraints on the controls, ensuring LCvx holds along the trajectory edges. Finally, we provide numerical results demonstrating the effectiveness of our algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.18004v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shosuke Kiami</dc:creator>
    </item>
    <item>
      <title>Differentiability of the value function in control-constrained parabolic problems</title>
      <link>https://arxiv.org/abs/2412.20310</link>
      <description>arXiv:2412.20310v2 Announce Type: replace 
Abstract: Along the optimal trajectory of an optimal control problem constrained by a semilinear parabolic partial differential equation, we prove the differentiability of the value function with respect to the initial condition and, under additional assumptions on the solution of the state equation, the differentiability of the value function with respect to the time variable. In our proof, we rely on local growth assumptions commonly associated with the study of second-order sufficient conditions. These assumptions are generally applicable to a wide range of problems, including, for instance, certain tracking-type problems. Finally, we discuss the differentiability of the value function in a neighborhood of the optimal trajectory when a growth condition for optimal controls is used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20310v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Dom\'inguez Corella, Nicolai Jork, Stefan Volkwein</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Zeroth-Order Optimization with Compressed Communication</title>
      <link>https://arxiv.org/abs/2503.17429</link>
      <description>arXiv:2503.17429v3 Announce Type: replace 
Abstract: The dual challenges of prohibitive communication overhead and the impracticality of gradient computation due to data privacy or black-box constraints in distributed systems motivate this work on communication-constrained gradient-free optimization. We propose a stochastic distributed zeroth-order algorithm (Com-DSZO) requiring only two function evaluations per iteration, integrated with general compression operators. Rigorous analysis establishes its sublinear convergence rate for both smooth and nonsmooth objectives, while explicitly elucidating the compression-convergence trade-off. Furthermore, we develop a variance-reduced variant (VR-Com-DSZO) under stochastic mini-batch feedback. The empirical algorithm performance are illustrated with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17429v3</guid>
      <category>math.OC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3610109</arxiv:DOI>
      <dc:creator>Youqing Hua, Shuai Liu, Yiguang Hong, Wei Ren</dc:creator>
    </item>
    <item>
      <title>Hamiltonian Descent Algorithms for Optimization: Accelerated Rates via Randomized Integration Time</title>
      <link>https://arxiv.org/abs/2505.12553</link>
      <description>arXiv:2505.12553v2 Announce Type: replace 
Abstract: We study the Hamiltonian flow for optimization (HF-opt), which simulates the Hamiltonian dynamics for some integration time and resets the velocity to $0$ to decrease the objective function; this is the optimization analogue of the Hamiltonian Monte Carlo algorithm for sampling. For short integration time, HF-opt has the same convergence rates as gradient descent for minimizing strongly and weakly convex functions. We show that by randomizing the integration time in HF-opt, the resulting randomized Hamiltonian flow (RHF) achieves accelerated convergence rates in continuous time, similar to the rates for the accelerated gradient flow. We study a discrete-time implementation of RHF as the randomized Hamiltonian gradient descent (RHGD) algorithm. We prove that RHGD achieves the same accelerated convergence rates as Nesterov's accelerated gradient descent (AGD) for minimizing smooth strongly and weakly convex functions. We provide numerical experiments to demonstrate that RHGD is competitive with classical accelerated methods such as AGD across all settings and outperforms them in certain regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12553v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Fu, Andre Wibisono</dc:creator>
    </item>
    <item>
      <title>Provable Non-Convex Euclidean Distance Matrix Completion: Geometry, Reconstruction, and Robustness</title>
      <link>https://arxiv.org/abs/2508.00091</link>
      <description>arXiv:2508.00091v2 Announce Type: replace 
Abstract: The problem of recovering the configuration of points from their partial pairwise distances, referred to as the Euclidean Distance Matrix Completion (EDMC) problem, arises in a broad range of applications, including sensor network localization, molecular conformation, and manifold learning. In this paper, we propose a Riemannian optimization framework for solving the EDMC problem by formulating it as a low-rank matrix completion task over the space of positive semi-definite Gram matrices. The available distance measurements are encoded as expansion coefficients in a non-orthogonal basis, and optimization over the Gram matrix implicitly enforces geometric consistency through nonnegativity and the triangle inequality, a structure inherited from classical multidimensional scaling. Under a Bernoulli sampling model for observed distances, we prove that Riemannian gradient descent on the manifold of rank-$r$ matrices locally converges linearly with high probability when the sampling probability satisfies $p\geq O(\nu^2 r^2\log(n)/n)$, where $\nu$ is an EDMC-specific incoherence parameter. Furthermore, we provide an initialization candidate using a one-step hard thresholding procedure that yields convergence, provided the sampling probability satisfies $p \geq O(\nu r^{3/2}\log^{3/4}(n)/n^{1/4})$. A key technical contribution of this work is the analysis of a symmetric linear operator arising from a dual basis expansion in the non-orthogonal basis, which requires a novel application of the Hanson-Wright inequality to establish an optimal restricted isometry property in the presence of coupled terms. Empirical evaluations on synthetic data demonstrate that our algorithm achieves competitive performance relative to state-of-the-art methods. Moreover, we provide a geometric interpretation of matrix incoherence tailored to the EDMC setting and provide robustness guarantees for our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00091v2</guid>
      <category>math.OC</category>
      <category>cs.CG</category>
      <category>cs.LG</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Chandler Smith, HanQin Cai, Abiy Tasissa</dc:creator>
    </item>
    <item>
      <title>A $\sqrt{2}$-accelerated FISTA for composite strongly convex problems</title>
      <link>https://arxiv.org/abs/2509.09295</link>
      <description>arXiv:2509.09295v2 Announce Type: replace 
Abstract: In this paper, we propose a novel accelerated forward-backward splitting algorithm for minimizing convex composite functions, written as the sum of a smooth function and a (possibly) nonsmooth function. When the objective function is strongly convex, the method attains, to the best of our knowledge, the fastest known convergence rate, yielding a simultaneous linear and sublinear nonasymptotic bound. Our convergence analysis remains valid even when one of the two terms is only weakly convex (while the sum remains convex). The algorithm is derived by discretizing a continuous-time model of the Information-Theoretic Exact Method (ITEM), which is the optimal method for unconstrained strongly convex minimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09295v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kansei Ushiyama</dc:creator>
    </item>
    <item>
      <title>A preconditioned third-order implicit-explicit algorithm with a difference of varying convex functions and extrapolation</title>
      <link>https://arxiv.org/abs/2509.09391</link>
      <description>arXiv:2509.09391v2 Announce Type: replace 
Abstract: This paper proposes a novel preconditioned implicit-explicit algorithm enhanced with the extrapolation technique for non-convex optimization problems. The algorithm employs a third-order Adams-Bashforth scheme for the nonlinear and explicit parts and a third-order backward differentiation formula for the implicit part of the gradient flow in variational functions. The proposed algorithm, akin to a generalized difference-of-convex (DC) approach, employs a changing set of convex functions in each iteration. Under the Kurdyka-\L ojasiewicz (KL) properties, the global convergence of the algorithm is guaranteed, ensuring that it converges within a finite number of preconditioned iterations. Our numerical experiments, including least squares problems with SCAD regularization and the graphical Ginzburg-Landau model, demonstrate the proposed algorithm's highly efficient performance compared to conventional DC algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09391v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kelin Wu, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>From Learning to Optimize to Learning Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2405.18222</link>
      <description>arXiv:2405.18222v3 Announce Type: replace-cross 
Abstract: Towards designing learned optimization algorithms that are usable beyond their training setting, we identify key principles that classical algorithms obey, but have up to now, not been used for Learning to Optimize (L2O). Following these principles, we provide a general design pipeline, taking into account data, architecture and learning strategy, and thereby enabling a synergy between classical optimization and L2O, resulting in a philosophy of Learning Optimization Algorithms. As a consequence our learned algorithms perform well far beyond problems from the training distribution. We demonstrate the success of these novel principles by designing a new learning-enhanced BFGS algorithm and provide numerical experiments evidencing its adaptation to many settings at test time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18222v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of The 28th International Conference on Artificial Intelligence and Statistics, PMLR 258:1792-1800, 2025</arxiv:journal_reference>
      <dc:creator>Camille Castera, Peter Ochs</dc:creator>
    </item>
  </channel>
</rss>
