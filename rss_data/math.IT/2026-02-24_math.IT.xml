<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 24 Feb 2026 05:01:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Turbo Coded Single Sideband OFDM-OQAM Signaling through Frequency Selective Rayleigh Fading Channels</title>
      <link>https://arxiv.org/abs/2602.18881</link>
      <description>arXiv:2602.18881v1 Announce Type: new 
Abstract: This work investigates the bit-error-rate (BER) performance of turbo coded orthogonal frequency division multiplexed - offset quadrature amplitude modulated (OFDM- OQAM) signals transmitted through frequency selective Rayleigh fading channels in the presence of carrier frequency offset (CFO) and additive white Gaussian noise (AWGN). The highlight of this work is to use the root raised cosine (RRC) pulse and its Hilbert transform as the complex-valued transmit filter and a simple matched filter at the receiver. The proposed system is similar to single sideband (SSB) modulation, that has roots in analog communications. Turbo code and subcarrier diversity is employed to improve the BER performance over that of an uncoded system. Discrete-time algorithms for frame detection, two-step CFO, channel and noise variance estimation have been proposed. A single transmit and receive antenna is assumed. Similar work has not been done earlier.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18881v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kasturi Vasudevan</dc:creator>
    </item>
    <item>
      <title>Derivation Depth as an Information Metric: Axioms, Coding Theorems, and Storage--Computation Tradeoffs</title>
      <link>https://arxiv.org/abs/2602.19137</link>
      <description>arXiv:2602.19137v1 Announce Type: new 
Abstract: We introduce derivation depth-a computable metric of the reasoning effort needed to answer a query based on a given set of premises. We model information as a two-layered structure linking abstract knowledge with physical carriers, and separate essential core facts from operational shortcuts. For any finite premise base, we define and prove the computability of derivation depth. By encoding reasoning traces and applying information-theoretic incompressibility arguments, we establish fundamental bounds linking depth to the descriptive complexity of queries. For frequently asked, information-rich queries, the minimal description length grows proportionally to depth times the logarithm of the knowledge base size. This leads to a practical storage-computation tradeoff: queries accessed beyond a critical threshold become cheaper to cache than recompute. We formulate optimal cache allocation as a mathematical optimization problem solvable with approximation guarantees and extend the framework to handle noisy or incomplete knowledge bases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19137v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Xu</dc:creator>
    </item>
    <item>
      <title>Physics-Compliant Modeling and Optimization of MIMO Systems Aided by Microwave Linear Analog Computers</title>
      <link>https://arxiv.org/abs/2602.19379</link>
      <description>arXiv:2602.19379v1 Announce Type: new 
Abstract: Microwave linear analog computer (MiLAC) has emerged as a promising architecture for implementing linear multiple-input multiple-output (MIMO) processing in the analog domain, with radio frequency (RF) signals. Existing studies on MiLAC-aided communications rely on idealized channel models and neglect antenna mutual coupling. However, since MiLAC performs processing at RF, mutual coupling becomes critical and alters the implemented operation, not only the channel characteristics. In this paper, we develop a physics-compliant model for MiLAC-aided MIMO systems accounting for mutual coupling with multiport network theory. We derive end-to-end system models for scenarios with MiLACs at the transmitter, the receiver, or both, showing how mutual coupling impacts the linear transformation implemented by the MiLACs. Furthermore, we formulate and solve a mutual coupling aware MiLAC optimization problem, deriving a closed-form globally optimal solution that maximizes the received signal power. We establish the fundamental performance limits of MiLAC with mutual coupling, and derive three analytical results. First, mutual coupling is beneficial in MiLAC-aided systems, on average. Second, with mutual coupling, MiLAC performs as digital architectures equipped with a matching network, while having fewer RF chains. Third, with mutual coupling, MiLAC always outperforms digital architectures with no matching network. Numerical simulations confirm our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19379v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Nerini, Bruno Clerckx</dc:creator>
    </item>
    <item>
      <title>Toward a Quiet Wireless World: Multi-Cell Pinching-Antenna Transmission</title>
      <link>https://arxiv.org/abs/2602.19459</link>
      <description>arXiv:2602.19459v1 Announce Type: new 
Abstract: Conventional-antenna-based multi-cell interference management can lead to excessive power consumption. For example, in order to serve those users which are close to the cell edge, base stations often must transmit at very high power levels to overcome severe large-scale path-loss, i.e., the base stations have to ``shout" at the users to realize the users' target quality of service (QoS). This letter focuses on the application of pinching antennas to multi-cell interference management and demonstrates that the use of multi-cell pinching-antenna transmission leads to a quiet wireless world. In particular, each transceiver pair can be positioned in close proximity, and hence the users' QoS requirements can be met with only low transmit power, i.e., via ``whispering" rather than high-power transmission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19459v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiguo Ding</dc:creator>
    </item>
    <item>
      <title>Physics-Aware, Shannon-Optimal Compression via Arithmetic Coding for Distributional Fidelity</title>
      <link>https://arxiv.org/abs/2602.19476</link>
      <description>arXiv:2602.19476v1 Announce Type: new 
Abstract: Assessing whether two datasets are distributionally consistent has become a central theme in modern scientific analysis, particularly as generative artificial intelligence is increasingly used to produce synthetic datasets whose fidelity must be rigorously validated against the original data on which they are trained, a task made more challenging by the continued growth in data volume and problem dimensionality. In this work, we propose the use of arithmetic coding to provide a lossless and invertible compression of datasets under a physics-informed probabilistic representation. Datasets that share the same underlying physical correlations admit comparable optimal descriptions, while discrepancies in those correlations-arising from miscalibration, mismodeling, or bias-manifest as an irreducible excess in code length. This excess codelength defines an operational fidelity metric, quantified directly in bits through differences in achievable compression length relative to a physics-inspired reference distribution. We demonstrate that this metric is global, interpretable, additive across components, and asymptotically optimal in the Shannon sense. Moreover, we show that differences in codelength correspond to differences in expected negative log-likelihood evaluated under the same physics-informed reference model. As a byproduct, we also demonstrate that our compression approach achieves a higher compression ratio than traditional general-purpose algorithms such as gzip. Our results establish lossless, physics-aware compression based on arithmetic coding not as an end in itself, but as a measurement instrument for testing the fidelity between datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19476v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cristiano Fanelli</dc:creator>
    </item>
    <item>
      <title>Nacrith: Neural Lossless Compression via Ensemble Context Modeling and High-Precision CDF Coding</title>
      <link>https://arxiv.org/abs/2602.19626</link>
      <description>arXiv:2602.19626v1 Announce Type: new 
Abstract: We present Nacrith, a lossless compression system that combines a 135M-parameter transformer language model (SmolLM2-135M) with an ensemble of lightweight online predictors and a 32-bit arithmetic coder. Beyond the base LLM-plus-arithmetic-coding paradigm, Nacrith introduces several contributions: (1) a CDF precision upgrade from 2^16 to 2^24 that eliminates ~75% of quantization overhead caused by minimum-probability floors in large vocabularies; (2) a token-level N-gram model for fast local predictions; (3) an adaptive log-space bias head correcting per-document LLM errors via online gradient descent; (4) confidence-based LLM skip for accelerating highly predictable tokens; (5) a hybrid binary format (NC06) extending neural compression to arbitrary binary files--to our knowledge a first among LLM-based compressors; (6) a llama.cpp inference backend achieving ~7x faster single-token decode than PyTorch; (7) parallel multi-GPU compression across up to 8 workers; and (8) native KV cache sliding window reducing per-slide cost by ~37x. The system requires only ~500 MB of GGUF weights and ~1.2 GB VRAM per worker, running on consumer GPUs.
  On alice29.txt (Canterbury Corpus, 152 KB), Nacrith achieves 0.918 bits per byte (bpb)--outperforming gzip by 3.1x, bzip2 by 2.5x, CMIX v21 by 44%, and ts_zip by 20%, while compressing below the 0th-, 1st-, and 2nd-order byte-level Shannon entropy bounds. On enwik8 (100 MB), Nacrith achieves 0.9389 bpb (11.74%), surpassing ts_zip (~1.11 bpb) by 15% and FineZip (1.024 bpb) by 8% despite using a 60x smaller model with no fine-tuning. An out-of-distribution evaluation on a document published after the model's training cutoff confirms these gains are not memorization artifacts, achieving 0.723 bpb on unseen text.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19626v1</guid>
      <category>cs.IT</category>
      <category>cs.CL</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Tacconelli</dc:creator>
    </item>
    <item>
      <title>Secure Communications, Sensing, and Computing Towards Next-Generation Networks</title>
      <link>https://arxiv.org/abs/2602.19942</link>
      <description>arXiv:2602.19942v1 Announce Type: new 
Abstract: Next-generation wireless networks are progressing beyond conventional connectivity to incorporate emerging sensing and computing capabilities. This convergence gives rise to integrated systems that enable not only uninterrupted communication, but also environmental awareness, intelligent decision-making, and novel applications that take advantage of these combined features. At the same time, this integration brings substantial security challenges. As computing, sensing, and communication become more tightly intertwined, the overall complexity of the system increases, creating new vulnerabilities and expanding the attack surface. The widespread deployment of data-heavy artificial intelligence applications further amplifies concerns regarding data security and privacy. This paper presents a comprehensive survey of security and privacy threats, along with potential countermeasures, in integrated wireless systems. We first review physical-layer security techniques for communication networks, and then investigate the security and privacy implications of semantic and pragmatic communications and their associated cross-layer design methodologies. For sensing functionalities, we pinpoint security and privacy risks at the levels of signal sources, propagation channels, and sensing targets, and summarize state-of-the-art defense strategies for each. The growing computational requirements of these applications drive the need for distributed computing over the network, which introduces additional risks such as data leakage, weak authentication, and multiple points of failure. We subsequently discuss secure coded computing approaches that can help overcome several of these challenges. Finally, we introduce unified security frameworks tailored to integrated communication-sensing-computing architectures, offering an end-to-end perspective on protecting future wireless systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19942v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiqi Liu, Beixiong Zheng, Jemin Lee, Si-Hyeon Lee, Georges Kaddoum, Onur G\"unl\"u, Deniz G\"und\"uz</dc:creator>
    </item>
    <item>
      <title>Enormous Fluid Antenna Systems (E-FAS)--Part II: Channel Estimation</title>
      <link>https://arxiv.org/abs/2602.20127</link>
      <description>arXiv:2602.20127v1 Announce Type: new 
Abstract: Enormous fluid antenna systems (E-FAS) have recently emerged as a new wireless architecture in which intelligent metasurfaces act as guided electromagnetic interfaces, enabling surface-wave (SW) propagation with much lower attenuation and more control than conventional space-wave transmission. While prior work has reported substantial power gains under perfect channel state information (CSI), the impact of practical channel acquisition on E-FAS performance remains largely unexplored. This paper presents the first comprehensive analysis of E-FAS-assisted downlink transmission under pilot-based channel estimation. We develop an estimation framework for the equivalent end-to-end channel and derive closed-form expressions for the statistics of the minimum mean-square-error (MMSE) channel estimate and its estimation error. Building on these results, we analyze both single-user and multiuser operation while explicitly accounting for the training overhead. For the single-user case, we characterize the outage probability and achievable rate with imperfect CSI, and reveal an inherent signal-to-noise ratio (SNR) saturation phenomenon caused by residual self-interference. For the multiuser case, we study zero-forcing (ZF) precoding based on imperfect channel estimates and show that the system becomes interference-limited in the high SNR regime because of residual inter-user interference. Furthermore, we quantify the trade-off between spatial multiplexing gains and pilot overhead when the number of users increases. Analytical findings are validated via Monte Carlo simulations and benchmarked against least-squares (LS) estimation and conventional non-E-FAS transmission. The results reveal that despite CSI imperfections and training costs, E-FAS retains substantial performance advantages and provides robustness enabled by its amplified large-scale channel gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20127v1</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farshad Rostami Ghadi, Kai-Kit Wong, Masoud Kaveh, Hao Xu, Baiyang Liu, Kin-Fai Tong, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Asymptotic Semantic Collapse in Hierarchical Optimization</title>
      <link>https://arxiv.org/abs/2602.18450</link>
      <description>arXiv:2602.18450v1 Announce Type: cross 
Abstract: Multi-agent language systems can exhibit a failure mode where a shared dominant context progressively absorbs individual semantics, yielding near-uniform behavior across agents. We study this effect under the name Asymptotic Semantic Collapse in Hierarchical Optimization. In a closed linguistic setting with a Dominant Anchor Node whose semantic state has effectively infinite inertia, we show that repeated interactions with Peripheral Agent Nodes drive an asymptotic alignment that minimizes a global loss. We model semantic states as points on a Riemannian manifold and analyze the induced projection dynamics. Two consequences follow. First, the limiting semantic configuration is insensitive to the optimization history: both smooth gradient-style updates and stochastic noisy updates converge to the same topological endpoint, establishing path independence at convergence. Second, the degree of context dependence controls information content: moving from atomic (independent) representations to fully entangled (context-bound) representations forces the node entropy, interpreted as available degrees of freedom, to vanish in the limit. The theory connects information-theoretic quantities with differential-geometric structure and suggests an interpretation as an immutable consensus rule that constrains agents to a shared semantic grammar. A lightweight dataset-free benchmark on an RWKV-7 13B GGUF checkpoint complements the analysis, reporting zero hash collisions, mean compliance of 0.50 under greedy decoding and 0.531 under stochastic decoding, and final Jaccard-to-anchor similarity values of 0.295 and 0.224, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18450v1</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faruk Alpay, Bugra Kilictas</dc:creator>
    </item>
    <item>
      <title>Information-Guided Noise Allocation for Efficient Diffusion Training</title>
      <link>https://arxiv.org/abs/2602.18647</link>
      <description>arXiv:2602.18647v1 Announce Type: cross 
Abstract: Training diffusion models typically relies on manually tuned noise schedules, which can waste computation on weakly informative noise regions and limit transfer across datasets, resolutions, and representations. We revisit noise schedule allocation through an information-theoretic lens and propose the conditional entropy rate of the forward process as a theoretically grounded, data-dependent diagnostic for identifying suboptimal noise-level allocation in existing schedules. Based on these insight, we introduce InfoNoise, a principled data-adaptive training noise schedule that replaces heuristic schedule design with an information-guided noise sampling distribution derived from entropy-reduction rates estimated from denoising losses already computed during training. Across natural-image benchmarks, InfoNoise matches or surpasses tuned EDM-style schedules, in some cases with a substantial training speedup (about $1.4\times$ on CIFAR-10). On discrete datasets, where standard image-tuned schedules exhibit significant mismatch, it reaches superior quality in up to $3\times$ fewer training steps. Overall, InfoNoise makes noise scheduling data-adaptive, reducing the need for per-dataset schedule design as diffusion models expand across domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.18647v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel Raya, Bac Nguyen, Georgios Batzolis, Yuhta Takida, Dejan Stancevic, Naoki Murata, Chieh-Hsin Lai, Yuki Mitsufuji, Luca Ambrogioni</dc:creator>
    </item>
    <item>
      <title>Structural Analysis of Directional qLDPC Codes</title>
      <link>https://arxiv.org/abs/2602.19057</link>
      <description>arXiv:2602.19057v1 Announce Type: cross 
Abstract: Directional codes, recently introduced by Geh\'er--Byfield--Ruban \cite{Geher2025Directional}, constitute a hardware-motivated family of quantum low-density parity-check (qLDPC) codes. These codes are defined by stabilizers measured by ancilla qubits executing a fixed \emph{direction word} (route) on square- or hex-grid connectivity. In this work, we develop a comprehensive \emph{word-first} analysis framework for route-generated, translation-invariant CSS codes on rectangular tori. Under this framework, a direction word $W$ deterministically induces a finite support pattern $P(W)$, from which we analytically derive: (i)~a closed-form route-to-support map; (ii)~the odd-multiplicity difference lattice $L(W)$ that classifies commutation-compatible $X/Z$ layouts; and (iii)~conservative finite-torus admissibility criteria. Furthermore, we provide: (iv)~a rigorous word equivalence and canonicalization theory (incorporating dihedral lattice symmetries, reversal/inversion, and cyclic shifts) to enable symmetry-quotiented searches; (v)~an ``inverse problem'' criterion to determine when a translation-invariant support pattern is realizable by a single route, including reconstruction and non-realizability certificates; and (vi)~a quasi-cyclic (group-algebra) reduction for row-periodic layouts that explains the sensitivity of code dimension $k$ to boundary conditions. As a case study, we analyze the word $W=\texttt{NE$^2$NE$^2$N}$ end-to-end. We provide explicit stabilizer dependencies, commuting-operator motifs, and an exact criterion for dimension collapse on thin rectangles: for $(L_x, L_y) = (2d, d)$ with row alternation, we find $k=4$ if $6 \mid d$, and $k=0$ otherwise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19057v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Rowshan</dc:creator>
    </item>
    <item>
      <title>Strategic Gaussian Signaling under Linear Sensitivity Mismatch</title>
      <link>https://arxiv.org/abs/2602.19292</link>
      <description>arXiv:2602.19292v1 Announce Type: cross 
Abstract: This paper analyzes Stackelberg Gaussian signaling games under linear sensitivity mismatch, generalizing standard additive and constant-bias models. We characterize the Stackelberg equilibrium structure for both noiseless and noisy signaling regimes. In the noiseless case, we show that the encoder selectively reveals information along specific eigenspaces of a cost-mismatch matrix. We then extend the analysis to the noisy regime and derive analytical thresholds for the existence of informative equilibria, demonstrating a sharp phase transition where communication collapses into silence if the sensitivity mismatch is sufficiently high, in contrast with the fully revealing equilibria often found in constant-bias models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19292v1</guid>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hassan Mohamad, Vineeth Satheeskumar Varma, Samson Lasaulce</dc:creator>
    </item>
    <item>
      <title>From Asymptotic to Finite-Sample Minimax Robust Hypothesis Testing</title>
      <link>https://arxiv.org/abs/2602.19803</link>
      <description>arXiv:2602.19803v1 Announce Type: cross 
Abstract: This paper establishes a formal connection between finite-sample and asymptotically minimax robust hypothesis testing under distributional uncertainty. It is shown that, whenever a finite-sample minimax robust test exists, it coincides with the solution of the corresponding asymptotic minimax problem. This result enables the analytical derivation of finite-sample minimax robust tests using asymptotic theory, bypassing the need for heuristic constructions. The total variation distance and band model are examined as representative uncertainty classes. For each, the least favorable distributions and corresponding robust likelihood ratio functions are derived in parametric form. In the total variation case, the new derivation generalizes earlier results by allowing unequal robustness parameters. The theory also explains and systematizes previously heuristic designs. Simulations are provided to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.19803v1</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\"okhan G\"ul</dc:creator>
    </item>
    <item>
      <title>Dual Security for MIMO-OFDM ISAC Systems: Artificial Ghosts or Artificial Noise</title>
      <link>https://arxiv.org/abs/2602.20045</link>
      <description>arXiv:2602.20045v1 Announce Type: cross 
Abstract: Integrated sensing and communication (ISAC) enables the efficient sharing of wireless resources to support emerging applications, but it also gives rise to new sensing-based security vulnerabilities. Here, potential communication security threats whereby confidential messages intended for legitimate users are intercepted, but also unauthorized receivers (Eves) can passively exploit target echoes to infer sensing parameters without users being aware. Despite these risks, the joint protection of sensing and communication security in ISAC systems remains unexplored. To address this challenge, this paper proposes a two-layer dual-secure ISAC framework that simultaneously protects sensing and communication against passive sensing Eves and communication Eves, without requiring their channel state information (CSI). Specifically, transmit beamformers are jointly designed to inject artificial noise (AN) to introduce interference to communication Eves, while deliberately distorting the reference signal available to sensing Eves to impair their sensing capability. Furthermore, the proposed design generates artificial ghosts (AGs) with fake angle-range-velocity profiles observable by all receivers. Legitimate receivers can suppress these AGs, whereas sensing Eves cannot, thereby significantly reducing their probability of correctly detecting the true targets. Numerical results demonstrate that the proposed framework effectively enhances both communication and sensing security, while preserving the performance of communication users and legitimate sensing receivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20045v1</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinchao Yang, Prabhat Raj Gautam, Yathreb Bouazizi, Michael Breza, Julie McCann</dc:creator>
    </item>
    <item>
      <title>Adaptation to Intrinsic Dependence in Diffusion Language Models</title>
      <link>https://arxiv.org/abs/2602.20126</link>
      <description>arXiv:2602.20126v1 Announce Type: cross 
Abstract: Diffusion language models (DLMs) have recently emerged as a promising alternative to autoregressive (AR) approaches, enabling parallel token generation beyond a rigid left-to-right order. Despite growing empirical success, the theoretical understanding of how unmasking schedules -- which specify the order and size of unmasked tokens during sampling -- affect generation quality remains limited. In this work, we introduce a distribution-agnostic unmasking schedule for DLMs that adapts to the (unknown) dependence structure of the target data distribution, without requiring any prior knowledge or hyperparameter tuning. In contrast to prior deterministic procedures that fix unmasking sizes, our method randomizes the number of tokens revealed at each iteration. We show that, for two specific parameter choices, the sampling convergence guarantees -- measured by Kullback-Leibler (KL) divergence -- scale as $\widetilde O(\mathsf{TC}/K)$ and $\widetilde O(\mathsf{DTC}/K)$ respectively. Here, $K$ is the number of iterations, and $\mathsf{TC}$ and $\mathsf{DTC}$ are the total correlation and dual total correlation of the target distribution, capturing the intrinsic dependence structure underlying the data. Importantly, our guarantees hold in the practically relevant parallel-sampling regime $K&lt;L$ where $L$ is the token sequence length. These results significantly improve upon prior convergence theories and yield substantial sampling acceleration for low-complexity distributions. Overall, our findings unveil the adaptivity of DLMs to intrinsic data structures and shed light on the benefit of randomized unmasking sizes in inference schedule design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.20126v1</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunxiao Zhao, Changxiao Cai</dc:creator>
    </item>
    <item>
      <title>Quantum Soft Covering with Relative Entropy Criterion</title>
      <link>https://arxiv.org/abs/2402.11112</link>
      <description>arXiv:2402.11112v2 Announce Type: replace 
Abstract: In this work, we propose a soft covering problem for fully quantum channels using relative entropy as a criterion for operator closeness. We establish covering lemmas by deriving one-shot bounds on the achievable rates in terms of smooth min-entropies. In the asymptotic regime, we show that the infimum of the rate, defined as the logarithm of the minimum rank of the encoded input state, is given by the minimal coherent information between the reference and output systems that yields the target output state. Furthermore, we present a one-shot quantum decoupling theorem that also employs a relative-entropy criterion. Due to the Pinsker inequality, our one-shot results based on the relative-entropy criterion are tighter than the corresponding results based on the trace norm considered in the literature. In addition, we establish achievable error exponents and second-order rates for quantum soft covering under both trace-distance and relative-entropy criteria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11112v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>quant-ph</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyi He, S. Sandeep Pradhan</dc:creator>
    </item>
    <item>
      <title>On the Structure of Information</title>
      <link>https://arxiv.org/abs/2409.20331</link>
      <description>arXiv:2409.20331v3 Announce Type: replace 
Abstract: We characterize information as risk reduction between knowledge states represented by partitions of the underlying probability space. Entropy corresponds to risk reduction from no (or partial) knowledge to full knowledge about a random variable, while information corresponds to risk reduction from no (or partial) knowledge to partial knowledge. This applies to any information measure that is based on expected loss minimization, such as Bregman information, with Shannon information and variance as prominent examples. In each case, fundamental properties like the chain rule, non-negativity, and the relationship between information and divergence are preserved. Because partitions form a lattice under refinement, our general treatment reveals how information can be decomposed into redundant, unique, and synergistic contributions, a question important in applications from neuroscience to machine learning, yet one for which existing formulations lack consensus on foundational definitions and can violate basic properties such as the chain rule or non-negativity. Redundancy corresponds to Aumann's common knowledge, synergy to the gap between separately and jointly observed sources, and unique information is necessarily path-dependent, taking different values depending on what is already known. The resulting partial information decomposition is grounded directly in probability theory, avoids treating scalar information quantities as primitive compositional objects, yields non-negative terms by construction, and offers a more fine-grained credit assignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20331v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Gottwald, Daniel A. Braun</dc:creator>
    </item>
    <item>
      <title>Editable-DeepSC: Reliable Cross-Modal Semantic Communications for Facial Editing</title>
      <link>https://arxiv.org/abs/2411.15702</link>
      <description>arXiv:2411.15702v4 Announce Type: replace 
Abstract: Interactive computer vision (CV) plays a crucial role in various real-world applications, whose performance is highly dependent on communication networks. Nonetheless, the data-oriented characteristics of conventional communications often do not align with the special needs of interactive CV tasks. To alleviate this issue, the recently emerged semantic communications only transmit task-related semantic information and exhibit a promising landscape to address this problem. However, the communication challenges associated with Semantic Facial Editing, one of the most important interactive CV applications on social media, still remain largely unexplored. In this paper, we fill this gap by proposing Editable-DeepSC, a novel cross-modal semantic communication approach for facial editing. Firstly, we theoretically discuss different transmission schemes that separately handle communications and editings, and emphasize the necessity of Joint Editing-Channel Coding (JECC) via iterative attributes matching, which integrates editings into the communication chain to preserve more semantic mutual information. To compactly represent the high-dimensional data, we leverage inversion methods via pre-trained StyleGAN priors for semantic coding. To tackle the dynamic channel noise conditions, we propose SNR-aware channel coding via model fine-tuning. Extensive experiments indicate that Editable-DeepSC can achieve superior editings while significantly saving the transmission bandwidth, even under high-resolution and out-of-distribution (OOD) settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15702v4</guid>
      <category>cs.IT</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Chen, Wenbo Yu, Qinshan Zhang, Tianqu Zhuang, Hao Wu, Yong Jiang, Shu-Tao Xia</dc:creator>
    </item>
    <item>
      <title>Remote State Estimation over Unreliable Channels with Unreliable Feedback: Strategies and Limits</title>
      <link>https://arxiv.org/abs/2501.13192</link>
      <description>arXiv:2501.13192v2 Announce Type: replace 
Abstract: In this article, we establish a comprehensive theoretical framework for remote estimation in a networked system composed of a source that is observed by a sensor, a remote monitor that needs to estimate the state of the source in real time, and a communication channel that connects the source to the monitor. The source is a partially observable dynamical process, and the communication channel is a packet-erasure channel with feedback. We consider a novel communication model that captures implicit information. Our main objective is to identify the optimal strategies and the fundamental performance limits of the underlying system in the sense of a causal tradeoff between the packet rate and the mean square error when both forward and backward channels are unreliable. We characterise an optimal coding policy profile consisting of a scheduling policy for an encoder and an estimation policy for a decoder, collocated with the source and the monitor, respectively. We derive the recursive equations that must be solved online by the encoder and the decoder. In addition, we prove that the value function, originally defined over an expanding information set, admits a lower-dimensional representation depending only on two variables. We discuss the structural properties of the optimal policies, and analyse the computational complexity of an algorithm proposed for their computation. We then examine a range of special cases derived from our main theoretical results. We complement the theoretical results with a numerical analysis, and compare the performance of different remote estimation tasks in various operating regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13192v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Touraj Soleymani, Mohamad Assaad, John S. Baras</dc:creator>
    </item>
    <item>
      <title>From Bayesian Asymptotics to General Large-Scale MIMO Capacity</title>
      <link>https://arxiv.org/abs/2504.13325</link>
      <description>arXiv:2504.13325v3 Announce Type: replace 
Abstract: We present a unifying framework that bridges Bayesian asymptotics and information theory to analyze the asymptotic Shannon capacity of general large-scale MIMO channels including ones with nonlinearities or imperfect hardware. We derive both an analytic capacity formula and an asymptotically optimal input distribution in the large-antenna regime, each of which depends solely on the single-output channel's Fisher information through a term we call the (tilted) Jeffreys factor. We demonstrate how our method applies broadly to scenarios with clipping, coarse quantization (including 1-bit ADCs), phase noise, fading with imperfect CSI, and even optical Poisson channels. Our asymptotic analysis motivates a practical approach to constellation design via a compander-like transformation. Furthermore, we introduce a low-complexity receiver structure that approximates the log-likelihood by quantizing the channel outputs into finitely many bins, enabling near-capacity performance with computational complexity independent of the output dimension. Numerical results confirm that the proposed method unifies and simplifies many previously intractable MIMO capacity problems and reveals how the Fisher information alone governs the channel's asymptotic behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.13325v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sheng Yang, Richard Combes</dc:creator>
    </item>
    <item>
      <title>The Voronoi Spherical CDF for Lattices and Linear Codes: New Bounds for Quantization and Coding</title>
      <link>https://arxiv.org/abs/2506.19791</link>
      <description>arXiv:2506.19791v3 Announce Type: replace 
Abstract: For a lattice/linear code, we define the Voronoi spherical cumulative density function (CDF) as the CDF of the $\ell_2$-norm/Hamming weight of a random vector uniformly distributed over the Voronoi cell. Using the first moment method together with a simple application of Jensen's inequality, we develop lower bounds on the expected Voronoi spherical CDF of a random lattice/linear code. Our bounds are valid for any finite dimension and are quite close to a ball-based lower bound. They immediately translate to new non-asymptotic upper bounds on the normalized second moment and the error probability of a random lattice over the additive white Gaussian noise channel, as well as new non-asymptotic upper bounds on the Hamming distortion and the error probability of a random linear code over the binary symmetric channel. In particular, we show that for most lattices in $\mathbb{R}^n$ the second moment is greater than that of a Euclidean ball with the same covolume only by a $\left(1+O(\frac{1}{n})\right)$ multiplicative factor. Similarly, for most linear codes in $\mathbb{F}_2^n$ the expected Hamming distortion is greater than that of a corresponding Hamming ball only by an additive universal constant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19791v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.NT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Or Ordentlich</dc:creator>
    </item>
    <item>
      <title>Using nonassociative algebras to classify skew polycyclic codes up to isometry and equivalence</title>
      <link>https://arxiv.org/abs/2508.10139</link>
      <description>arXiv:2508.10139v3 Announce Type: replace 
Abstract: Employing isomorphisms between their ambient rings, we propose new definitions of equivalence and isometry for skew polycyclic codes that will lead to tighter classifications than existing ones. This reduces the number of previously known isometry and equivalence classes. In the process, we classify classes of skew $(f,\sigma,\delta)$-polycyclic codes with the same performance parameters, to avoid duplicating already existing codes, and state precisely when different notions of equivalence coincide. The generator of a skew polycyclic code is in one-one correspondence with the generator of a principal left ideal in its nonassociative unital ambient ring. By allowing the ambient rings to be nonassociative, we eliminate the need on restrictions on the length of the codes. Ring isomorphisms that preserve the Hamming distance (called isometries) map generators of principal left ideals to generators of principal left ideals and preserve length, dimension, and Hamming distance of the corresponding isometric skew polycyclic codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10139v3</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.RA</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Susanne Pumpluen</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Computation Offloading for Edge Inference: An Integrated Bayesian Optimization and Deep Reinforcement Learning Framework</title>
      <link>https://arxiv.org/abs/2509.21090</link>
      <description>arXiv:2509.21090v2 Announce Type: replace 
Abstract: Edge intelligence (EI) allows resource-constrained edge devices (EDs) to offload computation-intensive AI tasks (e.g., visual object detection) to edge servers (ESs) for fast execution. However, transmitting high-volume raw task data (e.g., 4K video) over bandwidth-limited wireless networks incurs significant latency. While EDs can reduce transmission latency by degrading data before transmission (e.g., reducing resolution from 4K to 720p or 480p), it often deteriorates inference accuracy, creating a critical accuracy-latency tradeoff. The difficulty in balancing this tradeoff stems from the absence of closed-form models capturing content-dependent accuracy-latency relationships. Besides, under bandwidth sharing constraints, the discrete degradation decisions among the EDs demonstrate inherent combinatorial complexity. Mathematically, it requires solving a challenging \textit{black-box} mixed-integer nonlinear programming (MINLP). To address this problem, we propose LAB, a novel learning framework that seamlessly integrates deep reinforcement learning (DRL) and Bayesian optimization (BO). Specifically, LAB employs: (a) a DNN-based actor that maps input system state to degradation actions, directly addressing the combinatorial complexity of the MINLP; and (b) a BO-based critic with an explicit model built from fitting a Gaussian process surrogate with historical observations, enabling model-based evaluation of degradation actions. For each selected action, optimal bandwidth allocation is then efficiently derived via convex optimization. Numerical evaluations on real-world self-driving datasets demonstrate that LAB achieves near-optimal accuracy-latency tradeoff, exhibiting only 1.22\% accuracy degradation and 0.07s added latency compared to exhaustive search... The complete source code for LAB is available at https://github.com/Ethan-Xian-Li/LAB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21090v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xian Li, Suzhi Bi, Ying-Jun Angela Zhang</dc:creator>
    </item>
    <item>
      <title>On the Limits of Self-Improving in Large Language Models: The Singularity Is Not Near Without Symbolic Model Synthesis</title>
      <link>https://arxiv.org/abs/2601.05280</link>
      <description>arXiv:2601.05280v2 Announce Type: replace 
Abstract: We formalise recursive self-training in Large Language Models (LLMs) and Generative AI as a discrete-time dynamical system. We prove that if the proportion of exogenous, externally grounded signal $\alpha_t$ vanishes asymptotically ($\alpha_t \to 0$), the system undergoes degenerative dynamics. We derive two fundamental failure modes: (1) \textit{Entropy Decay}, where finite sampling effects induce monotonic loss of distributional diversity, and (2) \textit{Variance Amplification}, where the absence of persistent grounding causes distributional drift via a random-walk mechanism. These behaviours are architectural invariants of distributional learning on finite samples. We show that the collapse results apply specifically to closed-loop density matching without persistent external signal. Systems with non-vanishing exogenous grounding fall outside this regime. However, mainstream Singularity, AGI, and ASI narratives typically posit systems that become increasingly autonomous and require little to no human or external intervention for self-improvement. In that autonomy regime, the vanishing-signal condition is satisfied, and collapse follows under KL-based objectives. To overcome these limits, we propose neurosymbolic integration based on algorithmic probability and program synthesis. The Coding Theorem Method (CTM) enables identification of generative mechanisms rather than mere correlations, escaping the distribution-only constraints that bind standard statistical learning. We conclude that fully autonomous recursive density matching leads to degenerative fixed points, whereas externally anchored or mechanism-based approaches operate under fundamentally different asymptotic dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05280v2</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hector Zenil</dc:creator>
    </item>
    <item>
      <title>Generalized Schalkwijk-Kailath Coding for Autoregressive Gaussian Channels</title>
      <link>https://arxiv.org/abs/2601.09329</link>
      <description>arXiv:2601.09329v2 Announce Type: replace 
Abstract: We propose a Gaussian random coding scheme for AR($p$) Gaussian channels that generalizes the celebrated Schalkwijk-Kailath (SK) coding scheme. This constructive coding scheme, termed the SK(2) coding scheme, yields a closed-form characterization for the corresponding achievable rate. Among many others, this result shows that the celebrated SK coding scheme is not universally optimal, and therefore, disprove the conjecture proposed by Butman in \cite{butman1976linear}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09329v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Su (Shitz), Guangyue Han (Shitz), Shlomo Shamai (Shitz)</dc:creator>
    </item>
    <item>
      <title>Identification capacity and rate-query tradeoffs in classification systems</title>
      <link>https://arxiv.org/abs/2601.14252</link>
      <description>arXiv:2601.14252v3 Announce Type: replace 
Abstract: We study zero-error class identification under constrained observations with three resources: tag rate $L$ (bits per entity), identification cost $W$ (attribute queries), and distortion $D$ (misidentification probability). We prove an information barrier: if the attribute-profile map $\pi$ is not injective on classes, then attribute-only observation cannot identify class identity with zero error. Let $A_\pi := \max_u |\{c : \pi(c)=u\}|$ be collision multiplicity. Any $D=0$ scheme must satisfy $L \ge \log_2 A_\pi$, and this bound is tight. In maximal-barrier domains ($A_\pi = k$), the nominal point $(L,W,D) = (\lceil \log_2 k \rceil, O(1), 0)$ is the unique Pareto-optimal zero-error point. Without tags ($L=0$), zero-error identification requires $W = \Omega(d)$ queries, where $d$ is the distinguishing dimension (worst case $d=n$, so $W=\Omega(n)$). Minimal sufficient query sets form the bases of a matroid, making $d$ well-defined and linking the model to zero-error source coding via graph entropy. We also state fixed-axis incompleteness: a fixed observation axis is complete only for axis-measurable properties. Results instantiate to databases, biology, typed software systems, and model registries, and are machine-checked in Lean 4 (6707 lines, 296 theorem/lemma statements, 0 sorry).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.14252v3</guid>
      <category>cs.IT</category>
      <category>cs.PL</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tristan Simas</dc:creator>
    </item>
    <item>
      <title>Double-Cover-Based Analysis of the Bethe Permanent of Block-Structured Positive Matrices</title>
      <link>https://arxiv.org/abs/2601.17508</link>
      <description>arXiv:2601.17508v2 Announce Type: replace 
Abstract: We consider the permanent of a square matrix with non-negative entries. A tractable approximation is given by the so-called Bethe permanent that can be efficiently computed by running the sum-product algorithm on a suitable factor graph. While the ratio of the permanent of a matrix to its Bethe permanent is, in the worst case, upper and lower bounded by expressions that are exponentially far apart in the matrix size, in practice it is observed for many ensembles of matrices of interest that this ratio is strongly concentrated around some value that depends only on the matrix size. In this paper, for an ensemble of block-structured matrices where entries in a block take the same value, we numerically study the ratio of the permanent of a matrix to its Bethe permanent. It is observed that also for this ensemble the ratio is strongly concentrated around some value depending only on a few key parameters of the ensemble. We use graph-cover-based approaches to explain the reasons for this behavior and to quantify the observed value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17508v2</guid>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binghong Wu, Pascal O. Vontobel</dc:creator>
    </item>
    <item>
      <title>Two-Stage Coded-Sliding Beam Training and QoS-Constrained Sum-Rate Maximization for SIM-Assisted Wireless Communications</title>
      <link>https://arxiv.org/abs/2602.02131</link>
      <description>arXiv:2602.02131v2 Announce Type: replace 
Abstract: Stacked intelligent metasurfaces (SIM) provide a cost-effective and scalable solution for large-scale antenna communications.However, efficient channel state information acquisition and phase shift optimization remain critical challenges. In this paper, we develop a unified framework of low-complexity algorithms for SIM-assisted communication systems to address these issues. Specifically, we propose a generalized two-step codebook construction (TSCC) method that leverages two-dimensional angular-domain decoupling to transform planar array beamformer design into two independent one-dimensional linear array beamformer design problems, efficiently solved via the Gerchberg-Saxton algorithm and our proposed majorization-minimization-based proximal distance (PDMM) algorithm. We further develop a two-stage coded-sliding beam training (TSCSBT) method for low-overhead and high-accuracy beam training, where error-correcting codes are embedded in the first-stage training to enhance robustness against noise, and sliding sampling is subsequently performed around the matched angular samples to improve angular resolution. The proposed framework is further extended to multi-path user channels. Finally, a variable decoupling-based block successive upper bound minimization (VD-BSUM) algorithm is proposed to directly solve the QoS-constrained sum-rate maximization problem through closed-form iterative updates with substantially reduced computational complexity. Simulation results demonstrate the effectiveness of the proposed methods in achieving precise beam pattern realization, improved beam training accuracy and angular resolution, and enhanced sum-rate performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02131v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Wireless Communications,2026</arxiv:journal_reference>
      <dc:creator>Qian Zhang, Ju Liu, Yao Ge, Yufei Zhao, Wali Ullah Khan, Zheng Dong, Yong Liang Guan, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>Isometric Invariant Quantification of Gaussian Divergence over Poincare Disc</title>
      <link>https://arxiv.org/abs/2602.17159</link>
      <description>arXiv:2602.17159v2 Announce Type: replace 
Abstract: The paper presents a geometric duality between the spherical squared-Hellinger distance and a hyperbolic isometric invariant of the Poincare disc under the action of the general Mobius group. Motivated by the geometric connection, we propose the usage of the L2-embedded hyperbolic isometric invariant as an alternative way to quantify divergence between Gaussian measures as a contribution to information theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17159v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Levent Ali Meng\"ut\"urk</dc:creator>
    </item>
    <item>
      <title>Flexible Coupler Array with Reconfigurable Pattern: Mechanical Beamforming and Digital Agent</title>
      <link>https://arxiv.org/abs/2602.17710</link>
      <description>arXiv:2602.17710v2 Announce Type: replace 
Abstract: Flexible coupler is a promising solution for enhancing wireless network capacity by moving passive couplers around a fixed-position active antenna to reshape the induced currents on passive elements. Motivated by this, this paper proposes a novel flexible coupler array that incorporates additional degrees of freedom (DoF) in radiation pattern reconfiguration and enhanced communication coverage with low hardware cost. Specifically, a new form of mechanical beamforming can be obtained by moving only the passive coupling elements while keeping the active antenna stationary. In addition, the flexible coupler antenna can slide along a rail toward users, thereby enhancing communication coverage. To fully exploit the potential of the flexible coupler array, we formulate a two-timescale sum-rate maximization problem with statistical channel state information (CSI). The antenna position is optimized based on scattering cluster-core statistics in the slow timescale, while mechanical beamforming is optimized based on multipath channel statistics in the fast timescale, subject to movement and energy constraints. To address the coupling between timescales and the high cost of extensive channel sampling, we develop a digital agent framework that leverages an electromagnetic (EM) map to generate statistical channel information for different user and antenna positions. Then, a deep neural network is trained to learn a slow-fast performance (SFP) surrogate. Mechanical beamforming at the fast timescale is obtained by selecting per-antenna radiation patterns from a predefined dictionary via a convex relaxation. Simulation results verify the performance gains achieved by the proposed flexible coupler array and the digital-agent-assisted algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.17710v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaodan Shao, Yixiao Zhang, Nan Cheng, Weihua Zhuang, Xuemin Shen</dc:creator>
    </item>
    <item>
      <title>Non-permutation phenomena in trivariate families over $\F_{2^m}$ and resolution of a conjecture</title>
      <link>https://arxiv.org/abs/2410.23097</link>
      <description>arXiv:2410.23097v2 Announce Type: replace-cross 
Abstract: Constructing permutation polynomials over finite fields, particularly those with simple algebraic structure in multiple variables, is a fundamental problem with applications in cryptography and coding theory. Recently, Li and Kaleyski (IEEE Trans. Inf. Theory, 2024) generalized two sporadic quadratic APN permutations into infinite families of trivariate functions. Motivated by their work, we investigate conditions under which generalized trivariate functions fail to be permutations. We establish necessary conditions on coefficient parameters that prevent the permutation property, provide a complete computational classification for small field extensions, and prove general non-permutation results. As a key application of our algebraic geometry approach, we resolve the permutation part of a conjecture by Beierle, Carlet, Leander, and Perrin (Finite Fields Appl., 2022) regarding a related trivariate form. Specifically, we prove that for all odd characteristic-2 extension degrees $m \geq 23$, their function $C_u$ is not a permutation over $\mathbb{F}_{2^m}^3$ for any $u \in \mathbb{F}_{2^m}^*$, resolving the permutation part of their conjecture for sufficiently large fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23097v2</guid>
      <category>math.NT</category>
      <category>cs.IT</category>
      <category>math.AG</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Bartoli, Mohit Pal, Pantelimon Stanica, Tommaso Toccotelli</dc:creator>
    </item>
    <item>
      <title>Efficient Approximate Degenerate Ordered Statistics Decoding for Quantum Codes via Reliable Subset Reduction</title>
      <link>https://arxiv.org/abs/2412.21118</link>
      <description>arXiv:2412.21118v4 Announce Type: replace-cross 
Abstract: Efficient and scalable decoding of quantum codes is essential for high-performance quantum error correction. In this work, we introduce Reliable Subset Reduction (RSR), a reliability-driven preprocessing framework that leverages belief propagation (BP) statistics to identify and remove highly reliable qubits, substantially reducing the effective problem size. Additionally, we identify a degeneracy condition that allows high-order OSD to be simplified to order-0 OSD. By integrating these techniques, we present an ADOSD algorithm that significantly improves OSD efficiency. Our BP+RSR+ADOSD framework extends naturally to circuit-level noise and can handle large-scale codes with more than $10^4$ error variables. Through extensive simulations, we demonstrate improved performance over MWPM and Localized Statistics Decoding for a variety of CSS and non-CSS codes under the code-capacity noise model, and for rotated surface codes under realistic circuit-level noise. At low physical error rates, RSR reduces the effective problem size to as little as 1\% (e.g., for $\epsilon=0.001$ in surface-code DEM), enabling higher-order OSD with drastically reduced computational complexity. These results highlight the practical efficiency and broad applicability of the BP+ADOSD framework for both theoretical and realistic quantum error correction scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.21118v4</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ching-Feng Kung, Kao-Yueh Kuo, Ching-Yi Lai</dc:creator>
    </item>
    <item>
      <title>Extended c-differential distinguishers of full 9 and reduced-round Kuznyechik cipher</title>
      <link>https://arxiv.org/abs/2507.02181</link>
      <description>arXiv:2507.02181v3 Announce Type: replace-cross 
Abstract: This paper introduces {\em truncated inner $c$-differential cryptanalysis}, a technique that enables the practical application of $c$-differential uniformity to block ciphers. While Ellingsen et al. (IEEE Trans. Inf. Theory, 2020) established the notion of $c$-differential uniformity by analyzing the equation $F(x\oplus a) \oplus cF(x) = b$, a key challenge remained: the outer multiplication by $c$ disrupts the structural properties essential for block cipher analysis, particularly key addition. We address this challenge by developing an \emph{inner} $c$-differential approach where multiplication by $c$ affects the input: $(F(cx\oplus a), F(x))$, thereby returning to the original idea of Borisov et al. (FSE, 2002). We prove that the inner $c$-differential uniformity of a function $F$ equals the outer $c$-differential uniformity of $F^{-1}$, establishing a duality between the two notions. This modification preserves cipher structure while enabling practical cryptanalytic applications.
  We apply our methodology to Kuznyechik (GOST R 34.12-2015) without initial key whitening. For reduced rounds, we construct explicit $c$-differential trails achieving probability $2^{-84.0}$ for two rounds and $2^{-169.7}$ for three rounds, representing improvements of 5.2 and 4.6 bits respectively over the best classical differential trails. For the full 9-round cipher, we develop a statistical truncated $c$-differential distinguisher. Through computational analysis involving millions of differential pairs, we identify configurations with bias ratios reaching $1.7\times$ and corrected p-values as low as $1.85 \times 10^{-3}$. The distinguisher requires data complexity $2^{33}$ chosen plaintext pairs, time complexity $2^{34}$, and memory complexity $2^{16}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02181v3</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pantelimon Stanica, Ranit Dutta, Bimal Mandal</dc:creator>
    </item>
    <item>
      <title>Approximation does not help in quantum unitary time-reversal</title>
      <link>https://arxiv.org/abs/2507.05736</link>
      <description>arXiv:2507.05736v4 Announce Type: replace-cross 
Abstract: Access to the time-reverse $U^{-1}$ of an unknown quantum unitary process $U$ is widely assumed in quantum learning, metrology, and many-body physics. The fundamental task of unitary time-reversal dictates implementing $U^{-1}$ to within diamond-norm error $\epsilon$ using black-box queries to the $d$-dimensional unitary $U$. Although the query complexity of this task has been extensively studied, existing lower bounds either hold only for the exact case (i.e., $\epsilon=0$) or are suboptimal in $d$. This raises a central question: does approximation help reduce the query complexity of unitary time-reversal? We settle this question in the negative by establishing a robust and tight lower bound $\Omega((1-\epsilon)d^2)$ with explicit dependence on the error $\epsilon$. This implies that unitary time-reversal retains optimal exponential hardness (in the number of qubits) even when constant error is allowed. Our bound applies to adaptive and coherent algorithms with unbounded ancillas and holds even when $\epsilon$ is an average-case distance error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05736v4</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kean Chen, Nengkun Yu, Zhicheng Zhang</dc:creator>
    </item>
    <item>
      <title>On Estimating the Quantum Tsallis Relative Entropy</title>
      <link>https://arxiv.org/abs/2510.00752</link>
      <description>arXiv:2510.00752v2 Announce Type: replace-cross 
Abstract: The relative entropy between quantum states quantifies their distinguishability. The estimation of certain relative entropies has been investigated in the literature, e.g., the von Neumann relative entropy and sandwiched R\'enyi relative entropy. In this paper, we present a comprehensive study of the estimation of the quantum Tsallis relative entropy. We show that for any constant $\alpha \in (0, 1)$, the $\alpha$-Tsallis relative entropy between two quantum states of rank $r$ can be estimated with sample complexity $\operatorname{poly}(r)$, which can be made more efficient if we know their state-preparation circuits. As an application, we obtain an approach to tolerant quantum state certification with respect to the quantum Hellinger distance with sample complexity $\widetilde{O}(r^{3.5})$, which exponentially outperforms the folklore approach based on quantum state tomography when $r$ is polynomial in the number of qubits. In addition, we show that the quantum state distinguishability problems with respect to the quantum $\alpha$-Tsallis relative entropy and quantum Hellinger distance are $\mathsf{QSZK}$-complete in a certain regime, and they are $\mathsf{BQP}$-complete in the low-rank case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.00752v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinge Bao, Minbo Gao, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>The Gravitational Aspect of Information: The Physical Reality of Asymmetric "Distance"</title>
      <link>https://arxiv.org/abs/2510.22664</link>
      <description>arXiv:2510.22664v4 Announce Type: replace-cross 
Abstract: We show that when a Brownian bridge is physically constrained to satisfy a canonical condition, its time evolution exactly coincides with an m-geodesic on the statistical manifold of Gaussian distributions. This identification provides a direct physical realization of a geometric concept in information geometry. It implies that purely random processes evolve along informationally straight trajectories, analogous to geodesics in general relativity. Our findings suggest that the asymmetry of informational ``distance" (divergence) plays a fundamental physical role, offering a concrete step toward an equivalence principle for information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.22664v4</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.IT</category>
      <category>gr-qc</category>
      <category>hep-ph</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>quant-ph</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomoi Koide, Armin van de Venn</dc:creator>
    </item>
    <item>
      <title>On the Classification of Dillon's APN Hexanomials</title>
      <link>https://arxiv.org/abs/2511.01003</link>
      <description>arXiv:2511.01003v3 Announce Type: replace-cross 
Abstract: We systematically analyze a class of hexanomial functions over finite fields of characteristic $2$ proposed by Dillon (2006) as candidates for almost perfect nonlinear (APN) functions, significantly extending earlier partial-APN results. For functions over $\mathbb{F}_{q^2}$, where $q=2^n$, of the form \[ F(x)=x(Ax^2+Bx^q+Cx^{2q})+x^2(Dx^q+Ex^{2q})+x^{3q}, \] we derive necessary conditions on the coefficients $A,B,C,D,E$ for APNness using algebraic number theory and algebraic-geometry methods over finite fields.
  Our main contribution is a comprehensive case-by-case analysis that excludes large classes of Dillon hexanomials via vanishing patterns of key coefficient polynomials. We identify algebraic obstructions -- including absolutely irreducible components of associated varieties and degree incompatibilities in polynomial factorizations -- that prevent these functions from attaining optimal differential uniformity. These results substantially narrow the search space for new APN functions in this family and provide a framework applicable to other APN candidates.
  We complement the theory with extensive computations: exhaustive searches over $\mathbb{F}_{2^2}$ and $\mathbb{F}_{2^4}$, and random sampling over $\mathbb{F}_{2^6}$ and $\mathbb{F}_{2^8}$, yielding hundreds of APN hexanomials. Complete CCZ-equivalence testing shows that, although many examples occur, they fall into few distinct classes. For $q\in\{2,4\}$, all examples are CCZ-equivalent to the Budaghyan--Carlet family, while in larger dimensions none appear equivalent to that family.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.01003v3</guid>
      <category>math.NT</category>
      <category>cs.IT</category>
      <category>math.AG</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniele Bartoli, Giovanni Giuseppe Grimaldi, Pantelimon Stanica</dc:creator>
    </item>
    <item>
      <title>High-Dimensional Asymptotics of Differentially Private PCA</title>
      <link>https://arxiv.org/abs/2511.07270</link>
      <description>arXiv:2511.07270v3 Announce Type: replace-cross 
Abstract: In differential privacy, random noise is introduced to privatize summary statistics of a sensitive dataset before releasing them. The noise level determines the privacy loss, which quantifies how easily an adversary can detect a target individual's presence in the dataset using the published statistic. Most privacy analyses provide upper bounds on the privacy loss. Sometimes, these bounds offer weak privacy guarantees unless the noise level is so high that it overwhelms the meaningful signal. It is unclear whether such high noise levels are necessary or a limitation of loose and pessimistic privacy bounds. This paper explores whether it is possible to obtain sharp privacy characterizations that determine the exact privacy loss of a mechanism on a given dataset. We study this problem in the context of differentially private principal component analysis (PCA), where the goal is to privatize the leading principal components of a dataset with $n$ samples and $p$ features. We analyze the exponential mechanism in a model-free setting and provide sharp utility and privacy characterizations in the high-dimensional limit ($p \rightarrow \infty$). We show that in high dimensions, detecting a target individual's presence using privatized PCs is exactly as hard as distinguishing between two Gaussians with slightly different means, where the mean difference depends on certain spectral properties of the dataset. Our analysis combines the hypothesis-testing formulation of privacy guarantees proposed by Dong, Roth, and Su (2022) with Le Cam's contiguity arguments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.07270v3</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Youngjoo Yun, Rishabh Dudeja</dc:creator>
    </item>
    <item>
      <title>MIST: Mutual Information Estimation Via Supervised Training</title>
      <link>https://arxiv.org/abs/2511.18945</link>
      <description>arXiv:2511.18945v3 Announce Type: replace-cross 
Abstract: We propose a fully data-driven approach to designing mutual information (MI) estimators. Since any MI estimator is a function of the observed sample from two random variables, we parameterize this function with a neural network (MIST) and train it end-to-end to predict MI values. Training is performed on a large meta-dataset of 625,000 synthetic joint distributions with known ground-truth MI. To handle variable sample sizes and dimensions, we employ a two-dimensional attention scheme ensuring permutation invariance across input samples. To quantify uncertainty, we optimize a quantile regression loss, enabling the estimator to approximate the sampling distribution of MI rather than return a single point estimate. This research program departs from prior work by taking a fully empirical route, trading universal theoretical guarantees for flexibility and efficiency. Empirically, the learned estimators largely outperform classical baselines across sample sizes and dimensions, including on joint distributions unseen during training. The resulting quantile-based intervals are well-calibrated and more reliable than bootstrap-based confidence intervals, while inference is orders of magnitude faster than existing neural baselines. Beyond immediate empirical gains, this framework yields trainable, fully differentiable estimators that can be embedded into larger learning pipelines. Moreover, exploiting MI's invariance to invertible transformations, meta-datasets can be adapted to arbitrary data modalities via normalizing flows, enabling flexible training for diverse target meta-distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.18945v3</guid>
      <category>cs.LG</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>German Gritsai, Megan Richards, Maxime M\'eloux, Kyunghyun Cho, Maxime Peyrard</dc:creator>
    </item>
    <item>
      <title>Strip-Symmetric Quantum Codes for Biased Noise: Z-Decoupling in Stabilizer and Floquet Codes</title>
      <link>https://arxiv.org/abs/2601.03623</link>
      <description>arXiv:2601.03623v2 Announce Type: replace-cross 
Abstract: Bias-tailored codes such as the XZZX surface code and the domain wall color code achieve high dephasing-biased thresholds because, in the infinite-bias limit, their $Z$ syndromes decouple into one-dimensional repetition-like chains; the $X^3Z^3$ Floquet code shows an analogous strip-wise structure for detector events in spacetime. We capture this common mechanism by defining strip-symmetric biased codes, a class of static stabilizer and dynamical (Floquet) codes for which, under pure dephasing and perfect measurements, each elementary $Z$ fault is confined to a strip and the Z-detector--fault incidence matrix is block diagonal. For such codes the Z-detector hypergraph decomposes into independent strip components and maximum-likelihood $Z$ decoding factorizes across strips, yielding complexity savings for matching-based decoders. We characterize strip symmetry via per-strip stabilizer products, viewed as a $\mathbb{Z}_2$ 1-form symmetry, place XZZX, the domain wall color code, and $X^3Z^3$ in this framework, and introduce synthetic strip-symmetric detector models and domain-wise Clifford constructions that serve as design tools for new bias-tailored Floquet codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03623v2</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Rowshan</dc:creator>
    </item>
    <item>
      <title>Contextuality from Single-State Ontological Models: An Information-Theoretic No-Go Theorem</title>
      <link>https://arxiv.org/abs/2602.16716</link>
      <description>arXiv:2602.16716v2 Announce Type: replace-cross 
Abstract: Contextuality is a central feature of quantum theory, traditionally understood as the impossibility of reproducing quantum measurement statistics using noncontextual ontological models. We consider classical ontological models constrained to reuse a single ontic state space across multiple interventions. We prove an information-theoretic no-go theorem showing that such models must incur an irreducible contextual information cost: contextual dependence cannot be fully mediated through the ontic state alone and requires additional contextual information beyond it. We provide a constructive example illustrating this obstruction and show that it arises solely from the requirement of ontic state reuse within a classical probability space. We further explain how quantum theory avoids this obstruction by relaxing the assumption that all measurement statistics arise from a single underlying classical ontic variable. These results identify contextuality as a fundamental information-theoretic constraint on classical ontological models and clarify its origin as a limitation on classical representations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.16716v2</guid>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 24 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Song-Ju Kim</dc:creator>
    </item>
  </channel>
</rss>
