<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 04:01:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Large-Scale Estimation under Unknown Heteroskedasticity</title>
      <link>https://arxiv.org/abs/2507.02293</link>
      <description>arXiv:2507.02293v1 Announce Type: new 
Abstract: This paper studies nonparametric empirical Bayes methods in a heterogeneous parameters framework that features unknown means and variances. We provide extended Tweedie's formulae that express the (infeasible) optimal estimators of heterogeneous parameters, such as unit-specific means or quantiles, in terms of the density of certain sufficient statistics. These are used to propose feasible versions with nearly parametric regret bounds of the order of $(\log n)^\kappa / n$. The estimators are employed in a study of teachers' value-added, where we find that allowing for heterogeneous variances across teachers is crucial for delivery optimal estimates of teacher quality and detecting low-performing teachers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02293v1</guid>
      <category>econ.EM</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sheng Chao Ho</dc:creator>
    </item>
    <item>
      <title>It's Hard to Be Normal: The Impact of Noise on Structure-agnostic Estimation</title>
      <link>https://arxiv.org/abs/2507.02275</link>
      <description>arXiv:2507.02275v1 Announce Type: cross 
Abstract: Structure-agnostic causal inference studies how well one can estimate a treatment effect given black-box machine learning estimates of nuisance functions (like the impact of confounders on treatment and outcomes). Here, we find that the answer depends in a surprising way on the distribution of the treatment noise. Focusing on the partially linear model of \citet{robinson1988root}, we first show that the widely adopted double machine learning (DML) estimator is minimax rate-optimal for Gaussian treatment noise, resolving an open problem of \citet{mackey2018orthogonal}. Meanwhile, for independent non-Gaussian treatment noise, we show that DML is always suboptimal by constructing new practical procedures with higher-order robustness to nuisance errors. These \emph{ACE} procedures use structure-agnostic cumulant estimators to achieve $r$-th order insensitivity to nuisance errors whenever the $(r+1)$-st treatment cumulant is non-zero. We complement these core results with novel minimax guarantees for binary treatments in the partially linear model. Finally, using synthetic demand estimation experiments, we demonstrate the practical benefits of our higher-order robust estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02275v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jikai Jin, Lester Mackey, Vasilis Syrgkanis</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Reinforcement Learning for Dynamic Pricing in Supply Chains: Benchmarking Strategic Agent Behaviours under Realistically Simulated Market Conditions</title>
      <link>https://arxiv.org/abs/2507.02698</link>
      <description>arXiv:2507.02698v1 Announce Type: cross 
Abstract: This study investigates how Multi-Agent Reinforcement Learning (MARL) can improve dynamic pricing strategies in supply chains, particularly in contexts where traditional ERP systems rely on static, rule-based approaches that overlook strategic interactions among market actors. While recent research has applied reinforcement learning to pricing, most implementations remain single-agent and fail to model the interdependent nature of real-world supply chains. This study addresses that gap by evaluating the performance of three MARL algorithms: MADDPG, MADQN, and QMIX against static rule-based baselines, within a simulated environment informed by real e-commerce transaction data and a LightGBM demand prediction model. Results show that rule-based agents achieve near-perfect fairness (Jain's Index: 0.9896) and the highest price stability (volatility: 0.024), but they fully lack competitive dynamics. Among MARL agents, MADQN exhibits the most aggressive pricing behaviour, with the highest volatility and the lowest fairness (0.5844). MADDPG provides a more balanced approach, supporting market competition (share volatility: 9.5 pp) while maintaining relatively high fairness (0.8819) and stable pricing. These findings suggest that MARL introduces emergent strategic behaviour not captured by static pricing rules and may inform future developments in dynamic pricing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02698v1</guid>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Hazenberg, Yao Ma, Seyed Sahand Mohammadi Ziabari, Marijn van Rijswijk</dc:creator>
    </item>
    <item>
      <title>Asymptotic Properties of the Maximum Likelihood Estimator for Markov-switching Observation-driven Models</title>
      <link>https://arxiv.org/abs/2412.19555</link>
      <description>arXiv:2412.19555v2 Announce Type: replace 
Abstract: A Markov-switching observation-driven model is a stochastic process $((S_t,Y_t))_{t \in \mathbb{Z}}$ where (i) $(S_t)_{t \in \mathbb{Z}}$ is an unobserved Markov process taking values in a finite set and (ii) $(Y_t)_{t \in \mathbb{Z}}$ is an observed process such that the conditional distribution of $Y_t$ given all past $Y$'s and the current and all past $S$'s depends only on all past $Y$'s and $S_t$. In this paper, we prove the consistency and asymptotic normality of the maximum likelihood estimator for such model. As a special case hereof, we give conditions under which the maximum likelihood estimator for the widely applied Markov-switching generalised autoregressive conditional heteroscedasticity model introduced by Haas et al. (2004b) is consistent and asymptotic normal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19555v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 04 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Krabbe</dc:creator>
    </item>
  </channel>
</rss>
