<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 14 Nov 2025 05:00:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Parallel and GPU accelerated code for phase-field and reaction-diffusion simulations</title>
      <link>https://arxiv.org/abs/2511.10508</link>
      <description>arXiv:2511.10508v1 Announce Type: new 
Abstract: We present SymPhas 2.0, a major update of the compile-time symbolic algebra simulation framework SymPhas for phase-field and reaction-diffusion models. This release introduces significant expansions and enhancements that enable the definition of a phase-field model directly from the free-energy functional via compile-time evaluated functional differentiation. It also introduces directional derivatives, symbolic summation, tensor-valued expressions, and compile-time derived finite difference stencils of arbitrary order and accuracy. Furthermore, the code has been parallelized for CPUs with MPI, and GPU computing has been added using CUDA (Compute Unified Device Architecture). For the latter, symbolic expressions are compiled into optimized CUDA kernels, allowing large-scale simulations to execute entirely on the GPU. For large systems ($32,768^2$ in 2D and $1,024^3$ in 3D with double precision), speedups up to $\sim \!\!1,000 \times$ were obtained compared to the first version of SymPhas using multi-threaded CPU execution on a single system. These developments establish SymPhas 2.0 as a flexible and scalable framework for efficient implementation of phase-field and reaction-diffusion models on GPU-based high-performance computing platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10508v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Steven A. Silber, Mikko Karttunen</dc:creator>
    </item>
    <item>
      <title>HeatGen: A Guided Diffusion Framework for Multiphysics Heat Sink Design Optimization</title>
      <link>https://arxiv.org/abs/2511.09578</link>
      <description>arXiv:2511.09578v1 Announce Type: cross 
Abstract: This study presents a generative optimization framework based on a guided denoising diffusion probabilistic model (DDPM) that leverages surrogate gradients to generate heat sink designs minimizing pressure drop while maintaining surface temperatures below a specified threshold. Geometries are represented using boundary representations of multiple fins, and a multi-fidelity approach is employed to generate training data. Using this dataset, along with vectors representing the boundary representation geometries, we train a denoising diffusion probabilistic model to generate heat sinks with characteristics consistent with those observed in the data. We train two different residual neural networks to predict the pressure drop and surface temperature for each geometry. We use the gradients of these surrogate models with respect to the design variables to guide the geometry generation process toward satisfying the low-pressure and surface temperature constraints. This inference-time guidance directs the generative process toward heat sink designs that not only prevent overheating but also achieve lower pressure drops compared to traditional optimization methods such as CMA-ES. In contrast to traditional black-box optimization approaches, our method is scalable, provided sufficient training data is available. Unlike traditional topology optimization methods, once the model is trained and the heat sink world model is saved, inference under new constraints (e.g., temperature) is computationally inexpensive and does not require retraining. Samples generated using the guided diffusion model achieve pressure drops up to 10 percent lower than the limits obtained by traditional black-box optimization methods. This work represents a step toward building a foundational generative model for electronics cooling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09578v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hadi Keramati, Morteza Sadeghi, Rajeev K. Jaiman</dc:creator>
    </item>
    <item>
      <title>Optimal Interpolation of Entanglement Purification Protocols</title>
      <link>https://arxiv.org/abs/2511.09657</link>
      <description>arXiv:2511.09657v1 Announce Type: cross 
Abstract: Bipartite entanglement purification is the conversion of copies of weakly entangled pairs shared between two separated parties into a smaller number of strongly entangled shared pairs using only local operations and classical communication. Choosing between different entanglement purification protocols generally involves weighing up a trade-off between the ratio of strongly entangled pairs produced to weakly entangled pairs consumed, which we call the rate of the protocol, and the degree of the entanglement of the strongly entangled pairs, typically measured by the fidelity of those pairs to maximally entangled states. By randomly choosing a protocol according to a probability distribution over a list of protocols for each pair we want to produce, we can achieve rates and fidelities not achieved by any of the original protocols. Here, we show how to choose this distribution to maximise the rate at which we produce qubit pairs with a given fidelity to a Bell state or, equivalently, to maximise the fidelity to a Bell state of the qubit pairs produced at a given rate. We investigate both the asymptotic case, where the number of initial pairs goes to infinity, and the finite-size regime, where protocols are restricted to a finite number of weakly entangled pairs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09657v1</guid>
      <category>quant-ph</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew Barber, Stefano Pirandola</dc:creator>
    </item>
    <item>
      <title>Constrained Shadow Tomography for Molecular Simulation on Quantum Devices</title>
      <link>https://arxiv.org/abs/2511.09717</link>
      <description>arXiv:2511.09717v1 Announce Type: cross 
Abstract: Quantum state tomography is a fundamental task in quantum information science, enabling detailed characterization of correlations, entanglement, and electronic structure in quantum systems. However, its exponential measurement and computational demands limit scalability, motivating efficient alternatives such as classical shadows, which enable accurate prediction of many observables from randomized measurements. In this work, we introduce a bi-objective semidefinite programming approach for constrained shadow tomography, designed to reconstruct the two-particle reduced density matrix (2-RDM) from noisy or incomplete shadow data. By integrating $N$-representability constraints and nuclear-norm regularization into the optimization, the method builds an $N$-representable 2-RDM that balances fidelity to the shadow measurements with energy minimization. This unified framework mitigates noise and sampling errors while enforcing physical consistency in the reconstructed states. Numerical and hardware results demonstrate that the approach significantly improves accuracy, noise resilience, and scalability, providing a robust foundation for physically consistent fermionic state reconstruction in realistic quantum simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09717v1</guid>
      <category>quant-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Irma Avdic, Yuchen Wang, Michael Rose, Lillian I. Payne Torres, Anna O. Schouten, Kevin J. Sung, David A. Mazziotti</dc:creator>
    </item>
    <item>
      <title>The Role of Deep Mesoscale Eddies in Ensemble Forecast Performance</title>
      <link>https://arxiv.org/abs/2511.09747</link>
      <description>arXiv:2511.09747v1 Announce Type: cross 
Abstract: Present forecasting efforts rely on assimilation of observational data captured in the upper ocean (&lt; 1000 m depth). These observations constrain the upper ocean and minimally influence the deep ocean. Nevertheless, development of the full water column circulation critically depends upon the dynamical interactions between upper and deep fields. Forecasts demonstrate that the initialization of the deep field is influential for the development and evolution of the surface in the forecast. Deep initial conditions that better agree with observations have lower upper ocean uncertainty as the forecast progresses. Here, best and worst ensemble members in two 92-day forecasts are identified and contrasted in order to determine how the deep ocean differs between these groups. The forecasts cover the duration of the Loop Current Eddy Thor separation event, which coincides with available deep observations in the Gulf. Model member performance is assessed by comparing surface variables against verifying analysis and satellite altimeter data during the forecast time-period. Deep cyclonic and anticyclonic features are reviewed, and compared against deep observations, indicating subtle differences in locations of deep eddies at relevant times. These results highlight both the importance of deep circulation in the dynamics of the Loop Current system and more broadly motivate efforts to assimilate deep observations to better constrain the deep initial fields and improve surface predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09747v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Cooke, Kathleen Donohue, Clark D Rowley, Prasad G Thoppil, D Randolph Watts</dc:creator>
    </item>
    <item>
      <title>Mitigating numerical dissipation in simulations of subsonic turbulent flows</title>
      <link>https://arxiv.org/abs/2511.09806</link>
      <description>arXiv:2511.09806v1 Announce Type: cross 
Abstract: Magnetohydrodynamic (MHD) simulations of subsonic (Mach number~$&lt;1$) turbulence are crucial to our understanding of several processes including oceanic and atmospheric flows, the amplification of magnetic fields in the early universe, accretion discs, and stratified flows in stars. In this work, we demonstrate that conventional numerical schemes are excessively dissipative in this low-Mach regime. We demonstrate that a new numerical scheme (termed `USM-BK' and implemented in the FLASH MHD code) reduces the dissipation of kinetic and magnetic energy, constrains the divergence of magnetic field to zero close to machine precision, and resolves smaller-scale structure than other, more conventional schemes, and hence, is the most accurate for simulations of low-Mach turbulent flows among the schemes compared in this work. We first compare several numerical schemes/solvers, including Split-Roe, Split-Bouchut, USM-Roe, USM-HLLC, USM-HLLD, and the new USM-BK, on a simple vortex problem. We then compare the schemes/solvers in simulations of the turbulent dynamo and show that the choice of scheme affects the growth rate, saturation level, and viscous and resistive dissipation scale of the dynamo. We also measure the numerical kinematic Reynolds number (Re) and magnetic Reynolds number (Rm) of our otherwise ideal MHD flows, and show that the new USM-BK scheme provides the highest Re and comparable Rm amongst all the schemes compared.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09806v1</guid>
      <category>physics.flu-dyn</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Watt, Christoph Federrath, Claudius Birke, Christian Klingenberg</dc:creator>
    </item>
    <item>
      <title>Data-driven modeling of multiscale phenomena with applications to fluid turbulence</title>
      <link>https://arxiv.org/abs/2511.09847</link>
      <description>arXiv:2511.09847v1 Announce Type: cross 
Abstract: This letter introduces a novel data driven framework for constructing accurate and general equivariant models of multiscale phenomena which does not rely on specific assumptions about the underlying physics. This framework is illustrated using incompressible fluid turbulence as an example that is representative, practically important, reasonably simple, and exceedingly well studied. We use direct numerical simulations of freely decaying turbulence in two spatial dimensions to infer an effective field theory comprising explicit, interpretable evolution equations for both the large (resolved) and small (modeled) scales. The resulting closed system of equations is capable of accurately describing the effect of small scales, including backscatter -- the flow of energy from small to large scales, which is particularly pronounced in two dimensions -- which is an outstanding challenge that, to our knowledge, no existing alternative successfully tackles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09847v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brandon Choi, Matteo Ugliotti, Mateo Reynoso, Daniel R. Gurevich, Roman O. Grigoriev</dc:creator>
    </item>
    <item>
      <title>Learning of Statistical Field Theories</title>
      <link>https://arxiv.org/abs/2511.09859</link>
      <description>arXiv:2511.09859v1 Announce Type: cross 
Abstract: Recovering microscopic couplings directly from data provides a route to solving the inverse problem in statistical field theories, one that complements the traditional-often computationally intractable-forward approach of predicting observables from an action or Hamiltonian. Here, we propose an approach for the inverse problem that uniformly accommodates systems with discrete, continuous, and hybrid variables. We demonstrate accurate parameter recovery in several benchmark systems-including Wegner's Ising gauge theory, $\phi^4$ theory, Schwinger and Sine-Gordon models, and mixed spin-gauge systems, and show how iterating the procedure under coarse-graining reconstructs full non-perturbative renormalization-group flows. This gives direct access to phase boundaries, fixed points, and emergent interactions without relying on perturbation theory. We also address a realistic setting where full gauge configurations may be unavailable, and reformulate learning algorithms for multiple field theories so that they are recovered directly using observables such as correlations from scattering data or quantum simulators. We anticipate that our methodology will find widespread use in practical learning of field theories in strongly coupled regimes where analytical tools might fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09859v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shreya Shukla, Abhijith Jayakumar, Andrey Y. Lokhov</dc:creator>
    </item>
    <item>
      <title>Quantum Period-Finding using One-Qubit Reduced Density Matrices</title>
      <link>https://arxiv.org/abs/2511.09896</link>
      <description>arXiv:2511.09896v1 Announce Type: cross 
Abstract: The quantum period-finding (QPF) algorithm can compute the period of a function exponentially faster than the best-known classical algorithm. In standard QPF, the output state has a primary contribution from $r$ high-probability bit strings, where $r$ is the period. Measurement of this state, combined with continued fraction analysis, reveals the unknown period. Here, we explore a different approach to QPF, where the period is obtained from single-qubit quantities $-$ specifically, the set of one-qubit reduced density matrices (1-RDMs) $-$ rather than the output bit strings of the entire quantum circuit. Using state-vector simulations, we compute the 1-RDMs of the QPF circuit for a generic periodic function. Analysis of these 1-RDMs as a function of period reveals distinctive patterns, which allows us to obtain the unknown period from the 1-RDMs using a numerical root-finding approach. Our results show that the 1-RDMs $-$ a set of $O(n)$ one-qubit marginals $-$ contain enough information to reconstruct the period, which is typically obtained by sampling the space of $O(2^n)$ bit strings. Conceptually, this can be viewed as a "compression" of the information in the QPF algorithm, which enables period-finding from $n$ one-qubit marginals. Our results motivate the development of approximate simulations of reduced density matrices to design novel period-finding algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09896v1</guid>
      <category>quant-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Bernardi</dc:creator>
    </item>
    <item>
      <title>SeQuant Framework for Symbolic and Numerical Tensor Algebra. I. Core Capabilities</title>
      <link>https://arxiv.org/abs/2511.09943</link>
      <description>arXiv:2511.09943v1 Announce Type: cross 
Abstract: SeQuant is an open-source library for symbolic algebra of tensors over commutative (scalar) and non-commutative (operator) rings. The key innovation supporting most of its functionality is a graph-theoretic tensor network (TN) canonicalizer that can handle tensor networks with symmetries faster than their standard group-theoretic counterparts. The TN canonicalizer is used for routine simplification of conventional tensor expressions, for optimizing application of Wick's theorem (used to canonicalize products of tensors over operator fields), and for manipulation of the intermediate representation leading to the numerical evaluation. Notable features of SeQuant include support for noncovariant tensor networks (which often arise from tensor decompositions) and for tensors with modes that depend parametrically on indices of other tensor modes (such dependencies between degrees of freedom are naturally viewed as nesting of tensors, "tensors of tensors" arising in block-wise data compressions in data science and modern quantum simulation). SeQuant blurs the line between pure symbolic manipulation/code generation and numerical evaluation by including compiler-like components to optimize and directly interpret tensor expressions using external numerical tensor algebra frameworks. The SeQuant source code is available at https://github.com/ValeevGroup/SeQuant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09943v1</guid>
      <category>cs.MS</category>
      <category>cs.SC</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bimal Gaudel, Robert G. Adam, Ajay Melekamburath, Conner Masteran, Nakul Teke, Azam Besharatnik, Andreas K\"ohn, Edward F. Valeev</dc:creator>
    </item>
    <item>
      <title>Tailored Three Dimensional Betatron Dynamics in UltraStable Hybrid Laser Plasma RF Accelerators</title>
      <link>https://arxiv.org/abs/2511.10096</link>
      <description>arXiv:2511.10096v1 Announce Type: cross 
Abstract: The detailed theoretical and numerical investigation of hybrid laser plasma RF accelerators, elucidating the mechanisms governing transverse beam dynamics, betatron polarization, and radiation reaction in ultra-relativistic electron bunches is presented. This framework combines analytical models of spatiotemporal plasma wakefield modulation, phase-dependent RF-driven oscillations, and quantum-corrected Landau Lifshitz radiation reaction with fully self-consistent 3D particle in cell simulations using EPOCH. The results demonstrate that RF amplitude, frequency, and phase enable precise control over transverse focusing strengths, betatron oscillation amplitudes, and polarization states. Resonant alignment between RF fields and natural betatron frequencies amplifies transverse excursions while damping parasitic oscillations through enhanced focusing gradients and radiation reaction, yielding reductions in emittance and mitigation of synchrotron-like energy losses. Stability maps and 3D force landscapes reveal strong phase sensitivity, where initial conditions and RF component ratios govern the temporal evolution of betatron amplitudes, and longitudinal field gradients modulate {\gamma} growth rates. These findings provide a comprehensive picture of nonlinear, resonant, and damping phenomena in hybrid laser plasma RF systems, highlighting the full spectrum of controllable transverse, longitudinal, and polarization dynamics in ultra relativistic electron beams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10096v1</guid>
      <category>physics.plasm-ph</category>
      <category>physics.acc-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>A. A. Molavi Choobini, M. Shahmansouri</dc:creator>
    </item>
    <item>
      <title>Effect of Concentration Fluctuations on Material Properties of Disordered Alloys</title>
      <link>https://arxiv.org/abs/2511.10259</link>
      <description>arXiv:2511.10259v1 Announce Type: cross 
Abstract: Alloying compound AX with another compound BX is widely used to tune material properties. For disordered alloys, due to the lack of periodicity, it has been challenging to calculate and study their material properties. Special quasi-random structure (SQS) method has been developed and widely used to treat this issue by matching averaged atomic correlation functions to those of ideal random alloys, enabling accurate predictions of macroscopic material properties such as total energy and volume. However, in AxB1-x alloys, statistically allowed local concentration fluctuations can give rise to defect-like minority configurations, such as bulk-like AX or BX regions in the extreme, which could strongly affect calculation of some of the material properties such as semiconductor bandgap, if it is not defined properly, leading to significant discrepancies between theory and experiment. In this work, taking the bandgap as an example, we demonstrate that the calculated alloy bandgap can be significantly underestimated in standard SQS calculations when the SQS cell size is increased to improve the structural model and the bandgap is defined conventionally as the energy difference between the lowest unoccupied state and the highest occupied state, because the rare event motifs can lead to wavefunction localization and become the dominant factor in determining the "bandgap", contrary to experiment. To be consistent with experiment, we show that the bandgap of the alloy should be extracted from the majority configurations using a density-of-states fitting (DOSF) method. This DOSF approach resolves the long-standing issue of calculating electronic structure of disordered semiconductor alloys. Similar approaches should also be developed to treat material properties that depends on localized alloy wavefunctions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10259v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han-Pu Liang, Chuan-Nan Li, Xin-Ru Tang, Xun Xu, Chen Qiu, Qiu-Shi Huang, Su-Huai Wei</dc:creator>
    </item>
    <item>
      <title>Regret, Uncertainty, and Bounded Rationality in Norm-Driven Decisions</title>
      <link>https://arxiv.org/abs/2511.10342</link>
      <description>arXiv:2511.10342v1 Announce Type: cross 
Abstract: This study introduces an agent-based model that explains how regret, uncertainty, and social norms interact to shape vaccination behavior during epidemics. The model integrates three behavioral mechanisms, anticipated regret, evolving norms, and uncertainty-dependent trust, within a unified learning framework. Grounded in psychology and behavioral economics, it captures how individuals make probabilistic choices influenced by material payoffs, fear, trust, and social approval. Simulations of the Susceptible-Infected-Recovered process show that collective outcomes are best when agents display an intermediate level of rationality; they deliberate enough to respond to risk but remain flexible enough to adapt, avoiding the instability of both random and overly rigid decision-making. Regret exerts a dual influence; moderate levels encourage adaptive self-correction, while excessive regret or greed destabilize choices. Uncertainty has a similarly non-linear effect; moderate ambiguity promotes caution, but too much uncertainty disrupts coordination. Social norms restore cooperation by compensating for incomplete information. Among them, personal norms drive behavior when individuals have clear information and moral confidence; injunctive norms, reflecting perceived approval, gain influence under uncertainty; and descriptive norms, based on observing others' actions, serve as informational cues that guide behavior when direct knowledge is limited. Overall, the model provides a psychologically grounded, computationally explicit account of how emotion, cognition, and social norms govern preventive behavior during epidemics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10342v1</guid>
      <category>physics.soc-ph</category>
      <category>nlin.AO</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christos Charalambous</dc:creator>
    </item>
    <item>
      <title>Are Foundational Atomistic Models Reliable for Finite-Temperature Molecular Dynamics?</title>
      <link>https://arxiv.org/abs/2503.08207</link>
      <description>arXiv:2503.08207v3 Announce Type: replace 
Abstract: Machine learning force fields have emerged as promising tools for molecular dynamics (MD) simulations, potentially offering quantum-mechanical accuracy with the efficiency of classical MD. Inspired by foundational large language models, recent years have seen considerable progress in developing foundational atomistic models, sometimes referred to as universal force fields, designed to cover most elements in the periodic table. This Perspective adopts a practitioner's viewpoint to ask a critical question: Are these foundational atomistic models reliable for one of their most compelling applications, in particular simulating finite-temperature dynamics? Instead of a broad benchmark, we use the canonical ferroelectric-paraelectric phase transition in PbTiO$_3$ as a focused case study to evaluate prominent foundational atomistic models. Our findings suggest a potential disconnect between static accuracy and dynamic reliability. While 0 K properties are often well-reproduced, we observed that the models can struggle to consistently capture the correct phase transition, sometimes exhibiting simulation instabilities. We believe these challenges may stem from inherent biases in training data and a limited description of anharmonicity. These observed shortcomings, though demonstrated on a single system, appear to point to broader, systemic challenges that can be addressed with targeted fine-tuning. This Perspective serves not to rank models, but to initiate a crucial discussion on the practical readiness of foundational atomistic models and to explore future directions for their improvement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08207v3</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denan Li, Jiyuan Yang, Xiangkai Chen, Lintao Yu, Shi Liu</dc:creator>
    </item>
    <item>
      <title>Improving the robustness of the immersed interface method through regularized velocity reconstruction</title>
      <link>https://arxiv.org/abs/2504.03929</link>
      <description>arXiv:2504.03929v3 Announce Type: replace 
Abstract: Robust, broadly applicable fluid-structure interaction (FSI) algorithms remain a challenge for computational mechanics. In previous work, we introduced an immersed interface method (IIM) for discrete surfaces and an extension based on an immersed Lagrangia-Eulerian (ILE) coupling strategy for modeling FSI involving complex geometries. The ability of the method to sharply resolve stress discontinuities induced by singular immersed boundary forces in the presence of low-regularity geometrical representations makes it a compelling choice for three-dimensional modeling of complex geometries in diverse engineering applications. Although the IIM we previously introduced offers many desirable advantages, it also imposes a restrictive mesh factor ratio, requiring the surface mesh to be coarser than the fluid grid to ensure stability. This is because when the mesh factor ratio constraint is not satisfied, parts of the structure motion are not controlled by the discrete FSI system. This constraint can significantly increase computational costs, particularly in applications involving multiscale geometries with highly localized complexity or fine-scale features. To address this limitation, we devise a stabilization strategy for the velocity restriction operator inspired by Tikhonov regularization. This study demonstrates that using a stabilized velocity restriction operator in IIM enables a broader range of structure-to-fluid grid-size ratios without compromising accuracy or altering the flow dynamics. This advancement significantly broadens the applicability of the method to real-world FSI problems involving complex geometries and dynamic conditions, offering a robust and practical solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03929v3</guid>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qi Sun, Ebrahim M. Kolahdouz, Boyce E. Griffith</dc:creator>
    </item>
    <item>
      <title>Regularized Fluctuating Lattice Boltzmann Model</title>
      <link>https://arxiv.org/abs/2507.08820</link>
      <description>arXiv:2507.08820v2 Announce Type: replace 
Abstract: We introduce a regularized fluctuating lattice Boltzmann model (Reg-FLBM) for the D3Q27 lattice, which incorporates thermal fluctuations through Hermite-based projections to ensure compliance with the fluctuation-dissipation theorem. By leveraging the recursive regularization framework, the model achieves thermodynamic consistency for both hydrodynamic and ghost modes. Compared to the conventional single-relaxation-time BGK-FLBM, the Reg-FLBM provides improved stability and a more accurate description of thermal fluctuations. The implementation is optimized for large-scale parallel simulations on GPU-accelerated architectures, enabling systematic investigation of fluctuation-driven phenomena in mesoscale and nanoscale fluid systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.08820v2</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0288232</arxiv:DOI>
      <arxiv:journal_reference>J. Chem. Phys. 163, 164102 (2025)</arxiv:journal_reference>
      <dc:creator>Marco Lauricella, Andrea Montessori, Adriano Tiribocchi, Sauro Succi</dc:creator>
    </item>
    <item>
      <title>Spectral methods for Neural Integral Equations</title>
      <link>https://arxiv.org/abs/2312.05654</link>
      <description>arXiv:2312.05654v4 Announce Type: replace-cross 
Abstract: Neural integral equations are deep learning models based on the theory of integral equations, where the model consists of an integral operator and the corresponding equation (of the second kind) which is learned through an optimization procedure. This approach allows to leverage the nonlocal properties of integral operators in machine learning, but it is computationally expensive. In this article, we introduce a framework for neural integral equations based on spectral methods that allows us to learn an operator in the spectral domain, resulting in a cheaper computational cost, as well as in high interpolation accuracy. We study the properties of our methods and show various theoretical guarantees regarding the approximation capabilities of the model, and convergence to solutions of the numerical methods. We provide numerical experiments to demonstrate the practical effectiveness of the resulting model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05654v4</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emanuele Zappala</dc:creator>
    </item>
    <item>
      <title>The Singlet-Triplet Gap of Cyclobutadiene: The CIPSI-Driven CC($P$;$Q$) Study</title>
      <link>https://arxiv.org/abs/2405.15864</link>
      <description>arXiv:2405.15864v2 Announce Type: replace-cross 
Abstract: An accurate determination of singlet-triplet gaps in biradicals, including cyclobutadiene in the automerization barrier region where one has to balance the substantial nondynamical many-electron correlation effects characterizing the singlet ground state with the predominantly dynamical correlations of the lowest-energy triplet, remains a challenge for many quantum chemistry methods. High-level coupled-cluster (CC) approaches, such as the CC method with a full treatment of singly, doubly, and triply excited clusters (CCSDT), are often capable of providing reliable results, but the routine application of such methods is hindered by their high computational costs. We have recently proposed a practical alternative to converging the CCSDT energetics at small fractions of the computational effort, even when electron correlations become stronger and connected triply excited clusters are larger and nonperturbative, by merging the CC($P$;$Q$) moment expansions with the selected configuration interaction methodology abbreviated as CIPSI. We demonstrate that one can accurately approximate the highly accurate CCSDT potential surfaces characterizing the lowest singlet and triplet states of cyclobutadiene along the automerization coordinate and the gap between them using tiny fractions of triply excited cluster amplitudes identified with the help of relatively inexpensive CIPSI Hamiltonian diagonalizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15864v2</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Swati S. Priyadarsini, Karthik Gururangan, Jun Shen, Piotr Piecuch</dc:creator>
    </item>
    <item>
      <title>LeapFrog: Getting the Jump on Multi-Scale Materials Simulations Using Machine Learning</title>
      <link>https://arxiv.org/abs/2406.15326</link>
      <description>arXiv:2406.15326v3 Announce Type: replace-cross 
Abstract: The development of novel materials in recent years has been accelerated greatly by the use of computational modelling techniques aimed at elucidating the complex physics controlling microstructure formation in materials, the properties of which control material function. One such technique is the phase field method, a field theoretic approach that couples various thermophysical fields to microscopic order parameter fields that track the phases of microstructure. Phase field models are framed as multiple, non-linear, partial differential equations, which are extremely challenging to compute efficiently. Recent years have seen an explosion of computational algorithms aimed at enhancing the efficiency of phase field simulations. One such technique, adaptive mesh refinement (AMR), dynamically adapts numerical meshes to be highly refined around steep spatial gradients of the PDE fields and coarser where the fields are smooth. This reduces the number of computations per time step significantly, thus reducing the total time of computation. What AMR doesn't do is allow for adaptive time stepping. This work combines AMR with a neural network algorithm that uses a U-Net with a Convolutional Long-Short Term Memory (CLSTM) base to accelerate phase field simulations. Our neural network algorithm is described in detail and tested in on simulations of directional solidification of a dilute binary alloy, a paradigm that is highly practical for its relevance to the solidification of alloys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.15326v3</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Damien Pinto, Michael Greenwood, Nikolas Provatas</dc:creator>
    </item>
    <item>
      <title>Non-Hermitian Quantum Mechanics Approach for Extracting and Emulating Continuum Physics Based on Bound-State-Like Calculations</title>
      <link>https://arxiv.org/abs/2408.03309</link>
      <description>arXiv:2408.03309v2 Announce Type: replace-cross 
Abstract: This work introduces a unified emulation framework for studying continuum physics in finite quantum systems. Using a reduced basis method, we construct powerful emulators for the inhomogeneous Schr\"{o}dinger equation that operate in a combined parameter space of complex energy ($E$) and other inputs ($\bm{\theta}$). Within the space, the emulators simultaneously perform analytical continuation in $E$ -- extracting continuum physics from numerically simpler bound-state-like calculations -- and interpolate this entire process across $\bm{\theta}$. This yields a small, non-Hermitian system whose properties (e.g., resonances and scattering observables) can be rapidly predicted for any $\bm{\theta}$. Crucially, the complex-$E$ emulation provides a pathway to compute continuum observables for complex systems where advanced bound-state methods exist but direct continuum calculations are yet to be developed, while the $\bm{\theta}$-emulation enables rapid parameter-space exploration and can be adapted to accelerate other existing continuum calculations. Demonstrations with two- and three-body systems highlight the method's effectiveness and suggest its connection to (near-)optimal rational approximation. This Letter presents the key results, with further details reserved for a companion paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03309v2</guid>
      <category>nucl-th</category>
      <category>hep-ph</category>
      <category>physics.atom-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/5frj-w5xh</arxiv:DOI>
      <dc:creator>Xilin Zhang</dc:creator>
    </item>
    <item>
      <title>Non-Hermitian quantum mechanics approach for extracting and emulating continuum physics based on bound-state-like calculations: Detailed description</title>
      <link>https://arxiv.org/abs/2411.06712</link>
      <description>arXiv:2411.06712v2 Announce Type: replace-cross 
Abstract: This work applies a reduced basis method to study the continuum physics of a finite quantum system -- either few or many-body. Specifically, I develop reduced-order models, or emulators, for the underlying inhomogeneous Schr\"{o}dinger equation and train the emulators against the equation's bound-state-like solutions at complex energies. The emulators rapidly and accurately interpolate and extrapolate the matrix elements of the Hamiltonian resolvent operator (Green's function) across a parameter space that includes both complex energy and other real-valued physical inputs in the Schr\"{o}dinger equation. The spectra, discretized and compressed as the result of emulation, and the associated resolvent matrix elements (or amplitudes), have the defining characteristics of non-Hermitian quantum mechanics calculations, featuring complex eigenenergies with negative imaginary parts and branch cuts moved below the real axis in the complex energy plane. Therefore, one now has a method that extracts continuum physics from bound-state-like calculations and emulates those extractions in the input parameter space. Building on a prior Letter [\href{https://arxiv.org/abs/2408.03309}{[arXiv:2408.03309}], this article provides the full theoretical details, a comprehensive analysis of the method's performance, and a brief discussion of how it can be coupled with existing continuum approaches to perform emulations in their input parameter spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06712v2</guid>
      <category>nucl-th</category>
      <category>hep-ph</category>
      <category>physics.atom-ph</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1103/4wbf-gzk5</arxiv:DOI>
      <dc:creator>Xilin Zhang</dc:creator>
    </item>
    <item>
      <title>High-level, high-resolution ocean modeling at all scales with Oceananigans</title>
      <link>https://arxiv.org/abs/2502.14148</link>
      <description>arXiv:2502.14148v2 Announce Type: replace-cross 
Abstract: We describe the user interface, governing equations, and numerical methods underpinning the community ocean modeling software called "Oceananigans". Oceananigans development has been lead by the Climate Modeling Alliance to build a trainable climate model with quantifiable uncertainty. Oceananigans is written in the Julia programming language, which, like similar recent efforts based on modern programming languages, distinguishes it from usual software based on Fortran. Oceananigans can efficiently simulate all scales of ocean motion, ranging from millimeter-scale turbulence in a small box to planetary-scale ocean circulation. Oceananigans design combines (i) a basic structured finite volume algorithm (ii) optimized for high-resolution simulations on GPUs which is (iii) exposed behind a high-level, programmable user interface. This design negotiates a dual mandate for highest-possible performance (to support state-of-the-art applications) and enhanced accessibility (to facilitate adoption and development). The dual mandate aims ultimately to accelerate the progress of Earth system science. Achieving this aim, however, requires a substantial and sustained increase in the collective effort of Oceananigans development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.14148v2</guid>
      <category>physics.ao-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.flu-dyn</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory L. Wagner, Simone Silvestri, Navid C. Constantinou, Ali Ramadhan, Jean-Michel Campin, Chris Hill, Tomas Chor, Jago Strong-Wright, Xin Kai Lee, Francis Poulin, Andre Souza, Keaton J. Burns, Siddhartha Bishnu, John Marshall, Raffaele Ferrari</dc:creator>
    </item>
    <item>
      <title>ELECTRA: A Cartesian Network for 3D Charge Density Prediction with Floating Orbitals</title>
      <link>https://arxiv.org/abs/2503.08305</link>
      <description>arXiv:2503.08305v3 Announce Type: replace-cross 
Abstract: We present the Electronic Tensor Reconstruction Algorithm (ELECTRA) - an equivariant model for predicting electronic charge densities using floating orbitals. Floating orbitals are a long-standing concept in the quantum chemistry community that promises more compact and accurate representations by placing orbitals freely in space, as opposed to centering all orbitals at the position of atoms. Finding the ideal placement of these orbitals requires extensive domain knowledge, though, which thus far has prevented widespread adoption. We solve this in a data-driven manner by training a Cartesian tensor network to predict the orbital positions along with orbital coefficients. This is made possible through a symmetry-breaking mechanism that is used to learn position displacements with lower symmetry than the input molecule while preserving the rotation equivariance of the charge density itself. Inspired by recent successes of Gaussian Splatting in representing densities in space, we are using Gaussian orbitals and predicting their weights and covariance matrices. Our method achieves a state-of-the-art balance between computational efficiency and predictive accuracy on established benchmarks. Furthermore, ELECTRA is able to lower the compute time required to arrive at converged DFT solutions - initializing calculations using our predicted densities yields an average 50.72 \% reduction in self-consistent field (SCF) iterations on unseen molecules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08305v3</guid>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Elsborg, Luca Thiede, Al\'an Aspuru-Guzik, Tejs Vegge, Arghya Bhowmik</dc:creator>
    </item>
    <item>
      <title>Efficient Berry Phase Calculation via Adaptive Variational Quantum Computing Approach</title>
      <link>https://arxiv.org/abs/2506.19150</link>
      <description>arXiv:2506.19150v2 Announce Type: replace-cross 
Abstract: We present an adaptive variational quantum algorithm to estimate the Berry phase accumulated by a nondegenerate ground state under cyclic, adiabatic evolution of a time-dependent Hamiltonian. Our method leverages cyclic adiabatic evolution of the Hamiltonian and employs adaptive variational quantum algorithms for state preparation and evolution, optimizing circuit efficiency while maintaining high accuracy. We benchmark our approach on dimerized Fermi-Hubbard chains with four sites, demonstrating precise Berry phase simulations in both noninteracting and interacting regimes. Our results show that circuit depths reach up to 106 layers for noninteracting systems and increase to 279 layers for interacting systems due to added complexity. Additionally, we demonstrate the robustness of our scheme across a wide range of parameters governing adiabatic evolution and variational algorithm. These findings highlight the potential of adaptive variational quantum algorithms for advancing quantum simulations of topological materials and computing geometric phases in strongly correlated systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19150v2</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Mootz, Yong-Xin Yao</dc:creator>
    </item>
    <item>
      <title>More sophisticated is not always better: comparison of similarity measures for unsupervised learning of pathways in biomolecular simulations</title>
      <link>https://arxiv.org/abs/2507.01725</link>
      <description>arXiv:2507.01725v3 Announce Type: replace-cross 
Abstract: Finding process pathways in molecular simulations such as the unbinding paths of small molecule ligands from their binding sites at protein targets in a set of trajectories via unsupervised learning approaches requires the definition of a suitable similarity measure between trajectories. We here evaluate the performance of four such measures with varying degree of sophistication, i.e., Euclidean and Wasserstein distances, Procrustes analysis and dynamical time warping, when analyzing trajectory data from two different biased simulation driving protocols in the form of constant velocity constraint targeted MD and steered MD. In a streptavidin-biotin benchmark system with known ground truth clusters, Wasserstein distances yielded the best clustering performance, closely followed by Euclidean distances, both being the most computationally efficient similarity measures. In a more complex A2a receptor-inhibitor system, however, the simplest measure, i.e., Euclidean distances, was sufficient to reveal meaningful and interpretable clusters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01725v3</guid>
      <category>cond-mat.soft</category>
      <category>physics.bio-ph</category>
      <category>physics.comp-ph</category>
      <category>q-bio.BM</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1021/acs.jpcb.5c04586</arxiv:DOI>
      <arxiv:journal_reference>J\"ager, M., Wolf, S. More sophisticated is not always better: comparison of similarity measures for unsupervised learning of pathways in biomolecular simulations. J. Phys. Chem. B 2025, 129, 42, 10956-10966</arxiv:journal_reference>
      <dc:creator>Miriam J\"ager, Steffen Wolf</dc:creator>
    </item>
    <item>
      <title>Surrogate Quantum Circuit Design for the Lattice Boltzmann Collision Operator</title>
      <link>https://arxiv.org/abs/2507.12256</link>
      <description>arXiv:2507.12256v2 Announce Type: replace-cross 
Abstract: This study introduces a framework for learning a low-depth surrogate quantum circuit (SQC) that approximates the nonlinear, dissipative, and hence non-unitary Bhatnagar-Gross-Krook (BGK) collision operator in the lattice Boltzmann method (LBM) for the D2Q9 lattice. By appropriately selecting the quantum state encoding, circuit architecture, and measurement protocol, non-unitary dynamics emerge naturally within the physical population space. This approach removes the need for probabilistic algorithms relying on any ancilla qubits and post-selection to reproduce dissipation, or for multiple state copies to capture nonlinearity. The SQC is designed to preserve key physical properties of the BGK operator, including mass conservation, scale equivariance, and D8 equivariance, while momentum conservation is encouraged through penalization in the training loss. When compiled to the IBM Heron quantum processor's native gate set, assuming all-to-all qubit connectivity, the circuit requires only 724 native gates and operates locally on the velocity register, making it independent of the lattice size. The learned SQC is validated on two benchmark cases, the Taylor-Green vortex decay and the lid-driven cavity, showing accurate reproduction of vortex decay and flow recirculation. While integration of the SQC into a quantum LBM framework presently requires measurement and re-initialization at each timestep, the necessary steps towards a measurement-free formulation are outlined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12256v2</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Fri, 14 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Monica L\u{a}c\u{a}tu\c{s}, Matthias M\"oller</dc:creator>
    </item>
  </channel>
</rss>
