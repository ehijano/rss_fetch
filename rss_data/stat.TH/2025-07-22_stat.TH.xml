<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 23 Jul 2025 01:40:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Identifiability in Unlinked Linear Regression: Some Results and Open Problems</title>
      <link>https://arxiv.org/abs/2507.14986</link>
      <description>arXiv:2507.14986v1 Announce Type: new 
Abstract: A tacit assumption in classical linear regression problems is the full knowledge of the existing link between the covariates and responses. In Unlinked Linear Regression (ULR) this link is either partially or completely missing. While the reasons causing such missingness can be different, a common challenge in statistical inference is the potential non-identifiability of the regression parameter. In this note, we review the existing literature on identifiability when the $d \ge 2$ components of the vector of covariates are independent and identically distributed. When these components have different distributions, we show that it is not possible to prove similar theorems in the general case. Nevertheless, we prove some identifiability results, either under additional parametric assumptions for $d \ge 2$ or conditions on the fourth moments in the case $d=2$. Finally, we draw some interesting connections between the ULR and the well established field of Independent Component Analysis (ICA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14986v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fadoua Balabdaoui, Martin Slawski, Jonathan Steffani</dc:creator>
    </item>
    <item>
      <title>Unbiased Estimation in One-Parameter Exponential Families of the Natural Parameter with Extensions</title>
      <link>https://arxiv.org/abs/2507.15077</link>
      <description>arXiv:2507.15077v1 Announce Type: new 
Abstract: For one-parameter continuous exponential families, we identify an unbiased estimator of the inverse of the natural parameter $\theta$ for cases where $\theta &gt; 0$, extending an earlier result of \cite{voinov1985unbiased} applicable to a normal model. We provide various applications for Gamma models, Inverse Gaussian models, distributions obtained by truncation, and ratios of normal means. Moreover, we extend the findings to estimating negative powers $\theta^{-k}$, and more generally to complete monotone functions $q(\theta)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15077v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pankaj Bhagwat, Eric Marchand</dc:creator>
    </item>
    <item>
      <title>Eigenvalue distribution of some random matrices</title>
      <link>https://arxiv.org/abs/2507.15342</link>
      <description>arXiv:2507.15342v1 Announce Type: new 
Abstract: In this paper, we investigate the eigenvalue distribution of a class of kernel random matrices whose $(i,j)$-th entry is $f(X_i,X_j)$ where $f$ is a symmetric function belonging to the Paley-Wiener space $\mathcal{B}_c$ and $(X_i)_{1\leq i \leq N}$ are i.i.d. random variables.
  We rigorously prove that, with high probability, the eigenvalues of these random matrices are well approximated by those of an underlying estimator.
  A particularly notable case is when $f=sinc$ , which has been widely studied due to its relevance in various scientific fields, including machine learning and telecommunications.
  In this case, we push forward the general approach by computing the eigenvalues of the estimator. More precisely, we have proved that the eigenvalues are concentrated around zero and one. In particular, we address the case of large values of $c$ with respect to the matrix size $N$, which, to the best of our knowledge, has not been studied in the literature. Furthermore, we establish that the frequency of eigenvalues close to one is proportional to $c$. Numerical results are provided in order to illustrate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15342v1</guid>
      <category>math.ST</category>
      <category>math.CA</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jebalia Mohamed, Ahmed Souabni</dc:creator>
    </item>
    <item>
      <title>Assessing continuous common-shock risk through matrix distributions</title>
      <link>https://arxiv.org/abs/2507.15637</link>
      <description>arXiv:2507.15637v1 Announce Type: new 
Abstract: We introduce a class of continuous-time bivariate phase-type distributions for modeling dependencies from common shocks. The construction uses continuous-time Markov processes that evolve identically until an internal common-shock event, after which they diverge into independent processes. We derive and analyze key risk measures for this new class, including joint cumulative distribution functions, dependence measures, and conditional risk measures. Theoretical results establish analytically tractable properties of the model. For parameter estimation, we employ efficient gradient-based methods. Applications to both simulated and real-world data illustrate the ability to capture common-shock dependencies effectively. Our analysis also demonstrates that CSPH distributions may capture dependencies that extend beyond those explicitly triggered by common shocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15637v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Bladt, Oscar Peralta, Jorge Yslas</dc:creator>
    </item>
    <item>
      <title>Online survival analysis with quantile regression</title>
      <link>https://arxiv.org/abs/2507.15696</link>
      <description>arXiv:2507.15696v1 Announce Type: new 
Abstract: We propose an online inference method for censored quantile regression with streaming data sets. A key strategy is to approximate the martingale-based unsmooth objective function with a quadratic loss function involving a well-justified second-order expansion. This enables us to derive a new online convex function based on the current data batch and summary statistics of historical data, thereby achieving online updating and occupying low storage space. To estimate the regression parameters, we design a novel majorize-minimize algorithm by reasonably constructing a quadratic surrogate objective function, which renders a closed-form parameter update and thus reduces the computational burden notably. Theoretically, compared to the oracle estimators derived from analyzing the entire raw data once, we posit a weaker assumption on the quantile grid size and show that the proposed online estimators can maintain the same convergence rate and statistical efficiency. Simulation studies and an application demonstrate the satisfactory empirical performance and practical utilities of the proposed online method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15696v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Deng, Shuwei Li, Liuquan Sun, Baoxue Zhang</dc:creator>
    </item>
    <item>
      <title>Robust and Smooth Estimation of the Extreme Tail Index via Weighted Minimum Density Power Divergence</title>
      <link>https://arxiv.org/abs/2507.15744</link>
      <description>arXiv:2507.15744v1 Announce Type: new 
Abstract: By introducing a weight function into the density power divergence, we develop a new class of robust and smooth estimators for the tail index of Pareto-type distributions, offering improved efficiency in the presence of outliers. These estimators can be viewed as a robust generalization of both weighted least squares and kernel-based tail index estimators. We establish the consistency and asymptotic normality of the proposed class. A simulation study is conducted to assess their finite-sample performance in comparison with existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15744v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saida Mancer, Abdelhakim Necir, Djamel Meraghni</dc:creator>
    </item>
    <item>
      <title>Empirical Likelihood Based Inference for a Divergence Measure Based on Survival Extropy</title>
      <link>https://arxiv.org/abs/2507.15810</link>
      <description>arXiv:2507.15810v1 Announce Type: new 
Abstract: We consider a divergence measure based on survival extropy and derive its non-parametric estimators based on U-statistics, empirical distribution-functions, and kernel density. Further, we construct confidence intervals for the divergence measure using the jackknife empirical likelihood (JEL) method and the normal approximation method with a jackknife pseudo-value-based variance estimator. A comprehensive simulation study is conducted to compare the performance of the measure with existing divergence measures. In addition, we assess the finite-sample performance of various estimators for the measure. The findings highlight the effectiveness of the divergence measure and its estimators in practical applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15810v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Naresh Garg, Isha Dewan, Sudheesh Kumar Kattumannil</dc:creator>
    </item>
    <item>
      <title>Regional compositional trajectories and structural change: A spatiotemporal multivariate autoregressive framework</title>
      <link>https://arxiv.org/abs/2507.14389</link>
      <description>arXiv:2507.14389v1 Announce Type: cross 
Abstract: Compositional data, such as regional shares of economic sectors or property transactions, are central to understanding structural change in economic systems across space and time. This paper introduces a spatiotemporal multivariate autoregressive model tailored for panel data with composition-valued responses at each areal unit and time point. The proposed framework enables the joint modelling of temporal dynamics and spatial dependence under compositional constraints and is estimated via a quasi maximum likelihood approach. We build on recent theoretical advances to establish identifiability and asymptotic properties of the estimator when both the number of regions and time points grow. The utility and flexibility of the model are demonstrated through two applications: analysing property transaction compositions in an intra-city housing market (Berlin), and regional sectoral compositions in Spain's economy. These case studies highlight how the proposed framework captures key features of spatiotemporal economic processes that are often missed by conventional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14389v1</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Eckardt, Philipp Otto</dc:creator>
    </item>
    <item>
      <title>Bivariate generalized autoregressive models for forecasting bivariate non-Gaussian times series</title>
      <link>https://arxiv.org/abs/2507.14442</link>
      <description>arXiv:2507.14442v1 Announce Type: cross 
Abstract: This paper introduces a novel approach, the bivariate generalized autoregressive (BGAR) model, for modeling and forecasting bivariate time series data. The BGAR model generalizes the bivariate vector autoregressive (VAR) models by allowing data that does not necessarily follow a normal distribution. We consider a random vector of two time series and assume each belongs to the canonical exponential family, similarly to the univariate generalized autoregressive moving average (GARMA) model. We include autoregressive terms of one series into the dynamical structure of the other and vice versa. The model parameters are estimated using the conditional maximum likelihood (CML) method. We provide general closed-form expressions for the conditional score vector and conditional Fisher information matrix, encompassing all canonical exponential family distributions. We develop asymptotic confidence intervals and hypothesis tests. We discuss techniques for model selection, residual diagnostic analysis, and forecasting. We carry out Monte Carlo simulation studies to evaluate the performance of the finite sample CML inferences, including point and interval estimation. An application to real data analyzes the number of leptospirosis cases on hospitalizations due to leptospirosis in S\~ao Paulo state, Brazil. Competing models such as GARMA, autoregressive integrated moving average (ARIMA), and VAR models are considered for comparison purposes. The new model outperforms the competing models by providing more accurate out-of-sample forecasting and allowing quantification of the lagged effect of the case count series on hospitalizations due to leptospirosis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14442v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiane Fontana Ribeiro, Airlane P. Alencar, F\'abio M. Bayer</dc:creator>
    </item>
    <item>
      <title>Statistical and Algorithmic Foundations of Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2507.14444</link>
      <description>arXiv:2507.14444v1 Announce Type: cross 
Abstract: As a paradigm for sequential decision making in unknown environments, reinforcement learning (RL) has received a flurry of attention in recent years. However, the explosion of model complexity in emerging applications and the presence of nonconvexity exacerbate the challenge of achieving efficient RL in sample-starved situations, where data collection is expensive, time-consuming, or even high-stakes (e.g., in clinical trials, autonomous systems, and online advertising). How to understand and enhance the sample and computational efficacies of RL algorithms is thus of great interest. In this tutorial, we aim to introduce several important algorithmic and theoretical developments in RL, highlighting the connections between new ideas and classical topics. Employing Markov Decision Processes as the central mathematical model, we cover several distinctive RL scenarios (i.e., RL with a simulator, online RL, offline RL, robust RL, and RL with human feedback), and present several mainstream RL approaches (i.e., model-based approach, value-based approach, and policy optimization). Our discussions gravitate around the issues of sample complexity, computational efficiency, as well as algorithm-dependent and information-theoretic lower bounds from a non-asymptotic viewpoint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14444v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuejie Chi, Yuxin Chen, Yuting Wei</dc:creator>
    </item>
    <item>
      <title>When few labeled target data suffice: a theory of semi-supervised domain adaptation via fine-tuning from multiple adaptive starts</title>
      <link>https://arxiv.org/abs/2507.14661</link>
      <description>arXiv:2507.14661v1 Announce Type: cross 
Abstract: Semi-supervised domain adaptation (SSDA) aims to achieve high predictive performance in the target domain with limited labeled target data by exploiting abundant source and unlabeled target data. Despite its significance in numerous applications, theory on the effectiveness of SSDA remains largely unexplored, particularly in scenarios involving various types of source-target distributional shifts. In this work, we develop a theoretical framework based on structural causal models (SCMs) which allows us to analyze and quantify the performance of SSDA methods when labeled target data is limited. Within this framework, we introduce three SSDA methods, each having a fine-tuning strategy tailored to a distinct assumption about the source and target relationship. Under each assumption, we demonstrate how extending an unsupervised domain adaptation (UDA) method to SSDA can achieve minimax-optimal target performance with limited target labels. When the relationship between source and target data is only vaguely known -- a common practical concern -- we propose the Multi Adaptive-Start Fine-Tuning (MASFT) algorithm, which fine-tunes UDA models from multiple starting points and selects the best-performing one based on a small hold-out target validation dataset. Combined with model selection guarantees, MASFT achieves near-optimal target predictive performance across a broad range of types of distributional shifts while significantly reducing the need for labeled target data. We empirically validate the effectiveness of our proposed methods through simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14661v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wooseok Ha, Yuansi Chen</dc:creator>
    </item>
    <item>
      <title>A Comparative Analysis of Statistical and Machine Learning Models for Outlier Detection in Bitcoin Limit Order Books</title>
      <link>https://arxiv.org/abs/2507.14960</link>
      <description>arXiv:2507.14960v1 Announce Type: cross 
Abstract: The detection of outliers within cryptocurrency limit order books (LOBs) is of paramount importance for comprehending market dynamics, particularly in highly volatile and nascent regulatory environments. This study conducts a comprehensive comparative analysis of robust statistical methods and advanced machine learning techniques for real-time anomaly identification in cryptocurrency LOBs. Within a unified testing environment, named AITA Order Book Signal (AITA-OBS), we evaluate the efficacy of thirteen diverse models to identify which approaches are most suitable for detecting potentially manipulative trading behaviours. An empirical evaluation, conducted via backtesting on a dataset of 26,204 records from a major exchange, demonstrates that the top-performing model, Empirical Covariance (EC), achieves a 6.70% gain, significantly outperforming a standard Buy-and-Hold benchmark. These findings underscore the effectiveness of outlier-driven strategies and provide insights into the trade-offs between model complexity, trade frequency, and performance. This study contributes to the growing corpus of research on cryptocurrency market microstructure by furnishing a rigorous benchmark of anomaly detection models and highlighting their potential for augmenting algorithmic trading and risk management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.14960v1</guid>
      <category>q-fin.TR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ivan Letteri</dc:creator>
    </item>
    <item>
      <title>Learning under Latent Group Sparsity via Diffusion on Networks</title>
      <link>https://arxiv.org/abs/2507.15097</link>
      <description>arXiv:2507.15097v1 Announce Type: cross 
Abstract: Group or cluster structure on explanatory variables in machine learning problems is a very general phenomenon, which has attracted broad interest from practitioners and theoreticians alike. In this work we contribute an approach to sparse learning under such group structure, that does not require prior information on the group identities. Our paradigm is motivated by the Laplacian geometry of an underlying network with a related community structure, and proceeds by directly incorporating this into a penalty that is effectively computed via a heat-flow-based local network dynamics. The proposed penalty interpolates between the lasso and the group lasso penalties, the runtime of the heat-flow dynamics being the interpolating parameter. As such it can automatically default to lasso when the group structure reflected in the Laplacian is weak. In fact, we demonstrate a data-driven procedure to construct such a network based on the available data. Notably, we dispense with computationally intensive pre-processing involving clustering of variables, spectral or otherwise. Our technique is underpinned by rigorous theorems that guarantee its effective performance and provide bounds on its sample complexity. In particular, in a wide range of settings, it provably suffices to run the diffusion for time that is only logarithmic in the problem dimensions. We explore in detail the interfaces of our approach with key statistical physics models in network science, such as the Gaussian Free Field and the Stochastic Block Model. Our work raises the possibility of applying similar diffusion-based techniques to classical learning tasks, exploiting the interplay between geometric, dynamical and stochastic structures underlying the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15097v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Subhroshekhar Ghosh, Soumendu Sundar Mukherjee</dc:creator>
    </item>
    <item>
      <title>Total Loss Functions for Measuring the Accuracy of Nonnegative Cross-Sectional Predictions</title>
      <link>https://arxiv.org/abs/2507.15136</link>
      <description>arXiv:2507.15136v1 Announce Type: cross 
Abstract: The total loss function associated with a set of cross-sectional predictions, that is, estimates or forecasts, summarizes the set's overall accuracy. Its arguments are the individual cross-sectional units' loss functions. Under general assumptions, including impartiality, about the forms of the individual loss functions, and the specific assumptions that the total loss function is anonymous and monotonic, only the additive, multiplicative and L-type (with restrictions) total loss functions are found to be admissible. The first two total loss functions correspond to different interpretations of economic utility. An isomorphism exists between these two total loss functions. Thus, the additive total loss function can always be used. This isomorphism can also be used to explore the properties of various combinations of total and individual loss functions. Moreover, the additive loss function obeys the von Neumann-Morgenstern expected utility axioms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15136v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Charles D. Coleman</dc:creator>
    </item>
    <item>
      <title>Sufficiency-principled Transfer Learning via Model Averaging</title>
      <link>https://arxiv.org/abs/2507.15416</link>
      <description>arXiv:2507.15416v1 Announce Type: cross 
Abstract: When the transferable set is unknowable, transfering informative knowledge as much as possible\textemdash a principle we refer to as \emph{sufficiency}, becomes crucial for enhancing transfer learning effectiveness. However, existing transfer learning methods not only overlook the sufficiency principle, but also rely on restrictive single-similarity assumptions (\eg individual or combinatorial similarity), leading to suboptimal performance. To address these limitations, we propose a sufficiency-principled transfer learning framework via unified model averaging algorithms, accommodating both individual and combinatorial similarities. Theoretically, we establish the asymptotic/high-probability optimality, enhanced convergence rate and asymptotic normality for multi-source linear regression models with a diverging number of parameters, achieving sufficiency, robustness to negative transfer, privacy protection and feasible statistical inference. Extensive simulations and an empirical data analysis of Beijing housing rental data demonstrate the promising superiority of our framework over conventional alternatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15416v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiyuan Zhang, Huihang Liu, Xinyu Zhang</dc:creator>
    </item>
    <item>
      <title>Multiple Hypothesis Testing To Estimate The Number Of Communities in Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2507.15471</link>
      <description>arXiv:2507.15471v1 Announce Type: cross 
Abstract: Clustering of single-cell RNA sequencing (scRNA-seq) datasets can give key insights into the biological functions of cells. Therefore, it is not surprising that network-based community detection methods (one of the better clustering methods) are increasingly being used for the clustering of scRNA-seq datasets. The main challenge in implementing network-based community detection methods for scRNA-seq datasets is that these methods \emph{apriori} require the true number of communities or blocks for estimating the community memberships. Although there are existing methods for estimating the number of communities, they are not suitable for noisy scRNA-seq datasets. Moreover, we require an appropriate method for extracting suitable networks from scRNA-seq datasets. For addressing these issues, we present a two-fold solution: i) a simple likelihood-based approach for extracting stochastic block models (SBMs) out of scRNA-seq datasets, ii) a new sequential multiple testing (SMT) method for estimating the number of communities in SBMs. We study the theoretical properties of SMT and establish its consistency under moderate sparsity conditions. In addition, we compare the numerical performance of the SMT with several existing methods. We also show that our approach performs competitively well against existing methods for estimating the number of communities on benchmark scRNA-seq datasets. Finally, we use our approach for estimating subgroups of a human retina bipolar single cell dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15471v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chetkar Jha, Mingyao Li, Ian Barnett</dc:creator>
    </item>
    <item>
      <title>Scalable Estimation of Crossed Random Effects Models via Multi-way Grouping</title>
      <link>https://arxiv.org/abs/2507.15593</link>
      <description>arXiv:2507.15593v1 Announce Type: cross 
Abstract: Cross-classified data frequently arise in scientific fields such as education, healthcare, and social sciences. A common modeling strategy is to introduce crossed random effects within a regression framework. However, this approach often encounters serious computational bottlenecks, particularly for non-Gaussian outcomes. In this paper, we propose a scalable and flexible method that approximates the distribution of each random effect by a discrete distribution, effectively partitioning the random effects into a finite number of representative groups. This approximation allows us to express the model as a multi-way grouped structure, which can be efficiently estimated using a simple and fast iterative algorithm. The proposed method accommodates a wide range of outcome models and remains applicable even in settings with more than two-way cross-classification. We theoretically establish the consistency and asymptotic normality of the estimator under general settings of classification levels. Through simulation studies and real data applications, we demonstrate the practical performance of the proposed method in logistic, Poisson, and ordered probit regression models involving cross-classified structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15593v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shota Takeishi, Shonosuke Sugasawa</dc:creator>
    </item>
    <item>
      <title>Conformal and kNN Predictive Uncertainty Quantification Algorithms in Metric Spaces</title>
      <link>https://arxiv.org/abs/2507.15741</link>
      <description>arXiv:2507.15741v1 Announce Type: cross 
Abstract: This paper introduces a framework for uncertainty quantification in regression models defined in metric spaces. Leveraging a newly defined notion of homoscedasticity, we develop a conformal prediction algorithm that offers finite-sample coverage guarantees and fast convergence rates of the oracle estimator. In heteroscedastic settings, we forgo these non-asymptotic guarantees to gain statistical efficiency, proposing a local $k$--nearest--neighbor method without conformal calibration that is adaptive to the geometry of each particular nonlinear space. Both procedures work with any regression algorithm and are scalable to large data sets, allowing practitioners to plug in their preferred models and incorporate domain expertise. We prove consistency for the proposed estimators under minimal conditions. Finally, we demonstrate the practical utility of our approach in personalized--medicine applications involving random response objects such as probability distributions and graph Laplacians.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15741v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>G\'abor Lugosi, Marcos Matabuena</dc:creator>
    </item>
    <item>
      <title>A Fisher's exact test justification of the TF-IDF term-weighting scheme</title>
      <link>https://arxiv.org/abs/2507.15742</link>
      <description>arXiv:2507.15742v1 Announce Type: cross 
Abstract: Term frequency-inverse document frequency, or TF-IDF for short, is arguably the most celebrated mathematical expression in the history of information retrieval. Conceived as a simple heuristic quantifying the extent to which a given term's occurrences are concentrated in any one given document out of many, TF-IDF and its many variants are routinely used as term-weighting schemes in diverse text analysis applications. There is a growing body of scholarship dedicated to placing TF-IDF on a sound theoretical foundation. Building on that tradition, this paper justifies the use of TF-IDF to the statistics community by demonstrating how the famed expression can be understood from a significance testing perspective. We show that the common TF-IDF variant TF-ICF is, under mild regularity conditions, closely related to the negative logarithm of the $p$-value from a one-tailed version of Fisher's exact test of statistical significance. As a corollary, we establish a connection between TF-IDF and the said negative log-transformed $p$-value under certain idealized assumptions. We further demonstrate, as a limiting case, that this same quantity converges to TF-IDF in the limit of an infinitely large document collection. The Fisher's exact test justification of TF-IDF equips the working statistician with a ready explanation of the term-weighting scheme's long-established effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.15742v1</guid>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paul Sheridan, Zeyad Ahmed, Aitazaz A. Farooque</dc:creator>
    </item>
    <item>
      <title>A leave-one-out approach to approximate message passing</title>
      <link>https://arxiv.org/abs/2312.05911</link>
      <description>arXiv:2312.05911v3 Announce Type: replace 
Abstract: Approximate message passing (AMP) has emerged both as a popular class of iterative algorithms and as a powerful analytic tool in a wide range of statistical estimation problems and statistical physics models. A well established line of AMP theory proves Gaussian approximations for the empirical distributions of the AMP iterate in the high dimensional limit, under the GOE random matrix model and its variants.
  This paper provides a non-asymptotic, leave-one-out representation for the AMP iterate that holds under a broad class of Gaussian random matrix models with general variance profiles. In contrast to the typical AMP theory that describes the empirical distributions of the AMP iterate via a low dimensional state evolution, our leave-one-out representation yields an intrinsically high dimensional state evolution formula which provides non-asymptotic characterizations for the possibly heterogeneous, entrywise behavior of the AMP iterate under the prescribed random matrix models.
  To exemplify some distinct features of our AMP theory in applications, we analyze, in the context of regularized linear estimation, the precise stochastic behavior of the Ridge estimator for independent and non-identically distributed observations whose covariates exhibit general variance profiles. We find that its finite-sample distribution is characterized via a weighted Ridge estimator in a heterogeneous Gaussian sequence model. Notably, in contrast to the i.i.d. sampling scenario, the effective noise and regularization are now full dimensional vectors determined via a high dimensional system of equations.
  Our leave-one-out method of proof differs significantly from the widely adopted conditioning approach for rotational invariant ensembles, and relies instead on an inductive method that utilizes almost solely integration-by-parts and concentration techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05911v3</guid>
      <category>math.ST</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhigang Bao, Qiyang Han, Xiaocong Xu</dc:creator>
    </item>
    <item>
      <title>Contraction rates and projection subspace estimation with Gaussian process priors in high dimension</title>
      <link>https://arxiv.org/abs/2403.03540</link>
      <description>arXiv:2403.03540v3 Announce Type: replace 
Abstract: This work explores the dimension reduction problem for Bayesian nonparametric regression and density estimation. More precisely, we are interested in estimating a functional parameter $f$ over the unit ball in $\mathbb{R}^d$, which depends only on a $d^*$-dimensional subspace of $\mathbb{R}^d$, with $d^* &lt; d$. It is well-known that rescaled Gaussian process priors over the function space achieve smoothness adaptation and posterior contraction with near minimax-optimal rates. Moreover, hierarchical extensions of this approach, equipped with subspace projection, can also adapt to the intrinsic dimension $d^*$ (\cite{Tokdar2011DimensionAdapt}). When the ambient dimension $d$ does not vary with $n$, the minimax rate remains of the order $n^{-\beta/(2\beta +d^*)}$, where $\beta$ denotes the smoothnes of $f$. However, this is up to multiplicative constants that can become prohibitively large when $d$ grows. The dependences between the contraction rate and the ambient dimension have not been fully explored yet and this work provides a first insight: we let the dimension $d$ grow with $n$ and, by combining the arguments of \cite{Tokdar2011DimensionAdapt} and \cite{Jiang2021VariableSelection}, we derive a growth rate for $d$ that still leads to posterior consistency with minimax rate. The optimality of this growth rate is then discussed. Additionally, we provide a set of assumptions under which consistent estimation of $f$ leads to a correct estimation of the subspace projection, assuming that $d^*$ is known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03540v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elie Odin (IMT), Fran\c{c}ois Bachoc (IMT), Agn\`es Lagnoux (IMT)</dc:creator>
    </item>
    <item>
      <title>Deepening the Understanding of Double Robustness Geometrically</title>
      <link>https://arxiv.org/abs/2404.13960</link>
      <description>arXiv:2404.13960v2 Announce Type: replace 
Abstract: Double robustness (DR) is a widely-used property of estimators that provides protection against model misspecification and slow convergence of nuisance functions. Despite its widespread application, the theoretical foundation of DR remains underexplored. While DR is a property of global invariance along both nuisance directions, it is often implied by influence curves (ICs), which only have zero first-order derivatives in those directions locally. On the other hand, some literature proved the absence of DR estimating functions for the same estimand, under one parameterization yet was able to find one under another parameterization, highlighting the nuances in parameterization.
  In this short communication, we address two key questions: (1) Why do ICs frequently imply DR ``for free''? (2) Under what conditions would a given statistical model and parameterization support or prevent the existence of DR estimators? Using tools from semiparametric theory, we show that convexity is the crucial property that enables influence curves to imply DR. We then derive necessary and sufficient conditions for the existence of DR estimators.
  Our main contribution also lies in the novel geometric interpretation of DR using information geometry, a discipline devoted to integrating global differential geometry with statistical analysis. By leveraging concepts such as parallel transport, m-flatness, and m-curvature freeness, we characterize DR in terms of invariance along submanifolds. This geometric perspective deepens the understanding of when and why DR estimators exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13960v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Ying</dc:creator>
    </item>
    <item>
      <title>Decompounding Under General Mixing Distributions</title>
      <link>https://arxiv.org/abs/2405.05419</link>
      <description>arXiv:2405.05419v2 Announce Type: replace 
Abstract: This study focuses on statistical inference for compound models of the form $X=\xi_1+\ldots+\xi_N$, where $N$ is a random variable denoting the count of summands, which are independent and identically distributed (i.i.d.) random variables $\xi_1, \xi_2, \ldots$. The paper addresses the problem of reconstructing the distribution of $\xi$ from observed samples of $X$'s distribution, a process referred to as decompounding, with the assumption that $N$'s distribution is known. This work diverges from the conventional scope by not limiting $N$'s distribution to the Poisson type, thus embracing a broader context. We propose a nonparametric estimate for the density of $\xi$, derive its rates of convergence and prove that these rates are minimax optimal for suitable classes of distributions for $\xi$ and $N$. Finally, we illustrate the numerical performance of the algorithm on simulated examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05419v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Denis Belomestny, Ekaterina Morozova, Vladimir Panov</dc:creator>
    </item>
    <item>
      <title>Asymptotic efficiency for Sobol' and Cram{\'e}r-von Mises indices under two designs of experiments</title>
      <link>https://arxiv.org/abs/2407.15468</link>
      <description>arXiv:2407.15468v2 Announce Type: replace 
Abstract: A variety of indices aim to quantify the impact of input variables on a response, typically the output from a complex computer code or black-box model. Most commonly used, the Sobol' index typically measures the influence of some inputs from an explained variance perspective. However, some situations may require a more targeted analysis of some inputs influence. With no prior information, distribution-based measures appear to be appealing. In this purpose, so-called Cram{\'e}r-von Mises indices (and their generalization) have been proposed in the literature, defined as an excess probability integrated over the output distribution that aim to reflect influence on the whole distribution of the output rather than on the variance solely. Inference of these various indices has remained a challenging topic especially in presence of many inputs. While several Sobol' indices estimators are known to be optimal under regularity conditions, the issue of asymptotic efficiency for Cram{\'e}r-von Mises indices has been unaddressed in the literature so far. For these indices, we derive in this paper the efficiency bounds and discuss the known methods to achieve such optimal bounds. Two estimation contexts are considered: the so-called Pick-Freeze scheme and the Given-Data setting, for which the estimation is produced from a unique input-output sample.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.15468v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thierry Klein (ENAC, IMT), Agn\`es Lagnoux (IMT), Paul Rochet (OPTIM), Thi Mong Ngoc Nguyen</dc:creator>
    </item>
    <item>
      <title>Survey Data Integration for Distribution Function Estimation</title>
      <link>https://arxiv.org/abs/2409.14284</link>
      <description>arXiv:2409.14284v2 Announce Type: replace 
Abstract: Integration of probabilistic and non-probabilistic samples for the estimation of finite population totals (or means) has recently received considerable attention in the field of survey sampling; yet, to the best of our knowledge, this framework has not been extended to cumulative distribution function (CDF) estimation. To address this gap, we propose a novel CDF estimator that integrates data from probability samples with data from, potentially big, nonprobability samples. Assuming that a set of shared covariates are observed in both, while the response variable is observed only in the latter, the proposed estimator uses a survey-weighted empirical CDF of regression residuals trained on the convenience sample to estimate the CDF of the response variable. Under some assumptions, we derive the asymptotic bias and variance of our CDF estimator and show that it is asymptotically unbiased for the finite population CDF if ignorability holds. Our empirical results imply that the proposed CDF estimator is robust to model misspecification under ignorability, and robust to ignorability under model misspecification; when both assumptions are violated, our residual-based CDF estimator still outperforms its `plug-in' mass imputation and naive siblings, albeit with noted decreases in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14284v2</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Flood, Sayed Mostafa</dc:creator>
    </item>
    <item>
      <title>Sampling models for selective inference</title>
      <link>https://arxiv.org/abs/2502.02213</link>
      <description>arXiv:2502.02213v2 Announce Type: replace 
Abstract: This paper explores the challenges of constructing suitable inferential models in scenarios where the parameter of interest is determined in light of the data, such as regression after variable selection. Two compelling arguments for conditioning converge in this context, whose interplay can introduce ambiguity in the choice of conditioning strategy: the Conditionality Principle, from classical statistics, and the `condition on selection' paradigm, central to selective inference. We discuss two general principles that can be employed to resolve this ambiguity in some recurrent contexts. The first one refers to the consideration of how information is processed at the selection stage. The second one concerns an exploration of ancillarity in the presence of selection. We demonstrate that certain notions of ancillarity are preserved after conditioning on the selection event, supporting the application of the Conditionality Principle. We illustrate these concepts through examples and provide guidance on the adequate inferential approach in some common scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02213v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Garcia Rasines, G. Alastair Young</dc:creator>
    </item>
    <item>
      <title>Asymptotic representations for Spearman's footrule correlation coefficient</title>
      <link>https://arxiv.org/abs/2505.01825</link>
      <description>arXiv:2505.01825v2 Announce Type: replace 
Abstract: In order to address the theoretical challenges arising from the dependence structure of ranks in Spearman's footrule correlation coefficient, we propose two asymptotic representations to approximate the distribution of this coefficient under the hypothesis of independence. The first representation simplifies the dependence structure by replacing empirical distribution functions with their population counterparts. The second representation leverages the H\'{a}jek projection technique to decompose the initial form into a sum of independent components, thereby rigorously justifying asymptotic normality. Simulation studies demonstrate the appropriateness of two proposed asymptotic representations, as well as their excellent approximation to the limiting normal distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.01825v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liqi Xia, Li Guan, Weimin Xu</dc:creator>
    </item>
    <item>
      <title>Beyond Sin-Squared Error: Linear-Time Entrywise Uncertainty Quantification for Streaming PCA</title>
      <link>https://arxiv.org/abs/2506.12655</link>
      <description>arXiv:2506.12655v2 Announce Type: replace 
Abstract: We propose a novel statistical inference framework for streaming principal component analysis (PCA) using Oja's algorithm, enabling the construction of confidence intervals for individual entries of the estimated eigenvector. Most existing works on streaming PCA focus on providing sharp sin-squared error guarantees. Recently, there has been some interest in uncertainty quantification for the sin-squared error. However, uncertainty quantification or sharp error guarantees for entries of the estimated eigenvector in the streaming setting remains largely unexplored. We derive a sharp Bernstein-type concentration bound for elements of the estimated vector matching the optimal error rate up to logarithmic factors. We also establish a Central Limit Theorem for a suitably centered and scaled subset of the entries. To efficiently estimate the coordinate-wise variance, we introduce a provably consistent subsampling algorithm that leverages the median-of-means approach, empirically achieving similar accuracy to multiplier bootstrap methods while being significantly more computationally efficient. Numerical experiments demonstrate its effectiveness in providing reliable uncertainty estimates with a fraction of the computational cost of existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.12655v2</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syamantak Kumar, Shourya Pandey, Purnamrita Sarkar</dc:creator>
    </item>
    <item>
      <title>Multiscale Quantile Regression with Local Error Control</title>
      <link>https://arxiv.org/abs/2403.11356</link>
      <description>arXiv:2403.11356v2 Announce Type: replace-cross 
Abstract: For robust and efficient detection of change points, we introduce a novel methodology MUSCLE (multiscale quantile segmentation controlling local error) that partitions serial data into multiple segments, each sharing a common quantile. It leverages multiple tests for quantile changes over different scales and locations, and variational estimation. Unlike the often adopted global error control, MUSCLE focuses on local errors defined on individual segments, significantly improving detection power in finding change points. Meanwhile, due to the built-in model complexity penalty, it enjoys the finite sample guarantee that its false discovery rate (or the expected proportion of falsely detected change points) is upper bounded by its unique tuning parameter. Further, we obtain the consistency and the localisation error rates in estimating change points, under mild signal-to-noise-ratio conditions. Both match (up to log factors) the minimax optimality results in the Gaussian setup. All theories hold under the only distributional assumption of serial independence. Incorporating the wavelet tree data structure, we develop an efficient dynamic programming algorithm for computing MUSCLE. Extensive simulations as well as real data applications in electrophysiology and geophysics demonstrate its competitiveness and effectiveness. An implementation via R package muscle is available from GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11356v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhi Liu, Housen Li</dc:creator>
    </item>
    <item>
      <title>Central limit theory for Peaks-over-Threshold partial sums of long memory linear time series</title>
      <link>https://arxiv.org/abs/2506.20789</link>
      <description>arXiv:2506.20789v2 Announce Type: replace-cross 
Abstract: Over the last 30 years, extensive work has been devoted to developing central limit theory for partial sums of subordinated long memory linear time series. A much less studied problem, motivated by questions that are ubiquitous in extreme value theory, is the asymptotic behavior of such partial sums when the subordination mechanism has a threshold depending on sample size, so as to focus on the right tail of the time series. This article substantially extends longstanding asymptotic techniques by allowing the subordination mechanism to depend on the sample size in this way and to grow at a polynomial rate, while permitting the innovation process to have infinite variance. The cornerstone of our theoretical approach is a tailored $L^r(\mathbf{P})$ reduction principle, which enables the use of classical results on partial sums of long memory linear processes. In this way we obtain asymptotic theory for certain Peaks-over-Threshold estimators with deterministic or random thresholds. Applications comprise both the heavy- and light-tailed regimes -- yielding unexpected results which, to the best of our knowledge, are new to the literature. A simulation study illustrates the relevance of our findings in finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20789v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 22 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ioan Scheffel, Marco Oesting, Gilles Stupfler</dc:creator>
    </item>
  </channel>
</rss>
