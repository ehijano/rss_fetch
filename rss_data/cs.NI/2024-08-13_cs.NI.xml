<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Aug 2024 01:38:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 13 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Diffusion Model-based Contrastive Learning for Human Activity Recognition</title>
      <link>https://arxiv.org/abs/2408.05567</link>
      <description>arXiv:2408.05567v1 Announce Type: new 
Abstract: WiFi Channel State Information (CSI)-based activity recognition has sparked numerous studies due to its widespread availability and privacy protection. However, when applied in practical applications, general CSI-based recognition models may face challenges related to the limited generalization capability, since individuals with different behavior habits will cause various fluctuations in CSI data and it is difficult to gather enough training data to cover all kinds of motion habits. To tackle this problem, we design a diffusion model-based Contrastive Learning framework for human Activity Recognition (CLAR) using WiFi CSI. On the basis of the contrastive learning framework, we primarily introduce two components for CLAR to enhance CSI-based activity recognition. To generate diverse augmented data and complement limited training data, we propose a diffusion model-based time series-specific augmentation model. In contrast to typical diffusion models that directly apply conditions to the generative process, potentially resulting in distorted CSI data, our tailored model dissects these condition into the high-frequency and low-frequency components, and then applies these conditions to the generative process with varying weights. This can alleviate data distortion and yield high-quality augmented data. To efficiently capture the difference of the sample importance, we present an adaptive weight algorithm. Different from typical contrastive learning methods which equally consider all the training samples, this algorithm adaptively adjusts the weights of positive sample pairs for learning better data representations. The experiments suggest that CLAR achieves significant gains compared to state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05567v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2024.3429245</arxiv:DOI>
      <dc:creator>Chunjing Xiao, Yanhui Han, Wei Yang, Yane Hou, Fangzhan Shi, Kevin Chetty</dc:creator>
    </item>
    <item>
      <title>DeepAir: A Multi-Agent Deep Reinforcement Learning Based Scheme for an Unknown User Location Problem</title>
      <link>https://arxiv.org/abs/2408.05712</link>
      <description>arXiv:2408.05712v1 Announce Type: new 
Abstract: The deployment of unmanned aerial vehicles (UAVs) in many different settings has provided various solutions and strategies for networking paradigms. Therefore, it reduces the complexity of the developments for the existing problems, which otherwise require more sophisticated approaches. One of those existing problems is the unknown user locations in an infrastructure-less environment in which users cannot connect to any communication device or computation-providing server, which is essential to task offloading in order to achieve the required quality of service (QoS). Therefore, in this study, we investigate this problem thoroughly and propose a novel deep reinforcement learning (DRL) based scheme, DeepAir. DeepAir considers all of the necessary steps including sensing, localization, resource allocation, and multi-access edge computing (MEC) to achieve QoS requirements for the offloaded tasks without violating the maximum tolerable delay. To this end, we use two types of UAVs including detector UAVs, and serving UAVs. We utilize detector UAVs as DRL agents which ensure sensing, localization, and resource allocation. On the other hand, we utilize serving UAVs to provide MEC features. Our experiments show that DeepAir provides a high task success rate by deploying fewer detector UAVs in the environment, which includes different numbers of users and user attraction points, compared to benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05712v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baris Yamansavascilar, Atay Ozgovde, Cem Ersoy</dc:creator>
    </item>
    <item>
      <title>Convergence of Symbiotic Communications and Blockchain for Sustainable and Trustworthy 6G Wireless Networks</title>
      <link>https://arxiv.org/abs/2408.05776</link>
      <description>arXiv:2408.05776v1 Announce Type: new 
Abstract: Symbiotic communication (SC) is known as a new wireless communication paradigm, similar to the natural ecosystem population, and can enable multiple communication systems to cooperate and mutualize through service exchange and resource sharing. As a result, SC is seen as an important potential technology for future sixth-generation (6G) communications, solving the problem of lack of spectrum resources and energy inefficiency. Symbiotic relationships among communication systems can complement radio resources in 6G. However, the absence of established trust relationships among diverse communication systems presents a formidable hurdle in ensuring efficient and trusted resource and service exchange within SC frameworks. To better realize trusted SC services in 6G, in this paper, we propose a solution that converges SC and blockchain, called a symbiotic blockchain network (SBN). Specifically, we first use cognitive backscatter communication to transform blockchain consensus, that is, the symbiotic blockchain consensus (SBC), so that it can be better suited for the wireless network. Then, for SBC, we propose a highly energy-efficient sharding scheme to meet the extremely low power consumption requirements in 6G. Finally, such a blockchain scheme guarantees trusted transactions of communication services in SC. Through ablation experiments, our proposed SBN demonstrates significant efficacy in mitigating energy consumption and reducing processing latency in adversarial networks, which is expected to achieve a sustainable and trusted 6G wireless network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05776v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Haoxiang Luo, Gang Sun, Cheng Chi, Hongfang Yu, Mohsen Guizani</dc:creator>
    </item>
    <item>
      <title>Value-based Proactive Caching for Sensing Data in Internet of Vehicles</title>
      <link>https://arxiv.org/abs/2408.05996</link>
      <description>arXiv:2408.05996v1 Announce Type: new 
Abstract: Sensing data (SD) plays an important role in safe-related applications for Internet of Vehicles. Proactively caching required sensing data (SD) is a pivotal strategy for alleviating network congestion and improving data accessibility. Despite merits, existing studies predominantly address SD caching within a single time slot, which may not be scalable to scenarios involving multi-slots. Furthermore, the oversight of service capacity at caching nodes could lead to significant queuing delays in SD reception. To tackle these limitations, we jointly consider the problem of anchoring caching placement and requests allocation for SD. A value model incorporating both temporal and spacial characteristics is first proposed to estimate the significance of different caching decisions. Subsequently, a stochastic integer nonlinear programming model is provided to optimize the long-term system performance, which is converted into a series of online optimization problem by leveraging the Lyapunov method and linearized via introducing auxiliary variables. To expedite the solution, we provide a binary quantum particle swarm optimization based algorithm with quadratic time complexity. Numerical investigations demonstrate the superiority of proposed algorithms compared with other schemes in terms of energy consumption, response latency, and cache-hit ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05996v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yantong Wang, Ke Liu, Hui Ji, Jiande Sun</dc:creator>
    </item>
    <item>
      <title>Measurement Study of Programmable Network Coding in Cloud-native 5G and Beyond Networks</title>
      <link>https://arxiv.org/abs/2408.06115</link>
      <description>arXiv:2408.06115v1 Announce Type: new 
Abstract: Emerging 5G/6G use cases span various industries, necessitating flexible solutions that leverage emerging technologies to meet diverse and stringent application requirements under changing network conditions. The standard 5G RAN solution, retransmission, reduces packet loss but can increase transmission delay in the process. Random Linear Network Coding (RLNC) offers an alternative by proactively sending combinations of original packets, thus reducing both delay and packet loss. Current research often only simulates the integration of RLNC in 5G while we implement and evaluate our approach on real commercially available hardware in a real-world deployment.
  We introduce Flexible Network Coding (FlexNC), which enables the flexible fusion of several RLNC protocols by incorporating a forwarder with multiple RLNC nodes. Network operators can configure FlexNC based on network conditions and application requirements. To further boost network programmability, our Recoder in the Network (RecNet) leverages intermediate network nodes to join the coding process. Both the proposed algorithms have been implemented on OpenAirInterface and extensively tested with traffic from different applications in a real network. While FlexNC adapts to various application needs of latency and packet loss, RecNet significantly minimizes packet loss for a remote user with minimal increase in delay compared to pure RLNC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06115v1</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Osel Lhamo, Tung V. Doan, Elif Tasdemir, Mahdi Attawna, Giang T. Nguyen, Patrick Seeling, Martin Reisslein, Frank H. P. Fitzek</dc:creator>
    </item>
    <item>
      <title>Multi-tree Quantum Routing in Realistic Topologies</title>
      <link>https://arxiv.org/abs/2408.06207</link>
      <description>arXiv:2408.06207v1 Announce Type: new 
Abstract: In entanglement distribution networks, communication between two nodes necessitates the generation of end-to-end entanglement by entanglement swapping at intermediate nodes. Efficiently creating end-to-end entanglements over long distances is a key objective. In our prior study on asynchronous routing, we enhanced these entanglement rates by leveraging solely the local knowledge of the entanglement links of a node. This was achieved by creating a tree structure, particularly a destination-oriented directed acyclic graph (DODAG) or a spanning tree, eliminating synchronous operations and conserving unused entanglement links. In this article, we present a multi-tree approach with multiple DODAGs designed to improve end-to-end entanglement rates in large-scale networks, specifically catering to a range of network topologies, including grids and barbells, as well as realistic topologies found in research testbeds like ESnet and Internet2. Our simulations show a marked improvement in end-to-end entanglement rates for specific topologies compared to the single-tree method. This study underscores the promise of asynchronous routing schemes in quantum networks, highlighting the effectiveness of asynchronous routing across different network topologies and proposing a superior routing tactic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06207v1</guid>
      <category>cs.NI</category>
      <category>quant-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zebo Yang, Ali Ghubaish, Raj Jain, Ramana Kompella, Hassan Shapourian</dc:creator>
    </item>
    <item>
      <title>Integration of blockchain in smart systems: problems and opportunities for real-time sensor data storage</title>
      <link>https://arxiv.org/abs/2408.06331</link>
      <description>arXiv:2408.06331v1 Announce Type: new 
Abstract: The internet of things (IoT) and other emerging ubiquitous technologies are supporting the rapid spread of smart systems, which has underlined the need for safe, open, and decentralized data storage solutions. With its inherent decentralization and immutability, blockchain offers itself as a potential solution for these requirements. However, the practicality of incorporating blockchain into real-time sensor data storage systems is a topic that demands in-depth examination. While blockchain promises unmatched data security and auditability, some intrinsic qualities, namely scalability restrictions, transactional delays, and escalating storage demands, impede its seamless deployment in high-frequency, voluminous data contexts typical of real-time sensors. This essay launches a methodical investigation into these difficulties, illuminating their underlying causes, potential effects, and potential countermeasures. In addition, we present a novel pragmatic experimental setup and analysis of blockchain for smart system applications, with an extended discussion of the benefits and disadvantages of deploying blockchain based solutions for smart system ecosystems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06331v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3013828</arxiv:DOI>
      <dc:creator>Naseem Alsadi, Syed Zaidi, Mankaran Rooprai, Stephen A. Gadsden, John Yawney</dc:creator>
    </item>
    <item>
      <title>AirChain: A Novel Blockchain Framework and Low-Cost Device for Democratized Air Quality Data Aggregation</title>
      <link>https://arxiv.org/abs/2408.05216</link>
      <description>arXiv:2408.05216v1 Announce Type: cross 
Abstract: Air pollutant exposure kills over 6,700,000 people it per annum, yet there remains a systemic lack of accurate ground level data reporting the concentrations of the leading causes of such fatalities. Ambient particulate matter is a primary driver of this effect. Namely, PM1.0, PM2.5, and PM10.0 display a systemic lack of accurate and high-definition reporting. This project suggests and implements a prototype for a distributed and low cost model for reporting such data and designs a novel framework in order to remedy three main shortfalls of previously implemented systems. First, their central operation and distribution, and therefore their requirement of trust in a central governing body. Second, their requirement of the purchase of comparatively high-cost devices for ordinary consumers. Finally, their high degree of error and accordingly low functional certainty. This project explores the creation of AirChain, a prototype system utilizing blockchain technology that will demonstrate the effectiveness of low-cost sensors when paired with simple microcontroller devices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05216v1</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Stankiewicz</dc:creator>
    </item>
    <item>
      <title>Early-Exit meets Model-Distributed Inference at Edge Networks</title>
      <link>https://arxiv.org/abs/2408.05247</link>
      <description>arXiv:2408.05247v1 Announce Type: cross 
Abstract: Distributed inference techniques can be broadly classified into data-distributed and model-distributed schemes. In data-distributed inference (DDI), each worker carries the entire deep neural network (DNN) model but processes only a subset of the data. However, feeding the data to workers results in high communication costs, especially when the data is large. An emerging paradigm is model-distributed inference (MDI), where each worker carries only a subset of DNN layers. In MDI, a source device that has data processes a few layers of DNN and sends the output to a neighboring device, i.e., offloads the rest of the layers. This process ends when all layers are processed in a distributed manner. In this paper, we investigate the design and development of MDI with early-exit, which advocates that there is no need to process all the layers of a model for some data to reach the desired accuracy, i.e., we can exit the model without processing all the layers if target accuracy is reached. We design a framework MDI-Exit that adaptively determines early-exit and offloading policies as well as data admission at the source. Experimental results on a real-life testbed of NVIDIA Nano edge devices show that MDI-Exit processes more data when accuracy is fixed and results in higher accuracy for the fixed data rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05247v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marco Colocrese, Erdem Koyuncu, Hulya Seferoglu</dc:creator>
    </item>
    <item>
      <title>Multimodal generative semantic communication based on latent diffusion model</title>
      <link>https://arxiv.org/abs/2408.05455</link>
      <description>arXiv:2408.05455v1 Announce Type: cross 
Abstract: In emergencies, the ability to quickly and accurately gather environmental data and command information, and to make timely decisions, is particularly critical. Traditional semantic communication frameworks, primarily based on a single modality, are susceptible to complex environments and lighting conditions, thereby limiting decision accuracy. To this end, this paper introduces a multimodal generative semantic communication framework named mm-GESCO. The framework ingests streams of visible and infrared modal image data, generates fused semantic segmentation maps, and transmits them using a combination of one-hot encoding and zlib compression techniques to enhance data transmission efficiency. At the receiving end, the framework can reconstruct the original multimodal images based on the semantic maps. Additionally, a latent diffusion model based on contrastive learning is designed to align different modal data within the latent space, allowing mm-GESCO to reconstruct latent features of any modality presented at the input. Experimental results demonstrate that mm-GESCO achieves a compression ratio of up to 200 times, surpassing the performance of existing semantic communication frameworks and exhibiting excellent performance in downstream tasks such as object classification and detection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05455v1</guid>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiqi Fu, Lianming Xu, Xin Wu, Haoyang Wei, Li Wang</dc:creator>
    </item>
    <item>
      <title>Palantir: Towards Efficient Super Resolution for Ultra-high-definition Live Streaming</title>
      <link>https://arxiv.org/abs/2408.06152</link>
      <description>arXiv:2408.06152v1 Announce Type: cross 
Abstract: Neural enhancement through super-resolution deep neural networks opens up new possibilities for ultra-high-definition live streaming over existing encoding and networking infrastructure. Yet, the heavy SR DNN inference overhead leads to severe deployment challenges. To reduce the overhead, existing systems propose to apply DNN-based SR only on selected anchor frames while upscaling non-anchor frames via the lightweight reusing-based SR approach. However, frame-level scheduling is coarse-grained and fails to deliver optimal efficiency. In this work, we propose Palantir, the first neural-enhanced UHD live streaming system with fine-grained patch-level scheduling. In the presented solutions, two novel techniques are incorporated to make good scheduling decisions for inference overhead optimization and reduce the scheduling latency. Firstly, under the guidance of our pioneering and theoretical analysis, Palantir constructs a directed acyclic graph (DAG) for lightweight yet accurate quality estimation under any possible anchor patch set. Secondly, to further optimize the scheduling latency, Palantir improves parallelizability by refactoring the computation subprocedure of the estimation process into a sparse matrix-matrix multiplication operation. The evaluation results suggest that Palantir incurs a negligible scheduling latency accounting for less than 5.7% of the end-to-end latency requirement. When compared to the state-of-the-art real-time frame-level scheduling strategy, Palantir reduces the energy overhead of SR-integrated mobile clients by 38.1% at most (and 22.4% on average) and the monetary costs of cloud-based SR by 80.1% at most (and 38.4% on average).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06152v1</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinqi Jin, Zhui Zhu, Xikai Sun, Fan Dang, Jiangchuan Liu, Jingao Xu, Kebin Liu, Xinlei Chen, Yunhao Liu</dc:creator>
    </item>
    <item>
      <title>Hi-SAM: A high-scalable authentication model for satellite-ground Zero-Trust system using mean field game</title>
      <link>https://arxiv.org/abs/2408.06185</link>
      <description>arXiv:2408.06185v1 Announce Type: cross 
Abstract: As more and more Internet of Thing (IoT) devices are connected to satellite networks, the Zero-Trust Architecture brings dynamic security to the satellite-ground system, while frequent authentication creates challenges for system availability. To make the system's accommodate more IoT devices, this paper proposes a high-scalable authentication model (Hi-SAM). Hi-SAM introduces the Proof-of-Work idea to authentication, which allows device to obtain the network resource based on frequency. To optimize the frequency, mean field game is used for competition among devices, which can reduce the decision space of large-scale population games. And a dynamic time-range message authentication code is designed for security. From the test at large population scales, Hi-SAM is superior in the optimization of authentication workload and the anomaly detection efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06185v1</guid>
      <category>eess.SY</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuesong Wu, Tianshuai Zheng, Runfang Wu, Jie Ren, Junyan Guo, Ye Du</dc:creator>
    </item>
    <item>
      <title>STX-Vote: Improving Reliability with Bit Voting in Synchronous Transmission-based IoT Networks</title>
      <link>https://arxiv.org/abs/2405.02022</link>
      <description>arXiv:2405.02022v3 Announce Type: replace 
Abstract: Industrial Internet of Things (IIoT) networks must meet strict reliability, latency, and low energy consumption requirements. However, traditional low-power wireless protocols are ineffective in finding a sweet spot for balancing these performance metrics. Recently, network flooding protocols based on Synchronous Transmissions (STX) have been proposed for better performance in reliability-critical IIoT, where simultaneous transmissions are possible without packet collisions. STX-based protocols can offer a competitive edge over routing-based protocols, particularly in dependability. However, they notably suffer from the beating effect, a physical layer phenomenon that results in sinusoidal interference across a packet and, consequently, packet loss. Thus, we introduce STX-Vote, an error correction scheme that can handle errors caused by beating effects. Importantly, we utilize transmission redundancy already inherent within STX protocols so do not incur additional on-air overhead. Through simulation, we demonstrate STX-Vote can provide a 40% increase in reliability. We subsequently implement STX-Vote on nRF52840-DK devices and perform extensive experiments. The results confirm that STX-Vote improves reliability by 25-28% for BLE 5 PHYs and 8% for IEEE 802.15.4; thus, it can complement existing error correction schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02022v3</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Burhanuddin Rangwala, Ava Powelson, Michael Baddeley, Israat Haque</dc:creator>
    </item>
    <item>
      <title>FIGRET: Fine-Grained Robustness-Enhanced Traffic Engineering</title>
      <link>https://arxiv.org/abs/2405.04932</link>
      <description>arXiv:2405.04932v2 Announce Type: replace 
Abstract: Traffic Engineering (TE) is critical for improving network performance and reliability. A key challenge in TE is the management of sudden traffic bursts. Existing TE schemes either do not handle traffic bursts or uniformly guard against traffic bursts, thereby facing difficulties in achieving a balance between normal-case performance and burst-case performance. To address this issue, we introduce FIGRET, a Fine-Grained Robustness-Enhanced TE scheme. FIGRET offers a novel approach to TE by providing varying levels of robustness enhancements, customized according to the distinct traffic characteristics of various source-destination pairs. By leveraging a burst-aware loss function and deep learning techniques, FIGRET is capable of generating high-quality TE solutions efficiently. Our evaluations of real-world production networks, including Wide Area Networks and data centers, demonstrate that FIGRET significantly outperforms existing TE schemes. Compared to the TE scheme currently deployed in Jupiter data center networks of Google, FIGRET achieves a 9\%-34\% reduction in average Maximum Link Utilization and improves solution speed by $35\times$-$1800 \times$. Against DOTE, a state-of-the-art deep learning-based TE method, FIGRET substantially lowers the occurrence of significant congestion events triggered by traffic bursts by 41\%-53.9\% in topologies with high traffic dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04932v2</guid>
      <category>cs.NI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3651890.3672258</arxiv:DOI>
      <dc:creator>Ximeng Liu, Shizhen Zhao, Yong Cui</dc:creator>
    </item>
    <item>
      <title>From Point Data to Geographic Boundaries: Regionalizing Crowdsourced Latency Measurements</title>
      <link>https://arxiv.org/abs/2405.11138</link>
      <description>arXiv:2405.11138v3 Announce Type: replace 
Abstract: Despite significant investments in access network infrastructure, universal access to high-quality Internet connectivity remains a challenge. Policymakers often rely on large-scale, crowdsourced measurement datasets to assess the distribution of access network performance across geographic areas. These decisions typically rest on the assumption that Internet performance is uniformly distributed within predefined social boundaries. However, this assumption may not be valid for two reasons: crowdsourced measurements often exhibit non-uniform sampling densities within geographic areas; and predefined social boundaries may not align with the actual boundaries of Internet infrastructure. In this paper, we present a spatial analysis on crowdsourced datasets for constructing stable boundaries for sampling Internet performance. We hypothesize that greater stability in sampling boundaries will reflect the true nature of Internet performance disparities than misleading patterns observed as a result of data sampling variations. We apply and evaluate a series of statistical techniques to: aggregate Internet performance over geographic regions; overlay interpolated maps with various sampling unit choices; and spatially cluster boundary units to identify contiguous areas with similar performance characteristics. We assess the effectiveness of the techniques we apply by comparing the similarity of the resulting boundaries for monthly samples drawn from the dataset. Our evaluation shows that the combination of techniques we apply achieves higher similarity compared to directly calculating central measures of network metrics over census tracts or neighborhood boundaries. These findings underscore the important role of spatial modeling in accurately assessing and optimizing the distribution of Internet performance, to inform policy, network operations, and long-term planning decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11138v3</guid>
      <category>cs.NI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Taveesh Sharma, Paul Schmitt, Francesco Bronzino, Nick Feamster, Nicole Marwell</dc:creator>
    </item>
    <item>
      <title>A UAV-Enabled Time-Sensitive Data Collection Scheme for Grassland Monitoring Edge Networks</title>
      <link>https://arxiv.org/abs/2407.20585</link>
      <description>arXiv:2407.20585v2 Announce Type: replace 
Abstract: Grassland monitoring is essential for the sustainable development of grassland resources. Traditional Internet of Things (IoT) devices generate critical ecological data, making data loss unacceptable, but the harsh environment complicates data collection. Unmanned Aerial Vehicle (UAV) and mobile edge computing (MEC) offer efficient data collection solutions, enhancing performance on resource-limited mobile devices. In this context, this paper is the first to investigate a UAV-enabled time-sensitive data collection problem (TSDCMP) within grassland monitoring edge networks (GMENs). Unlike many existing data collection scenarios, this problem has three key challenges. First, the total amount of data collected depends significantly on the data collection duration and arrival time of UAV at each access point (AP). Second, the volume of data at different APs varies among regions due to differences in monitoring objects and vegetation coverage. Third, the service requests time and locations from APs are often not adjacent topologically. To address these issues, We formulate the TSDCMP for UAV-enabled GMENs as a mixed-integer programming model in a single trip. This model considers constraints such as the limited energy of UAV, the coupled routing and time scheduling, and the state of APs and UAV arrival time. Subsequently, we propose a novel cooperative heuristic algorithm based on temporal-spatial correlations (CHTSC) that integrates a modified dynamic programming (MDP) into an iterated local search to solve the TSDCMP for UAV-enabled GMENs. This approach fully takes into account the temporal and spatial relationships between consecutive service requests from APs. Systematic simulation studies demonstrate that the mixed-integer programming model effectively represents the TSDCMP within UAV-enabled GMENs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20585v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dongbin Jiao, Zihao Wang, Wen Fan, Weibo Yang, Peng Yang, Zhanhuan Shang, Shi Yan</dc:creator>
    </item>
    <item>
      <title>IoT in the Era of Generative AI: Vision and Challenges</title>
      <link>https://arxiv.org/abs/2401.01923</link>
      <description>arXiv:2401.01923v3 Announce Type: replace-cross 
Abstract: Advancements in Generative AI hold immense promise to push Internet of Things (IoT) to the next level. In this article, we share our vision on IoT in the era of Generative AI. We discuss some of the most important applications of Generative AI in IoT-related domains. We also identify some of the most critical challenges and discuss current gaps as well as promising opportunities on enabling Generative AI for IoT. We hope this article can inspire new research on IoT in the era of Generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01923v3</guid>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Wang, Zhongwei Wan, Arvin Hekmati, Mingyu Zong, Samiul Alam, Mi Zhang, Bhaskar Krishnamachari</dc:creator>
    </item>
    <item>
      <title>An Alternative to Multi-Factor Authentication with a Triple-Identity Authentication Scheme</title>
      <link>https://arxiv.org/abs/2407.19459</link>
      <description>arXiv:2407.19459v3 Announce Type: replace-cross 
Abstract: Every user authentication scheme involves three login credentials, i.e. a username, a password and a hash value, but only one of them is associated with a user identity. However, this single identity is not robust enough to protect the whole system and the login entries (i.e., the username and password forms) have not been effectively authenticated. Therefore, a multi-factor authentication service is utilized to help guarantee the account security by transmitting an extra factor to the user to use. If more identities can be employed for the two login forms to associate with the corresponding login credentials, and if the identifiers are neither transmitted through the network nor accessible to users, such a system can be more robust even without relying on a third-party service. To achieve this, a triple-identity authentication scheme is designed within a dual-password login-authentication system, by which the identities for the username and the login password can be defined respectively. Therefore, in addition to the traditional server verification, the system can also verify the identity of a user at the username and password forms simultaneously. In the triple-identity authentication, the identifiers are entirely managed by the system without involvement of users or any third-party service, and they are concealed, incommunicable, inaccessible and independent of personal information. Thus, such truly unique identifiers are useless in online attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19459v3</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Suyun Borjigin</dc:creator>
    </item>
  </channel>
</rss>
