<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 05 Mar 2025 05:00:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Boosting Rectilinear Steiner Minimum Tree Algorithms with Augmented Bounding Volume Hierarchy</title>
      <link>https://arxiv.org/abs/2503.02319</link>
      <description>arXiv:2503.02319v1 Announce Type: new 
Abstract: The rectilinear Steiner minimum tree (RSMT) problem computes the shortest network connecting a given set of points using only horizontal and vertical lines, possibly adding extra points (Steiner points) to minimize the total length. RSMT solvers seek to balance speed and accuracy. In this work, we design a framework to boost existing RSMT solvers, extending the Pareto front. Combined with GeoSteiner, our algorithm reaches 5.16\% length error on nets with 1000 pins. The average time needed is 0.46 seconds. This provides an effective way to solve large-scale RSMT problems with small-scale solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02319v1</guid>
      <category>cs.DS</category>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Puhan Yang, Guchan Li</dc:creator>
    </item>
    <item>
      <title>On the sensitivity of CDAWG-grammars</title>
      <link>https://arxiv.org/abs/2503.02415</link>
      <description>arXiv:2503.02415v1 Announce Type: new 
Abstract: The compact directed acyclic word graphs (CDAWG) [Blumer et al. 1987] of a string is the minimal compact automaton that recognizes all the suffixes of the string. CDAWGs are known to be useful for various string tasks including text pattern searching, data compression, and pattern discovery. The CDAWG-grammar [Belazzougui &amp; Cunial 2017] is a grammar-based text compression based on the CDAWG. In this paper, we prove that the CDAWG-grammar size $g$ can increase by at most an additive factor of $4e + 4$ than the original after any single-character edit operation is performed on the input string, where $e$ denotes the number of edges in the corresponding CDAWG before the edit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02415v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroto Fujimaru, Shunsuke Inenaga</dc:creator>
    </item>
    <item>
      <title>Online Fair Division: Towards Ex-Post Constant MMS Guarantees</title>
      <link>https://arxiv.org/abs/2503.02088</link>
      <description>arXiv:2503.02088v1 Announce Type: cross 
Abstract: We investigate the problem of fairly allocating $m$ indivisible items among $n$ sequentially arriving agents with additive valuations, under the sought-after fairness notion of maximin share (MMS). We first observe a strong impossibility: without appropriate knowledge about the valuation functions of the incoming agents, no online algorithm can ensure any non-trivial MMS approximation, even when there are only two agents. Motivated by this impossibility, we introduce OnlineKTypeFD (online $k$-type fair division), a model that balances theoretical tractability with real-world applicability. In this model, each arriving agent belongs to one of $k$ types, with all agents of a given type sharing the same known valuation function. We do not constrain $k$ to be a constant. Upon arrival, an agent reveals her type, receives an irrevocable allocation, and departs. We study the ex-post MMS guarantees of online algorithms under two arrival models:
  1- Adversarial arrivals: In this model, an adversary determines the type of each arriving agent. We design a $\frac{1}{k}$-MMS competitive algorithm and complement it with a lower bound, ruling out any $\Omega(\frac{1}{\sqrt{k}})$-MMS-competitive algorithm, even for binary valuations.
  2- Stochastic arrivals: In this model, the type of each arriving agent is independently drawn from an underlying, possibly unknown distribution. Unlike the adversarial setting where the dependence on $k$ is unavoidable, we surprisingly show that in the stochastic setting, an asymptotic, arbitrarily close-to-$\frac{1}{2}$-MMS competitive guarantee is achievable under mild distributional assumptions.
  Our results extend naturally to a learning-augmented framework; when given access to predictions about valuation functions, we show that the competitive ratios of our algorithms degrade gracefully with multiplicative prediction errors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02088v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pooja Kulkarni, Ruta Mehta, Parnian Shahkar</dc:creator>
    </item>
    <item>
      <title>Improved MMS Approximations for Few Agent Types</title>
      <link>https://arxiv.org/abs/2503.02089</link>
      <description>arXiv:2503.02089v1 Announce Type: cross 
Abstract: We study fair division of indivisible goods under the maximin share (MMS) fairness criterion in settings where agents are grouped into a small number of types, with agents within each type having identical valuations. For the special case of a single type, an exact MMS allocation is always guaranteed to exist. However, for two or more distinct agent types, exact MMS allocations do not always exist, shifting the focus to establishing the existence of approximate-MMS allocations. A series of works over the last decade has resulted in the best-known approximation guarantee of $\frac{3}{4} + \frac{3}{3836}$.
  In this paper, we improve the approximation guarantees for settings where agents are grouped into two or three types, a scenario that arises in many practical settings. Specifically, we present novel algorithms that guarantee a $\frac{4}{5}$-MMS allocation for two agent types and a $\frac{16}{21}$-MMS allocation for three agent types. Our approach leverages the MMS partition of the majority type and adapts it to provide improved fairness guarantees for all types.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02089v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jugal Garg, Parnian Shahkar</dc:creator>
    </item>
    <item>
      <title>Tight Gap-Dependent Memory-Regret Trade-Off for Single-Pass Streaming Stochastic Multi-Armed Bandits</title>
      <link>https://arxiv.org/abs/2503.02428</link>
      <description>arXiv:2503.02428v1 Announce Type: cross 
Abstract: We study the problem of minimizing gap-dependent regret for single-pass streaming stochastic multi-armed bandits (MAB). In this problem, the $n$ arms are present in a stream, and at most $m&lt;n$ arms and their statistics can be stored in the memory. We establish tight non-asymptotic regret bounds regarding all relevant parameters, including the number of arms $n$, the memory size $m$, the number of rounds $T$ and $(\Delta_i)_{i\in [n]}$ where $\Delta_i$ is the reward mean gap between the best arm and the $i$-th arm. These gaps are not known in advance by the player. Specifically, for any constant $\alpha \ge 1$, we present two algorithms: one applicable for $m\ge \frac{2}{3}n$ with regret at most $O_\alpha\Big(\frac{(n-m)T^{\frac{1}{\alpha + 1}}}{n^{1 + {\frac{1}{\alpha + 1}}}}\displaystyle\sum_{i:\Delta_i &gt; 0}\Delta_i^{1 - 2\alpha}\Big)$ and another applicable for $m&lt;\frac{2}{3}n$ with regret at most $O_\alpha\Big(\frac{T^{\frac{1}{\alpha+1}}}{m^{\frac{1}{\alpha+1}}}\displaystyle\sum_{i:\Delta_i &gt; 0}\Delta_i^{1 - 2\alpha}\Big)$. We also prove matching lower bounds for both cases by showing that for any constant $\alpha\ge 1$ and any $m\leq k &lt; n$, there exists a set of hard instances on which the regret of any algorithm is $\Omega_\alpha\Big(\frac{(k-m+1) T^{\frac{1}{\alpha+1}}}{k^{1 + \frac{1}{\alpha+1}}} \sum_{i:\Delta_i &gt; 0}\Delta_i^{1-2\alpha}\Big)$. This is the first tight gap-dependent regret bound for streaming MAB. Prior to our work, an $O\Big(\sum_{i\colon\Delta&gt;0} \frac{\sqrt{T}\log T}{\Delta_i}\Big)$ upper bound for the special case of $\alpha=1$ and $m=O(1)$ was established by Agarwal, Khanna and Patil (COLT'22). In contrast, our results provide the correct order of regret as $\Theta\Big(\frac{1}{\sqrt{m}}\sum_{i\colon\Delta&gt;0}\frac{\sqrt{T}}{\Delta_i}\Big)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02428v1</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zichun Ye, Chihao Zhang, Jiahao Zhao</dc:creator>
    </item>
    <item>
      <title>Mixing Time Matters: Accelerating Effective Resistance Estimation via Bidirectional Method</title>
      <link>https://arxiv.org/abs/2503.02513</link>
      <description>arXiv:2503.02513v1 Announce Type: cross 
Abstract: We study the problem of efficiently approximating the \textit{effective resistance} (ER) on undirected graphs, where ER is a widely used node proximity measure with applications in graph spectral sparsification, multi-class graph clustering, network robustness analysis, graph machine learning, and more. Specifically, given any nodes $s$ and $t$ in an undirected graph $G$, we aim to efficiently estimate the ER value $R(s,t)$ between nodes $s$ and $t$, ensuring a small absolute error $\epsilon$. The previous best algorithm for this problem has a worst-case computational complexity of $\tilde{O}\left(\frac{L_{\max}^3}{\epsilon^2 d^2}\right)$, where the value of $L_{\max}$ depends on the mixing time of random walks on $G$, $d = \min\{d(s), d(t)\}$, and $d(s)$, $d(t)$ denote the degrees of nodes $s$ and $t$, respectively. We improve this complexity to $\tilde{O}\left(\min\left\{\frac{L_{\max}^{7/3}}{\epsilon^{2/3}}, \frac{L_{\max}^3}{\epsilon^2d^2}, mL_{\max}\right\}\right)$, achieving a theoretical improvement of $\tilde{O}\left(\max\left\{\frac{L_{\max}^{2/3}}{\epsilon^{4/3} d^2}, 1, \frac{L_{\max}^2}{\epsilon^2 d^2 m}\right\}\right)$ over previous results. Here, $m$ denotes the number of edges. Given that $L_{\max}$ is often very large in real-world networks (e.g., $L_{\max} &gt; 10^4$), our improvement on $L_{\max}$ is significant, especially for real-world networks. We also conduct extensive experiments on real-world and synthetic graph datasets to empirically demonstrate the superiority of our method. The experimental results show that our method achieves a $10\times$ to $1000\times$ speedup in running time while maintaining the same absolute error compared to baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02513v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanyu Cui, Hanzhi Wang, Zhewei Wei</dc:creator>
    </item>
    <item>
      <title>Spike-and-Slab Posterior Sampling in High Dimensions</title>
      <link>https://arxiv.org/abs/2503.02798</link>
      <description>arXiv:2503.02798v1 Announce Type: cross 
Abstract: Posterior sampling with the spike-and-slab prior [MB88], a popular multimodal distribution used to model uncertainty in variable selection, is considered the theoretical gold standard method for Bayesian sparse linear regression [CPS09, Roc18]. However, designing provable algorithms for performing this sampling task is notoriously challenging. Existing posterior samplers for Bayesian sparse variable selection tasks either require strong assumptions about the signal-to-noise ratio (SNR) [YWJ16], only work when the measurement count grows at least linearly in the dimension [MW24], or rely on heuristic approximations to the posterior. We give the first provable algorithms for spike-and-slab posterior sampling that apply for any SNR, and use a measurement count sublinear in the problem dimension. Concretely, assume we are given a measurement matrix $\mathbf{X} \in \mathbb{R}^{n\times d}$ and noisy observations $\mathbf{y} = \mathbf{X}\mathbf{\theta}^\star + \mathbf{\xi}$ of a signal $\mathbf{\theta}^\star$ drawn from a spike-and-slab prior $\pi$ with a Gaussian diffuse density and expected sparsity k, where $\mathbf{\xi} \sim \mathcal{N}(\mathbb{0}_n, \sigma^2\mathbf{I}_n)$. We give a polynomial-time high-accuracy sampler for the posterior $\pi(\cdot \mid \mathbf{X}, \mathbf{y})$, for any SNR $\sigma^{-1}$ &gt; 0, as long as $n \geq k^3 \cdot \text{polylog}(d)$ and $X$ is drawn from a matrix ensemble satisfying the restricted isometry property. We further give a sampler that runs in near-linear time $\approx nd$ in the same setting, as long as $n \geq k^5 \cdot \text{polylog}(d)$. To demonstrate the flexibility of our framework, we extend our result to spike-and-slab posterior sampling with Laplace diffuse densities, achieving similar guarantees when $\sigma = O(\frac{1}{k})$ is bounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02798v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syamantak Kumar, Purnamrita Sarkar, Kevin Tian, Yusong Zhu</dc:creator>
    </item>
    <item>
      <title>Near-optimal Algorithms for Stochastic Online Bin Packing</title>
      <link>https://arxiv.org/abs/2205.03622</link>
      <description>arXiv:2205.03622v2 Announce Type: replace 
Abstract: We study the online bin packing problem under two stochastic settings. In the bin packing problem, we are given n items with sizes in (0,1] and the goal is to pack them into the minimum number of unit-sized bins. First, we study bin packing under the i.i.d. model, where item sizes are sampled independently and identically from a distribution in (0,1]. Both the distribution and the total number of items are unknown. The items arrive one by one and their sizes are revealed upon their arrival and they must be packed immediately and irrevocably in bins of size 1. We provide a simple meta-algorithm that takes an offline $\alpha$-asymptotic approximation algorithm and provides a polynomial-time $(\alpha + \varepsilon)$-competitive algorithm for online bin packing under the i.i.d. model, where $\varepsilon$&gt;0 is a small constant. Using the AFPTAS for offline bin packing, we thus provide a linear time $(1+\varepsilon)$-competitive algorithm for online bin packing under i.i.d. model, thus settling the problem.
  We then study the random-order model, where an adversary specifies the items, but the order of arrival of items is drawn uniformly at random from the set of all permutations of the items. Kenyon's seminal result [SODA'96] showed that the Best-Fit algorithm has a competitive ratio of at most 3/2 in the random-order model, and conjectured the ratio to be around 1.15. However, it has been a long-standing open problem to break the barrier of 3/2 even for special cases. Recently, Albers et al. [Algorithmica'21] showed an improvement to 5/4 competitive ratio in the special case when all the item sizes are greater than 1/3. For this special case, we settle the analysis by showing that Best-Fit has a competitive ratio of 1. We make further progress by breaking the barrier of 3/2 for the 3-Partition problem, a notoriously hard special case of bin packing, where all item sizes lie in (1/4,1/2].</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.03622v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Ayyadevara, Rajni Dabas, Arindam Khan, K. V. N. Sreenivas</dc:creator>
    </item>
    <item>
      <title>Static Pricing Guarantees for Queueing Systems</title>
      <link>https://arxiv.org/abs/2305.09168</link>
      <description>arXiv:2305.09168v4 Announce Type: replace 
Abstract: We consider a general queueing model with price-sensitive customers in which the service provider seeks to balance two objectives, maximizing the average revenue rate and minimizing the average queue length. Customers arrive according to a Poisson process, observe an offered price, and decide to join the queue if their valuation exceeds the price. The queue is operated first-in first-out, and the service times are exponential. Our model represents applications in areas like make-to-order manufacturing, cloud computing, and food delivery.
  The optimal solution for our model is dynamic; the price changes as the state of the system changes. However, such dynamic pricing policies may be undesirable for a variety of reasons. In this work, we provide performance guarantees for a simple and natural class of static pricing policies which charge a fixed price up to a certain occupancy threshold and then allow no more customers into the system. We provide a series of results showing that such static policies can simultaneously guarantee a constant fraction of the optimal revenue with at most a constant factor increase in expected queue length. For instance, our policy for the M/M/1 setting allows bi-criteria approximations of $(0.5, 1), (0.66, 1.16), (0.75, 1.54)$ and $(0.8, 2)$ for the revenue and queue length, respectively. We also provide guarantees for settings with multiple customer classes and multiple servers, as well as the expected sojourn time objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.09168v4</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jacob Bergquist, Adam N. Elmachtoub</dc:creator>
    </item>
    <item>
      <title>Subgraph Counting in Subquadratic Time for Bounded Degeneracy Graphs</title>
      <link>https://arxiv.org/abs/2410.08376</link>
      <description>arXiv:2410.08376v2 Announce Type: replace 
Abstract: We study the classic problem of subgraph counting, where we wish to determine the number of occurrences of a fixed pattern graph $H$ in an input graph $G$ of $n$ vertices. Our focus is on bounded degeneracy inputs, a rich family of graph classes that also characterizes real-world massive networks. Building on the seminal techniques introduced by Chiba-Nishizeki (SICOMP 1985), a recent line of work has built subgraph counting algorithms for bounded degeneracy graphs. Assuming fine-grained complexity conjectures, there is a complete characterization of patterns $H$ for which linear time subgraph counting is possible. For every $r \geq 6$, there exists an $H$ with $r$ vertices that cannot be counted in linear time.
  In this paper, we initiate a study of subquadratic algorithms for subgraph counting on bounded degeneracy graphs. We prove that when $H$ has at most $9$ vertices, subgraph counting can be done in $\tilde{O}(n^{5/3})$ time. As a secondary result, we give improved algorithms for counting cycles of length at most $10$. Previously, no subquadratic algorithms were known for the above problems on bounded degeneracy graphs.
  Our main conceptual contribution is a framework that reduces subgraph counting in bounded degeneracy graphs to counting smaller hypergraphs in arbitrary graphs. We believe that our results will help build a general theory of subgraph counting for bounded degeneracy graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08376v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Paul-Pena, C. Seshadhri</dc:creator>
    </item>
    <item>
      <title>Output-sensitive Complexity of Multi-Objective Integer Network Flow Problems</title>
      <link>https://arxiv.org/abs/2312.01786</link>
      <description>arXiv:2312.01786v3 Announce Type: replace-cross 
Abstract: This paper addresses the output-sensitive complexity for linear multi-objective integer minimum cost flow (MOIMCF) problems and provides insights about the time complexity for enumerating all supported nondominated vectors. The paper shows that there can not exist an output-polynomial time algorithm for the enumeration of all supported nondominated vectors that determine the vectors in an ordered way in the outcome space unless NP = P. Moreover, novel methods for identifying supported nondominated vectors in bi-objective minimum cost flow (BOIMCF) problems are proposed, accompanied by a numerical comparison between decision- and objective-space methods. A novel, equivalent and more compact formulation of the minimum cost flow ILP formulation used in the e-constrained-scalarization approach is introduced, demonstrating enhanced efficiency in the numerical tests</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01786v3</guid>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David K\"onen, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>Learning Mixtures of Gaussians Using Diffusion Models</title>
      <link>https://arxiv.org/abs/2404.18869</link>
      <description>arXiv:2404.18869v2 Announce Type: replace-cross 
Abstract: We give a new algorithm for learning mixtures of $k$ Gaussians (with identity covariance in $\mathbb{R}^n$) to TV error $\varepsilon$, with quasi-polynomial ($O(n^{\text{poly\,log}\left(\frac{n+k}{\varepsilon}\right)})$) time and sample complexity, under a minimum weight assumption. Our results extend to continuous mixtures of Gaussians where the mixing distribution is supported on a union of $k$ balls of constant radius. In particular, this applies to the case of Gaussian convolutions of distributions on low-dimensional manifolds, or more generally sets with small covering number, for which no sub-exponential algorithm was previously known. Unlike previous approaches, most of which are algebraic in nature, our approach is analytic and relies on the framework of diffusion models. Diffusion models are a modern paradigm for generative modeling, which typically rely on learning the score function (gradient log-pdf) along a process transforming a pure noise distribution, in our case a Gaussian, to the data distribution. Despite their dazzling performance in tasks such as image generation, there are few end-to-end theoretical guarantees that they can efficiently learn nontrivial families of distributions; we give some of the first such guarantees. We proceed by deriving higher-order Gaussian noise sensitivity bounds for the score functions for a Gaussian mixture to show that that they can be inductively learned using piecewise polynomial regression (up to poly-logarithmic degree), and combine this with known convergence results for diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18869v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khashayar Gatmiry, Jonathan Kelner, Holden Lee</dc:creator>
    </item>
    <item>
      <title>A Characterization of List Regression</title>
      <link>https://arxiv.org/abs/2409.19218</link>
      <description>arXiv:2409.19218v2 Announce Type: replace-cross 
Abstract: There has been a recent interest in understanding and characterizing the sample complexity of list learning tasks, where the learning algorithm is allowed to make a short list of $k$ predictions, and we simply require one of the predictions to be correct. This includes recent works characterizing the PAC sample complexity of standard list classification and online list classification.
  Adding to this theme, in this work, we provide a complete characterization of list PAC regression. We propose two combinatorial dimensions, namely the $k$-OIG dimension and the $k$-fat-shattering dimension, and show that they characterize realizable and agnostic $k$-list regression respectively. These quantities generalize known dimensions for standard regression. Our work thus extends existing list learning characterizations from classification to regression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19218v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chirag Pabbaraju, Sahasrajit Sarmasarkar</dc:creator>
    </item>
    <item>
      <title>Anytime-Constrained Equilibria in Polynomial Time</title>
      <link>https://arxiv.org/abs/2410.23637</link>
      <description>arXiv:2410.23637v2 Announce Type: replace-cross 
Abstract: We extend anytime constraints to the Markov game setting and the corresponding solution concept of an anytime-constrained equilibrium (ACE). Then, we present a comprehensive theory of anytime-constrained equilibria that includes (1) a computational characterization of feasible policies, (2) a fixed-parameter tractable algorithm for computing ACE, and (3) a polynomial-time algorithm for approximately computing ACE. Since computing a feasible policy is NP-hard even for two-player zero-sum games, our approximation guarantees are optimal so long as $P \neq NP$. We also develop the first theory of efficient computation for action-constrained Markov games, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23637v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Wed, 05 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jeremy McMahan</dc:creator>
    </item>
  </channel>
</rss>
