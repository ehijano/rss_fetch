<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 21 May 2025 04:02:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>CATS: Clustering-Aggregated and Time Series for Business Customer Purchase Intention Prediction</title>
      <link>https://arxiv.org/abs/2505.13558</link>
      <description>arXiv:2505.13558v1 Announce Type: new 
Abstract: Accurately predicting customers' purchase intentions is critical to the success of a business strategy. Current researches mainly focus on analyzing the specific types of products that customers are likely to purchase in the future, little attention has been paid to the critical factor of whether customers will engage in repurchase behavior. Predicting whether a customer will make the next purchase is a classic time series forecasting task. However, in real-world purchasing behavior, customer groups typically exhibit imbalance - i.e., there are a large number of occasional buyers and a small number of loyal customers. This head-to-tail distribution makes traditional time series forecasting methods face certain limitations when dealing with such problems. To address the above challenges, this paper proposes a unified Clustering and Attention mechanism GRU model (CAGRU) that leverages multi-modal data for customer purchase intention prediction. The framework first performs customer profiling with respect to the customer characteristics and clusters the customers to delineate the different customer clusters that contain similar features. Then, the time series features of different customer clusters are extracted by GRU neural network and an attention mechanism is introduced to capture the significance of sequence locations. Furthermore, to mitigate the head-to-tail distribution of customer segments, we train the model separately for each customer segment, to adapt and capture more accurately the differences in behavioral characteristics between different customer segments, as well as the similar characteristics of the customers within the same customer segment. We constructed four datasets and conducted extensive experiments to demonstrate the superiority of the proposed CAGRU approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13558v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingjie Kuang, Tianchen Zhang, Zhen-Wei Huang, Zhongjie Zeng, Zhe-Yuan Li, Ling Huang, Yuefang Gao</dc:creator>
    </item>
    <item>
      <title>Valid Post-Contextual Bandit Inference</title>
      <link>https://arxiv.org/abs/2505.13897</link>
      <description>arXiv:2505.13897v1 Announce Type: new 
Abstract: We establish an asymptotic framework for the statistical analysis of the stochastic contextual multi-armed bandit problem (CMAB), which is widely employed in adaptively randomized experiments across various fields. While algorithms for maximizing rewards or, equivalently, minimizing regret have received considerable attention, our focus centers on statistical inference with adaptively collected data under the CMAB model. To this end we derive the limit experiment (in the Hajek-Le Cam sense). This limit experiment is highly nonstandard and, applying Girsanov's theorem, we obtain a structural representation in terms of stochastic differential equations. This structural representation, and a general weak convergence result we develop, allow us to obtain the asymptotic distribution of statistics for the CMAB problem. In particular, we obtain the asymptotic distributions for the classical t-test (non-Gaussian), Adaptively Weighted tests, and Inverse Propensity Weighted tests (non-Gaussian). We show that, when comparing both arms, validity of these tests requires the sampling scheme to be translation invariant in a way we make precise. We propose translation-invariant versions of Thompson, tempered greedy, and tempered Upper Confidence Bound sampling. Simulation results corroborate our asymptotic analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13897v1</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramon van den Akker, Bas J. M. Werker, Bo Zhou</dc:creator>
    </item>
    <item>
      <title>The Post Double LASSO for Efficiency Analysis</title>
      <link>https://arxiv.org/abs/2505.14282</link>
      <description>arXiv:2505.14282v1 Announce Type: new 
Abstract: Big data and machine learning methods have become commonplace across economic milieus. One area that has not seen as much attention to these important topics yet is efficiency analysis. We show how the availability of big (wide) data can actually make detection of inefficiency more challenging. We then show how machine learning methods can be leveraged to adequately estimate the primitives of the frontier itself as well as inefficiency using the `post double LASSO' by deriving Neyman orthogonal moment conditions for this problem. Finally, an application is presented to illustrate key differences of the post-double LASSO compared to other approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14282v1</guid>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Christopher Parmeter, Artem Prokhorov, Valentin Zelenyuk</dc:creator>
    </item>
    <item>
      <title>Characterization of Efficient Influence Function for Off-Policy Evaluation Under Optimal Policies</title>
      <link>https://arxiv.org/abs/2505.13809</link>
      <description>arXiv:2505.13809v1 Announce Type: cross 
Abstract: Off-policy evaluation (OPE) provides a powerful framework for estimating the value of a counterfactual policy using observational data, without the need for additional experimentation. Despite recent progress in robust and efficient OPE across various settings, rigorous efficiency analysis of OPE under an estimated optimal policy remains limited. In this paper, we establish a concise characterization of the efficient influence function for the value function under optimal policy within canonical Markov decision process models. Specifically, we provide the sufficient conditions for the existence of the efficient influence function and characterize its expression. We also give the conditions under which the EIF does not exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13809v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoyu Wei</dc:creator>
    </item>
    <item>
      <title>Quantum Reservoir Computing for Realized Volatility Forecasting</title>
      <link>https://arxiv.org/abs/2505.13933</link>
      <description>arXiv:2505.13933v1 Announce Type: cross 
Abstract: Recent advances in quantum computing have demonstrated its potential to significantly enhance the analysis and forecasting of complex classical data. Among these, quantum reservoir computing has emerged as a particularly powerful approach, combining quantum computation with machine learning for modeling nonlinear temporal dependencies in high-dimensional time series. As with many data-driven disciplines, quantitative finance and econometrics can hugely benefit from emerging quantum technologies. In this work, we investigate the application of quantum reservoir computing for realized volatility forecasting. Our model employs a fully connected transverse-field Ising Hamiltonian as the reservoir with distinct input and memory qubits to capture temporal dependencies. The quantum reservoir computing approach is benchmarked against several econometric models and standard machine learning algorithms. The models are evaluated using multiple error metrics and the model confidence set procedures. To enhance interpretability and mitigate current quantum hardware limitations, we utilize wrapper-based forward selection for feature selection, identifying optimal subsets, and quantifying feature importance via Shapley values. Our results indicate that the proposed quantum reservoir approach consistently outperforms benchmark models across various metrics, highlighting its potential for financial forecasting despite existing quantum hardware constraints. This work serves as a proof-of-concept for the applicability of quantum computing in econometrics and financial analysis, paving the way for further research into quantum-enhanced predictive modeling as quantum hardware capabilities continue to advance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13933v1</guid>
      <category>quant-ph</category>
      <category>econ.EM</category>
      <category>q-fin.ST</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyu Li, Chiranjib Mukhopadhyay, Abolfazl Bayat, Ali Habibnia</dc:creator>
    </item>
    <item>
      <title>Individualized Treatment Allocation in Sequential Network Games</title>
      <link>https://arxiv.org/abs/2302.05747</link>
      <description>arXiv:2302.05747v5 Announce Type: replace 
Abstract: Designing individualized allocation of treatments so as to maximize the equilibrium welfare of interacting agents has many policy-relevant applications. Focusing on sequential decision games of interacting agents, this paper develops a method to obtain optimal treatment assignment rules that maximize a social welfare criterion by evaluating stationary distributions of outcomes. Stationary distributions in sequential decision games are given by Gibbs distributions, which are difficult to optimize with respect to a treatment allocation due to analytical and computational complexity. We apply a variational approximation to the stationary distribution and optimize the approximated equilibrium welfare with respect to treatment allocation using a greedy optimization algorithm. We characterize the performance of the variational approximation, deriving a performance guarantee for the greedy optimization algorithm via a welfare regret bound. We implement our proposed method in simulation exercises and an empirical application using the Indian microfinance data (Banerjee et al., 2013), and show it delivers significant welfare gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.05747v5</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Toru Kitagawa, Guanyi Wang</dc:creator>
    </item>
    <item>
      <title>Don't (fully) exclude me, it's not necessary! Causal inference with semi-IVs</title>
      <link>https://arxiv.org/abs/2303.12667</link>
      <description>arXiv:2303.12667v4 Announce Type: replace 
Abstract: This paper proposes semi-instrumental variables (semi-IVs) as an alternative to instrumental variables (IVs) to identify the causal effect of a binary (or discrete) endogenous treatment. A semi-IV is a less restrictive form of instrument: it affects the selection into treatment but is excluded only from one, not necessarily both, potential outcomes. Having two semi-IVs, one excluded from the potential outcome under treatment and the other from the potential outcome under control, is sufficient to nonparametrically point identify local average treatment effect (LATE) and marginal treatment effect (MTE) parameters. In practice, semi-IVs provide a solution to the challenge of finding valid IVs because they are easier to find: many selection-specific shocks, policies, costs, or benefits are valid semi-IVs. As an application, I estimate the returns to working in the manufacturing sector using sector-specific semi-IVs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.12667v4</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christophe Bruneel-Zupanc</dc:creator>
    </item>
    <item>
      <title>An early warning system for emerging markets</title>
      <link>https://arxiv.org/abs/2404.03319</link>
      <description>arXiv:2404.03319v2 Announce Type: replace 
Abstract: Financial markets of emerging economies are vulnerable to extreme and cascading information spillovers, surges, sudden stops and reversals. With this in mind, we develop a new online early warning system (EWS) to detect what is referred to as `concept drift' in machine learning, as a `regime shift' in economics and as a `change-point' in statistics. The system explores nonlinearities in financial information flows and remains robust to heavy tails and dependence of extremes. The key component is the use of conditional entropy, which captures shifts in various channels of information transmission, not only in conditional mean or variance. We design a baseline method, and adapt it to a modern high-dimensional setting through the use of random forests and copulas. We show the relevance of each system component to the analysis of emerging markets. The new approach detects significant shifts where conventional methods fail. We explore when this happens using simulations and we provide two illustrations when the methods generate meaningful warnings. The ability to detect changes early helps improve resilience in emerging markets against shocks and provides new economic and financial insights into their operation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03319v2</guid>
      <category>econ.EM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artem Kraevskiy, Artem Prokhorov, Evgeniy Sokolovskiy</dc:creator>
    </item>
    <item>
      <title>On Selection of Cross-Section Averages in Non-stationary Environments</title>
      <link>https://arxiv.org/abs/2505.08615</link>
      <description>arXiv:2505.08615v2 Announce Type: replace 
Abstract: Information criteria (IC) have been widely used in factor models to estimate an unknown number of latent factors. It has recently been shown that IC perform well in Common Correlated Effects (CCE) and related setups in selecting a set of cross-section averages (CAs) sufficient for the factor space under stationary factors. As CAs can proxy non-stationary factors, it is tempting to claim such generality of IC, too. We show formally and in simulations that IC have a severe underselection issue even under very mild forms of factor non-stationarity, which goes against the sentiment in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.08615v2</guid>
      <category>econ.EM</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jan Ditzen, Ovidijus Stauskas</dc:creator>
    </item>
    <item>
      <title>Statistically Significant Linear Regression Coefficients Solely Driven By Outliers In Finite-sample Inference</title>
      <link>https://arxiv.org/abs/2505.10738</link>
      <description>arXiv:2505.10738v2 Announce Type: replace-cross 
Abstract: In this paper, we investigate the impact of outliers on the statistical significance of coefficients in linear regression. We demonstrate, through numerical simulation using R, that a single outlier can cause an otherwise insignificant coefficient to appear statistically significant. We compare this with robust Huber regression, which reduces the effects of outliers. Afterwards, we approximate the influence of a single outlier on estimated regression coefficients and discuss common diagnostic statistics to detect influential observations in regression (e.g., studentized residuals). Furthermore, we relate this issue to the optional normality assumption in simple linear regression [14], required for exact finite-sample inference but asymptotically justified for large n by the Central Limit Theorem (CLT). We also address the general dangers of relying solely on p-values without performing adequate regression diagnostics. Finally, we provide a brief overview of regression methods and discuss how they relate to the assumptions of the Gauss-Markov theorem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.10738v2</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 21 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Felix Reichel</dc:creator>
    </item>
  </channel>
</rss>
