<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 27 Nov 2025 02:40:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Large Scale Community-Aware Network Generation</title>
      <link>https://arxiv.org/abs/2511.19717</link>
      <description>arXiv:2511.19717v1 Announce Type: new 
Abstract: Community detection, or network clustering, is used to identify latent community structure in networks. Due to the scarcity of labeled ground truth in real-world networks, evaluating these algorithms poses significant challenges. To address this, researchers use synthetic network generators that produce networks with ground-truth community labels. RECCS is one such algorithm that takes a network and its clustering as input and generates a synthetic network through a modular pipeline. Each generated ground truth cluster preserves key characteristics of the corresponding input cluster, including connectivity, minimum degree, and degree sequence distribution. The output consists of a synthetically generated network, and disjoint ground truth cluster labels for all nodes. In this paper, we present two enhanced versions: RECCS+ and RECCS++. RECCS+ maintains algorithmic fidelity to the original RECCS while introducing parallelization through an orchestrator that coordinates algorithmic components across multiple processes and employs multithreading. RECCS++ builds upon this foundation with additional algorithmic optimizations to achieve further speedup. Our experimental results demonstrate that RECCS+ and RECCS++ achieve speedups of up to 49x and 139x respectively on our benchmark datasets, with RECCS++'s additional performance gains involving a modest accuracy tradeoff. With this newfound performance, RECCS++ can now scale to networks with over 100 million nodes and nearly 2 billion edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19717v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vikram Ramavarapu, Jo\~ao Alfredo Cardoso Lamy, Mohammad Dindoost, David A. Bader</dc:creator>
    </item>
    <item>
      <title>Modelling the Spread of Toxicity and Exploring its Mitigation on Online Social Networks</title>
      <link>https://arxiv.org/abs/2511.20546</link>
      <description>arXiv:2511.20546v1 Announce Type: new 
Abstract: Hate speech on online platforms has been credibly linked to multiple instances of real world violence. This calls for an urgent need to understand how toxic content spreads and how it might be mitigated on online social networks, and expectedly has been the topic of extensive research in recent times. Prior work has largely modelled hate through epidemic or spread activation based diffusion models, in which the users are often divided into two categories, hateful or not. In this work, users are treated as transformers of toxicity, based on how they respond to incoming toxicity. Compared with the incoming toxicity, users amplify, attenuate, or replicate (effectively, transform) the toxicity and send it forward. We do a temporal analysis of toxicity on Twitter, Koo and Gab and find that (a) toxicity is not conserved in the network; (b) only a subset of users change behaviour over time; and (c) there is no evidence of homophily among behaviour-changing users. In our model, each user transforms incoming toxicity by applying a "shift" to it prior to sending it forward. Based on this, we develop a network model of toxicity spread that incorporates time-varying behaviour of users. We find that the "shift" applied by a user is dependent on the input toxicity and the category. Based on this finding, we propose an intervention strategy for toxicity reduction. This is simulated by deploying peace-bots. Through experiments on both real-world and synthetic networks, we demonstrate that peace-bot interventions can reduce toxicity, though their effectiveness depends on network structure and placement strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20546v1</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aatman Vaidya, Harsh Bhagat, Seema Nagar, Amit A. Nanavati</dc:creator>
    </item>
    <item>
      <title>Rethinking Semi-Supervised Node Classification with Self-Supervised Graph Clustering</title>
      <link>https://arxiv.org/abs/2511.19976</link>
      <description>arXiv:2511.19976v1 Announce Type: cross 
Abstract: The emergence of graph neural networks (GNNs) has offered a powerful tool for semi-supervised node classification tasks. Subsequent studies have achieved further improvements through refining the message passing schemes in GNN models or exploiting various data augmentation techniques to mitigate limited supervision. In real graphs, nodes often tend to form tightly-knit communities/clusters, which embody abundant signals for compensating label scarcity in semi-supervised node classification but are not explored in prior methods.
  Inspired by this, this paper presents NCGC that integrates self-supervised graph clustering and semi-supervised classification into a unified framework. Firstly, we theoretically unify the optimization objectives of GNNs and spectral graph clustering, and based on that, develop soft orthogonal GNNs (SOGNs) that leverage a refined message passing paradigm to generate node representations for both classification and clustering. On top of that, NCGC includes a self-supervised graph clustering module that enables the training of SOGNs for learning representations of unlabeled nodes in a self-supervised manner. Particularly, this component comprises two non-trivial clustering objectives and a Sinkhorn-Knopp normalization that transforms predicted cluster assignments into balanced soft pseudo-labels. Through combining the foregoing clustering module with the classification model using a multi-task objective containing the supervised classification loss on labeled data and self-supervised clustering loss on unlabeled data, NCGC promotes synergy between them and achieves enhanced model capacity. Our extensive experiments showcase that the proposed NCGC framework consistently and considerably outperforms popular GNN models and recent baselines for semi-supervised node classification on seven real graphs, when working with various classic GNN backbones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.19976v1</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songbo Wang, Renchi Yang, Yurui Lai, Xiaoyang Lin, Tsz Nam Chan</dc:creator>
    </item>
    <item>
      <title>A Machine Learning Approach for Detection of Mental Health Conditions and Cyberbullying from Social Media</title>
      <link>https://arxiv.org/abs/2511.20001</link>
      <description>arXiv:2511.20001v1 Announce Type: cross 
Abstract: Mental health challenges and cyberbullying are increasingly prevalent in digital spaces, necessitating scalable and interpretable detection systems. This paper introduces a unified multiclass classification framework for detecting ten distinct mental health and cyberbullying categories from social media data. We curate datasets from Twitter and Reddit, implementing a rigorous "split-then-balance" pipeline to train on balanced data while evaluating on a realistic, held-out imbalanced test set. We conducted a comprehensive evaluation comparing traditional lexical models, hybrid approaches, and several end-to-end fine-tuned transformers. Our results demonstrate that end-to-end fine-tuning is critical for performance, with the domain-adapted MentalBERT emerging as the top model, achieving an accuracy of 0.92 and a Macro F1 score of 0.76, surpassing both its generic counterpart and a zero-shot LLM baseline. Grounded in a comprehensive ethical analysis, we frame the system as a human-in-the-loop screening aid, not a diagnostic tool. To support this, we introduce a hybrid SHAPLLM explainability framework and present a prototype dashboard ("Social Media Screener") designed to integrate model predictions and their explanations into a practical workflow for moderators. Our work provides a robust baseline, highlighting future needs for multi-label, clinically-validated datasets at the critical intersection of online safety and computational mental health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20001v1</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edward Ajayi, Martha Kachweka, Mawuli Deku, Emily Aiken</dc:creator>
    </item>
    <item>
      <title>Realistic gossip in Trust Game on networks: the GODS model</title>
      <link>https://arxiv.org/abs/2511.20248</link>
      <description>arXiv:2511.20248v1 Announce Type: cross 
Abstract: Gossip has been shown to be a relatively efficient solution to problems of cooperation in reputation-based systems of exchange, but many studies don't conceptualize gossiping in a realistic way, often assuming near-perfect information or broadcast-like dynamics of its spread. To solve this problem, we developed an agent-based model that pairs realistic gossip processes with different variants of Trust Game. The results show that cooperators suffer when local interactions govern spread of gossip, because they cannot discriminate against defectors. Realistic gossiping increases the overall amount of resources, but is more likely to promote defection. Moreover, even partner selection through dynamic networks can lead to high payoff inequalities among agent types. Cooperators face a choice between outcompeting defectors and overall growth. By blending direct and indirect reciprocity with reputations we show that gossiping increases the efficiency of cooperation by an order of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20248v1</guid>
      <category>cs.MA</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <category>econ.TH</category>
      <category>physics.soc-ph</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jan Majewski, Francesca Giardini</dc:creator>
    </item>
    <item>
      <title>Limit Order Book Dynamics in Matching Markets: Microstructure, Spread, and Execution Slippage</title>
      <link>https://arxiv.org/abs/2511.20606</link>
      <description>arXiv:2511.20606v2 Announce Type: cross 
Abstract: Conventional models of matching markets assume that monetary transfers can clear markets by compensating for utility differentials. However, empirical patterns show that such transfers often fail to close structural preference gaps. This paper introduces a market microstructure framework that models matching decisions as a limit order book system with rigid bid ask spreads. Individual preferences are represented by a latent preference state matrix, where the spread between an agent's internal ask price (the unconditional maximum) and the market's best bid (the reachable maximum) creates a structural liquidity constraint. We establish a Threshold Impossibility Theorem showing that linear compensation cannot close these spreads unless it induces a categorical identity shift. A dynamic discrete choice execution model further demonstrates that matches occur only when the market to book ratio crosses a time decaying liquidity threshold, analogous to order execution under inventory pressure. Numerical experiments validate persistent slippage, regional invariance of preference orderings, and high tier zero spread executions. The model provides a unified microstructure explanation for matching failures, compensation inefficiency, and post match regret in illiquid order driven environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.20606v2</guid>
      <category>q-fin.TR</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yao Wu</dc:creator>
    </item>
    <item>
      <title>A multilevel network approach to revealing patterns of online political selective exposure</title>
      <link>https://arxiv.org/abs/2408.03828</link>
      <description>arXiv:2408.03828v2 Announce Type: replace 
Abstract: Selective exposure, individuals' inclination to seek out information that supports their beliefs while avoiding information that contradicts them, plays an important role in the emergence of polarization and echo chambers. In the political domain, selective exposure is usually measured on a left-right ideology scale, ignoring finer details. To bridge the gap, this work introduces a multilevel analysis framework based on a multi-scale community detection approach. To test this approach, we combine survey and Twitter/X data collected during the 2022 Brazilian Presidential Election and investigate selective exposure patterns among survey respondents in their choices of whom to follow. We construct a bipartite network connecting survey respondents with political influencers and project it onto the influencer nodes. Applying multi-scale community detection to this projection uncovers a hierarchical clustering of political influencers. Different indices of selective exposure suggest that the characteristics of the influencer communities engaged by survey respondents vary with the level of community resolution. This finding indicates that online political selective exposure exhibits a more complex structure than a mere left-right dichotomy. Moreover, depending on the resolution level we consider, we find different associations between network indices of exposure patterns and 189 individual attributes of the survey respondents. For example, at finer levels, survey respondents' Community Overlap is associated with several factors, such as ideological position, demographics, news consumption frequency, and incivility perception. In comparison, only their ideological position is a significant factor at coarser levels. Our work demonstrates that measuring selective exposure at a single level, such as left and right, misses important information necessary to capture this phenomenon correctly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03828v2</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yuan Zhang, Laia Castro Herrero, Frank Esser, Alexandre Bovet</dc:creator>
    </item>
    <item>
      <title>Modelling the Closed Loop Dynamics Between a Social Media Recommender System and Users' Opinions</title>
      <link>https://arxiv.org/abs/2507.19792</link>
      <description>arXiv:2507.19792v2 Announce Type: replace 
Abstract: This paper proposes a mathematical model to study the coupled dynamics of a Recommender System (RS) algorithm and content consumers (users). The model posits that a large population of users, each with an opinion, consumes personalised content recommended by the RS. The RS can select from a range of content to recommend, based on users' past engagement, while users can engage with the content (like, watch), and in doing so, users' opinions evolve. This occurs repeatedly to capture the endless content available for user consumption on social media. We employ a campaign of Monte Carlo simulations to study how recommender systems influence users' opinions, and in turn how users' opinions shape the subsequent recommended content. Both the performance of the RS (e.g., how users engage with the content) and the polarisation and radicalisation of users' opinions are of interest. We find that different opinion distributions are more susceptible to becoming polarised than others, many content stances are ineffective in changing user opinions, and creating viral content is an effective measure in combating polarisation of opinions.
  This work has been submitted to the IEEE for possible publication. Copyright may be transferred without notice, after which this version may no longer be accessible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19792v2</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ella C. Davidson, Mengbin Ye</dc:creator>
    </item>
    <item>
      <title>A Multi-echelon Demand-driven Supply Chain Model for Proactive Optimal Control of Epidemics: Insights from a COVID-19 Study</title>
      <link>https://arxiv.org/abs/2510.16969</link>
      <description>arXiv:2510.16969v2 Announce Type: replace 
Abstract: Timely and effective decision-making is critical during epidemics to reduce preventable infections and deaths. This demands integrated models that jointly capture disease dynamics, vaccine distribution, regional disparities, and behavioral responses. However, most existing approaches decouple epidemic forecasting from logistics planning, hindering adaptive and regionally responsive interventions. We propose a novel epidemiological-optimization framework that jointly models epidemic progression and a multiscale vaccine supply chain. The model incorporates spatio-temporally varying effective infection rates to reflect regional policy and behavioral dynamics. It supports coordinated, data-driven decision-making across spatial scales through two formulations: a multi-objective Gini-based model and a knapsack-based model that leverages regional vulnerability indicators for tractability and improved mitigation. To address computational complexity, we design two scalable heuristic decomposition algorithms inspired by the Benders decomposition. The model is validated using COVID-19 data in the U.S.. We introduce SARIMA-based forecasting as a novel approach for validating epidemic-optimization models under data limitations. The results show that our approach can prevent more than 2 million infections and 30,000 deaths in just six months while significantly improving the accessibility of vaccines in underserved regions. Our framework demonstrates that integrating fairness and epidemic dynamics with vaccine logistics leads to superior outcomes compared to traditional myopic policies. Fairness improves overall efficiency in the long term by prioritizing the most vulnerable populations, leading to better long-term public health outcomes. The model offers policymakers a scalable and operationally relevant tool to strengthen preparedness and ensure a more effective and equitable response to epidemics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.16969v2</guid>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kimiya Jozani, Nihal A. Sageer, Hode Eldardiry, Sait Tunc, Esra Buyuktahtakin Toy</dc:creator>
    </item>
    <item>
      <title>AI-Mediated Communication Reshapes Social Structure in Opinion-Diverse Groups</title>
      <link>https://arxiv.org/abs/2510.21984</link>
      <description>arXiv:2510.21984v2 Announce Type: replace 
Abstract: Group segregation or cohesion can emerge from micro-level communication, and AI-assisted messaging may shape this process. Here, we report a preregistered online experiment (N = 557 across 60 sessions) in which participants discussed controversial political topics over multiple rounds and could freely change groups. Some participants received real-time message suggestions from a large language model (LLM), either personalized to their stance (individual assistance) or incorporating their group members' perspectives (relational assistance). We find that small variations in AI-mediated communication cascade into macro-level differences in group composition. Participants with individual assistance send more messages and show greater stance-based clustering, whereas those with relational assistance use more receptive language and form more heterogeneous ties. Hybrid expressive processes-jointly produced by humans and AI-can reshape collective organization. The patterns of structural division and cohesion depend on how AI incorporates users' interaction context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.21984v2</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faria Huq, Elijah L. Claggett, Hirokazu Shirado</dc:creator>
    </item>
    <item>
      <title>Multiple Randomization Designs: Estimation and Inference with Interference</title>
      <link>https://arxiv.org/abs/2112.13495</link>
      <description>arXiv:2112.13495v3 Announce Type: replace-cross 
Abstract: In this study we introduce a new class of experimental designs. In a classical randomized controlled trial (RCT), or A/B test, a randomly selected subset of a population of units (e.g., individuals, plots of land, or experiences) is assigned to a treatment (treatment A), and the remainder of the population is assigned to the control treatment (treatment B). The difference in average outcome by treatment group is an estimate of the average effect of the treatment. However, motivating our study, the setting for modern experiments is often different, with the outcomes and treatment assignments indexed by multiple populations. For example, outcomes may be indexed by buyers and sellers, by content creators and subscribers, by drivers and riders, or by travelers and airlines and travel agents, with treatments potentially varying across these indices. Spillovers or interference can arise from interactions between units across populations. For example, sellers' behavior may depend on buyers' treatment assignment, or vice versa. This can invalidate the simple comparison of means as an estimator for the average effect of the treatment in classical RCTs. We propose new experiment designs for settings in which multiple populations interact. We show how these designs allow us to study questions about interference that cannot be answered by classical randomized experiments. Finally, we develop new statistical methods for analyzing these Multiple Randomization Designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2112.13495v3</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Masoero, Suhas Vijaykumar, Thomas Richardson, James McQueen, Ido Rosen, Brian Burdick, Pat Bajari, Guido Imbens</dc:creator>
    </item>
    <item>
      <title>PriME: Privacy-aware Membership profile Estimation in networks</title>
      <link>https://arxiv.org/abs/2406.02794</link>
      <description>arXiv:2406.02794v2 Announce Type: replace-cross 
Abstract: This paper presents a novel approach to estimating community membership probabilities for network vertices generated by the Degree Corrected Mixed Membership Stochastic Block Model while preserving individual edge privacy. Operating within the $\varepsilon$-edge local differential privacy framework, we introduce an optimal private algorithm based on a symmetric edge flip mechanism and spectral clustering for accurate estimation of vertex community memberships. We conduct a comprehensive analysis of the estimation risk and establish the optimality of our procedure by providing matching lower bounds to the minimax risk under privacy constraints. To validate our approach, we demonstrate its performance through numerical simulations and its practical application to real-world data. This work represents a significant step forward in balancing accurate community membership estimation with stringent privacy preservation in network data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02794v2</guid>
      <category>stat.ME</category>
      <category>cs.SI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhinav Chakraborty, Sayak Chatterjee, Sagnik Nandy</dc:creator>
    </item>
    <item>
      <title>Demystifying Higher-Order Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2406.12841</link>
      <description>arXiv:2406.12841v4 Announce Type: replace-cross 
Abstract: Higher-order graph neural networks (HOGNNs) and the related architectures from Topological Deep Learning are an important class of GNN models that harness polyadic relations between vertices beyond plain edges. They have been used to eliminate issues such as over-smoothing or over-squashing, to significantly enhance the accuracy of GNN predictions, to improve the expressiveness of GNN architectures, and for numerous other goals. A plethora of HOGNN models have been introduced, and they come with diverse neural architectures, and even with different notions of what the "higher-order" means. This richness makes it very challenging to appropriately analyze and compare HOGNN models, and to decide in what scenario to use specific ones. To alleviate this, we first design an in-depth taxonomy and a blueprint for HOGNNs. This facilitates designing models that maximize performance. Then, we use our taxonomy to analyze and compare the available HOGNN models. The outcomes of our analysis are synthesized in a set of insights that help to select the most beneficial GNN model in a given scenario, and a comprehensive list of challenges and opportunities for further research into more powerful HOGNNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12841v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Pattern Analysis and Machine Intelligence, 2025</arxiv:journal_reference>
      <dc:creator>Maciej Besta, Florian Scheidl, Lukas Gianinazzi, Grzegorz Kwasniewski, Shachar Klaiman, J\"urgen M\"uller, Torsten Hoefler</dc:creator>
    </item>
    <item>
      <title>AI-in-the-Loop: Privacy Preserving Real-Time Scam Detection and Conversational Scambaiting by Leveraging LLMs and Federated Learning</title>
      <link>https://arxiv.org/abs/2509.05362</link>
      <description>arXiv:2509.05362v3 Announce Type: replace-cross 
Abstract: Scams exploiting real-time social engineering -- such as phishing, impersonation, and phone fraud -- remain a persistent and evolving threat across digital platforms. Existing defenses are largely reactive, offering limited protection during active interactions. We propose a privacy-preserving, AI-in-the-loop framework that proactively detects and disrupts scam conversations in real time. The system combines instruction-tuned artificial intelligence with a safety-aware utility function that balances engagement with harm minimization, and employs federated learning to enable continual model updates without raw data sharing. Experimental evaluations show that the system produces fluent and engaging responses (perplexity as low as 22.3, engagement $\approx$0.80), while human studies confirm significant gains in realism, safety, and effectiveness over strong baselines. In federated settings, models trained with FedAvg sustain up to 30 rounds while preserving high engagement ($\approx$0.80), strong relevance ($\approx$0.74), and low PII leakage ($\leq$0.0085). Even with differential privacy, novelty and safety remain stable, indicating that robust privacy can be achieved without sacrificing performance. The evaluation of guard models (LlamaGuard, LlamaGuard2/3, MD-Judge) shows a straightforward pattern: stricter moderation settings reduce the chance of exposing personal information, but they also limit how much the model engages in conversation. In contrast, more relaxed settings allow longer and richer interactions, which improve scam detection, but at the cost of higher privacy risk. To our knowledge, this is the first framework to unify real-time scam-baiting, federated privacy preservation, and calibrated safety moderation into a proactive defense paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.05362v3</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ismail Hossain, Sai Puppala, Md Jahangir Alam, Sajedul Talukder</dc:creator>
    </item>
    <item>
      <title>Computational Turing Test Reveals Systematic Differences Between Human and AI Language</title>
      <link>https://arxiv.org/abs/2511.04195</link>
      <description>arXiv:2511.04195v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) are increasingly used in the social sciences to simulate human behavior, based on the assumption that they can generate realistic, human-like text. Yet this assumption remains largely untested. Existing validation efforts rely heavily on human-judgment-based evaluations -- testing whether humans can distinguish AI from human output -- despite evidence that such judgments are blunt and unreliable. As a result, the field lacks robust tools for assessing the realism of LLM-generated text or for calibrating models to real-world data. This paper makes two contributions. First, we introduce a computational Turing test: a validation framework that integrates aggregate metrics (BERT-based detectability and semantic similarity) with interpretable linguistic features (stylistic markers and topical patterns) to assess how closely LLMs approximate human language within a given dataset. Second, we systematically compare nine open-weight LLMs across five calibration strategies -- including fine-tuning, stylistic prompting, and context retrieval -- benchmarking their ability to reproduce user interactions on X (formerly Twitter), Bluesky, and Reddit. Our findings challenge core assumptions in the literature. Even after calibration, LLM outputs remain clearly distinguishable from human text, particularly in affective tone and emotional expression. Instruction-tuned models underperform their base counterparts, and scaling up model size does not enhance human-likeness. Crucially, we identify a trade-off: optimizing for human-likeness often comes at the cost of semantic fidelity, and vice versa. These results provide a much-needed scalable framework for validation and calibration in LLM simulations -- and offer a cautionary note about their current limitations in capturing human communication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04195v2</guid>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <pubDate>Wed, 26 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicol\`o Pagan, Petter T\"ornberg, Christopher A. Bail, Anik\'o Hann\'ak, Christopher Barrie</dc:creator>
    </item>
  </channel>
</rss>
