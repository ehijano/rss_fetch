<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 28 May 2025 01:54:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>EtherBee: A Global Dataset of Ethereum Node Performance Measurements Coupled with Honeypot Interactions and Full Network Sessions</title>
      <link>https://arxiv.org/abs/2505.18290</link>
      <description>arXiv:2505.18290v1 Announce Type: new 
Abstract: We introduce EtherBee, a global dataset integrating detailed Ethereum node metrics, network traffic metadata, and honeypot interaction logs collected from ten geographically diverse vantage points over three months. By correlating node data with granular network sessions and security events, EtherBee provides unique insights into benign and malicious activity, node stability, and network-level threats in the Ethereum peer-to-peer network. A case study shows how client-based optimizations can unintentionally concentrate the network geographically, impacting resilience and censorship resistance. We publicly release EtherBee to promote further investigations into performance, reliability, and security in decentralized networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18290v1</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Scott Seidenberger, Anindya Maiti</dc:creator>
    </item>
    <item>
      <title>Evaluation of Indoor/Outdoor Sharing in the Unlicensed 6 GHz Band</title>
      <link>https://arxiv.org/abs/2505.18359</link>
      <description>arXiv:2505.18359v1 Announce Type: new 
Abstract: Standard Power (SP) Wi-Fi 6E in the U.S. is just beginning to be deployed outdoors in the shared but unlicensed 6 GHz band under the control of an Automated Frequency Coordination (AFC) system to protect incumbents, while low-power-indoor (LPI) usage has been steadily increasing over the past 2 years. In this paper, we present the first comprehensive measurements and analyses of a SP Wi-Fi 6E deployment at the University of Notre Dame's football stadium, with 902 access points and a seating capacity of 80,000, coexisting with LPI deployments in adjacent buildings. Measurement campaigns were conducted during and after games, outdoors and indoors to fully characterize the performance of SP Wi-Fi 6E, interactions between SP and LPI and potential for interference to incumbents. Our main conclusions are: (i) in a very short time of about 2 months, the percentage of Wi-Fi 6E client connections is already 14% indicating rapid adoption, (ii) dense SP operation outdoors can negatively impact LPI deployments indoors, depending on building loss, indicating the need to carefully consider hybrid indoor-outdoor sharing deployments, and (iii) spectrum analyzer results indicate an aggregate signal level increase of approximately 10 dB in a Wi-Fi channel during peak usage which could potentially lead to interference since the AFC does not consider aggregate interference when allocating permitted power levels. These results from real-world deployments can inform spectrum policy in other bands where similar sharing mechanisms are being considered, such as 7.125 - 8.4 GHz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18359v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seda Dogan-Tusha, Armed Tusha, Muhammad Iqbal Rochman, Hossein Nasiri, Joshua Roy Palathinkal, Mike Atkins, Monisha Ghosh</dc:creator>
    </item>
    <item>
      <title>Neutral-Hosts In The Shared Mid-Bands: Addressing Indoor Cellular Performance</title>
      <link>https://arxiv.org/abs/2505.18360</link>
      <description>arXiv:2505.18360v1 Announce Type: new 
Abstract: The 3.55 - 3.7 GHz Citizens Broadband Radio Service (CBRS) band in the U.S., shared with incumbent Navy radars, is witnessing increasing deployments both indoors and outdoors using a shared, licensed model. Among the many use-cases of such private networks is the indoor neutral-host, where cellular customers of Mobile Network Operators (MNOs) can be seamlessly served indoors over CBRS with improved performance, since building loss reduces the indoor signal strength of mid-band 5G cellular signals considerably. In this paper, we present the first detailed measurements and analyses of a real-world deployment of an indoor private network serving as a neutral-host in the CBRS band serving two MNOs. Our findings demonstrate significant advantages: (i) minimal outdoor interference from the CBRS network due to over 22 dB median penetration loss, ensuring compatibility with incumbent users; (ii) substantial indoor performance gains with up to 535$\times$ and 33$\times$ median downlink and uplink throughput improvements, respectively, compared to the worst-performing MNO; (iii) reduced uplink transmit power for user devices (median 12 dB reduction), increasing energy efficiency; and (iv) significant capacity offload from the MNO network (median 233 resource blocks/slot freed in 5G), allowing MNOs to better serve outdoor users. These results highlight the potential of low-power indoor CBRS deployments to improve performance, increase spectrum efficiency, and support coexistence with current and future incumbents, e.g., the 3.1 - 3.45 GHz band being considered for sharing with federal incumbents in the U.S.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18360v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Iqbal Rochman, Joshua Roy Palathinkal, Vanlin Sathya, Mehmet Yavuz, Monisha Ghosh</dc:creator>
    </item>
    <item>
      <title>ALLSTaR: Automated LLM-Driven Scheduler Generation and Testing for Intent-Based RAN</title>
      <link>https://arxiv.org/abs/2505.18389</link>
      <description>arXiv:2505.18389v2 Announce Type: new 
Abstract: The evolution toward open, programmable O-RAN and AI-RAN 6G networks creates unprecedented opportunities for Intent-Based Networking (IBN) to dynamically optimize RAN[...]. However, applying IBN effectively to the RAN scheduler [...] remains a significant challenge. Current approaches predominantly rely on coarse-grained network slicing, lacking the granularity for dynamic adaptation to individual user conditions and traffic patterns. Despite the existence of a vast body of scheduling algorithms [...], their practical utilization is hindered by implementation heterogeneity, insufficient systematic evaluation in production environments, and the complexity of developing high-performance scheduler implementations.[...] To address these limitations, we propose ALLSTaR (Automated LLm-driven Scheduler generation and Testing for intent-based RAN), a novel framework leveraging LLMs for automated, intent-driven scheduler design, implementation, and evaluation. ALLSTaR interprets NL intents, automatically generates functional scheduler code from the research literature using OCR and LLMs, and intelligently matches operator intents to the most suitable scheduler(s). Our implementation deploys these schedulers as O-RAN dApps, enabling on-the-fly deployment and testing on a production-grade, 5G-compliant testbed. This approach has enabled the largest-scale OTA experimental comparison of 18 scheduling algorithms automatically synthesized from the academic literature. The resulting performance profiles serve as the input for our Intent-Based Scheduling (IBS) framework, which dynamically selects and deploys appropriate schedulers that optimally satisfy operator intents. We validate our approach through multiple use cases unattainable with current slicing-based optimization techniques, demonstrating fine-grained control based on buffer status, physical layer conditions, and heterogeneous traffic types</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18389v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxime Elkael, Michele Polese, Reshma Prasad, Stefano Maxenti, Tommaso Melodia</dc:creator>
    </item>
    <item>
      <title>The Dual Horizon: A Rendezvous of Computing and Communication Services at the Optical Layer in Optical Computing-Communication Integrated Network</title>
      <link>https://arxiv.org/abs/2505.18753</link>
      <description>arXiv:2505.18753v1 Announce Type: new 
Abstract: With the significant advancements in optical computing platforms recently capable of performing various primitive operations, a seamless integration of optical computing into very fabric of optical communication links is envisioned, paving the way for the advent of \textit{optical computing-communication integrated network}, which provides computing services at the ligthpath scale, alongside the traditional high-capacity communication ones. This necessitates a paradigm shift in optical node architecture, moving away from the conventional optical-bypass design that avoids lightpath interference crossing the same node, toward leveraging such interference for computation. Such new computing capability at the optical layer appears to be a good match with the growing needs of geo-distributed machine learning, where the training of large-scale models and datasets spans geographically diverse nodes, and intermediate results require further aggregation/computation to produce the desired outcomes for the destination node. To address this potential use case, an illustrative example is presented, which highlights the merit of providing in-network optical computing services in comparison with the traditional optical-bypass mode in the context of distributed learning scenarios taking place at two source nodes, and partial results are then optically aggregated to the destination. We then formulate the new \textit{routing, wavelength and computing assignment problem} arisen in serving computing requests, which could be considered as an extension of the traditional routing and wavelength assignment, that is used to accommodate the transmission requests. Simulation results performed on the realistic COST239 topology demonstrate the promising spectral efficiency gains achieved through the \textit{optical computing-communication integrated network} compared to the optical-bypass model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18753v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dao Thanh Hai, Isaac Woungang</dc:creator>
    </item>
    <item>
      <title>Evaluation and Performance Analysis of the Ryu Controller in Various Network Scenarios</title>
      <link>https://arxiv.org/abs/2505.19290</link>
      <description>arXiv:2505.19290v1 Announce Type: new 
Abstract: Software-defined networking (SDN) represents a revolutionary shift in network technology by decoupling the data plane from the control plane.}In this architecture, all network decision-making processes are centralized in a controller, meaning each switch receives routing information from the controller and forwards network packets accordingly. This clearly highlights the crucial role that controllers play in the overall performance of SDN. Ryu is one of the most widely used SDN controllers, known for its ease of use in research due to its support for Python programming. This makes Ryu a suitable option for experimental and academic studies. In this research, we evaluate the performance of the Ryu controller based on various network metrics and across different network topologies. For experimental analysis, we use Mininet, a powerful network emulation tool that enables the creation of diverse network structures and the connection of switches to controllers. To facilitate the experiments, we developed a Python-based script that executes various network scenarios, connects to different controllers, and captures and stores the results. This study not only provides a comprehensive performance evaluation of the Ryu controller but also paves the way for evaluating other SDN controllers in future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19290v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmadreza Montazerolghaem, Somaye Imanpour</dc:creator>
    </item>
    <item>
      <title>Leveraging Large Language Models to Contextualize Network Measurements</title>
      <link>https://arxiv.org/abs/2505.19305</link>
      <description>arXiv:2505.19305v1 Announce Type: new 
Abstract: With the worldwide growth of remote communication and telepresence, network measurements form a cornerstone of effective performance assessment and diagnostics for Internet users. Most often, users seek for overall connection performance measurement using publicly available tools (also known as `speed tests') that provide an overview of their connection's throughput and latency. However, extracting meaningful insights from these measurements remains a challenging task for a non-technical audience. Interpreting network measurement data often requires considerable domain expertise to account not only for subtle variations of the connection stability and metrics, but even for simpler concepts such as latency under load or packet loss influence towards connection performance. In the absence of proper expertise, common misconceptions can easily arise. To address these issues, researchers should recognize the importance of making network measurements not only more comprehensive but also more accessible for wider audience without deep technical knowledge. A promising direction to achieve this goal involves leveraging recent advancements in large language models (LLMs), which have demonstrated capabilities in conducting an analysis of complex data in other fields, such as laboratory test results interpretation, news summarization, and personal assistance.
  In this paper, we describe an ongoing effort to apply large language models and historical data to enhance the interpretation of network measurements in real-world environments. We aim to automate the translation of low-level metric data into accessible explanations, allowing non-experts to make more informed decisions regarding network performance and reliability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19305v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator> Roman (Sylee),  Beltiukov, Karthik Bhattaram, Evania Cheng, Vinod Kanigicherla, Akul Singh, Natchanon Thampiratwong, Arpit Gupta</dc:creator>
    </item>
    <item>
      <title>A Cost-efficient Credit-Based Shaper Deployment Framework for Time-Sensitive Networks</title>
      <link>https://arxiv.org/abs/2505.19771</link>
      <description>arXiv:2505.19771v1 Announce Type: new 
Abstract: Time-sensitive networks are designed to meet stringent Quality of Service (QoS) requirements for mixed-criticality traffic with diverse performance demands. Ensuring deterministic guarantees for such traffic while reducing deployment costs remains a significant challenge. This paper proposes a cost-efficient partial deployment strategy for Time Sensitive Networking (TSN) devices within legacy Ethernet network. At the core of our approach is the Credit-Based Shaper (CBS), a key TSN scheduling mechanism. Unlike cost-prohibitive full CBS deployment, our approach selectively integrates CBS where it is most needed to enhance performance while reducing costs. Combining Network Calculus for schedulability verification and a heuristic optimization method for CBS configuration and placement, our proposal minimizes deployment costs while improving schedulability for medium-priority traffic and mitigating blocking delays for high-priority traffic. The feasibility and benefits of our approach are validated on a realistic automotive TSN use case with up to 70% of reduction in TSN devices requirements compared to a full deployment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19771v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Santiago Torres-Borda, Ahlem Mifdaoui</dc:creator>
    </item>
    <item>
      <title>Unleashing 5G Seamless Integration with TSN for Industry 5.0: Frame Forwarding and QoS Treatment</title>
      <link>https://arxiv.org/abs/2505.20239</link>
      <description>arXiv:2505.20239v1 Announce Type: new 
Abstract: Integrating Time-Sensitive Networking (TSN) and 5th Generation (5G) systems is key for providing wireless low-latency services in industry. Despite research efforts, challenges remain. Due to the lack of commercial 5G modems supporting Ethernet-based sessions, tunneling mechanisms must be used to enable Layer 2 connectivity between TSN islands via IP-based 5G modems. Furthermore, harmonizing traffic classification and prioritization between TSN and 5G technologies is crucial for meeting industrial service requirements. In this work, we propose a Virtual Extensible LAN (VxLAN)-based solution to harmonize frame forwarding and Quality of Service (QoS) treatment among 5G and TSN. Our solution supports multiple Virtual Local Area Networks (VLANs) across several production lines. Furthermore, it supports TSN traffic mapping into 5G QoS flows. We use a 5G testbed to validate the effectiveness of the adopted solution. Our results show the average delay introduced by the proposed mechanisms is approximately 100 {\mu}s, which is significantly lower than the typical 5G packet transmission delay. Moreover, our findings demonstrate our solution preserves QoS treatment between the 5G system and TSN, ensuring that the priority of 5G QoS flows aligns with the priorities of industrial traffic flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20239v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/OJCOMS.2025.3574397</arxiv:DOI>
      <dc:creator>Oscar Adamuz-Hinojosa, Felix Delgado-Ferro, Jorge Navarro-Ortiz, Pablo Mu\~noz, Pablo Ameigeiras</dc:creator>
    </item>
    <item>
      <title>Towards a Quantum-classical Augmented Network</title>
      <link>https://arxiv.org/abs/2505.18282</link>
      <description>arXiv:2505.18282v1 Announce Type: cross 
Abstract: In the past decade, several small-scale quantum key distribution networks have been established. However, the deployment of large-scale quantum networks depends on the development of quantum repeaters, quantum channels, quantum memories, and quantum network protocols. To improve the security of existing networks and adopt currently feasible quantum technologies, the next step is to augment classical networks with quantum devices, properties, and phenomena. To achieve this, we propose a change in the structure of the HTTP protocol such that it can carry both quantum and classical payload. This work lays the foundation for dividing one single network packet into classical and quantum payloads depending on the privacy needs. We implement logistic regression, CNN, LSTM, and BiLSTM models to classify the privacy label for outgoing communications. This enables reduced utilization of quantum resources allowing for a more efficient secure quantum network design. Experimental results using the proposed methods are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18282v1</guid>
      <category>quant-ph</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3042150</arxiv:DOI>
      <arxiv:journal_reference>In Quantum Computing, Communication, and Simulation V (Vol. 13391, pp. 72-86). SPIE 2025</arxiv:journal_reference>
      <dc:creator>Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam</dc:creator>
    </item>
    <item>
      <title>A DSP-Free Carrier Phase Recovery System using 16-Offset-QAM Laser Forwarded Links for 400Gb/s and Beyond</title>
      <link>https://arxiv.org/abs/2505.18534</link>
      <description>arXiv:2505.18534v1 Announce Type: cross 
Abstract: Optical interconnects are becoming a major bottleneck in scaling up future GPU racks and network switches within data centers. Although 200 Gb/s optical transceivers using PAM-4 modulation have been demonstrated, achieving higher data rates and energy efficiencies requires high-order coherent modulations like 16-QAM. Current coherent links rely on energy-intensive digital signal processing (DSP) for channel impairment compensation and carrier phase recovery (CPR), which consumes approximately 50pJ/b - 10x higher than future intra-data center requirements. For shorter links, simpler or DSP-free CPR methods can significantly reduce power and complexity. While Costas loops enable CPR for QPSK, they face challenges in scaling to higher-order modulations (e.g., 16/64-QAM) due to varying symbol amplitudes. In this work, we propose an optical coherent link architecture using laser forwarding and a novel DSP-free CPR system using offset-QAM modulation. The proposed analog CPR feedback loop is highly scalable, capable of supporting arbitrary offset-QAM modulations without requiring architectural modifications. This scalability is achieved through its phase error detection mechanism, which operates independently of the data rate and modulation type. We validated this method using GlobalFoundry's monolithic 45nm silicon photonics PDK models, with circuit- and system-level implementation at 100GBaud in the O-band. We will investigate the feedback loop dynamics, circuit-level implementations, and phase-noise performance of the proposed CPR loop. Our method can be adopted to realize low-power QAM optical interconnects for future coherent-lite pluggable transceivers as well as co-packaged optics (CPO) applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18534v1</guid>
      <category>eess.SP</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marziyeh Rezaei, Dan Sturm, Pengyu Zeng, Sajjad Moazeni</dc:creator>
    </item>
    <item>
      <title>SANNet: A Semantic-Aware Agentic AI Networking Framework for Multi-Agent Cross-Layer Coordination</title>
      <link>https://arxiv.org/abs/2505.18946</link>
      <description>arXiv:2505.18946v1 Announce Type: cross 
Abstract: Agentic AI networking (AgentNet) is a novel AI-native networking paradigm that relies on a large number of specialized AI agents to collaborate and coordinate for autonomous decision-making, dynamic environmental adaptation, and complex goal achievement. It has the potential to facilitate real-time network management alongside capabilities for self-configuration, self-optimization, and self-adaptation across diverse and complex networking environments, laying the foundation for fully autonomous networking systems in the future. Despite its promise, AgentNet is still in the early stage of development, and there still lacks an effective networking framework to support automatic goal discovery and multi-agent self-orchestration and task assignment. This paper proposes SANNet, a novel semantic-aware agentic AI networking architecture that can infer the semantic goal of the user and automatically assign agents associated with different layers of a mobile system to fulfill the inferred goal. Motivated by the fact that one of the major challenges in AgentNet is that different agents may have different and even conflicting objectives when collaborating for certain goals, we introduce a dynamic weighting-based conflict-resolving mechanism to address this issue. We prove that SANNet can provide theoretical guarantee in both conflict-resolving and model generalization performance for multi-agent collaboration in dynamic environment. We develop a hardware prototype of SANNet based on the open RAN and 5GS core platform. Our experimental results show that SANNet can significantly improve the performance of multi-agent networking systems, even when agents with conflicting objectives are selected to collaborate for the same goal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18946v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yong Xiao, Haoran Zhou, Xubo Li, Yayu Gao, Guangming Shi, Ping Zhang</dc:creator>
    </item>
    <item>
      <title>Grassroots Consensus</title>
      <link>https://arxiv.org/abs/2505.19216</link>
      <description>arXiv:2505.19216v2 Announce Type: cross 
Abstract: Grassroots platforms aim to offer an egalitarian alternative to global platforms -- centralized/autocratic and decentralized/plutocratic alike. Within the grassroots architecture, consensus is needed to realize platforms that employ digital social contracts, which are like smart contracts except that they are among people not accounts and are executed by these people's smartphones not by high-performance servers controlled by parties outside to the contract. Key envisioned grassroots platforms include sovereign democratic digital communities and federations, community banks and their grassroots cryptocurrencies, and digital cooperatives.
  The grassroots architecture can benefit from a consensus protocol that is (i) quiescent, (ii) efficient during low- and high-throughput, (iii) responsive, (iv) blocklace-based, (v) UDP-ready, and (vi) grassroots. The Grassroots Consensus protocol addresses all these requirements while having competitive performance in both low- and high-throughput scenarios and being one of the most concise and elegant consensus protocols for partial synchrony. It achieves that by building on two cutting-edge consensus protocols -- the quiescent high-performance Morpheus and the blocklace-based Cordial Miners, improving the latter's dissemination protocol and making it UDP-ready, and extending the protocol with a constitution and a constitutional amendment component, making it grassroots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19216v2</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Idit Keidar, Andrew Lewis-Pye, Ehud Shapiro</dc:creator>
    </item>
    <item>
      <title>Effect of noise and topologies on multi-photon quantum protocols</title>
      <link>https://arxiv.org/abs/2505.19270</link>
      <description>arXiv:2505.19270v1 Announce Type: cross 
Abstract: Quantum-augmented networks aim to use quantum phenomena to improve detection and protection against malicious actors in a classical communication network. This may include multiplexing quantum signals into classical fiber optical channels and incorporating purely quantum links alongside classical links in the network. In such hybrid networks, quantum protocols based on single photons become a bottleneck for transmission distances and data speeds, thereby reducing entire network performance. Furthermore, many of the security assumptions of the single-photon protocols do not hold up in practice because of the impossibility of manufacturing single-photon emitters. Multi-photon quantum protocols, on the other hand, are designed to operate under practical assumptions and do not require single photon emitters. As a result, they provide higher levels of security guarantees and longer transmission distances. However, the effect of channel and device noise on multiphoton protocols in terms of security, transmission distances, and bit rates has not been investigated. In this paper, we focus on channel noise and present our observations on the effect of various types of noise on multi-photon protocols. We also investigate the effect of topologies such as ring, star, and torus on the noise characteristics of the multi-photon protocols. Our results show the possible advantages of switching to multi-photon protocols and give insights into the repeater placement and topology choice for quantum-augmented networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19270v1</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1117/12.3000586</arxiv:DOI>
      <arxiv:journal_reference>In Quantum computing, communication, and simulation IV (Vol. 12911, pp. 148-161). SPIE 2024</arxiv:journal_reference>
      <dc:creator>Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam</dc:creator>
    </item>
    <item>
      <title>BSAGIoT: A Bayesian Security Aspect Graph for Internet of Things (IoT)</title>
      <link>https://arxiv.org/abs/2505.19283</link>
      <description>arXiv:2505.19283v1 Announce Type: cross 
Abstract: IoT is a dynamic network of interconnected things that communicate and exchange data, where security is a significant issue. Previous studies have mainly focused on attack classifications and open issues rather than presenting a comprehensive overview on the existing threats and vulnerabilities. This knowledge helps analyzing the network in the early stages even before any attack takes place. In this paper, the researchers have proposed different security aspects and a novel Bayesian Security Aspects Dependency Graph for IoT (BSAGIoT) to illustrate their relations. The proposed BSAGIoT is a generic model applicable to any IoT network and contains aspects from five categories named data, access control, standard, network, and loss. This proposed Bayesian Security Aspect Graph (BSAG) presents an overview of the security aspects in any given IoT network. The purpose of BSAGIoT is to assist security experts in analyzing how a successful compromise and/or a failed breach could impact the overall security and privacy of the respective IoT network. In addition, root cause identification of security challenges, how they affect one another, their impact on IoT networks via topological sorting, and risk assessment could be achieved. Hence, to demonstrate the feasibility of the proposed method, experimental results with various scenarios has been presented, in which the security aspects have been quantified based on the network configurations. The results indicate the impact of the aspects on each other and how they could be utilized to mitigate and/or eliminate the security and privacy deficiencies in IoT networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.19283v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeinab Lashkaripour, Masoud Khosravi-Farmad, AhmadReza Montazerolghaem, Razieh Rezaee</dc:creator>
    </item>
    <item>
      <title>Revenue Optimization in Video Caching Networks with Privacy-Preserving Demand Predictions</title>
      <link>https://arxiv.org/abs/2505.07872</link>
      <description>arXiv:2505.07872v2 Announce Type: replace 
Abstract: Performance of video streaming, which accounts for most of the traffic in wireless communication, can be significantly improved by caching popular videos at the wireless edge. Determining the cache content that optimizes performance (defined via a revenue function) is thus an important task, and prediction of the future demands based on past history can make this process much more efficient. However, since practical video caching networks involve various parties (e.g., users, isp, and csp) that do not wish to reveal information such as past history to each other, privacy-preserving solutions are required. Motivated by this, we propose a proactive caching method based on users' privacy-preserving multi-slot future demand predictions -- obtained from a trained Transformer -- to optimize revenue. Specifically, we first use a privacy-preserving fl algorithm to train a Transformer to predict multi-slot future demands of the users. However, prediction accuracy is not perfect and decreases the farther into the future the prediction is done. We model the impact of prediction errors invoking the file popularities, based on which we formulate a long-term system revenue optimization to make the cache placement decisions. As the formulated problem is NP-hard, we use a greedy algorithm to efficiently obtain an approximate solution. Simulation results validate that (i) the fl solution achieves results close to the centralized (non-privacy-preserving) solution and (ii) optimization of revenue may provide different solutions than the classical chr criterion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07872v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yijing Zhang, Ferdous Pervej, Andreas F. Molisch</dc:creator>
    </item>
    <item>
      <title>LLM-Based Emulation of the Radio Resource Control Layer: Towards AI-Native RAN Protocols</title>
      <link>https://arxiv.org/abs/2505.16821</link>
      <description>arXiv:2505.16821v2 Announce Type: replace 
Abstract: Integrating large AI models (LAMs) into 6G mobile networks promises to redefine protocol design and control-plane intelligence by enabling autonomous, cognitive network operations. While industry concepts, such as ETSI's Experiential Networked Intelligence (ENI), envision LAM-driven agents for adaptive network slicing and intent-based management, practical implementations still face challenges in protocol literacy and real-world deployment. This paper presents an end-to-end demonstration of a LAM that generates standards-compliant, ASN.1-encoded Radio Resource Control (RRC) messages as part of control-plane procedures inside a gNB. We treat RRC messaging as a domain-specific language and fine-tune a decoder-only transformer model (LLaMA class) using parameter-efficient Low-Rank Adaptation (LoRA) on RRC messages linearized to retain their ASN.1 syntactic structure before standard byte-pair encoding tokenization. This enables combinatorial generalization over RRC protocol states while minimizing training overhead. On 30k field-test request-response pairs, our 8 B model achieves a median cosine similarity of 0.97 with ground-truth messages on an edge GPU -- a 61 % relative gain over a zero-shot LLaMA-3 8B baseline -- indicating substantially improved structural and semantic RRC fidelity. Overall, our results show that LAMs, when augmented with Radio Access Network (RAN)-specific reasoning, can directly orchestrate control-plane procedures, representing a stepping stone toward the AI-native air-interface paradigm. Beyond RRC emulation, this work lays the groundwork for future AI-native wireless standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16821v2</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziming Liu, Bryan Liu, Alvaro Valcarce, Xiaoli Chu</dc:creator>
    </item>
    <item>
      <title>Semantic-Aware Resource Management for C-V2X Platooning via Multi-Agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2411.04672</link>
      <description>arXiv:2411.04672v2 Announce Type: replace-cross 
Abstract: Semantic communication transmits the extracted features of information rather than raw data, significantly reducing redundancy, which is crucial for addressing spectrum and energy challenges in 6G networks. In this paper, we introduce semantic communication into a cellular vehicle-to-everything (C-V2X)- based autonomous vehicle platoon system for the first time, aiming to achieve efficient management of communication resources in a dynamic environment. Firstly, we construct a mathematical model for semantic communication in platoon systems, in which the DeepSC model and MU-DeepSC model are used to semantically encode and decode unimodal and multi-modal data, respectively. Then, we propose the quality of experience (QoE) metric based on semantic similarity and semantic rate. Meanwhile, we consider the success rate of semantic information transmission (SRS) metric to ensure the fairness of channel resource allocation. Next, the optimization problem is posed with the aim of maximizing the QoE in vehicle-to-vehicle (V2V) links while improving SRS. To solve this mixed integer nonlinear programming problem (MINLP) and adapt to time-varying channel conditions, the paper proposes a distributed semantic-aware multi-modal resource allocation (SAMRA) algorithm based on multi-agent reinforcement learning (MARL), referred to as SAMRAMARL. The algorithm can dynamically allocate channels and power and determine semantic symbol length based on the contextual importance of the transmitted information, ensuring efficient resource utilization. Finally, extensive simulations have demonstrated that SAMRAMARL outperforms existing methods, achieving significant gains in QoE, SRS, and communication delay in C-V2X platooning scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04672v2</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenjun Zhang, Qiong Wu, Pingyi Fan, Kezhi Wang, Nan Cheng, Wen Chen, Khaled B. Letaief</dc:creator>
    </item>
    <item>
      <title>How to design a Public Key Infrastructure for a Central Bank Digital Currency</title>
      <link>https://arxiv.org/abs/2412.04051</link>
      <description>arXiv:2412.04051v2 Announce Type: replace-cross 
Abstract: Central Bank Digital Currency (CBDC) is a new form of money, issued by a country's or region's central bank, that can be used for a variety of payment scenarios. Depending on its concrete implementation, there are many participants in a production CBDC ecosystem, including the central bank, commercial banks, merchants, individuals, and wallet providers. There is a need for robust and scalable Public Key Infrastructure (PKI) for CBDC to ensure the continued trust of all entities in the system. This paper discusses the criteria that should flow into the design of a PKI and proposes a certificate hierarchy, together with a rollover concept ensuring continuous operation of the system. We further consider several peculiarities, such as the circulation of offline-capable hardware wallets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04051v2</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Makan Rafiee, Lars Hupel</dc:creator>
    </item>
    <item>
      <title>Task-Oriented Communications for Visual Navigation with Edge-Aerial Collaboration in Low Altitude Economy</title>
      <link>https://arxiv.org/abs/2504.18317</link>
      <description>arXiv:2504.18317v4 Announce Type: replace-cross 
Abstract: To support the Low Altitude Economy (LAE), it is essential to achieve precise localization of unmanned aerial vehicles (UAVs) in urban areas where global positioning system (GPS) signals are unavailable. Vision-based methods offer a viable alternative but face severe bandwidth, memory and processing constraints on lightweight UAVs. Inspired by mammalian spatial cognition, we propose a task-oriented communication framework, where UAVs equipped with multi-camera systems extract compact multi-view features and offload localization tasks to edge servers. We introduce the Orthogonally-constrained Variational Information Bottleneck encoder (O-VIB), which incorporates automatic relevance determination (ARD) to prune non-informative features while enforcing orthogonality to minimize redundancy. This enables efficient and accurate localization with minimal transmission cost. Extensive evaluation on a dedicated LAE UAV dataset shows that O-VIB achieves high-precision localization under stringent bandwidth budgets. Code and dataset will be made publicly available at: github.com/fangzr/TOC-Edge-Aerial.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18317v4</guid>
      <category>cs.CV</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhengru Fang, Zhenghao Liu, Jingjing Wang, Senkang Hu, Yu Guo, Yiqin Deng, Yuguang Fang</dc:creator>
    </item>
    <item>
      <title>Recursive Offloading for LLM Serving in Multi-tier Networks</title>
      <link>https://arxiv.org/abs/2505.16502</link>
      <description>arXiv:2505.16502v2 Announce Type: replace-cross 
Abstract: Heterogeneous device-edge-cloud computing infrastructures have become widely adopted in telecommunication operators and Wide Area Networks (WANs), offering multi-tier computational support for emerging intelligent services. With the rapid proliferation of Large Language Model (LLM) services, efficiently coordinating inference tasks and reducing communication overhead within these multi-tier network architectures becomes a critical deployment challenge. Existing LLM serving paradigms exhibit significant limitations: on-device deployment supports only lightweight LLMs due to hardware constraints, while cloud-centric deployment suffers from resource congestion and considerable prompt communication overhead caused by frequent service requests during peak periods. Although the model-cascading-based inference strategy adapts better to multi-tier networks, its reliance on fine-grained, manually adjusted thresholds makes it less responsive to dynamic network conditions and varying task complexities. To address these challenges, we propose RecServe, a recursive offloading framework tailored for LLM serving in multi-tier networks. RecServe integrates a task-specific hierarchical confidence evaluation mechanism that guides offloading decisions based on inferred task complexity in progressively scaled LLMs across device, edge, and cloud tiers. To further enable intelligent task routing across tiers, RecServe employs a sliding-window-based dynamic offloading strategy with quantile interpolation, enabling real-time tracking of historical confidence distributions and adaptive offloading threshold adjustments. Experiments on eight datasets demonstrate that RecServe outperforms CasServe in both service quality and communication efficiency, and reduces the communication burden by over 50\% compared to centralized cloud-based serving.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.16502v2</guid>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiyuan Wu, Sheng Sun, Yuwei Wang, Min Liu, Bo Gao, Jinda Lu, Zheming Yang, Tian Wen</dc:creator>
    </item>
    <item>
      <title>Joint Encryption and Error Correction for Secure Quantum Communication</title>
      <link>https://arxiv.org/abs/2505.18133</link>
      <description>arXiv:2505.18133v2 Announce Type: replace-cross 
Abstract: Secure quantum networks are a bedrock requirement for developing a future quantum internet. However, quantum channels are susceptible to channel noise that introduce errors in the transmitted data. The traditional approach to providing error correction typically encapsulates the message in an error correction code after encryption. Such separate processes incur overhead that must be avoided when possible. We, consequently, provide a single integrated process that allows for encryption as well as error correction. This is a first attempt to do so for secure quantum communication and combines the Calderbank-Shor-Steane (CSS) code with the three-stage secure quantum communication protocol. Lastly, it allows for arbitrary qubits to be transmitted from sender to receiver making the proposed protocol general purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18133v2</guid>
      <category>quant-ph</category>
      <category>cs.NI</category>
      <pubDate>Tue, 27 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41598-024-75212-8</arxiv:DOI>
      <arxiv:journal_reference>Sci Rep 14, 24542 (2024)</arxiv:journal_reference>
      <dc:creator>Nitin Jha, Abhishek Parakh, Mahadevan Subramaniam</dc:creator>
    </item>
  </channel>
</rss>
