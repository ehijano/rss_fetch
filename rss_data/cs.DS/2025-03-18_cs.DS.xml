<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Mar 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Graph Discovery and Source Detection in Temporal Graphs</title>
      <link>https://arxiv.org/abs/2503.13567</link>
      <description>arXiv:2503.13567v1 Announce Type: new 
Abstract: Researchers, policy makers, and engineers need to make sense of data on spreading processes as diverse as viral infections, water contamination, and misinformation in social networks. Classical questions include predicting infection behavior in a given network or deducing the structure of a network from infection data. We study two central problems in this area. In graph discovery, we aim to fully reconstruct the structure of a graph from infection data. In source detection, we observe a limited subset of the infections and aim to deduce the source of the infection chain. These questions have received considerable attention and have been analyzed in many settings (e.g., under different models of spreading processes), yet all previous work shares the assumption that the network has the same structure at every point in time. For example, if we consider how a disease spreads, it is unrealistic to assume that two people can either never or always infect each other, rather such an infection is possible precisely when they meet. Temporal graphs, in which connections change over time, have recently been used as a more realistic graph model to study infections. Despite this recent attention, we are the first to study graph discovery or source detection in temporal graphs.
  We propose models for temporal graph discovery and source detection that are consistent with previous work on static graphs and extend it to embrace the stronger expressiveness of temporal graphs. For this, we employ the standard susceptible-infected-resistant model of spreading processes, which is particularly often used to study diseases. We provide algorithms, lower bounds, and some experimental evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13567v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Bals</dc:creator>
    </item>
    <item>
      <title>Optimal Non-Oblivious Open Addressing</title>
      <link>https://arxiv.org/abs/2503.13628</link>
      <description>arXiv:2503.13628v1 Announce Type: new 
Abstract: A hash table is said to be open-addressed (or non-obliviously open-addressed) if it stores elements (and free slots) in an array with no additional metadata. Intuitively, open-addressed hash tables must incur a space-time tradeoff: The higher the load factor at which the hash table operates, the longer insertions/deletions/queries should take.
  In this paper, we show that no such tradeoff exists: It is possible to construct an open-addressed hash table that supports constant-time operations even when the hash table is entirely full. In fact, it is even possible to construct a version of this data structure that: (1) is dynamically resized so that the number of slots in memory that it uses, at any given moment, is the same as the number of elements it contains; (2) supports $O(1)$-time operations, not just in expectation, but with high probability; and (3) requires external access to just $O(1)$ hash functions that are each just $O(1)$-wise independent.
  Our results complement a recent lower bound by Bender, Kuszmaul, and Zhou showing that oblivious open-addressed hash tables must incur $\Omega(\log \log \varepsilon^{-1})$-time operations. The hash tables in this paper are non-oblivious, which is why they are able to bypass the previous lower bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13628v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael A. Bender, William Kuszmaul, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Branch Prediction Analysis of Morris-Pratt and Knuth-Morris-Pratt Algorithms</title>
      <link>https://arxiv.org/abs/2503.13694</link>
      <description>arXiv:2503.13694v1 Announce Type: new 
Abstract: We analyze the classical Morris-Pratt and Knuth-Morris-Pratt pattern matching algorithms through the lens of computer architecture, investigating the impact of incorporating a simple branch prediction mechanism into the model of computation. Assuming a fixed pattern and a random text, we derive precise estimates of the number of mispredictions these algorithms produce using local predictors. Our approach is based on automata theory and Markov chains, providing a foundation for the theoretical analysis of other text algorithms and more advanced branch prediction strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13694v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cyril Nicaud, Carine Pivoteau, St\'ephane Vialette</dc:creator>
    </item>
    <item>
      <title>Color-Constrained Arborescences in Edge-Colored Digraphs</title>
      <link>https://arxiv.org/abs/2503.13984</link>
      <description>arXiv:2503.13984v1 Announce Type: new 
Abstract: Given a multigraph $G$ whose edges are colored from the set $[q]:=\{1,2,\ldots,q\}$ (\emph{$q$-colored graph}), and a vector $\alpha=(\alpha_1,\ldots,\alpha_{q}) \in \mathbb{N}^{q}$ (\emph{color-constraint}), a subgraph $H$ of $G$ is called \emph{$\alpha$-colored}, if $H$ has exactly $\alpha_i$ edges of color $i$ for each $i \in[q]$. In this paper, we focus on $\alpha$-colored arborescences (spanning out-trees) in $q$-colored multidigraphs. We study the decision, counting and search versions of this problem. It is known that the decision and search problems are polynomial-time solvable when $q=2$ and that the decision problem is NP-complete when $q$ is arbitrary. However the complexity status of the problem for fixed $q$ was open for $q &gt; 2$. We show that, for a $q$-colored digraph $G$ and a vertex $s$ in $G$, the number of $\alpha$-colored arborescences in $G$ rooted at $s$ for all color-constraints $\alpha \in \mathbb{N}^q$ can be read from the determinant of a symbolic matrix in $q-1$ indeterminates. This result extends Tutte's matrix-tree theorem for directed graphs and gives a polynomial-time algorithm for the counting and decision problems for fixed $q$. We also use it to design an algorithm that finds an $\alpha$-colored arborescence when one exists. Finally, we study the weighted variant of the problem and give a polynomial-time algorithm (when $q$ is fixed) which finds a minimum weight solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13984v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>P. S. Ardra, Jasine Babu, R. Krithika, Deepak Rajendraprasad</dc:creator>
    </item>
    <item>
      <title>Streaming and Massively Parallel Algorithms for Euclidean Max-Cut</title>
      <link>https://arxiv.org/abs/2503.14362</link>
      <description>arXiv:2503.14362v1 Announce Type: new 
Abstract: Given a set of vectors $X = \{ x_1,\dots, x_n \} \subset \mathbb{R}^d$, the Euclidean max-cut problem asks to partition the vectors into two parts so as to maximize the sum of Euclidean distances which cross the partition. We design new algorithms for Euclidean max-cut in models for massive datasets:
  $\bullet$ We give a fully-scalable constant-round MPC algorithm using $O(nd) + n \cdot \text{poly}( \log(n) / \epsilon)$ total space which gives a $(1+\epsilon)$-approximate Euclidean max-cut.
  $\bullet$ We give a dynamic streaming algorithm using $\text{poly}(d \log \Delta / \epsilon)$ space when $X \subseteq [\Delta]^d$, which provides oracle access to a $(1+\epsilon)$-approximate Euclidean max-cut.
  Recently, Chen, Jiang, and Krauthgamer $[\text{STOC}~'23]$ gave a dynamic streaming algorithm with space $\text{poly}(d\log\Delta/\epsilon)$ to approximate the value of the Euclidean max-cut, but could not provide oracle access to an approximately optimal cut. This was left open in that work, and we resolve it here. Both algorithms follow from the same framework, which analyzes a ``parallel'' and ``subsampled'' (Euclidean) version of a greedy algorithm of Mathieu and Schudy $[\text{SODA}~'08]$ for dense max-cut.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14362v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nicolas Menand, Erik Waingarten</dc:creator>
    </item>
    <item>
      <title>Quantum EigenGame for excited state calculation</title>
      <link>https://arxiv.org/abs/2503.13644</link>
      <description>arXiv:2503.13644v1 Announce Type: cross 
Abstract: Computing the excited states of a given Hamiltonian is computationally hard for large systems, but methods that do so using quantum computers scale tractably. This problem is equivalent to the PCA problem where we are interested in decomposing a matrix into a collection of principal components. Classically, PCA is a well-studied problem setting, for which both centralized and distributed approaches have been developed. On the distributed side, one recent approach is that of EigenGame, a game-theoretic approach to finding eigenvectors where each eigenvector reaches a Nash equilibrium either sequentially or in parallel. With this work, we extend the EigenGame algorithm for both a $0^\text{th}$-order approach and for quantum computers, and harness the framework that quantum computing provides in computing excited states. Results show that using the Quantum EigenGame allows us to converge to excited states of a given Hamiltonian without the need of a deflation step. We also develop theory on error accumulation for finite-differences and parameterized approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13644v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Quiroga, Jason Han, Anastasios Kyrillidis</dc:creator>
    </item>
    <item>
      <title>Efficient Greedy Discrete Subtrajectory Clustering</title>
      <link>https://arxiv.org/abs/2503.14115</link>
      <description>arXiv:2503.14115v1 Announce Type: cross 
Abstract: We cluster a set of trajectories T using subtrajectories of T. Clustering quality may be measured by the number of clusters, the number of vertices of T that are absent from the clustering, and by the Fr\'{e}chet distance between subtrajectories in a cluster. A $\Delta$-cluster of T is a cluster ${\mathcal{P}}$ of subtrajectories of T with a centre $P \in {\mathcal{P}}$ with complexity $\ell$, where all subtrajectories in ${\mathcal{P}}$ have Fr\'{e}chet distance at most $\Delta$ to $P$. Buchin, Buchin, Gudmundsson, L\"{o}ffler and Luo present two $O(n^2 + n m \ell)$-time algorithms: SC($\max$, $\ell$, $\Delta$, T) computes a single $\Delta$-cluster where $P$ has at least $\ell$ vertices and maximises the cardinality $m$ of ${\mathcal{P}}$. SC($m$, $\max$, $\Delta$, T) computes a single $\Delta$-cluster where ${\mathcal{P}}$ has cardinality $m$ and maximises the complexity $\ell$ of $P$.
  We use such maximum-cardinality clusters in a greedy clustering algorithm. We provide an efficient implementation of SC($\max$, $\ell$, $\Delta$, T) and SC($m$, $\max$, $\Delta$, T) that significantly outperforms previous implementations. We use these functions as a subroutine in a greedy clustering algorithm, which performs well when compared to existing subtrajectory clustering algorithms on real-world data. Finally, we observe that, for fixed $\Delta$ and T, these two functions always output a point on the Pareto front of some bivariate function $\theta(\ell, m)$. We design a new algorithm PSC($\Delta$, T) that in $O( n^2 \log^4 n)$ time computes a $2$-approximation of this Pareto front. This yields a broader set of candidate clusters, with comparable quality. We show that using PSC($\Delta$, T) as a subroutine improves the clustering quality and performance even further.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14115v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivor van der Hoog, Lara Ost, Eva Rotenberg, Daniel Rutschmann</dc:creator>
    </item>
    <item>
      <title>Better Differentially Private Approximate Histograms and Heavy Hitters using the Misra-Gries Sketch</title>
      <link>https://arxiv.org/abs/2301.02457</link>
      <description>arXiv:2301.02457v2 Announce Type: replace 
Abstract: We consider the problem of computing differentially private approximate histograms and heavy hitters in a stream of elements. In the non-private setting, this is often done using the sketch of Misra and Gries [Science of Computer Programming, 1982]. Chan, Li, Shi, and Xu [PETS 2012] describe a differentially private version of the Misra-Gries sketch, but the amount of noise it adds can be large and scales linearly with the size of the sketch; the more accurate the sketch is, the more noise this approach has to add. We present a better mechanism for releasing a Misra-Gries sketch under $(\varepsilon,\delta)$-differential privacy. It adds noise with magnitude independent of the size of the sketch; in fact, the maximum error coming from the noise is the same as the best known in the private non-streaming setting, up to a constant factor. Our mechanism is simple and likely to be practical. We also give a simple post-processing step of the Misra-Gries sketch that does not increase the worst-case error guarantee. It is sufficient to add noise to this new sketch with less than twice the magnitude of the non-streaming setting. This improves on the previous result for $\varepsilon$-differential privacy where the noise scales linearly to the size of the sketch. Finally, we consider a general setting where users can contribute multiple distinct elements. We present a new sketch with maximum error matching the Misra-Gries sketch. For many parameters in this setting our sketch can be released with less noise under $(\varepsilon, \delta)$-differential privacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02457v2</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.IR</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Janos Lebeda, Jakub T\v{e}tek</dc:creator>
    </item>
    <item>
      <title>Suffixient Arrays: a New Efficient Suffix Array Compression Technique</title>
      <link>https://arxiv.org/abs/2407.18753</link>
      <description>arXiv:2407.18753v2 Announce Type: replace 
Abstract: The Suffix Array is a classic text index enabling on-line pattern matching queries via simple binary search. The main drawback of the Suffix Array is that it takes linear space in the text's length, even if the text itself is extremely compressible. Several works in the literature showed that the Suffix Array can be compressed, but they all rely on complex succinct data structures which in practice tend to exhibit poor cache locality and thus significantly slow down queries. In this paper, we propose a new simple and very efficient solution to this problem by presenting the \emph{Suffixient Array}: a tiny subset of the Suffix Array \emph{sufficient} to locate on-line one pattern occurrence (in general, all its Maximal Exact Matches) via binary search, provided that random access to the text is available. We prove that: (i) the Suffixient Array length $\chi$ is a strong repetitiveness measure, (ii) unlike most existing repetition-aware indexes such as the $r$-index, our new index is efficient in the I/O model, and (iii) Suffixient Arrays can be computed in linear time and compressed working space. We show experimentally that, when using well-established compressed random access data structures on repetitive collections, the Suffixient Array $\SuA$ is \emph{simultaneously} (i) faster and orders of magnitude smaller than the Suffix Array $\SA$ and (ii) smaller and \emph{one to two orders of magnitude faster} than the $r$-index. With an average pattern matching query time as low as 3.5 ns per character, our new index gets very close to the ultimate lower bound: the RAM throughput of our workstation (1.18 ns per character).</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18753v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Cenzato, Lore Depuydt, Travis Gagie, Sung-Hwan Kim, Giovanni Manzini, Francisco Olivares, Nicola Prezza</dc:creator>
    </item>
    <item>
      <title>Totally $\Delta$-modular IPs with two non-zeros in most rows</title>
      <link>https://arxiv.org/abs/2411.15282</link>
      <description>arXiv:2411.15282v2 Announce Type: replace 
Abstract: Integer programs (IPs) on constraint matrices with bounded subdeterminants are conjectured to be solvable in polynomial time. We give a strongly polynomial time algorithm to solve IPs where the constraint matrix has bounded subdeterminants and at most two non-zeros per row after removing a constant number of rows and columns. This result extends the work by Fiorini, Joret, Weltge \&amp; Yuditsky (J. ACM 72(1), 1-50 (2025)) by allowing for additional, unifying constraints and variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15282v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Kober</dc:creator>
    </item>
    <item>
      <title>Dynamic Demand-Aware Link Scheduling for Reconfigurable Datacenters</title>
      <link>https://arxiv.org/abs/2301.05751</link>
      <description>arXiv:2301.05751v2 Announce Type: replace-cross 
Abstract: Emerging reconfigurable datacenters allow to dynamically adjust the network topology in a demand-aware manner. These datacenters rely on optical switches which can be reconfigured to provide direct connectivity between racks, in the form of edge-disjoint matchings. While state-of-the-art optical switches in principle support microsecond reconfigurations, the demand-aware topology optimization constitutes a bottleneck.
  This paper proposes a dynamic algorithms approach to improve the performance of reconfigurable datacenter networks, by supporting faster reactions to changes in the traffic demand. This approach leverages the temporal locality of traffic patterns in order to update the interconnecting matchings incrementally, rather than recomputing them from scratch. In particular, we present six (batch-)dynamic algorithms and compare them to static ones. We conduct an extensive empirical evaluation on 176 synthetic and 39 real-world traces, and find that dynamic algorithms can both significantly improve the running time and reduce the number of changes to the configuration, especially in networks with high temporal locality, while retaining matching weight.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05751v2</guid>
      <category>cs.NI</category>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kathrin Hanauer, Monika Henzinger, Lara Ost, Stefan Schmid</dc:creator>
    </item>
    <item>
      <title>Better Gaussian Mechanism using Correlated Noise</title>
      <link>https://arxiv.org/abs/2408.06853</link>
      <description>arXiv:2408.06853v3 Announce Type: replace-cross 
Abstract: We present a simple variant of the Gaussian mechanism for answering differentially private queries when the sensitivity space has a certain common structure. Our motivating problem is the fundamental task of answering $d$ counting queries under the add/remove neighboring relation. The standard Gaussian mechanism solves this task by adding noise distributed as a Gaussian with variance scaled by $d$ independently to each count. We show that adding a random variable distributed as a Gaussian with variance scaled by $(\sqrt{d} + 1)/4$ to all counts allows us to reduce the variance of the independent Gaussian noise samples to scale only with $(d + \sqrt{d})/4$. The total noise added to each counting query follows a Gaussian distribution with standard deviation scaled by $(\sqrt{d} + 1)/2$ rather than $\sqrt{d}$. The central idea of our mechanism is simple and the technique is flexible. We show that applying our technique to another problem gives similar improvements over the standard Gaussian mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06853v3</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Janos Lebeda</dc:creator>
    </item>
    <item>
      <title>Reconstructing semi-directed level-1 networks using few quarnets</title>
      <link>https://arxiv.org/abs/2409.06034</link>
      <description>arXiv:2409.06034v2 Announce Type: replace-cross 
Abstract: Semi-directed networks are partially directed graphs that model evolution where the directed edges represent reticulate evolutionary events. We present an algorithm that reconstructs binary $n$-leaf semi-directed level-1 networks in $O( n^2)$ time from its quarnets (4-leaf subnetworks). Our method assumes we have direct access to all quarnets, yet uses only an asymptotically optimal number of $O(n \log n)$ quarnets. When the network is assumed to contain no triangles, our method instead relies only on four-cycle quarnets and the splits of the other quarnets. A variant of our algorithm works with quartets rather than quarnets and we show that it reconstructs most of a semi-directed level-1 network from an asymptotically optimal $O(n \log n)$ of the quartets it displays. Additionally, we provide an $O(n^3)$ time algorithm that reconstructs the tree-of-blobs of any binary $n$-leaf semi-directed network with unbounded level from $O(n^3)$ splits of its quarnets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06034v2</guid>
      <category>q-bio.PE</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Frohn, Niels Holtgrefe, Leo van Iersel, Mark Jones, Steven Kelk</dc:creator>
    </item>
    <item>
      <title>Testing classical properties from quantum data</title>
      <link>https://arxiv.org/abs/2411.12730</link>
      <description>arXiv:2411.12730v2 Announce Type: replace-cross 
Abstract: Properties of Boolean functions can often be tested much faster than the functions can be learned. However, this advantage usually disappears when testers are limited to random samples of a function $f$--a natural setting for data science--rather than queries. In this work we initiate the study of a quantum version of this "data science scenario": quantum algorithms that test properties of $f$ solely from quantum data in the form of copies of the function state $|f\rangle \propto \sum_x|x,f(x)\rangle$.
  $\bullet$ New tests. For three well-established properties--monotonicity, symmetry, and triangle-freeness--we show that the speedup lost when restricting classical testers to sampled data can be recovered by quantum algorithms operating solely from quantum data.
  $\bullet$ Inadequacy of Fourier sampling. Our new testers use techniques beyond quantum Fourier sampling, and we show that this necessary. In particular, there is no constant-complexity tester for symmetry relying solely on Fourier sampling and random classical samples.
  $\bullet$ Classical queries vs. quantum data. We exhibit a testing problem that can be solved from $O(1)$ classical queries but that requires $\Omega(2^{n/2})$ function state copies. The Forrelation problem provides a separation of the same magnitude in the opposite direction, so we conclude that quantum data and classical queries are "maximally incomparable" resources for testing.
  $\bullet$ Towards lower bounds. We also begin the study of lower bounds for testing from quantum data. For quantum monotonicity testing, we prove that the ensembles of Goldreich et al. (2000) and Black (2023), which give exponential lower bounds for classical sample-based testing, do not yield any nontrivial lower bounds for testing from quantum data. New insights specific to quantum data will be required for proving copy complexity lower bounds for testing in this model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.12730v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias C. Caro, Preksha Naik, Joseph Slote</dc:creator>
    </item>
    <item>
      <title>On the Parameterized Complexity of Controlling Amendment and Successive Winners</title>
      <link>https://arxiv.org/abs/2501.00860</link>
      <description>arXiv:2501.00860v3 Announce Type: replace-cross 
Abstract: The successive and the amendment procedures have been widely employed in parliamentary and legislative decision making and have undergone extensive study in the literature from various perspectives. However, investigating them through the lens of computational complexity theory has not been as thoroughly conducted as for many other prevalent voting procedures heretofore. To the best of our knowledge, there is only one paper which explores the complexity of several strategic voting problems under these two procedures, prior to our current work. To provide a better understanding of to what extent the two procedures resist strategic behavior, we study the parameterized complexity of constructive/destructive control by adding/deleting voters/candidates for both procedures. To enhance the generalizability of our results, we also examine a more generalized form of the amendment procedure. Our exploration yields a comprehensive (parameterized) complexity landscape of these problems with respect to numerous parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00860v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 19 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yongjie Yang</dc:creator>
    </item>
  </channel>
</rss>
