<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 14 Nov 2024 02:45:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scaled Proximal Gradient Methods for Multiobjective Optimization: Improved Linear Convergence and Nesterov's Acceleration</title>
      <link>https://arxiv.org/abs/2411.07253</link>
      <description>arXiv:2411.07253v1 Announce Type: new 
Abstract: Over the past two decades, descent methods have received substantial attention within the multiobjective optimization field. Nonetheless, both theoretical analyses and empirical evidence reveal that existing first-order methods for multiobjective optimization converge slowly, even for well-conditioned problems, due to the objective imbalances. To address this limitation, we incorporate curvature information to scale each objective within the direction-finding subproblem, introducing a scaled proximal gradient method for multiobjective optimization (SPGMO). We demonstrate that the proposed method achieves improved linear convergence, exhibiting rapid convergence in well-conditioned scenarios. Furthermore, by applying small scaling to linear objectives, we prove that the SPGMO attains improved linear convergence for problems with multiple linear objectives. Additionally, integrating Nesterov's acceleration technique further enhances the linear convergence of SPGMO. To the best of our knowledge, this advancement in linear convergence is the first theoretical result that directly addresses objective imbalances in multiobjective first-order methods. Finally, we provide numerical experiments to validate the efficiency of the proposed methods and confirm the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07253v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Chen, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>A Total Variation Flow Scheme for Ergodic Mean Field Games</title>
      <link>https://arxiv.org/abs/2411.07331</link>
      <description>arXiv:2411.07331v1 Announce Type: new 
Abstract: Motivated by recent developments in mean-field games in ecology, in this paper we introduce a connection between the best response dynamics in evolutionary game theory, the minimization of the highest income of a game, and minimizing movement schemes. The aim of this work is to develop a variational approach to compute solutions of first order ergodic mean-field games that may not possess a priori a variational structure. The study is complemented by a discussion and successful implementation of the algorithms, and comparisons between them in a variety of cases</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07331v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dante Kalise, Alessio Oliviero, Dom\`enec Ruiz-Balet</dc:creator>
    </item>
    <item>
      <title>Reduced Sample Complexity in Scenario-Based Control System Design via Constraint Scaling</title>
      <link>https://arxiv.org/abs/2411.07361</link>
      <description>arXiv:2411.07361v2 Announce Type: new 
Abstract: The scenario approach is widely used in robust control system design and chance-constrained optimization, maintaining convexity without requiring assumptions about the probability distribution of uncertain parameters. However, the approach can demand large sample sizes, making it intractable for safety-critical applications that require very low levels of constraint violation. To address this challenge, we propose a novel yet simple constraint scaling method, inspired by large deviations theory. Under mild nonparametric conditions on the underlying probability distribution, we show that our method yields an exponential reduction in sample size requirements for bilinear constraints with low violation levels compared to the classical approach, thereby significantly improving computational tractability. Numerical experiments on robust pole assignment problems support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07361v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaeseok Choi, Anand Deo, Constantino Lagoa, Anirudh Subramanyam</dc:creator>
    </item>
    <item>
      <title>ADMM for Structured Fractional Minimization</title>
      <link>https://arxiv.org/abs/2411.07496</link>
      <description>arXiv:2411.07496v1 Announce Type: new 
Abstract: We consider a class of structured fractional minimization problems, where the numerator includes a differentiable function, a simple nonconvex nonsmooth function, a concave nonsmooth function, and a convex nonsmooth function composed with a linear operator, while the denominator is a continuous function that is either weakly convex or has a weakly convex square root. These problems are widespread and span numerous essential applications in machine learning and data science. Existing methods are mainly based on subgradient methods and smoothing proximal gradient methods, which may suffer from slow convergence and numerical stability issues. In this paper, we introduce {\sf FADMM}, the first Alternating Direction Method of Multipliers tailored for this class of problems. {\sf FADMM} decouples the original problem into linearized proximal subproblems, featuring two variants: one using Dinkelbach's parametric method ({\sf FADMM-D}) and the other using the quadratic transform method ({\sf FADMM-Q}). By introducing a novel Lyapunov function, we establish that {\sf FADMM} converges to $\epsilon$-approximate critical points of the problem within an oracle complexity of $\mathcal{O}(1/\epsilon^{3})$. Our experiments on synthetic and real-world data for sparse Fisher discriminant analysis, robust Sharpe ratio minimization, and robust sparse recovery demonstrate the effectiveness of our approach.
  Keywords: Fractional Minimization, Nonconvex Optimization, Proximal Linearized ADMM, Nonsmooth Optimization, Convergence Analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07496v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Stability for a stochastic fractional differential variational inequality with L\'{e}vy jump</title>
      <link>https://arxiv.org/abs/2411.07557</link>
      <description>arXiv:2411.07557v1 Announce Type: new 
Abstract: The main goal of this paper is to investigate the multi-parameter stability result for a stochastic fractional differential variational inequality with L\'{e}vy jump (SFDVI with L\'{e}vy jump) under some mild conditions. We verify that Mosco convergence of the perturbed set implies point convergence of the projection onto the Hilbert space consisting of special stochastic processes whose range is the perturbed set. Moreover, by using the projection method and some inequality techniques, we establish a strong convergence result for the solution of SFDVI with L\'{e}vy jump when the mappings and constraint set are both perturbed. Finally, we apply the stability results to the spatial price equilibrium problem and the multi-agent optimization problem in stochastic environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07557v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Zeng, Yao-jia Zhang, Nan-jing Huang</dc:creator>
    </item>
    <item>
      <title>The analytic criterion of strict copositivity for a 4th-order 3-dimensional tensor</title>
      <link>https://arxiv.org/abs/2411.07596</link>
      <description>arXiv:2411.07596v1 Announce Type: new 
Abstract: This paper focuses on the strict copositivity analysis of 4th-order 3-dimensional symmetric tensors. A necessary and sufficient condition is provided for the strict copositivity of a fourth-order symmetric tensor. Subsequently, building upon this conclusion, we discuss the strict copositivity of fourth-order three-dimensional symmetric tensors with its entries $\pm 1, 0$, and further build their necessary and sufficient conditions. Utilizing these theorems, we can effectively verify the strict copositivity of a general fourth-order three-dimensional symmetric tensors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07596v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingjun Sheng, Yisheng Song</dc:creator>
    </item>
    <item>
      <title>A preconditioned second-order convex splitting algorithm with a difference of varying convex functions and line search</title>
      <link>https://arxiv.org/abs/2411.07661</link>
      <description>arXiv:2411.07661v1 Announce Type: new 
Abstract: This paper introduces a preconditioned convex splitting algorithm enhanced with line search techniques for nonconvex optimization problems. The algorithm utilizes second-order backward differentiation formulas (BDF) for the implicit and linear components and the Adams-Bashforth scheme for the nonlinear and explicit parts of the gradient flow in variational functions. The proposed algorithm, resembling a generalized difference-of-convex-function approach, involves a changing set of convex functions in each iteration. It integrates the Armijo line search strategy to improve performance. The study also discusses classical preconditioners such as symmetric Gauss-Seidel, Jacobi, and Richardson within this context. The global convergence of the algorithm is established through the Kurdyka-{\L}ojasiewicz properties, ensuring convergence within a finite number of preconditioned iterations. Numerical experiments demonstrate the superiority of the proposed second-order convex splitting with line search over conventional difference-of-convex-function algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07661v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinhua Shen, Zaijiu Shang, Hongpeng Sun</dc:creator>
    </item>
    <item>
      <title>Second-order Optimality Conditions for Time-Optimal Control Problems Governed by Semilinear Parabolic Equations</title>
      <link>https://arxiv.org/abs/2411.07723</link>
      <description>arXiv:2411.07723v1 Announce Type: new 
Abstract: A class of time-optimal control problems governed by semilinear parabolic equations with mixed pointwise constraints and final point constraints is considered. By introducing the so-called locally optimal solution to time-optimal control problems, we establish first and second-order necessary optimality conditions of KKT-type and second-order sufficient conditions for locally optimal solutions to the problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07723v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huynh Khanh, Bui Trong Kien, Arnd R\"osch</dc:creator>
    </item>
    <item>
      <title>Scaling policy iteration based reinforcement learning for unknown discrete-time linear systems</title>
      <link>https://arxiv.org/abs/2411.07825</link>
      <description>arXiv:2411.07825v1 Announce Type: new 
Abstract: In optimal control problem, policy iteration (PI) is a powerful reinforcement learning (RL) tool used for designing optimal controller for the linear systems. However, the need for an initial stabilizing control policy significantly limits its applicability. To address this constraint, this paper proposes a novel scaling technique, which progressively brings a sequence of stable scaled systems closer to the original system, enabling the acquisition of stable control gain. Based on the designed scaling update law, we develop model-based and model-free scaling policy iteration (SPI) algorithms for solving the optimal control problem for discrete-time linear systems, in both known and completely unknown system dynamics scenarios. Unlike existing works on PI based RL, the SPI algorithms do not necessitate an initial stabilizing gain to initialize the algorithms, they can achieve the optimal control under any initial control gain. Finally, the numerical results validate the theoretical findings and confirm the effectiveness of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07825v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen Pang, Shengda Tang, Jun Cheng, Shuping He</dc:creator>
    </item>
    <item>
      <title>Suboptimal MPC with a Computation Governor: Stability, Recursive Feasibility, and Applications to ADMM</title>
      <link>https://arxiv.org/abs/2411.07919</link>
      <description>arXiv:2411.07919v1 Announce Type: new 
Abstract: The paper considers a computational governor strategy to facilitate the implementation of Model Predictive Control (MPC) based on inexact optimization when the time available to compute the solution may be insufficient. In the setting of linear-quadratic MPC and a class of optimizers that includes Alternating Direction Method of Multipliers (ADMM), we derive conditions on the reference command adjustment by the computational governor and on a constraint tightening strategy which ensure recursive feasibility, convergence of the modified reference command, and closed-loop stability. An online procedure to select the modified reference command and construct an implicit terminal set is also proposed. A simulation example is reported which illustrates the developed procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07919v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven van Leeuwen, Ilya Kolmanovsky</dc:creator>
    </item>
    <item>
      <title>Optimization Thresholding Problem</title>
      <link>https://arxiv.org/abs/2411.07949</link>
      <description>arXiv:2411.07949v1 Announce Type: new 
Abstract: We consider a simplified model for optimizing a single-asset portfolio in the presence of transaction costs given a signal with a certain autocorrelation and cross-correlation structure. In our setup, the portfolio manager is given two one-parameter controls to influence the construction of the portfolio. The first is a linear filtering parameter that may increase or decrease the level of autocorrelation in the signal. The second is a numerical threshold that determines a symmetric ``no-trade" zone. Portfolio positions are constrained to a single unit long or a single unit short. These constraints allow us to focus on the interplay between the signal filtering mechanism and the hysteresis introduced by the ``no-trade" zone. We then formulate an optimization problem where we aim to minimize the frequency of trades subject to a fixed return level of the portfolio. We show that maintaining a no-trade zone while removing autocorrelation entirely from the signal yields a locally optimal solution. For any given ``no-trade" zone threshold, this locally optimal solution also achieves the maximum attainable return level, and we derive a quantitative lower bound for the amount of improvement in terms of the given threshold and the amount of autocorrelation removed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07949v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.PM</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chutian Ma, Paul Smith</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis and Acceleration of Fictitious Play for General Mean-Field Games via the Best Response</title>
      <link>https://arxiv.org/abs/2411.07989</link>
      <description>arXiv:2411.07989v1 Announce Type: new 
Abstract: A mean-field game (MFG) seeks the Nash Equilibrium of a game involving a continuum of players, where the Nash Equilibrium corresponds to a fixed point of the best-response mapping. However, simple fixed-point iterations do not always guarantee convergence. Fictitious play is an iterative algorithm that leverages a best-response mapping combined with a weighted average. Through a thorough study of the best-response mapping, this paper develops a simple and unified convergence analysis, providing the first explicit convergence rate for the fictitious play algorithm in MFGs of general types, especially non-potential MFGs. We demonstrate that the convergence and rate can be controlled through the weighting parameter in the algorithm, with linear convergence achievable under a general assumption. Building on this analysis, we propose two strategies to accelerate fictitious play. The first uses a backtracking line search to optimize the weighting parameter, while the second employs a hierarchical grid strategy to enhance stability and computational efficiency. We demonstrate the effectiveness of these acceleration techniques and validate our convergence rate analysis with various numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07989v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiajia Yu, Xiuyuan Cheng, Jian-Guo Liu, Hongkai Zhao</dc:creator>
    </item>
    <item>
      <title>Projection onto cones generated by epigraphs of perspective functions</title>
      <link>https://arxiv.org/abs/2411.08000</link>
      <description>arXiv:2411.08000v1 Announce Type: new 
Abstract: In this paper we provide an efficient computation of the projection onto the cone generated by the epigraph of the perspective of any convex lower semicontinuous function. Our formula requires solving only two scalar equations involving the proximity operator of the function. This enables the computation of projections, for instance, onto exponential and power cones, and extends to previously unexplored conic projections, such as the projection onto the hyperbolic cone. We compare numerically the efficiency of the proposed approach in the case of exponential cones with an open source available method in the literature, illustrating its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08000v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis M. Brice\~no-Arias, Crist\'obal Vivar-Vargas</dc:creator>
    </item>
    <item>
      <title>Cutting Some Slack for SGD with Adaptive Polyak Stepsizes</title>
      <link>https://arxiv.org/abs/2202.12328</link>
      <description>arXiv:2202.12328v2 Announce Type: cross 
Abstract: Tuning the step size of stochastic gradient descent is tedious and error prone. This has motivated the development of methods that automatically adapt the step size using readily available information. In this paper, we consider the family of SPS (Stochastic gradient with a Polyak Stepsize) adaptive methods. These are methods that make use of gradient and loss value at the sampled points to adaptively adjust the step size. We first show that SPS and its recent variants can all be seen as extensions of the Passive-Aggressive methods applied to nonlinear problems. We use this insight to develop new variants of the SPS method that are better suited to nonlinear models. Our new variants are based on introducing a slack variable into the interpolation equations. This single slack variable tracks the loss function across iterations and is used in setting a stable step size. We provide extensive numerical results supporting our new methods and a convergence theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.12328v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert M. Gower, Mathieu Blondel, Nidham Gazagnadou, Fabian Pedregosa</dc:creator>
    </item>
    <item>
      <title>Coupled Wasserstein Gradient Flows for Min-Max and Cooperative Games</title>
      <link>https://arxiv.org/abs/2411.07403</link>
      <description>arXiv:2411.07403v1 Announce Type: cross 
Abstract: We propose a framework for two-player infinite-dimensional games with cooperative or competitive structure. These games take the form of coupled partial differential equations in which players optimize over a space of measures, driven by either a gradient descent or gradient descent-ascent in Wasserstein-2 space. We characterize the properties of the Nash equilibrium of the system, and relate it to the steady state of the dynamics. In the min-max setting, we show, under sufficient convexity conditions, that solutions converge exponentially fast and with explicit rate to the unique Nash equilibrium. Similar results are obtained for the cooperative setting. We apply this framework to distribution shift induced by interactions among a strategic population of agents and an algorithm, proving additional convergence results in the timescale-separated setting. We illustrate the performance of our model on (i) real data from an economics study on Colombia census data, (ii) feature modification in loan applications, and (iii) performative prediction. The numerical experiments demonstrate the importance of distribution-level, rather than moment-level, modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07403v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lauren Conger, Franca Hoffmann, Eric Mazumdar, Lillian J. Ratliff</dc:creator>
    </item>
    <item>
      <title>Degree Matrix Comparison for Graph Alignment</title>
      <link>https://arxiv.org/abs/2411.07475</link>
      <description>arXiv:2411.07475v1 Announce Type: cross 
Abstract: Graph alignment considers the optimal node correspondence across networks. To advance unsupervised graph alignment algorithms on plain graphs, we propose Degree Matrix Comparison (DMC). Through extensive experiments and mathematical motivations, we demonstrate the potential of this method. Remarkably, DMC achieves up to 99% correct node alignment for 90%-overlap graphs and 100% accuracy for isomorphic graphs. Additionally, we propose a reduced version of DMC (Greedy DMC) that provides a solution to the graph alignment problem with lower time complexity. DMC could significantly impact graph alignment, offering a reliable solution for the task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07475v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Wang, Peter Chin</dc:creator>
    </item>
    <item>
      <title>Unraveling the Gradient Descent Dynamics of Transformers</title>
      <link>https://arxiv.org/abs/2411.07538</link>
      <description>arXiv:2411.07538v1 Announce Type: cross 
Abstract: While the Transformer architecture has achieved remarkable success across various domains, a thorough theoretical foundation explaining its optimization dynamics is yet to be fully developed. In this study, we aim to bridge this understanding gap by answering the following two core questions: (1) Which types of Transformer architectures allow Gradient Descent (GD) to achieve guaranteed convergence? and (2) Under what initial conditions and architectural specifics does the Transformer achieve rapid convergence during training? By analyzing the loss landscape of a single Transformer layer using Softmax and Gaussian attention kernels, our work provides concrete answers to these questions. Our findings demonstrate that, with appropriate weight initialization, GD can train a Transformer model (with either kernel type) to achieve a global optimal solution, especially when the input embedding dimension is large. Nonetheless, certain scenarios highlight potential pitfalls: training a Transformer using the Softmax attention kernel may sometimes lead to suboptimal local solutions. In contrast, the Gaussian attention kernel exhibits a much favorable behavior. Our empirical study further validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07538v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bingqing Song, Boran Han, Shuai Zhang, Jie Ding, Mingyi Hong</dc:creator>
    </item>
    <item>
      <title>Convergence Rate Analysis of LION</title>
      <link>https://arxiv.org/abs/2411.07724</link>
      <description>arXiv:2411.07724v1 Announce Type: cross 
Abstract: The LION (evoLved sIgn mOmeNtum) optimizer for deep neural network training was found by Google via program search, with the simple sign update yet showing impressive performance in training large scale networks. Although previous studies have investigated its convergence properties, a comprehensive analysis, especially the convergence rate, is still desirable. Recognizing that LION can be regarded as solving a specific constrained problem, this paper focuses on demonstrating its convergence to the Karush-Kuhn-Tucker (KKT) point at the rate of $\cal O(\sqrt{d}K^{-1/4})$ measured by gradient $\ell_1$ norm, where $d$ is the problem dimension and $K$ is the number of iteration steps. Step further, we remove the constraint and establish that LION converges to the critical point of the general unconstrained problem at the same rate. This rate not only delivers the currently optimal dependence on the problem dimension $d$ but also tightly matches the theoretical lower bound for nonconvex stochastic optimization algorithms, which is typically measured using the gradient $\ell_2$ norm, with respect to the number of iterations $K$. Through extensive experiments, we not only demonstrate that LION achieves lower loss and higher performance compared to standard SGD, but also empirically confirm that the gradient $\ell_1/\ell_2$ norm ratio aligns with $\Theta(\sqrt{d})$, thus proving that our convergence rate matches the theoretical lower bound with respect to $d$ in the empirical sense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07724v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiming Dong, Huan Li, Zhouchen Lin</dc:creator>
    </item>
    <item>
      <title>A variational approach to the stability in the homogenization of some Hamilton-Jacobi equations</title>
      <link>https://arxiv.org/abs/2411.07756</link>
      <description>arXiv:2411.07756v1 Announce Type: cross 
Abstract: We investigate the stability with respect to homogenization of classes of integrals arising in the control-theoretic interpretation of some Hamilton-Jacobi equations. The prototypical case is the homogenization of energies with a Lagrangian consisting of the sum of a kinetic term and a highly oscillatory potential $V =V_{\rm per}+ W$, where $V_{\rm per}$ is periodic and $W$ is a nonnegative perturbation thereof. We assume that $W$ has zero average in tubular domains oriented along a dense set of directions. Stability then holds true; that is, the resulting homogenized functional is identical to that for $W= 0$. We consider various extensions of this case. As a consequence of our results, we obtain stability for the homogenization of some steady-state and time-dependent, first-order Hamilton-Jacobi equations with convex Hamiltonians and perturbed periodic potentials. Finally, we show with an example that, for negative $W$, stability may not hold. Our study revisits and, depending on the different assumptions, complements results obtained by P.-L. Lions and collaborators using PDE techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07756v1</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Braides, Gianni Dal Maso, Claude Le Bris</dc:creator>
    </item>
    <item>
      <title>Approximation rates of entropic maps in semidiscrete optimal transport</title>
      <link>https://arxiv.org/abs/2411.07947</link>
      <description>arXiv:2411.07947v1 Announce Type: cross 
Abstract: Entropic optimal transport offers a computationally tractable approximation to the classical problem. In this note, we study the approximation rate of the entropic optimal transport map (in approaching the Brenier map) when the regularization parameter $\varepsilon$ tends to zero in the semidiscrete setting, where the input measure is absolutely continuous while the output is finitely discrete. Previous work shows that the approximation rate is $O(\sqrt{\varepsilon})$ under the $L^2$-norm with respect to the input measure. In this work, we establish faster, $O(\varepsilon^2)$ rates up to polylogarithmic factors, under the dual Lipschitz norm, which is weaker than the $L^2$-norm. For the said dual norm, the $O(\varepsilon^2)$ rate is sharp. As a corollary, we derive a central limit theorem for the entropic estimator for the Brenier map in the dual Lipschitz space when the regularization parameter tends to zero as the sample size increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07947v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ritwik Sadhu, Ziv Goldfeld, Kengo Kato</dc:creator>
    </item>
    <item>
      <title>A Block Coordinate Descent Method for Nonsmooth Composite Optimization under Orthogonality Constraints</title>
      <link>https://arxiv.org/abs/2304.03641</link>
      <description>arXiv:2304.03641v2 Announce Type: replace 
Abstract: Nonsmooth composite optimization with orthogonality constraints is crucial in statistical learning and data science, but it presents challenges due to its nonsmooth objective and computationally expensive, non-convex constraints. In this paper, we propose a new approach called \textbf{OBCD}, which leverages Block Coordinate Descent (BCD) to address these challenges. \textbf{OBCD} is a feasible method with a small computational footprint. In each iteration, it updates $k$ rows of the solution matrix, where $k \geq 2$, while globally solving a small nonsmooth optimization problem under orthogonality constraints. We prove that \textbf{OBCD} converges to block-$k$ stationary points, which offer stronger optimality than standard critical points. Notably, \textbf{OBCD} is the first greedy descent method with monotonicity for this problem class. Under the Kurdyka-Lojasiewicz (KL) inequality, we establish strong limit-point convergence. We also extend \textbf{OBCD} with breakpoint searching methods for subproblem solving and greedy strategies for working set selection. Comprehensive experiments demonstrate the superior performance of our approach across various tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03641v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Enhanced computation of the proximity operator for perspective functions</title>
      <link>https://arxiv.org/abs/2305.04999</link>
      <description>arXiv:2305.04999v2 Announce Type: replace 
Abstract: In this paper we provide an explicit expression for the proximity operator of a perspective of any proper lower semicontinuous convex function defined on a Hilbert space. Our computation enhances and generalizes known formulae for the case when the Fenchel conjugate of the convex function has open domain or when it is radial. We provide several examples of non-radial functions for which the domain of its conjugate is not open and we compute the proximity operators of their perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.04999v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luis M. Brice\~no-Arias, Crist\'obal Vivar-Vargas</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Model Predictive Control: Closed-loop Guarantees and Scalable Algorithms</title>
      <link>https://arxiv.org/abs/2309.12758</link>
      <description>arXiv:2309.12758v2 Announce Type: replace 
Abstract: We establish a collection of closed-loop guarantees and propose a scalable optimization algorithm for distributionally robust model predictive control (DRMPC) applied to linear systems, convex constraints, and quadratic costs. Via standard assumptions for the terminal cost and constraint, we establish distribtionally robust long-term and stage-wise performance guarantees for the closed-loop system. We further demonstrate that a common choice of the terminal cost, i.e., via the discrete-algebraic Riccati equation, renders the origin input-to-state stable for the closed-loop system. This choice also ensures that the exact long-term performance of the closed-loop system is independent of the choice of ambiguity set for the DRMPC formulation. Thus, we establish conditions under which DRMPC does not provide a long-term performance benefit relative to stochastic MPC. To solve the DRMPC optimization problem, we propose a Newton-type algorithm that empirically achieves superlinear convergence and guarantees the feasibility of each iterate. We demonstrate the implications of the closed-loop guarantees and the scalability of the proposed algorithm via two examples. To facilitate the reproducibility of the results, we also provide open-source code to implement the proposed algorithm and generate the figures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.12758v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert D. McAllister, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>A Knowledge Compilation Take on Binary Polynomial Optimization</title>
      <link>https://arxiv.org/abs/2311.00149</link>
      <description>arXiv:2311.00149v2 Announce Type: replace 
Abstract: The Binary Polynomial Optimization (BPO) problem is defined as the problem of maximizing a given polynomial function over all binary points. The main contribution of this paper is to draw a novel connection between BPO and the field of Knowledge Compilation. This connection allows us to unify and significantly extend the state-of-the-art for BPO, both in terms of tractable classes, and in terms of existence of extended formulations. In particular, for instances of BPO with hypergraphs that are either $\beta$-acyclic or with bounded incidence treewidth, we obtain strongly polynomial algorithms for BPO, and extended formulations of polynomial size for the corresponding multilinear polytopes. The generality of our technique allows us to obtain the same type of results for extensions of BPO, where we enforce extended cardinality constraints on the set of binary points, and where variables are replaced by literals. We also obtain strongly polynomial algorithms for the variant of the above problems where we seek $k$ best feasible solutions, instead of only one optimal solution. Computational results show that the resulting algorithms can be significantly faster than current state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00149v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Florent Capelli, Alberto Del Pia, Silvia Di Gregorio</dc:creator>
    </item>
    <item>
      <title>Piecewise Linearity of Min-Norm Solution Map of a Nonconvexly Regularized Convex Sparse Model</title>
      <link>https://arxiv.org/abs/2311.18438</link>
      <description>arXiv:2311.18438v3 Announce Type: replace 
Abstract: It is well known that the minimum $\ell_2$-norm solution of the convex LASSO model, say $\mathbf{x}_{\star}$, is a continuous piecewise linear function of the regularization parameter $\lambda$, and its signed sparsity pattern is constant within each linear piece. The current study is an extension of this classic result, proving that the aforementioned properties extend to the min-norm solution map $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, where $\mathbf{y}$ is the observed signal, for a generalization of LASSO termed the scaled generalized minimax concave (sGMC) model. The sGMC model adopts a nonconvex debiased variant of the $\ell_1$-norm as sparse regularizer, but its objective function is overall-convex. Based on the geometric properties of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we propose an extension of the least angle regression (LARS) algorithm, which iteratively computes the closed-form expression of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ in each linear zone. Under suitable conditions, the proposed algorithm provably obtains the whole solution map $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ within finite iterations. Notably, our proof techniques for establishing continuity and piecewise linearity of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$ are novel, and they lead to two side contributions: (a) our proofs establish continuity of the sGMC solution set as a set-valued mapping of $(\mathbf{y},\lambda)$; (b) to prove piecewise linearity and piecewise constant sparsity pattern of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we do not require any assumption that previous work relies on (whereas to prove some additional properties of $\mathbf{x}_{\star}(\mathbf{y},\lambda)$, we use a different set of assumptions from previous work).</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18438v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Zhang, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>Auto-Calibration and Biconvex Compressive Sensing with Applications to Parallel MRI</title>
      <link>https://arxiv.org/abs/2401.10400</link>
      <description>arXiv:2401.10400v2 Announce Type: replace 
Abstract: We study an auto-calibration problem in which a transform-sparse signal is acquired via compressive sensing by multiple sensors in parallel, but with unknown calibration parameters of the sensors. This inverse problem has an important application in pMRI reconstruction, where the calibration parameters of the receiver coils are often difficult and costly to obtain explicitly, but nonetheless are a fundamental requirement for high-precision reconstructions. Most auto-calibration strategies for this problem involve solving a challenging biconvex optimization problem, which lacks reconstruction guarantees. In this work, we transform the auto-calibrated parallel compressive sensing problem to a convex optimization problem using the idea of `lifting'. By exploiting sparsity structures in the signal and the redundancy introduced by multiple sensors, we solve a mixed-norm minimization problem to recover the underlying signal and the sensing parameters simultaneously. Our method provides robust and stable recovery guarantees that take into account the presence of noise and sparsity deficiencies in the signals. As such, it offers a theoretically guaranteed approach to auto-calibrated parallel imaging in MRI under appropriate assumptions. Applications in compressive sensing pMRI are discussed, and numerical experiments using real and simulated MRI data are presented to support our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10400v2</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Ni, Thomas Strohmer</dc:creator>
    </item>
    <item>
      <title>ADMM for Nonsmooth Composite Optimization under Orthogonality Constraints</title>
      <link>https://arxiv.org/abs/2405.15129</link>
      <description>arXiv:2405.15129v2 Announce Type: replace 
Abstract: We consider a class of structured, nonconvex, nonsmooth optimization problems under orthogonality constraints, where the objectives combine a smooth function, a nonsmooth concave function, and a nonsmooth weakly convex function. This class of problems finds diverse applications in statistical learning and data science. Existing methods for addressing these problems often fail to exploit the specific structure of orthogonality constraints, struggle with nonsmooth functions, or result in suboptimal oracle complexity. We propose {\sf OADMM}, an Alternating Direction Method of Multipliers (ADMM) designed to solve this class of problems using efficient proximal linearized strategies. Two specific variants of {\sf OADMM} are explored: one based on Euclidean Projection ({\sf OADMM-EP}) and the other on Riemannian Retraction ({\sf OADMM-RR}). Under mild assumptions, we prove that {\sf OADMM} converges to a critical point of the problem with an ergodic convergence rate of $\mathcal{O}(1/\epsilon^{3})$. Additionally, we establish a super-exponential convergence rate or polynomial convergence rate for {\sf OADMM}, depending on the specific setting, under the Kurdyka-Lojasiewicz (KL) inequality. To the best of our knowledge, this is the first non-ergodic convergence result for this class of nonconvex nonsmooth optimization problems. Numerical experiments demonstrate that the proposed algorithm achieves state-of-the-art performance.
  \textbf{Keywords:} Orthogonality Constraints; Nonconvex Optimization; Nonsmooth Composite Optimization; ADMM; Convergence Analysis</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15129v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ganzhao Yuan</dc:creator>
    </item>
    <item>
      <title>Tikhonov regularization of monotone operator flows not only ensures strong convergence of the trajectories but also speeds up the vanishing of the residuals</title>
      <link>https://arxiv.org/abs/2406.00852</link>
      <description>arXiv:2406.00852v3 Announce Type: replace 
Abstract: In the framework of real Hilbert spaces, we investigate first-order dynamical systems governed by monotone and continuous operators. We demonstrate that when the monotone operator flow is augmented with a Tikhonov regularization term, the resulting trajectory converges strongly to the element of the set of zeros with minimal norm. In addition, rates of convergence in norm for the trajectory's velocity and the operator along the trajectory can be derived in terms of the regularization function. In some particular cases, these rates of convergence can outperform the ones of the coercive operator flows and can be as fast as $O(\frac{1}{t})$ as $t \rightarrow +\infty$. In this way, we emphasize a surprising acceleration feature of the Tikhonov regularization. Additionally, we explore these properties for monotone operator flows that incorporate time rescaling and an anchor point and show that they are closely linked to second-order dynamics with a vanishing damping term. The convergence and convergence rate results we achieve for these systems complement recent findings for the Fast Optimistic Gradient Descent Ascent (OGDA) dynamics.
  When the monotone operator is defined as the identity minus a nonexpansive operator, the monotone equations transform into a fixed point problem. In such cases, explicitly discretizing the system with Tikhonov regularization, enhanced by an anchor point, leads to the Halpern fixed point iteration. We identify two regimes for the regularization sequence which ensure that the generated sequence of iterates converges strongly to the fixed point nearest to the anchor point. Furthermore, we establish a general theoretical framework that provides convergence rates for the vanishing of the discrete velocity and the fixed point residual. For certain regularization sequences, we derive specific convergence rates that align with those observed in continuous time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00852v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Radu Ioan Bot, Dang-Khoa Nguyen</dc:creator>
    </item>
    <item>
      <title>Block cubic Newton with greedy selection</title>
      <link>https://arxiv.org/abs/2407.18150</link>
      <description>arXiv:2407.18150v2 Announce Type: replace 
Abstract: A second-order block coordinate descent method is proposed for the unconstrained minimization of an objective function with Lipschitz continuous Hessian. At each iteration, a block of variables is selected by means of a greedy (Gauss-Southwell) rule which considers the amount of first-order stationarity violation, then an approximate minimizer of a cubic model is computed for the block update. In the proposed scheme, blocks are not required to have a prefixed structure and their size is allowed to change during the iterations. For non-convex objective functions, global convergence to stationary points is proved and a worst-case iteration complexity analysis is provided. In particular, given a tolerance $\epsilon$, we show that at most ${\cal O}(\epsilon^{-3/2})$ iterations are needed to drive the stationarity violation with respect to the selected block of variables below $\epsilon$, while at most ${\cal O}(\epsilon^{-2})$ iterations are needed to drive the stationarity violation with respect to all variables below $\epsilon$. Numerical results are finally provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18150v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrea Cristofari</dc:creator>
    </item>
    <item>
      <title>Beyond Discretization: Learning the Optimal Solution Path</title>
      <link>https://arxiv.org/abs/2410.14885</link>
      <description>arXiv:2410.14885v2 Announce Type: replace 
Abstract: Many applications require minimizing a family of optimization problems indexed by some hyperparameter $\lambda \in \Lambda$ to obtain an entire solution path. Traditional approaches proceed by discretizing $\Lambda$ and solving a series of optimization problems. We propose an alternative approach that parameterizes the solution path with a set of basis functions and solves a \emph{single} stochastic optimization problem to learn the entire solution path. Our method offers substantial complexity improvements over discretization. When using constant-step size SGD, the uniform error of our learned solution path relative to the true path exhibits linear convergence to a constant related to the expressiveness of the basis. When the true solution path lies in the span of the basis, this constant is zero. We also prove stronger results for special cases common in machine learning: When $\lambda \in [-1, 1]$ and the solution path is $\nu$-times differentiable, constant step-size SGD learns a path with $\epsilon$ uniform error after at most $O(\epsilon^{\frac{1}{1-\nu}} \log(1/\epsilon))$ iterations, and when the solution path is analytic, it only requires $O\left(\log^2(1/\epsilon)\log\log(1/\epsilon)\right)$. By comparison, the best-known discretization schemes in these settings require at least $O(\epsilon^{-1/2})$ discretization points (and even more gradient calls). Finally, we propose an adaptive variant of our method that sequentially adds basis functions and demonstrates strong numerical performance through experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.14885v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiran Dong, Paul Grigas, Vishal Gupta</dc:creator>
    </item>
    <item>
      <title>Sard properties for polynomial maps in infinite dimension</title>
      <link>https://arxiv.org/abs/2407.02296</link>
      <description>arXiv:2407.02296v2 Announce Type: replace-cross 
Abstract: Sard's theorem asserts that the set of critical values of a smooth map from one Euclidean space to another one has measure zero. A version of this result for infinite-dimensional Banach manifolds was proven by Smale for maps with Fredholm differential. It is well-known, however, that when the domain is infinite dimensional and the range is finite dimensional, the result is not true -- even under the assumption that the map is ``polynomial'' -- and a general theory is still lacking. Addressing this issue, in this paper, we provide sharp quantitative criteria for the validity of Sard's theorem in this setting. Our motivation comes from sub-Riemannian geometry and, as an application of our results, we prove the sub-Riemannian Sard conjecture for the restriction of the Endpoint map of Carnot groups to the set of piece-wise real-analytic controls with large enough radius of convergence, and the strong Sard conjecture for the restriction to the set of piece-wise entire controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02296v2</guid>
      <category>math.DG</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Lerario, Luca Rizzi, Daniele Tiberio</dc:creator>
    </item>
    <item>
      <title>Robust Clustering on High-Dimensional Data with Stochastic Quantization</title>
      <link>https://arxiv.org/abs/2409.02066</link>
      <description>arXiv:2409.02066v4 Announce Type: replace-cross 
Abstract: This paper addresses the limitations of conventional vector quantization algorithms, particularly K-Means and its variant K-Means++, and investigates the Stochastic Quantization (SQ) algorithm as a scalable alternative for high-dimensional unsupervised and semi-supervised learning tasks. Traditional clustering algorithms often suffer from inefficient memory utilization during computation, necessitating the loading of all data samples into memory, which becomes impractical for large-scale datasets. While variants such as Mini-Batch K-Means partially mitigate this issue by reducing memory usage, they lack robust theoretical convergence guarantees due to the non-convex nature of clustering problems. In contrast, the Stochastic Quantization algorithm provides strong theoretical convergence guarantees, making it a robust alternative for clustering tasks. We demonstrate the computational efficiency and rapid convergence of the algorithm on an image classification problem with partially labeled data, comparing model accuracy across various ratios of labeled to unlabeled data. To address the challenge of high dimensionality, we employ a Triplet Network to encode images into low-dimensional representations in a latent space, which serve as a basis for comparing the efficiency of both the Stochastic Quantization algorithm and traditional quantization algorithms. Furthermore, we enhance the algorithm's convergence speed by introducing modifications with an adaptive learning rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02066v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Anton Kozyriev, Vladimir Norkin</dc:creator>
    </item>
    <item>
      <title>A Review of Scalable and Privacy-Preserving Multi-Agent Frameworks for Distributed Energy Resources</title>
      <link>https://arxiv.org/abs/2409.14499</link>
      <description>arXiv:2409.14499v2 Announce Type: replace-cross 
Abstract: Distributed energy resources (DERs) are gaining prominence due to their advantages in improving energy efficiency, reducing carbon emissions, and enhancing grid resilience. Despite the increasing deployment, the potential of DERs has yet to be fully explored and exploited. A fundamental question restrains the management of numerous DERs in large-scale power systems, "How should DER data be securely processed and DER operations be efficiently optimized?" To address this question, this paper considers two critical issues, namely privacy for processing DER data and scalability in optimizing DER operations, then surveys existing and emerging solutions from a multi-agent framework perspective. In the context of scalability, this paper reviews state-of-the-art research that relies on parallel control, optimization, and learning within distributed and/or decentralized information exchange structures, while in the context of privacy, it identifies privacy preservation measures that can be synthesized into the aforementioned scalable structures. Despite research advances in these areas, challenges remain because these highly interdisciplinary studies blend a wide variety of scalable computing architectures and privacy preservation techniques from different fields, making them difficult to adapt in practice. To mitigate this issue, this paper provides a holistic review of trending strategies that orchestrate privacy and scalability for large-scale power system operations from a multi-agent perspective, particularly for DER control problems. Furthermore, this review extrapolates new approaches for future scalable, privacy-aware, and cybersecure pathways to unlock the full potential of DERs through controlling, optimizing, and learning generic multi-agent-based cyber-physical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14499v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 13 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Huo, Hao Huang, Katherine R. Davis, H. Vincent Poor, Mingxi Liu</dc:creator>
    </item>
  </channel>
</rss>
