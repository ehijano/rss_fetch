<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 01:52:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ENOVA: Autoscaling towards Cost-effective and Stable Serverless LLM Serving</title>
      <link>https://arxiv.org/abs/2407.09486</link>
      <description>arXiv:2407.09486v1 Announce Type: new 
Abstract: Since the increasing popularity of large language model (LLM) backend systems, it is common and necessary to deploy stable serverless serving of LLM on multi-GPU clusters with autoscaling. However, there exist challenges because the diversity and co-location of applications in multi-GPU clusters will lead to low service quality and GPU utilization. To address them, we build ENOVA, a deployment, monitoring and autoscaling service towards serverless LLM serving. ENOVA deconstructs the execution process of LLM service comprehensively, based on which ENOVA designs a configuration recommendation module for automatic deployment on any GPU clusters and a performance detection module for autoscaling. On top of them, ENOVA implements a deployment execution engine for multi-GPU cluster scheduling. The experiment results show that ENOVA significantly outperforms other state-of-the-art methods and is suitable for wide deployment in large online systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09486v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Huang, Pengfei Chen, Kyoka Gong, Jocky Hawk, Zachary Bright, Wenxin Xie, Kecheng Huang, Zhi Ji</dc:creator>
    </item>
    <item>
      <title>Application of cloud computing platform in industrial big data processing</title>
      <link>https://arxiv.org/abs/2407.09491</link>
      <description>arXiv:2407.09491v1 Announce Type: new 
Abstract: With the rapid growth and increasing complexity of industrial big data, traditional data processing methods are facing many challenges. This article takes an in-depth look at the application of cloud computing technology in industrial big data processing and explores its potential impact on improving data processing efficiency, security, and cost-effectiveness. The article first reviews the basic principles and key characteristics of cloud computing technology, and then analyzes the characteristics and processing requirements of industrial big data. In particular, this study focuses on the application of cloud computing in real-time data processing, predictive maintenance, and optimization, and demonstrates its practical effects through case studies. At the same time, this article also discusses the main challenges encountered during the implementation process, such as data security, privacy protection, performance and scalability issues, and proposes corresponding solution strategies. Finally, this article looks forward to the future trends of the integration of cloud computing and industrial big data, as well as the application prospects of emerging technologies such as artificial intelligence and machine learning in this field. The results of this study not only provide practical guidance for cloud computing applications in the industry, but also provide a basis for further research in academia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09491v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyan Yao</dc:creator>
    </item>
    <item>
      <title>Memory Lower Bounds and Impossibility Results for Anonymous Dynamic Broadcast</title>
      <link>https://arxiv.org/abs/2407.09714</link>
      <description>arXiv:2407.09714v1 Announce Type: new 
Abstract: Broadcast is a ubiquitous distributed computing problem that underpins many other system tasks. In static, connected networks, it was recently shown that broadcast is solvable without any node memory and only constant-size messages in worst-case asymptotically optimal time (Hussak and Trehan, PODC'19/STACS'20/DC'23). In the dynamic setting of adversarial topology changes, however, existing algorithms rely on identifiers, port labels, or polynomial memory to solve broadcast and compute functions over node inputs. We investigate space-efficient, terminating broadcast algorithms for anonymous, synchronous, 1-interval connected dynamic networks and introduce the first memory lower bounds in this setting. Specifically, we prove that broadcast with termination detection is impossible for idle-start algorithms (where only the broadcaster can initially send messages) and otherwise requires $\Omega(\log n)$ memory per node, where $n$ is the number of nodes in the network. Even if the termination condition is relaxed to stabilizing termination (eventually no additional messages are sent), we show that any idle-start algorithm must use $\omega(1)$ memory per node, separating the static and dynamic settings for anonymous broadcast. This lower bound is not far from optimal, as we present an algorithm that solves broadcast with stabilizing termination using $\mathcal{O}(\log n)$ memory per node in worst-case asymptotically optimal time. In sum, these results reveal the necessity of non-constant memory for nontrivial terminating computation in anonymous dynamic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09714v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Garrett Parzych, Joshua J. Daymude</dc:creator>
    </item>
    <item>
      <title>DRPC: Distributed Reinforcement Learning Approach for Scalable Resource Provisioning in Container-based Clusters</title>
      <link>https://arxiv.org/abs/2407.10169</link>
      <description>arXiv:2407.10169v1 Announce Type: new 
Abstract: Microservices have transformed monolithic applications into lightweight, self-contained, and isolated application components, establishing themselves as a dominant paradigm for application development and deployment in public clouds such as Google and Alibaba. Autoscaling emerges as an efficient strategy for managing resources allocated to microservices' replicas. However, the dynamic and intricate dependencies within microservice chains present challenges to the effective management of scaled microservices. Additionally, the centralized autoscaling approach can encounter scalability issues, especially in the management of large-scale microservice-based clusters. To address these challenges and enhance scalability, we propose an innovative distributed resource provisioning approach for microservices based on the Twin Delayed Deep Deterministic Policy Gradient algorithm. This approach enables effective autoscaling decisions and decentralizes responsibilities from a central node to distributed nodes. Comparative results with state-of-the-art approaches, obtained from a realistic testbed and traces, indicate that our approach reduces the average response time by 15% and the number of failed requests by 24%, validating improved scalability as the number of requests increases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10169v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Service Computing, 2024</arxiv:journal_reference>
      <dc:creator>Haoyu Bai, Minxian Xu, Kejiang Ye, Rajkumar Buyya, Chengzhong Xu</dc:creator>
    </item>
    <item>
      <title>StatuScale: Status-aware and Elastic Scaling Strategy for Microservice Applications</title>
      <link>https://arxiv.org/abs/2407.10173</link>
      <description>arXiv:2407.10173v1 Announce Type: new 
Abstract: Microservice architecture has transformed traditional monolithic applications into lightweight components. Scaling these lightweight microservices is more efficient than scaling servers. However, scaling microservices still faces the challenges resulted from the unexpected spikes or bursts of requests, which are difficult to detect and can degrade performance instantaneously. To address this challenge and ensure the performance of microservice-based applications, we propose a status-aware and elastic scaling framework called StatuScale, which is based on load status detector that can select appropriate elastic scaling strategies for differentiated resource scheduling in vertical scaling. Additionally, StatuScale employs a horizontal scaling controller that utilizes comprehensive evaluation and resource reduction to manage the number of replicas for each microservice. We also present a novel metric named correlation factor to evaluate the resource usage efficiency. Finally, we use Kubernetes, an open-source container orchestration and management platform, and realistic traces from Alibaba to validate our approach. The experimental results have demonstrated that the proposed framework can reduce the average response time in the Sock-Shop application by 8.59% to 12.34%, and in the Hotel-Reservation application by 7.30% to 11.97%, decrease service level objective violations, and offer better performance in resource usage compared to baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10173v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ACM Transactions on Autonomous and Adaptive Systems, 2024</arxiv:journal_reference>
      <dc:creator>Linfeng Wen, Minxian Xu, Sukhpal Singh Gill, Muhammad Hafizhuddin Hilman, Satish Narayana Srirama, Kejiang Ye, Chengzhong Xu</dc:creator>
    </item>
    <item>
      <title>Comprehensive Review of Performance Optimization Strategies for Serverless Applications on AWS Lambda</title>
      <link>https://arxiv.org/abs/2407.10397</link>
      <description>arXiv:2407.10397v1 Announce Type: new 
Abstract: This review paper synthesizes the latest research on performance optimization strategies for serverless applications deployed on AWS Lambda. By examining recent studies, we highlight the challenges, solutions, and best practices for enhancing the performance, cost efficiency, and scalability of serverless applications. The review covers a range of optimization techniques including resource management, runtime selection, observability improvements, and workload aware operations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10397v1</guid>
      <category>cs.DC</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohamed Lemine El Bechir, Cheikh Sad Bouh, Abobakr Shuwail</dc:creator>
    </item>
    <item>
      <title>Error Bounds for the Network Scale-Up Method</title>
      <link>https://arxiv.org/abs/2407.10640</link>
      <description>arXiv:2407.10640v1 Announce Type: new 
Abstract: Epidemiologists and social scientists have used the Network Scale-Up Method (NSUM) for over thirty years to estimate the size of a hidden sub-population within a social network. This method involves querying a subset of network nodes about the number of their neighbours belonging to the hidden sub-population. In general, NSUM assumes that the social network topology and the hidden sub-population distribution are well-behaved; hence, the NSUM estimate is close to the actual value. However, bounds on NSUM estimation errors have not been analytically proven. This paper provides analytical bounds on the error incurred by the two most popular NSUM estimators. These bounds assume that the queried nodes accurately provide their degree and the number of neighbors belonging to the hidden population. Our key findings are twofold. First, we show that when an adversary designs the network and places the hidden sub-population, then the estimate can be a factor of $\Omega(\sqrt{n})$ off from the real value (in a network with $n$ nodes). Second, we also prove error bounds when the underlying network is randomly generated, showing that a small constant factor can be achieved with high probability using samples of logarithmic size $O(\log{n})$. We present improved analytical bounds for Erdos-Renyi and Scale-Free networks. Our theoretical analysis is supported by an extensive set of numerical experiments designed to determine the effect of the sample size on the accuracy of the estimates in both synthetic and real networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10640v1</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sergio D\'iaz-Aranda, Juan Marcos Ram\'irez, Mohit Daga, Jaya Prakash Champati, Jos\'e Aguilar, Rosa Elvira Lillo, Antonio Fern\'andez Anta</dc:creator>
    </item>
    <item>
      <title>The Blockchain Risk Parity Line: Moving From The Efficient Frontier To The Final Frontier Of Investments</title>
      <link>https://arxiv.org/abs/2407.09536</link>
      <description>arXiv:2407.09536v1 Announce Type: cross 
Abstract: We engineer blockchain based risk managed portfolios by creating three funds with distinct risk and return profiles: 1) Alpha - high risk portfolio; 2) Beta - mimics the wider market; and 3) Gamma - represents the risk free rate adjusted to beat inflation. Each of the sub-funds (Alpha, Beta and Gamma) provides risk parity because the weight of each asset in the corresponding portfolio is set to be inversely proportional to the risk derived from investing in that asset. This can be equivalently stated as equal risk contributions from each asset towards the overall portfolio risk.
  We provide detailed mechanics of combining assets - including mathematical formulations - to obtain better risk managed portfolios. The descriptions are intended to show how a risk parity based efficient frontier portfolio management engine - that caters to different risk appetites of investors by letting each individual investor select their preferred risk-return combination - can be created seamlessly on blockchain.
  Any Investor - using decentralized ledger technology - can select their desired level of risk, or return, and allocate their wealth accordingly among the sub funds, which balance one another under different market conditions. This evolution of the risk parity principle - resulting in a mechanism that is geared to do well under all market cycles - brings more robust performance and can be termed as conceptual parity.
  We have given several numerical examples that illustrate the various scenarios that arise when combining Alpha, Beta and Gamma to obtain Parity.
  The final investment frontier is now possible - a modification to the efficient frontier, thus becoming more than a mere theoretical construct - on blockchain since anyone from anywhere can participate at anytime to obtain wealth appreciation based on their financial goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09536v1</guid>
      <category>q-fin.PM</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <category>q-fin.CP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ravi Kashyap</dc:creator>
    </item>
    <item>
      <title>Distributed computing for physics-based data-driven reduced modeling at scale: Application to a rotating detonation rocket engine</title>
      <link>https://arxiv.org/abs/2407.09994</link>
      <description>arXiv:2407.09994v1 Announce Type: cross 
Abstract: High-performance computing (HPC) has revolutionized our ability to perform detailed simulations of complex real-world processes. A prominent contemporary example is from aerospace propulsion, where HPC is used for rotating detonation rocket engine (RDRE) simulations in support of the design of next-generation rocket engines; however, these simulations take millions of core hours even on powerful supercomputers, which makes them impractical for engineering tasks like design exploration and risk assessment. Reduced-order models (ROMs) address this limitation by constructing computationally cheap yet sufficiently accurate approximations that serve as surrogates for the high-fidelity model. This paper contributes a new distributed algorithm that achieves fast and scalable construction of predictive physics-based ROMs trained from sparse datasets of extremely large state dimension. The algorithm learns structured physics-based ROMs that approximate the dynamical systems underlying those datasets. This enables model reduction for problems at a scale and complexity that exceeds the capabilities of existing approaches. We demonstrate our algorithm's scalability using up to $2,048$ cores on the Frontera supercomputer at the Texas Advanced Computing Center. We focus on a real-world three-dimensional RDRE for which one millisecond of simulated physical time requires one million core hours on a supercomputer. Using a training dataset of $2,536$ snapshots each of state dimension $76$ million, our distributed algorithm enables the construction of a predictive data-driven reduced model in just $13$ seconds on $2,048$ cores on Frontera.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09994v1</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ionut-Gabriel Farcas, Rayomand P. Gundevia, Ramakanth Munipalli, Karen E. Willcox</dc:creator>
    </item>
    <item>
      <title>Accelerator-as-a-Service in Public Clouds: An Intra-Host Traffic Management View for Performance Isolation in the Wild</title>
      <link>https://arxiv.org/abs/2407.10098</link>
      <description>arXiv:2407.10098v1 Announce Type: cross 
Abstract: I/O devices in public clouds have integrated increasing numbers of hardware accelerators, e.g., AWS Nitro, Azure FPGA and Nvidia BlueField. However, such specialized compute (1) is not explicitly accessible to cloud users with performance guarantee, (2) cannot be leveraged simultaneously by both providers and users, unlike general-purpose compute (e.g., CPUs). Through ten observations, we present that the fundamental difficulty of democratizing accelerators is insufficient performance isolation support. The key obstacles to enforcing accelerator isolation are (1) too many unknown traffic patterns in public clouds and (2) too many possible contention sources in the datapath. In this work, instead of scheduling such complex traffic on-the-fly and augmenting isolation support on each system component, we propose to model traffic as network flows and proactively re-shape the traffic to avoid unpredictable contention. We discuss the implications of our findings on the design of future I/O management stacks and device interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10098v1</guid>
      <category>cs.OS</category>
      <category>cs.AR</category>
      <category>cs.DC</category>
      <category>cs.NI</category>
      <category>cs.PF</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jiechen Zhao, Ran Shu, Katie Lim, Zewen Fan, Thomas Anderson, Mingyu Gao, Natalie Enright Jerger</dc:creator>
    </item>
    <item>
      <title>Mysticeti: Reaching the Limits of Latency with Uncertified DAGs</title>
      <link>https://arxiv.org/abs/2310.14821</link>
      <description>arXiv:2310.14821v4 Announce Type: replace 
Abstract: We introduce Mysticeti-C, the first DAG-based Byzantine consensus protocol to achieve the lower bounds of latency of 3 message rounds. Since Mysticeti-C is built over DAGs it also achieves high resource efficiency and censorship resistance. Mysticeti-C achieves this latency improvement by avoiding explicit certification of the DAG blocks and by proposing a novel commit rule such that every block can be committed without delays, resulting in optimal latency in the steady state and under crash failures. We further extend Mysticeti-C to Mysticeti-FPC, which incorporates a fast commit path that achieves even lower latency for transferring assets. Unlike prior fast commit path protocols, Mysticeti-FPC minimizes the number of signatures and messages by weaving the fast path transactions into the DAG. This frees up resources, which subsequently result in better performance. We prove the safety and liveness in a Byzantine context. We evaluate both Mysticeti protocols and compare them with state-of-the-art consensus and fast path protocols to demonstrate their low latency and resource efficiency, as well as their more graceful degradation under crash failures. Mysticeti-C is the first Byzantine consensus protocol to achieve WAN latency of 0.5s for consensus commit while simultaneously maintaining state-of-the-art throughput of over 200k TPS. Finally, we report on integrating Mysticeti-C as the consensus protocol into the Sui blockchain, resulting in over 4x latency reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14821v4</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kushal Babel, Andrey Chursin, George Danezis, Anastasios Kichidis, Lefteris Kokoris-Kogias, Arun Koshy, Alberto Sonnino, Mingwei Tian</dc:creator>
    </item>
    <item>
      <title>Lessons Learned from Building Edge Software System Testbeds</title>
      <link>https://arxiv.org/abs/2403.16869</link>
      <description>arXiv:2403.16869v2 Announce Type: replace 
Abstract: Edge computing requires the complex software interaction of geo-distributed, heterogeneous components. The growing research and industry interest in edge computing software systems has necessitated exploring ways of testing and evaluating edge software at scale without relying on physical infrastructure. Beyond simulation, virtual testbeds that emulate edge infrastructure can provide a cost-efficient yet realistic environment to evaluate edge software.
  In this experience paper, we share lessons learned from building a total of five edge software testbeds. We describe pitfalls in architecture and development as well as experiences from having students use our testbed tooling in distributed systems prototyping classes. While we remain confident that building custom testbed tooling is the right approach for edge computing researchers and practitioners alike, we hope this paper allows others to avoid common mistakes and benefit from our experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16869v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias Pfandzelter, David Bermbach</dc:creator>
    </item>
    <item>
      <title>MPI Progress For All</title>
      <link>https://arxiv.org/abs/2405.13807</link>
      <description>arXiv:2405.13807v2 Announce Type: replace 
Abstract: The progression of communication in the Message Passing Interface (MPI) is not well defined, yet it is critical for application performance, particularly in achieving effective computation and communication overlap. The opaque nature of MPI progress poses significant challenges in advancing MPI within modern high-performance computing (HPC) practices. Firstly, the lack of clarity hinders the development of explicit guidelines for enhancing computation and communication overlap in applications. Secondly, it prevents MPI from seamlessly integrating with contemporary programming paradigms, such as task-based runtimes and event-driven programming. Thirdly, it limits the extension of MPI functionalities from the user space. In this paper, we examine the role of MPI progress by analyzing the implementation details of MPI messaging. We then generalize the asynchronous communication pattern and identify key factors influencing application performance. Based on this analysis, we propose a set of MPI extensions designed to enable users to explicitly construct and manage an efficient progress engine. We provide example codes to demonstrate the use of these proposed APIs in achieving improved performance, adapting MPI to task-based or event-driven programming styles, and constructing collective algorithms that rival the performance of native implementations. Our approach is compared to previous efforts in the field, highlighting its reduced complexity and increased effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13807v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Zhou, Robert Latham, Ken Raffenetti, Yanfei Guo, Rajeev Thakur</dc:creator>
    </item>
    <item>
      <title>SAMM: Sharded Automated Market Makers</title>
      <link>https://arxiv.org/abs/2406.05568</link>
      <description>arXiv:2406.05568v2 Announce Type: replace 
Abstract: \emph{Automated Market Makers} (\emph{AMMs}) are a cornerstone of decentralized finance (DeFi) blockchain-based platforms.
  They are smart contracts, enabling the direct exchange of virtual tokens by maintaining \emph{liquidity pools}.
  Traders exchange tokens with the contract, paying a fee; liquidity comes from \emph{liquidity providers}, paid by those fees.
  But despite growing demand, the performance of AMMs is limited.
  State-of-the-art blockchain platforms allow for parallel execution of transactions.
  However, we show that AMMs do not enjoy these gains, since their operations are not commutative so transactions using them must be serialized.
  We present \emph{SAMM}, an AMM comprising multiple independent \emph{shards}.
  All shards are smart contracts operating in the same chain, but they allow for parallel execution as each is independent.
  The challenge is that trading in a standard AMM is cheaper if its liquidity pool is larger.
  Therefore, we show that simply using multiple smaller AMMs results in traders splitting each trade among all AMMs, which worsens performance.
  SAMM addresses this issue with a novel design of the trading fees.
  Traders are incentivized to use only a single smallest shard.
  We show that all Subgame-Perfect Nash Equilibria (SPNE) fit the desired behavior: Liquidity providers balance the liquidity among all pools, so the system converges to the state where trades are evenly distributed.
  Evaluation in the Sui blockchain shows that SAMM's throughput is over fivefold that of traditional AMMs, approaching the system's limit.
  SAMM is a directly deployable open-source smart contract, allowing trading at scale for individuals and DeFi applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05568v2</guid>
      <category>cs.DC</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyin Chen, Amit Vaisman, Ittay Eyal</dc:creator>
    </item>
    <item>
      <title>A Framework for Evaluating Privacy-Utility Trade-off in Vertical Federated Learning</title>
      <link>https://arxiv.org/abs/2209.03885</link>
      <description>arXiv:2209.03885v3 Announce Type: replace-cross 
Abstract: Federated learning (FL) has emerged as a practical solution to tackle data silo issues without compromising user privacy. One of its variants, vertical federated learning (VFL), has recently gained increasing attention as the VFL matches the enterprises' demands of leveraging more valuable features to build better machine learning models while preserving user privacy. Current works in VFL concentrate on developing a specific protection or attack mechanism for a particular VFL algorithm. In this work, we propose an evaluation framework that formulates the privacy-utility evaluation problem. We then use this framework as a guide to comprehensively evaluate a broad range of protection mechanisms against most of the state-of-the-art privacy attacks for three widely deployed VFL algorithms. These evaluations may help FL practitioners select appropriate protection mechanisms given specific requirements. Our evaluation results demonstrate that: the model inversion and most of the label inference attacks can be thwarted by existing protection mechanisms; the model completion (MC) attack is difficult to be prevented, which calls for more advanced MC-targeted protection mechanisms. Based on our evaluation results, we offer concrete advice on improving the privacy-preserving capability of VFL systems. The code is available at https://github.com/yankang18/VFL-Attack-Defense</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.03885v3</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Kang, Jiahuan Luo, Yuanqin He, Xiaojin Zhang, Lixin Fan, Qiang Yang</dc:creator>
    </item>
    <item>
      <title>A Two-Layer Blockchain Sharding Protocol Leveraging Safety and Liveness for Enhanced Performance</title>
      <link>https://arxiv.org/abs/2310.11373</link>
      <description>arXiv:2310.11373v5 Announce Type: replace-cross 
Abstract: Sharding is essential for improving blockchain scalability. Existing protocols overlook diverse adversarial attacks, limiting transaction throughput. This paper presents Reticulum, a groundbreaking sharding protocol addressing this issue, boosting blockchain scalability.
  Reticulum employs a two-phase approach, adapting transaction throughput based on runtime adversarial attacks. It comprises "control" and "process" shards in two layers. Process shards contain at least one trustworthy node, while control shards have a majority of trusted nodes. In the first phase, transactions are written to blocks and voted on by nodes in process shards. Unanimously accepted blocks are confirmed. In the second phase, blocks without unanimous acceptance are voted on by control shards. Blocks are accepted if the majority votes in favor, eliminating first-phase opponents and silent voters. Reticulum uses unanimous voting in the first phase, involving fewer nodes, enabling more parallel process shards. Control shards finalize decisions and resolve disputes.
  Experiments confirm Reticulum's innovative design, providing high transaction throughput and robustness against various network attacks, outperforming existing sharding protocols for blockchain networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.11373v5</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.14722/ndss.2024.24006</arxiv:DOI>
      <arxiv:journal_reference>Network and Distributed System Security (NDSS) Symposium 2024</arxiv:journal_reference>
      <dc:creator>Yibin Xu, Jingyi Zheng, Boris D\"udder, Tijs Slaats, Yongluan Zhou</dc:creator>
    </item>
    <item>
      <title>Learned Best-Effort LLM Serving</title>
      <link>https://arxiv.org/abs/2401.07886</link>
      <description>arXiv:2401.07886v2 Announce Type: replace-cross 
Abstract: Many applications must provide low-latency LLM service to users or risk unacceptable user experience. However, over-provisioning resources to serve fluctuating request patterns is often prohibitively expensive. In this work, we present a best-effort serving system that employs deep reinforcement learning to adjust service quality based on the task distribution and system load. Our best-effort system can maintain availability with over 10x higher client request rates, serves above 96% of peak performance 4.1x more often, and serves above 98% of peak performance 2.3x more often than static serving on unpredictable workloads. Our learned router is robust to shifts in both the arrival and task distribution. Compared to static serving, learned best-effort serving allows for cost-efficient serving through increased hardware utility. Additionally, we argue that learned best-effort LLM serving is applicable in wide variety of settings and provides application developers great flexibility to meet their specific needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07886v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siddharth Jha, Coleman Hooper, Xiaoxuan Liu, Sehoon Kim, Kurt Keutzer</dc:creator>
    </item>
    <item>
      <title>Byzantine-Robust Decentralized Federated Learning</title>
      <link>https://arxiv.org/abs/2406.10416</link>
      <description>arXiv:2406.10416v4 Announce Type: replace-cross 
Abstract: Federated learning (FL) enables multiple clients to collaboratively train machine learning models without revealing their private training data. In conventional FL, the system follows the server-assisted architecture (server-assisted FL), where the training process is coordinated by a central server. However, the server-assisted FL framework suffers from poor scalability due to a communication bottleneck at the server, and trust dependency issues. To address challenges, decentralized federated learning (DFL) architecture has been proposed to allow clients to train models collaboratively in a serverless and peer-to-peer manner. However, due to its fully decentralized nature, DFL is highly vulnerable to poisoning attacks, where malicious clients could manipulate the system by sending carefully-crafted local models to their neighboring clients. To date, only a limited number of Byzantine-robust DFL methods have been proposed, most of which are either communication-inefficient or remain vulnerable to advanced poisoning attacks. In this paper, we propose a new algorithm called BALANCE (Byzantine-robust averaging through local similarity in decentralization) to defend against poisoning attacks in DFL. In BALANCE, each client leverages its own local model as a similarity reference to determine if the received model is malicious or benign. We establish the theoretical convergence guarantee for BALANCE under poisoning attacks in both strongly convex and non-convex settings. Furthermore, the convergence rate of BALANCE under poisoning attacks matches those of the state-of-the-art counterparts in Byzantine-free settings. Extensive experiments also demonstrate that BALANCE outperforms existing DFL methods and effectively defends against poisoning attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10416v4</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minghong Fang, Zifan Zhang,  Hairi, Prashant Khanduri, Jia Liu, Songtao Lu, Yuchen Liu, Neil Gong</dc:creator>
    </item>
  </channel>
</rss>
