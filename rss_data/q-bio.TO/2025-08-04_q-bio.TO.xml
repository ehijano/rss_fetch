<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.TO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.TO</link>
    <description>q-bio.TO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.TO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Aug 2025 04:14:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Evolutionary Paradigms in Histopathology Serial Sections technology</title>
      <link>https://arxiv.org/abs/2508.02423</link>
      <description>arXiv:2508.02423v1 Announce Type: new 
Abstract: Histopathological analysis has been transformed by serial section-based methods, advancing beyond traditional 2D histology to enable volumetric and microstructural insights in oncology and inflammatory disease diagnostics. This review outlines key developments in specimen preparation and high-throughput imaging that support these innovations. Computational workflows are categorized into multimodal image co-registration, 3D histoarchitecture reconstruction, multiplexed immunohistochemical correlation, and cross-scale data fusion. These approaches exploit serial section-derived spatial concordance to enhance resolution in microenvironmental and molecular profiling. Despite progress, challenges remain in harmonizing heterogeneous datasets, optimizing large-scale registration, and ensuring interpretability. Future directions include spatial transcriptomics, and applications in developmental biology and neuroscience in AI integration, establishing serial section analytics as central to precision histopathology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02423v1</guid>
      <category>q-bio.TO</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhenfeng Zhuang, Min Cen, Lei Jiang, Qiong Peng, Yihuang Hu, Hong-Yu Zhou, Liansheng Wang</dc:creator>
    </item>
    <item>
      <title>A Large-Scale Benchmark of Cross-Modal Learning for Histology and Gene Expression in Spatial Transcriptomics</title>
      <link>https://arxiv.org/abs/2508.01490</link>
      <description>arXiv:2508.01490v1 Announce Type: cross 
Abstract: Spatial transcriptomics enables simultaneous measurement of gene expression and tissue morphology, offering unprecedented insights into cellular organization and disease mechanisms. However, the field lacks comprehensive benchmarks for evaluating multimodal learning methods that leverage both histology images and gene expression data. Here, we present HESCAPE, a large-scale benchmark for cross-modal contrastive pretraining in spatial transcriptomics, built on a curated pan-organ dataset spanning 6 different gene panels and 54 donors. We systematically evaluated state-of-the-art image and gene expression encoders across multiple pretraining strategies and assessed their effectiveness on two downstream tasks: gene mutation classification and gene expression prediction. Our benchmark demonstrates that gene expression encoders are the primary determinant of strong representational alignment, and that gene models pretrained on spatial transcriptomics data outperform both those trained without spatial data and simple baseline approaches. However, downstream task evaluation reveals a striking contradiction: while contrastive pretraining consistently improves gene mutation classification performance, it degrades direct gene expression prediction compared to baseline encoders trained without cross-modal objectives. We identify batch effects as a key factor that interferes with effective cross-modal alignment. Our findings highlight the critical need for batch-robust multimodal learning approaches in spatial transcriptomics. To accelerate progress in this direction, we release HESCAPE, providing standardized datasets, evaluation protocols, and benchmarking tools for the community</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01490v1</guid>
      <category>q-bio.GN</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.TO</category>
      <category>stat.AP</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rushin H. Gindra, Giovanni Palla, Mathias Nguyen, Sophia J. Wagner, Manuel Tran, Fabian J Theis, Dieter Saur, Lorin Crawford, Tingying Peng</dc:creator>
    </item>
    <item>
      <title>Sub-surface Skin Deformation in Response to Gentle Brushing</title>
      <link>https://arxiv.org/abs/2507.23462</link>
      <description>arXiv:2507.23462v2 Announce Type: replace-cross 
Abstract: Even simple tactile stimuli can lead to remarkably different perceptions among individuals, both in intensity and pleasantness. To understand the physical factors behind this variation, it is important to investigate how mechanical events are transmitted through the skin. In this study, we visualize the internal skin strains in response to soft brushing stimuli using functional Optical Coherence Tomography (fOCT), which provides depth-resolved time-series data of the displacement of the skin. Driven with custom-made software, the system enabled sub-surface imaging at a refresh rate of 10 kHz. Brushing was applied to the back of the hand, and skin displacement was observed at different depths. The results show that each skin layer responds differently to the stimulus, suggesting that internal skin dynamics play a role in tactile perception. This method offers a way to investigate how mechanical events within the skin relate to sensory function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.23462v2</guid>
      <category>physics.bio-ph</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saito Sakaguchi, Basil Duvernoy, Anders Fridberger, H{\aa}kan Olausson, Sarah McIntyre</dc:creator>
    </item>
  </channel>
</rss>
