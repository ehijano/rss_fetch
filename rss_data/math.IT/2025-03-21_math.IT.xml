<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.IT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.IT</link>
    <description>math.IT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.IT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Mar 2025 04:02:50 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On the Secrecy Performance of $\alpha$-$\mathcal{F}$ Channels with Pointing Errors</title>
      <link>https://arxiv.org/abs/2503.15618</link>
      <description>arXiv:2503.15618v1 Announce Type: new 
Abstract: This paper investigates the physical layer security (PLS) performance of $\alpha$-$\mathcal{F}$ fading channels with pointing errors under passive and active eavesdropping scenarios. Novel analytical expressions are derived for key PLS metrics, including the probability of strictly positive secrecy capacity, the average secrecy capacity, and the secure outage probability. An asymptotic analysis is also investigated to provide further insights into the system behavior under high signal-to-noise ratio conditions. The analytical results are validated through Monte Carlo simulations, with several performance curves presented for a range of channel and system parameters. All expressions derived in this work are original and have not been previously published.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15618v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabriel M. C. Neves, Hugerles S. Silva, Higo T. P. Silva, Wamberto J. L. Queiroz, Felipe A. P. Figueiredo, Rausley A. A. de Souza</dc:creator>
    </item>
    <item>
      <title>Most continuous-variable cluster states are too entangled to be useless</title>
      <link>https://arxiv.org/abs/2503.15698</link>
      <description>arXiv:2503.15698v1 Announce Type: cross 
Abstract: We define absolutely maximal entanglement (AME) in continuous-variable (CV) systems and show that, in stark contrast to qudit systems, this entanglement is generic among infinitely squeezed Gaussian states. In particular, we show that CV cluster states are generically AME and provide explicit constructions using Cauchy, Vandermonde, totally positive, and real-block-code generator matrices. Finitely squeezed versions of CV AME states give rise to open-destination multi-party CV teleportation, CV quantum secret sharing, CV majority-agreed key distribution, Gaussian perfect-tensor networks on arbitrary geometries, and Gaussian multi-unitary circuits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15698v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James I. Kwon, Anthony J. Brady, Victor V. Albert</dc:creator>
    </item>
    <item>
      <title>The Fundamental Limits of Recovering Planted Subgraphs</title>
      <link>https://arxiv.org/abs/2503.15723</link>
      <description>arXiv:2503.15723v1 Announce Type: cross 
Abstract: Given an arbitrary subgraph $H=H_n$ and $p=p_n \in (0,1)$, the planted subgraph model is defined as follows. A statistician observes the union a random copy $H^*$ of $H$, together with random noise in the form of an instance of an Erdos-Renyi graph $G(n,p)$. Their goal is to recover the planted $H^*$ from the observed graph. Our focus in this work is to understand the minimum mean squared error (MMSE) for sufficiently large $n$.
  A recent paper [MNSSZ23] characterizes the graphs for which the limiting MMSE curve undergoes a sharp phase transition from $0$ to $1$ as $p$ increases, a behavior known as the all-or-nothing phenomenon, up to a mild density assumption on $H$. In this paper, we provide a formula for the limiting MMSE curve for any graph $H=H_n$, up to the same mild density assumption. This curve is expressed in terms of a variational formula over pairs of subgraphs of $H$, and is inspired by the celebrated subgraph expectation thresholds from the probabilistic combinatorics literature [KK07]. Furthermore, we give a polynomial-time description of the optimizers of this variational problem. This allows one to efficiently approximately compute the MMSE curve for any dense graph $H$ when $n$ is large enough. The proof relies on a novel graph decomposition of $H$ as well as a new minimax theorem which may be of independent interest.
  Our results generalize to the setting of minimax rates of recovering arbitrary monotone boolean properties planted in random noise, where the statistician observes the union of a planted minimal element $A \subseteq [N]$ of a monotone property and a random $Ber(p)^{\otimes N}$ vector. In this setting, we provide a variational formula inspired by the so-called "fractional" expectation threshold [Tal10], again describing the MMSE curve (in this case up to a multiplicative constant) for large enough $n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15723v1</guid>
      <category>math.ST</category>
      <category>cs.DM</category>
      <category>cs.IT</category>
      <category>math.CO</category>
      <category>math.IT</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Lee, Francisco Pernice, Amit Rajaraman, Ilias Zadik</dc:creator>
    </item>
    <item>
      <title>Extending the HNLS Condition to Robust Quantum Metrology</title>
      <link>https://arxiv.org/abs/2503.15743</link>
      <description>arXiv:2503.15743v1 Announce Type: cross 
Abstract: Quantum sensing holds great promise for high-precision magnetic field measurements. However, its performance is significantly limited by noise. In this work, we develop a quantum sensing protocol to estimate a parameter $\theta$, associated with a magnetic field, under full-rank Markovian noise. Our approach uses a probe state constructed from a CSS code that evolves under the parameter's Hamiltonian for a short time, but without any active error correction. Then we measure the code's $\hat{X}$ stabilizers to infer $\theta$. Given $N$ copies of the probe state, we derive the probability that all stabilizer measurements return $+1$, which depends on $\theta$. The uncertainty in $\theta$ (estimated from these measurements) is bounded by a new quantity, the Robustness Bound, which characterizes how the structure of the quantum code affects the Quantum Fisher Information of the measurement. Using this bound, we establish a strong no-go result: a nontrivial CSS code can achieve Heisenberg scaling if and only if the Hamiltonian is orthogonal to the span of the noise channel's Lindblad operators. This result extends the well-known HNLS condition under infinite rounds of error correction to the robust quantum sensing setting that does not use active error correction. Our finding suggests fundamental limitations in the use of linear quantum codes for dephased magnetic field sensing applications both in the near-term robust sensing regime and in the long-term fault tolerant era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15743v1</guid>
      <category>quant-ph</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oskar Novak, Narayanan Rengaswamy</dc:creator>
    </item>
    <item>
      <title>Model-based learning for multi-antenna multi-frequency location-to-channel mapping</title>
      <link>https://arxiv.org/abs/2407.07719</link>
      <description>arXiv:2407.07719v3 Announce Type: replace 
Abstract: Years of study of the propagation channel showed a close relation between a location and the associated communication channel response. The use of a neural network to learn the location-to-channel mapping can therefore be envisioned. The Implicit Neural Representation (INR) literature showed that classical neural architecture are biased towards learning low-frequency content, making the location-to-channel mapping learning a non-trivial problem. Indeed, it is well known that this mapping is a function rapidly varying with the location, on the order of the wavelength. This paper leverages the model-based machine learning paradigm to derive a problem-specific neural architecture from a propagation channel model. The resulting architecture efficiently overcomes the spectral-bias issue. It only learns low-frequency sparse correction terms activating a dictionary of high-frequency components. The proposed architecture is evaluated against classical INR architectures on realistic synthetic data, showing much better accuracy. Its mapping learning performance is explained based on the approximated channel model, highlighting the explainability of the model-based machine learning paradigm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07719v3</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Chatelier (IETR, MERCE-France, INSA Rennes), Vincent Corlay (MERCE-France), Matthieu Crussi\`ere (IETR, INSA Rennes), Luc Le Magoarou (IETR, INSA Rennes)</dc:creator>
    </item>
    <item>
      <title>On Fast SC-based Polar Decoders: Metric Polarization and a Pruning Technique</title>
      <link>https://arxiv.org/abs/2408.03840</link>
      <description>arXiv:2408.03840v2 Announce Type: replace 
Abstract: Short- to medium-block-length polar-like and polarization-adjusted convolutional (PAC) codes have demonstrated exceptional error-correction performance through sequential decoding. Successive cancellation list (SCL) decoding of polar-like and PAC codes can potentially match the performance of sequential decoding though a relatively large list size is often required. By benefiting from an optimal metric function, sequential decoding can find the correct path corresponding to the transmitted data by following almost one path on average at high Eb/N0 regimes. When considering a large number of paths in SCL decoding, a main bottleneck emerges that is the need for a rather expensive sorting operation at each level of decoding of data bits. In this paper, we propose a method to obtain the optimal metric function for each depth of the polarization tree through a process that we call polarization of the metric function. One of the major advantages of the proposed metric function is that it can be utilized in fast SC-based (FSC) and SCL-based (FSCL) decoders, i.e., decoders that opt to skip the so-called rate-1 and rate-0 nodes in the binary tree representation for significantly more efficient implementation. Furthermore, based on the average value of the polarized metric function of FSC-based decoders, we introduce a pruning technique that keeps only the paths whose metric values are close to the average value. As a result, our proposed technique significantly reduces the number of required sorting operations for FSCL-based decoding algorithms. For instance, for a high-rate PAC(128,99) code, SCL decoding with a list size of 32 achieves error-correction performance comparable to the Fano algorithm. Our method reduces the number of sorting operations of FSCL decoding to 33%, further decreasing latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03840v2</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohsen Moradi, Hessam Mahdavifar</dc:creator>
    </item>
    <item>
      <title>SCAN-BEST: Efficient Sub-6GHz-Aided Near-field Beam Selection with Formal Reliability Guarantees</title>
      <link>https://arxiv.org/abs/2503.13801</link>
      <description>arXiv:2503.13801v2 Announce Type: replace 
Abstract: As millimeter-wave (mmWave) multiple-input multiple-output (MIMO) systems continue to incorporate larger antenna arrays, the range of near-field propagation expands, making it more likely for users close to the transmitter to fall within the near-field regime. Traditional far-field beam training methods are no longer effective in this context. Additionally, near-field beam training presents challenges, since the training codebook must account for both angular and distance dimensions, leading to large codebook sizes. To reduce the in-band training overhead, we propose the Sub-6G Channel-Aided Near-field BEam SelecTion (SCAN-BEST) framework, which is motivated by the spatial-temporal congruence between sub-6 GHz (sub-6G) and mmWave channels. SCAN-BEST utilizes preprocessed sub-6G channel estimates as input, and employs a convolutional neural network (CNN) to predict the probability of each beam being optimal within the near-field beam training codebook. Given the prediction uncertainty arising from the variance between sub-6G and mmWave channels, we introduce a conformal risk control (CRC)-based module that generates a set of beam candidates for further limited in-band training, enabling the final beam selection to formally meet user-defined target coverage rate. Numerical results confirm the thereoretical properties of SCAN-BEST in terms of the achieved coverage rate of the beam candidates and various metrics. Moreover, SCAN-BEST enjoys good scalability and robustness to various sub-6G system configurations, including to the sizes of calibration datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13801v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weicao Deng, Binpu Shi, Min Li, Osvaldo Simeone</dc:creator>
    </item>
    <item>
      <title>Exponentially Consistent Nonparametric Linkage-Based Clustering of Data Sequences</title>
      <link>https://arxiv.org/abs/2411.13922</link>
      <description>arXiv:2411.13922v2 Announce Type: replace-cross 
Abstract: In this paper, we consider nonparametric clustering of $M$ independent and identically distributed (i.i.d.) data sequences generated from {\em unknown} distributions. The distributions of the $M$ data sequences belong to $K$ underlying distribution clusters. Existing results on exponentially consistent nonparametric clustering algorithms, like single linkage-based (SLINK) clustering and $k$-medoids distribution clustering, assume that the maximum intra-cluster distance ($d_L$) is smaller than the minimum inter-cluster distance ($d_H$). First, in the fixed sample size (FSS) setting, we show that exponential consistency can be achieved for SLINK clustering under a less strict assumption, $d_I &lt; d_H$, where $d_I$ is the maximum distance between any two sub-clusters of a cluster that partition the cluster. Note that $d_I &lt; d_L$ in general. Thus, our results show that SLINK is exponentially consistent for a larger class of problems than previously known. In our simulations, we also identify examples where $k$-medoids clustering is unable to find the true clusters, but SLINK is exponentially consistent. Then, we propose a sequential clustering algorithm, named SLINK-SEQ, based on SLINK and prove that it is also exponentially consistent. Simulation results show that the SLINK-SEQ algorithm requires fewer expected number of samples than the FSS SLINK algorithm for the same probability of error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13922v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bhupender Singh, Ananth Ram Rajagopalan, Srikrishna Bhashyam</dc:creator>
    </item>
    <item>
      <title>Physically Parameterized Differentiable MUSIC for DoA Estimation with Uncalibrated Arrays</title>
      <link>https://arxiv.org/abs/2411.15144</link>
      <description>arXiv:2411.15144v3 Announce Type: replace-cross 
Abstract: Direction of arrival (DoA) estimation is a common sensing problem in radar, sonar, audio, and wireless communication systems. It has gained renewed importance with the advent of the integrated sensing and communication paradigm. To fully exploit the potential of such sensing systems, it is crucial to take into account potential hardware impairments that can negatively impact the obtained performance. This study introduces a joint DoA estimation and hardware impairment learning scheme following a model-based approach. Specifically, a differentiable version of the multiple signal classification (MUSIC) algorithm is derived, allowing efficient learning of the considered impairments. The proposed approach supports both supervised and unsupervised learning strategies, showcasing its practical potential. Simulation results indicate that the proposed method successfully learns significant inaccuracies in both antenna locations and complex gains. Additionally, the proposed method outperforms the classical MUSIC algorithm in the DoA estimation task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15144v3</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baptiste Chatelier (INSA Rennes, IETR, MERCE-France), Jos\'e Miguel Mateos-Ramos (MERCE-France), Vincent Corlay (MERCE-France), Christian H\"ager (INSA Rennes, IETR), Matthieu Crussi\`ere (INSA Rennes, IETR), Henk Wymeersch (INSA Rennes, IETR), Luc Le Magoarou (INSA Rennes, IETR)</dc:creator>
    </item>
    <item>
      <title>On H-Intersecting Graph Families and Counting of Homomorphisms</title>
      <link>https://arxiv.org/abs/2501.02894</link>
      <description>arXiv:2501.02894v5 Announce Type: replace-cross 
Abstract: This work derives an upper bound on the maximum cardinality of a family of graphs on a fixed number of vertices, in which the intersection of every two graphs in that family contains a subgraph that is isomorphic to a specified graph H. Such families are referred to as H-intersecting graph families. The bound is derived using the combinatorial version of Shearer's lemma, and it forms a nontrivial extension of the bound derived by Chung, Graham, Frankl, and Shearer (1986), where H is specialized to a triangle. The derived bound is expressed in terms of the chromatic number of H, while a relaxed version, formulated using the Lov\'{a}sz $\vartheta$-function of the complement of H, offers reduced computational complexity. Additionally, a probabilistic version of Shearer's lemma, combined with properties of the Shannon entropy, are employed to establish bounds related to the enumeration of graph homomorphisms, providing further insights into the interplay between combinatorial structures and information-theoretic principles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.02894v5</guid>
      <category>math.CO</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igal Sason</dc:creator>
    </item>
    <item>
      <title>Generalization Guarantees for Representation Learning via Data-Dependent Gaussian Mixture Priors</title>
      <link>https://arxiv.org/abs/2502.15540</link>
      <description>arXiv:2502.15540v2 Announce Type: replace-cross 
Abstract: We establish in-expectation and tail bounds on the generalization error of representation learning type algorithms. The bounds are in terms of the relative entropy between the distribution of the representations extracted from the training and "test'' datasets and a data-dependent symmetric prior, i.e., the Minimum Description Length (MDL) of the latent variables for the training and test datasets. Our bounds are shown to reflect the "structure" and "simplicity'' of the encoder and significantly improve upon the few existing ones for the studied model. We then use our in-expectation bound to devise a suitable data-dependent regularizer; and we investigate thoroughly the important question of the selection of the prior. We propose a systematic approach to simultaneously learning a data-dependent Gaussian mixture prior and using it as a regularizer. Interestingly, we show that a weighted attention mechanism emerges naturally in this procedure. Our experiments show that our approach outperforms the now popular Variational Information Bottleneck (VIB) method as well as the recent Category-Dependent VIB (CDVIB).</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15540v2</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Milad Sefidgaran, Abdellatif Zaidi, Piotr Krasnowski</dc:creator>
    </item>
    <item>
      <title>Reversal Blessing: Thinking Backward May Outpace Thinking Forward in Multi-choice Questions</title>
      <link>https://arxiv.org/abs/2502.18435</link>
      <description>arXiv:2502.18435v2 Announce Type: replace-cross 
Abstract: Language models usually use left-to-right (L2R) autoregressive factorization. However, L2R factorization may not always be the best inductive bias. Therefore, we investigate whether alternative factorizations of the text distribution could be beneficial in some tasks. We investigate right-to-left (R2L) training as a compelling alternative, focusing on multiple-choice questions (MCQs) as a test bed for knowledge extraction and reasoning. Through extensive experiments across various model sizes (2B-8B parameters) and training datasets, we find that R2L models can significantly outperform L2R models on several MCQ benchmarks, including logical reasoning, commonsense understanding, and truthfulness assessment tasks. Our analysis reveals that this performance difference may be fundamentally linked to multiple factors including calibration, computability and directional conditional entropy. We ablate the impact of these factors through controlled simulation studies using arithmetic tasks, where the impacting factors can be better disentangled. Our work demonstrates that exploring alternative factorizations of the text distribution can lead to improvements in LLM capabilities and provides theoretical insights into optimal factorization towards approximating human language distribution, and when each reasoning order might be more advantageous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18435v2</guid>
      <category>cs.CL</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <pubDate>Fri, 21 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhe Zhang, Richard Bai, Zijin Gu, Ruixiang Zhang, Jiatao Gu, Emmanuel Abbe, Samy Bengio, Navdeep Jaitly</dc:creator>
    </item>
  </channel>
</rss>
