<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NE</link>
    <description>cs.NE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 Jan 2025 02:31:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Neural Cellular Automata and Deep Equilibrium Models</title>
      <link>https://arxiv.org/abs/2501.03573</link>
      <description>arXiv:2501.03573v1 Announce Type: new 
Abstract: This essay discusses the connections and differences between two emerging paradigms in deep learning, namely Neural Cellular Automata and Deep Equilibrium Models, and train a simple Deep Equilibrium Convolutional model to demonstrate the inherent similarity of NCA and DEQ based methods. Finally, this essay speculates about ways to combine theoretical and practical aspects of both approaches for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03573v1</guid>
      <category>cs.NE</category>
      <category>cs.FL</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhibai Jia</dc:creator>
    </item>
    <item>
      <title>Neuromorphic Optical Tracking and Imaging of Randomly Moving Targets through Strongly Scattering Media</title>
      <link>https://arxiv.org/abs/2501.03874</link>
      <description>arXiv:2501.03874v1 Announce Type: new 
Abstract: Tracking and acquiring simultaneous optical images of randomly moving targets obscured by scattering media remains a challenging problem of importance to many applications that require precise object localization and identification. In this work we develop an end-to-end neuromorphic optical engineering and computational approach to demonstrate how to track and image normally invisible objects by combining an event detecting camera with a multistage neuromorphic deep learning strategy. Photons emerging from dense scattering media are detected by the event camera and converted to pixel-wise asynchronized spike trains - a first step in isolating object-specific information from the dominant uninformative background. Spiking data is fed into a deep spiking neural network (SNN) engine where object tracking and image reconstruction are performed by two separate yet interconnected modules running in parallel in discrete time steps over the event duration. Through benchtop experiments we demonstrate tracking and imaging randomly moving objects in dense turbid media as well as image reconstruction of spatially stationary but optically dynamic objects. Standardized character sets serve as representative proxies for geometrically complex objects, underscoring the method's generality. The results highlight the advantages of a fully neuromorphic approach in meeting a major imaging technology with high computational efficiency and low power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03874v1</guid>
      <category>cs.NE</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Zhang, Timothy Shea, Arto Nurmikko</dc:creator>
    </item>
    <item>
      <title>A GPU Implementation of Multi-Guiding Spark Fireworks Algorithm for Efficient Black-Box Neural Network Optimization</title>
      <link>https://arxiv.org/abs/2501.03944</link>
      <description>arXiv:2501.03944v1 Announce Type: new 
Abstract: Swarm intelligence optimization algorithms have gained significant attention due to their ability to solve complex optimization problems. However, the efficiency of optimization in large-scale problems limits the use of related methods. This paper presents a GPU-accelerated version of the Multi-Guiding Spark Fireworks Algorithm (MGFWA), which significantly improves the computational efficiency compared to its traditional CPU-based counterpart. We benchmark the GPU-MGFWA on several neural network black-box optimization problems and demonstrate its superior performance in terms of both speed and solution quality. By leveraging the parallel processing power of modern GPUs, the proposed GPU-MGFWA results in faster convergence and reduced computation time for large-scale optimization tasks. The proposed implementation offers a promising approach to accelerate swarm intelligence algorithms, making them more suitable for real-time applications and large-scale industrial problems. Source code is released at https://github.com/mxxxr/MGFWA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03944v1</guid>
      <category>cs.NE</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiangrui Meng, Ying Tan</dc:creator>
    </item>
    <item>
      <title>Neural networks consisting of DNA</title>
      <link>https://arxiv.org/abs/2501.03235</link>
      <description>arXiv:2501.03235v1 Announce Type: cross 
Abstract: Neural networks based on soft and biological matter constitute an interesting potential alternative to traditional implementations based on electric circuits. DNA is a particularly promising system in this context due its natural ability to store information. In recent years, researchers have started to construct neural networks that are based on DNA. In this chapter, I provide a very basic introduction to the concept of DNA neural networks, aiming at an audience that is not familiar with biochemistry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03235v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.soft</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>q-bio.BM</category>
      <category>q-bio.MN</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael te Vrugt</dc:creator>
    </item>
    <item>
      <title>Advanced Displacement Magnitude Prediction in Multi-Material Architected Lattice Structure Beams Using Physics Informed Neural Network Architecture</title>
      <link>https://arxiv.org/abs/2501.03254</link>
      <description>arXiv:2501.03254v1 Announce Type: cross 
Abstract: This paper proposes an innovative method for predicting deformation in architected lattice structures that combines Physics-Informed Neural Networks (PINNs) with finite element analysis. A thorough study was carried out on FCC-based lattice beams utilizing five different materials (Structural Steel, AA6061, AA7075, Ti6Al4V, and Inconel 718) under varied edge loads (1000-10000 N). The PINN model blends data-driven learning with physics-based limitations via a proprietary loss function, resulting in much higher prediction accuracy than linear regression. PINN outperforms linear regression, achieving greater R-square (0.7923 vs 0.5686) and lower error metrics (MSE: 0.00017417 vs 0.00036187). Among the materials examined, AA6061 had the highest displacement sensitivity (0.1014 mm at maximum load), while Inconel718 had better structural stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03254v1</guid>
      <category>cs.AI</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akshansh Mishra</dc:creator>
    </item>
    <item>
      <title>Navigation Variable-based Multi-objective Particle Swarm Optimization for UAV Path Planning with Kinematic Constraints</title>
      <link>https://arxiv.org/abs/2501.03261</link>
      <description>arXiv:2501.03261v1 Announce Type: cross 
Abstract: Path planning is essential for unmanned aerial vehicles (UAVs) as it determines the path that the UAV needs to follow to complete a task. This work addresses this problem by introducing a new algorithm called navigation variable-based multi-objective particle swarm optimization (NMOPSO). It first models path planning as an optimization problem via the definition of a set of objective functions that include optimality and safety requirements for UAV operation. The NMOPSO is then used to minimize those functions through Pareto optimal solutions. The algorithm features a new path representation based on navigation variables to include kinematic constraints and exploit the maneuverable characteristics of the UAV. It also includes an adaptive mutation mechanism to enhance the diversity of the swarm for better solutions. Comparisons with various algorithms have been carried out to benchmark the proposed approach. The results indicate that the NMOPSO performs better than not only other particle swarm optimization variants but also other state-of-the-art multi-objective and metaheuristic optimization algorithms. Experiments have also been conducted with real UAVs to confirm the validity of the approach for practical flights. The source code of the algorithm is available at https://github.com/ngandng/NMOPSO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03261v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s00521-024-10945-1</arxiv:DOI>
      <arxiv:journal_reference>Neural Computing and Applications, 2025</arxiv:journal_reference>
      <dc:creator>Thi Thuy Ngan Duong, Duy-Nam Bui, Manh Duong Phung</dc:creator>
    </item>
    <item>
      <title>Bridge the Inference Gaps of Neural Processes via Expectation Maximization</title>
      <link>https://arxiv.org/abs/2501.03264</link>
      <description>arXiv:2501.03264v1 Announce Type: cross 
Abstract: The neural process (NP) is a family of computationally efficient models for learning distributions over functions. However, it suffers from under-fitting and shows suboptimal performance in practice. Researchers have primarily focused on incorporating diverse structural inductive biases, \textit{e.g.} attention or convolution, in modeling. The topic of inference suboptimality and an analysis of the NP from the optimization objective perspective has hardly been studied in earlier work. To fix this issue, we propose a surrogate objective of the target log-likelihood of the meta dataset within the expectation maximization framework. The resulting model, referred to as the Self-normalized Importance weighted Neural Process (SI-NP), can learn a more accurate functional prior and has an improvement guarantee concerning the target log-likelihood. Experimental results show the competitive performance of SI-NP over other NPs objectives and illustrate that structural inductive biases, such as attention modules, can also augment our method to achieve SOTA performance. Our code is available at \url{https://github.com/hhq123gogogo/SI_NPs}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03264v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Wang, Marco Federici, Herke van Hoof</dc:creator>
    </item>
    <item>
      <title>Gradient descent in materia through homodyne gradient extraction</title>
      <link>https://arxiv.org/abs/2105.11233</link>
      <description>arXiv:2105.11233v3 Announce Type: replace 
Abstract: Deep learning, a multi-layered neural network approach inspired by the brain, has revolutionized machine learning. One of its key enablers has been backpropagation, an algorithm that computes the gradient of a loss function with respect to the weights and biases in the neural network model, in combination with its use in gradient descent. However, the implementation of deep learning in digital computers is intrinsically energy hungry, with energy consumption becoming prohibitively high for many applications. This has stimulated the development of specialized hardware, ranging from neuromorphic CMOS integrated circuits and integrated photonic tensor cores to unconventional, material-based computing system. The learning process in these material systems, realized, e.g., by artificial evolution, equilibrium propagation or surrogate modelling, is a complicated and time-consuming process. Here, we demonstrate a simple yet efficient and accurate gradient extraction method, based on the principle of homodyne detection, for performing gradient descent on a loss function directly in a physical system without the need of an analytical description. By perturbing the parameters that need to be optimized using sinusoidal waveforms with distinct frequencies, we effectively obtain the gradient information in a highly robust and scalable manner. We illustrate the method in dopant network processing units, but argue that it is applicable in a wide range of physical systems. Homodyne gradient extraction can in principle be fully implemented in materia, facilitating the development of autonomously learning material systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2105.11233v3</guid>
      <category>cs.NE</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Wed, 08 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marcus N. Boon, Lorenzo Cassola, Hans-Christian Ruiz Euler, Tao Chen, Bram van de Ven, Unai Alegre Ibarra, Peter A. Bobbert, Wilfred G. van der Wiel</dc:creator>
    </item>
  </channel>
</rss>
