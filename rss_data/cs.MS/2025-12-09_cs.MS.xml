<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MS</link>
    <description>cs.MS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 09 Dec 2025 05:00:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ORTHOCUB: integral and differential cubature rules by orthogonal moments</title>
      <link>https://arxiv.org/abs/2512.06049</link>
      <description>arXiv:2512.06049v1 Announce Type: new 
Abstract: We discuss a numerical package, named ORTHOCUB, for the computation of linear functionals of both integral and differential type on multivariate polynomial spaces. The weighted sums corresponding to such integral and differential cubatures are implemented via orthogonal polynomial moments and auxiliary near-minimal algebraic cubature in a bounding box, with no conditioning issue since no matrix inversion or factorization is needed. The whole computational process indeed reduces to moment computation and dense matrix-vector products of relatively small size. The Matlab and Python codes are freely available, to be used as building blocks for integral and differential problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06049v1</guid>
      <category>cs.MS</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laura Rinaldi, Alvise Sommariva, Marco Vianello</dc:creator>
    </item>
    <item>
      <title>An abstraction for solving multi-domain problems using finite element methods</title>
      <link>https://arxiv.org/abs/2512.06146</link>
      <description>arXiv:2512.06146v1 Announce Type: new 
Abstract: We introduce a new abstraction for the representation and solution of multi-domain problems using finite element methods. This is an advance over previous work in that it achieves a single higher-level abstraction that represents multi-domain problems in the mixed variational problem formalism. We implemented our new abstraction in UFL and Firedrake, and validated our implementations solving a quad-triangle mixed-cell-type problem, a hex-quad mixed-cell-type problem, and a fluid-structure interaction benchmark problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.06146v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Koki Sagiyama, Lawrence Mitchell, David A. Ham</dc:creator>
    </item>
    <item>
      <title>Accurate Models of NVIDIA Tensor Cores</title>
      <link>https://arxiv.org/abs/2512.07004</link>
      <description>arXiv:2512.07004v1 Announce Type: new 
Abstract: Matrix multiplication is a fundamental operation in for both training of neural networks and inference. To accelerate matrix multiplication, Graphical Processing Units (GPUs) provide it implemented in hardware. Due to the increased throughput over the software-based matrix multiplication, the multipliers are increasingly used outside of AI, to accelerate various applications in scientific computing. However, matrix multipliers targeted at AI are at present not compliant with IEEE 754 floating-point arithmetic behaviour, with different vendors offering different numerical features. This leads to non-reproducible results across different generations of GPU architectures, at the matrix multiply-accumulate instruction level. To study numerical characteristics of matrix multipliers-such as rounding behaviour, accumulator width, normalization points, extra carry bits, and others-test vectors are typically constructed. Yet, these vectors may or may not distinguish between different hardware models, and due to limited hardware availability, their reliability across many different platforms remains largely untested. We present software models for emulating the inner product behavior of low- and mixed-precision matrix multipliers in the V100, A100, H100 and B200 data center GPUs in most supported input formats of interest to mixed-precision algorithm developers: 8-, 16-, and 19-bit floating point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.07004v1</guid>
      <category>cs.MS</category>
      <category>cs.AR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 09 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Faizan A. Khattak, Mantas Mikaitis</dc:creator>
    </item>
  </channel>
</rss>
