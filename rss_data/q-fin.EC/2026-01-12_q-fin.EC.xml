<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.EC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.EC</link>
    <description>q-fin.EC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.EC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 12 Jan 2026 05:01:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Accounting for environmental awareness in wheat production through Life Cycle Assessment</title>
      <link>https://arxiv.org/abs/2601.05912</link>
      <description>arXiv:2601.05912v1 Announce Type: new 
Abstract: This paper presents a modeling framework for simulating the decision-making processes of artificial farms populating an agent-based model for the Italian wheat production system. The decision process is based on a mathematical programming model with which farms (i.e., agents) decide the target yield (production per hectare) and the mix of inputs needed to obtain such production, namely 1) fertilizers, 2) herbicides, and 3) insecticides. The environmental impacts of conventional production practices are assessed through a Life Cycle Assessment (LCA), using the ReCiPe 2016 methodology at the Endpoint level. Agents are made aware of the environmental consequences of their choices through two indicators: Disability-Adjusted Life Years (DALYs), which capture human health impacts, and the number of species lost per year, reflecting impacts on ecosystems. By internalizing this information, agents can make more balanced and sustainable production decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05912v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Gianfranco Giulioni, Edmondo Di Giuseppe, Arianna Di Paola</dc:creator>
    </item>
    <item>
      <title>Using satellite imagery to map rural marketplaces and monitor their activity at high frequency</title>
      <link>https://arxiv.org/abs/2407.12953</link>
      <description>arXiv:2407.12953v4 Announce Type: replace 
Abstract: In many rural areas of low- and middle-income countries, weekly gatherings of buyers and sellers are the most tangible manifestation of the market economy. Knowing these markets' whereabouts and activity over time could provide insights in otherwise data-scarce environments, helping researchers and policymakers to better understand poor rural economies. But these markets are by nature informal and scattered widely across often-remote regions. As a result, data on this fundamental institution are sparse and inconsistent. We develop, test, and apply a method to fill this gap, leveraging market activity's unique temporal and visual signature in satellite imagery. Using secondary data from Kenya, Malawi, and Mozambique, we first confirm that we detect markets with high sensitivity and specificity. We then derive a map of 1,776 markets in Ethiopia and track their activity at up-to-weekly frequency between 2017 and 2024. Measured market activity exhibits seasonal patterns following local agricultural calendars and responds to weather and conflict shocks. Our approach is applicable wherever satellites can regularly acquire images of rural periodic markets and requires no ground data. Once markets are mapped, our approach can be fully automated to produce an up-to-weekly measure of economic conditions in areas where such data is otherwise generally not available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12953v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tillmann von Carnap (Department of Economics, University of Oslo, Oslo, 0851, Norway, Center on Food Security and the Environment, Stanford University, Stanford, 94305, United States of America), Reza M. Asiyabi (Mistra Center for Sustainable Markets, Stockholm School of Economics, Stockholm, 11350, Sweden, School of GeoScience, University of Edinburgh, Edinburgh, United Kingdom, EH8 9XP, United Kingdom), Paul Dingus (Center on Food Security and the Environment, Stanford University, Stanford, 94305, United States of America), Anna Tompsett (Beijer Institute of Ecological Economics, The Royal Swedish Academy of Sciences, Stockholm, 10405, Sweden, Institute for International Economic Studies, Stockholm University, Stockholm, 10691, Sweden)</dc:creator>
    </item>
    <item>
      <title>Neither Consent nor Property: A Policy Lab for Data Law</title>
      <link>https://arxiv.org/abs/2510.26727</link>
      <description>arXiv:2510.26727v2 Announce Type: replace 
Abstract: Regulators currently govern the AI data economy based on intuition rather than evidence, struggling to choose between inconsistent regimes of informed consent, immunity, and liability. To fill this policy vacuum, this paper develops a novel computational policy laboratory: a spatially explicit Agent-Based Model (ABM) of the data market. To solve the problem of missing data, we introduce a two-stage methodological pipeline. First, we translate decision rules from multi-year fieldwork (2022-2025) into agent constraints. This ensures the model reflects actual bargaining frictions rather than theoretical abstractions. Second, we deploy Large Language Models (LLMs) as "subjects" in a Discrete Choice Experiment (DCE). This novel approach recovers precise preference primitives, such as willingness-to-pay elasticities, which are empirically unobservable in the wild. Calibrated by these inputs, our model places rival legal institutions side-by-side to simulate their welfare effects. The results challenge the dominant regulatory paradigm. We find that property-rule mechanisms, such as informed consent, fail to maximize welfare. Counterintuitively, social welfare peaks when liability for substantive harm is shifted to the downstream buyer. This aligns with the "least cost avoider" principle, because downstream users control post-acquisition safeguards, they are best positioned to mitigate risk efficiently. By "de-romanticizing" seller-centric frameworks, this paper provides an economic justification for emerging doctrines of downstream reachability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26727v2</guid>
      <category>econ.GN</category>
      <category>cs.CY</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoyi Zhang, Tianyi Zhu</dc:creator>
    </item>
    <item>
      <title>Large language models can effectively convince people to believe conspiracies</title>
      <link>https://arxiv.org/abs/2601.05050</link>
      <description>arXiv:2601.05050v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have been shown to be persuasive across a variety of contexts. But it remains unclear whether this persuasive power advantages truth over falsehood, or if LLMs can promote misbeliefs just as easily as refuting them. Here, we investigate this question across three pre-registered experiments in which participants (N = 2,724 Americans) discussed a conspiracy theory they were uncertain about with GPT-4o, and the model was instructed to either argue against ("debunking") or for ("bunking") that conspiracy. When using a "jailbroken" GPT-4o variant with guardrails removed, the AI was as effective at increasing conspiracy belief as decreasing it. Concerningly, the bunking AI was rated more positively, and increased trust in AI, more than the debunking AI. Surprisingly, we found that using standard GPT-4o produced very similar effects, such that the guardrails imposed by OpenAI did little to prevent the LLM from promoting conspiracy beliefs. Encouragingly, however, a corrective conversation reversed these newly induced conspiracy beliefs, and simply prompting GPT-4o to only use accurate information dramatically reduced its ability to increase conspiracy beliefs. Our findings demonstrate that LLMs possess potent abilities to promote both truth and falsehood, but that potential solutions may exist to help mitigate this risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05050v2</guid>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 12 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas H. Costello, Kellin Pelrine, Matthew Kowal, Antonio A. Arechar, Jean-Fran\c{c}ois Godbout, Adam Gleave, David Rand, Gordon Pennycook</dc:creator>
    </item>
  </channel>
</rss>
