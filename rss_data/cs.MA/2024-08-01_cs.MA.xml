<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 02 Aug 2024 01:40:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 01 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Modeling Urban Transport Choices: Incorporating Sociocultural Aspects</title>
      <link>https://arxiv.org/abs/2407.21307</link>
      <description>arXiv:2407.21307v1 Announce Type: new 
Abstract: This paper introduces an agent-based simulation model aimed at understanding urban commuters mode choices and evaluating the impacts of transport policies to promote sustainable mobility. Crafted for developing countries, where utilitarian travel heavily relies on motorcycles, the model integrates sociocultural factors that influence transport behavior. Multinomial models and inferential statistics applied to survey data from Cali, Colombia, inform the model, revealing significant influences of sociodemographic factors and travel attributes on mode choice. Findings highlight the importance of cost, time, safety, comfort, and personal security, with disparities across socioeconomic groups. Policy simulations demonstrate positive responses to interventions like free public transportation, increased bus frequency, and enhanced security, yet with modest shifts in mode choice. Multifaceted policy approaches are deemed more effective, addressing diverse user preferences. Outputs can be extended to cities with similar sociocultural characteristics and transport dynamics. The methodology applied in this work can be replicated for other territories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21307v1</guid>
      <category>cs.MA</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kathleen Salazar-Serna, Lorena Cadavid, Carlos J. Franco</dc:creator>
    </item>
    <item>
      <title>Decentralized and Uncoordinated Learning of Stable Matchings: A Game-Theoretic Approach</title>
      <link>https://arxiv.org/abs/2407.21294</link>
      <description>arXiv:2407.21294v1 Announce Type: cross 
Abstract: We consider the problem of learning stable matchings in a fully decentralized and uncoordinated manner. In this problem, there are $n$ men and $n$ women, each having preference over the other side. It is assumed that women know their preferences over men, but men are not aware of their preferences over women, and they only learn them if they propose and successfully get matched to women. A matching is called stable if no man and woman prefer each other over their current matches. When all the preferences are known a priori, the celebrated Deferred-Acceptance algorithm proposed by Gale and Shapley provides a decentralized and uncoordinated algorithm to obtain a stable matching. However, when the preferences are unknown, developing such an algorithm faces major challenges due to a lack of coordination. We achieve this goal by making a connection between stable matchings and learning Nash equilibria (NE) in noncooperative games. First, we provide a complete information game formulation for the stable matching problem with known preferences such that its set of pure NE coincides with the set of stable matchings, while its mixed NE can be rounded in a decentralized manner to a stable matching. Relying on such a game-theoretic formulation, we show that for hierarchical markets, adopting the exponential weight (EXP) learning algorithm for the stable matching game achieves logarithmic regret with polynomial dependence on the number of players, thus answering a question posed in previous literature. Moreover, we show that the same EXP learning algorithm converges locally and exponentially fast to a stable matching in general matching markets. We complement this result by introducing another decentralized and uncoordinated learning algorithm that globally converges to a stable matching with arbitrarily high probability, leveraging the weak acyclicity property of the stable matching game.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21294v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S. Rasoul Etesami, R. Srikant</dc:creator>
    </item>
    <item>
      <title>Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory</title>
      <link>https://arxiv.org/abs/2405.19024</link>
      <description>arXiv:2405.19024v2 Announce Type: replace-cross 
Abstract: We consider inverse reinforcement learning problems with concave utilities. Concave Utility Reinforcement Learning (CURL) is a generalisation of the standard RL objective, which employs a concave function of the state occupancy measure, rather than a linear function. CURL has garnered recent attention for its ability to represent instances of many important applications including the standard RL such as imitation learning, pure exploration, constrained MDPs, offline RL, human-regularized RL, and others. Inverse reinforcement learning is a powerful paradigm that focuses on recovering an unknown reward function that can rationalize the observed behaviour of an agent. There has been recent theoretical advances in inverse RL where the problem is formulated as identifying the set of feasible reward functions. However, inverse RL for CURL problems has not been considered previously. In this paper we show that most of the standard IRL results do not apply to CURL in general, since CURL invalidates the classical Bellman equations. This calls for a new theoretical framework for the inverse CURL problem. Using a recent equivalence result between CURL and Mean-field Games, we propose a new definition for the feasible rewards for I-CURL by proving that this problem is equivalent to an inverse game theory problem in a subclass of mean-field games. We present initial query and sample complexity results for the I-CURL problem under assumptions such as Lipschitz-continuity. Finally, we outline future directions and applications in human--AI collaboration enabled by our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19024v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa Mert \c{C}elikok, Frans A. Oliehoek, Jan-Willem van de Meent</dc:creator>
    </item>
  </channel>
</rss>
