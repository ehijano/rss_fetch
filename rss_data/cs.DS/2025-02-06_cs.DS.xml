<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 02:42:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Improving polynomial bounds for the Graphical Traveling Salesman Problem with release dates on paths</title>
      <link>https://arxiv.org/abs/2502.02680</link>
      <description>arXiv:2502.02680v2 Announce Type: new 
Abstract: The Graphical Traveling Salesman Problem with release dates (GTSP-rd) is a variation of the TSP-rd where each vertex in a weighted graph $G$ must be visited at least once, respecting the release date restriction. The edges may be traversed multiple times if necessary, as in some sparse graphs. This paper focuses on solving the GTSP-rd in paths. We consider two objective functions: minimizing the route completion time (GTSP-rd (time)) and minimizing the total distance traveled (GTSP-rd (distance)). We present improvements to existing dynamic programming algorithms, offering an $O(n)$ solution for paths where the depot is located at the extremity and an $O(n^2)$ solution for paths where the depot is located anywhere. For the GTSP-rd (distance), we propose an $O(n \log \log n)$ solution for the case with the depot at the extremity and an $O(n^2 \log \log n)$ solution for the general case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02680v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thailsson Clementino, Rosiane de Freitas</dc:creator>
    </item>
    <item>
      <title>Near-optimal Linear Sketches and Fully-Dynamic Algorithms for Hypergraph Spectral Sparsification</title>
      <link>https://arxiv.org/abs/2502.03313</link>
      <description>arXiv:2502.03313v2 Announce Type: new 
Abstract: A hypergraph spectral sparsifier of a hypergraph $G$ is a weighted subgraph $H$ that approximates the Laplacian of $G$ to a specified precision. Recent work has shown that similar to ordinary graphs, there exist $\widetilde{O}(n)$-size hypergraph spectral sparsifiers. However, the task of computing such sparsifiers turns out to be much more involved, and all known algorithms rely on the notion of balanced weight assignments, whose computation inherently relies on repeated, complete access to the underlying hypergraph. We introduce a significantly simpler framework for hypergraph spectral sparsification which bypasses the need to compute such weight assignments, essentially reducing hypergraph sparsification to repeated effective resistance sampling in \textit{ordinary graphs}, which are obtained by \textit{oblivious vertex-sampling} of the original hypergraph.
  Our framework immediately yields a simple, new nearly-linear time algorithm for nearly-linear size spectral hypergraph sparsification. Furthermore, as a direct consequence of our framework, we obtain the first nearly-optimal algorithms in several other models of computation, namely the linear sketching, fully dynamic, and online settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03313v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sanjeev Khanna, Huan Li, Aaron Putterman</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of the Global Cardinality Constraint with Costs</title>
      <link>https://arxiv.org/abs/2502.02688</link>
      <description>arXiv:2502.02688v1 Announce Type: cross 
Abstract: The success of Constraint Programming relies partly on the global constraints and implementation of the associated filtering algorithms. Recently, new ideas emerged to improve these implementations in practice, especially regarding the all different constraint. In this paper, we consider the cardinality constraint with costs. The cardinality constraint is a generalization of the all different constraint that specifies the number of times each value must be taken by a given set of variables in a solution. The version with costs introduces an assignment cost and bounds the total sum of assignment costs. The arc consistency filtering algorithm of this constraint is difficult to use in practice, as it systematically searches for many shortest paths. We propose a new approach that works with upper bounds on shortest paths based on landmarks. This approach can be seen as a preprocessing. It is fast and avoids, in practice, a large number of explicit computations of shortest paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02688v1</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.CP.2024.27</arxiv:DOI>
      <arxiv:journal_reference>30th International Conference on Principles and Practice of Constraint Programming (CP 2024), Leibniz International Proceedings in Informatics (LIPIcs), Volume 307, pp. 27:1--27:18</arxiv:journal_reference>
      <dc:creator>Margaux Schmied, Jean-Charles Regin</dc:creator>
    </item>
    <item>
      <title>Unweighted Code Sparsifiers and Thin Subgraphs</title>
      <link>https://arxiv.org/abs/2502.02799</link>
      <description>arXiv:2502.02799v1 Announce Type: cross 
Abstract: We show that for every $k$-dimensional linear code $\mathcal{C} \subseteq \mathbb{F}_2^n$ there exists a set $S\subseteq [n]$ of size at most $n/2+O(\sqrt{nk})$ such that the projection of $\mathcal{C}$ onto $S$ has distance at least $\frac12\mathrm{dist}(\mathcal{C})$. As a consequence we show that any connected graph $G$ with $m$ edges and $n$ vertices has at least $2^{m-(n-1)}$ many $1/2$-thin subgraphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02799v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shayan Oveis Gharan, Arvin Sahami</dc:creator>
    </item>
    <item>
      <title>Algorithms with Calibrated Machine Learning Predictions</title>
      <link>https://arxiv.org/abs/2502.02861</link>
      <description>arXiv:2502.02861v1 Announce Type: cross 
Abstract: The field of algorithms with predictions incorporates machine learning advice in the design of online algorithms to improve real-world performance. While this theoretical framework often assumes uniform reliability across all predictions, modern machine learning models can now provide instance-level uncertainty estimates. In this paper, we propose calibration as a principled and practical tool to bridge this gap, demonstrating the benefits of calibrated advice through two case studies: the ski rental and online job scheduling problems. For ski rental, we design an algorithm that achieves optimal prediction-dependent performance and prove that, in high-variance settings, calibrated advice offers more effective guidance than alternative methods for uncertainty quantification. For job scheduling, we demonstrate that using a calibrated predictor leads to significant performance improvements over existing methods. Evaluations on real-world data validate our theoretical findings, highlighting the practical impact of calibration for algorithms with predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02861v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Judy Shen, Ellen Vitercik, Anders Wikum</dc:creator>
    </item>
    <item>
      <title>Group Trip Planning Query Problem with Multimodal Journey</title>
      <link>https://arxiv.org/abs/2502.03144</link>
      <description>arXiv:2502.03144v1 Announce Type: cross 
Abstract: In Group Trip Planning (GTP) Query Problem, we are given a city road network where a number of Points of Interest (PoI) have been marked with their respective categories (e.g., Cafeteria, Park, Movie Theater, etc.). A group of agents want to visit one PoI from every category from their respective starting location and once finished, they want to reach their respective destinations. This problem asks which PoI from every category should be chosen so that the aggregated travel cost of the group is minimized. This problem has been studied extensively in the last decade, and several solution approaches have been proposed. However, to the best of our knowledge, none of the existing studies have considered the different modalities of the journey, which makes the problem more practical. To bridge this gap, we introduce and study the GTP Query Problem with Multimodal Journey in this paper. Along with the other inputs of the GTP Query Problem, we are also given the different modalities of the journey that are available and their respective cost. Now, the problem is not only to select the PoIs from respective categories but also to select the modality of the journey. For this problem, we have proposed an efficient solution approach, which has been analyzed to understand their time and space requirements. A large number of experiments have been conducted using real-life datasets and the results have been reported. From the results, we observe that the PoIs and modality of journey recommended by the proposed solution approach lead to much less time and cost than the baseline methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03144v1</guid>
      <category>cs.MA</category>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dildar Ali, Suman Banerjee, Yamuna Prasad</dc:creator>
    </item>
    <item>
      <title>Optimal Orthogonal Drawings in Linear Time</title>
      <link>https://arxiv.org/abs/2502.03309</link>
      <description>arXiv:2502.03309v1 Announce Type: cross 
Abstract: A planar orthogonal drawing {\Gamma} of a connected planar graph G is a geometric representation of G such that the vertices are drawn as distinct points of the plane, the edges are drawn as chains of horizontal and vertical segments, and no two edges intersect except at common end-points. A bend of {\Gamma} is a point of an edge where a horizontal and a vertical segment meet. Drawing {\Gamma} is bend-minimum if it has the minimum number of bends over all possible planar orthogonal drawings of G. Its curve complexity is the maximum number of bends per edge. In this paper we present a linear-time algorithm for the computation of planar orthogonal drawings of 3-graphs (i.e., graphs with vertex-degree at most three), that minimizes both the total number of bends and the curve complexity. The algorithm works in the so-called variable embedding setting, that is, it can choose among the exponentially many planar embeddings of the input graph. While the time complexity of minimizing the total number of bends of a planar orthogonal drawing of a 3-graph in the variable embedding settings is a long standing, widely studied, open question, the existence of an orthogonal drawing that is optimal both in the total number of bends and in the curve complexity was previously unknown. Our result combines several graph decomposition techniques, novel data-structures, and efficient approaches to re-rooting decomposition trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03309v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Walter Didimo, Giuseppe Liotta, Giacomo Ortali, Maurizio Patrignani</dc:creator>
    </item>
    <item>
      <title>Parameterized Algorithms for Editing to Uniform Cluster Graph</title>
      <link>https://arxiv.org/abs/2404.10023</link>
      <description>arXiv:2404.10023v3 Announce Type: replace 
Abstract: We study the parameterized complexity of transforming graphs into Uniform Cluster graphs, where each component is an equal-sized clique. We consider Uniform Cluster Vertex Deletion (UCVD), Uniform Cluster Edge Deletion (UCED), Uniform Cluster Edge Addition (UCEA), Uniform Cluster Edge Editing (UCEE), Uniform Cluster Exclusive Vertex Splitting (UCEVS), and Uniform Cluster Inclusive Vertex Splitting (UCIVS). For UCVD, we provide a vertex kernel of size $\mathcal{O}(k^{3})$ and an FPT algorithm with running time $2^{k} \cdot n^{\mathcal{O}(1)}$, improving the known $3^{k} \cdot n^{\mathcal{O}(1)}$ algorithm. For edge-based variants, we obtain a $\mathcal{O}(k^{2})$ vertex kernel for UCEE and linear vertex kernels for UCED and UCEA, improving the best-known results. Additionally, we present a $1.47^{k} \cdot n^{\mathcal{O}(1)}$ algorithm for UCED, improving upon the previous $2^{k} \cdot n^{\mathcal{O}(1)}$ bound. We develop a sub-exponential algorithm for UCED on everywhere dense graphs by reducing it to $d$-Way Cut. Lastly, we study vertex splitting operations and provide vertex kernels of size $4k$ for both UCIVS and UCEVS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10023v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajinkya Gaikwad, Hitendra Kumar, Soumen Maity</dc:creator>
    </item>
    <item>
      <title>It's Hard to HAC with Average Linkage!</title>
      <link>https://arxiv.org/abs/2404.14730</link>
      <description>arXiv:2404.14730v2 Announce Type: replace 
Abstract: Average linkage Hierarchical Agglomerative Clustering (HAC) is an extensively studied and applied method for hierarchical clustering. Recent applications to massive datasets have driven significant interest in near-linear-time and efficient parallel algorithms for average linkage HAC.
  We provide hardness results that rule out such algorithms. On the sequential side, we establish a runtime lower bound of $n^{3/2-\epsilon}$ on $n$ node graphs for sequential combinatorial algorithms under standard fine-grained complexity assumptions. This essentially matches the best-known running time for average linkage HAC. On the parallel side, we prove that average linkage HAC likely cannot be parallelized even on simple graphs by showing that it is CC-hard on trees of diameter $4$. On the possibility side, we demonstrate that average linkage HAC can be efficiently parallelized (i.e., it is in NC) on paths and can be solved in near-linear time when the height of the output cluster hierarchy is small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14730v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>MohammadHossein Bateni, Laxman Dhulipala, Kishen N Gowda, D Ellis Hershkowitz, Rajesh Jayaram, Jakub {\L}\k{a}cki</dc:creator>
    </item>
    <item>
      <title>Discretely Beyond $1/e$: Guided Combinatorial Algorithms for Submodular Maximization</title>
      <link>https://arxiv.org/abs/2405.05202</link>
      <description>arXiv:2405.05202v3 Announce Type: replace 
Abstract: For constrained, not necessarily monotone submodular maximization, all known approximation algorithms with ratio greater than $1/e$ require continuous ideas, such as queries to the multilinear extension of a submodular function and its gradient, which are typically expensive to simulate with the original set function. For combinatorial algorithms, the best known approximation ratios for both size and matroid constraint are obtained by a simple randomized greedy algorithm of Buchbinder et al. [9]: $1/e \approx 0.367$ for size constraint and $0.281$ for the matroid constraint in $\mathcal O (kn)$ queries, where $k$ is the rank of the matroid. In this work, we develop the first combinatorial algorithms to break the $1/e$ barrier: we obtain approximation ratio of $0.385$ in $\mathcal O (kn)$ queries to the submodular set function for size constraint, and $0.305$ for a general matroid constraint. These are achieved by guiding the randomized greedy algorithm with a fast local search algorithm. Further, we develop deterministic versions of these algorithms, maintaining the same ratio and asymptotic time complexity. Finally, we develop a deterministic, nearly linear time algorithm with ratio $0.377$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05202v3</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixin Chen, Ankur Nath, Chunli Peng, Alan Kuhnle</dc:creator>
    </item>
    <item>
      <title>On the on-line coloring of unit interval graphs with proper interval representation</title>
      <link>https://arxiv.org/abs/2401.05648</link>
      <description>arXiv:2401.05648v4 Announce Type: replace-cross 
Abstract: We define the problem as a two-player game between Algorithm and Builder. The game is played in rounds. Each round, Builder presents an interval that is neither contained in nor contains any previously presented interval. Algorithm immediately and irrevocably assigns the interval a color that has not been assigned to any interval intersecting it. The set of intervals form an interval representation for a unit interval graph and the colors form a proper coloring of that graph. For every positive integer $\omega$, we define the value $R(\omega)$ as the maximum number of colors for which Builder has a strategy that forces Algorithm to use $R(\omega)$ colors with the restriction that the unit interval graph constructed cannot contain a clique of size $\omega$. In 1981, Chrobak and \'{S}lusarek showed that $R(\omega)\leq2\omega -1$. In 2005, Epstein and Levy showed that $R(\omega)\geq\lfloor{3\omega/2\rfloor}$. This problem remained unsolved for $\omega\geq 3$. In 2022, Bir\'o and Curbelo showed that $R(3)=5$. In this paper, we show that $R(4)=7$</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05648v4</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Israel R. Curbelo, Hannah R. Malko</dc:creator>
    </item>
    <item>
      <title>Causal Equal Protection as Algorithmic Fairness</title>
      <link>https://arxiv.org/abs/2402.12062</link>
      <description>arXiv:2402.12062v4 Announce Type: replace-cross 
Abstract: By combining the philosophical literature on statistical evidence and the interdisciplinary literature on algorithmic fairness, we revisit recent objections against classification parity in light of causal analyses of algorithmic fairness and the distinction between predictive and diagnostic evidence. We focus on trial proceedings as a black-box classification algorithm in which defendants are sorted into two groups by convicting or acquitting them. We defend a novel principle, causal equal protection, that combines classification parity with the causal approach. In the do-calculus, causal equal protection requires that individuals should not be subject to uneven risks of classification error because of their protected or socially salient characteristics. The explicit use of protected characteristics, however, may be required if it equalizes these risks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12062v4</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcello Di Bello, Nicol\`o Cangiotti, Michele Loi</dc:creator>
    </item>
    <item>
      <title>The Polymatroid Representation of a Greedoid, and Associated Galois Connections</title>
      <link>https://arxiv.org/abs/2411.15363</link>
      <description>arXiv:2411.15363v2 Announce Type: replace-cross 
Abstract: The greedoid is a significant abstraction of the matroid allowing for a more flexible analysis of structures in which the greedy algorithm "works." However, their diverse structure imposes difficulties towards their application in combinatorial optimization [Sze21]. In response, we revisit the polymatroid greedoid [KL85a] to characterize it by properties approximating those of matroids, by using the submodularity of its polymatroid representation in particular. Towards doing so, our main contribution is a full description of this class. Specifically, we show that a greedoid is a polymatroid greedoid if and only if it is an optimistic interval greedoid whose kernels are closed under intersection. This constitutes the first necessary and sufficient characterization of the polymatroid greedoid in terms of its combinatorial attributes, thereby resolving a central open question of Korte and Lov\'asz [KL85a]. Here, we introduce the optimism property to approximate properties of a matroid's continuations which are implied by the closure axioms of its span, which no longer hold for greedoids. And, because the kernels of an interval greedoid are in many ways an extension of a matroid's closed sets, our direction of necessity is a direct generalization of Birkhoff and Edmond's characterization of the meet in the lattice of a matroid's closed sets [Bir35, Edm03]. Towards achieving this result, our main technical insights arise from relating the lattice of flats of a polymatroid greedoid to that of the closed sets of its representation through order preserving mappings. Specifically, we will show the novel insight that the notion of polymatroid representation considered in [KL85a] is equivalent to the existence of a certain Galois connection. As a consequence, the representation of a greedoid via a polymatroid is an order theoretic concept in disguise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15363v2</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 06 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Streit, Vijay K. Garg</dc:creator>
    </item>
  </channel>
</rss>
