<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.PM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.PM</link>
    <description>q-fin.PM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.PM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 05:05:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Distillation-based Future-aware Graph Neural Network for Stock Trend Prediction</title>
      <link>https://arxiv.org/abs/2502.10776</link>
      <description>arXiv:2502.10776v1 Announce Type: cross 
Abstract: Stock trend prediction involves forecasting the future price movements by analyzing historical data and various market indicators. With the advancement of machine learning, graph neural networks (GNNs) have been extensively employed in stock prediction due to their powerful capability to capture spatiotemporal dependencies of stocks. However, despite the efforts of various GNN stock predictors to enhance predictive performance, the improvements remain limited, as they focus solely on analyzing historical spatiotemporal dependencies, overlooking the correlation between historical and future patterns. In this study, we propose a novel distillation-based future-aware GNN framework (DishFT-GNN) for stock trend prediction. Specifically, DishFT-GNN trains a teacher model and a student model, iteratively. The teacher model learns to capture the correlation between distribution shifts of historical and future data, which is then utilized as intermediate supervision to guide the student model to learn future-aware spatiotemporal embeddings for accurate prediction. Through extensive experiments on two real-world datasets, we verify the state-of-the-art performance of DishFT-GNN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10776v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhipeng Liu, Peibo Duan, Mingyang Geng, Bin Zhang</dc:creator>
    </item>
    <item>
      <title>Time-consistent portfolio selection with strictly monotone mean-variance preference</title>
      <link>https://arxiv.org/abs/2502.11052</link>
      <description>arXiv:2502.11052v1 Announce Type: cross 
Abstract: This paper is devoted to time-consistent control problems of portfolio selection with strictly monotone mean-variance preferences. These preferences are variational modifications of the conventional mean-variance preferences, and remain time-inconsistent as in mean-variance optimization problems. To tackle the time-inconsistency, we study the Nash equilibrium controls of both the open-loop type and the closed-loop type, and characterize them within a random parameter setting. The problem is reduced to solving a flow of forward-backward stochastic differential equations for open-loop equilibria, and to solving extended Hamilton-Jacobi-Bellman equations for closed-loop equilibria. In particular, we derive semi-closed-form solutions for these two types of equilibria under a deterministic parameter setting. Both solutions are represented by the same function, which is independent of wealth state and random path. This function can be expressed as the conventional time-consistent mean-variance portfolio strategy multiplied by a factor greater than one. Furthermore, we find that the state-independent closed-loop Nash equilibrium control is a strong equilibrium strategy in a constant parameter setting only when the interest rate is sufficiently large.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11052v1</guid>
      <category>math.OC</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yike Wang, Yusha Chen</dc:creator>
    </item>
    <item>
      <title>A Cholesky decomposition-based asset selection heuristic for sparse tangent portfolio optimization</title>
      <link>https://arxiv.org/abs/2502.11701</link>
      <description>arXiv:2502.11701v1 Announce Type: cross 
Abstract: In practice, including large number of assets in mean-variance portfolios can lead to higher transaction costs and management fees. To address this, one common approach is to select a smaller subset of assets from the larger pool, constructing more efficient portfolios. As a solution, we propose a new asset selection heuristic which generates a pre-defined list of asset candidates using a surrogate formulation and re-optimizes the cardinality-constrained tangent portfolio with these selected assets. This method enables faster optimization and effectively constructs portfolios with fewer assets, as demonstrated by numerical analyses on historical stock returns. Finally, we discuss a quantitative metric that can provide a initial assessment of the performance of the proposed heuristic based on asset covariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11701v1</guid>
      <category>q-fin.MF</category>
      <category>q-fin.PM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hyunglip Bae, Haeun Jeon, Minsu Park, Yongjae Lee, Woo Chang Kim</dc:creator>
    </item>
    <item>
      <title>Pontryagin-Guided Deep Learning for Large-Scale Constrained Dynamic Portfolio Choice</title>
      <link>https://arxiv.org/abs/2501.12600</link>
      <description>arXiv:2501.12600v4 Announce Type: replace 
Abstract: We present a Pontryagin-Guided Direct Policy Optimization (PG-DPO) method for constrained dynamic portfolio choice - incorporating consumption and multi-asset investment - that scales to thousands of risky assets. By combining neural-network controls with Pontryagin's Maximum Principle (PMP), it circumvents the curse of dimensionality that renders dynamic programming (DP) grids intractable beyond a handful of assets. Unlike value-based PDE or BSDE approaches, PG-DPO enforces PMP conditions at each gradient step, naturally accommodating no-short-selling or borrowing constraints and optional consumption bounds. A "one-shot" variant rapidly computes Pontryagin-optimal controls after a brief warm-up, leading to substantially higher accuracy than naive baselines. On modern GPUs, near-optimal solutions often emerge within just one or two minutes of training. Numerical experiments confirm that, for up to 1,000 assets, PG-DPO accurately recovers the known closed-form solution in the unconstrained case and remains tractable under constraints -- far exceeding the longstanding DP-based limit of around seven assets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12600v4</guid>
      <category>q-fin.PM</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeonggyu Huh, Jaegi Jeon, Hyeng Keun Koo, Byung Hwa Lim</dc:creator>
    </item>
  </channel>
</rss>
