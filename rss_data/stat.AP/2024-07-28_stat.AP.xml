<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 29 Jul 2024 04:00:48 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 29 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Organizational Effectiveness: A New Strategy to Leverage Multisite Randomized Trials for Valid Assessment</title>
      <link>https://arxiv.org/abs/2407.18360</link>
      <description>arXiv:2407.18360v1 Announce Type: new 
Abstract: In education, health, and human services, an intervention program is usually implemented by many local organizations. Determining which organizations are more effective is essential for theoretically characterizing effective practices and for intervening to enhance the capacity of ineffective organizations. In multisite randomized trials, site-specific intention-to-treat (ITT) effects are likely invalid indicators for organizational effectiveness and may lead to inequitable decisions. This is because sites differ in their local ecological conditions including client composition, alternative programs, and community context. Applying the potential outcomes framework, this study proposes a mathematical definition for the relative effectiveness of an organization. The estimand contrasts the performance of a focal organization with those that share the features of its local ecological conditions. The identification relies on relatively weak assumptions by leveraging observed control group outcomes that capture the confounding impacts of alternative programs and community context. We propose a two-step mixed-effects modeling (2SME) procedure. Simulations demonstrate significant improvements when compared with site-specific ITT analyses or analyses that only adjust for between-site differences in the observed baseline participant composition. We illustrate its use through an evaluation of the relative effectiveness of individual Job Corps centers by reanalyzing data from the National Job Corps Study, a multisite randomized trial that included 100 Job Corps centers nationwide serving disadvantaged youths. The new strategy promises to alleviate consequential misclassifications of some of the most effective Job Corps centers as least effective and vice versa.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18360v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanglei Hong (University of Chicago), Jonah Deutsch (Mathematica), Peter Kress (Mathematica), Jose Eos Trinidad (University of California-Berkeley), Zhengyan Xu (University of Pennsylvania)</dc:creator>
    </item>
    <item>
      <title>Bayesian Nowcasting Data Breach IBNR Incidents</title>
      <link>https://arxiv.org/abs/2407.18377</link>
      <description>arXiv:2407.18377v1 Announce Type: new 
Abstract: The reporting delay in data breach incidents poses a formidable challenge for Incurred But Not Reported (IBNR) studies, complicating reserve estimation for actuarial professionals. This work presents a novel Bayesian nowcasting model designed to accurately model and predict the number of IBNR data breach incidents. Leveraging a Bayesian modeling framework, the model integrates time and heterogeneous effects to enhance predictive accuracy. Synthetic and empirical studies demonstrate the superior performance of the proposed model, highlighting its efficacy in addressing the complexities of IBNR estimation. Furthermore, we examine reserve estimation for IBNR incidents using the proposed model, shedding light on its implications for actuarial practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18377v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maochao Xu, Hong Sun, Peng Zhao</dc:creator>
    </item>
    <item>
      <title>Bernoulli amputation</title>
      <link>https://arxiv.org/abs/2407.18572</link>
      <description>arXiv:2407.18572v1 Announce Type: new 
Abstract: An approach to amputation, the process of introducing missing values to a complete dataset, is presented. It allows to construct missingness indicators in a flexible and principled way via copulas and Bernoulli margins and to incorporate dependence in missingness patterns. Besides more classical missingness models such as missing completely at random, missing at random, and missing not at random, the approach is able to model structured missingness such as block missingness and, via mixtures, monotone missingness, which are patterns of missing data frequently found in real-life datasets. Properties such as joint missingness probabilities or missingness correlation are derived mathematically. The approach is demonstrated with mathematical examples and empirical illustrations in terms of a well-known dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18572v1</guid>
      <category>stat.AP</category>
      <category>math.ST</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marius Hofert, James Jackson, Niels Hagenbuch</dc:creator>
    </item>
    <item>
      <title>Spatial analysis of tails of air pollution PDFs in Europe</title>
      <link>https://arxiv.org/abs/2407.18268</link>
      <description>arXiv:2407.18268v1 Announce Type: cross 
Abstract: Outdoor air pollution is estimated to cause a huge number of premature deaths worldwide, it catalyses many diseases on a variety of time scales, and it has a detrimental effect on the environment. In light of these impacts it is necessary to obtain a better understanding of the dynamics and statistics of measured air pollution concentrations, including temporal fluctuations of observed concentrations and spatial heterogeneities. Here we present an extensive analysis for measured data from Europe. The observed probability density functions (PDFs) of air pollution concentrations depend very much on the spatial location and on the pollutant substance. We analyse a large number of time series data from 3544 different European monitoring sites and show that the PDFs of nitric oxide ($NO$), nitrogen dioxide ($NO_{2}$) and particulate matter ($PM_{10}$ and $PM_{2.5}$) concentrations generically exhibit heavy tails. These are asymptotically well approximated by $q$-exponential distributions with a given entropic index $q$ and width parameter $\lambda$. We observe that the power-law parameter $q$ and the width parameter $\lambda$ vary widely for the different spatial locations. We present the results of our data analysis in the form of a map that shows which parameters $q$ and $\lambda$ are most relevant in a given region. A variety of interesting spatial patterns is observed that correlate to properties of the geographical region. We also present results on typical time scales associated with the dynamical behaviour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18268v1</guid>
      <category>physics.ao-ph</category>
      <category>math.DS</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hankun He, Benjamin Sch\"afer, Christian Beck</dc:creator>
    </item>
    <item>
      <title>Doubly Robust Targeted Estimation of Conditional Average Treatment Effects for Time-to-event Outcomes with Competing Risks</title>
      <link>https://arxiv.org/abs/2407.18389</link>
      <description>arXiv:2407.18389v1 Announce Type: cross 
Abstract: In recent years, precision treatment strategy have gained significant attention in medical research, particularly for patient care. We propose a novel framework for estimating conditional average treatment effects (CATE) in time-to-event data with competing risks, using ICU patients with sepsis as an illustrative example. Our approach, based on cumulative incidence functions and targeted maximum likelihood estimation (TMLE), achieves both asymptotic efficiency and double robustness. The primary contribution of this work lies in our derivation of the efficient influence function for the targeted causal parameter, CATE. We established the theoretical proofs for these properties, and subsequently confirmed them through simulations. Our TMLE framework is flexible, accommodating various regression and machine learning models, making it applicable in diverse scenarios. In order to identify variables contributing to treatment effect heterogeneity and to facilitate accurate estimation of CATE, we developed two distinct variable importance measures (VIMs). This work provides a powerful tool for optimizing personalized treatment strategies, furthering the pursuit of precision medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18389v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Runjia Li, Victor B. Talisa, Chung-Chou H. Chang</dc:creator>
    </item>
    <item>
      <title>A Public Dataset For the ZKsync Rollup</title>
      <link>https://arxiv.org/abs/2407.18699</link>
      <description>arXiv:2407.18699v1 Announce Type: cross 
Abstract: Despite blockchain data being publicly available, practical challenges and high costs often hinder its effective use by researchers, thus limiting data-driven research and exploration in the blockchain space. This is especially true when it comes to Layer~2 (L2) ecosystems, and ZKsync, in particular. To address these issues, we have curated a dataset from 1 year of activity extracted from a ZKsync Era archive node and made it freely available to external parties. In this paper, we provide details on this dataset and how it was created, showcase a few example analyses that can be performed with it, and discuss some future research directions. We also publish and share the code used in our analysis on GitHub to promote reproducibility and to support further research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18699v1</guid>
      <category>cs.CR</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maria In\^es Silva, Johnnatan Messias, Benjamin Livshits</dc:creator>
    </item>
    <item>
      <title>Robust Estimation of Polychoric Correlation</title>
      <link>https://arxiv.org/abs/2407.18835</link>
      <description>arXiv:2407.18835v1 Announce Type: cross 
Abstract: Polychoric correlation is often an important building block in the analysis of rating data, particularly for structural equation models. However, the commonly employed maximum likelihood (ML) estimator is highly susceptible to misspecification of the polychoric correlation model, for instance through violations of latent normality assumptions. We propose a novel estimator that is designed to be robust to partial misspecification of the polychoric model, that is, the model is only misspecified for an unknown fraction of observations, for instance (but not limited to) careless respondents. In contrast to existing literature, our estimator makes no assumption on the type or degree of model misspecification. It furthermore generalizes ML estimation and is consistent as well as asymptotically normally distributed. We demonstrate the robustness and practical usefulness of our estimator in simulation studies and an empirical application on a Big Five administration. In the latter, the polychoric correlation estimates of our estimator and ML differ substantially, which, after further inspection, is likely due to the presence of careless respondents that the estimator helps identify.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18835v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max Welz, Patrick Mair, Andreas Alfons</dc:creator>
    </item>
    <item>
      <title>Group integrative dynamic factor models with application to multiple subject brain connectivity</title>
      <link>https://arxiv.org/abs/2307.15330</link>
      <description>arXiv:2307.15330v4 Announce Type: replace-cross 
Abstract: This work introduces a novel framework for dynamic factor model-based group-level analysis of multiple subjects time series data, called GRoup Integrative DYnamic factor (GRIDY) models. The framework identifies and characterizes inter-subject similarities and differences between two pre-determined groups by considering a combination of group spatial information and individual temporal dynamics. Furthermore, it enables the identification of intra-subject similarities and differences over time by employing different model configurations for each subject. Methodologically, the framework combines a novel principal angle-based rank selection algorithm and a non-iterative integrative analysis framework. Inspired by simultaneous component analysis, this approach also reconstructs identifiable latent factor series with flexible covariance structures. The performance of the GRIDY models is evaluated through simulations conducted under various scenarios. An application is also presented to compare resting-state functional MRI data collected from multiple subjects in autism spectrum disorder and control groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15330v4</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Younghoon Kim, Zachary F. Fisher, Vladas Pipiras</dc:creator>
    </item>
    <item>
      <title>Topological Data Analysis in smart manufacturing: State of the art and futuredirections</title>
      <link>https://arxiv.org/abs/2310.09319</link>
      <description>arXiv:2310.09319v3 Announce Type: replace-cross 
Abstract: Topological Data Analysis (TDA) is a discipline that applies algebraic topology techniques to analyze complex, multi-dimensional data. Although it is a relatively new field, TDA has been widely and successfully applied across various domains, such as medicine, materials science, and biology. This survey provides an overview of the state of the art of TDA within a dynamic and promising application area: industrial manufacturing and production, particularly within the Industry 4.0 context. We have conducted a rigorous and reproducible literature search focusing on TDA applications in industrial production and manufacturing settings. The identified works are categorized based on their application areas within the manufacturing process and the types of input data. We highlight the principal advantages of TDA tools in this context, address the challenges encountered and the future potential of the field. Furthermore, we identify TDA methods that are currently underexploited in specific industrial areas and discuss how their application could be beneficial, with the aim of stimulating further research in this field. This work seeks to bridge the theoretical advancements in TDA with the practical needs of industrial production. Our goal is to serve as a guide for practitioners and researchers applying TDA in industrial production and manufacturing systems. We advocate for the untapped potential of TDA in this domain and encourage continued exploration and research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.09319v3</guid>
      <category>cs.LG</category>
      <category>math.AT</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jmsy.2024.07.006</arxiv:DOI>
      <dc:creator>Martin Uray, Barbara Giunti, Michael Kerber, Stefan Huber</dc:creator>
    </item>
    <item>
      <title>HMM for Discovering Decision-Making Dynamics Using Reinforcement Learning Experiments</title>
      <link>https://arxiv.org/abs/2401.13929</link>
      <description>arXiv:2401.13929v2 Announce Type: replace-cross 
Abstract: Major depressive disorder (MDD) presents challenges in diagnosis and treatment due to its complex and heterogeneous nature. Emerging evidence indicates that reward processing abnormalities may serve as a behavioral marker for MDD. To measure reward processing, patients perform computer-based behavioral tasks that involve making choices or responding to stimulants that are associated with different outcomes. Reinforcement learning (RL) models are fitted to extract parameters that measure various aspects of reward processing to characterize how patients make decisions in behavioral tasks. Recent findings suggest the inadequacy of characterizing reward learning solely based on a single RL model; instead, there may be a switching of decision-making processes between multiple strategies. An important scientific question is how the dynamics of learning strategies in decision-making affect the reward learning ability of individuals with MDD. Motivated by the probabilistic reward task (PRT) within the EMBARC study, we propose a novel RL-HMM framework for analyzing reward-based decision-making. Our model accommodates learning strategy switching between two distinct approaches under a hidden Markov model (HMM): subjects making decisions based on the RL model or opting for random choices. We account for continuous RL state space and allow time-varying transition probabilities in the HMM. We introduce a computationally efficient EM algorithm for parameter estimation and employ a nonparametric bootstrap for inference. We apply our approach to the EMBARC study to show that MDD patients are less engaged in RL compared to the healthy controls, and engagement is associated with brain activities in the negative affect circuitry during an emotional conflict task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.13929v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingche Guo, Donglin Zeng, Yuanjia Wang</dc:creator>
    </item>
    <item>
      <title>Bayesian Methods for Modeling Cumulative Exposure to Extensive Environmental Health Hazards</title>
      <link>https://arxiv.org/abs/2404.04398</link>
      <description>arXiv:2404.04398v2 Announce Type: replace-cross 
Abstract: Measuring the impact of an environmental point source exposure on the risk of disease, like cancer or childhood asthma, is well-developed. Modeling how an environmental health hazard that is extensive in space, like a wastewater canal, impacts disease risk is not. We propose a novel Bayesian generative semiparametric model for characterizing the cumulative spatial exposure to an environmental health hazard that is not well-represented by a single point in space. The model couples a dose-response model with a log-Gaussian Cox process integrated against a distance kernel with an unknown length-scale. We show that this model is a well-defined Bayesian inverse model, namely that the posterior exists under a Gaussian process prior for the log-intensity of exposure, and that a simple integral approximation adequately controls the computational error. We quantify the finite-sample properties and the computational tractability of the discretization scheme in a simulation study. Finally, we apply the model to survey data on household risk of childhood diarrheal illness from exposure to a system of wastewater canals in Mezquital Valley, Mexico.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04398v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rob Trangucci, Jesse Contreras, Jon Zelner, Joseph N. S. Eisenberg, Yang Chen</dc:creator>
    </item>
    <item>
      <title>animal2vec and MeerKAT: A self-supervised transformer for rare-event raw audio input and a large-scale reference dataset for bioacoustics</title>
      <link>https://arxiv.org/abs/2406.01253</link>
      <description>arXiv:2406.01253v2 Announce Type: replace-cross 
Abstract: Bioacoustic research, vital for understanding animal behavior, conservation, and ecology, faces a monumental challenge: analyzing vast datasets where animal vocalizations are rare. While deep learning techniques are becoming standard, adapting them to bioacoustics remains difficult. We address this with animal2vec, an interpretable large transformer model, and a self-supervised training scheme tailored for sparse and unbalanced bioacoustic data. It learns from unlabeled audio and then refines its understanding with labeled data. Furthermore, we introduce and publicly release MeerKAT: Meerkat Kalahari Audio Transcripts, a dataset of meerkat (Suricata suricatta) vocalizations with millisecond-resolution annotations, the largest labeled dataset on non-human terrestrial mammals currently available. Our model outperforms existing methods on MeerKAT and the publicly available NIPS4Bplus birdsong dataset. Moreover, animal2vec performs well even with limited labeled data (few-shot learning). animal2vec and MeerKAT provide a new reference point for bioacoustic research, enabling scientists to analyze large amounts of data even with scarce ground truth information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01253v2</guid>
      <category>cs.SD</category>
      <category>cs.AI</category>
      <category>eess.AS</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian C. Sch\"afer-Zimmermann, Vlad Demartsev, Baptiste Averly, Kiran Dhanjal-Adams, Mathieu Duteil, Gabriella Gall, Marius Fai{\ss}, Lily Johnson-Ulrich, Dan Stowell, Marta B. Manser, Marie A. Roch, Ariana Strandburg-Peshkin</dc:creator>
    </item>
  </channel>
</rss>
