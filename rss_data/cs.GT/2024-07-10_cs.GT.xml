<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 11 Jul 2024 04:00:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 11 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fast Revenue Maximization</title>
      <link>https://arxiv.org/abs/2407.07316</link>
      <description>arXiv:2407.07316v1 Announce Type: new 
Abstract: We study a data-driven problem pricing problem in which a seller offers a price for a single item based on demand observed at a small finite number of historical prices. Our goal is to derive precise evaluation procedures of the value of the historical information gathered by the seller, along with prescriptions for more efficient price experimentation. Our main methodological result is an exact characterization of the maximin ratio (defined as the worst-case revenue garnered by a seller who only relies on past data divided by the optimal revenue achievable with full knowledge of the distribution of values). This result allows to measure the value of any historical data consisting of prices and corresponding conversion rates. We leverage this central reduction to provide new insights about price experimentation. Motivated by practical constraints that impede the seller from changing prices abruptly, we first illustrate our framework by evaluating the value of local information and show that the mere sign of the gradient may sometimes provide significant information to the seller. We then showcase how our framework can be used to run efficient price experiments. On the one hand, we develop a method to select the next price experiment that the seller should use to maximize the information obtained. On the other hand, we demonstrate that our result allows to considerably reduce the price experimentation needed to reach preset revenue guarantees through dynamic pricing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07316v1</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Achraf Bahamou, Omar Besbes, Omar Mouchtaki</dc:creator>
    </item>
    <item>
      <title>Searcher Competition in Block Building</title>
      <link>https://arxiv.org/abs/2407.07474</link>
      <description>arXiv:2407.07474v1 Announce Type: new 
Abstract: We study the amount of maximal extractable value (MEV) captured by validators, as a function of searcher competition, in blockchains with competitive block building markets such as Ethereum. We argue that the core is a suitable solution concept in this context that makes robust predictions that are independent of implementation details or specific mechanisms chosen. We characterize how much value validators extract in the core and quantify the surplus share of validators as a function of searcher competition. Searchers can obtain at most the marginal value increase of the winning block relative to the best block that can be built without their bundles. Dually this gives a lower bound on the value extracted by the validator. If arbitrages are easy to find and many searchers find similar bundles, the validator gets paid all value almost surely, while searchers can capture most value if there is little searcher competition per arbitrage. For the case of passive block-proposers we study, moreover, mechanisms that implement core allocations in dominant strategies and find that for submodular value, there is a unique dominant-strategy incentive compatible core-selecting mechanism that gives each searcher exactly their marginal value contribution to the winning block. We validate our theoretical prediction empirically with aggregate bundle data and find a significant positive relation between the number of submitted backruns for the same opportunity and the median value captured by the proposer from the opportunity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07474v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akaki Mamageishvili, Christoph Schlegel, Benny Sudakov, Danning Sui</dc:creator>
    </item>
    <item>
      <title>The Complexity of Computing Robust Mediated Equilibria in Ordinal Games</title>
      <link>https://arxiv.org/abs/2407.07625</link>
      <description>arXiv:2407.07625v1 Announce Type: new 
Abstract: Usually, to apply game-theoretic methods, we must specify utilities precisely, and we run the risk that the solutions we compute are not robust to errors in this specification. Ordinal games provide an attractive alternative: they require specifying only which outcomes are preferred to which other ones. Unfortunately, they provide little guidance for how to play unless there are pure Nash equilibria; evaluating mixed strategies appears to fundamentally require cardinal utilities.
  In this paper, we observe that we can in fact make good use of mixed strategies in ordinal games if we consider settings that allow for folk theorems. These allow us to find equilibria that are robust, in the sense that they remain equilibria no matter which cardinal utilities are the correct ones -- as long as they are consistent with the specified ordinal preferences. We analyze this concept and study the computational complexity of finding such equilibria in a range of settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07625v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1609/aaai.v38i9.28817</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the Thirty-Eighth AAAI Conference on Artificial Intelligence, 2024</arxiv:journal_reference>
      <dc:creator>Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Low communication protocols for fair allocation of indivisible goods</title>
      <link>https://arxiv.org/abs/2407.07641</link>
      <description>arXiv:2407.07641v1 Announce Type: new 
Abstract: We study the multi-party randomized communication complexity of computing a fair allocation of $m$ indivisible goods to $n &lt; m$ equally entitled agents. We first consider MMS allocations, allocations that give every agent at least her maximin share. Such allocations are guaranteed to exist for simple classes of valuation functions. We consider the expected number of bits that each agent needs to transmit, on average over all agents. For unit demand valuations, we show that this number is only $O(1)$ (but $\Theta(\log n)$, if one seeks EF1 allocations instead of MMS allocations), for binary additive valuations we show that it is $\Theta(\log \frac{m}{n})$, and for 2-valued additive valuations we show a lower bound of $\Omega(\frac{m}{n})$.
  For general additive valuations, MMS allocations need not exist. We consider a notion of {\em approximately proportional} (Aprop) allocations, that approximates proportional allocations in two different senses, being both Prop1 (proportional up to one item), and $\frac{n}{2n-1}$-TPS (getting at least a $\frac{n}{2n-1}$ fraction of the {\em truncated proportional share}, and hence also at least a $\frac{n}{2n-1}$ fraction of the MMS). We design randomized protocols that output Aprop allocations, in which the expected average number of bits transmitted per agent is $O(\log m)$. For the stronger notion of MXS ({\em minimum EFX share}) we show a lower bound of $\Omega(\frac{m}{n})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07641v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Uriel Feige</dc:creator>
    </item>
    <item>
      <title>Edge-dominance games on graphs</title>
      <link>https://arxiv.org/abs/2407.07785</link>
      <description>arXiv:2407.07785v1 Announce Type: new 
Abstract: We consider zero-sum games in which players move between adjacent states, where in each pair of adjacent states one state dominates the other. The states in our game can represent positional advantages in physical conflict such as high ground or camouflage, or product characteristics that lend an advantage over competing sellers in a duopoly. We study the equilibria of the game as a function of the topological and geometric properties of the underlying graph. Our main result characterizes the expected payoff of both players starting from any initial position, under the assumption that the graph does not contain certain types of small cycles. This characterization leverages the block-cut tree of the graph, a construction that describes the topology of the biconnected components of the graph. We identify three natural types of (on-path) pure equilibria, and characterize when these equilibria exist under the above assumptions. On the geometric side, we show that strongly connected outerplanar graphs with undirected girth at least 4 always support some of these types of on-path pure equilibria. Finally, we show that a data structure describing all pure equilibria can be efficiently computed for these games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07785v1</guid>
      <category>cs.GT</category>
      <category>math.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farid Arthaud, Edan Orzech, Martin Rinard</dc:creator>
    </item>
    <item>
      <title>Natural Language Mechanisms via Self-Resolution with Foundation Models</title>
      <link>https://arxiv.org/abs/2407.07845</link>
      <description>arXiv:2407.07845v1 Announce Type: new 
Abstract: Practical mechanisms often limit agent reports to constrained formats like trades or orderings, potentially limiting the information agents can express. We propose a novel class of mechanisms that elicit agent reports in natural language and leverage the world-modeling capabilities of large language models (LLMs) to select outcomes and assign payoffs. We identify sufficient conditions for these mechanisms to be incentive-compatible and efficient as the LLM being a good enough world model and a strong inter-agent information over-determination condition. We show situations where these LM-based mechanisms can successfully aggregate information in signal structures on which prediction markets fail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07845v1</guid>
      <category>cs.GT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Della Penna</dc:creator>
    </item>
    <item>
      <title>Nash CoT: Multi-Path Inference with Preference Equilibrium</title>
      <link>https://arxiv.org/abs/2407.07099</link>
      <description>arXiv:2407.07099v1 Announce Type: cross 
Abstract: Chain-of-thought (CoT) prompting has emerged as a powerful technique for enhancing the reasoning capabilities of Large Language Models (LLMs) on complex problems. Among CoT-related studies, self-consistency (Multi-path inference with answer filtering through voting) involves generating multiple reasoning paths using the CoT framework and then selecting the most frequently produced outputs standing out as a concise yet competitive approach. While self-consistency has indeed led to the improvements in LLM inference, the use of multi-path inference also escalates deployment costs. Therefore, maintaining the performance benefits of self-consistency inherited from multi-path inference while reducing the inference costs holds significant value. In this research, we conceptualize language decoding as a preference consensus game, constructing a bi-player gaming system within each local path, and introduce Nash Chain-of-Thought (Nash CoT). Specifically, for a given question, we leverage LLM to autonomously select the contextually relevant template and generate outputs guided by this template, aiming to reach Nash Equilibrium alongside normal generation in each path. This approach allows us to achieve comparable or improved performance compared to self-consistency while using fewer inference paths on various inference tasks, including Arabic reasoning, Commonsense Question answering, and Symbolic inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.07099v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqi Zhang, Cunxiang Wang, Xiong Xiao, Yue Zhang, Donglin Wang</dc:creator>
    </item>
  </channel>
</rss>
