<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 01:55:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Multigrid Monte Carlo Revisited: Theory and Bayesian Inference</title>
      <link>https://arxiv.org/abs/2407.12149</link>
      <description>arXiv:2407.12149v1 Announce Type: new 
Abstract: Gaussian random fields play an important role in many areas of science and engineering. In practice, they are often simulated by sampling from a high-dimensional multivariate normal distribution which arises from the discretisation of a suitable precision operator on a finite grid. Existing methods such as Cholesky factorisation and Gibbs-sampling become prohibitively expensive on fine meshes due to their high computational cost or the fact that they do not explore the probability space efficiently. In this work we revisit the Multigrid Monte Carlo algorithm of Goodman &amp; Sokal (Physical Review D 40.6, 1989), which can overcome these issues. The novelty of our work consists in the application of the method to linear Bayesian settings where the prior is constrained by a finite set of observations. For this, we develop a bespoke random smoother which takes care of the low-rank updates that arise in Bayesian inference. We provide a rigorous analysis of the method based on the link between linear solvers and samplers for multivariate normal distributions, drawing on standard multigrid convergence theory in a finite element setting. In particular, we prove that Multigrid Monte Carlo is algorithmically near-optimal in the limit of the grid-size going to zero. These theoretical results are confirmed by numerical experiments which demonstrate that Multigrid Monte Carlo can be significantly more efficient than alternative methods when applied in a Bayesian setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12149v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoshihito Kazashi, Eike H. M\"uller, Robert Scheichl</dc:creator>
    </item>
    <item>
      <title>Computing $k$-means in mixed precision</title>
      <link>https://arxiv.org/abs/2407.12208</link>
      <description>arXiv:2407.12208v1 Announce Type: new 
Abstract: The $k$-means algorithm is one of the most popular and critical techniques in data mining and machine learning, and it has achieved significant success in numerous science and engineering domains. Computing $k$-means to a global optimum is NP-hard in Euclidean space, yet there are a variety of efficient heuristic algorithms, such as Lloyd's algorithm, that converge to a local optimum with superpolynomial complexity in the worst case. Motivated by the emergence and prominence of mixed precision capabilities in hardware, a current trend is to develop low and mixed precision variants of algorithms in order to improve the runtime and energy consumption. In this paper we study the numerical stability of Lloyd's $k$-means algorithm, and, in particular, we confirm the stability of the widely used distance computation formula. We propose a mixed-precision framework for $k$-means computation and investigate the effects of low-precision distance computation within the framework. Through extensive simulations on various data clustering and image segmentation tasks, we verify the applicability and robustness of the mixed precision $k$-means method. We find that, in $k$-means computation, normalized data is more tolerant to the reduction of precision in the distance computation, while for nonnormalized data more care is needed in the use of reduced precision, mainly to avoid overflow. Our study demonstrates the potential for the use of mixed precision to accelerate the $k$-means computation and offers some insights into other distance-based machine learning methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12208v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erin Carson, Xinye Chen, Xiaobo Liu</dc:creator>
    </item>
    <item>
      <title>Multi evolutional deep neural networks (Multi-EDNN)</title>
      <link>https://arxiv.org/abs/2407.12293</link>
      <description>arXiv:2407.12293v1 Announce Type: new 
Abstract: Evolutional deep neural networks (EDNN) solve partial differential equations (PDEs) by marching the network representation of the solution fields, using the governing equations. Use of a single network to solve coupled PDEs on large domains requires a large number of network parameters and incurs a significant computational cost. We introduce coupled EDNN (C-EDNN) to solve systems of PDEs by using independent networks for each state variable, which are only coupled through the governing equations. We also introduce distributed EDNN (D-EDNN) by spatially partitioning the global domain into several elements and assigning individual EDNNs to each element to solve the local evolution of the PDE. The networks then exchange the solution and fluxes at their interfaces, similar to flux-reconstruction methods, and ensure that the PDE dynamics are accurately preserved between neighboring elements. Together C-EDNN and D-EDNN form the general class of Multi-EDNN methods. We demonstrate these methods with aid of canonical problems including linear advection, the heat equation, and the compressible Navier-Stokes equations in Couette and Taylor-Green flows.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12293v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hadden Kim, Tamer A. Zaki</dc:creator>
    </item>
    <item>
      <title>A Finite Difference Scheme for (2+1)D Cubic-Quintic Nonlinear Schr\"odinger Equations with Nonlinear Damping</title>
      <link>https://arxiv.org/abs/2407.12311</link>
      <description>arXiv:2407.12311v1 Announce Type: new 
Abstract: Solitons of the purely cubic nonlinear Schr\"odinger equation in a space dimension of $n \geq 2$ suffer critical and supercritical collapses. These solitons can be stabilized in a cubic-quintic nonlinear medium. In this paper, we analyze the Crank-Nicolson finite difference scheme for the (2+1)D cubic-quintic nonlinear Schr\"odinger equation with cubic damping. We show that both the discrete solution, in the discrete $L^2$-norm, and discrete energy are bounded. By using appropriate settings and estimations, the existence and the uniqueness of the numerical solution are proved. In addition, the error estimations are established in terms of second order for both space and time in discrete $L^2$-norm and $H^1$-norm. Numerical simulations for the (2+1)D cubic-quintic nonlinear Schr\"odinger equation with cubic damping are conducted to validate the convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12311v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anh Ha Le, Toan T. Huynh, Quan M. Nguyen</dc:creator>
    </item>
    <item>
      <title>Structure-preserving approximation of the Cahn-Hilliard-Biot system</title>
      <link>https://arxiv.org/abs/2407.12349</link>
      <description>arXiv:2407.12349v1 Announce Type: new 
Abstract: In this work, we propose a structure-preserving discretisation for the recently studied Cahn-Hilliard-Biot system using conforming finite elements in space and problem-adapted explicit-implicit Euler time integration. We prove that the scheme preserves the thermodynamic structure, that is, the balance of mass and volumetric fluid content and the energy dissipation balance. The existence of discrete solutions is established under suitable growth conditions. Furthermore, it is shown that the algorithm can be realised as a splitting method, that is, decoupling the Cahn-Hilliard subsystem from the poro-elasticity subsystem, while the first one is nonlinear and the second subsystem is linear. The schemes are illustrated by numerical examples and a convergence test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12349v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Brunk, Marvin Fritz</dc:creator>
    </item>
    <item>
      <title>Intrinsic mixed-dimensional beam-shell-solid couplings in linear Cosserat continua via tangential differential calculus</title>
      <link>https://arxiv.org/abs/2407.12515</link>
      <description>arXiv:2407.12515v1 Announce Type: new 
Abstract: We present an approach to the coupling of mixed-dimensional continua by employing the mathematically enriched linear Cosserat micropolar model. The kinematical reduction of the model to lower dimensional domains leaves its fundamental degrees of freedom intact. Consequently, the degrees of freedom intrinsically agree even at the interface with a domain of a different dimensionality. Thus, this approach circumvents the need for intermediate finite elements or mortar methods. We introduce the derivations of all models of various dimensions using tangential differential calculus. The coupling itself is then achieved by defining a mixed-dimensional action functional with consistent Sobolev trace operators. Finally, we present numerical examples involving a three-dimensional silicone-rubber block reinforced with a curved graphite shell on its lower surface, a three-dimensional silver block reinforced with a graphite plate and beams, and lastly, intersecting silver shells reinforced with graphite beams.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12515v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Adam Sky, Jack S. Hale, Andreas Zilian, St\'ephane P. A. Bordas, Patrizio Neff</dc:creator>
    </item>
    <item>
      <title>Modified Patankar Linear Multistep methods for production-destruction systems</title>
      <link>https://arxiv.org/abs/2407.12540</link>
      <description>arXiv:2407.12540v1 Announce Type: new 
Abstract: Modified Patankar schemes are linearly implicit time integration methods designed to be unconditionally positive and conservative. In the present work we extend the Patankar-type approach to linear multistep methods and prove that the resulting discretizations retain, with no restrictions on the step size, the positivity of the solution and the linear invariant of the continuous-time system. Moreover, we provide results on arbitrarily high order of convergence and we introduce an embedding technique for the Patankar weight denominators to achieve it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12540v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Izzo, Eleonora Messina, Mario Pezzella, Antonia Vecchio</dc:creator>
    </item>
    <item>
      <title>On the global complexity of a derivative-free Levenberg-Marquardt algorithm via orthogonal spherical smoothing</title>
      <link>https://arxiv.org/abs/2407.12542</link>
      <description>arXiv:2407.12542v1 Announce Type: new 
Abstract: In this paper, we propose a derivative-free Levenberg-Marquardt algorithm for nonlinear least squares problems, where the Jacobian matrices are approximated via orthogonal spherical smoothing. It is shown that the gradient models which use the approximate Jacobian matrices are probabilistically first-order accurate, and the high probability complexity bound of the algorithm is also given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12542v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Chen, Jinyan Fan</dc:creator>
    </item>
    <item>
      <title>Serendipity discrete complexes with enhanced regularity</title>
      <link>https://arxiv.org/abs/2407.12625</link>
      <description>arXiv:2407.12625v1 Announce Type: new 
Abstract: In this work we address the problem of finding serendipity versions of approximate de Rham complexes with enhanced regularity. The starting point is a new abstract construction of general scope which, given three complexes linked by extension and reduction maps, generates a fourth complex with cohomology isomorphic to the former three. This construction is used to devise new serendipity versions of rot-rot and Stokes complexes derived in the Discrete de Rham spirit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12625v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniele Di Pietro, Marien Hanot, Marwa Salah</dc:creator>
    </item>
    <item>
      <title>Entropy-Stable Model Reduction of One-Dimensional Hyperbolic Systems using Rational Quadratic Manifolds</title>
      <link>https://arxiv.org/abs/2407.12627</link>
      <description>arXiv:2407.12627v1 Announce Type: new 
Abstract: In this work we propose a novel method to ensure important entropy inequalities are satisfied semi-discretely when constructing reduced order models (ROMs) on nonlinear reduced manifolds. We are in particular interested in ROMs of systems of nonlinear hyperbolic conservation laws. The so-called entropy stability property endows the semi-discrete ROMs with physically admissible behaviour. The method generalizes earlier results on entropy-stable ROMs constructed on linear spaces. The ROM works by evaluating the projected system on a well-chosen approximation of the state that ensures entropy stability. To ensure accuracy of the ROM after this approximation we locally enrich the tangent space of the reduced manifold with important quantities. Using numerical experiments on some well-known equations (the inviscid Burgers equation, shallow water equations and compressible Euler equations) we show the improved structure-preserving properties of our ROM compared to standard approaches and that our approximations have minimal impact on the accuracy of the ROM. We additionally generalize the recently proposed polynomial reduced manifolds to rational polynomial manifolds and show that this leads to an increase in accuracy for our experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12627v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robin Klein, Benjamin Sanderse, Pedro Costa, Rene Pecnik, Ruud Henkes</dc:creator>
    </item>
    <item>
      <title>Computational inverse scattering with internal sources: a reproducing kernel Hilbert space approach</title>
      <link>https://arxiv.org/abs/2407.12656</link>
      <description>arXiv:2407.12656v1 Announce Type: new 
Abstract: We present a method to reconstruct the dielectric susceptibility (scattering potential) of an inhomogeneous scattering medium, based on the solution to the inverse scattering problem with internal sources. We employ the theory of reproducing kernel Hilbert spaces, together with regularization to recover the susceptibility of two- and three-dimensional scattering media. Numerical examples illustrate the effectiveness of the proposed reconstruction method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12656v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yakun Dong, Kamran Sadiq, Otmar Scherzer, John C. Schotland</dc:creator>
    </item>
    <item>
      <title>Time-Domain Iterative Rational Krylov Method</title>
      <link>https://arxiv.org/abs/2407.12670</link>
      <description>arXiv:2407.12670v1 Announce Type: new 
Abstract: The Realization Independent Iterative Rational Krylov Algorithm (TF-IRKA) is a frequency-based data-driven reduced order modeling (DDROM) method that constructs $\mathcal H_2$ optimal DDROMs. However, as the $\mathcal H_2$ optimal approximation theory dictates, TF-IRKA requires repeated sampling of frequency data, that is, values of the system transfer function and its derivative, outside the unit circle. This repeated evaluation of frequency data requires repeated full model computations and may not be feasible. The data-informativity framework for moment matching provides a method for obtaining such frequency data from a single time-domain simulation. However, this framework usually requires solving linear systems with prohibitively ill-conditioned matrices, especially when recovering frequency data from off the unit circle as required for optimality. In this paper, building upon our previous work with the data informativity framework for moment matching, we provide a formula for the nonzero extreme eigenvalues of a symmetric rank-$1$ perturbation to an orthogonal projection, which then leads to an optimal scaling of the aforementioned linear systems. We also establish connections between the underlying dynamical system and conditioning of these linear systems. This analysis then leads to our algorithmic development, time-domain IRKA, which allows us to implement a time-domain variant of TF-IRKA, constructing $\mathcal H_2$ optimal DDROMs from a single time-domain simulation without requiring repeated frequency data evaluations. The numerical examples illustrate the effectiveness of the proposed algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12670v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael S. Ackermann, Serkan Gugercin</dc:creator>
    </item>
    <item>
      <title>Modal Decomposition in Numerical Computation of Eddy Current Transients</title>
      <link>https://arxiv.org/abs/2407.11993</link>
      <description>arXiv:2407.11993v1 Announce Type: cross 
Abstract: A methodology to reduce the computational cost of time domain computations of eddy currents problems is proposed and implemented in a parallel computing environment. It is based on the modal decomposition of the current density and it is applicable even in presence of injected currents into the electrodes of a conducting domain. Using a theta-method integration algorithm, the performances of the the proposed approach are compared against those of a classical method based on the Cholesky factorization, for a case of interest from eddy current nondestructive testing. For this large eddy current problem (number of unknowns greater than 100k, number of time steps of interest equal to 100k) the proposed solution method is shown to be much faster than those based on standard time integration schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11993v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvatore Ventre, Andrea Chiariello, Nicola Isernia, Vincenzo Mottola, Antonello Tamburrino</dc:creator>
    </item>
    <item>
      <title>Random ordinate method for mitigating the ray effect in radiative transport equation simulations</title>
      <link>https://arxiv.org/abs/2407.12527</link>
      <description>arXiv:2407.12527v1 Announce Type: cross 
Abstract: The Discrete Ordinates Method (DOM) is the most widely used velocity discretization method for simulating the radiative transport equation. The ray effect stands as a long-standing drawback of DOM. In benchmark tests displaying the ray effect, we observe low regularity in velocity within the solution. To address this issue, we propose a random ordinate method (ROM) to mitigate the ray effect. Compared with other strategies proposed in the literature for mitigating the ray effect, ROM offers several advantages: 1) the computational cost is comparable to DOM; 2) it is simple and requires minimal changes to existing code based on DOM; 3) it is easily parallelizable and independent of the problem setup. Analytical results are presented for the convergence orders of the error and bias, and numerical tests demonstrate its effectiveness in mitigating the ray effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12527v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lei Li, Min Tang, Yuqi Yang</dc:creator>
    </item>
    <item>
      <title>Dual Complex Adjoint Matrix: Applications in Dual Quaternion Research</title>
      <link>https://arxiv.org/abs/2407.12635</link>
      <description>arXiv:2407.12635v1 Announce Type: cross 
Abstract: Dual quaternions and dual quaternion matrices have garnered widespread applications in robotic research, and its spectral theory has been extensively studied in recent years. This paper introduces the novel concept of the dual complex adjoint matrices for dual quaternion matrices. We delve into exploring the properties of this matrix, utilizing it to study eigenvalues of dual quaternion matrices and defining the concept of standard right eigenvalues. Notably, we leverage the properties of the dual complex adjoint matrix to devise a direct solution to the Hand-Eye calibration problem. Additionally, we apply this matrix to solve dual quaternion linear equations systems, thereby advancing the Rayleigh quotient iteration method for computing eigenvalues of dual quaternion Hermitian matrices, enhancing its computational efficiency. Numerical experiments have validated the correctness of our proposed method in solving the Hand-Eye calibration problem and demonstrated the effectiveness in improving the Rayleigh quotient iteration method, underscoring the promising potential of dual complex adjoint matrices in tackling dual quaternion-related challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12635v1</guid>
      <category>math.RA</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yongjun Chen, Liping Zhang</dc:creator>
    </item>
    <item>
      <title>An Approximation for the 32-point Discrete Fourier Transform</title>
      <link>https://arxiv.org/abs/2407.12708</link>
      <description>arXiv:2407.12708v1 Announce Type: cross 
Abstract: This brief note aims at condensing some results on the 32-point approximate DFT and discussing its arithmetic complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12708v1</guid>
      <category>eess.SP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ME</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. J. Cintra</dc:creator>
    </item>
    <item>
      <title>$d$-dimensional extension of a penalization method for Neumann or Robin boundary conditions: a boundary layer approach and numerical experiments</title>
      <link>https://arxiv.org/abs/2407.12712</link>
      <description>arXiv:2407.12712v1 Announce Type: cross 
Abstract: This paper studies the $d$-dimensional extension of a fictitious domain penalization technique that we previously proposed for Neumann or Robin boundary conditions. We apply Droniou's approach for non-coercive linear elliptic problems to obtain the existence and uniqueness of the solution of the penalized problem, and we derive a boundary layer approach to establish the convergence of the penalization method. The developed boundary layer approach is adapted from the one used for Dirichlet boundary conditions, but in contrast to the latter where coercivity enables a straightforward estimate of the remainders, we reduce the convergence of the penalization method to the existence of suitable supersolutions of a dual problem. These supersolutions are then constructed as approximate solutions of the dual problem using an additional formal boundary layer approach. The proposed approach results in an advection-dominated problem, requiring the use of appropriate numerical methods suitable for singular perturbation problems. Numerical experiments, using upwind finite differences, validate both the convergence rate and the boundary layer thickness, illuminating the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12712v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bouchra Bensiali, Jacques Liandrat</dc:creator>
    </item>
    <item>
      <title>Near-optimal learning of Banach-valued, high-dimensional functions via deep neural networks</title>
      <link>https://arxiv.org/abs/2211.12633</link>
      <description>arXiv:2211.12633v3 Announce Type: replace 
Abstract: The past decade has seen increasing interest in applying Deep Learning (DL) to Computational Science and Engineering (CSE). Driven by impressive results in applications such as computer vision, Uncertainty Quantification (UQ), genetics, simulations and image processing, DL is increasingly supplanting classical algorithms, and seems poised to revolutionize scientific computing. However, DL is not yet well-understood from the standpoint of numerical analysis. Little is known about the efficiency and reliability of DL from the perspectives of stability, robustness, accuracy, and sample complexity. In particular, approximating solutions to parametric PDEs is an objective of UQ for CSE. Training data for such problems is often scarce and corrupted by errors. Moreover, the target function is a possibly infinite-dimensional smooth function taking values in the PDE solution space, generally an infinite-dimensional Banach space. This paper provides arguments for Deep Neural Network (DNN) approximation of such functions, with both known and unknown parametric dependence, that overcome the curse of dimensionality. We establish practical existence theorems that describe classes of DNNs with dimension-independent architecture size and training procedures based on minimizing the (regularized) $\ell^2$-loss which achieve near-optimal algebraic rates of convergence. These results involve key extensions of compressed sensing for Banach-valued recovery and polynomial emulation with DNNs. When approximating solutions of parametric PDEs, our results account for all sources of error, i.e., sampling, optimization, approximation and physical discretization, and allow for training high-fidelity DNN approximations from coarse-grained sample data. Our theoretical results fall into the category of non-intrusive methods, providing a theoretical alternative to classical methods for high-dimensional approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.12633v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ben Adcock, Simone Brugiapaglia, Nick Dexter, Sebastian Moraga</dc:creator>
    </item>
    <item>
      <title>Adaptive analysis-aware defeaturing: the case of Neumann boundary conditions</title>
      <link>https://arxiv.org/abs/2212.05183</link>
      <description>arXiv:2212.05183v2 Announce Type: replace 
Abstract: Removing geometrical details from a complex domain is a classical operation in computer aided design. This procedure simplifies the meshing process, and it enables faster simulations with less memory requirements. However, depending on the partial differential equation that one wants to solve, removing some important geometrical features may greatly impact the solution accuracy. Unfortunately, the effect of geometrical simplification on the accuracy of the problem solution is often neglected or its evaluation is based on engineering expertise, only due to the lack of reliable tools. It is therefore important to have a better understanding of the effect of geometrical model simplification, also called defeaturing, to improve our control on the simulation accuracy along the design and analysis phases. In this work, we consider as a model problem the Poisson equation on a geometry with Neumann features, we consider some finite element discretization of it, and we build an adaptive strategy that is twofold. Firstly, it is able to perform geometrical refinements, that is, to choose at each iteration step which geometrical feature is important to obtain an accurate solution. Secondly, it performs standard mesh refinements; since the geometry changes at each iteration, the algorithm is designed to be used with an immersed method. To drive this adaptive strategy, we introduce an a posteriori estimator of the energy error between the exact solution defined in the exact fully-featured geometry, and the numerical approximation of the solution defined in the defeatured geometry. The reliability of the estimator is proven for very general (potentially trimmed multipatch) geometric configurations, and in particular for IGA with hierarchical B-splines. Finally, numerical experiments are performed to validate the presented theory and to illustrate the capabilities of the proposed adaptive strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.05183v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annalisa Buffa, Ondine Chanon, Rafael V\'azquez</dc:creator>
    </item>
    <item>
      <title>An implicit DG solver for incompressible two-phase flows with an artificial compressibility formulation</title>
      <link>https://arxiv.org/abs/2307.04580</link>
      <description>arXiv:2307.04580v3 Announce Type: replace 
Abstract: We propose an implicit Discontinuous Galerkin (DG) discretization for incompressible two-phase flows using an artificial compressibility formulation. The conservative level set (CLS) method is employed in combination with a reinitialization procedure to capture the moving interface. A projection method based on the L-stable TR-BDF2 method is adopted for the time discretization of the Navier-Stokes equations and of the level set method. Adaptive Mesh Refinement (AMR) is employed to enhance the resolution in correspondence of the interface between the two fluids. The effectiveness of the proposed approach is shown in a number of classical benchmarks. A specific analysis on the influence of different choices of the mixture viscosity is also carried out.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.04580v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Orlando</dc:creator>
    </item>
    <item>
      <title>A Local discontinuous Galerkin method for the Benajamin-Ono equation</title>
      <link>https://arxiv.org/abs/2405.08360</link>
      <description>arXiv:2405.08360v2 Announce Type: replace 
Abstract: The main purpose of this paper is to design a local discontinuous Galerkin (LDG) method for the Benjamin-Ono equation. We analyze the stability and error estimates for the semi-discrete LDG scheme. We prove that the scheme is $L^2$-stable and it converges at a rate $\mathcal{O}(h^{k+1/2})$ for general nonlinear flux. Furthermore, we develop a fully discrete LDG scheme using the four-stage fourth order Runge-Kutta method and ensure the devised scheme is strongly stable in case of linear flux using two-step and three-step stability approach under an appropriate time step constraint. Numerical examples are provided to validate the efficiency and accuracy of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08360v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Mukul Dwivedi, Tanmay Sarkar</dc:creator>
    </item>
    <item>
      <title>Finite-difference least square methods for solving Hamilton-Jacobi equations using neural networks</title>
      <link>https://arxiv.org/abs/2406.10758</link>
      <description>arXiv:2406.10758v3 Announce Type: replace 
Abstract: We present a simple algorithm to approximate the viscosity solution of Hamilton-Jacobi (HJ) equations by means of an artificial deep neural network. The algorithm uses a stochastic gradient descent-based method to minimize the least square principle defined by a monotone, consistent numerical scheme. We analyze the least square principle's critical points and derive conditions that guarantee that any critical point approximates the sought viscosity solution. The use of a deep artificial neural network on a finite difference scheme lifts the restriction of conventional finite difference methods that rely on computing functions on a fixed grid. This feature makes it possible to solve HJ equations posed in higher dimensions where conventional methods are infeasible. We demonstrate the efficacy of our algorithm through numerical studies on various canonical HJ equations across different dimensions, showcasing its potential and versatility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10758v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Esteve-Yag\"ue, Richard Tsai, Alex Massucco</dc:creator>
    </item>
    <item>
      <title>A short proof for the parameter continuation theorem</title>
      <link>https://arxiv.org/abs/2302.14697</link>
      <description>arXiv:2302.14697v5 Announce Type: replace-cross 
Abstract: The Parameter Continuation Theorem is the theoretical foundation for polynomial homotopy continuation, which is one of the main tools in computational algebraic geometry. In this note, we give a short proof using Gr\"obner bases. Our approach gives a method for computing discriminants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14697v5</guid>
      <category>math.AG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Viktoriia Borovik, Paul Breiding</dc:creator>
    </item>
    <item>
      <title>Kinetic based optimization enhanced by genetic dynamics</title>
      <link>https://arxiv.org/abs/2306.09199</link>
      <description>arXiv:2306.09199v2 Announce Type: replace-cross 
Abstract: We propose and analyse a variant of the recently introduced kinetic based optimization method that incorporates ideas like survival-of-the-fittest and mutation strategies well-known from genetic algorithms. Thus, we provide a first attempt to reach out from the class of consensus/kinetic-based algorithms towards genetic metaheuristics. Different generations of genetic algorithms are represented via two species identified with different labels, binary interactions are prescribed on the particle level and then we derive a mean-field approximation in order to analyse the method in terms of convergence. Numerical results underline the feasibility of the approach and show in particular that the genetic dynamics allows to improve the efficiency, of this class of global optimization methods in terms of computational cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09199v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giacomo Albi, Federica Ferrarese, Claudia Totzeck</dc:creator>
    </item>
    <item>
      <title>Enhancing Gaussian Process Surrogates for Optimization and Posterior Approximation via Random Exploration</title>
      <link>https://arxiv.org/abs/2401.17037</link>
      <description>arXiv:2401.17037v2 Announce Type: replace-cross 
Abstract: This paper proposes novel noise-free Bayesian optimization strategies that rely on a random exploration step to enhance the accuracy of Gaussian process surrogate models. The new algorithms retain the ease of implementation of the classical GP-UCB algorithm, but the additional random exploration step accelerates their convergence, nearly achieving the optimal convergence rate. Furthermore, to facilitate Bayesian inference with an intractable likelihood, we propose to utilize optimization iterates for maximum a posteriori estimation to build a Gaussian process surrogate model for the unnormalized log-posterior density. We provide bounds for the Hellinger distance between the true and the approximate posterior distributions in terms of the number of design points. We demonstrate the effectiveness of our Bayesian optimization algorithms in non-convex benchmark objective functions, in a machine learning hyperparameter tuning problem, and in a black-box engineering design problem. The effectiveness of our posterior approximation approach is demonstrated in two Bayesian inference problems for parameters of dynamical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17037v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hwanwoo Kim, Daniel Sanz-Alonso</dc:creator>
    </item>
  </channel>
</rss>
