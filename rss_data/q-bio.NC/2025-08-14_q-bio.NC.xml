<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 01:25:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Perceptual Reality Transformer: Neural Architectures for Simulating Neurological Perception Conditions</title>
      <link>https://arxiv.org/abs/2508.09852</link>
      <description>arXiv:2508.09852v1 Announce Type: new 
Abstract: Neurological conditions affecting visual perception create profound experiential divides between affected individuals and their caregivers, families, and medical professionals. We present the Perceptual Reality Transformer, a comprehensive framework employing six distinct neural architectures to simulate eight neurological perception conditions with scientifically-grounded visual transformations. Our system learns mappings from natural images to condition-specific perceptual states, enabling others to experience approximations of simultanagnosia, prosopagnosia, ADHD attention deficits, visual agnosia, depression-related changes, anxiety tunnel vision, and Alzheimer's memory effects. Through systematic evaluation across ImageNet and CIFAR-10 datasets, we demonstrate that Vision Transformer architectures achieve optimal performance, outperforming traditional CNN and generative approaches. Our work establishes the first systematic benchmark for neurological perception simulation, contributes novel condition-specific perturbation functions grounded in clinical literature, and provides quantitative metrics for evaluating simulation fidelity. The framework has immediate applications in medical education, empathy training, and assistive technology development, while advancing our fundamental understanding of how neural networks can model atypical human perception.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09852v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Baihan Lin</dc:creator>
    </item>
    <item>
      <title>Reinforcement learning in densely recurrent biological networks</title>
      <link>https://arxiv.org/abs/2508.09618</link>
      <description>arXiv:2508.09618v1 Announce Type: cross 
Abstract: Training highly recurrent networks in continuous action spaces is a technical challenge: gradient-based methods suffer from exploding or vanishing gradients, while purely evolutionary searches converge slowly in high-dimensional weight spaces. We introduce a hybrid, derivative-free optimization framework that implements reinforcement learning by coupling global evolutionary exploration with local direct search exploitation. The method, termed ENOMAD (Evolutionary Nonlinear Optimization with Mesh Adaptive Direct search), is benchmarked on a suite of food-foraging tasks instantiated in the fully mapped neural connectome of the nematode \emph{Caenorhabditis elegans}. Crucially, ENOMAD leverages biologically derived weight priors, letting it refine--rather than rebuild--the organism's native circuitry. Two algorithmic variants of the method are introduced, which lead to either small distributed adjustments of many weights, or larger changes on a limited number of weights. Both variants significantly exceed the performance of the untrained connectome (in what can be interpreted as an example of transfer learning) and of existing training strategies. These findings demonstrate that integrating evolutionary search with nonlinear optimization provides an efficient, biologically grounded strategy for specializing natural recurrent networks towards a specified set of tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.09618v1</guid>
      <category>cs.NE</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Miles Walter Churchland, Jordi Garcia-Ojalvo</dc:creator>
    </item>
    <item>
      <title>Representation biases: will we achieve complete understanding by analyzing representations?</title>
      <link>https://arxiv.org/abs/2507.22216</link>
      <description>arXiv:2507.22216v2 Announce Type: replace 
Abstract: A common approach in neuroscience is to study neural representations as a means to understand a system -- increasingly, by relating the neural representations to the internal representations learned by computational models. However, a recent work in machine learning (Lampinen, 2024) shows that learned feature representations may be biased to over-represent certain features, and represent others more weakly and less-consistently. For example, simple (linear) features may be more strongly and more consistently represented than complex (highly nonlinear) features. These biases could pose challenges for achieving full understanding of a system through representational analysis. In this perspective, we illustrate these challenges -- showing how feature representation biases can lead to strongly biased inferences from common analyses like PCA, regression, and RSA. We also present homomorphic encryption as a simple case study of the potential for strong dissociation between patterns of representation and computation. We discuss the implications of these results for representational comparisons between systems, and for neuroscience more generally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22216v2</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Kyle Lampinen, Stephanie C. Y. Chan, Yuxuan Li, Katherine Hermann</dc:creator>
    </item>
    <item>
      <title>Neural correlates of learned categorical perception of visual stimuli with local features</title>
      <link>https://arxiv.org/abs/2508.08922</link>
      <description>arXiv:2508.08922v2 Announce Type: replace 
Abstract: Learning to categorize requires distinguishing category members from non-members by detecting the features that covary with membership. Whether this process can induce changes in perception is still a matter of debate. In prior studies, we reported Learned Categorical Perception (Learned CP) effects in the form of between-category separation and within-category compression in perceived similarity after training subjects to categorize visual stimuli with distributed, holistic features.These effects were correlated with changes in an early, perceptual component of Event Related Potentials (ERPs). Using the same methodology, in this experiment we trained 96 subjects to sort line drawings of fish with local, verbalizable features into two categories by trial and error with corrective feedback. We tested for Learned CP effects and their neural correlates by measuring subjects' pairwise dissimilarity judgments and(ERPs) before and after the training. With the same frequency of trials and feedback,about 40% of the participants succeeded in learning the categories ("learners") while the rest did not ("non-learners"). Learners showed a) significant between-category separation and within-category compression after training compared to before and b) an increase in a late parietal ERP positivity (LPC; 400-600 ms) and an early, occipital positivity (P1; 80-140 ms), correlated with categorization accuracy and degree of Learned CP. These behavioral and neural changes after learning a category, absent in Non Learners, provide further evidence that category learning can modulate perceptual processes, regardless of the nature of the visual features. We complement our experimental results with a neural net model using the same stimuli.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08922v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>F. P\'erez-Gay, T. Sicotte, N. Goulet, X. Kang, S. Harnad</dc:creator>
    </item>
    <item>
      <title>Probing Mechanical Reasoning in Large Vision Language Models</title>
      <link>https://arxiv.org/abs/2410.00318</link>
      <description>arXiv:2410.00318v4 Announce Type: replace-cross 
Abstract: Mechanical reasoning is a hallmark of human intelligence, defined by its ubiquitous yet irreplaceable role in human activities ranging from routine tasks to civil engineering. Embedding machines with mechanical reasoning is therefore an important step towards building human-level artificial intelligence. Here, we leveraged 155 cognitive experiments to test the understanding of system stability, gears and pulley systems, leverage principle, inertia and motion, and fluid mechanics in 26 Vision Language Models (VLMs). Results indicate that VLMs consistently perform worse than humans on all domains, while demonstrate significant difficulty in reasoning about gear systems and fluid mechanics. Notably, their performance on these tasks do not improve as number of parameters increase, suggesting that current attention-based architecture may fail to grasp certain underlying mechanisms required for mechanical reasoning, particularly those pertaining to mental simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00318v4</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 14 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Haoran Sun, Qingying Gao, Haiyun Lyu, Dezhi Luo, Yijiang Li, Hokin Deng</dc:creator>
    </item>
  </channel>
</rss>
