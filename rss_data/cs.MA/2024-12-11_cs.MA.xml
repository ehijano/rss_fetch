<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 12 Dec 2024 02:42:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Investigating social alignment via mirroring in a system of interacting language models</title>
      <link>https://arxiv.org/abs/2412.06834</link>
      <description>arXiv:2412.06834v1 Announce Type: new 
Abstract: Alignment is a social phenomenon wherein individuals share a common goal or perspective. Mirroring, or mimicking the behaviors and opinions of another individual, is one mechanism by which individuals can become aligned. Large scale investigations of the effect of mirroring on alignment have been limited due to the scalability of traditional experimental designs in sociology. In this paper, we introduce a simple computational framework that enables studying the effect of mirroring behavior on alignment in multi-agent systems. We simulate systems of interacting large language models in this framework and characterize overall system behavior and alignment with quantitative measures of agent dynamics. We find that system behavior is strongly influenced by the range of communication of each agent and that these effects are exacerbated by increased rates of mirroring. We discuss the observed simulated system behavior in the context of known human social dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06834v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harvey McGuinness, Tianyu Wang, Carey E. Priebe, Hayden Helm</dc:creator>
    </item>
    <item>
      <title>Incentivized Symbiosis: A Paradigm for Human-Agent Coevolution</title>
      <link>https://arxiv.org/abs/2412.06855</link>
      <description>arXiv:2412.06855v1 Announce Type: new 
Abstract: Cooperation is vital to our survival and progress. Evolutionary game theory offers a lens to understand the structures and incentives that enable cooperation to be a successful strategy. As artificial intelligence agents become integral to human systems, the dynamics of cooperation take on unprecedented significance. Decentralized frameworks like Web3, grounded in transparency, accountability, and trust, offer a foundation for fostering cooperation by establishing enforceable rules and incentives for humans and AI agents. Guided by our Incentivized Symbiosis model, a paradigm aligning human and AI agent goals through bidirectional incentives and mutual adaptation, we investigate mechanisms for embedding cooperation into human-agent coevolution. We conceptualize Incentivized Symbiosis as part of a contemporary moral framework inspired by Web3 principles, encoded in blockchain technology to define and enforce rules, incentives, and consequences for both humans and AI agents. By integrating these principles into the very architecture of human-agent interactions, Web3 ecosystems catalyze an environment ripe for collaborative innovation. Our study traverses several transformative applications of Incentivized Symbiosis, from decentralized finance to governance and cultural adaptation, illustrating how AI agents can coevolve with humans to forge a trajectory of shared, sustainable progress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06855v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomer Jordi Chaffer, Justin Goldston, Gemach D. A. T. A. I</dc:creator>
    </item>
    <item>
      <title>Modeling Speculative Trading Patterns in Token Markets: An Agent-Based Analysis with TokenLab</title>
      <link>https://arxiv.org/abs/2412.07512</link>
      <description>arXiv:2412.07512v1 Announce Type: new 
Abstract: This paper presents the application of Tokenlab, an agent-based modeling framework designed to analyze price dynamics and speculative behavior within token-based economies. By decomposing complex token systems into discrete agent interactions governed by fundamental behavioral rules, Tokenlab simplifies the simulation of otherwise intricate market scenarios. Its core innovation lies in its ability to model a range of speculative strategies and assess their collective influence on token price evolution.
  Through a novel controller mechanism, Tokenlab facilitates the simulation of multiple speculator archetypes and their interactions, thereby providing valuable insights into market sentiment and price formation. This method enables a systematic exploration of how varying degrees of speculative activity and evolving strategies across different market stages shape token price trajectories. Our findings enhance the understanding of speculation in token markets and present a quantitative framework for measuring and interpreting market heat indicators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07512v1</guid>
      <category>cs.MA</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mengjue Wang, Stylianos Kampakis</dc:creator>
    </item>
    <item>
      <title>AdaSociety: An Adaptive Environment with Social Structures for Multi-Agent Decision-Making</title>
      <link>https://arxiv.org/abs/2411.03865</link>
      <description>arXiv:2411.03865v2 Announce Type: replace 
Abstract: Traditional interactive environments limit agents' intelligence growth with fixed tasks. Recently, single-agent environments address this by generating new tasks based on agent actions, enhancing task diversity. We consider the decision-making problem in multi-agent settings, where tasks are further influenced by social connections, affecting rewards and information access. However, existing multi-agent environments lack a combination of adaptive physical surroundings and social connections, hindering the learning of intelligent behaviors. To address this, we introduce AdaSociety, a customizable multi-agent environment featuring expanding state and action spaces, alongside explicit and alterable social structures. As agents progress, the environment adaptively generates new tasks with social structures for agents to undertake. In AdaSociety, we develop three mini-games showcasing distinct social structures and tasks. Initial results demonstrate that specific social structures can promote both individual and collective benefits, though current reinforcement learning and LLM-based algorithms show limited effectiveness in leveraging social structures to enhance performance. Overall, AdaSociety serves as a valuable research platform for exploring intelligence in diverse physical and social settings. The code is available at https://github.com/bigai-ai/AdaSociety.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03865v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yizhe Huang, Xingbo Wang, Hao Liu, Fanqi Kong, Aoyang Qin, Min Tang, Xiaoxi Wang, Song-Chun Zhu, Mingjie Bi, Siyuan Qi, Xue Feng</dc:creator>
    </item>
    <item>
      <title>DCMAC: Demand-aware Customized Multi-Agent Communication via Upper Bound Training</title>
      <link>https://arxiv.org/abs/2409.07127</link>
      <description>arXiv:2409.07127v2 Announce Type: replace-cross 
Abstract: Efficient communication can enhance the overall performance of collaborative multi-agent reinforcement learning. A common approach is to share observations through full communication, leading to significant communication overhead. Existing work attempts to perceive the global state by conducting teammate model based on local information. However, they ignore that the uncertainty generated by prediction may lead to difficult training. To address this problem, we propose a Demand-aware Customized Multi-Agent Communication (DCMAC) protocol, which use an upper bound training to obtain the ideal policy. By utilizing the demand parsing module, agent can interpret the gain of sending local message on teammate, and generate customized messages via compute the correlation between demands and local observation using cross-attention mechanism. Moreover, our method can adapt to the communication resources of agents and accelerate the training progress by appropriating the ideal policy which is trained with joint observation. Experimental results reveal that DCMAC significantly outperforms the baseline algorithms in both unconstrained and communication constrained scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07127v2</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Wed, 11 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongkun Huo, Huateng Zhang, Yixue Hao, Yuanlin Ye, Long Hu, Rui Wang, Min Chen</dc:creator>
    </item>
  </channel>
</rss>
