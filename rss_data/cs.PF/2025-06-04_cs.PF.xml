<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PF</link>
    <description>cs.PF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 01:38:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Energy Efficiency Analysis of Active RIS-enhanced Wireless Network under Power-Sum Constraint</title>
      <link>https://arxiv.org/abs/2506.02823</link>
      <description>arXiv:2506.02823v1 Announce Type: new 
Abstract: Recently, as a green wireless technology, active reconfigurable intelligent surface (RIS) attracts numerous research activities due to its amplifying ability to combat the double-fading effect compared to passive one. How about its energy efficiency (EE) over passive one? Below, the EE of active RIS-aided wireless network in Rayleigh fading channels is analyzed. Using the law of large numbers, EE is derived as a function of five factors: power allocation factor, the number (N) of RIS elements, the total power, the noise variances at RIS and at user. To evaluate each factor's impact, the simple EE function for the concerning factor is given with others fixed. To assess the impact of N on EE, we establish an equation with the EE of active RIS equaling that of passive one, and three methods, bisection, Newton's method, and simulated annealing, are designed to find the roots of this equation. Simulation results show that as N tends to medium-scale or large-scale, the asymptotic performance formula is consistent with the exact EE expression well. As N varies from small-scale to large-scale, the active RIS intersects passive one at some point. When N&lt; N_0, active RIS performs better than passive one in terms of EE. Otherwise, there is a converse conclusion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02823v1</guid>
      <category>cs.PF</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingdie Xin, Yan Wang, Feng Shu, Feng Zhao, Yifan Zhao, Hao Jiang</dc:creator>
    </item>
    <item>
      <title>DistMLIP: A Distributed Inference Platform for Machine Learning Interatomic Potentials</title>
      <link>https://arxiv.org/abs/2506.02023</link>
      <description>arXiv:2506.02023v1 Announce Type: cross 
Abstract: Large-scale atomistic simulations are essential to bridge computational materials and chemistry to realistic materials and drug discovery applications. In the past few years, rapid developments of machine learning interatomic potentials (MLIPs) have offered a solution to scale up quantum mechanical calculations. Parallelizing these interatomic potentials across multiple devices poses a challenging, but promising approach to further extending simulation scales to real-world applications. In this work, we present DistMLIP, an efficient distributed inference platform for MLIPs based on zero-redundancy, graph-level parallelization. In contrast to conventional space-partitioning parallelization, DistMLIP enables efficient MLIP parallelization through graph partitioning, allowing multi-device inference on flexible MLIP model architectures like multi-layer graph neural networks. DistMLIP presents an easy-to-use, flexible, plug-in interface that enables distributed inference of pre-existing MLIPs. We demonstrate DistMLIP on four widely used and state-of-the-art MLIPs: CHGNet, MACE, TensorNet, and eSEN. We show that existing foundational potentials can perform near-million-atom calculations at the scale of a few seconds on 8 GPUs with DistMLIP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02023v1</guid>
      <category>cs.DC</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Kevin Han, Bowen Deng, Amir Barati Farimani, Gerbrand Ceder</dc:creator>
    </item>
    <item>
      <title>Exchangeability in Neural Network Architectures and its Application to Dynamic Pruning</title>
      <link>https://arxiv.org/abs/2506.02210</link>
      <description>arXiv:2506.02210v1 Announce Type: cross 
Abstract: Neural networks (NNs) are equipped with increasingly many parameters and require more and more resource for deployment. Researchers have explored various ways to improve the efficiency of NNs by identifying and reducing the redundancy, such as pruning or quantizing unimportant weights. Symmetry in the NN architectures has been identified by prior work as a possible type of redundancy, but exploiting it for efficient inference is not yet explored. In this work, we formalize the symmetry of parameters and intermediate values in NNs using the statistical property of exchangeablility. We identify that exchangeable values in NN computation may contain overlapping information, leading to redundancy. Exploiting the insight, we derive a principled general dynamic pruning algorithm ExPrune to remove symmetry-induced redundancy on a per-input basis. We also provide an instantiation of ExPrune that performs neuron-level dynamic pruning by predicting negative inputs to ReLU activations. We evaluate ExPrune on two computer vision models, one graph model and one language model. ExPrune provides 10.98--26.3% reduction in FLOPs with negligible accuracy drop and 21.01--39.05% reduction in FLOPs with at most 1% accuracy drop. We also demonstrate that ExPrune composes with static pruning. On models that have been aggressively pruned statically, ExPrune provides additional 10.24--11.11% reduction in FLOPs with negligible accuracy drop and 13.91--14.39% reduction in FLOPs with at most 1% accuracy drop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02210v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator> Pu (Luke),  Yi, Tianlang Chen, Yifan Yang, Sara Achour</dc:creator>
    </item>
    <item>
      <title>Spatially Correlated multi-RIS Communication: The Effect of Inter-Operator Interference</title>
      <link>https://arxiv.org/abs/2506.02666</link>
      <description>arXiv:2506.02666v1 Announce Type: cross 
Abstract: A multi-operator wireless communication system is studied where each operator is equipped with a reconfigurable intelligent surface (RIS) to enhance its communication quality. RISs controlled by different operators affect the system performance of one another due to the inherently rapid phase shift adjustments that occur on an independent basis. The system performance of such a communication scenario is analytically studied for the practical case where spatial correlation occurs at RIS of arbitrary size. The proposed framework is quite general since it is analyzed under Nakagami-$m$ channel fading conditions. Finally, the derived analytical results are verified via numerical and simulation trials as well as some new and useful engineering outcomes are revealed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02666v1</guid>
      <category>cs.IT</category>
      <category>cs.PF</category>
      <category>math.IT</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikolaos I. Miridakis, Panagiotis A. Karkazis</dc:creator>
    </item>
    <item>
      <title>Usability Evaluation of Cloud for HPC Applications</title>
      <link>https://arxiv.org/abs/2506.02709</link>
      <description>arXiv:2506.02709v1 Announce Type: cross 
Abstract: The rise of AI and the economic dominance of cloud computing have created a new nexus of innovation for high performance computing (HPC), which has a long history of driving scientific discovery. In addition to performance needs, scientific workflows increasingly demand capabilities of cloud environments: portability, reproducibility, dynamism, and automation. As converged cloud environments emerge, there is growing need to study their fit for HPC use cases. Here we present a cross-platform usability study that assesses 11 different HPC proxy applications and benchmarks across three clouds (Microsoft Azure, Amazon Web Services, and Google Cloud), six environments, and two compute configurations (CPU and GPU) against on-premises HPC clusters at a major center. We perform scaling tests of applications in all environments up to 28,672 CPUs and 256 GPUs. We present methodology and results to guide future study and provide a foundation to define best practices for running HPC workloads in cloud.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02709v1</guid>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vanessa Sochat, Daniel Milroy, Abhik Sarkar, Aniruddha Marathe</dc:creator>
    </item>
    <item>
      <title>Bayesian Hierarchical Models for Quantitative Estimates for Performance metrics applied to Saddle Search Algorithms</title>
      <link>https://arxiv.org/abs/2505.13621</link>
      <description>arXiv:2505.13621v2 Announce Type: replace-cross 
Abstract: Rigorous performance evaluation is essential for developing robust algorithms for high-throughput computational chemistry. Traditional benchmarking, however, often struggles to account for system-specific variability, making it difficult to form actionable conclusions. We present a Bayesian hierarchical modeling framework that rigorously quantifies performance metrics and their uncertainty, enabling a nuanced comparison of algorithmic strategies. We apply this framework to analyze the Dimer method, comparing Conjugate Gradient (CG) and L-BFGS rotation optimizers, with and without the removal of external rotations, across a benchmark of 500 molecular systems. Our analysis confirms that CG offers higher overall robustness than L-BFGS in this context. While the theoretically-motivated removal of external rotations led to higher computational cost (&gt;40% more energy and force calls) for most systems in this set, our models also reveal a subtle interplay, hinting that this feature may improve the reliability of the L-BFGS optimizer. Rather than identifying a single superior method, our findings support the design of adaptive "chain of methods" workflows. This work showcases how a robust statistical paradigm can move beyond simple performance rankings to inform the intelligent, context-dependent application of computational chemistry methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13621v2</guid>
      <category>physics.chem-ph</category>
      <category>cs.PF</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Goswami (Science Institute and Faculty of Physical Sciences, University of Iceland, Reykjav\'ik, Iceland, Department of Mechanical and Materials Engineering, Queen's University, Kingston, Ontario, Canada)</dc:creator>
    </item>
  </channel>
</rss>
