<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Feb 2026 05:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>End-to-End Differentiable Photon Counting CT</title>
      <link>https://arxiv.org/abs/2602.11497</link>
      <description>arXiv:2602.11497v1 Announce Type: new 
Abstract: Quantitative imaging is an important feature of spectral X-ray and CT systems, especially photon-counting CT (PCCT) imaging systems, which is achieved through material decomposition (MD) using spectral measurements. In this work, we present a novel framework that makes the PCCT imaging chain end-to-end differentiable (differentiable PCCT), with which we can leverage quantitative information in the image domain to enable cross-domain learning and optimization for upstream models. Specifically, the material decomposition from maximum-likelihood estimation (MLE) was made differentiable based on the Implicit Function Theorem and inserted as a layer into the imaging chain for end-to-end optimization. This framework allows for an automatic and adaptive solution of a wide range of imaging tasks, ultimately achieving quantitative imaging through computation rather than manual intervention. The end-to-end training mechanism effectively avoids the need for direct-domain training or supervision from intermediate references as models are trained using quantitative images. We demonstrate its applicability in two representative tasks: correcting detector energy bin drift and training an object scatter correction network using cross-domain reference from quantitative material images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11497v1</guid>
      <category>physics.med-ph</category>
      <category>eess.IV</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sen Wang, Yirong Yang, Jooho Lee, Grant M. Stevens, Adam S. Wang</dc:creator>
    </item>
    <item>
      <title>BSoNet: Deep Learning Solution for Optimizing Image Quality of Portable Backscatter Imaging Systems</title>
      <link>https://arxiv.org/abs/2602.11701</link>
      <description>arXiv:2602.11701v1 Announce Type: cross 
Abstract: Portable backscatter imaging systems (PBI) integrate an X-ray source and detector in a single unit, utilizing Compton scattering photons to rapidly acquire superficial or shallow structural information of an inspected object through single-sided imaging. The application of this technology overcomes the limitations of traditional transmission X-ray detection, offering greater flexibility and portability, making it the preferred tool for the rapid and accurate identification of potential threats in scenarios such as borders, ports, and industrial nondestructive security inspections. However, the image quality is significantly compromised due to the limited number of Compton backscattered photons. The insufficient photon counts result primarily from photon absorption in materials, the pencil-beam scanning design, and short signal sampling times. It therefore yields severe image noise and an extremely low signal-to-noise ratio, greatly reducing the accuracy and reliability of PBI systems. To address these challenges, this paper introduces BSoNet, a novel deep learning-based approach specifically designed to optimize the image quality of PBI systems. The approach significantly enhances image clarity, recognition, and contrast while meeting practical application requirements. It transforms PBI systems into more effective and reliable inspection tools, contributing significantly to strengthening security protection.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11701v1</guid>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linxuan Li, Wenjia Wei, Yunfei Lu, Wenwen Zhang, Yanlong Zhang, Wei Zhao</dc:creator>
    </item>
    <item>
      <title>Temporally resolved aortic 3D shape reconstruction from a limited number of cine 2D MRI slices</title>
      <link>https://arxiv.org/abs/2602.11873</link>
      <description>arXiv:2602.11873v1 Announce Type: cross 
Abstract: Background and Objective: We propose a shape reconstruction framework to generate time-resolved, patient-specific 3D aortic geometries from a limited number of standard cine 2D magnetic resonance imaging (MRI) acquisitions. A statistical shape model of the aorta is coupled with differentiable volumetric mesh optimization to obtain personalized aortic meshes.
  Methods: The statistical shape model was constructed from retrospective data and optimized 2D slice placements along the aortic arch were identified. Cine 2D MRI slices were then acquired in 30 subjects (19 volunteers, 11 aortic stenosis patients). After manual segmentation, time-resolved aortic models were generated via differentiable volumetric mesh optimization to derive vessel shape features, centerline parameters, and radial wall strain. In 10 subjects, additional 4D flow MRI was acquired to compare peak-systolic shapes.
  Results: Anatomically accurate aortic geometries were obtained from as few as six cine 2D MRI slices, achieving a mean +/- standard deviation Dice score of (89.9 +/- 1.6) %, Intersection over Union of (81.7 +/- 2.7) %, Hausdorff distance of (7.3 +/- 3.3) mm, and Chamfer distance of (3.7 +/- 0.6) mm relative to 4D flow MRI. The mean absolute radius error was (0.8 +/- 0.6) mm. Significant age-related differences were observed for all shape features, including radial strain, which decreased progressively ((11.00 +/- 3.11) x 10-2 vs. (3.74 +/- 1.25) x 10-2 vs. (2.89 +/- 0.87) x 10-2 for young, mid-age, and elderly groups).
  Conclusion: The proposed method enables efficient extraction of time-resolved 3D aortic meshes from limited sets of standard cine 2D MRI acquisitions, suitable for computational shape and strain analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.11873v1</guid>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <category>stat.ME</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gloria Wolkerstorfer, Stefano Buoso, Rabea Schlenker, Jochen von Spiczak, Robert Manka, Sebastian Kozerke</dc:creator>
    </item>
    <item>
      <title>Imaging Intravoxel Vessel Size Distribution in the Brain Using Susceptibility Contrast Enhanced MRI</title>
      <link>https://arxiv.org/abs/2503.17600</link>
      <description>arXiv:2503.17600v3 Announce Type: replace 
Abstract: Vascular remodelling is inherent to the pathogenesis of many diseases including cancer, neurodegeneration, fibrosis, hypertension, and diabetes. In this paper, a new susceptibility-contrast based MRI approach is established to analyse intravoxel vessel size distribution (VSD) enabling more comprehensive and quantitative assessment of vascular remodelling than existing clinical imaging modalities. We use segmented vascular structures from light-sheet fluorescence microscopy images of whole rodent brain to simulate gradient echo sampling of free induction decay and spin echo sequence (GESFIDE) and train a deep learning model to predict cerebral blood volume (CBV) and VSD from the simulated GESFIDE signal. The results from ex vivo experiments showed strong correlation (r=0.96) between the true and predicted CBV. Also, high similarity between true and predicted VSDs was observed with mean Bhattacharya Coefficient being 0.92. With further in vivo validation, intravoxel VSD imaging could become a transformative clinical tool for interrogating disease and treatment induced vascular remodelling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.17600v3</guid>
      <category>physics.med-ph</category>
      <category>eess.SP</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Natenael B. Semmineh, Indranil Guha, Deborah Healey, Anagha Chandrasekharan, Jerrold L. Boxerman, C. Chad Quarles</dc:creator>
    </item>
    <item>
      <title>A solution to the mystery of the sub-harmonic series via a linear model of the cochlea</title>
      <link>https://arxiv.org/abs/2509.26395</link>
      <description>arXiv:2509.26395v2 Announce Type: replace-cross 
Abstract: In this paper, we study a simple linear model of the cochlea as a set of vibrating strings. We make hypothesis that the information sent to the auditory cortex is the energy stored in the strings and consider all oscillation modes of the strings. We show the emergence of the sub-harmonic series whose existence was hypothesized in the XVI century to explain the consonance of the minor chord. We additionally show how the nonlinearity of the energy can be used to study the emergence of the combination tone (Tartini's third sound) shedding new light on this long debated subject.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26395v2</guid>
      <category>eess.SP</category>
      <category>math.AP</category>
      <category>physics.bio-ph</category>
      <category>physics.class-ph</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ugo Boscain (SU, CNRS, CaGE, LJLL), Xiangyu Ma (SU, CNRS, CaGE, LJLL), Dario Prandi (L2S, CNRS), Giuseppina Turco (LLF - UMR7110, CNRS, UPCit\'e)</dc:creator>
    </item>
    <item>
      <title>Fully 3D Unrolled Magnetic Resonance Fingerprinting Reconstruction via Staged Pretraining and Implicit Gridding</title>
      <link>https://arxiv.org/abs/2601.17143</link>
      <description>arXiv:2601.17143v2 Announce Type: replace-cross 
Abstract: Magnetic Resonance Fingerprinting (MRF) enables fast quantitative imaging, yet reconstructing high-resolution 3D data remains computationally demanding. Non-Cartesian reconstructions require repeated non-uniform FFTs, and the commonly used Locally Low Rank (LLR) prior adds computational overhead and becomes insufficient at high accelerations. Learned 3D priors could address these limitations, but training them at scale is challenging due to memory and runtime demands. We propose SPUR-iG, a fully 3D deep unrolled subspace reconstruction framework that integrates efficient data consistency with a progressive training strategy. Data consistency leverages implicit GROG, which grids non-Cartesian data onto a Cartesian grid with an implicitly learned kernel, enabling FFT-based updates with minimal artifacts. Training proceeds in three stages: (1) pretraining a denoiser with extensive data augmentation, (2) greedy per-iteration unrolled training, and (3) final fine-tuning with gradient checkpointing. Together, these stages make large-scale 3D unrolled learning feasible within a reasonable compute budget. On a large in vivo dataset with retrospective undersampling, SPUR-iG improves subspace coefficient maps quality and quantitative accuracy at 1-mm isotropic resolution compared with LLR and a hybrid 2D/3D unrolled baseline. Whole-brain reconstructions complete in under 15-seconds, with up to $\times$111 speedup for 2-minute acquisitions. Notably, $T_1$ maps with our method from 30-second scans achieve accuracy on par with or exceeding LLR reconstructions from 2-minute scans. Overall, the framework improves both accuracy and speed in large-scale 3D MRF reconstruction, enabling efficient and reliable accelerated quantitative imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17143v2</guid>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 13 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonatan Urman, Mark Nishimura, Daniel Abraham, Xiaozhi Cao, Kawin Setsompop</dc:creator>
    </item>
  </channel>
</rss>
