<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 22 Aug 2024 01:39:15 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 21 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Near-Orthogonal Overlay Communications in LoS Channel Enabled by Novel OAM Beams without Central Energy Voids: An Experimental Study</title>
      <link>https://arxiv.org/abs/2408.10222</link>
      <description>arXiv:2408.10222v1 Announce Type: new 
Abstract: This paper introduces a groundbreaking Line-of-Sight (LoS) Multiple-Input Multiple-Output (MIMO) communication architecture leveraging non-traditional Orbital Angular Momentum (OAM) beams. Challenging the conventional paradigm of hollow-emitting OAM beams, this study presents an innovative OAM transmitter design that produces directional OAM beams without central energy voids, aligning their radiation patterns with those of conventional planar wave horn antennas. Within the main lobe of these antennas, the phase variation characteristics inherent to OAM beams are ingeniously maintained, linking different OAM modes to the linear wavefront variation gradients, thereby reducing channel correlation in LoS scenarios and significantly augmenting the channel capacity of LoS-MIMO frameworks. Empirical validations conducted through a meticulously designed LoS-MIMO experimental platform reveal significant improvements in channel correlation coefficients, communication stability, and Bit Error Rate (BER) compared to systems utilizing traditional planar wave antennas. The experiment results underscore the potential of the novel OAM-based system to improve current LoS-MIMO communication protocols, and offer both academic and engineering guidance for the construction of practical communication infrastructures. Beyond its immediate contributions, this paper underscores a pivotal shift in the field of communications, pointing out that traditional communication algorithms have primarily focused on baseband signal processing while often overlooking the electromagnetic characteristics of the physical world.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10222v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufei Zhao, Xiaoyan Ma, Yong Liang Guan, Yile Liu, Afkar Mohamed Ismail, Xiaobei Liu, Siew Yam Yeo, Chau Yuen</dc:creator>
    </item>
    <item>
      <title>ECG Unveiled: Analysis of Client Re-identification Risks in Real-World ECG Datasets</title>
      <link>https://arxiv.org/abs/2408.10228</link>
      <description>arXiv:2408.10228v1 Announce Type: new 
Abstract: While ECG data is crucial for diagnosing and monitoring heart conditions, it also contains unique biometric information that poses significant privacy risks. Existing ECG re-identification studies rely on exhaustive analysis of numerous deep learning features, confining to ad-hoc explainability towards clinicians decision making. In this work, we delve into explainability of ECG re-identification risks using transparent machine learning models. We use SHapley Additive exPlanations (SHAP) analysis to identify and explain the key features contributing to re-identification risks. We conduct an empirical analysis of identity re-identification risks using ECG data from five diverse real-world datasets, encompassing 223 participants. By employing transparent machine learning models, we reveal the diversity among different ECG features in contributing towards re-identification of individuals with an accuracy of 0.76 for gender, 0.67 for age group, and 0.82 for participant ID re-identification. Our approach provides valuable insights for clinical experts and guides the development of effective privacy-preserving mechanisms. Further, our findings emphasize the necessity for robust privacy measures in real-world health applications and offer detailed, actionable insights for enhancing data anonymization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10228v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyu Wang, Anil Kanduri, Seyed Amir Hossein Aqajari, Salar Jafarlou, Sanaz R. Mousavi, Pasi Liljeberg, Shaista Malik, Amir M. Rahmani</dc:creator>
    </item>
    <item>
      <title>Multi-Source EEG Emotion Recognition via Dynamic Contrastive Domain Adaptation</title>
      <link>https://arxiv.org/abs/2408.10235</link>
      <description>arXiv:2408.10235v1 Announce Type: new 
Abstract: Electroencephalography (EEG) provides reliable indications of human cognition and mental states. Accurate emotion recognition from EEG remains challenging due to signal variations among individuals and across measurement sessions. To address these challenges, we introduce a multi-source dynamic contrastive domain adaptation method (MS-DCDA), which models coarse-grained inter-domain and fine-grained intra-class adaptations through a multi-branch contrastive neural network and contrastive sub-domain discrepancy learning. Our model leverages domain knowledge from each individual source and a complementary source ensemble and uses dynamically weighted learning to achieve an optimal tradeoff between domain transferability and discriminability. The proposed MS-DCDA model was evaluated using the SEED and SEED-IV datasets, achieving respectively the highest mean accuracies of $90.84\%$ and $78.49\%$ in cross-subject experiments as well as $95.82\%$ and $82.25\%$ in cross-session experiments. Our model outperforms several alternative domain adaptation methods in recognition accuracy, inter-class margin, and intra-class compactness. Our study also suggests greater emotional sensitivity in the frontal and parietal brain lobes, providing insights for mental health interventions, personalized medicine, and development of preventive strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10235v1</guid>
      <category>eess.SP</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yun Xiao, Yimeng Zhang, Xiaopeng Peng, Shuzheng Han, Xia Zheng, Dingyi Fang, Xiaojiang Chen</dc:creator>
    </item>
    <item>
      <title>Timely Communication from Sensors for Wireless Networked Control in Cloud-Based Digital Twins</title>
      <link>https://arxiv.org/abs/2408.10241</link>
      <description>arXiv:2408.10241v1 Announce Type: new 
Abstract: We consider a Wireless Networked Control System (WNCS) where sensors provide observations to build a DT model of the underlying system dynamics. The focus is on control, scheduling, and resource allocation for sensory observation to ensure timely delivery to the DT model deployed in the cloud. \phuc{Timely and relevant information, as characterized by optimized data acquisition policy and low latency, are instrumental in ensuring that the DT model can accurately estimate and predict system states. However, optimizing closed-loop control with DT and acquiring data for efficient state estimation and control computing pose a non-trivial problem given the limited network resources, partial state vector information, and measurement errors encountered at distributed sensing agents.} To address this, we propose the \emph{Age-of-Loop REinforcement learning and Variational Extended Kalman filter with Robust Belief (AoL-REVERB)}, which leverages an uncertainty-control reinforcement learning solution combined with an algorithm based on Value of Information (VoI) for performing optimal control and selecting the most informative sensors to satisfy the prediction accuracy of DT. Numerical results demonstrate that the DT platform can offer satisfactory performance while halving the communication overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10241v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Van-Phuc Bui, Shashi Raj Pandey, Pedro M. de Sant Ana, Beatriz Soret, Petar Popovski</dc:creator>
    </item>
    <item>
      <title>Stream-Based Ground Segmentation for Real-Time LiDAR Point Cloud Processing on FPGA</title>
      <link>https://arxiv.org/abs/2408.10410</link>
      <description>arXiv:2408.10410v1 Announce Type: new 
Abstract: This paper presents a novel and fast approach for ground plane segmentation in a LiDAR point cloud, specifically optimized for processing speed and hardware efficiency on FPGA hardware platforms. Our approach leverages a channel-based segmentation method with an advanced angular data repair technique and a cross-eight-way flood-fill algorithm. This innovative approach significantly reduces the number of iterations while ensuring the high accuracy of the segmented ground plane, which makes the stream-based hardware implementation possible.
  To validate the proposed approach, we conducted extensive experiments on the SemanticKITTI dataset. We introduced a bird's-eye view (BEV) evaluation metric tailored for the area representation of LiDAR segmentation tasks. Our method demonstrated superior performance in terms of BEV areas when compared to the existing approaches. Moreover, we presented an optimized hardware architecture targeted on a Zynq-7000 FPGA, compatible with LiDARs of various channel densities, i.e., 32, 64, and 128 channels. Our FPGA implementation operating at 160 MHz significantly outperforms the traditional computing platforms, which is 12 to 25 times faster than the CPU-based solutions and up to 6 times faster than the GPU-based solution, in addition to the benefit of low power consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10410v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Zhang, Zhanhong Huang, Garcia Gonzalez Antony, Witek Jachimczyk, Xinming Huang</dc:creator>
    </item>
    <item>
      <title>On the Security of Directional Modulation via Time Modulated Arrays Using OFDM Waveforms</title>
      <link>https://arxiv.org/abs/2408.10522</link>
      <description>arXiv:2408.10522v1 Announce Type: new 
Abstract: In this paper, we investigate how secure the TMA OFDM system is, by looking at the transmitted signal from an the viewpoint of eavesdropper. First, we propose a novel, low-complexity scheme via which the eavesdropper could defy the scrambling in the received signal and recover the transmitted symbols. We show that the symbols which the eavesdropper sees along the OFDM subcarriers are linear mixtures of the source symbols, where the mixing coefficients are unknown to the eavesdropper. Independent component analysis (ICA) could be used to obtain the mixing matrix but there would be permutation and scaling ambiguities. We show that these ambiguities can be resolved by leveraging the structure of the mixing matrix and the characteristics of the TMA OFDM system. In particular, we construct a k-nearest neighbors (KNN)-based algorithm that exploits jointly the Toeplitz structure of the mixing matrix, knowledge of data constellation, and the rules for designing the TMA ON-OFF pattern to resolve the ambiguities. In general, resolving the ambiguities and recovering the symbols requires long data. Specifically for the case of the constant modulus symbols, we propose a modified ICA approach, namely the constant-modulus ICA (CMICA), that provides a good estimate of the mixing matrix using a small number of received samples. We also propose measures which the TMA could undertake in order to defend the scrambling. Simulation results are presented to demonstrate the effectiveness, efficiency and robustness of our scrambling defying and defending schemes. Complete abstract please see in the paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10522v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihao Tao, Athina Petropulu</dc:creator>
    </item>
    <item>
      <title>Near-Field Multiuser Communications Aided by Movable Antennas</title>
      <link>https://arxiv.org/abs/2408.10552</link>
      <description>arXiv:2408.10552v1 Announce Type: new 
Abstract: This letter investigates movable antenna (MA)-aided downlink (DL) multiuser communication systems under the near-field channel condition, in which both the base station (BS) and the users are equipped with MAs to fully exploit the degrees of freedom (DoFs) in antenna position optimization by leveraging the wireless channel variation in spatial regions of large size. The objective is to minimize the transmit power by jointly optimizing the beamformers and the MA positions while satisfying the minimum-achievable-rate requirement for each user. We propose a two-loop dynamic neighborhood pruning particle swarm optimization (DNPPSO) algorithm that significantly reduces computational complexity while effectively maintaining the performance of the standard particle swarm optimization (PSO) algorithm. Simulation results validate the effectiveness and advantages of the proposed scheme in power-saving for multiuser communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10552v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingze Ding, Lipeng Zhu, Zijian Zhou, Bingli Jiao, Rui Zhang</dc:creator>
    </item>
    <item>
      <title>How to Perform Distributed Precoding to Wirelessly Power Shelf Labels: Signal Processing and Measurements</title>
      <link>https://arxiv.org/abs/2408.10611</link>
      <description>arXiv:2408.10611v1 Announce Type: new 
Abstract: Wireless power transfer (WPT) has garnered increasing attention due to its potential to eliminate device-side batteries. With the advent of (distributed) multiple-input multiple-output (MIMO), radio frequency (RF) WPT has become feasible over extended distances. This study focuses on optimizing the energy delivery to Energy Receivers (ERs) while minimizing system total transmit power. Rather than continuous power delivery, we optimize the precoding weights within specified time slots to meet the energy requirements of the ERs. Both unsynchronized (non-coherent) and synchronized (coherent) systems are evaluated. Our analysis indicates that augmenting the number of antennas and transitioning from an unsynchronized to asynchronized full phase-coherent system substantially enhances system performance. This optimization ensures precise energy delivery, reducing overshoots and overall energy consumption. Experimental validation was conducted using a testbed with84 antennas, validating the trends observed in our numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10611v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gilles Callebaut, Jarne Van Mulders, Bert Cox, Liesbet Van der Perre, Lieven De Strycker, Fran\c{c}ois Rottenberg</dc:creator>
    </item>
    <item>
      <title>A Novel Signal Detection Method for Photon-Counting Communications with Nonlinear Distortion Effects</title>
      <link>https://arxiv.org/abs/2408.10800</link>
      <description>arXiv:2408.10800v1 Announce Type: new 
Abstract: This paper proposes a method for estimating and detecting optical signals in practical photon-counting receivers. There are two important aspects of non-perfect photon-counting receivers, namely, (i) dead time which results in blocking loss, and (ii) non-photon-number-resolving, which leads to counting loss during the gate-ON interval. These factors introduce nonlinear distortion to the detected photon counts. The detected photon counts depend not only on the optical intensity but also on the signal waveform, and obey a Poisson binomial process. Using the discrete Fourier transform characteristic function (DFT-CF) method, we derive the probability mass function (PMF) of the detected photon counts. Furthermore, unlike conventional methods that assume an ideal rectangle wave, we propose a novel signal estimation and decision method applicable to arbitrary waveform. We demonstrate that the proposed method achieves superior error performance compared to conventional methods. The proposed algorithm has the potential to become an essential signal processing tool for photon-counting receivers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10800v1</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Chen Wang, Zhiyong Xu, Jingyuan Wang, Jianhua Li, Weifeng Mou, Huatao Zhu, Jiyong Zhao, Yang Su, Yimin Wang, Ailin Qi</dc:creator>
    </item>
    <item>
      <title>Deep Learning-based Classification of Dementia using Image Representation of Subcortical Signals</title>
      <link>https://arxiv.org/abs/2408.10816</link>
      <description>arXiv:2408.10816v1 Announce Type: new 
Abstract: Dementia is a neurological syndrome marked by cognitive decline. Alzheimer's disease (AD) and Frontotemporal dementia (FTD) are the common forms of dementia, each with distinct progression patterns. EEG, a non-invasive tool for recording brain activity, has shown potential in distinguishing AD from FTD and mild cognitive impairment (MCI). Previous studies have utilized various EEG features, such as subband power and connectivity patterns to differentiate these conditions. However, artifacts in EEG signals can obscure crucial information, necessitating advanced signal processing techniques. This study aims to develop a deep learning-based classification system for dementia by analyzing scout time-series signals from deep brain regions, specifically the hippocampus, amygdala, and thalamus. The study utilizes scout time series extracted via the standardized low-resolution brain electromagnetic tomography (sLORETA) technique. The time series is converted to image representations using continuous wavelet transform (CWT) and fed as input to deep learning models. Two high-density EEG datasets are utilized to check for the efficacy of the proposed method: the online BrainLat dataset (comprising AD, FTD, and healthy controls (HC)) and the in-house IITD-AIIA dataset (including subjects with AD, MCI, and HC). Different classification strategies and classifier combinations have been utilized for the accurate mapping of classes on both datasets. The best results were achieved by using a product of probabilities from classifiers for left and right subcortical regions in conjunction with the DenseNet model architecture. It yields accuracies of 94.17$\%$ and 77.72$\%$ on the BrainLat and IITD-AIIA datasets, respectively. This highlights the potential of this approach for early and accurate differentiation of neurodegenerative disorders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10816v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shivani Ranjan, Ayush Tripathi, Harshal Shende, Robin Badal, Amit Kumar, Pramod Yadav, Deepak Joshi, Lalan Kumar</dc:creator>
    </item>
    <item>
      <title>Self-Play Ensemble Q-learning enabled Resource Allocation for Network Slicing</title>
      <link>https://arxiv.org/abs/2408.10376</link>
      <description>arXiv:2408.10376v1 Announce Type: cross 
Abstract: In 5G networks, network slicing has emerged as a pivotal paradigm to address diverse user demands and service requirements. To meet the requirements, reinforcement learning (RL) algorithms have been utilized widely, but this method has the problem of overestimation and exploration-exploitation trade-offs. To tackle these problems, this paper explores the application of self-play ensemble Q-learning, an extended version of the RL-based technique. Self-play ensemble Q-learning utilizes multiple Q-tables with various exploration-exploitation rates leading to different observations for choosing the most suitable action for each state. Moreover, through self-play, each model endeavors to enhance its performance compared to its previous iterations, boosting system efficiency, and decreasing the effect of overestimation. For performance evaluation, we consider three RL-based algorithms; self-play ensemble Q-learning, double Q-learning, and Q-learning, and compare their performance under different network traffic. Through simulations, we demonstrate the effectiveness of self-play ensemble Q-learning in meeting the diverse demands within 21.92% in latency, 24.22% in throughput, and 23.63\% in packet drop rate in comparison with the baseline methods. Furthermore, we evaluate the robustness of self-play ensemble Q-learning and double Q-learning in situations where one of the Q-tables is affected by a malicious user. Our results depicted that the self-play ensemble Q-learning method is more robust against adversarial users and prevents a noticeable drop in system performance, mitigating the impact of users manipulating policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10376v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shavbo Salehi, Pedro Enrique Iturria-Rivera, Medhat Elsayed, Majid Bavand, Raimundas Gaigalas, Yigit Ozcan, Melike Erol-Kantarci</dc:creator>
    </item>
    <item>
      <title>Parallel Processing of Point Cloud Ground Segmentation for Mechanical and Solid-State LiDARs</title>
      <link>https://arxiv.org/abs/2408.10404</link>
      <description>arXiv:2408.10404v1 Announce Type: cross 
Abstract: In this study, we introduce a novel parallel processing framework for real-time point cloud ground segmentation on FPGA platforms, aimed at adapting LiDAR algorithms to the evolving landscape from mechanical to solid-state LiDAR (SSL) technologies. Focusing on the ground segmentation task, we explore parallel processing techniques on existing approaches and adapt them to real-world SSL data handling. We validated frame-segmentation based parallel processing methods using point-based, voxel-based, and range-image-based ground segmentation approaches on the SemanticKITTI dataset based on mechanical LiDAR. The results revealed the superior performance and robustness of the range-image method, especially in its resilience to slicing. Further, utilizing a custom dataset from our self-built Camera-SSLSS equipment, we examined regular SSL data frames and validated the effectiveness of our parallel approach for SSL sensor. Additionally, our pioneering implementation of range-image ground segmentation on FPGA for SSL sensors demonstrated significant processing speed improvements and resource efficiency, achieving processing rates up to 50.3 times faster than conventional CPU setups. These findings underscore the potential of parallel processing strategies to significantly enhance LiDAR technologies for advanced perception tasks in autonomous systems. Post-publication, both the data and the code will be made available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10404v1</guid>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Zhang, Zhanhong Huang, Garcia Gonzalez Antony, Witek Jachimczyk, Xinming Huang</dc:creator>
    </item>
    <item>
      <title>Parkinson's Disease Classification via EEG: All You Need is a Single Convolutional Layer</title>
      <link>https://arxiv.org/abs/2408.10457</link>
      <description>arXiv:2408.10457v1 Announce Type: cross 
Abstract: In this work, we introduce LightCNN, a minimalist Convolutional Neural Network (CNN) architecture designed for Parkinson's disease (PD) classification using EEG data. LightCNN's strength lies in its simplicity, utilizing just a single convolutional layer. Embracing Leonardo da Vinci's principle that "simplicity is the ultimate sophistication," LightCNN demonstrates that complexity is not required to achieve outstanding results. We benchmarked LightCNN against several state-of-the-art deep learning models known for their effectiveness in EEG-based PD classification. Remarkably, LightCNN outperformed all these complex architectures, with a 2.3% improvement in recall, a 4.6% increase in precision, a 0.1% edge in AUC, a 4% boost in F1-score, and a 3.3% higher accuracy compared to the closest competitor. Furthermore, LightCNN identifies known pathological brain rhythms associated with PD and effectively captures clinically relevant neurophysiological changes in EEG. Its simplicity and interpretability make it ideal for deployment in resource-constrained environments, such as mobile or embedded systems for EEG analysis. In conclusion, LightCNN represents a significant step forward in efficient EEG-based PD classification, demonstrating that a well-designed, lightweight model can achieve superior performance over more complex architectures. This work underscores the potential for minimalist models to meet the needs of modern healthcare applications, particularly where resources are limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10457v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Fahim Anjum</dc:creator>
    </item>
    <item>
      <title>Generative Diffusion Models for High Dimensional Channel Estimation</title>
      <link>https://arxiv.org/abs/2408.10501</link>
      <description>arXiv:2408.10501v1 Announce Type: cross 
Abstract: Along with the prosperity of generative artificial intelligence (AI), its potential for solving conventional challenges in wireless communications has also surfaced. Inspired by this trend, we investigate the application of the advanced diffusion models (DMs), a representative class of generative AI models, to high dimensional wireless channel estimation. By capturing the structure of multiple-input multiple-output (MIMO) wireless channels via a deep generative prior encoded by DMs, we develop a novel posterior inference method for channel reconstruction. We further adapt the proposed method to recover channel information from low-resolution quantized measurements. Additionally, to enhance the over-the-air viability, we integrate the DM with the unsupervised Stein's unbiased risk estimator to enable learning from noisy observations and circumvent the requirements for ground truth channel data that is hardly available in practice. Results reveal that the proposed estimator achieves high-fidelity channel recovery while reducing estimation latency by a factor of 10 compared to state-of-the-art schemes, facilitating real-time implementation. Moreover, our method outperforms existing estimators while reducing the pilot overhead by half, showcasing its scalability to ultra-massive antenna arrays.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10501v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingyu Zhou, Le Liang, Jing Zhang, Peiwen Jiang, Yong Li, Shi Jin</dc:creator>
    </item>
    <item>
      <title>Performance Analysis of Physical Layer Security: From Far-Field to Near-Field</title>
      <link>https://arxiv.org/abs/2408.10706</link>
      <description>arXiv:2408.10706v1 Announce Type: cross 
Abstract: The secrecy performance in both near-field and far-field communications is analyzed using two fundamental metrics: the secrecy capacity under a power constraint and the minimum power requirement to achieve a specified secrecy rate target. 1) For the secrecy capacity, a closed-form expression is derived under a discrete-time memoryless setup. This expression is further analyzed under several far-field and near-field channel models, and the capacity scaling law is revealed by assuming an infinitely large transmit array and an infinitely high power. A novel concept of "depth of insecurity" is proposed to evaluate the secrecy performance achieved by near-field beamfocusing. It is demonstrated that increasing the number of transmit antennas reduces this depth and thus improves the secrecy performance. 2) Regarding the minimum required power, a closed-form expression is derived and analyzed within far-field and near-field scenarios. Asymptotic analyses are performed by setting the number of transmit antennas to infinity to unveil the power scaling law. Numerical results are provided to demonstrate that: i) compared to far-field communications, near-field communications expand the areas where secure transmission is feasible, specifically when the eavesdropper is located in the same direction as the intended receiver; ii) as the number of transmit antennas increases, neither the secrecy capacity nor the minimum required power scales or vanishes unboundedly, adhering to the principle of energy conservation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10706v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Boqun Zhao, Chongjun Ouyang, Xingqi Zhang, Yuanwei Liu</dc:creator>
    </item>
    <item>
      <title>Mid-Band Extra Large-Scale MIMO System: Channel Modeling and Performance Analysis</title>
      <link>https://arxiv.org/abs/2408.10737</link>
      <description>arXiv:2408.10737v1 Announce Type: cross 
Abstract: In pursuit of enhanced quality of service and higher transmission rates, communication within the mid-band spectrum, such as bands in the 6-15 GHz range, combined with extra large-scale multiple-input multiple-output (XL-MIMO), is considered a potential enabler for future communication systems. However, the characteristics introduced by mid-band XL-MIMO systems pose challenges for channel modeling and performance analysis. In this paper, we first analyze the potential characteristics of mid-band MIMO channels. Then, an analytical channel model incorporating novel channel characteristics is proposed, based on a review of classical analytical channel models. This model is convenient for theoretical analysis and compatible with other analytical channel models. Subsequently, based on the proposed channel model, we analyze key metrics of wireless communication, including the ergodic spectral efficiency (SE) and outage probability (OP) of MIMO maximal-ratio combining systems. Specifically, we derive closed-form approximations and performance bounds for two typical scenarios, aiming to illustrate the influence of mid-band XL-MIMO systems. Finally, comparisons between systems under different practical configurations are carried out through simulations. The theoretical analysis and simulations demonstrate that mid-band XL-MIMO systems excel in SE and OP due to the increased array elements, moderate large-scale fading, and enlarged transmission bandwidth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10737v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Tian, Yu Han, Xiao Li, Shi Jin, Chao-Kai Wen</dc:creator>
    </item>
    <item>
      <title>Hardware Implementation of Projection-Aggregation Decoders for Reed-Muller Codes</title>
      <link>https://arxiv.org/abs/2408.10850</link>
      <description>arXiv:2408.10850v1 Announce Type: cross 
Abstract: This paper presents the hardware implementation of two variants of projection-aggregation-based decoding of Reed-Muller (RM) codes, namely unique projection aggregation (UPA) and collapsed projection aggregation (CPA). Our study focuses on introducing hardware architectures for both UPA and CPA. Through thorough analysis and experimentation, we observe that the hardware implementation of UPA exhibits superior resource usage and reduced energy consumption compared to CPA for the vanilla IPA decoder. This finding underscores a critical insight: software optimizations, in isolation, may not necessarily translate into hardware cost-effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10850v1</guid>
      <category>cs.AR</category>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marzieh Hashemipour-Nazari, Andrea Nardi-Dei, Kees Goossens, Alexios Balatsoukas-Stimming</dc:creator>
    </item>
    <item>
      <title>CrossFi: A Cross Domain Wi-Fi Sensing Framework Based on Siamese Network</title>
      <link>https://arxiv.org/abs/2408.10919</link>
      <description>arXiv:2408.10919v2 Announce Type: cross 
Abstract: In recent years, Wi-Fi sensing has garnered significant attention due to its numerous benefits, such as privacy protection, low cost, and penetration ability. Extensive research has been conducted in this field, focusing on areas such as gesture recognition, people identification, and fall detection. However, many data-driven methods encounter challenges related to domain shift, where the model fails to perform well in environments different from the training data. One major factor contributing to this issue is the limited availability of Wi-Fi sensing datasets, which makes models learn excessive irrelevant information and over-fit to the training set. Unfortunately, collecting large-scale Wi-Fi sensing datasets across diverse scenarios is a challenging task. To address this problem, we propose CrossFi, a siamese network-based approach that excels in both in-domain scenario and cross-domain scenario, including few-shot, zero-shot scenarios, and even works in few-shot new-class scenario where testing set contains new categories. The core component of CrossFi is a sample-similarity calculation network called CSi-Net, which improves the structure of the siamese network by using an attention mechanism to capture similarity information, instead of simply calculating the distance or cosine similarity. Based on it, we develop an extra Weight-Net that can generate a template for each class, so that our CrossFi can work in different scenarios. Experimental results demonstrate that our CrossFi achieves state-of-the-art performance across various scenarios. In gesture recognition task, our CrossFi achieves an accuracy of 98.17% in in-domain scenario, 91.72% in one-shot cross-domain scenario, 64.81% in zero-shot cross-domain scenario, and 84.75% in one-shot new-class scenario. To facilitate future research, we will release the code for our model upon publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.10919v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Zhao, Tingwei Chen, Zhijie Cai, Xiaoyang Li, Hang Li, Qimei Chen, Guangxu Zhu</dc:creator>
    </item>
    <item>
      <title>EMORF/S: EM-Based Outlier-Robust Filtering and Smoothing With Correlated Measurement Noise</title>
      <link>https://arxiv.org/abs/2307.02163</link>
      <description>arXiv:2307.02163v2 Announce Type: replace 
Abstract: In this article, we consider the problem of outlier-robust state estimation where the measurement noise can be correlated. Outliers in data arise due to many reasons like sensor malfunctioning, environmental behaviors, communication glitches, etc. Moreover, noise correlation emerges in several real-world applications e.g. sensor networks, radar data, GPS-based systems, etc. We consider these effects in system modeling which is subsequently used for inference. We employ the Expectation-Maximization (EM) framework to derive both outlier-resilient filtering and smoothing methods, suitable for online and offline estimation respectively. The standard Gaussian filtering and the Gaussian Rauch-Tung-Striebel (RTS) smoothing results are leveraged to devise the estimators. In addition, Bayesian Cramer-Rao Bounds (BCRBs) for a filter and a smoother which can perfectly detect and reject outliers are presented. These serve as useful theoretical benchmarks to gauge the error performance of different estimators. Lastly, different numerical experiments, for an illustrative target tracking application, are carried out that indicate performance gains compared to similarly engineered state-of-the-art outlier-rejecting state estimators. The advantages are in terms of simpler implementation, enhanced estimation quality, and competitive computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.02163v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aamir Hussain Chughtai, Muhammad Tahir, Momin Uppal</dc:creator>
    </item>
    <item>
      <title>Accelerating Innovation in 6G Research: Real-Time Capable SDR System Architecture for Rapid Prototyping</title>
      <link>https://arxiv.org/abs/2402.06520</link>
      <description>arXiv:2402.06520v5 Announce Type: replace 
Abstract: The upcoming 3GPP global mobile communication standard 6G strives to push the technological limits of radio frequency (RF) communication even further than its predecessors: Sum data rates beyond 100 Gbit/s, RF bandwidths above 1 GHz per link, and sub-millisecond latency necessitate very high performance development tools. We propose a new SDR firmware and software architecture designed explicitly to meet these challenging requirements. It relies on Ethernet and commercial off-the-shelf network and server components to maximize flexibility and to reduce costs. We analyze state-of-the-art solutions (USRP X440 and other RFSoC-based systems), derive architectural design goals, explain resulting design decision in detail, and exemplify our architecture's implementation on the XCZU48DR RFSoC. Finally, we validate its performance via measurements and outline how the architecture surpasses the state-of-the-art with respect to sustained RF recording, while maintaining high Ethernet bandwidth efficiency. Building a 6G integrated sensing and communication (ISAC) example, we demonstrate its real-time and rapid application development capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06520v5</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maximilian Engelhardt, Sebastian Giehl, Michael Schubert, Alexander Ihlow, Christian Schneider, Alexander Ebert, Markus Landmann, Giovanni Del Galdo, Carsten Andrich</dc:creator>
    </item>
    <item>
      <title>Single-BS Simultaneous Environment Sensing and UE Localization without LoS Path by Exploiting Near-Field Scatterers</title>
      <link>https://arxiv.org/abs/2407.20536</link>
      <description>arXiv:2407.20536v2 Announce Type: replace 
Abstract: As the mobile communication network evolves over the past few decades, localizing user equipment (UE) has become an important network service. While localization in line-of-sight (LoS) scenarios has reached a level of maturity, it is known that in far-field scenarios without a LoS path nor any prior information about the scatterers, accurately localizing the UE is impossible. In this letter, we show that this becomes possible if there are scatterers in the near-field region of the base station (BS) antenna arrays. Specifically, by exploiting the additional distance sensing capability of extremely large-scale antenna arrays (XL-arrays) provided by near-field effects, we propose a novel method that simultaneously performs environment sensing and non-line-of-sight (NLoS) UE localization using one single BS. In the proposed method, the BS leverages the near-field characteristics of XL-arrays to directly estimate the locations of the near-field scatterers with array signal processing, which then serves as virtual anchors for UE localization. Then, the propagation delay for each path is estimated and the position of the UE is obtained based on the positions of scatterers and the path delays. Simulation results demonstrate that the proposed method achieves superior accuracy and robustness with similar complexity compared with benchmark methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20536v2</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhiwen Zhou, Zhiqiang Xiao, Yong Zeng</dc:creator>
    </item>
    <item>
      <title>Spectrum Prediction With Deep 3D Pyramid Vision Transformer Learning</title>
      <link>https://arxiv.org/abs/2408.06870</link>
      <description>arXiv:2408.06870v3 Announce Type: replace 
Abstract: In this paper, we propose a deep learning (DL)-based task-driven spectrum prediction framework, named DeepSPred. The DeepSPred comprises a feature encoder and a task predictor, where the encoder extracts spectrum usage pattern features, and the predictor configures different networks according to the task requirements to predict future spectrum. Based on the Deep- SPred, we first propose a novel 3D spectrum prediction method combining a flow processing strategy with 3D vision Transformer (ViT, i.e., Swin) and a pyramid to serve possible applications such as spectrum monitoring task, named 3D-SwinSTB. 3D-SwinSTB unique 3D Patch Merging ViT-to-3D ViT Patch Expanding and pyramid designs help the model accurately learn the potential correlation of the evolution of the spectrogram over time. Then, we propose a novel spectrum occupancy rate (SOR) method by redesigning a predictor consisting exclusively of 3D convolutional and linear layers to serve possible applications such as dynamic spectrum access (DSA) task, named 3D-SwinLinear. Unlike the 3D-SwinSTB output spectrogram, 3D-SwinLinear projects the spectrogram directly as the SOR. Finally, we employ transfer learning (TL) to ensure the applicability of our two methods to diverse spectrum services. The results show that our 3D-SwinSTB outperforms recent benchmarks by more than 5%, while our 3D-SwinLinear achieves a 90% accuracy, with a performance improvement exceeding 10%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.06870v3</guid>
      <category>eess.SP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangliang Pan, Qihui Wu, Bo Zhou, Jie Li, Wei Wang, Guoru Ding, David K. Y. Yau</dc:creator>
    </item>
    <item>
      <title>SPEED: Scalable Preprocessing of EEG Data for Self-Supervised Learning</title>
      <link>https://arxiv.org/abs/2408.08065</link>
      <description>arXiv:2408.08065v2 Announce Type: replace 
Abstract: Electroencephalography (EEG) research typically focuses on tasks with narrowly defined objectives, but recent studies are expanding into the use of unlabeled data within larger models, aiming for a broader range of applications. This addresses a critical challenge in EEG research. For example, Kostas et al. (2021) show that self-supervised learning (SSL) outperforms traditional supervised methods. Given the high noise levels in EEG data, we argue that further improvements are possible with additional preprocessing. Current preprocessing methods often fail to efficiently manage the large data volumes required for SSL, due to their lack of optimization, reliance on subjective manual corrections, and validation processes or inflexible protocols that limit SSL. We propose a Python-based EEG preprocessing pipeline optimized for self-supervised learning, designed to efficiently process large-scale data. This optimization not only stabilizes self-supervised training but also enhances performance on downstream tasks compared to training with raw data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.08065v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anders Gj{\o}lbye, Lina Skerath, William Lehn-Schi{\o}ler, Nicolas Langer, Lars Kai Hansen</dc:creator>
    </item>
    <item>
      <title>Limited Communications Distributed Optimization via Deep Unfolded Distributed ADMM</title>
      <link>https://arxiv.org/abs/2309.14353</link>
      <description>arXiv:2309.14353v2 Announce Type: replace-cross 
Abstract: Distributed optimization is a fundamental framework for collaborative inference and decision making in decentralized multi-agent systems. The operation is modeled as the joint minimization of a shared objective which typically depends on observations gathered locally by each agent. Distributed optimization algorithms, such as the common D-ADMM, tackle this task by iteratively combining local computations and message exchanges. One of the main challenges associated with distributed optimization, and particularly with D-ADMM, is that it requires a large number of communications, i.e., messages exchanged between the agents, to reach consensus. This can make D-ADMM costly in power, latency, and channel resources. In this work we propose unfolded D-ADMM, which follows the emerging deep unfolding methodology to enable D-ADMM to operate reliably with a predefined and small number of messages exchanged by each agent. Unfolded D-ADMM fully preserves the operation of D-ADMM, while leveraging data to tune the hyperparameters of each iteration of the algorithm. These hyperparameters can either be agent-specific, aiming at achieving the best performance within a fixed number of iterations over a given network, or shared among the agents, allowing to learn to distributedly optimize over different networks. For both settings, our unfolded D-ADMM operates with limited communications, while preserving the interpretability and flexibility of the original D-ADMM algorithm. We specialize unfolded D-ADMM for two representative settings: a distributed estimation task, considering a sparse recovery setup, and a distributed learning scenario, where multiple agents collaborate in learning a machine learning model. Our numerical results demonstrate that the proposed approach dramatically reduces the number of communications utilized by D-ADMM, without compromising on its performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14353v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yoav Noah, Nir Shlezinger</dc:creator>
    </item>
    <item>
      <title>Generative AI for Space-Air-Ground Integrated Networks</title>
      <link>https://arxiv.org/abs/2311.06523</link>
      <description>arXiv:2311.06523v2 Announce Type: replace-cross 
Abstract: Recently, generative AI technologies have emerged as a significant advancement in artificial intelligence field, renowned for their language and image generation capabilities. Meantime, space-air-ground integrated network (SAGIN) is an integral part of future B5G/6G for achieving ubiquitous connectivity. Inspired by this, this article explores an integration of generative AI in SAGIN, focusing on potential applications and case study. We first provide a comprehensive review of SAGIN and generative AI models, highlighting their capabilities and opportunities of their integration. Benefiting from generative AI's ability to generate useful data and facilitate advanced decision-making processes, it can be applied to various scenarios of SAGIN. Accordingly, we present a concise survey on their integration, including channel modeling and channel state information (CSI) estimation, joint air-space-ground resource allocation, intelligent network deployment, semantic communications, image extraction and processing, security and privacy enhancement. Next, we propose a framework that utilizes a Generative Diffusion Model (GDM) to construct channel information map to enhance quality of service for SAGIN. Simulation results demonstrate the effectiveness of the proposed framework. Finally, we discuss potential research directions for generative AI-enabled SAGIN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06523v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruichen Zhang, Hongyang Du, Dusit Niyato, Jiawen Kang, Zehui Xiong, Abbas Jamalipour, Ping Zhang, Dong In Kim</dc:creator>
    </item>
    <item>
      <title>Robust MRI Reconstruction by Smoothed Unrolling (SMUG)</title>
      <link>https://arxiv.org/abs/2312.07784</link>
      <description>arXiv:2312.07784v2 Announce Type: replace-cross 
Abstract: As the popularity of deep learning (DL) in the field of magnetic resonance imaging (MRI) continues to rise, recent research has indicated that DL-based MRI reconstruction models might be excessively sensitive to minor input disturbances, including worst-case additive perturbations. This sensitivity often leads to unstable, aliased images. This raises the question of how to devise DL techniques for MRI reconstruction that can be robust to train-test variations. To address this problem, we propose a novel image reconstruction framework, termed Smoothed Unrolling (SMUG), which advances a deep unrolling-based MRI reconstruction model using a randomized smoothing (RS)-based robust learning approach. RS, which improves the tolerance of a model against input noises, has been widely used in the design of adversarial defense approaches for image classification tasks. Yet, we find that the conventional design that applies RS to the entire DL-based MRI model is ineffective. In this paper, we show that SMUG and its variants address the above issue by customizing the RS process based on the unrolling architecture of a DL-based MRI reconstruction model. Compared to the vanilla RS approach, we show that SMUG improves the robustness of MRI reconstruction with respect to a diverse set of instability sources, including worst-case and random noise perturbations to input measurements, varying measurement sampling rates, and different numbers of unrolling steps. Furthermore, we theoretically analyze the robustness of our method in the presence of perturbations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.07784v2</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shijun Liang, Van Hoang Minh Nguyen, Jinghan Jia, Ismail Alkhouri, Sijia Liu, Saiprasad Ravishankar</dc:creator>
    </item>
    <item>
      <title>A Convex-Nonconvex Framework for Enhancing Minimization Induced Penalties</title>
      <link>https://arxiv.org/abs/2407.14819</link>
      <description>arXiv:2407.14819v2 Announce Type: replace-cross 
Abstract: This paper presents a novel framework for nonconvex enhancement of minimization induced (MI) penalties while preserving the overall convexity of associated regularization models. MI penalties enable the adaptation to certain signal structures via minimization, but often underestimate significant components owing to convexity. To overcome this shortcoming, we design a generalized Moreau enhanced minimization induced (GME-MI) penalty by subtracting from the MI penalty its generalized Moreau envelope. While the proposed GME-MI penalty is nonconvex in general, we derive an overall convexity condition for the GME-MI regularized least-squares model. Moreover, we present a proximal splitting algorithm with guaranteed convergence to a globally optimal solution of the GME-MI model under the overall convexity condition. Numerical examples illustrate the effectiveness of the proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14819v2</guid>
      <category>math.OC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hiroki Kuroda</dc:creator>
    </item>
  </channel>
</rss>
