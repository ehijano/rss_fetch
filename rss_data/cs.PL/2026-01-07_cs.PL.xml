<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 Jan 2026 02:34:25 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Backwards Data-Flow Analysis using Prophecy Variable in the BuildIt System</title>
      <link>https://arxiv.org/abs/2601.02653</link>
      <description>arXiv:2601.02653v1 Announce Type: new 
Abstract: Many program transformations and optimizations require information about the future behavior of the program. A standard way to obtain this information is to build an intermediate program representation, then use a backwards program analysis to propagate relevant information against the flow of control back to the transformation/optimization site. We instead propose to use prophecy variables, which predict information about the future execution of the program, to enable such transformations and optimizations. We implement prophecy variables in BuildIt, a lightweight domain specific language implementation system. BuildIt uses staged compilation to implement high performance domain specific languages embedded within a standard general purpose programming language (C++). The BuildIt first phase uses standard C++ program execution to generate optimized C, C++, and CUDA second phase code. This approach enables BuildIt to eliminate programming language implementation components such as parsers and intermediate representations, delivering a dramatic decrease in the engineering effort required to implement domain specific languages. The combination of prophecy variables and repeated forward program execution enables BuildIt to extend this approach to include transformations and optimizations that require information about the future execution of the program without backwards analyses and without the engineering overhead associated with implementing these analyses. We formalize the use of prophecy variables for this purpose, discuss the implementation of prophecy variables and repeated execution in BuildIt, and present experimental results for BuildIt computations that benefit from optimizations enabled by the information that prophecy variables provide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02653v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajay Brahmakshatriya, Saman Amarasinghe, Martin Rinard</dc:creator>
    </item>
    <item>
      <title>Compressed code: the hidden effects of quantization and distillation on programming tokens</title>
      <link>https://arxiv.org/abs/2601.02563</link>
      <description>arXiv:2601.02563v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have demonstrated exceptional code generation capabilities, yet their token-level mechanisms remain underexplored, particularly in compressed models. Through systematic analysis of programming language token representations, we characterize how programming languages are encoded in LLM tokenizers by analyzing their vocabulary distribution and keyword coverage patterns. We introduce a novel cold-start probability analysis method that provides insights into model behavior without requiring explicit prompts. Additionally, we present a comprehensive evaluation of how different model optimization techniques - including quantization, distillation, model scaling, and task-specific fine-tuning - affect token-level representations and code generation quality. Our experiments, supported by comprehensive probability distribution analysis and evaluation metrics, reveal critical insights into token-level behavior and provide empirically-validated guidelines for maintaining code generation quality under various optimization constraints. These findings advance both theoretical understanding of LLM code generation and practical implementation of optimized models in production environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02563v1</guid>
      <category>cs.SE</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viacheslav Siniaev, Iaroslav Chelombitko, Aleksey Komissarov</dc:creator>
    </item>
    <item>
      <title>Proceedings 16th International Workshop on Graph Computation Models</title>
      <link>https://arxiv.org/abs/2601.03249</link>
      <description>arXiv:2601.03249v1 Announce Type: cross 
Abstract: This volume contains the post-proceedings of the Sixteenth International Workshop on Graph Computation Models (GCM 2025). The workshops took place in Koblenz, Germany on June 10 as part of STAF (Software Technologies: Applications and Foundations).  
  Graphs are common mathematical structures that are visual and intuitive. They constitute a natural and seamless way for system modeling in science, engineering, and beyond, including computer science, biology, and business process modeling. Graph computation models constitute a class of very high-level models where graphs are first-class citizens. The aim of the International GCM Workshop series is to bring together researchers interested in all aspects of computation models based on graphs and graph transformation. It promotes the cross-fertilizing exchange of ideas and experiences among senior and young researchers from the different communities interested in the foundations, applications, and implementations of graph computation models and related areas. </description>
      <guid isPermaLink="false">oai:arXiv.org:2601.03249v1</guid>
      <category>cs.LO</category>
      <category>cs.FL</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.440</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 440, 2026</arxiv:journal_reference>
      <dc:creator>Leen Lambers (Brandenburg University of Technology Cottbus-Senftenberg), Oszk\'ar Semer\'ath (Budapest University of Technology,Economics)</dc:creator>
    </item>
    <item>
      <title>Asynchronous Global Protocols, Precisely: Full Proofs</title>
      <link>https://arxiv.org/abs/2505.17676</link>
      <description>arXiv:2505.17676v2 Announce Type: replace 
Abstract: Asynchronous multiparty session types are a type-based framework which ensure the compatibility of components in a distributed system by checking compliance against a specified global protocol. We propose a top-down approach, starting with the global protocol which is then projected into a set of local specifications. Next, we use an asynchronous refinement relation, precise asynchronous multiparty subtyping, to enable local specifications to be optimised by permuting actions within individual asynchronous components. This supports local reasoning, as each component can be independently developed and refined in isolation, before being integrated into a larger system. We show that this methodology guarantees both type soundness and liveness of the collection of optimised components. In this article, we first propose new operational semantics of global protocols which capture sound optimisations in the context of asynchronous message-passing. Next we define an asynchronous association between global protocols and a set of optimised local types. Thirdly, we prove, for the first time, the correctness of the most expressive endpoint projection in the literature, coinductive full merging projection. We then show the main theorems of this article: soundness and completeness of the operational correspondence of the asynchronous association. As a consequence, the association acts as an invariant that can be used to transfer key theorems from the bottom-up system to the top-down system. In particular, we used this to prove type soundness, session-fidelity, deadlock-freedom and liveness of the collection of optimised endpoints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.17676v2</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kai Pischke, Jake Masters, Nobuko Yoshida</dc:creator>
    </item>
    <item>
      <title>Deciding Serializability in Network Systems</title>
      <link>https://arxiv.org/abs/2601.02251</link>
      <description>arXiv:2601.02251v2 Announce Type: replace-cross 
Abstract: We present the SER modeling language for automatically verifying serializability of concurrent programs, i.e., whether every concurrent execution of the program is equivalent to some serial execution. SER programs are suitably restricted to make this problem decidable, while still allowing for an unbounded number of concurrent threads of execution, each potentially running for an unbounded number of steps. Building on prior theoretical results, we give the first automated end-to-end decision procedure that either proves serializability by producing a checkable certificate, or refutes it by producing a counterexample trace. We also present a network-system abstraction to which SER programs compile. Our decision procedure then reduces serializability in this setting to a Petri net reachability query. Furthermore, in order to scale, we curtail the search space via multiple optimizations, including Petri net slicing, semilinear-set compression, and Presburger-formula manipulation. We extensively evaluate our framework and show that, despite the theoretical hardness of the problem, it can successfully handle various models of real-world programs, including stateful firewalls, BGP routers, and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02251v2</guid>
      <category>cs.FL</category>
      <category>cs.DC</category>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <pubDate>Wed, 07 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guy Amir, Mark Barbone, Nicolas Amat, Jules Jacobs</dc:creator>
    </item>
  </channel>
</rss>
