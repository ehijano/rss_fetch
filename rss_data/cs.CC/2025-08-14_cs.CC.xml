<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 15 Aug 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On Kernelization with Access to NP-Oracles</title>
      <link>https://arxiv.org/abs/2508.10550</link>
      <description>arXiv:2508.10550v1 Announce Type: new 
Abstract: Kernelization is the standard framework to analyze preprocessing routines mathematically. Here, in terms of efficiency, we demand the preprocessing routine to run in time polynomial in the input size. However, today, various NP-complete problems are already solved very fast in practice; in particular, SAT-solvers and ILP-solvers have become extremely powerful and used frequently. Still, this fails to capture the wide variety of computational problems that lie at higher levels of the polynomial hierarchy. Thus, for such problems, it is natural to relax the definition of kernelization to permit the preprocessing routine to make polynomially many calls to a SAT-solver, rather than run, entirely, in polynomial time.
  Our conceptual contribution is the introduction of a new notion of a kernel that harnesses the power of SAT-solvers for preprocessing purposes, and which we term a P^NP-Kernel. Technically, we investigate various facets of this notion, by proving both positive and negative results, including a lower-bounds framework to reason about the negative results. Here, we consider both satisfiability and graph problems. Additionally, we present a meta-theorem for so-called "discovery problems". This work falls into a long line of research on extensions of the concept of kernelization, including lossy kernels [Lokshtanov et al., STOC '17], dynamic kernels [Alman et al., ACM TALG '20], counting kernels [Lokshtanov et al., ICTS '24], and streaming kernels [Fafianie and Kratsch, MFCS '14].</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10550v1</guid>
      <category>cs.CC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Molter, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Deciding Whether a C-Q Channel Preserves a Bit is QCMA-Complete</title>
      <link>https://arxiv.org/abs/2508.10664</link>
      <description>arXiv:2508.10664v1 Announce Type: cross 
Abstract: We prove that deciding whether a classical-quantum (C-Q) channel can exactly preserve a single classical bit is QCMA-complete. This "bit-preservation" problem is a special case of orthogonality-constrained optimization tasks over C-Q channels, in which one seeks orthogonal input states whose outputs have small or large Hilbert-Schmidt overlap after passing through the channel. Both problems can be cast as biquadratic optimization with orthogonality constraints. Our main technical contribution uses tools from matrix analysis to give a complete characterization of the optimal witnesses: computational basis states for the minimum, and |+&gt;, |-&gt; over a single basis pair for the maximum. Using this characterization, we give concise proofs of QCMA-completeness for both problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10664v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>math.OA</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiera Hutton, Arthur Mehta, Andrej Vukovic</dc:creator>
    </item>
    <item>
      <title>PAC codes with Bounded-Complexity Sequential Decoding: Pareto Distribution and Code Design</title>
      <link>https://arxiv.org/abs/2412.06072</link>
      <description>arXiv:2412.06072v2 Announce Type: replace-cross 
Abstract: Recently, a novel variation of polar codes known as polarization-adjusted convolutional (PAC) codes has been introduced by Ar{\i}kan. These codes significantly outperform conventional polar and convolutional codes, particularly for short codeword lengths, and are shown to operate very close to the optimal bounds. It has also been shown that if the rate profile of PAC codes does not adhere to certain polarized cutoff rate constraints, the computation complexity for their sequential decoding grows exponentially. In this paper, we address the converse problem, demonstrating that if the rate profile of a PAC code follows the polarized cutoff rate constraints, the required computations for its sequential decoding can be bounded with a distribution that follows a Pareto distribution. This serves as a guideline for the rate-profile design of PAC codes. For a high-rate PAC\,$(1024,899)$ code, simulation results show that the PAC code with Fano decoder, when constructed based on the polarized cutoff rate constraints, achieves a coding gain of more than $0.75$ dB at a frame error rate (FER) of $10^{-5}$ compared to the state-of-the-art 5G polar and LDPC codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.06072v2</guid>
      <category>cs.IT</category>
      <category>cs.CC</category>
      <category>math.IT</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mohsen Moradi, Hessam Mahdavifar</dc:creator>
    </item>
    <item>
      <title>Structures preserved by primitive actions of $S_\omega$</title>
      <link>https://arxiv.org/abs/2501.03789</link>
      <description>arXiv:2501.03789v3 Announce Type: replace-cross 
Abstract: We present a dichotomy for structures $A$ that are preserved by primitive actions of $S_{\omega} = \text{Sym}({\mathbb N})$: such a structure primitively positively constructs all finite structures and the constraint satisfaction problem is NP-complete, or the constraint satisfaction problem for $A$ is in P. To prove our result, we study the first-order reducts of the Johnson graph $J(k)$, for $k \geq 2$, whose automorphism group $G$ equals the action of $\text{Sym}({\mathbb N})$ on the set $V$ of $k$-element subsets of $\mathbb N$. We use the fact that $J(k)$ has a finitely bounded homogeneous Ramsey expansion and that $G$ is a maximal closed subgroup of $\text{Sym}(V)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03789v3</guid>
      <category>math.LO</category>
      <category>cs.CC</category>
      <pubDate>Fri, 15 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Manuel Bodirsky, Bertalan Bodor</dc:creator>
    </item>
  </channel>
</rss>
