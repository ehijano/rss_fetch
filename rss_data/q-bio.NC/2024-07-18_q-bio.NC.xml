<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 01:56:31 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>AI-Driven Bio-Silicon Intelligence System: Integrating Hybrid Systems, Biocomputing, Neural Networks, and Machine Learning, for Advanced Neurotechnology</title>
      <link>https://arxiv.org/abs/2407.11939</link>
      <description>arXiv:2407.11939v2 Announce Type: replace 
Abstract: We present the Bio-Silicon Intelligence System (BSIS), an innovative hybrid platform that integrates biological neural networks with silicon-based computing. The BSIS employs carbon nanotube-coated electrodes to interface rat brains with computational systems, enabling high-fidelity neural interfacing and bidirectional communication through self-organizing systems in both biological and silicon forms. Our system leverages both analogue and digital AI theory, incorporating concepts from chaos theory, dynamical systems theory, physics, and quantum mechanics. Neural signals are read through the FreeEEG32 board and BrainFlow software, then features are extracted and mapped to game actions by tracking feature changes in continuous data. Metadata is encoded into both analogue and digital brain stimulation signals at the microvolt level using our proprietary software. The system employs a dual signaling approach for training the rat brain, incorporating a reward solution and human-inaudible distress sounds. This paper details the design, functionality, and technical specifications of the BSIS, highlighting its interdisciplinary approach and advanced technological integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11939v2</guid>
      <category>q-bio.NC</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vincent Jorgsson, Raghav Kumar, Mustaf Ahmed, Maxx Yung, Aryaman Pattnayak, Georg Weidlich, Maria Michailidou, Sri Pradhyumna Sridhar, Vaishnav Varma, Arun Ram Ponnambalam</dc:creator>
    </item>
    <item>
      <title>Searching for long time scales without fine tuning</title>
      <link>https://arxiv.org/abs/2008.11674</link>
      <description>arXiv:2008.11674v2 Announce Type: replace-cross 
Abstract: Most of animal and human behavior occurs on time scales much longer than the response times of individual neurons. In many cases it is plausible that these long time scales emerge from the recurrent dynamics of electrical activity in networks of neurons. In linear models, time scales are set by the eigenvalues of a dynamical matrix whose elements measure the strengths of synaptic connections between neurons. It is not clear to what extent these matrix elements need to be tuned in order to generate long time scales; in some cases, one needs not just a single long time scale but a whole range. Starting from the simplest case of random symmetric connections, we combine maximum entropy and random matrix theory methods to construct ensembles of networks, exploring the constraints required for long time scales to become generic. We argue that a single long time scale can emerge generically from realistic constraints, but a full spectrum of slow modes requires more tuning. Langevin dynamics that will generate patterns of synaptic connections drawn from these ensembles involve a combination of Hebbian learning and activity-dependent synaptic scaling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2008.11674v2</guid>
      <category>physics.bio-ph</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaowen Chen, William Bialek</dc:creator>
    </item>
  </channel>
</rss>
