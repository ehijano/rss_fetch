<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 08 May 2025 04:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Graphical Global Optimization Framework for Parameter Estimation of Statistical Models with Nonconvex Regularization Functions</title>
      <link>https://arxiv.org/abs/2505.03899</link>
      <description>arXiv:2505.03899v1 Announce Type: new 
Abstract: Optimization problems with norm-bounding constraints arise in a variety of applications, including portfolio optimization, machine learning, and feature selection. A common approach to these problems involves relaxing the norm constraint via Lagrangian relaxation, transforming it into a regularization term in the objective function. A particularly challenging class includes the zero-norm function, which promotes sparsity in statistical parameter estimation. Most existing exact methods for solving these problems introduce binary variables and artificial bounds to reformulate them as higher-dimensional mixed-integer programs, solvable by standard solvers. Other exact approaches exploit specific structural properties of the objective, making them difficult to generalize across different problem types. Alternative methods employ nonconvex penalties with favorable statistical characteristics, but these are typically addressed using heuristic or local optimization techniques due to their structural complexity. In this paper, we propose a novel graph-based method to globally solve optimization problems involving generalized norm-bounding constraints. Our approach encompasses standard $\ell_p$-norms for $p \in [0, \infty)$ and nonconvex penalties such as SCAD and MCP. We leverage decision diagrams to construct strong convex relaxations directly in the original variable space, eliminating the need for auxiliary variables or artificial bounds. Integrated into a spatial branch-and-cut framework, our method guarantees convergence to the global optimum. We demonstrate its effectiveness through preliminary computational experiments on benchmark sparse linear regression problems involving complex nonconvex penalties, which are not tractable using existing global optimization techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03899v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>Proceedings of The 28th International Conference on Artificial Intelligence and Statistics (AISTATS), 2025, PMLR 258:3484-3492</arxiv:journal_reference>
      <dc:creator>Danial Davarnia, Mohammadreza Kiaghadi</dc:creator>
    </item>
    <item>
      <title>Model-Targeted Data Poisoning Attacks against ITS Applications with Provable Convergence</title>
      <link>https://arxiv.org/abs/2505.03966</link>
      <description>arXiv:2505.03966v1 Announce Type: new 
Abstract: The growing reliance of intelligent systems on data makes the systems vulnerable to data poisoning attacks. Such attacks could compromise machine learning or deep learning models by disrupting the input data. Previous studies on data poisoning attacks are subject to specific assumptions, and limited attention is given to learning models with general (equality and inequality) constraints or lacking differentiability. Such learning models are common in practice, especially in Intelligent Transportation Systems (ITS) that involve physical or domain knowledge as specific model constraints. Motivated by ITS applications, this paper formulates a model-target data poisoning attack as a bi-level optimization problem with a constrained lower-level problem, aiming to induce the model solution toward a target solution specified by the adversary by modifying the training data incrementally. As the gradient-based methods fail to solve this optimization problem, we propose to study the Lipschitz continuity property of the model solution, enabling us to calculate the semi-derivative, a one-sided directional derivative, of the solution over data. We leverage semi-derivative descent to solve the bi-level optimization problem, and establish the convergence conditions of the method to any attainable target model. The model and solution method are illustrated with a simulation of a poisoning attack on the lane change detection using SVM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03966v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xin Wanga (Jeff), Feilong Wang (Jeff), Yuan Hong (Jeff), R. Tyrrell Rockafellar (Jeff),  Xuegang (Jeff),  Ban</dc:creator>
    </item>
    <item>
      <title>Recent Advances in Disaster Emergency Response Planning: Integrating Optimization, Machine Learning, and Simulation</title>
      <link>https://arxiv.org/abs/2505.03979</link>
      <description>arXiv:2505.03979v1 Announce Type: new 
Abstract: The increasing frequency and severity of natural disasters underscore the critical importance of effective disaster emergency response planning to minimize human and economic losses. This survey provides a comprehensive review of recent advancements (2019--2024) in five essential areas of disaster emergency response planning: evacuation, facility location, casualty transport, search and rescue, and relief distribution. Research in these areas is systematically categorized based on methodologies, including optimization models, machine learning, and simulation, with a focus on their individual strengths and synergies. A notable contribution of this work is its examination of the interplay between machine learning, simulation, and optimization frameworks, highlighting how these approaches can address the dynamic, uncertain, and complex nature of disaster scenarios. By identifying key research trends and challenges, this study offers valuable insights to improve the effectiveness and resilience of emergency response strategies in future disaster planning efforts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03979v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.26599/SES.2025.9590007</arxiv:DOI>
      <arxiv:journal_reference>Safety Emergency Science, 2025, 1(1): 9590007</arxiv:journal_reference>
      <dc:creator>Fan Pu, Zihao Li, Yifan Wu, Chaolun Ma, Ruonan Zhao</dc:creator>
    </item>
    <item>
      <title>Learning based convex approximation for constrained parametric optimization</title>
      <link>https://arxiv.org/abs/2505.04037</link>
      <description>arXiv:2505.04037v1 Announce Type: new 
Abstract: We propose an input convex neural network (ICNN)-based self-supervised learning framework to solve continuous constrained optimization problems. By integrating the augmented Lagrangian method (ALM) with the constraint correction mechanism, our framework ensures \emph{non-strict constraint feasibility}, \emph{better optimality gap}, and \emph{best convergence rate} with respect to the state-of-the-art learning-based methods. We provide a rigorous convergence analysis, showing that the algorithm converges to a Karush-Kuhn-Tucker (KKT) point of the original problem even when the internal solver is a neural network, and the approximation error is bounded. We test our approach on a range of benchmark tasks including quadratic programming (QP), nonconvex programming, and large-scale AC optimal power flow problems. The results demonstrate that compared to existing solvers (e.g., \texttt{OSQP}, \texttt{IPOPT}) and the latest learning-based methods (e.g., DC3, PDL), our approach achieves a superior balance among accuracy, feasibility, and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04037v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kang Liu, Wei Peng, Jianchen Hu</dc:creator>
    </item>
    <item>
      <title>A Flexible Algorithmic Framework for Strictly Convex Quadratic Minimization</title>
      <link>https://arxiv.org/abs/2505.04047</link>
      <description>arXiv:2505.04047v1 Announce Type: new 
Abstract: This paper presents an algorithmic framework for the minimization of strictly convex quadratic functions. The framework is flexible and generic. At every iteration the search direction is a linear combination of the negative gradient, as well as (possibly) several other `sub-search' directions, where the user determines which, and how many, sub-search directions to include. Then, a step size along each sub-direction is generated in such a way that the gradient is minimized (with respect to a matrix norm), over the hyperplane specified by the user chosen search directions. Theoretical machinery is developed, which shows that any algorithm that fits into the generic framework is guaranteed to converge at a linear rate. Moreover, these theoretical results hold even when relaxation and/or symmetric preconditioning is employed. Several state-of-the-art algorithms fit into this scheme, including steepest descent and conjugate gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04047v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Liam MacDonald, Rua Murray, Rachael Tappenden</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Methods Through Variable and Operator Splitting</title>
      <link>https://arxiv.org/abs/2505.04065</link>
      <description>arXiv:2505.04065v1 Announce Type: new 
Abstract: This paper introduces a unified framework for accelerated gradient methods through the variable and operator splitting (VOS). The operator splitting decouples the optimization process into simpler subproblems, and more importantly, the variable splitting leads to acceleration. The key contributions include the development of strong Lyapunov functions to analyze stability and convergence rates, as well as advanced discretization techniques like Accelerated Over-Relaxation (AOR) and extrapolation by the predictor-corrector methods (EPC). For convex case, we introduce a dynamic updating parameter and a perturbed VOS flow. The framework effectively handles a wide range of optimization problems, including convex optimization, composite convex optimization, and saddle point systems with bilinear coupling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04065v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Long Chen, Luo Hao, Jingrong Wei</dc:creator>
    </item>
    <item>
      <title>Tseng's Type Methods in Continuous and Discrete Time for Quasi-Variational Inequalities</title>
      <link>https://arxiv.org/abs/2505.04102</link>
      <description>arXiv:2505.04102v1 Announce Type: new 
Abstract: This paper presents an approach for obtaining approximate solutions to quasi-variational inequalities in a real Hilbert space by modifying Tseng's scheme, which was originally designed for variational inequalities. The study explores the existence of equilibrium points and investigates convergence results related to dynamical systems. Linear convergence for discretized systems is examined through examples, illustrations, and special cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04102v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lkhamsuren Altangerel</dc:creator>
    </item>
    <item>
      <title>Semi-Explicit Solution of Some Discrete-Time Mean-Field-Type Control with Higher-Order Costs</title>
      <link>https://arxiv.org/abs/2505.04112</link>
      <description>arXiv:2505.04112v1 Announce Type: new 
Abstract: Traditional solvable optimal control theory predominantly focuses on quadratic costs due to their analytical tractability, yet they often fail to capture critical non-linearities inherent in real-world systems including water, energy, agriculture, and financial networks. Here, we present a unified framework for solving discrete-time optimal control with higher-order state and control costs of power-law form. By building convex-completion techniques, we derive semi-explicit expressions for control laws, cost-to-go functions, and recursive coefficient dynamics across deterministic and stochastic system settings. Key contributions include variance-aware solutions under additive and multiplicative noise, extensions to mean-field-type-dependent dynamics, and conditions that ensure the positivity of recursive coefficients. In particular, we establish that higher-order costs induce less aggressive control policies compared to quadratic formulations, a finding that is validated through numerical analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04112v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Julian Barreiro-Gomez, Tyrone E. Duncan, Bozenna Pasik-Duncan, Hamidou Tembine</dc:creator>
    </item>
    <item>
      <title>On submodularity of the expected information gain</title>
      <link>https://arxiv.org/abs/2505.04145</link>
      <description>arXiv:2505.04145v1 Announce Type: new 
Abstract: We consider finite-dimensional linear Gaussian Bayesian inverse problems with uncorrelated sensor measurements. In this setting, it is known that the expected information gain (EIG), measured by the expected Kullback-Leibler divergence from the posterior to prior, is submodular. We present a simple alternative proof of this fact tailored to a weighted inner product space setting arising from discretization of infinite- dimensional linear inverse problems governed by partial differential equations (PDEs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04145v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Steven Maio, Alen Alexanderian</dc:creator>
    </item>
    <item>
      <title>Integrated Airline Fleet and Crew Recovery through Local Search</title>
      <link>https://arxiv.org/abs/2505.04274</link>
      <description>arXiv:2505.04274v1 Announce Type: new 
Abstract: Airline operations are prone to delays and disruptions, since the schedules are generally tight and depend on a lot of resources. When disruptions occur, the flight schedule needs to be adjusted such that the operation can continue. Since this happens during the day of operations, this needs to be done as close to real time as possible, posing a challenge with respect to computation time. Moreover, to limit the impact of disruptions, we want a solution with minimal cost and passenger impact. Since airline operations include many interlinked decisions, an integrated approach leads to better overall solutions. We specifically look at resolving these disruptions in both the aircraft and crew schedules. Resolving these disruptions is complex, especially when it is done in an integrated way, i.e. including multiple different resources.
  To solve this problem in an integrated manner, we developed a fast simulated annealing approach. To the best of our knowledge, we are the first to develop a local search approach to resolve airline disruptions in an integrated way. This approach is compared with traditional approaches, and an experimental study is done to evaluate different neighbour generation methods, and to investigate different recovery scenarios and strategies. The comparison is done using real world data from KLM Royal Dutch Airlines. Here, we show that our approach resolves disruptions quickly and in a cost-efficient manner, and that it outperforms traditional approaches. Compared to naive delay propagation, our method saves 40% in non-performance costs. Moreover, while most airlines use tools that consider resources separately, our approach shows that integrated disruption management is possible within 30 seconds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04274v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip de Bruin, Marjan van den Akker, Kunal Kumar, Lisanne Heuseveldt, Marc Paelinck</dc:creator>
    </item>
    <item>
      <title>Adjoint-based optimal control of jump-diffusion processes</title>
      <link>https://arxiv.org/abs/2505.04328</link>
      <description>arXiv:2505.04328v1 Announce Type: new 
Abstract: Stochastic differential equations (SDEs) using jump-diffusion processes describe many natural phenomena at the microscopic level. Since they are commonly used to model economic and financial evolutions, the calibration and optimal control of such processes are of interest to many communities and have been the subject of extensive research. In this work, we develop an optimization method working at the microscopic level. This allows us also to reduce computational time since we can parallelize the calculations and do not encounter the so-called curse of dimensionality that occurs when lifting the problem to its macroscopic counterpart using partial differential equations (PDEs). Using a discretize-then-optimize approach, we derive an adjoint process and an optimality system in the Lagrange framework. Then, we apply Monte Carlo methods to solve all the arising equations. We validate our optimization strategy by extensive numerical experiments. We also successfully test a optimization procedure that avoids storing the information of the forward equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04328v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Jan Bartsch, Alfio Borzi, Gabriele Ciaramella, Jan Reichle</dc:creator>
    </item>
    <item>
      <title>Optimization of the cut configuration for skin grafts</title>
      <link>https://arxiv.org/abs/2505.04348</link>
      <description>arXiv:2505.04348v1 Announce Type: new 
Abstract: The subject of this work is the problem of optimizing the configuration of cuts for skin grafting in order to improve the efficiency of the procedure. We consider the optimization problem in the framework of a linear elasticity model. We choose three mechanical measures that define optimality via related objective functionals: the compliance, the \(L^p\)-norm of the von Mises stress, and the area of the stretched skin. We provide a proof of the existence of solutions for each problem, but we cannot claim uniqueness. We compute the gradient of the objectives with respect to the cut configuration using shape calculus concepts. To solve the problem numerically, we use the gradient descent method, which performs well under uniaxial stretching. However, in more complex cases, such as multidirectional stretching, its effectiveness is limited due to low sensitivity of the functionals. To avoid this difficulty, we use a combination of the genetic algorithm and the gradient descent method, which leads to a significant improvement in the results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04348v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helmut Harbrecht, Viacheslav Karnaev</dc:creator>
    </item>
    <item>
      <title>Optimization Problem Solving Can Transition to Evolutionary Agentic Workflows</title>
      <link>https://arxiv.org/abs/2505.04354</link>
      <description>arXiv:2505.04354v1 Announce Type: new 
Abstract: This position paper argues that optimization problem solving can transition from expert-dependent to evolutionary agentic workflows. Traditional optimization practices rely on human specialists for problem formulation, algorithm selection, and hyperparameter tuning, creating bottlenecks that impede industrial adoption of cutting-edge methods. We contend that an evolutionary agentic workflow, powered by foundation models and evolutionary search, can autonomously navigate the optimization space, comprising problem, formulation, algorithm, and hyperparameter spaces. Through case studies in cloud resource scheduling and ADMM parameter adaptation, we demonstrate how this approach can bridge the gap between academic innovation and industrial implementation. Our position challenges the status quo of human-centric optimization workflows and advocates for a more scalable, adaptive approach to solving real-world optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04354v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhao Li, Bo Jin, Mingyi Hong, Changhong Lu, Xiangfeng Wang</dc:creator>
    </item>
    <item>
      <title>Adaptive finite element method for an unregularized semilinear optimal control problem</title>
      <link>https://arxiv.org/abs/2505.04439</link>
      <description>arXiv:2505.04439v1 Announce Type: new 
Abstract: We devise an a posteriori error estimator for an affine optimal control problem subject to a semilinear elliptic PDE and control constraints. To approximate the problem, we consider a semidiscrete scheme based on the variational discretization approach. For this solution technique, we design an a posteriori error estimator that accounts for the discretization of the state and adjoint equations, and prove, under suitable local growth conditions of optimal controls, reliability and efficiency properties of such error estimator. A simple adaptive strategy based on the devised estimator is designed and its performance is illustrated with numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04439v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francisco Fuica, Nicolai Jork</dc:creator>
    </item>
    <item>
      <title>A Two-Timescale Primal-Dual Framework for Reinforcement Learning via Online Dual Variable Guidance</title>
      <link>https://arxiv.org/abs/2505.04494</link>
      <description>arXiv:2505.04494v1 Announce Type: new 
Abstract: We study reinforcement learning by combining recent advances in regularized linear programming formulations with the classical theory of stochastic approximation. Motivated by the challenge of designing algorithms that leverage off-policy data while maintaining on-policy exploration, we propose PGDA-RL, a novel primal-dual Projected Gradient Descent-Ascent algorithm for solving regularized Markov Decision Processes (MDPs). PGDA-RL integrates experience replay-based gradient estimation with a two-timescale decomposition of the underlying nested optimization problem. The algorithm operates asynchronously, interacts with the environment through a single trajectory of correlated data, and updates its policy online in response to the dual variable associated with the occupation measure of the underlying MDP. We prove that PGDA-RL converges almost surely to the optimal value function and policy of the regularized MDP. Our convergence analysis relies on tools from stochastic approximation theory and holds under weaker assumptions than those required by existing primal-dual RL approaches, notably removing the need for a simulator or a fixed behavioral policy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04494v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Axel Friedrich Wolter, Tobias Sutter</dc:creator>
    </item>
    <item>
      <title>Algorithms for zero-sum stochastic games with the risk-sensitive average criterion</title>
      <link>https://arxiv.org/abs/2505.04546</link>
      <description>arXiv:2505.04546v1 Announce Type: new 
Abstract: This paper is an attempt to compute the value and saddle points of zero-sum risk-sensitive average stochastic games. For the average games with finite states and actions, we first introduce the so-called irreducibility coefficient and then establish its equivalence to the irreducibility condition. Using this equivalence,we develop an iteration algorithm to compute $\varepsilon$-approximations of the value (for any given $\varepsilon&gt;0$) and show its convergence. Based on $\varepsilon$-approximations of the value and the irreducibility coefficient, we further propose another iteration algorithm, which is proved to obtain $\varepsilon$-saddle points in finite steps. Finally, a numerical example of energy management in smart grids is provided to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04546v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fang Chen, Xianping Guo, Xin Guo, Junyu Zhang</dc:creator>
    </item>
    <item>
      <title>Dynamic Network Flow Optimization for Task Scheduling in PTZ Camera Surveillance Systems</title>
      <link>https://arxiv.org/abs/2505.04596</link>
      <description>arXiv:2505.04596v1 Announce Type: new 
Abstract: This paper presents a novel approach for optimizing the scheduling and control of Pan-Tilt-Zoom (PTZ) cameras in dynamic surveillance environments. The proposed method integrates Kalman filters for motion prediction with a dynamic network flow model to enhance real-time video capture efficiency. By assigning Kalman filters to tracked objects, the system predicts future locations, enabling precise scheduling of camera tasks. This prediction-driven approach is formulated as a network flow optimization, ensuring scalability and adaptability to various surveillance scenarios. To further reduce redundant monitoring, we also incorporate group-tracking nodes, allowing multiple objects to be captured within a single camera focus when appropriate. In addition, a value-based system is introduced to prioritize camera actions, focusing on the timely capture of critical events. By adjusting the decay rates of these values over time, the system ensures prompt responses to tasks with imminent deadlines. Extensive simulations demonstrate that this approach improves coverage, reduces average wait times, and minimizes missed events compared to traditional master-slave camera systems. Overall, our method significantly enhances the efficiency, scalability, and effectiveness of surveillance systems, particularly in dynamic and crowded environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04596v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Merati, David Casta\~n\'on</dc:creator>
    </item>
    <item>
      <title>Deep Reinforcement Learning for Investor-Specific Portfolio Optimization: A Volatility-Guided Asset Selection Approach</title>
      <link>https://arxiv.org/abs/2505.03760</link>
      <description>arXiv:2505.03760v1 Announce Type: cross 
Abstract: Portfolio optimization requires dynamic allocation of funds by balancing the risk and return tradeoff under dynamic market conditions. With the recent advancements in AI, Deep Reinforcement Learning (DRL) has gained prominence in providing adaptive and scalable strategies for portfolio optimization. However, the success of these strategies depends not only on their ability to adapt to market dynamics but also on the careful pre-selection of assets that influence overall portfolio performance. Incorporating the investor's preference in pre-selecting assets for a portfolio is essential in refining their investment strategies. This study proposes a volatility-guided DRL-based portfolio optimization framework that dynamically constructs portfolios based on investors' risk profiles. The Generalized Autoregressive Conditional Heteroscedasticity (GARCH) model is utilized for volatility forecasting of stocks and categorizes them based on their volatility as aggressive, moderate, and conservative. The DRL agent is then employed to learn an optimal investment policy by interacting with the historical market data. The efficacy of the proposed methodology is established using stocks from the Dow $30$ index. The proposed investor-specific DRL-based portfolios outperformed the baseline strategies by generating consistent risk-adjusted returns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03760v1</guid>
      <category>q-fin.PM</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Arishi Orra, Aryan Bhambu, Himanshu Choudhary, Manoj Thakur, Selvaraju Natarajan</dc:creator>
    </item>
    <item>
      <title>A Double Inertial Forward-Backward Splitting Algorithm With Applications to Regression and Classification Problems</title>
      <link>https://arxiv.org/abs/2505.03794</link>
      <description>arXiv:2505.03794v1 Announce Type: cross 
Abstract: This paper presents an improved forward-backward splitting algorithm with two inertial parameters. It aims to find a point in the real Hilbert space at which the sum of a co-coercive operator and a maximal monotone operator vanishes. Under standard assumptions, our proposed algorithm demonstrates weak convergence. We present numerous experimental results to demonstrate the behavior of the developed algorithm by comparing it with existing algorithms in the literature for regression and data classification problems. Furthermore, these implementations suggest our proposed algorithm yields superior outcomes when benchmarked against other relevant algorithms in existing literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03794v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\.Irfan I\c{s}ik, Ibrahim Karahan, Okan Erkaymaz</dc:creator>
    </item>
    <item>
      <title>Learning Interactions Between Continuous Treatments and Covariates with a Semiparametric Model</title>
      <link>https://arxiv.org/abs/2505.03893</link>
      <description>arXiv:2505.03893v1 Announce Type: cross 
Abstract: Estimating the impact of continuous treatment variables (e.g., dosage amount) on binary outcomes presents significant challenges in modeling and estimation because many existing approaches make strong assumptions that do not hold for certain continuous treatment variables. For instance, traditional logistic regression makes strong linearity assumptions that do not hold for continuous treatment variables like time of initiation. In this work, we propose a semiparametric regression framework that decomposes effects into two interpretable components: a prognostic score that captures baseline outcome risk based on a combination of clinical, genetic, and sociodemographic features, and a treatment-interaction score that flexibly models the optimal treatment level via a nonparametric link function. By connecting these two parametric scores with Nadaraya-Watson regression, our approach is both interpretable and flexible. The potential of our approach is demonstrated through numerical simulations that show empirical estimation convergence. We conclude by applying our approach to a real-world case study using the International Warfarin Pharmacogenomics Consortium (IWPC) dataset to show our approach's clinical utility by deriving personalized warfarin dosing recommendations that integrate both genetic and clinical data, providing insights towards enhancing patient safety and therapeutic efficacy in anticoagulation therapy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03893v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Muyan Jiang, Yunkai Zhang, Anil Aswani</dc:creator>
    </item>
    <item>
      <title>Sufficient Decision Proxies for Decision-Focused Learning</title>
      <link>https://arxiv.org/abs/2505.03953</link>
      <description>arXiv:2505.03953v1 Announce Type: cross 
Abstract: When solving optimization problems under uncertainty with contextual data, utilizing machine learning to predict the uncertain parameters is a popular and effective approach. Decision-focused learning (DFL) aims at learning a predictive model such that decision quality, instead of prediction accuracy, is maximized. Common practice here is to predict a single value for each uncertain parameter, implicitly assuming that there exists a (single-scenario) deterministic problem approximation (proxy) that is sufficient to obtain an optimal decision. Other work assumes the opposite, where the underlying distribution needs to be estimated. However, little is known about when either choice is valid. This paper investigates for the first time problem properties that justify using either assumption. Using this, we present effective decision proxies for DFL, with very limited compromise on the complexity of the learning task. We show the effectiveness of presented approaches in experiments on problems with continuous and discrete variables, as well as uncertainty in the objective function and in the constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.03953v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Noah Schutte, Grigorii Veviurko, Krzysztof Postek, Neil Yorke-Smith</dc:creator>
    </item>
    <item>
      <title>On the Crouzeix-Raviart Finite Element Approximation of Phase-Field Dependent Topology Optimization in Stokes Flow</title>
      <link>https://arxiv.org/abs/2505.04120</link>
      <description>arXiv:2505.04120v1 Announce Type: cross 
Abstract: In this work, we investigate a nonconforming finite element approximation of phase-field parameterized topology optimization governed by the Stokes flow. The phase field, the velocity field and the pressure field are approximated by conforming linear finite elements, nonconforming linear finite elements (Crouzeix-Raviart elements) and piecewise constants, respectively. When compared with the standard conforming counterpart, the nonconforming FEM can provide an approximation with fewer degrees of freedom, leading to improved computational efficiency. We establish the convergence of the resulting numerical scheme in the sense that the sequences of phase-field functions and discrete velocity fields contain subsequences that converge to a minimizing pair of the continuous problem in the $H^1$-norm and a mesh-dependent norm, respectively. We present extensive numerical results to illustrate the performance of the approach, including a comparison with the popular Taylor-Hood elements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04120v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bangti Jin, Jing Li, Yifeng Xu, Shengfeng Zhu</dc:creator>
    </item>
    <item>
      <title>optHIM: Hybrid Iterative Methods for Continuous Optimization in PyTorch</title>
      <link>https://arxiv.org/abs/2505.04137</link>
      <description>arXiv:2505.04137v1 Announce Type: cross 
Abstract: We introduce optHIM, an open-source library of continuous unconstrained optimization algorithms implemented in PyTorch for both CPU and GPU. By leveraging PyTorch's autograd, optHIM seamlessly integrates function, gradient, and Hessian information into flexible line-search and trust-region methods. We evaluate eleven state-of-the-art variants on benchmark problems spanning convex and non-convex landscapes. Through a suite of quantitative metrics and qualitative analyses, we demonstrate each method's strengths and trade-offs. optHIM aims to democratize advanced optimization by providing a transparent, extensible, and efficient framework for research and education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04137v1</guid>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nikhil Sridhar, Sajiv Shah</dc:creator>
    </item>
    <item>
      <title>New solutions for the symmetrical n-body problem through variational approach and optimisation techniques</title>
      <link>https://arxiv.org/abs/2505.04221</link>
      <description>arXiv:2505.04221v1 Announce Type: cross 
Abstract: Advances in the variational approach to the $n$-body problem have led to significant progress in celestial mechanics, uncovering new types of possible orbits. In this paper, critical points of the Lagrangian action associated with the $n$-body problem are analysed using evolutionary algorithms to identify periodic and symmetrical solutions of the discretised system. A key objective is to locate minimum points of the action functional, as these correspond to feasible periodic solutions that satisfy the system's differential equations. By employing both stochastic and deterministic algorithms, we explore the solution space and obtain numerical representations of these orbits.
  Next, we examine the stability of these orbits by treating them as critical points. One approach is to compute their discrete Morse index to distinguish between minimum points and saddle points. Another is to classify them based on their action levels. Finally, analysing the boundaries of their attraction basins allows us to identify non-minimal critical points via the Ambrosetti-Rabinowitz Mountain Pass Theorem. This leads to an updated version of the algorithm that provides a constructive proof of the theorem, yielding new orbits in specific cases.
  This paper builds upon and extends the results presented in \cite{nostro}, providing a more detailed theoretical framework and deeper insights into the formulation. Additionally, we present new numerical results and an extended analysis of the critical points found, further enhancing the findings of the previous study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04221v1</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s42496-025-00265-5</arxiv:DOI>
      <dc:creator>Roberto Ciccarelli, Margaux Introna, Susanna Terracini, Massimiliano Vasile</dc:creator>
    </item>
    <item>
      <title>Exit Incentives for Carbon Emissive Firms</title>
      <link>https://arxiv.org/abs/2505.04301</link>
      <description>arXiv:2505.04301v1 Announce Type: cross 
Abstract: We develop a continuous-time model of incentives for carbon emissive firms to exit the market based on a compensation payment identical to all firms. In our model, firms enjoy profits from production modeled as a simple geometric Brownian motion and do not bear any environmental damage from production. A regulator maximises the expected discounted value of firms profits from production minus environmental damages caused by production and proposes a compensation payment whose dynamics is known to the firms. We provide in both situations closed-form expressions for the compensation payment process and the exit thresholds of each firms. We apply our model to the crude oil market. We show that market concentration both reduces the total expected discounted payment to firms and the expected closing time of polluting assets. We extend this framework to the case of two countries each regulating its own market. The presence of a second mover advantage leads to the possibility of multiple equilibria. Applying this result to large producing countries, we find that they are unlikely to agree on the timing to exit market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04301v1</guid>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ren\'e A\"id, Xiangying Pang, Xiaolu Tan</dc:creator>
    </item>
    <item>
      <title>Flow Models for Unbounded and Geometry-Aware Distributional Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2505.04310</link>
      <description>arXiv:2505.04310v1 Announce Type: cross 
Abstract: We introduce a new architecture for Distributional Reinforcement Learning (DistRL) that models return distributions using normalizing flows. This approach enables flexible, unbounded support for return distributions, in contrast to categorical approaches like C51 that rely on fixed or bounded representations. It also offers richer modeling capacity to capture multi-modality, skewness, and tail behavior than quantile based approaches. Our method is significantly more parameter-efficient than categorical approaches. Standard metrics used to train existing models like KL divergence or Wasserstein distance either are scale insensitive or have biased sample gradients, especially when return supports do not overlap. To address this, we propose a novel surrogate for the Cram\`er distance, that is geometry-aware and computable directly from the return distribution's PDF, avoiding the costly CDF computation. We test our model on the ATARI-5 sub-benchmark and show that our approach outperforms PDF based models while remaining competitive with quantile based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04310v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simo Alami C., Rim Kaddah, Jesse Read, Marie-Paule Cani</dc:creator>
    </item>
    <item>
      <title>Duality-Based Algorithm and Numerical Analysis for Optimal Insulation Problems on Non-Smooth Domains</title>
      <link>https://arxiv.org/abs/2505.04571</link>
      <description>arXiv:2505.04571v1 Announce Type: cross 
Abstract: This article develops a numerical approximation of a convex non-local and non-smooth minimization problem. The physical problem involves determining the optimal distribution, given by $h\colon \Gamma_I\to [0,+\infty)$, of a given amount $m\in \mathbb{N}$ of insulating material attached to a boundary part $\Gamma_I\subseteq \partial\Omega$ of a thermally conducting body $\Omega \subseteq \mathbb{R}^d$, $d \in \mathbb{N}$, subject to conductive heat transfer. To tackle the non-local and non-smooth character of the problem, the article introduces a (Fenchel) duality framework: (a) At the continuous level, using (Fenchel) duality relations, we derive an a posteriori error identity that can handle arbitrary admissible approximations of the primal and dual formulations of the convex non-local and non-smooth minimization problem; (b) At the discrete level, using discrete (Fenchel) duality relations, we derive an a priori error identity that applies to a Crouzeix--Raviart discretization of the primal formulation and a Raviart--Thomas discretization of the dual formulation. The proposed framework leads to error decay rates that are optimal with respect to the specific regularity of a minimizer. In addition, we prove convergence of the numerical approximation under minimal regularity assumptions. Since the discrete dual formulation can be written as a quadratic program, it is solved using a primal-dual active set strategy interpreted as semismooth Newton method. A solution of the discrete primal formulation is reconstructed from the solution of the discrete dual formulation by means of an inverse generalized Marini formula. This is the first such formula for this class of convex non-local and non-smooth minimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.04571v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harbir Antil, Alex Kaltenbach, Keegan L. A. Kirk</dc:creator>
    </item>
    <item>
      <title>Complexity of a linearized augmented Lagrangian method for nonconvex minimization with nonlinear equality constraints</title>
      <link>https://arxiv.org/abs/2301.08345</link>
      <description>arXiv:2301.08345v2 Announce Type: replace 
Abstract: In this paper, we consider a nonconvex optimization problem with nonlinear equality constraints. We assume that both, the objective function and the functional constraints are locally smooth. For solving this problem, we propose a linearized augmented Lagrangian method, i.e., we linearize the objective function and the functional constraints in a Gauss-Newton fashion at the current iterate within the augmented Lagrangian function and add a quadratic regularization, yielding a subproblem that is easy to solve, and whose solution is the next primal iterate. The update of the dual multipliers is also based on the linearization of functional constraints. Under a novel dynamic regularization parameter choice, we prove boundedness and global asymptotic convergence of the iterates to a first-order solution of the problem. We also derive convergence guarantees for the iterates of our method to an $\epsilon$-first-order solution in $\mathcal{O}(\sqrt{\rho} \epsilon^{-2})$ Jacobian evaluations, where $\rho$ is the penalty parameter. Moreover, when the problem exhibits a benign nonconvex property, we derive improved convergence results to an $\epsilon$-second-order solution. Finally, we validate the performance of the proposed algorithm by numerically comparing it with the existing methods and software from the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.08345v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lahcen El Bourkhissi, Ion Necoara</dc:creator>
    </item>
    <item>
      <title>Efficient Branching Rules for Optimizing Range and Order-Based Objective Functions</title>
      <link>https://arxiv.org/abs/2311.03885</link>
      <description>arXiv:2311.03885v3 Announce Type: replace 
Abstract: We consider range minimization problems featuring exponentially many variables, as frequently arising in fairness-oriented or bi-objective optimization. While branch and price is successful at solving cost-oriented problems with many variables, the performance of classical branch-and-price algorithms for range minimization is drastically impaired by weak linear programming relaxations. We propose range branching, a generic branching rule that directly tackles this issue and can be used on top of problem-specific branching schemes. We show several desirable properties of range branching and show its effectiveness on a series of instances of the fair capacitated vehicle routing problem and fair generalized assignment problem. Range branching significantly improves multiple classical branching schemes in terms of computing time, optimality gap, and size of the branch-and-bound tree, allowing us to solve many more large instances than classical methods. Moreover, we show how range branching can be successfully generalized to order-based objective functions, such as the Gini deviation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03885v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bart van Rossum, Rui Chen, Andrea Lodi</dc:creator>
    </item>
    <item>
      <title>Sensitivity analysis for mixed binary quadratic programming</title>
      <link>https://arxiv.org/abs/2312.06714</link>
      <description>arXiv:2312.06714v2 Announce Type: replace 
Abstract: We consider sensitivity analysis for Mixed Binary Quadratic Programs (MBQPs) with respect to changing right-hand-sides (rhs). We show that even if the optimal solution of a given MBQP is known, it is NP-hard to approximate the change in objective function value with respect to changes in rhs. Next, we study algorithmic approaches to obtaining dual bounds for MBQP with changing rhs. We leverage Burer's completely-positive (CPP) reformulation of MBQPs. Its dual is an instance of co-positive programming (COP), and can be used to obtain sensitivity bounds. We prove that strong duality between the CPP and COP problems holds if the feasible region is bounded or if the objective function is convex, while the duality gap can be strictly positive if neither condition is met. We also show that the COP dual has multiple optimal solutions, and the choice of the dual solution affects the quality of the bounds with rhs changes. We finally provide a method for finding good nearly optimal dual solutions, and we present preliminary computational results on sensitivity analysis for MBQPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.06714v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Diego Cifuentes, Santanu S. Dey, Jingye Xu</dc:creator>
    </item>
    <item>
      <title>Anderson acceleration of derivative-free projection methods for constrained monotone nonlinear equations</title>
      <link>https://arxiv.org/abs/2403.14924</link>
      <description>arXiv:2403.14924v2 Announce Type: replace 
Abstract: The derivative-free projection method (DFPM) is an efficient algorithm for solving monotone nonlinear equations. As problems grow larger, there is a strong demand for speeding up the convergence of DFPM. This paper considers the application of Anderson acceleration (AA) to DFPM for constrained monotone nonlinear equations. By employing a nonstationary relaxation parameter and interleaving with slight modifications in each iteration, a globally convergent variant of AA for DFPM named as AA-DFPM is proposed. Further, the linear convergence rate is proved under some mild assumptions. Experiments on both mathematical examples and a real-world application show encouraging results of AA-DFPM and confirm the suitability of AA for accelerating DFPM in solving optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14924v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiachen Jin, Hongxia Wang, Kangkang Deng</dc:creator>
    </item>
    <item>
      <title>Structured Nonsmooth Optimization Using Functional Encoding and Branching Information</title>
      <link>https://arxiv.org/abs/2404.16273</link>
      <description>arXiv:2404.16273v2 Announce Type: replace 
Abstract: We develop a novel gradient-based algorithm for optimizing nonsmooth nonconvex functions where nonsmoothness arises from explicit nonsmooth operators in the objective's analytical form. Our key innovation involves encoding active smooth branches of these operators, enabling both branch function extraction at arbitrary points and transition detection through branch tracking. This approach yields a Branch-Information-Driven Gradient Descent (BIGD) method for encodable piecewise-differentiable functions, with an enhanced version achieving local linear convergence under appropriate conditions. The computationally efficient encoding mechanism is straightforward to implement. The power of using branch information has been proved via substantial numerical experiments compared to some existing nonsmooth optimization methods on standard test problems. Most importantly, for piecewise-smooth problems given analytical expressions, implementation of functional encoding can be integrated into a wide range of existing nonsmooth optimization methods to improve the bundle points management, reduce the complexity of the quadratic programming sub-problems, and improve the efficiency of line search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.16273v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fengqiao Luo</dc:creator>
    </item>
    <item>
      <title>Optimal Rates of Convergence for Entropy Regularization in Discounted Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2406.04163</link>
      <description>arXiv:2406.04163v3 Announce Type: replace 
Abstract: We study the error introduced by entropy regularization in infinite-horizon, discrete, discounted Markov decision processes. We show that this error decreases exponentially in the inverse regularization strength both in a weighted KL-divergence and in value with a problem-specific exponent. This is in contrast to previously known estimates, of the order $O(\tau)$, where $\tau$ is the regularization strength. We provide a lower bound matching our upper bound up to a polynomial term, thereby characterizing the exponential convergence rate for entropy regularization. Our proof relies on the observation that the solutions of entropy-regularized Markov decision processes solve a gradient flow of the unregularized reward with respect to a Riemannian metric common in natural policy gradient methods. This correspondence allows us to identify the limit of this gradient flow as the generalized maximum entropy optimal policy, thereby characterizing the implicit bias of this gradient flow, which corresponds to a time-continuous version of the natural policy gradient method. We use our improved error estimates to show that for entropy-regularized natural policy gradient methods, the overall error decays exponentially in the square root of the number of iterations, improving over existing sublinear guarantees. Finally, we extend our analysis to settings beyond the entropy. In particular, we characterize the implicit bias regarding general convex potentials and their resulting generalized natural policy gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04163v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes M\"uller, Semih Cayci</dc:creator>
    </item>
    <item>
      <title>Actively learning equilibria in Nash games with misleading information</title>
      <link>https://arxiv.org/abs/2503.13167</link>
      <description>arXiv:2503.13167v2 Announce Type: replace 
Abstract: We develop a scheme based on active learning to compute equilibria in a generalized Nash equilibrium problem (GNEP). Specifically, an external observer (or entity), with little knowledge on the multi-agent process at hand, collects sensible data by probing the agents' best-response (BR) mappings, which are then used to recursively update local parametric estimates of these mappings. Unlike [1], we consider the realistic case in which the agents share corrupted information with the external entity for, e.g., protecting their privacy. Inspired by a popular approach in stochastic optimization, we endow the external observer with an inexact proximal scheme for updating the local BR proxies. This technique will prove key to establishing the convergence of our scheme under standard assumptions, thereby enabling the external observer to predict an equilibrium strategy even when relying on masked information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13167v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Barbara Franci, Filippo Fabiani, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>Stochastic Programming for Dynamic Temperature Control of Refrigerated Road Transport</title>
      <link>https://arxiv.org/abs/2504.15741</link>
      <description>arXiv:2504.15741v2 Announce Type: replace 
Abstract: Temperature control in refrigerated delivery vehicles is critical for preserving product quality, yet existing approaches neglect critical operational uncertainties, such as stochastic door opening durations and heterogeneous initial product temperatures. We propose a framework to optimize cooling policies for refrigerated trucks on fixed routes by explicitly modeling these uncertainties while capturing all relevant thermodynamic interactions in the trailer. To this end, we integrate high-fidelity thermodynamic modeling with a multistage stochastic programming formulation and solve the resulting problem using stochastic dual dynamic programming. In cooperation with industry partners and based on real-world data, we set up computational experiments that demonstrate that our stochastic policy consistently outperforms the best deterministic benchmark by 35% on average while being computationally tractable. In a separate analysis, we show that by fixing the duration of temperature violations, our policy operates with up to $40$\% less fuel than deterministic policies. Our results demonstrate that pallet-level thermal status information is the single most crucial information in the problem and can be used to significantly reduce temperature violations. Knowledge of the timing and length of customer stops is the second most important factor and, together with detailed modeling of thermodynamic interactions, can be used to further significantly reduce violations. Our analysis of the optimal stochastic cooling policy reveals that preemptive cooling before a stop is the key element of an optimal policy. These findings highlight the value of sophisticated control strategies in maintaining the quality of perishable products while reducing the carbon footprint of the industry and improving operational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.15741v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Giliberto, Rosario Paradiso, David Wozabal</dc:creator>
    </item>
    <item>
      <title>Tight Regret Bounds for Bayesian Optimization in One Dimension</title>
      <link>https://arxiv.org/abs/1805.11792</link>
      <description>arXiv:1805.11792v3 Announce Type: replace-cross 
Abstract: We consider the problem of Bayesian optimization (BO) in one dimension, under a Gaussian process prior and Gaussian sampling noise. We provide a theoretical analysis showing that, under fairly mild technical assumptions on the kernel, the best possible cumulative regret up to time $T$ behaves as $\Omega(\sqrt{T})$ and $O(\sqrt{T\log T})$. This gives a tight characterization up to a $\sqrt{\log T}$ factor, and includes the first non-trivial lower bound for noisy BO. Our assumptions are satisfied, for example, by the squared exponential and Mat\'ern-$\nu$ kernels, with the latter requiring $\nu &gt; 2$. Our results certify the near-optimality of existing bounds (Srinivas {\em et al.}, 2009) for the SE kernel, while proving them to be strictly suboptimal for the Mat\'ern kernel with $\nu &gt; 2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:1805.11792v3</guid>
      <category>stat.ML</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Scarlett</dc:creator>
    </item>
    <item>
      <title>Calibration of Local Volatility Models with Stochastic Interest Rates using Optimal Transport</title>
      <link>https://arxiv.org/abs/2305.00200</link>
      <description>arXiv:2305.00200v2 Announce Type: replace-cross 
Abstract: We develop a non-parametric, semimartingale optimal transport, calibration methodology for local volatility models with stochastic interest rate. The method finds a fully calibrated model which is the closest, in a way that can be defined by a general cost function, to a given reference model. We establish a general duality result which allows to solve the problem by optimising over solutions to a second order fully non-linear Hamilton-Jacobi-Bellman equation. Our methodology is analogous to Guo, Loeper, and Wang, 2022 and Guo, Loeper, Obloj, et al., 2022a but features a novel element of solving for discounted densities, or sub-probability measures. As an example, we apply the method to a sequential calibration problem, where a Vasicek model is already given for the interest rates and we seek to calibrate a stock price's local volatility model with volatility coefficient depending on time, the underlying and the short rate process, and the two processes driven by possibly correlated Brownian motions. The equity model is calibrated to any number of European options prices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00200v2</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Benjamin Joseph, Gregoire Loeper, Jan Obloj</dc:creator>
    </item>
    <item>
      <title>Disjunctive Branch-And-Bound for Certifiably Optimal Low-Rank Matrix Completion</title>
      <link>https://arxiv.org/abs/2305.12292</link>
      <description>arXiv:2305.12292v3 Announce Type: replace-cross 
Abstract: Low-rank matrix completion consists of computing a matrix of minimal complexity that recovers a given set of observations as accurately as possible. Unfortunately, existing methods for matrix completion are heuristics that, while highly scalable and often identifying high-quality solutions, do not possess any optimality guarantees. We reexamine matrix completion with an optimality-oriented eye. We reformulate low-rank matrix completion problems as convex problems over the non-convex set of projection matrices and implement a disjunctive branch-and-bound scheme that solves them to certifiable optimality. Further, we derive a novel and often near-exact class of convex relaxations by decomposing a low-rank matrix as a sum of rank-one matrices and incentivizing that two-by-two minors in each rank-one matrix have determinant zero. In numerical experiments, our new convex relaxations decrease the optimality gap by two orders of magnitude compared to existing attempts, and our disjunctive branch-and-bound scheme solves $n \times m$ rank-$r$ matrix completion problems to certifiable optimality or near optimality in hours for $\max \{m, n\} \leq 2500$ and $r \leq 5$. Moreover, this improvement in the training error translates into an average $2\%$--$50\%$ improvement in the test set error.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12292v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Ryan Cory-Wright, Sean Lo, Jean Pauphilet</dc:creator>
    </item>
    <item>
      <title>Randomized Transport Plans via Hierarchical Fully Probabilistic Design</title>
      <link>https://arxiv.org/abs/2408.02701</link>
      <description>arXiv:2408.02701v2 Announce Type: replace-cross 
Abstract: An optimal randomized strategy for design of balanced, normalized mass transport plans is developed. It replaces -- but specializes to -- the deterministic, regularized optimal transport (OT) strategy, which yields only a certainty-equivalent plan. The incompletely specified -- and therefore uncertain -- transport plan is acknowledged to be a random process. Therefore, hierarchical fully probabilistic design (HFPD) is adopted, yielding an optimal hyperprior supported on the set of possible transport plans, and consistent with prior mean constraints on the marginals of the uncertain plan. This Bayesian resetting of the design problem for transport plans -- which we call HFPD-OT -- confers new opportunities. These include (i) a strategy for the generation of a random sample of joint transport plans; (ii) randomized marginal contracts for individual source-target pairs; and (iii) consistent measures of uncertainty in the plan and its contracts. An application in fair market matching is outlined, in which HFPD-OT enables the recruitment of a more diverse subset of contracts -- than is possible in classical OT -- into the delivery of an expected plan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.02701v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarah Boufelja Y., Anthony Quinn, Robert Shorten</dc:creator>
    </item>
    <item>
      <title>Gradient flow structure for some nonlocal diffusion equations</title>
      <link>https://arxiv.org/abs/2412.20969</link>
      <description>arXiv:2412.20969v2 Announce Type: replace-cross 
Abstract: We study ``nonlocal diffusion equations'' of the form \[ \partial_{t}\frac{d\rho_{t}}{d\pi}(x)+\int_{X}\left(\frac{d\rho_{t}}{d\pi}(x)-\frac{d\rho_{t}}{d\pi}(y)\right)\eta(x,y)d\pi(y)=0\qquad(\dagger) \] where $X$ is either $\mathbb{R}^{d}$ or $\mathbb{T}^{d}$, $\pi$ is a probability distribution on $X$, and $\eta(x,y)$ is a ``transition kernel'' which may be singular as $x\rightarrow y$. For a suitable notion of weak solutions which we discuss below, we show that solutions to these nonlocal diffusion equations can be interpreted as gradient flows of the relative entropy with respect to a certain nonlocal Wasserstein-type metric defined in terms of $\eta$ and $\pi$. These ``nonlocal Wasserstein metrics'' endow the space of probability measures on $X$ with a formal Riemannian structure, thereby providing for us a nonlocal analogue of the \emph{Otto calculus} originally developed in the context of the 2-Wasserstein metric. The class of equations $(\dagger)$ includes a family of ``nonlocal Fokker-Planck equations'', which are thus identified as nonlocal Wasserstein gradient flows of the relative entropy, analogously with the usual Fokker-Planck equation and the $W_{2}$ metric.
  The gradient flow structure we provide allows us to deduce: existence and uniqueness of solutions to ($\dagger$) in a suitable class of weak solutions; stability of solutions in the sense of evolutionary $\Gamma$-convergence, with respect to perturbations of initial condition, reference measure $\pi$, and transition kernel $\eta$; sufficient conditions for exponential convergence to equilibrium, in terms of a nonlocal analogue of the log-Sobolev inequality; as well as the consistency of a finite-volume-type spatial discretization scheme in the $\mathbb{T}^{d}$ case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20969v2</guid>
      <category>math.AP</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 08 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Warren</dc:creator>
    </item>
  </channel>
</rss>
