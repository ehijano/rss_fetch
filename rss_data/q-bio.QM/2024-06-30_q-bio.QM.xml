<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 01 Jul 2024 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Multimodal Data Integration for Precision Oncology: Challenges and Future Directions</title>
      <link>https://arxiv.org/abs/2406.19611</link>
      <description>arXiv:2406.19611v1 Announce Type: new 
Abstract: The essence of precision oncology lies in its commitment to tailor targeted treatments and care measures to each patient based on the individual characteristics of the tumor. The inherent heterogeneity of tumors necessitates gathering information from diverse data sources to provide valuable insights from various perspectives, fostering a holistic comprehension of the tumor. Over the past decade, multimodal data integration technology for precision oncology has made significant strides, showcasing remarkable progress in understanding the intricate details within heterogeneous data modalities. These strides have exhibited tremendous potential for improving clinical decision-making and model interpretation, contributing to the advancement of cancer care and treatment. Given the rapid progress that has been achieved, we provide a comprehensive overview of about 300 papers detailing cutting-edge multimodal data integration techniques in precision oncology. In addition, we conclude the primary clinical applications that have reaped significant benefits, including early assessment, diagnosis, prognosis, and biomarker discovery. Finally, derived from the findings of this survey, we present an in-depth analysis that explores the pivotal challenges and reveals essential pathways for future research in the field of multimodal data integration for precision oncology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19611v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huajun Zhou, Fengtao Zhou, Chenyu Zhao, Yingxue Xu, Luyang Luo, Hao Chen</dc:creator>
    </item>
    <item>
      <title>ProtSolM: Protein Solubility Prediction with Multi-modal Features</title>
      <link>https://arxiv.org/abs/2406.19744</link>
      <description>arXiv:2406.19744v1 Announce Type: new 
Abstract: Understanding protein solubility is essential for their functional applications. Computational methods for predicting protein solubility are crucial for reducing experimental costs and enhancing the efficiency and success rates of protein engineering. Existing methods either construct a supervised learning scheme on small-scale datasets with manually processed physicochemical properties, or blindly apply pre-trained protein language models to extract amino acid interaction information. The scale and quality of available training datasets leave significant room for improvement in terms of accuracy and generalization. To address these research gaps, we propose \sol, a novel deep learning method that combines pre-training and fine-tuning schemes for protein solubility prediction. ProtSolM integrates information from multiple dimensions, including physicochemical properties, amino acid sequences, and protein backbone structures. Our model is trained using \data, the largest solubility dataset that we have constructed. PDBSol includes over $60,000$ protein sequences and structures. We provide a comprehensive leaderboard of existing statistical learning and deep learning methods on independent datasets with computational and experimental labels. ProtSolM achieved state-of-the-art performance across various evaluation metrics, demonstrating its potential to significantly advance the accuracy of protein solubility prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19744v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Tan, Jia Zheng, Liang Hong, Bingxin Zhou</dc:creator>
    </item>
    <item>
      <title>Protein Representation Learning with Sequence Information Embedding: Does it Always Lead to a Better Performance?</title>
      <link>https://arxiv.org/abs/2406.19755</link>
      <description>arXiv:2406.19755v1 Announce Type: new 
Abstract: Deep learning has become a crucial tool in studying proteins. While the significance of modeling protein structure has been discussed extensively in the literature, amino acid types are typically included in the input as a default operation for many inference tasks. This study demonstrates with structure alignment task that embedding amino acid types in some cases may not help a deep learning model learn better representation. To this end, we propose ProtLOCA, a local geometry alignment method based solely on amino acid structure representation. The effectiveness of ProtLOCA is examined by a global structure-matching task on protein pairs with an independent test dataset based on CATH labels. Our method outperforms existing sequence- and structure-based representation learning methods by more quickly and accurately matching structurally consistent protein domains. Furthermore, in local structure pairing tasks, ProtLOCA for the first time provides a valid solution to highlight common local structures among proteins with different overall structures but the same function. This suggests a new possibility for using deep learning methods to analyze protein structure to infer function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19755v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Tan, Lirong Zheng, Bozitao Zhong, Liang Hong, Bingxin Zhou</dc:creator>
    </item>
    <item>
      <title>Enhancing Terrestrial Net Primary Productivity Estimation with EXP-CASA: A Novel Light Use Efficiency Model Approach</title>
      <link>https://arxiv.org/abs/2406.19969</link>
      <description>arXiv:2406.19969v1 Announce Type: new 
Abstract: The Light Use Efficiency model, epitomized by the CASA model, is extensively applied in the quantitative estimation of vegetation Net Primary Productivity. However, the classic CASA model is marked by significant complexity: the estimation of environmental stress parameters, in particular, necessitates multi-source observation data, adding to the complexity and uncertainty of the model's operation. Additionally, the saturation effect of the Normalized Difference Vegetation Index (NDVI), a key variable in the CASA model, weakened the accuracy of CASA's NPP predictions in densely vegetated areas. To address these limitations, this study introduces the Exponential-CASA (EXP-CASA) model. The EXP-CASA model effectively improves the CASA model by using novel functions for estimating the fraction of absorbed photosynthetically active radiation (FPAR) and environmental stress, by utilizing long-term observational data from FLUXNET and MODIS surface reflectance data. In a comparative analysis of NPP estimation accuracy among four different NPP products, EXP-CASA ($R^2 = 0.68, RMSE= 1.1gC\cdot m^{-2} \cdot d^{-1}$) outperforms others, followed by GLASS-NPP, and lastly MODIS-NPP and classic CASA. Additionally, this research assesses the EXP-CASA model's adaptability to various vegetation indices, evaluates the sensitivity and stability of its parameters over time, and compares its accuracy against other leading NPP estimation products. The findings reveal that the EXP-CASA model exhibits strong adaptability to diverse vegetation indices and stability of model parameters over time series. By introducing a novel estimation approach that optimizes model construction, the EXP-CASA model remarkably improves the accuracy of NPP estimations and paves the way for global-scale, consistent, and continuous assessment of vegetation NPP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19969v1</guid>
      <category>q-bio.QM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanzhou Chen, Kaiqi Zhang, Xiaodong Zhang, Hong Xie, Haobo Yang, Xiaoliang Tan, Tong Wang, Yule Ma, Qing Wang, Jinzhou Cao, Weihong Cui</dc:creator>
    </item>
    <item>
      <title>Approximate solutions of a general stochastic velocity-jump process subject to discrete-time noisy observations</title>
      <link>https://arxiv.org/abs/2406.19787</link>
      <description>arXiv:2406.19787v1 Announce Type: cross 
Abstract: Advances in experimental techniques allow the collection of high-space-and-time resolution data that track individual motile entities over time. This poses the question of how to use these data to efficiently and effectively calibrate motion models. However, typical mathematical models often overlook the inherent aspects of data collection, such as the discreteness and the experimental noise of the measured locations. In this paper, we focus on velocity-jump models suitable to describe single-agent motion in one spatial dimension, characterised by successive Markovian transitions between a finite network of $n$ states, each with a specified velocity and a fixed rate of switching to every other state. Since the problem of finding the exact distributions of discrete-time noisy data is generally intractable, we derive a series of approximations for the data distributions and compare them to in-silico data generated by the models using four example network structures. These comparisons suggest that the approximations are accurate given sufficiently infrequent state switching, or equivalently, a sufficiently high data collection frequency. Moreover, for infrequent switching, the PDFs comparisons highlight the importance of accounting for the correlation between subsequent measured locations, due to the likely permanence in the state visited in the previous measurement. The approximate distributions computed can be used for fast parameter inference and model selection between a range of velocity-jump models using single-agent tracking data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19787v1</guid>
      <category>physics.data-an</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arianna Ceccarelli, Alexander P. Browning, Ruth E. Baker</dc:creator>
    </item>
    <item>
      <title>On the Value of PHH3 for Mitotic Figure Detection on H&amp;E-stained Images</title>
      <link>https://arxiv.org/abs/2406.19899</link>
      <description>arXiv:2406.19899v1 Announce Type: cross 
Abstract: The count of mitotic figures (MFs) observed in hematoxylin and eosin (H&amp;E)-stained slides is an important prognostic marker as it is a measure for tumor cell proliferation. However, the identification of MFs has a known low inter-rater agreement. Deep learning algorithms can standardize this task, but they require large amounts of annotated data for training and validation. Furthermore, label noise introduced during the annotation process may impede the algorithm's performance. Unlike H&amp;E, the mitosis-specific antibody phospho-histone H3 (PHH3) specifically highlights MFs. Counting MFs on slides stained against PHH3 leads to higher agreement among raters and has therefore recently been used as a ground truth for the annotation of MFs in H&amp;E. However, as PHH3 facilitates the recognition of cells indistinguishable from H&amp;E stain alone, the use of this ground truth could potentially introduce noise into the H&amp;E-related dataset, impacting model performance. This study analyzes the impact of PHH3-assisted MF annotation on inter-rater reliability and object level agreement through an extensive multi-rater experiment. We found that the annotators' object-level agreement increased when using PHH3-assisted labeling. Subsequently, MF detectors were evaluated on the resulting datasets to investigate the influence of PHH3-assisted labeling on the models' performance. Additionally, a novel dual-stain MF detector was developed to investigate the interpretation-shift of PHH3-assisted labels used in H&amp;E, which clearly outperformed single-stain detectors. However, the PHH3-assisted labels did not have a positive effect on solely H&amp;E-based models. The high performance of our dual-input detector reveals an information mismatch between the H&amp;E and PHH3-stained images as the cause of this effect.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19899v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jonathan Ganz, Christian Marzahl, Jonas Ammeling, Barbara Richter, Chlo\'e Puget, Daniela Denk, Elena A. Demeter, Flaviu A. Tabaran, Gabriel Wasinger, Karoline Lipnik, Marco Tecilla, Matthew J. Valentine, Michael J. Dark, Niklas Abele, Pompei Bolfa, Ramona Erber, Robert Klopfleisch, Sophie Merz, Taryn A. Donovan, Samir Jabari, Christof A. Bertram, Katharina Breininger, Marc Aubreville</dc:creator>
    </item>
    <item>
      <title>A Closed-Form Solution to the 2-Sample Problem for Quantifying Changes in Gene Expression using Bayes Factors</title>
      <link>https://arxiv.org/abs/2406.19989</link>
      <description>arXiv:2406.19989v1 Announce Type: cross 
Abstract: Sequencing technologies have revolutionised the field of molecular biology. We now have the ability to routinely capture the complete RNA profile in tissue samples. This wealth of data allows for comparative analyses of RNA levels at different times, shedding light on the dynamics of developmental processes, and under different environmental responses, providing insights into gene expression regulation and stress responses. However, given the inherent variability of the data stemming from biological and technological sources, quantifying changes in gene expression proves to be a statistical challenge. Here, we present a closed-form Bayesian solution to this problem. Our approach is tailored to the differential gene expression analysis of processed RNA-Seq data. The framework unifies and streamlines an otherwise complex analysis, typically involving parameter estimations and multiple statistical tests, into a concise mathematical equation for the calculation of Bayes factors. Using conjugate priors we can solve the equations analytically. For each gene, we calculate a Bayes factor, which can be used for ranking genes according to the statistical evidence for the gene's expression change given RNA-Seq data. The presented closed-form solution is derived under minimal assumptions and may be applied to a variety of other 2-sample problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19989v1</guid>
      <category>stat.ME</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Franziska Hoerbst, Gurpinder Singh Sidhu, Melissa Tomkins, Richard J. Morris</dc:creator>
    </item>
    <item>
      <title>Digital Twin Calibration for Biological System-of-Systems: Cell Culture Manufacturing Process</title>
      <link>https://arxiv.org/abs/2405.03913</link>
      <description>arXiv:2405.03913v2 Announce Type: replace 
Abstract: Biomanufacturing innovation relies on an efficient Design of Experiments (DoEs) to optimize processes and product quality. Traditional DoE methods, ignoring the underlying bioprocessing mechanisms, often suffer from a lack of interpretability and sample efficiency. This limitation motivates us to create a new optimal learning approach for digital twin model calibration. In this study, we consider the cell culture process multi-scale mechanistic model, also known as Biological System-of-Systems (Bio-SoS). This model with a modular design, composed of sub-models, allows us to integrate data across various production processes. To calibrate the Bio-SoS digital twin, we evaluate the mean squared error of model prediction and develop a computational approach to quantify the impact of parameter estimation error of individual sub-models on the prediction accuracy of digital twin, which can guide sample-efficient and interpretable DoEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03913v2</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fuqiang Cheng, Wei Xie, Hua Zheng</dc:creator>
    </item>
    <item>
      <title>Bioptic -- A Target-Agnostic Efficacy-Based Small Molecules Search Engine</title>
      <link>https://arxiv.org/abs/2406.14572</link>
      <description>arXiv:2406.14572v2 Announce Type: replace 
Abstract: Recent successes in virtual screening have been made possible by large models and extensive chemical libraries. However, combining these elements is challenging: the larger the model, the more expensive it is to run, making ultra-large libraries unfeasible. To address this, we developed a target-agnostic, efficacy-based molecule search model, which allows us to find structurally dissimilar molecules with similar biological activities. We used the best practices to design fast retrieval system, based on processor-optimized SIMD instructions, enabling us to screen the ultra-large 40B Enamine REAL library with 100\% recall rate. We extensively benchmarked our model and several state-of-the-art models for both speed performance and retrieval quality of novel molecules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14572v2</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vlad Vinogradov, Ivan Izmailov, Simon Steshin, Kong T. Nguyen</dc:creator>
    </item>
    <item>
      <title>Sequential Model for Predicting Patient Adherence in Subcutaneous Immunotherapy for Allergic Rhinitis</title>
      <link>https://arxiv.org/abs/2401.11447</link>
      <description>arXiv:2401.11447v4 Announce Type: replace-cross 
Abstract: Objective: Subcutaneous Immunotherapy (SCIT) is the long-lasting causal treatment of allergic rhinitis (AR). How to enhance the adherence of patients to maximize the benefit of allergen immunotherapy (AIT) plays a crucial role in the management of AIT. This study aims to leverage novel machine learning models to precisely predict the risk of non-adherence of AR patients and related local symptom scores in three years SCIT.
  Methods: The research develops and analyzes two models, sequential latent-variable model (SLVM) of Sequential Latent Actor-Critic (SLAC) and Long Short-Term Memory (LSTM) evaluating them based on scoring and adherence prediction capabilities.
  Results: Excluding the biased samples at the first time step, the predictive adherence accuracy of the SLAC models is from 60\% to 72\%, and for LSTM models, it is 66\% to 84\%, varying according to the time steps. The range of Root Mean Square Error (RMSE) for SLAC models is between 0.93 and 2.22, while for LSTM models it is between 1.09 and 1.77. Notably, these RMSEs are significantly lower than the random prediction error of 4.55.
  Conclusion: We creatively apply sequential models in the long-term management of SCIT with promising accuracy in the prediction of SCIT nonadherence in AR patients. While LSTM outperforms SLAC in adherence prediction, SLAC excels in score prediction for patients undergoing SCIT for AR. The state-action-based SLAC adds flexibility, presenting a novel and effective approach for managing long-term AIT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11447v4</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yin Li, Yu Xiong, Wenxin Fan, Kai Wang, Qingqing Yu, Liping Si, Patrick van der Smagt, Jun Tang, Nutan Chen</dc:creator>
    </item>
    <item>
      <title>Deformable MRI Sequence Registration for AI-based Prostate Cancer Diagnosis</title>
      <link>https://arxiv.org/abs/2404.09666</link>
      <description>arXiv:2404.09666v2 Announce Type: replace-cross 
Abstract: The PI-CAI (Prostate Imaging: Cancer AI) challenge led to expert-level diagnostic algorithms for clinically significant prostate cancer detection. The algorithms receive biparametric MRI scans as input, which consist of T2-weighted and diffusion-weighted scans. These scans can be misaligned due to multiple factors in the scanning process. Image registration can alleviate this issue by predicting the deformation between the sequences. We investigate the effect of image registration on the diagnostic performance of AI-based prostate cancer diagnosis. First, the image registration algorithm, developed in MeVisLab, is analyzed using a dataset with paired lesion annotations. Second, the effect on diagnosis is evaluated by comparing case-level cancer diagnosis performance between using the original dataset, rigidly aligned diffusion-weighted scans, or deformably aligned diffusion-weighted scans. Rigid registration showed no improvement. Deformable registration demonstrated a substantial improvement in lesion overlap (+10% median Dice score) and a positive yet non-significant improvement in diagnostic performance (+0.3% AUROC, p=0.18). Our investigation shows that a substantial improvement in lesion alignment does not directly lead to a significant improvement in diagnostic performance. Qualitative analysis indicated that jointly developing image registration methods and diagnostic AI algorithms could enhance diagnostic accuracy and patient outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09666v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessa Hering, Sarah de Boer, Anindo Saha, Jasper J. Twilt, Mattias P. Heinrich, Derya Yakar, Maarten de Rooij, Henkjan Huisman, Joeran S. Bosma</dc:creator>
    </item>
    <item>
      <title>Bayesian analysis of biomarker levels can predict time of recurrence of prostate cancer with strictly positive apparent Shannon information against an exponential attrition prior</title>
      <link>https://arxiv.org/abs/2404.17857</link>
      <description>arXiv:2404.17857v2 Announce Type: replace-cross 
Abstract: Shariat et al previously investigated the possibility of predicting from clinical data (including Gleason grade and stage) and preoperative biomarkers, which of any pair of patients would suffer recurrence of prostate cancer first. We wished to establish the extent to which predictions of time of relapse from such a model could be improved upon using Bayesian methods.
  The same dataset was reanalysed with a Bayesian skew-Student mixture model. Predictions were made of which of any pair of patients would relapse first and of the time of relapse. The benefit of using these biomarkers relative to predictions made without them was measured by the apparent Shannon information, using as prior an exponential attrition model of relapse time independent of input variables.
  Using half the dataset for training and the other half for testing, predictions of relapse time from the strict Cox model gave $-\infty$ nepers of apparent Shannon information (it predicts that relapse can only occur at times when patients in the training set relapsed). Deliberately smoothed predictions from the Cox model gave -0.001 (-0.131 to +0.120) nepers, while the Bayesian model gave +0.109 (+0.021 to +0.192) nepers (mean, 2.5 to 97.5 centiles), being positive with posterior probability 0.993 and beating the blurred Cox model with posterior probability 0.927.
  These predictions from the Bayesian model thus outperform those of the Cox model, but the overall yield of predictive information leaves scope for improvement of the range of biomarkers in use. The Bayesian model presented here is the first such model for prostate cancer to consider the variation of relapse hazard with biomarker concentrations to be smooth, as is intuitive. It is also the first to be shown to provide more apparent Shannon information than the Cox model or to be shown to provide positive apparent information relative to an exponential prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17857v2</guid>
      <category>stat.AP</category>
      <category>q-bio.QM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Roger Sewell, Elisabeth Crowe, Sharokh F. Shariat</dc:creator>
    </item>
  </channel>
</rss>
