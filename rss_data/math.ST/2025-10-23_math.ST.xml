<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 23 Oct 2025 04:00:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Shrinkage to Infinity: Reducing Test Error by Inflating the Minimum Norm Interpolator in Linear Models</title>
      <link>https://arxiv.org/abs/2510.19206</link>
      <description>arXiv:2510.19206v1 Announce Type: new 
Abstract: Hastie et al. (2022) found that ridge regularization is essential in high dimensional linear regression $y=\beta^Tx + \epsilon$ with isotropic co-variates $x\in \mathbb{R}^d$ and $n$ samples at fixed $d/n$. However, Hastie et al. (2022) also notes that when the co-variates are anisotropic and $\beta$ is aligned with the top eigenvalues of population covariance, the "situation is qualitatively different." In the present article, we make precise this observation for linear regression with highly anisotropic covariances and diverging $d/n$. We find that simply scaling up (or inflating) the minimum $\ell_2$ norm interpolator by a constant greater than one can improve the generalization error. This is in sharp contrast to traditional regularization/shrinkage prescriptions. Moreover, we use a data-splitting technique to produce consistent estimators that achieve generalization error comparable to that of the optimally inflated minimum-norm interpolator. Our proof relies on apparently novel matching upper and lower bounds for expectations of Gaussian random projections for a general class of anisotropic covariance matrices when $d/n\to \infty$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19206v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jake Freeman</dc:creator>
    </item>
    <item>
      <title>Error Analysis of Triangular Optimal Transport Maps for Filtering</title>
      <link>https://arxiv.org/abs/2510.19283</link>
      <description>arXiv:2510.19283v1 Announce Type: new 
Abstract: We present a systematic analysis of estimation errors for a class of optimal transport based algorithms for filtering and data assimilation. Along the way, we extend previous error analyses of Brenier maps to the case of conditional Brenier maps that arise in the context of simulation based inference. We then apply these results in a filtering scenario to analyze the optimal transport filtering algorithm of Al-Jarrah et al. (2024, ICML). An extension of that algorithm along with numerical benchmarks on various non-Gaussian and high-dimensional examples are provided to demonstrate its effectiveness and practical potential.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19283v1</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Al-Jarrah, Bamdad Hosseini, Niyizhen Jin, Michele Martino, Amirhossein Taghvaei</dc:creator>
    </item>
    <item>
      <title>Probabilistic PCA on tensors</title>
      <link>https://arxiv.org/abs/2510.19516</link>
      <description>arXiv:2510.19516v1 Announce Type: new 
Abstract: In probabilistic principal component analysis (PPCA), an observed vector is modeled as a linear transformation of a low-dimensional Gaussian factor plus isotropic noise. We generalize PPCA to tensors by constraining the loading operator to have Tucker structure, yielding a probabilistic multilinear PCA model that enables uncertainty quantification and naturally accommodates multiple, possibly heterogeneous, tensor observations. We develop the associated theory: we establish identifiability of the loadings and noise variance and show that-unlike in matrix PPCA-the maximum likelihood estimator (MLE) exists even from a single tensor sample. We then study two estimators. First, we consider the MLE and propose an expectation maximization (EM) algorithm to compute it. Second, exploiting that Tucker maps correspond to rank-one elements after a Kronecker lifting, we design a computationally efficient estimator for which we provide provable finite-sample guarantees. Together, these results provide a coherent probabilistic framework and practical algorithms for learning from tensor-valued data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19516v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaoming Zhen, Piotr Zwiernik</dc:creator>
    </item>
    <item>
      <title>Ranking Statistical Experiments via the Linear Convex Order and the Lorenz Zonoid: Economic Applications</title>
      <link>https://arxiv.org/abs/2502.06530</link>
      <description>arXiv:2502.06530v11 Announce Type: cross 
Abstract: This paper introduces a novel ranking of statistical experiments, the Linear-Blackwell (LB) order, equivalently characterized by (i) more dispersed posteriors and likelihood ratios in the sense of the linear convex order, (ii) a larger Lorenz zonoid--the set of statewise profiles spanned by signals, and (iii) greater variability of the posterior mean. We apply the LB order to compare experiments in binary-action decision problems and in problems with quasiconcave payoffs, as analyzed by Kolotilin, Corrao, and Wolitzky (2025). Furthermore, the LB order enables the comparison of experiments in moral hazard problems, complementing the findings in Holmstr\"om (1979) and Kim (1995). Finally, the LB order applies to the comparison of experiments generating ex post signals in screening problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06530v11</guid>
      <category>econ.TH</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kailin Chen</dc:creator>
    </item>
    <item>
      <title>Centered MA Dirichlet ARMA for Financial Compositions: Theory &amp; Empirical Evidence</title>
      <link>https://arxiv.org/abs/2510.18903</link>
      <description>arXiv:2510.18903v1 Announce Type: cross 
Abstract: Observation-driven Dirichlet models for compositional time series often use the additive log-ratio (ALR) link and include a moving-average (MA) term built from ALR residuals. In the standard B--DARMA recursion, the usual MA regressor $\alr(\mathbf{Y}_t)-\boldsymbol{\eta}_t$ has nonzero conditional mean under the Dirichlet likelihood, which biases the mean path and blurs the interpretation of MA coefficients. We propose a minimal change: replace the raw regressor with a \emph{centered} innovation $\boldsymbol{\epsilon}_t^{\circ}=\alr(\mathbf{Y}_t)-\mathbb{E}\{\alr(\mathbf{Y}_t)\mid \boldsymbol{\eta}_t,\phi_t\}$, computable in closed form via digamma functions. Centering restores mean-zero innovations for the MA block without altering either the likelihood or the ALR link. We provide simple identities for the conditional mean and the forecast recursion, show first-order equivalence to a digamma-link DARMA while retaining a closed-form inverse to $\boldsymbol{\mu}_t$, and give ready-to-use code. A weekly application to the Federal Reserve H.8 bank-asset composition compares the original (raw-MA) and centered specifications under a fixed holdout and rolling one-step origins. The centered formulation improves log predictive scores with essentially identical point error and markedly cleaner Hamiltonian Monte Carlo diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.18903v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>q-fin.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harrison Katz</dc:creator>
    </item>
    <item>
      <title>Estimation of causal dose-response functions under data fusion</title>
      <link>https://arxiv.org/abs/2510.19094</link>
      <description>arXiv:2510.19094v1 Announce Type: cross 
Abstract: Estimating the causal dose-response function is challenging, particularly when data from a single source are insufficient to estimate responses precisely across all exposure levels. To overcome this limitation, we propose a data fusion framework that leverages multiple data sources that are partially aligned with the target distribution. Specifically, we derive a Neyman-orthogonal loss function tailored for estimating the dose-response function within data fusion settings. To improve computational efficiency, we propose a stochastic approximation that retains orthogonality. We apply kernel ridge regression with this approximation, which provides closed-form estimators. Our theoretical analysis demonstrates that incorporating additional data sources yields tighter finite-sample regret bounds and improved worst-case performance, as confirmed via minimax lower bound comparison. Simulation studies validate the practical advantages of our approach, showing improved estimation accuracy when employing data fusion. This study highlights the potential of data fusion for estimating non-smooth parameters such as causal dose-response functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19094v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaewon Lim, Alex Luedtke</dc:creator>
    </item>
    <item>
      <title>Learning Upper Lower Value Envelopes to Shape Online RL: A Principled Approach</title>
      <link>https://arxiv.org/abs/2510.19528</link>
      <description>arXiv:2510.19528v1 Announce Type: cross 
Abstract: We investigate the fundamental problem of leveraging offline data to accelerate online reinforcement learning - a direction with strong potential but limited theoretical grounding. Our study centers on how to learn and apply value envelopes within this context. To this end, we introduce a principled two-stage framework: the first stage uses offline data to derive upper and lower bounds on value functions, while the second incorporates these learned bounds into online algorithms. Our method extends prior work by decoupling the upper and lower bounds, enabling more flexible and tighter approximations. In contrast to approaches that rely on fixed shaping functions, our envelopes are data-driven and explicitly modeled as random variables, with a filtration argument ensuring independence across phases. The analysis establishes high-probability regret bounds determined by two interpretable quantities, thereby providing a formal bridge between offline pre-training and online fine-tuning. Empirical results on tabular MDPs demonstrate substantial regret reductions compared with both UCBVI and prior methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19528v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Reboul, H\'el\`ene Halconruy, Randal Douc</dc:creator>
    </item>
    <item>
      <title>Robust Rank Estimation for Noisy Matrices</title>
      <link>https://arxiv.org/abs/2510.19583</link>
      <description>arXiv:2510.19583v1 Announce Type: cross 
Abstract: Estimating the true rank of a noisy data matrix is a fundamental problem underlying techniques such as principal component analysis, matrix completion, etc. Existing rank estimation criteria, including information-based and cross-validation methods, are either highly sensitive to outliers or computationally demanding when combined with robust estimators. This paper proposes a new criterion, the Divergence Information Criterion for Matrix Rank (DICMR), that achieves both robustness and computational simplicity. Derived from the density power divergence framework, DICMR inherits the robustness properties while being computationally very simple. We provide asymptotic bounds on its overestimation and underestimation probabilities, and demonstrate first-order B-robustness of the criteria. Extensive simulations show that DICMR delivers accuracy comparable to the robustified cross-validation methods, but with far lower computational cost. We also showcase a real-data application to microarray imputation to further demonstrate its practical utility, outperforming several state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19583v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Subhrajyoty Roy, Abhik Ghosh, Ayanendranath Basu</dc:creator>
    </item>
    <item>
      <title>Statistical Inference for Linear Functionals of Online Least-squares SGD when $t \gtrsim d^{1+\delta}$</title>
      <link>https://arxiv.org/abs/2510.19734</link>
      <description>arXiv:2510.19734v1 Announce Type: cross 
Abstract: Stochastic Gradient Descent (SGD) has become a cornerstone method in modern data science. However, deploying SGD in high-stakes applications necessitates rigorous quantification of its inherent uncertainty. In this work, we establish \emph{non-asymptotic Berry--Esseen bounds} for linear functionals of online least-squares SGD, thereby providing a Gaussian Central Limit Theorem (CLT) in a \emph{growing-dimensional regime}. Existing approaches to high-dimensional inference for projection parameters, such as~\cite{chang2023inference}, rely on inverting empirical covariance matrices and require at least $t \gtrsim d^{3/2}$ iterations to achieve finite-sample Berry--Esseen guarantees, rendering them computationally expensive and restrictive in the allowable dimensional scaling. In contrast, we show that a CLT holds for SGD iterates when the number of iterations grows as $t \gtrsim d^{1+\delta}$ for any $\delta &gt; 0$, significantly extending the dimensional regime permitted by prior works while improving computational efficiency. The proposed online SGD-based procedure operates in $\mathcal{O}(td)$ time and requires only $\mathcal{O}(d)$ memory, in contrast to the $\mathcal{O}(td^2 + d^3)$ runtime of covariance-inversion methods. To render the theory practically applicable, we further develop an \emph{online variance estimator} for the asymptotic variance appearing in the CLT and establish \emph{high-probability deviation bounds} for this estimator. Collectively, these results yield the first fully online and data-driven framework for constructing confidence intervals for SGD iterates in the near-optimal scaling regime $t \gtrsim d^{1+\delta}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.19734v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bhavya Agrawalla, Krishnakumar Balasubramanian, Promit Ghosal</dc:creator>
    </item>
    <item>
      <title>Survey Data Integration for Distribution Function Estimation</title>
      <link>https://arxiv.org/abs/2409.14284</link>
      <description>arXiv:2409.14284v4 Announce Type: replace 
Abstract: We propose a novel CDF estimator that integrates data from probability samples with data from, potentially big, nonprobability samples. Assuming that a set of shared covariates are observed in both, while the response variable is observed only in the latter, the proposed estimator uses a survey-weighted empirical CDF of regression residuals trained on the convenience sample to estimate the CDF of the response variable. Under some assumptions, we derive the asymptotic bias and variance of our CDF estimator and show that it is asymptotically unbiased for the finite population CDF if ignorability holds. Empirical results demonstrate that the estimator performs well under model misspecification when ignorability holds, and under nonignorable sampling when the outcome model is correctly specified. Even when both assumptions fail, the residual-based estimator continues to outperform its plug-in and na\"ive counterparts, albeit with noted decreases in efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14284v4</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeremy Flood, Sayed Mostafa</dc:creator>
    </item>
    <item>
      <title>Generalizing while preserving monotonicity in comparison-based preference learning models</title>
      <link>https://arxiv.org/abs/2506.08616</link>
      <description>arXiv:2506.08616v3 Announce Type: replace 
Abstract: If you tell a learning model that you prefer an alternative $a$ over another alternative $b$, then you probably expect the model to be monotone, that is, the valuation of $a$ increases, and that of $b$ decreases. Yet, perhaps surprisingly, many widely deployed comparison-based preference learning models, including large language models, fail to have this guarantee. Until now, the only comparison-based preference learning algorithms that were proved to be monotone are the Generalized Bradley-Terry models. Yet, these models are unable to generalize to uncompared data. In this paper, we advance the understanding of the set of models with generalization ability that are monotone. Namely, we propose a new class of Linear Generalized Bradley-Terry models with Diffusion Priors, and identify sufficient conditions on alternatives' embeddings that guarantee monotonicity. Our experiments show that this monotonicity is far from being a general guarantee, and that our new class of generalizing models improves accuracy, especially when the dataset is limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.08616v3</guid>
      <category>math.ST</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Fageot, Peva Blanchard, Gilles Bareilles, L\^e-Nguy\^en Hoang</dc:creator>
    </item>
    <item>
      <title>Efficient Sampling for Realized Variance Estimation in Time-Changed Diffusion Models</title>
      <link>https://arxiv.org/abs/2212.11833</link>
      <description>arXiv:2212.11833v4 Announce Type: replace-cross 
Abstract: This paper analyzes the benefits of sampling intraday returns in intrinsic time for the realized variance (RV) estimator. We theoretically show in finite samples that depending on the permitted sampling information, the RV estimator is most efficient under either hitting time sampling that samples whenever the price changes by a pre-determined threshold, or under the new concept of realized business time that samples according to a combination of observed trades and estimated tick variance. The analysis builds on the assumption that asset prices follow a diffusion that is time-changed with a jump process that separately models the transaction times. This provides a flexible model that allows for leverage specifications and Hawkes-type jump processes and separately captures the empirically varying trading intensity and tick variance processes, which are particularly relevant for disentangling the driving forces of the sampling schemes. Extensive simulations confirm our theoretical results and show that for low levels of noise, hitting time sampling remains superior while for increasing noise levels, realized business time becomes the empirically most efficient sampling scheme. An application to stock data provides empirical evidence for the benefits of using these intrinsic sampling schemes to construct more efficient RV estimators as well as for an improved forecast performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11833v4</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>q-fin.RM</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Dimitriadis, Roxana Halbleib, Jeannine Polivka, Jasper Rennspies, Sina Streicher, Axel Friedrich Wolter</dc:creator>
    </item>
    <item>
      <title>Limit Theorems for One-Dimensional Homogenized Diffusion Processes</title>
      <link>https://arxiv.org/abs/2503.06691</link>
      <description>arXiv:2503.06691v2 Announce Type: replace-cross 
Abstract: We present two limit theorems, a mean ergodic and a central limit theorem, for a specific class of one-dimensional diffusion processes that depend on a small-scale parameter $\varepsilon$ and converge weakly to a homogenized diffusion process in the limit $\varepsilon \rightarrow 0$. In these results, we allow for the time horizon to blow up such that $T_\varepsilon \rightarrow \infty$ as $\varepsilon \rightarrow 0$. The novelty of the results arises from the circumstance that many quantities are unbounded for $\varepsilon \rightarrow 0$, so that formerly established theory is not directly applicable here and a careful investigation of all relevant $\varepsilon$-dependent terms is required. As a mathematical application, we then use these limit theorems to prove asymptotic properties of a minimum distance estimator for parameters in a homogenized diffusion equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06691v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaroslav I. Borodavka, Sebastian Krumscheid</dc:creator>
    </item>
    <item>
      <title>Online Conformal Prediction with Efficiency Guarantees</title>
      <link>https://arxiv.org/abs/2507.02496</link>
      <description>arXiv:2507.02496v2 Announce Type: replace-cross 
Abstract: We study the problem of conformal prediction in a novel online framework that directly optimizes efficiency. In our problem, we are given a target miscoverage rate $\alpha &gt; 0$, and a time horizon $T$. On each day $t \le T$ an algorithm must output an interval $I_t \subseteq [0, 1]$, then a point $y_t \in [0, 1]$ is revealed. The goal of the algorithm is to achieve coverage, that is, $y_t \in I_t$ on (close to) a $(1 - \alpha)$-fraction of days, while maintaining efficiency, that is, minimizing the average volume (length) of the intervals played. This problem is an online analogue to the problem of constructing efficient confidence intervals.
  We study this problem over arbitrary and exchangeable (random order) input sequences. For exchangeable sequences, we show that it is possible to construct intervals that achieve coverage $(1 - \alpha) - o(1)$, while having length upper bounded by the best fixed interval that achieves coverage in hindsight. For arbitrary sequences however, we show that any algorithm that achieves a $\mu$-approximation in average length compared to the best fixed interval achieving coverage in hindsight, must make a multiplicative factor more mistakes than $\alpha T$, where the multiplicative factor depends on $\mu$ and the aspect ratio of the problem. Our main algorithmic result is a matching algorithm that can recover all Pareto-optimal settings of $\mu$ and number of mistakes. Furthermore, our algorithm is deterministic and therefore robust to an adaptive adversary.
  This gap between the exchangeable and arbitrary settings is in contrast to the classical online learning problem. In fact, we show that no single algorithm can simultaneously be Pareto-optimal for arbitrary sequences and optimal for exchangeable sequences. On the algorithmic side, we give an algorithm that achieves the near-optimal tradeoff between the two cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02496v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vaidehi Srinivas</dc:creator>
    </item>
    <item>
      <title>Loss Functions for Detecting Outliers in Panel Data</title>
      <link>https://arxiv.org/abs/2509.07014</link>
      <description>arXiv:2509.07014v2 Announce Type: replace-cross 
Abstract: The detection of outliers is of critical importance in the assurance of data quality. Outliers may exist in observed data or in data derived from these observed data, such as estimates and forecasts. An outlier may indicate a problem with its data generation process or may simply be a true, but unusual, statement about the world. Without making any distributional assumptions, we proposes the use of loss functions to detect these outliers in panel data.
  Part I covers nonnegative data. We axiomatically derive an unsigned loss function. We then develop a signed loss function ito account for positive and negative outliers separately. In the case of nominal time we obtain an exact parametrization of the loss function. A time-invariant loss function permits the comparison of data at multiple times on the same basis. We provide several examples, including an example in which the outliers are classified by another variable.
  Part II covers data of mixed sign. Similar to Part I, we axiomatically develop unsigned and signed loss functions. We search for optimal values of the loss function parameter using graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07014v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Charles D. Coleman, Thomas Bryan</dc:creator>
    </item>
    <item>
      <title>The Coverage Principle: How Pre-Training Enables Post-Training</title>
      <link>https://arxiv.org/abs/2510.15020</link>
      <description>arXiv:2510.15020v2 Announce Type: replace-cross 
Abstract: Language models demonstrate remarkable abilities when pre-trained on large text corpora and fine-tuned for specific tasks, but how and why pre-training shapes the success of the final model remains poorly understood. Notably, although pre-training success is often quantified by cross-entropy loss, cross-entropy can be a poor predictor of downstream performance. Instead, we provide a theoretical perspective on this relationship through the lens of \emph{coverage}, which quantifies the probability mass the pre-trained model places on high-quality responses and which is necessary and sufficient for post-training and test-time scaling methods such as Best-of-N to succeed. Our main results develop an understanding of \emph{the coverage principle}, a phenomenon whereby next-token prediction (more generally, maximum likelihood) implicitly optimizes toward a model with good coverage. In particular, we uncover a mechanism that explains the power of coverage in predicting downstream performance: \emph{coverage generalizes faster than cross-entropy}, avoiding spurious dependence on problem-dependent parameters such as the sequence length. We also study practical algorithmic interventions with provable benefits for improving coverage, including (i) model/checkpoint selection procedures, (ii) gradient normalization schemes, and (iii) test-time decoding strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15020v2</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 23 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Chen, Audrey Huang, Noah Golowich, Sadhika Malladi, Adam Block, Jordan T. Ash, Akshay Krishnamurthy, Dylan J. Foster</dc:creator>
    </item>
  </channel>
</rss>
