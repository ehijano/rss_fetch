<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 05:00:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Pandora with Inaccurate Priors</title>
      <link>https://arxiv.org/abs/2502.03574</link>
      <description>arXiv:2502.03574v1 Announce Type: new 
Abstract: We investigate the role of inaccurate priors for the classical Pandora's box problem. In the classical Pandora's box problem we are given a set of boxes each with a known cost and an unknown value sampled from a known distribution. We investigate how inaccuracies in the beliefs can affect existing algorithms. Specifically, we assume that the knowledge of the underlying distribution has a small error in the Kolmogorov distance, and study how this affects the utility obtained by the optimal algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03574v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiarash Banihashem, Xiang Chen, MohammadTaghi Hajiaghayi, Sungchul Kim, Kanak Mahadik, Ryan Rossi, Tong Yu</dc:creator>
    </item>
    <item>
      <title>Fast Geographic Routing in Fixed-Growth Graphs</title>
      <link>https://arxiv.org/abs/2502.03663</link>
      <description>arXiv:2502.03663v1 Announce Type: new 
Abstract: In the 1960s, the social scientist Stanley Milgram performed his famous "small-world" experiments where he found that people in the US who are far apart geographically are nevertheless connected by remarkably short chains of acquaintances. Since then, there has been considerable work to design networks that accurately model the phenomenon that Milgram observed. One well-known approach was Barab{\'a}si and Albert's preferential attachment model, which has small diameter yet lacks an algorithm that can efficiently find those short connections between nodes. Jon Kleinberg, in contrast, proposed a small-world graph formed from an $n \times n$ lattice that guarantees that greedy routing can navigate between any two nodes in $\mathcal{O}(\log^2 n)$ time with high probability. Further work by Goodrich and Ozel and by Gila, Goodrich, and Ozel present a hybrid technique that combines elements from these previous approaches to improve greedy routing time to $\mathcal{O}(\log n)$ hops. These are important theoretical results, but we believe that their reliance on the square lattice limits their application in the real world. In this work, we generalize the model of Gila, Ozel, and Goodrich to any class of what we call fixed-growth graphs of dimensionality $\alpha$, a subset of bounded-growth graphs introduced in several prior papers. We prove tight bounds for greedy routing and diameter in these graphs, both in expectation and with high probability. We then apply our model to the U.S. road network to show that by modeling the network as a fixed-growth graph rather than as a lattice, we are able to improve greedy routing performance over all 50 states. We also show empirically that the optimal clustering exponent for the U.S. road network is much better modeled by the dimensionality of the network $\alpha$ than by the network's size, as was conjectured in a previous work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03663v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ofek Gila, Michael T. Goodrich, Abraham M. Illickan, Vinesh Sridhar</dc:creator>
    </item>
    <item>
      <title>Cascaded Learned Bloom Filter for Optimal Model-Filter Size Balance and Fast Rejection</title>
      <link>https://arxiv.org/abs/2502.03696</link>
      <description>arXiv:2502.03696v1 Announce Type: new 
Abstract: Recent studies have demonstrated that learned Bloom filters, which combine machine learning with the classical Bloom filter, can achieve superior memory efficiency. However, existing learned Bloom filters face two critical unresolved challenges: the balance between the machine learning model size and the Bloom filter size is not optimal, and the reject time cannot be minimized effectively. We propose the Cascaded Learned Bloom Filter (CLBF) to address these issues. Our dynamic programming-based optimization automatically selects configurations that achieve an optimal balance between the model and filter sizes while minimizing reject time. Experiments on real-world datasets show that CLBF reduces memory usage by up to 24% and decreases reject time by up to 14 times compared to state-of-the-art learned Bloom filters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03696v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Atsuki Sato, Yusuke Matsui</dc:creator>
    </item>
    <item>
      <title>Tensor Decomposition Meets Knowledge Compilation: A Study Comparing Tensor Trains with OBDDs</title>
      <link>https://arxiv.org/abs/2502.03702</link>
      <description>arXiv:2502.03702v1 Announce Type: new 
Abstract: A knowledge compilation map analyzes tractable operations in Boolean function representations and compares their succinctness. This enables the selection of appropriate representations for different applications. In the knowledge compilation map, all representation classes are subsets of the negation normal form (NNF). However, Boolean functions may be better expressed by a representation that is different from that of the NNF subsets. In this study, we treat tensor trains as Boolean function representations and analyze their succinctness and tractability. Our study is the first to evaluate the expressiveness of a tensor decomposition method using criteria from knowledge compilation literature. Our main results demonstrate that tensor trains are more succinct than ordered binary decision diagrams (OBDDs) and support the same polytime operations as OBDDs. Our study broadens their application by providing a theoretical link between tensor decomposition and existing NNF subsets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03702v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryoma Onaka, Kengo Nakamura, Masaaki Nishino, Norihito Yasuda</dc:creator>
    </item>
    <item>
      <title>Knowing When to Stop Matters: A Unified Algorithm for Online Conversion under Horizon Uncertainty</title>
      <link>https://arxiv.org/abs/2502.03817</link>
      <description>arXiv:2502.03817v1 Announce Type: new 
Abstract: This paper investigates the online conversion problem, which involves sequentially trading a divisible resource (e.g., energy) under dynamically changing prices to maximize profit. A key challenge in online conversion is managing decisions under horizon uncertainty, where the duration of trading is either known, revealed partway, or entirely unknown. We propose a unified algorithm that achieves optimal competitive guarantees across these horizon models, accounting for practical constraints such as box constraints, which limit the maximum allowable trade per step. Additionally, we extend the algorithm to a learning-augmented version, leveraging horizon predictions to adaptively balance performance: achieving near-optimal results when predictions are accurate while maintaining strong guarantees when predictions are unreliable. These results advance the understanding of online conversion under various degrees of horizon uncertainty and provide more practical strategies to address real world constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03817v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanzhao Wang, Hasti Nourmohammadi Sigaroudi, Bo Sun, Omid Ardakanian, Xiaoqi Tan</dc:creator>
    </item>
    <item>
      <title>Fast In-Spectrum Graph Watermarks</title>
      <link>https://arxiv.org/abs/2502.04182</link>
      <description>arXiv:2502.04182v1 Announce Type: new 
Abstract: We address the problem of watermarking graph objects, which consists in hiding information within them, to prove their origin. The two existing methods to watermark graphs use subgraph matching or graph isomorphism techniques, which are known to be intractable for large graphs. To reduce the operational complexity, we propose FFG, a new graph watermarking scheme adapted from an image watermarking scheme, since graphs and images can be represented as matrices. We analyze and compare FFG, whose novelty lies in embedding the watermark in the Fourier transform of the adjacency matrix of a graph. Our technique enjoys a much lower complexity than that of related works (i.e. in $\mathcal{O}\left(N^2 \log N\right)$), while performing better or at least as well as the two state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04182v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jade Garcia Bourr\'ee, Anne-Marie Kermarrec, Erwan Le Merrer, Othmane Safsafi</dc:creator>
    </item>
    <item>
      <title>Faster run-length compressed suffix arrays</title>
      <link>https://arxiv.org/abs/2408.04537</link>
      <description>arXiv:2408.04537v4 Announce Type: replace 
Abstract: We review how we can store a run-length compressed suffix array (RLCSA) for a text $T$ of length $n$ over an alphabet of size $\sigma$ whose Burrows-Wheeler Transform (BWT) consists of $r$ runs in $O \left( \rule{0ex}{2ex} r \log (n / r) + r \log \sigma + \sigma \right)$ bits such that later, given character $a$ and the suffix array interval for $P$, we can find the suffix-array (SA) interval for $a P$ in $O (\log r_a + \log \log n)$ time, where $r_a$ is the number of runs of copies of $a$ in the BWT. We then show how to modify the RLCSA such that we find the SA interval for $a P$ in only $O (\log r_a)$ time, without increasing its asymptotic space bound. Our key idea is applying a result by Nishimoto and Tabei (ICALP 2021) and replacing rank queries on sparse bitvectors by a constant number of select queries. Finally, we review two-level indexing and discuss how our faster RLCSA may be useful in improving it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04537v4</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Travis Gagie, Giovanni Manzini, Gonzalo Navarro, Marinella Sciortino</dc:creator>
    </item>
    <item>
      <title>Improving polynomial bounds for the Graphical Traveling Salesman Problem with release dates on paths</title>
      <link>https://arxiv.org/abs/2502.02680</link>
      <description>arXiv:2502.02680v2 Announce Type: replace 
Abstract: The Graphical Traveling Salesman Problem with release dates (GTSP-rd) is a variation of the TSP-rd where each vertex in a weighted graph $G$ must be visited at least once, respecting the release date restriction. The edges may be traversed multiple times if necessary, as in some sparse graphs. This paper focuses on solving the GTSP-rd in paths. We consider two objective functions: minimizing the route completion time (GTSP-rd (time)) and minimizing the total distance traveled (GTSP-rd (distance)). We present improvements to existing dynamic programming algorithms, offering an $O(n)$ solution for paths where the depot is located at the extremity and an $O(n^2)$ solution for paths where the depot is located anywhere. For the GTSP-rd (distance), we propose an $O(n \log \log n)$ solution for the case with the depot at the extremity and an $O(n^2 \log \log n)$ solution for the general case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02680v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thailsson Clementino, Rosiane de Freitas</dc:creator>
    </item>
    <item>
      <title>Near-optimal Linear Sketches and Fully-Dynamic Algorithms for Hypergraph Spectral Sparsification</title>
      <link>https://arxiv.org/abs/2502.03313</link>
      <description>arXiv:2502.03313v2 Announce Type: replace 
Abstract: A hypergraph spectral sparsifier of a hypergraph $G$ is a weighted subgraph $H$ that approximates the Laplacian of $G$ to a specified precision. Recent work has shown that similar to ordinary graphs, there exist $\widetilde{O}(n)$-size hypergraph spectral sparsifiers. However, the task of computing such sparsifiers turns out to be much more involved, and all known algorithms rely on the notion of balanced weight assignments, whose computation inherently relies on repeated, complete access to the underlying hypergraph. We introduce a significantly simpler framework for hypergraph spectral sparsification which bypasses the need to compute such weight assignments, essentially reducing hypergraph sparsification to repeated effective resistance sampling in \textit{ordinary graphs}, which are obtained by \textit{oblivious vertex-sampling} of the original hypergraph.
  Our framework immediately yields a simple, new nearly-linear time algorithm for nearly-linear size spectral hypergraph sparsification. Furthermore, as a direct consequence of our framework, we obtain the first nearly-optimal algorithms in several other models of computation, namely the linear sketching, fully dynamic, and online settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03313v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Sanjeev Khanna, Huan Li, Aaron Putterman</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean High-Order Smooth Convex Optimization</title>
      <link>https://arxiv.org/abs/2411.08987</link>
      <description>arXiv:2411.08987v2 Announce Type: replace-cross 
Abstract: We develop algorithms for the optimization of convex objectives that have H\"older continuous $q$-th derivatives by using a $q$-th order oracle, for any $q \geq 1$. Our algorithms work for general norms under mild conditions, including the $\ell_p$-settings for $1\leq p\leq \infty$. We can also optimize structured functions that allow for inexactly implementing a non-Euclidean ball optimization oracle. We do this by developing a non-Euclidean inexact accelerated proximal point method that makes use of an \emph{inexact uniformly convex regularizer}. We show a lower bound for general norms that demonstrates our algorithms are nearly optimal in high-dimensions in the black-box oracle model for $\ell_p$-settings and all $q \geq 1$, even in randomized and parallel settings. This new lower bound, when applied to the first-order smooth case, resolves an open question in parallel convex optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.08987v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Pablo Contreras, Crist\'obal Guzm\'an, David Mart\'inez-Rubio</dc:creator>
    </item>
    <item>
      <title>Constant-Factor Distortion Mechanisms for $k$-Committee Election</title>
      <link>https://arxiv.org/abs/2501.19148</link>
      <description>arXiv:2501.19148v2 Announce Type: replace-cross 
Abstract: In the $k$-committee election problem, we wish to aggregate the preferences of $n$ agents over a set of alternatives and select a committee of $k$ alternatives that minimizes the cost incurred by the agents. While we typically assume that agent preferences are captured by a cardinal utility function, in many contexts we only have access to ordinal information, namely the agents' rankings over the outcomes. As preference rankings are not as expressive as cardinal utilities, a loss of efficiency is inevitable, and is quantified by the notion of \emph{distortion}.
  We study the problem of electing a $k$-committee that minimizes the sum of the $\ell$-largest costs incurred by the agents, when agents and candidates are embedded in a metric space. This problem is called the $\ell$-centrum problem and captures both the utilitarian and egalitarian objectives. When $k \geq 2$, it is not possible to compute a bounded-distortion committee using purely ordinal information. We develop the first algorithms (that we call mechanisms) for the $\ell$-centrum problem (when $k \geq 2$), which achieve $O(1)$-distortion while eliciting only a very limited amount of cardinal information via value queries. We obtain two types of query-complexity guarantees: $O(\log k \log n)$ queries \emph{per agent}, and $O(k^2 \log^2 n)$ queries \emph{in total} (while achieving $O(1)$-distortion in both cases). En route, we give a simple adaptive-sampling algorithm for the $\ell$-centrum $k$-clustering problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.19148v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haripriya Pulyassary, Chaitanya Swamy</dc:creator>
    </item>
  </channel>
</rss>
