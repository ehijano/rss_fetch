<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.ST updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.ST</link>
    <description>math.ST updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.ST" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 19 Jun 2025 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Identifiability by common backdoor in summary causal graphs of time series</title>
      <link>https://arxiv.org/abs/2506.14862</link>
      <description>arXiv:2506.14862v1 Announce Type: new 
Abstract: The identifiability problem for interventions aims at assessing whether the total effect of some given interventions can be written with a do-free formula, and thus be computed from observational data only. We study this problem, considering multiple interventions and multiple effects, in the context of time series when only abstractions of the true causal graph in the form of summary causal graphs are available. We focus in this study on identifiability by a common backdoor set, and establish, for time series with and without consistency throughout time, conditions under which such a set exists. We also provide algorithms of limited complexity to decide whether the problem is identifiable or not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.14862v1</guid>
      <category>math.ST</category>
      <category>cs.AI</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cl\'ement Yvernes, Charles K. Assaad, Emilie Devijver, Eric Gaussier</dc:creator>
    </item>
    <item>
      <title>Probabilistic closed-form formulas for pricing nonlinear payoff variance and volatility derivatives under Schwartz model with time-varying log-return volatility</title>
      <link>https://arxiv.org/abs/2506.15386</link>
      <description>arXiv:2506.15386v1 Announce Type: new 
Abstract: This paper presents closed-form analytical formulas for pricing volatility and variance derivatives with nonlinear payoffs under discrete-time observations. The analysis is based on a probabilistic approach assuming that the underlying asset price follows the Schwartz one-factor model, where the volatility of log-returns is time-varying. A difficult challenge in this pricing problem is to solve an analytical formula under the assumption of time-varying log-return volatility, resulting in the realized variance being distributed according to a linear combination of independent noncentral chi-square random variables with weighted parameters. By utilizing the probability density function, we analytically compute the expectation of the square root of the realized variance and derive pricing formulas for volatility swaps. Additionally, we derive analytical pricing formulas for volatility call options. For the payoff function without the square root, we also derive corresponding formulas for variance swaps and variance call options. Additionally, we study the case of constant log-return volatility; simplified pricing formulas are derived and sensitivity with respect to volatility (vega) is analytically studied. Furthermore,we propose simple closed-form approximations for pricing volatility swaps under the Schwartz one-factor model. The accuracy and efficiency of the proposed methods are demonstrated through Monte Carlo simulations, and the impact of price volatility and the number of trading days on fair strike prices of volatility and variance swaps is investigated across various numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15386v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nontawat Bunchak, Udomsak Rakwongwan, Phiraphat Sutthimat</dc:creator>
    </item>
    <item>
      <title>Density estimation via periodic scaled Korobov kernel method with exponential decay condition</title>
      <link>https://arxiv.org/abs/2506.15419</link>
      <description>arXiv:2506.15419v1 Announce Type: new 
Abstract: We propose the periodic scaled Korobov kernel (PSKK) method for nonparametric density estimation on $\mathbb{R}^d$. By first wrapping the target density into a periodic version through modulo operation and subsequently applying kernel ridge regression in scaled Korobov spaces, we extend the kernel approach proposed by Kazashi and Nobile (SIAM J. Numer. Anal., 2023) and eliminate its requirement for inherent periodicity of the density function. This key modification enables effective estimation of densities defined on unbounded domains. We establish rigorous mean integrated squared error (MISE) bounds, proving that for densities with smoothness of order $\alpha$ and exponential decay, our method achieves the $\mathcal{O}(M^{-1/(1+1/(2\alpha)+\epsilon)})$ MISE convergence rate with an arbitrarily small $\epsilon&gt;0$. While matching the convergence rate of the previous kernel approach, our approach applies to a broader class of non-periodic distributions. Numerical experiments confirm the theoretical results and demonstrate significant improvement over traditional kernel density estimation in large-sample regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15419v1</guid>
      <category>math.ST</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyang Ye, Haoyuan Tan, Xiaoqun Wang, Zhijian He</dc:creator>
    </item>
    <item>
      <title>Multivariate and Multiple Contrast Testing in General Covariate-adjusted Factorial Designs</title>
      <link>https://arxiv.org/abs/2506.15292</link>
      <description>arXiv:2506.15292v1 Announce Type: cross 
Abstract: Evaluating intervention effects on multiple outcomes is a central research goal in a wide range of quantitative sciences. It is thereby common to compare interventions among each other and with a control across several, potentially highly correlated, outcome variables. In this context, researchers are interested in identifying effects at both, the global level (across all outcome variables) and the local level (for specific variables). At the same time, potential confounding must be accounted for. This leads to the need for powerful multiple contrast testing procedures (MCTPs) capable of handling multivariate outcomes and covariates. Given this background, we propose an extension of MCTPs within a semiparametric MANCOVA framework that allows applicability beyond multivariate normality, homoscedasticity, or non-singular covariance structures. We illustrate our approach by analysing multivariate psychological intervention data, evaluating joint physiological and psychological constructs such as heart rate variability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15292v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Marl\'ene Baumeister, Konstantin Emil Thiel, Lynn Matits, Georg Zimmermann, Markus Pauly, Paavo Sattler</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of Classical Regression Methods for Optimal Switching Problems</title>
      <link>https://arxiv.org/abs/2506.15436</link>
      <description>arXiv:2506.15436v1 Announce Type: cross 
Abstract: Simple regression methods provide robust, near-optimal solutions for optimal switching problems in dimensions ranging from 1 to 50. While the theory requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with classical approaches like $k$-NN achieves excellent switching decisions without extensive hyperparameter tuning. Testing eight regression approaches on four benchmark problems, we find that simple methods maintain stable performance across diverse problem characteristics, even after extensive neural network optimization. The contaminated training targets inherent to backward induction-where each target contains both approximation bias and Monte Carlo noise-actually favor these robust approaches over more complex alternatives such as neural networks. Further, we establish concentration bounds for $k$-NN regression under jump-diffusion dynamics and show that PCA enables $k$-NN to scale to high dimensions. For practitioners: simple, minimally-tuned regression methods offer reliable performance for computationally demanding switching problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15436v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Andersson, Benny Avelin, Marcus Olofsson</dc:creator>
    </item>
    <item>
      <title>Causal inference amid missingness-specific independencies and mechanism shifts</title>
      <link>https://arxiv.org/abs/2506.15441</link>
      <description>arXiv:2506.15441v1 Announce Type: cross 
Abstract: The recovery of causal effects in structural models with missing data often relies on $m$-graphs, which assume that missingness mechanisms do not directly influence substantive variables. Yet, in many real-world settings, missing data can alter decision-making processes, as the absence of key information may affect downstream actions and states. To overcome this limitation, we introduce $lm$-SCMs and $lm$-graphs, which extend $m$-graphs by integrating a label set that represents relevant context-specific independencies (CSI), accounting for mechanism shifts induced by missingness. We define two causal effects within these systems: the Full Average Treatment Effect (FATE), which reflects the effect in a hypothetical scenario had no data been missing, and the Natural Average Treatment Effect (NATE), which captures the effect under the unaltered CSIs in the system. We propose recovery criteria for these queries and present doubly-robust estimators for a graphical model inspired by a real-world application. Simulations highlight key differences between these estimands and estimation methods. Findings from the application case suggest a small effect of ADHD treatment upon test achievement among Norwegian children, with a slight effect shift due to missing pre-tests scores.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15441v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Johan de Aguas, Leonard Henckel, Johan Pensar, Guido Biele</dc:creator>
    </item>
    <item>
      <title>On the Upper Bounds for the Matrix Spectral Norm</title>
      <link>https://arxiv.org/abs/2506.15660</link>
      <description>arXiv:2506.15660v1 Announce Type: cross 
Abstract: We consider the problem of estimating the spectral norm of a matrix using only matrix-vector products. We propose a new Counterbalance estimator that provides upper bounds on the norm and derive probabilistic guarantees on its underestimation. Compared to standard approaches such as the power method, the proposed estimator produces significantly tighter upper bounds in both synthetic and real-world settings. Our method is especially effective for matrices with fast-decaying spectra, such as those arising in deep learning and inverse problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15660v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexey Naumov, Maxim Rakhuba, Denis Ryapolov, Sergey Samsonov</dc:creator>
    </item>
    <item>
      <title>Optimal designs for discrete choice models via graph Laplacians</title>
      <link>https://arxiv.org/abs/2208.08926</link>
      <description>arXiv:2208.08926v2 Announce Type: replace 
Abstract: In discrete choice experiments, the information matrix depends on the model parameters. Therefore designing optimally informative experiments for arbitrary initial parameters often yields highly nonlinear optimization problems and makes optimal design infeasible. To overcome such challenges, we connect design theory for discrete choice experiments with Laplacian matrices of undirected graphs, resulting in complexity reduction and feasibility of optimal design. We rewrite the $D$-optimality criterion in terms of Laplacians via Kirchhoff's matrix tree theorem, and show that its dual has a simple description via the Cayley-Menger determinant of the Farris transform of the Laplacian matrix. This results in a drastic reduction of complexity and allows us to implement a gradient descent algorithm to find locally $D$-optimal designs. For the subclass of Bradley-Terry paired comparison models, we find a direct link to maximum likelihood estimation for Laplacian-constrained Gaussian graphical models. Finally, we study the performance of our algorithm and demonstrate its application to real and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08926v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank R\"ottger, Thomas Kahle, Rainer Schwabe</dc:creator>
    </item>
    <item>
      <title>Normal approximations for the multivariate inverse Gaussian distribution and asymmetric kernel smoothing on $d$-dimensional half-spaces</title>
      <link>https://arxiv.org/abs/2209.04757</link>
      <description>arXiv:2209.04757v5 Announce Type: replace 
Abstract: This paper introduces a novel density estimator supported on $d$-dimensional half-spaces. It stands out as the first asymmetric kernel density estimator for half-spaces in the literature. Using the multivariate inverse Gaussian (MIG) density from Minami (2003) as the kernel and incorporating locally adaptive parameters, the estimator achieves desirable boundary properties. To analyze its mean integrated squared error (MISE) and asymptotic normality, a local limit theorem and probability metric bounds are established between the MIG and the corresponding multivariate Gaussian distribution with the same mean vector and covariance matrix, which may also be of independent interest. Additionally, a new algorithm for generating MIG random vectors is developed, proving to be faster and more accurate than Minami's algorithm based on a Brownian first-hitting location representation. This algorithm is then used to discuss and compare optimal MISE and likelihood cross-validation bandwidths for the estimator in a simulation study under various target distributions. As an application, the MIG asymmetric kernel is used to smooth the posterior distribution of a generalized Pareto model fitted to large electromagnetic storms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04757v5</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'eo R. Belzile, Alain Desgagn\'e, Christian Genest, Fr\'ed\'eric Ouimet</dc:creator>
    </item>
    <item>
      <title>Symmetric Bernoulli distributions and minimal dependence copulas</title>
      <link>https://arxiv.org/abs/2309.17346</link>
      <description>arXiv:2309.17346v3 Announce Type: replace 
Abstract: The key result of this paper is to characterize all the multivariate symmetric Bernoulli distributions whose sum is minimal under convex order. In doing so, we automatically characterize extremal negative dependence among Bernoulli random vectors, since multivariate distributions with minimal convex sums are known to be strongly negative dependent. Moreover, beyond its interest per se, this result provides insight into negative dependence within the class of copulas. In particular, two classes of copulas can be built from multivariate symmetric Bernoulli distributions: extremal mixture copulas and FGM copulas. We analyze the extremal negative dependence structures of copulas corresponding to symmetric Bernoulli random vectors with minimal convex sums and explicitly find a class of minimal dependence copulas. Our main results derive from the geometric and algebraic representations of multivariate symmetric Bernoulli distributions, which effectively encode key statistical properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.17346v3</guid>
      <category>math.ST</category>
      <category>q-fin.MF</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Mutti, Patrizia Semeraro</dc:creator>
    </item>
    <item>
      <title>Theoretical Foundations of Ordinal Multidimensional Scaling, Including Internal and External Unfolding</title>
      <link>https://arxiv.org/abs/2310.00211</link>
      <description>arXiv:2310.00211v3 Announce Type: replace 
Abstract: We provide a comprehensive theory of multiple variants of ordinal multidimensional scaling,including internal unfolding and external unfolding. We first follow Shepard (1966) and work in a continuum model to gain insight. We then follow Kleindessner and von Luxburg (2014) and work in an asymptotic discrete setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00211v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ery Arias-Castro, Cl\'ement Berenfeld, Daniel Kane</dc:creator>
    </item>
    <item>
      <title>Efficient estimation with incomplete data via generalised ANOVA decompositions</title>
      <link>https://arxiv.org/abs/2409.05729</link>
      <description>arXiv:2409.05729v2 Announce Type: replace 
Abstract: We study the semiparametric efficient estimation of a class of linear functionals in settings where a complete multivariate dataset is supplemented by additional datasets recording subsets of the variables of interest. These datasets are allowed to have a general, in particular non-monotonic, structure. Our main contribution is to characterise the asymptotic minimal mean squared error for these problems and to introduce an estimator whose risk approximately matches this lower bound. We show that the efficient rescaled variance can be expressed as the minimal value of a quadratic optimisation problem over a function space, thus establishing a fundamental link between these estimation problems and the theory of generalised ANOVA decompositions. Our estimation procedure uses iterated nonparametric regression to mimic an approximate influence function derived through gradient descent. We prove that this estimator is approximately normally distributed, provide an estimator of its variance and thus develop confidence intervals of asymptotically minimal width. Finally we present extensions of our theory demonstrating that the framework can be adapted to include various types of sampling bias and non-linear functionals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05729v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas B. Berrett</dc:creator>
    </item>
    <item>
      <title>On the pointwise supremum of the set of copulas with a given curvilinear section</title>
      <link>https://arxiv.org/abs/2412.20629</link>
      <description>arXiv:2412.20629v3 Announce Type: replace 
Abstract: Making use of the total variation of particular functions, we give an explicit formula for the pointwise supremum of the set of all copulas with a given curvilinear section. When the pointwise supremum is a copula is characterized. We also characterize the coincidence of the pointwise supremum and the greatest quasi-copula with the same curvilinear section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20629v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yao Ouyang, Yonghui Sun, Hua-Peng Zhang</dc:creator>
    </item>
    <item>
      <title>Simple, Efficient Entropy Estimation using Harmonic Numbers</title>
      <link>https://arxiv.org/abs/2505.20153</link>
      <description>arXiv:2505.20153v2 Announce Type: replace 
Abstract: The estimation of entropy, a fundamental measure of uncertainty, is central to diverse data applications. For discrete random variables, however, efficient entropy estimation presents challenges, particularly when the cardinality of the support set is large relative to the available sample size. This is because, without other assumptions, there may be insufficient data to adequately characterize a probability mass function. Further complications stem from the dependence among transformations of empirical frequencies within the sample.
  This paper demonstrates that a simple entropy estimator based on the harmonic number function achieves asymptotic efficiency for discrete random variables with tail probabilities satisfying $p_j =o(j^{-2})$ as $j\rightarrow\infty$. This result renders statistical inference newly feasible for a broad class of distributions. Further, the proposed estimator has superior mean squared error bounds compared to the classical plug-in estimator, while retaining its computational simplicity, offering practical and theoretical advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20153v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Octavio C\'esar Mesner</dc:creator>
    </item>
    <item>
      <title>From Graphical Lasso to Atomic Norms: High-Dimensional Pattern Recovery</title>
      <link>https://arxiv.org/abs/2506.13353</link>
      <description>arXiv:2506.13353v2 Announce Type: replace 
Abstract: Estimating high-dimensional precision matrices is a fundamental problem in modern statistics, with the graphical lasso and its $\ell_1$-penalty being a standard approach for recovering sparsity patterns. However, many statistical models, e.g. colored graphical models, exhibit richer structures like symmetry or equality constraints, which the $\ell_1$-norm cannot adequately capture. This paper addresses the gap by extending the high-dimensional analysis of pattern recovery to a general class of atomic norm penalties, particularly those whose unit balls are polytopes, where patterns correspond to the polytope's facial structure. We establish theoretical guarantees for recovering the true pattern induced by these general atomic norms in precision matrix estimation.
  Our framework builds upon and refines the primal-dual witness methodology of Ravikumar et al. (2011). Our analysis provides conditions on the deviation between sample and true covariance matrices for successful pattern recovery, given a novel, generalized irrepresentability condition applicable to any atomic norm. When specialized to the $\ell_1$-penalty, our results offer improved conditions -- including weaker deviation requirements and a less restrictive irrepresentability condition -- leading to tighter bounds and better asymptotic performance than prior work. The proposed general irrepresentability condition, based on a new thresholding concept, provides a unified perspective on model selection consistency. Numerical examples demonstrate the tightness of the derived theoretical bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13353v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Piotr Graczyk, Bartosz Ko{\l}odziejek, Hideto Nakashima, Maciej Wilczy\'nski</dc:creator>
    </item>
    <item>
      <title>Dickman type stochastic processes with short- and long- range dependence</title>
      <link>https://arxiv.org/abs/2408.11521</link>
      <description>arXiv:2408.11521v2 Announce Type: replace-cross 
Abstract: We study properties of the (generalized) Dickman distribution with two parameters and the stationary solution of the Ornstein-Uhlenbeck stochastic differential equation driven by a Poisson process. In particular, we show that the marginal distribution of this solution is the Dickman distribution. Additionally, we investigate superpositions of Ornstein-Uhlenbeck processes which may have short- or long-range dependencies and marginal distribution of the form of the Dickman distribution. The numerical algorithm for simulation of these processes is presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.11521v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/17442508.2025.2522789</arxiv:DOI>
      <dc:creator>Danijel Grahovac, Anastasiia Kovtun, Nikolai N. Leonenko, Andrey Pepelyshev</dc:creator>
    </item>
    <item>
      <title>Asymptotically optimal Wasserstein couplings for the small-time stable domain of attraction</title>
      <link>https://arxiv.org/abs/2411.03609</link>
      <description>arXiv:2411.03609v2 Announce Type: replace-cross 
Abstract: We develop two novel couplings between general pure-jump L\'evy processes in $\R^d$ and apply them to obtain upper bounds on the rate of convergence in an appropriate Wasserstein distance on the path space for a wide class of L\'evy processes attracted to a multidimensional stable process in the small-time regime. We also establish general lower bounds based on certain universal properties of slowly varying functions and the relationship between the Wasserstein and Toscani--Fourier distances of the marginals. Our upper and lower bounds typically have matching rates. In particular, the rate of convergence is polynomial for the domain of normal attraction and slower than a slowly varying function for the domain of non-normal attraction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03609v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jorge Gonz\'alez C\'azares, David Kramer-Bang, Aleksandar Mijatovi\'c</dc:creator>
    </item>
    <item>
      <title>Local minima of the empirical risk in high dimension: General theorems and convex examples</title>
      <link>https://arxiv.org/abs/2502.01953</link>
      <description>arXiv:2502.01953v2 Announce Type: replace-cross 
Abstract: We consider a general model for high-dimensional empirical risk minimization whereby the data $\mathbf{x}_i$ are $d$-dimensional isotropic Gaussian vectors, the model is parametrized by $\mathbf{\Theta}\in\mathbb{R}^{d\times k}$, and the loss depends on the data via the projection $\mathbf{\Theta}^\mathsf{T}\mathbf{x}_i$. This setting covers as special cases classical statistics methods (e.g. multinomial regression and other generalized linear models), but also two-layer fully connected neural networks with $k$ hidden neurons. We use the Kac-Rice formula from Gaussian process theory to derive a bound on the expected number of local minima of this empirical risk, under the proportional asymptotics in which $n,d\to\infty$, with $n\asymp d$. Via Markov's inequality, this bound allows to determine the positions of these minimizers (with exponential deviation bounds) and hence derive sharp asymptotics on the estimation and prediction error. In this paper, we apply our characterization to convex losses, where high-dimensional asymptotics were not (in general) rigorously established for $k\ge 2$. We show that our approach is tight and allows to prove previously conjectured results. In addition, we characterize the spectrum of the Hessian at the minimizer. A companion paper applies our general result to non-convex examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.01953v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kiana Asgari, Andrea Montanari, Basil Saeed</dc:creator>
    </item>
    <item>
      <title>Distributionally-Constrained Adversaries in Online Learning</title>
      <link>https://arxiv.org/abs/2506.10293</link>
      <description>arXiv:2506.10293v2 Announce Type: replace-cross 
Abstract: There has been much recent interest in understanding the continuum from adversarial to stochastic settings in online learning, with various frameworks including smoothed settings proposed to bridge this gap. We consider the more general and flexible framework of distributionally constrained adversaries in which instances are drawn from distributions chosen by an adversary within some constrained distribution class [RST11]. Compared to smoothed analysis, we consider general distributional classes which allows for a fine-grained understanding of learning settings between fully stochastic and fully adversarial for which a learner can achieve non-trivial regret. We give a characterization for which distribution classes are learnable in this context against both oblivious and adaptive adversaries, providing insights into the types of interplay between the function class and distributional constraints on adversaries that enable learnability. In particular, our results recover and generalize learnability for known smoothed settings. Further, we show that for several natural function classes including linear classifiers, learning can be achieved without any prior knowledge of the distribution class -- in other words, a learner can simultaneously compete against any constrained adversary within learnable distribution classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.10293v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mo\"ise Blanchard, Samory Kpotufe</dc:creator>
    </item>
    <item>
      <title>From Data-Driven to Purpose-Driven Artificial Intelligence: Systems Thinking for Data-Analytic Automation of Patient Care</title>
      <link>https://arxiv.org/abs/2506.13584</link>
      <description>arXiv:2506.13584v2 Announce Type: replace-cross 
Abstract: In this work, we reflect on the data-driven modeling paradigm that is gaining ground in AI-driven automation of patient care. We argue that the repurposing of existing real-world patient datasets for machine learning may not always represent an optimal approach to model development as it could lead to undesirable outcomes in patient care. We reflect on the history of data analysis to explain how the data-driven paradigm rose to popularity, and we envision ways in which systems thinking and clinical domain theory could complement the existing model development approaches in reaching human-centric outcomes. We call for a purpose-driven machine learning paradigm that is grounded in clinical theory and the sociotechnical realities of real-world operational contexts. We argue that understanding the utility of existing patient datasets requires looking in two directions: upstream towards the data generation, and downstream towards the automation objectives. This purpose-driven perspective to AI system development opens up new methodological opportunities and holds promise for AI automation of patient care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.13584v2</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Thu, 19 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Anadria, Roel Dobbe, Anastasia Giachanou, Ruurd Kuiper, Richard Bartels, Wouter van Amsterdam, \'I\~nigo Mart\'inez de Rituerto de Troya, Carmen Z\"urcher, Daniel Oberski</dc:creator>
    </item>
  </channel>
</rss>
