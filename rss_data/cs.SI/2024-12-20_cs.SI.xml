<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Dec 2024 05:00:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Network Modelling in Analysing Cyber-related Graphs</title>
      <link>https://arxiv.org/abs/2412.14375</link>
      <description>arXiv:2412.14375v1 Announce Type: new 
Abstract: In order to improve the resilience of computer infrastructure against cyber attacks and finding ways to mitigate their impact we need to understand their structure and dynamics. Here we propose a novel network-based influence spreading model to investigate event trajectories or paths in various types of attack and causal graphs, which can be directed, weighted, and / or cyclic. In case of attack graphs with acyclic paths, only self-avoiding attack chains are allowed. In the framework of our model a detailed probabilistic analysis beyond the traditional visualisation of attack graphs, based on vulnerabilities, services, and exploitabilities, can be performed. In order to demonstrate the capabilities of the model, we present three use cases with cyber-related graphs, namely two attack graphs and a causal graph. The model can be of benefit to cyber analysts in generating quantitative metrics for prioritisation, summaries, or analysis of larger graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14375v1</guid>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vesa Kuikka, Lauri Pyk\"al\"a, Tuomas Takko, Kimmo Kaski</dc:creator>
    </item>
    <item>
      <title>In-Group Love, Out-Group Hate: A Framework to Measure Affective Polarization via Contentious Online Discussions</title>
      <link>https://arxiv.org/abs/2412.14414</link>
      <description>arXiv:2412.14414v1 Announce Type: new 
Abstract: Affective polarization, the emotional divide between ideological groups marked by in-group love and out-group hate, has intensified in the United States, driving contentious issues like masking and lockdowns during the COVID-19 pandemic. Despite its societal impact, existing models of opinion change fail to account for emotional dynamics nor offer methods to quantify affective polarization robustly and in real-time. In this paper, we introduce a discrete choice model that captures decision-making within affectively polarized social networks and propose a statistical inference method estimate key parameters -- in-group love and out-group hate -- from social media data. Through empirical validation from online discussions about the COVID-19 pandemic, we demonstrate that our approach accurately captures real-world polarization dynamics and explains the rapid emergence of a partisan gap in attitudes towards masking and lockdowns. This framework allows for tracking affective polarization across contentious issues has broad implications for fostering constructive online dialogues in digital spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14414v1</guid>
      <category>cs.SI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Buddhika Nettasinghe, Ashwin Rao, Bohan Jiang, Allon Percus, Kristina Lerman</dc:creator>
    </item>
    <item>
      <title>Vulnerable Connectivity Caused by Local Communities in Spatial Networks</title>
      <link>https://arxiv.org/abs/2412.14513</link>
      <description>arXiv:2412.14513v1 Announce Type: new 
Abstract: It has been shown that randomly formed communities in topological networks reduce the robustness of connectivity. However, in spatial networks, where community structures are not random but constrained by physical and geographical factors, the effect of these structures on the robustness is unclear. This paper investigates the emergence of local communities in road and communication networks, whose nodes are located by population data of major urban areas in Japan, and connected shortly with low cost. We show that, as the strength of community increases, the spatial networks become more vulnerable to both intentional attacks and random failures. As an application point of view, this result suggests that the densely setting nodes of equipments should be avoided under short links in constructing a spatial network. These findings contribute to understanding the important relation between local communities and the robustness of connectivity against attacks and disasters especially in spatial networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14513v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yingzhou Mou, Yukio Hayashi</dc:creator>
    </item>
    <item>
      <title>IOHunter: Graph Foundation Model to Uncover Online Information Operations</title>
      <link>https://arxiv.org/abs/2412.14663</link>
      <description>arXiv:2412.14663v1 Announce Type: new 
Abstract: Social media platforms have become vital spaces for public discourse, serving as modern agor\'as where a wide range of voices influence societal narratives. However, their open nature also makes them vulnerable to exploitation by malicious actors, including state-sponsored entities, who can conduct information operations (IOs) to manipulate public opinion. The spread of misinformation, false news, and misleading claims threatens democratic processes and societal cohesion, making it crucial to develop methods for the timely detection of inauthentic activity to protect the integrity of online discourse. In this work, we introduce a methodology designed to identify users orchestrating information operations, a.k.a. \textit{IO drivers}, across various influence campaigns. Our framework, named \texttt{IOHunter}, leverages the combined strengths of Language Models and Graph Neural Networks to improve generalization in \emph{supervised}, \emph{scarcely-supervised}, and \emph{cross-IO} contexts. Our approach achieves state-of-the-art performance across multiple sets of IOs originating from six countries, significantly surpassing existing approaches. This research marks a step toward developing Graph Foundation Models specifically tailored for the task of IO detection on social media platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14663v1</guid>
      <category>cs.SI</category>
      <category>cs.AI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Marco Minici, Luca Luceri, Francesco Fabbri, Emilio Ferrara</dc:creator>
    </item>
    <item>
      <title>Large-scale Group Brainstorming using Conversational Swarm Intelligence (CSI) versus Traditional Chat</title>
      <link>https://arxiv.org/abs/2412.14205</link>
      <description>arXiv:2412.14205v1 Announce Type: cross 
Abstract: Conversational Swarm Intelligence (CSI) is an AI-facilitated method for enabling real-time conversational deliberations and prioritizations among networked human groups of potentially unlimited size. Based on the biological principle of Swarm Intelligence and modelled on the decision-making dynamics of fish schools, CSI has been shown in prior studies to amplify group intelligence, increase group participation, and facilitate productive collaboration among hundreds of participants at once. It works by dividing a large population into a set of small subgroups that are woven together by real-time AI agents called Conversational Surrogates. The present study focuses on the use of a CSI platform called Thinkscape to enable real-time brainstorming and prioritization among groups of 75 networked users. The study employed a variant of a common brainstorming intervention called an Alternative Use Task (AUT) and was designed to compare through subjective feedback, the experience of participants brainstorming using a CSI structure vs brainstorming in a single large chat room. This comparison revealed that participants significantly preferred brainstorming with the CSI structure and reported that it felt (i) more collaborative, (ii) more productive, and (iii) was better at surfacing quality answers. In addition, participants using the CSI structure reported (iv) feeling more ownership and more buy-in in the final answers the group converged on and (v) reported feeling more heard as compared to brainstorming in a traditional text chat environment. Overall, the results suggest that CSI is a very promising AI-facilitated method for brainstorming and prioritization among large-scale, networked human groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14205v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Louis Rosenberg, Hans Schumann, Christopher Dishop, Gregg Willcox, Anita Woolley, Ganesh Mani</dc:creator>
    </item>
    <item>
      <title>Mobilizing Waldo: Evaluating Multimodal AI for Public Mobilization</title>
      <link>https://arxiv.org/abs/2412.14210</link>
      <description>arXiv:2412.14210v1 Announce Type: cross 
Abstract: Advancements in multimodal Large Language Models (LLMs), such as OpenAI's GPT-4o, offer significant potential for mediating human interactions across various contexts. However, their use in areas such as persuasion, influence, and recruitment raises ethical and security concerns. To evaluate these models ethically in public influence and persuasion scenarios, we developed a prompting strategy using "Where's Waldo?" images as proxies for complex, crowded gatherings. This approach provides a controlled, replicable environment to assess the model's ability to process intricate visual information, interpret social dynamics, and propose engagement strategies while avoiding privacy concerns. By positioning Waldo as a hypothetical agent tasked with face-to-face mobilization, we analyzed the model's performance in identifying key individuals and formulating mobilization tactics. Our results show that while the model generates vivid descriptions and creative strategies, it cannot accurately identify individuals or reliably assess social dynamics in these scenarios. Nevertheless, this methodology provides a valuable framework for testing and benchmarking the evolving capabilities of multimodal LLMs in social contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14210v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manuel Cebrian, Petter Holme, Niccolo Pescetelli</dc:creator>
    </item>
    <item>
      <title>Race Discrimination in Internet Advertising: Evidence From a Field Experiment</title>
      <link>https://arxiv.org/abs/2412.14307</link>
      <description>arXiv:2412.14307v1 Announce Type: cross 
Abstract: We present the results of an experiment documenting racial bias on Meta's Advertising Platform in Brazil and the United States. We find that darker skin complexions are penalized, leading to real economic consequences. For every \$1,000 an advertiser spends on ads with models with light-skin complexions, that advertiser would have to spend \$1,159 to achieve the same level of engagement using photos of darker skin complexion models. Meta's budget optimization tool reinforces these viewer biases. When pictures of models with light and dark complexions are allocated a shared budget, Meta funnels roughly 64\% of the budget towards photos featuring lighter skin complexions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14307v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Neil K. R. Sehgal, Dan Svirsky</dc:creator>
    </item>
    <item>
      <title>On the Robustness of Spectral Algorithms for Semirandom Stochastic Block Models</title>
      <link>https://arxiv.org/abs/2412.14315</link>
      <description>arXiv:2412.14315v1 Announce Type: cross 
Abstract: In a graph bisection problem, we are given a graph $G$ with two equally-sized unlabeled communities, and the goal is to recover the vertices in these communities. A popular heuristic, known as spectral clustering, is to output an estimated community assignment based on the eigenvector corresponding to the second smallest eigenvalue of the Laplacian of $G$. Spectral algorithms can be shown to provably recover the cluster structure for graphs generated from certain probabilistic models, such as the Stochastic Block Model (SBM). However, spectral clustering is known to be non-robust to model mis-specification. Techniques based on semidefinite programming have been shown to be more robust, but they incur significant computational overheads.
  In this work, we study the robustness of spectral algorithms against semirandom adversaries. Informally, a semirandom adversary is allowed to ``helpfully'' change the specification of the model in a way that is consistent with the ground-truth solution. Our semirandom adversaries in particular are allowed to add edges inside clusters or increase the probability that an edge appears inside a cluster. Semirandom adversaries are a useful tool to determine the extent to which an algorithm has overfit to statistical assumptions on the input.
  On the positive side, we identify classes of semirandom adversaries under which spectral bisection using the _unnormalized_ Laplacian is strongly consistent, i.e., it exactly recovers the planted partitioning. On the negative side, we show that in these classes spectral bisection with the _normalized_ Laplacian outputs a partitioning that makes a classification mistake on a constant fraction of the vertices. Finally, we demonstrate numerical experiments that complement our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14315v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Bhaskara, Agastya Vibhuti Jha, Michael Kapralov, Naren Sarayu Manoj, Davide Mazzali, Weronika Wrzos-Kaminska</dc:creator>
    </item>
    <item>
      <title>Computational Sociology of Humans and Machines; Conflict and Collaboration</title>
      <link>https://arxiv.org/abs/2412.14606</link>
      <description>arXiv:2412.14606v1 Announce Type: cross 
Abstract: This Chapter examines the dynamics of conflict and collaboration in human-machine systems, with a particular focus on large-scale, internet-based collaborative platforms. While these platforms represent successful examples of collective knowledge production, they are also sites of significant conflict, as diverse participants with differing intentions and perspectives interact. The analysis identifies recurring patterns of interaction, including serial attacks, reciprocal revenge, and third-party interventions. These microstructures reveal the role of experience, cultural differences, and topic sensitivity in shaping human-human, human-machine, and machine-machine interactions. The chapter further investigates the role of algorithmic agents and bots, highlighting their dual nature: they enhance collaboration by automating tasks but can also contribute to persistent conflicts with both humans and other machines. We conclude with policy recommendations that emphasize transparency, balance, cultural sensitivity, and governance to maximize the benefits of human-machine synergy while minimizing potential detriments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.14606v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha Yasseri</dc:creator>
    </item>
    <item>
      <title>Multipartite Entanglement Routing as a Hypergraph Immersion Problem</title>
      <link>https://arxiv.org/abs/2406.13452</link>
      <description>arXiv:2406.13452v2 Announce Type: replace-cross 
Abstract: Multipartite entanglement, linking multiple nodes simultaneously, is a higher-order correlation that offers advantages over pairwise connections in quantum networks (QNs). Creating reliable, large-scale multipartite entanglement requires entanglement routing, a process that combines local, short-distance connections into a long-distance connection, which can be considered as a transformation of network topology. Here, we address the question of whether a QN can be topologically transformed into another via entanglement routing. Our key result is an exact mapping from multipartite entanglement routing to Nash-Williams's graph immersion problem, extended to hypergraphs. This generalized hypergraph immersion problem introduces a partial order between QN topologies, permitting certain topological transformations while precluding others, offering discerning insights into the design and manipulation of higher-order network topologies in QNs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13452v2</guid>
      <category>quant-ph</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <category>physics.comp-ph</category>
      <category>physics.soc-ph</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Tian, Yuefei Liu, Xiangyi Meng</dc:creator>
    </item>
    <item>
      <title>Web Scraping for Research: Legal, Ethical, Institutional, and Scientific Considerations</title>
      <link>https://arxiv.org/abs/2410.23432</link>
      <description>arXiv:2410.23432v2 Announce Type: replace-cross 
Abstract: Scientists across disciplines often use data from the internet to conduct research, generating valuable insights about human behavior. However, as generative AI relying on massive text corpora becomes increasingly valuable, platforms have greatly restricted access to data through official channels. As a result, researchers will likely engage in more web scraping to collect data, introducing new challenges and concerns for researchers. This paper proposes a comprehensive framework for web scraping in social science research for U.S.-based researchers, examining the legal, ethical, institutional, and scientific factors that researchers should consider when scraping the web. We present an overview of the current regulatory environment impacting when and how researchers can access, collect, store, and share data via scraping. We then provide researchers with recommendations to conduct scraping in a scientifically legitimate and ethical manner. We aim to equip researchers with the relevant information to mitigate risks and maximize the impact of their research amidst this evolving data access landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.23432v2</guid>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Megan A. Brown, Andrew Gruen, Gabe Maldoff, Solomon Messing, Zeve Sanderson, Michael Zimmer</dc:creator>
    </item>
    <item>
      <title>Su-RoBERTa: A Semi-supervised Approach to Predicting Suicide Risk through Social Media using Base Language Models</title>
      <link>https://arxiv.org/abs/2412.01353</link>
      <description>arXiv:2412.01353v2 Announce Type: replace-cross 
Abstract: In recent times, more and more people are posting about their mental states across various social media platforms. Leveraging this data, AI-based systems can be developed that help in assessing the mental health of individuals, such as suicide risk. This paper is a study done on suicidal risk assessments using Reddit data leveraging Base language models to identify patterns from social media posts. We have demonstrated that using smaller language models, i.e., less than 500M parameters, can also be effective in contrast to LLMs with greater than 500M parameters. We propose Su-RoBERTa, a fine-tuned RoBERTa on suicide risk prediction task that utilized both the labeled and unlabeled Reddit data and tackled class imbalance by data augmentation using GPT-2 model. Our Su-RoBERTa model attained a 69.84% weighted F1 score during the Final evaluation. This paper demonstrates the effectiveness of Base language models for the analysis of the risk factors related to mental health with an efficient computation pipeline</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01353v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chayan Tank, Shaina Mehta, Sarthak Pol, Vinayak Katoch, Avinash Anand, Raj Jaiswal, Rajiv Ratn Shah</dc:creator>
    </item>
    <item>
      <title>Contextualized Counterspeech: Strategies for Adaptation, Personalization, and Evaluation</title>
      <link>https://arxiv.org/abs/2412.07338</link>
      <description>arXiv:2412.07338v2 Announce Type: replace-cross 
Abstract: AI-generated counterspeech offers a promising and scalable strategy to curb online toxicity through direct replies that promote civil discourse. However, current counterspeech is one-size-fits-all, lacking adaptation to the moderation context and the users involved. We propose and evaluate multiple strategies for generating tailored counterspeech that is adapted to the moderation context and personalized for the moderated user. We instruct an LLaMA2-13B model to generate counterspeech, experimenting with various configurations based on different contextual information and fine-tuning strategies. We identify the configurations that generate persuasive counterspeech through a combination of quantitative indicators and human evaluations collected via a pre-registered mixed-design crowdsourcing experiment. Results show that contextualized counterspeech can significantly outperform state-of-the-art generic counterspeech in adequacy and persuasiveness, without compromising other characteristics. Our findings also reveal a poor correlation between quantitative indicators and human evaluations, suggesting that these methods assess different aspects and highlighting the need for nuanced evaluation methodologies. The effectiveness of contextualized AI-generated counterspeech and the divergence between human and algorithmic evaluations underscore the importance of increased human-AI collaboration in content moderation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.07338v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.SI</category>
      <pubDate>Fri, 20 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Cima, Alessio Miaschi, Amaury Trujillo, Marco Avvenuti, Felice Dell'Orletta, Stefano Cresci</dc:creator>
    </item>
  </channel>
</rss>
