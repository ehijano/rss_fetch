<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 09 May 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 09 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Is artificial consciousness achievable? Lessons from the human brain</title>
      <link>https://arxiv.org/abs/2405.04540</link>
      <description>arXiv:2405.04540v1 Announce Type: new 
Abstract: We here analyse the question of developing artificial consciousness from an evolutionary perspective, taking the evolution of the human brain and its relation with consciousness as a reference model. This kind of analysis reveals several structural and functional features of the human brain that appear to be key for reaching human-like complex conscious experience and that current research on Artificial Intelligence (AI) should take into account in its attempt to develop systems capable of conscious processing. We argue that, even if AI is limited in its ability to emulate human consciousness for both intrinsic (structural and architectural) and extrinsic (related to the current stage of scientific and technological knowledge) reasons, taking inspiration from those characteristics of the brain that make conscious processing possible and/or modulate it, is a potentially promising strategy towards developing conscious AI. Also, it is theoretically possible that AI research can develop partial or potentially alternative forms of consciousness that is qualitatively different from the human, and that may be either more or less sophisticated depending on the perspectives. Therefore, we recommend neuroscience-inspired caution in talking about artificial consciousness: since the use of the same word consciousness for humans and AI becomes ambiguous and potentially misleading, we propose to clearly specify what is common and what differs in AI conscious processing from full human conscious experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04540v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michele Farisco, Kathinka Evers, Jean-Pierre Changeux</dc:creator>
    </item>
    <item>
      <title>Consciousness Driven Spike Timing Dependent Plasticity</title>
      <link>https://arxiv.org/abs/2405.04546</link>
      <description>arXiv:2405.04546v1 Announce Type: new 
Abstract: Spiking Neural Networks (SNNs), recognized for their biological plausibility and energy efficiency, employ sparse and asynchronous spikes for communication. However, the training of SNNs encounters difficulties coming from non-differentiable activation functions and the movement of spike-based inter-layer data. Spike-Timing Dependent Plasticity (STDP), inspired by neurobiology, plays a crucial role in SNN's learning, but its still lacks the conscious part of the brain used for learning. Considering the issue, this research work proposes a Consciousness Driven STDP (CD-STDP), an improved solution addressing inherent limitations observed in conventional STDP models. CD-STDP, designed to infuse the conscious part as coefficients of long-term potentiation (LTP) and long-term depression (LTD), exhibit a dynamic nature. The model connects LTP and LTD coefficients to current and past state of synaptic activities, respectively, enhancing consciousness and adaptability. This consciousness empowers the model to effectively learn while understanding the input patterns. The conscious coefficient adjustment in response to current and past synaptic activity extends the model's conscious and other cognitive capabilities, offering a refined and efficient approach for real-world applications. Evaluations on MNIST, FashionMNIST and CALTECH datasets showcase $CD$-STDP's remarkable accuracy of 98.6%, 85.61% and 99.0%, respectively, in a single hidden layer SNN. In addition, analysis of conscious elements and consciousness of the proposed model on SNN is performed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04546v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sushant Yadav, Santosh Chaudhary, Rajesh Kumar</dc:creator>
    </item>
    <item>
      <title>Exploring a Cognitive Architecture for Learning Arithmetic Equations</title>
      <link>https://arxiv.org/abs/2405.04550</link>
      <description>arXiv:2405.04550v1 Announce Type: new 
Abstract: The acquisition and performance of arithmetic skills and basic operations such as addition, subtraction, multiplication, and division are essential for daily functioning, and reflect complex cognitive processes. This paper explores the cognitive mechanisms powering arithmetic learning, presenting a neurobiologically plausible cognitive architecture that simulates the acquisition of these skills. I implement a number vectorization embedding network and an associative memory model to investigate how an intelligent system can learn and recall arithmetic equations in a manner analogous to the human brain. I perform experiments that provide insights into the generalization capabilities of connectionist models, neurological causes of dyscalculia, and the influence of network architecture on cognitive performance. Through this interdisciplinary investigation, I aim to contribute to ongoing research into the neural correlates of mathematical cognition in intelligent systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04550v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cole Gawin</dc:creator>
    </item>
    <item>
      <title>Motion Capture Analysis of Verb and Adjective Types in Austrian Sign Language</title>
      <link>https://arxiv.org/abs/2405.05161</link>
      <description>arXiv:2405.05161v1 Announce Type: cross 
Abstract: Across a number of sign languages, temporal and spatial characteristics of dominant hand articulation are used to express semantic and grammatical features. In this study of Austrian Sign Language (\"Osterreichische Geb\"ardensprache, or \"OGS), motion capture data of four Deaf signers is used to quantitatively characterize the kinematic parameters of sign production in verbs and adjectives. We investigate (1) the difference in production between verbs involving a natural endpoint (telic verbs; e.g. arrive) and verbs lacking an endpoint (atelic verbs; e.g. analyze), and (2) adjective signs in intensified vs. non-intensified (plain) forms. Motion capture data analysis using linear-mixed effects models (LME) indicates that both the endpoint marking in verbs, as well as marking of intensification in adjectives, are expressed by movement modulation in \"OGS. While the semantic distinction between verb types (telic/atelic) is marked by higher peak velocity and shorter duration for telic signs compared to atelic ones, the grammatical distinction (intensification) in adjectives is expressed by longer duration for intensified compared to non-intensified adjectives. The observed individual differences of signers might be interpreted as personal signing style.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05161v1</guid>
      <category>cs.CL</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julia Krebs, Evie Malaia, Ronnie B. Wilbur, Isabella Fessl, Hans-Peter Wiesinger, Hermann Schwameder, Dietmar Roehm</dc:creator>
    </item>
    <item>
      <title>Computational characterization of the role of an attention schema in controlling visuospatial attention</title>
      <link>https://arxiv.org/abs/2402.01056</link>
      <description>arXiv:2402.01056v2 Announce Type: replace 
Abstract: How does the brain control attention? The Attention Schema Theory suggests that the brain explicitly models its state of attention, termed an attention schema, for its control. However, it remains unclear under which circumstances an attention schema is computationally useful, and whether it can emerge in a learning system without hard-wiring. To address these questions, we trained a reinforcement learning agent with attention to track and catch a ball in a noisy environment. Crucially, the agent had additional resources that it could freely use. We asked under which conditions these additional resources develop an attention schema to track attention. We found that the more uncertain the agent was about the location of its attentional window, the more it benefited from these additional resources, which developed an attention schema. Together, these results indicate that an attention schema emerges in simple learning systems where attention is important and difficult to track.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01056v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lotta Piefke, Adrien Doerig, Tim Kietzmann, Sushrut Thorat</dc:creator>
    </item>
  </channel>
</rss>
