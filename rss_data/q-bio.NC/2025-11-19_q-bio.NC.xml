<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Nov 2025 02:44:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Subject-Independent Imagined Speech Detection via Cross-Subject Generalization and Calibration</title>
      <link>https://arxiv.org/abs/2511.13739</link>
      <description>arXiv:2511.13739v1 Announce Type: new 
Abstract: Achieving robust generalization across individuals remains a major challenge in electroencephalogram based imagined speech decoding due to substantial variability in neural activity patterns. This study examined how training dynamics and lightweight subject specific adaptation influence cross subject performance in a neural decoding framework. A cyclic inter subject training approach, involving shorter per subject training segments and frequent alternation among subjects, led to modest yet consistent improvements in decoding performance across unseen target data. Furthermore, under the subject calibrated leave one subject out scheme, incorporating only 10 % of the target subjects data for calibration achieved an accuracy of 0.781 and an AUC of 0.801, demonstrating the effectiveness of few shot adaptation. These findings suggest that integrating cyclic training with minimal calibration provides a simple and effective strategy for developing scalable, user adaptive brain computer interface systems that balance generalization and personalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13739v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.SD</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Byung-Kwan Ko, Soowon Kim, Seo-Hyun Lee</dc:creator>
    </item>
    <item>
      <title>A Disentangled Low-Rank RNN Framework for Uncovering Neural Connectivity and Dynamics</title>
      <link>https://arxiv.org/abs/2511.13899</link>
      <description>arXiv:2511.13899v1 Announce Type: new 
Abstract: Low-rank recurrent neural networks (lrRNNs) are a class of models that uncover low-dimensional latent dynamics underlying neural population activity. Although their functional connectivity is low-rank, it lacks disentanglement interpretations, making it difficult to assign distinct computational roles to different latent dimensions. To address this, we propose the Disentangled Recurrent Neural Network (DisRNN), a generative lrRNN framework that assumes group-wise independence among latent dynamics while allowing flexible within-group entanglement. These independent latent groups allow latent dynamics to evolve separately, but are internally rich for complex computation. We reformulate the lrRNN under a variational autoencoder (VAE) framework, enabling us to introduce a partial correlation penalty that encourages disentanglement between groups of latent dimensions. Experiments on synthetic, monkey M1, and mouse voltage imaging data show that DisRNN consistently improves the disentanglement and interpretability of learned neural latent trajectories in low-dimensional space and low-rank connectivity over baseline lrRNNs that do not encourage partial disentanglement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13899v1</guid>
      <category>q-bio.NC</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chengrui Li, Yunmiao Wang, Yule Wang, Weihan Li, Dieter Jaeger, Anqi Wu</dc:creator>
    </item>
    <item>
      <title>A Brain Wave Encodes a Thousand Tokens: Modeling Inter-Cortical Neural Interactions for Effective EEG-based Emotion Recognition</title>
      <link>https://arxiv.org/abs/2511.13954</link>
      <description>arXiv:2511.13954v1 Announce Type: new 
Abstract: Human emotions are difficult to convey through words and are often abstracted in the process; however, electroencephalogram (EEG) signals can offer a more direct lens into emotional brain activity. Recent studies show that deep learning models can process these signals to perform emotion recognition with high accuracy. However, many existing approaches overlook the dynamic interplay between distinct brain regions, which can be crucial to understanding how emotions unfold and evolve over time, potentially aiding in more accurate emotion recognition. To address this, we propose RBTransformer, a Transformer-based neural network architecture that models inter-cortical neural dynamics of the brain in latent space to better capture structured neural interactions for effective EEG-based emotion recognition. First, the EEG signals are converted into Band Differential Entropy (BDE) tokens, which are then passed through Electrode Identity embeddings to retain spatial provenance. These tokens are processed through successive inter-cortical multi-head attention blocks that construct an electrode x electrode attention matrix, allowing the model to learn the inter-cortical neural dependencies. The resulting features are then passed through a classification head to obtain the final prediction. We conducted extensive experiments, specifically under subject-dependent settings, on the SEED, DEAP, and DREAMER datasets, over all three dimensions, Valence, Arousal, and Dominance (for DEAP and DREAMER), under both binary and multi-class classification settings. The results demonstrate that the proposed RBTransformer outperforms all previous state-of-the-art methods across all three datasets, over all three dimensions under both classification settings. The source code is available at: https://github.com/nnilayy/RBTransformer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13954v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nilay Kumar, Priyansh Bhandari, G. Maragatham</dc:creator>
    </item>
    <item>
      <title>Intrinsic Resonance depends on Network Size of Coupled-Delayed Interacting Oscillators</title>
      <link>https://arxiv.org/abs/2511.14065</link>
      <description>arXiv:2511.14065v1 Announce Type: new 
Abstract: The collective frequency that emerges from synchronized neuronal populations--the network resonance--shows a systematic relationship with brain size: whole-brain's large networks oscillate slowly, whereas finer parcellations of fixed volume exhibit faster rhythms. This resonance-size scaling has been reported in delayed neural mass models and human neuroimaging, yet the physical mechanism remained unresolved. Here we show that size-dependent resonance follows directly from propagation delays in delay-coupled phase oscillators. Starting from a Kuramoto model with heterogeneous delays, we linearize around the near-synchronous solution and obtain a closed-form approximation linking the resonance $\Omega$ to the mean delay and the effective coupling field. The analysis predicts a generic scaling law: $\Omega \approx (\sum_j c_{ij} \tau)^{-1}$, so resonance is delay-limited and therefore depends systematically on geometric size or parcellation density. We evaluate four growth scenarios--expanding geometry, fixed-volume parcellation, constant geometry, and an unphysical reference case--and show that only geometry-consistent scaling satisfies the analytical prediction. Numerical simulations with heterogeneous delays validate the law and quantify its error as a function of delay dispersion. These results identify a minimal physical mechanism for size-dependent cortical resonance and provide an analytical framework that unifies numeric simulation outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14065v1</guid>
      <category>q-bio.NC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe A. Torres, Alejandro Weinstein, Jesus M. Cortes, Wael El-Deredy</dc:creator>
    </item>
    <item>
      <title>A region-specific brain dysfunction underlies cognitive impairment in long COVID brain fog</title>
      <link>https://arxiv.org/abs/2511.14188</link>
      <description>arXiv:2511.14188v2 Announce Type: new 
Abstract: Long COVID "brain fog" is a common and debilitating subjective syndrome often associated with persistent cognitive impairment after COVID-19 infection. Here we identify a specific regional brain dysfunction that mediates this cognitive impairment and provide evidence that targeted neuromodulation improves this deficit. In 120 patients with long COVID brain fog, we found an aberrant perceptual processing pattern. Patients with more severe brain fog committed significantly more false alarms (impulsive responses to non-signals) despite preserved overall accuracy. Both high-density (128-channel) EEG and structural MRI analyses provided converging evidence of a right inferior insula deficit, characterized by a blunted neural monitoring signal and cortical atrophy. We confirmed this deficit in a separate 796-participant UK Biobank longitudinal COVID re-imaging cohort, where COVID-19 survivors also showed selective impairment on a perceptual processing task and corresponding longitudinal atrophy of the right inferior insula compared with healthy controls. Finally, in a proof-of-principle randomized, sham-controlled trial (n = 40), a non-invasive, excitatory theta-burst ultrasound stimulation protocol targeting the right inferior insula rescued the perceptual deficit by reducing false alarms. These findings provide evidence of a causal role for right inferior insula dysfunction in long COVID-related perceptual impairment and show that modulation of this region can rescue the deficit, establishing it as a novel therapeutic target for long COVID cognitive impairment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14188v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinhao Yang, Shaojiong Zhou, Zhibin Wang, Jiahua Xu, Jia Chen, Zhouqian Yin, Tao Wei, Chaofan Geng, Xiaoduo Liu, Xiang Li, Xiaoyu Zhou, Kun Li, Ruolei Gu, Raymond Dolan, Yi Tang, Yunzhe Liu</dc:creator>
    </item>
    <item>
      <title>Multi-network Topology Underlying Individual Language Learning Success</title>
      <link>https://arxiv.org/abs/2511.14453</link>
      <description>arXiv:2511.14453v1 Announce Type: new 
Abstract: Adult language learning varies greatly among individuals. Traditionally associated with frontotemporal language regions, this variability is increasingly seen as stemming from distributed brain networks. However, the role of these networks and their topological organization in explaining these differences remains unclear. We hypothesize that graph-theory-based network analysis of intrinsic multimodal connectivities across multiple networks explains overall and component-specific variations in language learning. We tested this in 101 healthy adults who underwent resting-state fMRI, structural MRI, and diffusion tensor imaging before seven days of six artificial language training tasks. We identified one dominant general learning component shared across tasks and five task-specific ones. Cross-validated predictive models used multimodal multi-network graph-theoretic metrics to predict final learning outcomes (LO) and rates (LR). We significantly predicted the LO and LR of the general component, which were primarily contributed by dorsal attention and frontoparietal networks. Nodal local efficiency was the most consistent predictor, with additional contributions from node clustering coefficient and network centrality for LR, highlighting local robustness, mesoscale network segregation, and global influence in explaining individual differences. Only task-specific word learning LO was predictable, relying on default mode and frontoparietal hubs with high betweenness centrality and efficiency. These findings demonstrate that intrinsic network topologies underlie differences in language learning success, supporting a multiple-systems hypothesis in which attentional-control networks interact with default and subcortical systems to shape learning trajectories. This advances mechanistic understanding and paves the way for personalized language education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14453v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peilun Song, Shuguang Yang, Xiujuan Geng, Zhenzhong Gan, Suiping Wang, Gangyi Feng</dc:creator>
    </item>
    <item>
      <title>Effect of Dopamine in Enhancement of SNR of Cortico-Striatal-Thalamo-Cortical Loop Spiking</title>
      <link>https://arxiv.org/abs/2511.14466</link>
      <description>arXiv:2511.14466v1 Announce Type: new 
Abstract: In this work, the effects of dopamine neurotransmitter within the Cortico-Striatal-Thalamo-Cortical (CSTC) loop. Simulations confirmed dopamine facilitates movement via thalamic disinhibition. Analysis of its impact on the signal-to-noise ratio (SNR) revealed a complex, region-specific outcome: SNR increased in some regions (e.g., D2 Striatum: 3.41 dB to 6.25 dB), decreased in others (e.g., Thalamus VL: 6.24 dB to 3.93 dB), and remained stable elsewhere (e.g., M1: 3.16 dB to 3.13 dB). This heterogeneity stems from dopamine increasing the excitability of D1-receptor-expressing neurons, which amplifies channel conductance noise and reduces SNR in specific circuits. Thus, dopamine acts not as a uniform signal enhancer, but as a complex modulator that critically balances facilitation and noise within the CSTC loop.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14466v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Barati, Ali Nayerifar, Mehdi Fardmanesh</dc:creator>
    </item>
    <item>
      <title>DecNefLab: A Modular and Interpretable Simulation Framework for Decoded Neurofeedback</title>
      <link>https://arxiv.org/abs/2511.14555</link>
      <description>arXiv:2511.14555v1 Announce Type: new 
Abstract: Decoded Neurofeedback (DecNef) is a flourishing non-invasive approach to brain modulation with wide-ranging applications in neuromedicine and cognitive neuroscience. However, progress in DecNef research remains constrained by subject-dependent learning variability, reliance on indirect measures to quantify progress, and the high cost and time demands of experimentation.
  We present DecNefLab, a modular and interpretable simulation framework that formalizes DecNef as a machine learning problem. Beyond providing a virtual laboratory, DecNefLab enables researchers to model, analyze and understand neurofeedback dynamics. Using latent variable generative models as simulated participants, DecNefLab allows direct observation of internal cognitive states and systematic evaluation of how different protocol designs and subject characteristics influence learning.
  We demonstrate how this approach can (i) reproduce empirical phenomena of DecNef learning, (ii) identify conditions under which DecNef feedback fails to induce learning, and (iii) guide the design of more robust and reliable DecNef protocols in silico before human implementation.
  In summary, DecNefLab bridges computational modeling and cognitive neuroscience, offering a principled foundation for methodological innovation, robust protocol design, and ultimately, a deeper understanding of DecNef-based brain modulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14555v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alexander Olza, Roberto Santana, David Soto</dc:creator>
    </item>
    <item>
      <title>THD-BAR: Topology Hierarchical Derived Brain Autoregressive Modeling for EEG Generic Representations</title>
      <link>https://arxiv.org/abs/2511.13733</link>
      <description>arXiv:2511.13733v1 Announce Type: cross 
Abstract: Large-scale pre-trained models hold significant potential for learning universal EEG representations. However, most existing methods, particularly autoregressive (AR) frameworks, primarily rely on straightforward temporal sequencing of multi-channel EEG data, which fails to capture the rich physiological characteristics inherent to EEG signals. Moreover, their time-centered modeling approach also limits the effective representation of the dynamic spatial topology of brain activity. To address these challenges and fully exploit the potential of large-scale EEG models, we propose a novel Topology Hierarchical Derived Brain Autoregressive Modeling (THD-BAR) for EEG generic representations. The core innovation of THD-BAR lies in the introduction of the Brain Topology Hierarchy (BTH), which establishes a multi-scale spatial order for EEG channels. This hierarchical structure enables a redefinition of autoregressive learning as a "next-scale-time prediction" problem, effectively capturing both spatial and temporal dynamics. Based on BTH, we design a Topology-Hierarchical Vector Quantized-Variational Autoencoder (THVQ-VAE) for multi-scale tokenization and develop an enhanced Brain Autoregressive (BAR) module with specialized masking strategies for prediction. Through extensive large-scale pre-training on 17 datasets, followed by rigorous validation on 10 downstream datasets spanning 5 distinct tasks, THD-BAR consistently outperforms existing methods. These results highlight the superior generalization and modeling capabilities of our proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.13733v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wenchao Yang, Weidong Yan, Wenkang Liu, Yulan Ma, Yang Li</dc:creator>
    </item>
    <item>
      <title>A simple EEG-based decision tool for neonatal therapeutic hypothermia in hypoxic-ischemic encephalopathy</title>
      <link>https://arxiv.org/abs/2403.20239</link>
      <description>arXiv:2403.20239v4 Announce Type: replace 
Abstract: Objective Accurate identification of hypoxic-ischemic brain injury in the early neonatal period is essential for initiating therapeutic hypothermia (TH) within 6 hours of birth to optimize neurodevelopmental outcomes. We aimed to develop a simple decision-making tool for identifying term neonates with hypoxic-ischemic encephalopathy (HIE) based on features of conventional electroencephalograms (EEG) recorded within 6 hours of birth. Methods EEG recordings from 100 full-term neonates with HIE were graded by pediatric neurologists for severity. Amplitude in slow frequency bands was analyzed, focusing on delta (0.5-4 Hz) spectral power. Temporal fluctuations of delta power characterized each HIE grade, with joint level and duration probability densities estimated for delta oscillation power. This study is registered on clinicaltrials.gouv (NCT05114070). Results These 2D EEG representations effectively distinguish mild HIE cases from those requiring hypothermia, achieving 98% accuracy, 99% sensitivity, 99% positive predictive value, 94% negative predictive value, an F1 score of 99%, and a false alarm rate of only 6%. This system accurately discriminates mild from moderate or severe HIE, with only one mild case mistakenly identified as requiring hypothermia and one moderate case erroneously flagged for treatment. Conclusions Quantized probability densities of delta spectral features from early EEG (within 6 hours of birth) revealed significant differences between mild and moderate/severe HIE, enabling accurate discrimination of candidates for TH. Significance Simple, interpretable biomarkers from early EEG can provide an efficient visual clinical decision support tool to identify full-term neonates with HIE eligible for therapeutic hypothermia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.20239v4</guid>
      <category>q-bio.NC</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cmpb.2025.109166</arxiv:DOI>
      <dc:creator>Marc Fiammante (Paris Brain Institute, Inserm U1127, CNRS UMR7225, Sorbonne Universite UM75, Inria Paris, Retired IBM Fellow), Anne-Isabelle Vermersch (Physiology &amp; Paediatric Functional Explorations Unit, Armand Trousseau Hospital, Paris, France), Marie Vidailhet (Paris Brain Institute, Inserm U1127, CNRS UMR7225, Sorbonne Universite UM75, Inria Paris, Institut de Neurologie, Pitie-Salpetriere Hospital, Paris, France), Mario Chavez (CNRS UMR-7225, Pitie-Salpetriere Hospital, Paris, France)</dc:creator>
    </item>
    <item>
      <title>Quantum Models of Consciousness from a Quantum Information Science Perspective</title>
      <link>https://arxiv.org/abs/2501.03241</link>
      <description>arXiv:2501.03241v3 Announce Type: replace 
Abstract: This perspective explores various quantum models of consciousness from the viewpoint of quantum information science, offering potential ideas and insights. The models under consideration can be categorized into three distinct groups based on the level at which quantum mechanics might operate within the brain: those suggesting that consciousness arises from electron delocalization within microtubules inside neurons, those proposing it emerges from the electromagnetic field surrounding the entire neural network, and those positing it originates from the interactions between individual neurons governed by neurotransmitter molecules. Our focus is particularly on the Posner model of cognition, for which we provide preliminary calculations on the preservation of entanglement of phosphate molecules within the geometric structure of Posner clusters. These findings provide valuable insights into how quantum information theory can enhance our understanding of brain functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.03241v3</guid>
      <category>q-bio.NC</category>
      <category>quant-ph</category>
      <pubDate>Wed, 19 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.3390/e27030243</arxiv:DOI>
      <arxiv:journal_reference>Entropy 2025, 27, 243</arxiv:journal_reference>
      <dc:creator>Lea Gassab, Onur Pusuluk, Marco Cattaneo, \"Ozg\"ur E. M\"ustecapl{\i}o\u{g}lu</dc:creator>
    </item>
  </channel>
</rss>
