<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-fin.MF updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-fin.MF</link>
    <description>q-fin.MF updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-fin.MF" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Oct 2025 01:55:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Schr\"odinger bridge for generative AI: Soft-constrained formulation and convergence analysis</title>
      <link>https://arxiv.org/abs/2510.11829</link>
      <description>arXiv:2510.11829v1 Announce Type: cross 
Abstract: Generative AI can be framed as the problem of learning a model that maps simple reference measures into complex data distributions, and it has recently found a strong connection to the classical theory of the Schr\"odinger bridge problems (SBPs) due partly to their common nature of interpolating between prescribed marginals via entropy-regularized stochastic dynamics. However, the classical SBP enforces hard terminal constraints, which often leads to instability in practical implementations, especially in high-dimensional or data-scarce regimes. To address this challenge, we follow the idea of the so-called soft-constrained Schr\"odinger bridge problem (SCSBP), in which the terminal constraint is replaced by a general penalty function. This relaxation leads to a more flexible stochastic control formulation of McKean-Vlasov type.
  We establish the existence of optimal solutions for all penalty levels and prove that, as the penalty grows, both the controls and value functions converge to those of the classical SBP at a linear rate. Our analysis builds on Doob's h-transform representations, the stability results of Schr\"odinger potentials, Gamma-convergence, and a novel fixed-point argument that couples an optimization problem over the space of measures with an auxiliary entropic optimal transport problem. These results not only provide the first quantitative convergence guarantees for soft-constrained bridges but also shed light on how penalty regularization enables robust generative modeling, fine-tuning, and transfer learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11829v1</guid>
      <category>cs.LG</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jin Ma, Ying Tan, Renyuan Xu</dc:creator>
    </item>
    <item>
      <title>On time-consistent equilibrium stopping under aggregation of diverse discount rates</title>
      <link>https://arxiv.org/abs/2302.07470</link>
      <description>arXiv:2302.07470v4 Announce Type: replace 
Abstract: This paper studies a central planner's decision making on behalf of a group of members with diverse discount rates. In the context of optimal stopping, we work with an aggregation preference to incorporate all discount rates via an attitude function that reflects the aggregation rule chosen by the central planner. The problem formulation is also applicable to single agent's stopping problem with uncertain discount rate, where our aggregation preference coincides with the conventional smooth ambiguity preference. The resulting optimal stopping problem is time inconsistent, for which we develop an iterative approach using consistent planning and characterize all time-consistent mild equilibria as fixed points of an operator in the setting of one-dimensional diffusion processes. We provide some sufficient conditions on the underlying models and the attitude function such that the smallest mild equilibrium attains the optimal equilibrium. In addition, we show that the optimal equilibrium is a weak equilibrium. When the sufficient condition of the attitude function is violated, we illustrate by various examples that the characterization of the optimal equilibrium may differ significantly from some existing results for a single agent, which now sensitively depends on the attitude function and the diversity distribution of discount rates within the group.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.07470v4</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuoqing Deng, Xiang Yu, Jiacheng Zhang</dc:creator>
    </item>
    <item>
      <title>Computing Systemic Risk Measures with Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2410.07222</link>
      <description>arXiv:2410.07222v2 Announce Type: replace-cross 
Abstract: This paper investigates systemic risk measures for stochastic financial networks of explicitly modelled bilateral liabilities. We extend the notion of systemic risk measures from Biagini, Fouque, Fritelli and Meyer-Brandis (2019) to graph structured data. In particular, we focus on an aggregation function that is derived from a market clearing algorithm proposed by Eisenberg and Noe (2001). In this setting, we show the existence of an optimal random allocation that distributes the overall minimal bailout capital and secures the network. We study numerical methods for the approximation of systemic risk and optimal random allocations. We propose to use permutation equivariant architectures of neural networks like graph neural networks (GNNs) and a class that we name (extended) permutation equivariant neural networks ((X)PENNs). We compare their performance to several benchmark allocations. The main feature of GNNs and (X)PENNs is that they are permutation equivariant with respect to the underlying graph data. In numerical experiments we find evidence that these permutation equivariant methods are superior to other approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.07222v2</guid>
      <category>q-fin.CP</category>
      <category>cs.LG</category>
      <category>q-fin.MF</category>
      <pubDate>Wed, 15 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Lukas Gonon, Thilo Meyer-Brandis, Niklas Weber</dc:creator>
    </item>
  </channel>
</rss>
