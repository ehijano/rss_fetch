<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2024 04:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Manifold-based transformation of the probability distribution for convergence in optimization</title>
      <link>https://arxiv.org/abs/2410.01499</link>
      <description>arXiv:2410.01499v1 Announce Type: new 
Abstract: Reconstructing probability distributions from experimental data is a crucial problem across various fields. An effective approach is to optimize a theoretical or computational model of the distribution under an objective functional that evaluates consistency with the experimental data. However, achieving convergence in optimization remains a challenge. Given the manifold structure of the probability distribution space, we demonstrate that transformation of distribution in optimization should be infinitesimal displacements along exponential geodesics. Our theory was validated through the reconstruction of protein conformational ensembles, showing its broad applicability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01499v1</guid>
      <category>physics.data-an</category>
      <category>cond-mat.stat-mech</category>
      <category>physics.bio-ph</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tomotaka Oroguchi, Rintaro Inoue, Masaaki Sugiyama</dc:creator>
    </item>
    <item>
      <title>Lines of Thought in Large Language Models</title>
      <link>https://arxiv.org/abs/2410.01545</link>
      <description>arXiv:2410.01545v1 Announce Type: cross 
Abstract: Large Language Models achieve next-token prediction by transporting a vectorized piece of text (prompt) across an accompanying embedding space under the action of successive transformer layers. The resulting high-dimensional trajectories realize different contextualization, or 'thinking', steps, and fully determine the output probability distribution. We aim to characterize the statistical properties of ensembles of these 'lines of thought.' We observe that independent trajectories cluster along a low-dimensional, non-Euclidean manifold, and that their path can be well approximated by a stochastic equation with few parameters extracted from data. We find it remarkable that the vast complexity of such large models can be reduced to a much simpler form, and we reflect on implications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01545v1</guid>
      <category>cs.LG</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rapha\"el Sarfati, Toni J. B. Liu, Nicolas Boull\'e, Christopher J. Earls</dc:creator>
    </item>
    <item>
      <title>QESM: A Leap Towards Quantum-Enhanced ML Emulation Framework for Earth and Climate Modeling</title>
      <link>https://arxiv.org/abs/2410.01551</link>
      <description>arXiv:2410.01551v1 Announce Type: cross 
Abstract: Current climate models often struggle with accuracy because they lack sufficient resolution, a limitation caused by computational constraints. This reduces the precision of weather forecasts and long-term climate predictions. To address this issue, we explored the use of quantum computing to enhance traditional machine learning (ML) models. We replaced conventional models like Convolutional Neural Networks (CNN), Multilayer Perceptrons (MLP), and Encoder-Decoder frameworks with their quantum versions: Quantum Convolutional Neural Networks (QCNN), Quantum Multilayer Perceptrons (QMLP), and Quantum Encoder-Decoders (QED). These quantum models proved to be more accurate in predicting climate-related outcomes compared to their classical counterparts. Using the ClimSim dataset, a large collection of climate data created specifically for ML-based climate prediction, we trained and tested these quantum models. Individually, the quantum models performed better, but their performance was further improved when we combined them using a meta-ensemble approach, which merged the strengths of each model to achieve the highest accuracy overall. This study demonstrates that quantum machine learning can significantly improve the resolution and accuracy of climate simulations. The results offer new possibilities for better predicting climate trends and weather events, which could have important implications for both scientific understanding and policy-making in the face of global climate challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01551v1</guid>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <category>quant-ph</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adib Bazgir, Yuwen Zhang</dc:creator>
    </item>
    <item>
      <title>Uncertainty Quantification with Bayesian Higher Order ReLU KANs</title>
      <link>https://arxiv.org/abs/2410.01687</link>
      <description>arXiv:2410.01687v1 Announce Type: cross 
Abstract: We introduce the first method of uncertainty quantification in the domain of Kolmogorov-Arnold Networks, specifically focusing on (Higher Order) ReLUKANs to enhance computational efficiency given the computational demands of Bayesian methods. The method we propose is general in nature, providing access to both epistemic and aleatoric uncertainties. It is also capable of generalization to other various basis functions. We validate our method through a series of closure tests, including simple one-dimensional functions and application to the domain of (Stochastic) Partial Differential Equations. Referring to the latter, we demonstrate the method's ability to correctly identify functional dependencies introduced through the inclusion of a stochastic term. The code supporting this work can be found at https://github.com/wmdataphys/Bayesian-HR-KAN</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01687v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James Giroux, Cristiano Fanelli</dc:creator>
    </item>
    <item>
      <title>Impact of Redshift Space Distortion on Persistent Homology of cosmic matter density field</title>
      <link>https://arxiv.org/abs/2410.01751</link>
      <description>arXiv:2410.01751v1 Announce Type: cross 
Abstract: By employing summary statistics obtained from Persistent Homology (PH), we investigate the influence of Redshift Space Distortion (RSD) on the topology of excursion sets formed through the super-level filtration method applied to three-dimensional matter density fields. The synthetic fields simulated by the Quijote suite in both real and redshift spaces are smoothed by accounting for the Gaussian smoothing function with different scales. The RSD leads a tendency for clusters ($\tilde{\beta}_0$) to shift towards higher thresholds, while filament loops ($\tilde{\beta}_1$) and cosmic voids ($\tilde{\beta}_2$) migrate towards lower thresholds. Notably, $\tilde{\beta}_2$ exhibits greater sensitivity to RSD compared to clusters and independent loops. As the smoothing scales increase, the amplitude of the reduced Betti number curve ($\tilde{\beta}_k$) decreases, and the corresponding peak position shifts towards the mean threshold. Conversely, the amplitude of $\tilde{\beta}_k$ remains almost unchanged with variations in redshift for $z\in[0-3]$. The analysis of persistent entropy and the overall abundance of $k$-holes indicates that the linear Kaiser effect plays a significant role compared to the non-linear effect for $R \gtrsim 30$ Mpc $h^{-1}$ at $z=0$, whereas persistent entropy proves to be a reliable measure against non-linear influences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01751v1</guid>
      <category>astro-ph.CO</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatemeh Abedi, Mohammad Hossein Jalali Kanafi, S. M. S. Movahed</dc:creator>
    </item>
    <item>
      <title>Deep Bayesian Filter for Bayes-faithful Data Assimilation</title>
      <link>https://arxiv.org/abs/2405.18674</link>
      <description>arXiv:2405.18674v2 Announce Type: replace-cross 
Abstract: State estimation for nonlinear state space models (SSMs) is a challenging task. Existing assimilation methodologies predominantly assume Gaussian posteriors on physical space, where true posteriors become inevitably non-Gaussian. We propose Deep Bayesian Filtering (DBF) for data assimilation on nonlinear SSMs. DBF constructs new latent variables $h_t$ in addition to the original physical variables $z_t$ and assimilates observations $o_t$. By (i) constraining the state transition on the new latent space to be linear and (ii) learning a Gaussian inverse observation operator $r(h_t|o_t)$, posteriors remain Gaussian. Notably, the structured design of test distributions enables an analytical formula for the recursive computation, eliminating the accumulation of Monte Carlo sampling errors across time steps. DBF trains the Gaussian inverse observation operators $r(h_t|o_t)$ and other latent SSM parameters (e.g., dynamics matrix) by maximizing the evidence lower bound. Experiments demonstrate that DBF outperforms model-based approaches and latent assimilation methods in tasks where the true posterior distribution on physical space is significantly non-Gaussian.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18674v2</guid>
      <category>cs.LG</category>
      <category>physics.ao-ph</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuta Tarumi, Keisuke Fukuda, Shin-ichi Maeda</dc:creator>
    </item>
    <item>
      <title>A unified machine learning approach for reconstructing hadronically decaying tau leptons</title>
      <link>https://arxiv.org/abs/2407.06788</link>
      <description>arXiv:2407.06788v2 Announce Type: replace-cross 
Abstract: Tau leptons serve as an important tool for studying the production of Higgs and electroweak bosons, both within and beyond the Standard Model of particle physics.Accurate reconstruction and identification of hadronically decaying tau leptons is a crucial task for current and future high energy physics experiments. Given the advances in jet tagging, we demonstrate how tau lepton reconstruction can be decomposed into tau identification, kinematic reconstruction, and decay mode classification in a multi-task machine learning setup. Based on an electron-positron collision dataset with full detector simulation and reconstruction, we show that common jet tagging architectures can be effectively used for these sub-tasks. We achieve comparable momentum resolutions of 2-3% with all the tested models, while the precision of reconstructing individual decay modes is between 80-95%. We find ParticleTransformer to be the best-performing approach, significantly outperforming the heuristic baseline. This paper also serves as an introduction to a new publicly available $\mathtt{Fu}\tau\mathtt{ure}$ dataset for the development of tau reconstruction algorithms. This allows to further study the resilience of ML models to domain shifts and the efficient use of foundation models for such tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06788v2</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Laurits Tani, Nalong-Norman Seeba, Hardi Vanaveski, Joosep Pata, Torben Lange</dc:creator>
    </item>
  </channel>
</rss>
