<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Feb 2025 02:43:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimality in importance sampling: a gentle survey</title>
      <link>https://arxiv.org/abs/2502.07396</link>
      <description>arXiv:2502.07396v1 Announce Type: new 
Abstract: The performance of the Monte Carlo sampling methods relies on the crucial choice of a proposal density. The notion of optimality is fundamental to design suitable adaptive procedures of the proposal density within Monte Carlo schemes. This work is an exhaustive review around the concept of optimality in importance sampling. Several frameworks are described and analyzed, such as the marginal likelihood approximation for model selection, the use of multiple proposal densities, a sequence of tempered posteriors, and noisy scenarios including the applications to approximate Bayesian computation (ABC) and reinforcement learning, to name a few. Some theoretical and empirical comparisons are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07396v1</guid>
      <category>stat.CO</category>
      <category>cs.CE</category>
      <category>stat.ML</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Llorente, Luca Martino</dc:creator>
    </item>
    <item>
      <title>Method of moments for Gaussian mixtures: Implementation and benchmarks</title>
      <link>https://arxiv.org/abs/2502.07648</link>
      <description>arXiv:2502.07648v1 Announce Type: new 
Abstract: Gaussian mixture models are universal approximators in the sense that any smooth density can be approximated arbitrarily well with a Gaussian mixture model with enough components. Due to their broad expressive power, Gaussian mixture models appear in many applications. As a result, algebraic parameter recovery for Gaussian mixture models from data is a valuable contribution to multiple fields. Our work documents performance of the method of moments for high dimensional Gaussian mixtures. We outline the method of moments, and selections of moments and their corresponding polynomials that work well for parameter recovery in practice. Our main contribution puts these ideas into practice with an implementation as a julia package, GMMParameterEstimation, as well as computational benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07648v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Haley Colgate Kottler, Julia Lindberg, Jose Israel Rodriguez</dc:creator>
    </item>
    <item>
      <title>Online Covariance Matrix Estimation in Sketched Newton Methods</title>
      <link>https://arxiv.org/abs/2502.07114</link>
      <description>arXiv:2502.07114v1 Announce Type: cross 
Abstract: Given the ubiquity of streaming data, online algorithms have been widely used for parameter estimation, with second-order methods particularly standing out for their efficiency and robustness. In this paper, we study an online sketched Newton method that leverages a randomized sketching technique to perform an approximate Newton step in each iteration, thereby eliminating the computational bottleneck of second-order methods. While existing studies have established the asymptotic normality of sketched Newton methods, a consistent estimator of the limiting covariance matrix remains an open problem. We propose a fully online covariance matrix estimator that is constructed entirely from the Newton iterates and requires no matrix factorization. Compared to covariance estimators for first-order online methods, our estimator for second-order methods is batch-free. We establish the consistency and convergence rate of our estimator, and coupled with asymptotic normality results, we can then perform online statistical inference for the model parameters based on sketched Newton methods. We also discuss the extension of our estimator to constrained problems, and demonstrate its superior performance on regression problems as well as benchmark problems in the CUTEst set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07114v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Kuang, Mihai Anitescu, Sen Na</dc:creator>
    </item>
    <item>
      <title>Cheap Permutation Testing</title>
      <link>https://arxiv.org/abs/2502.07672</link>
      <description>arXiv:2502.07672v1 Announce Type: cross 
Abstract: Permutation tests are a popular choice for distinguishing distributions and testing independence, due to their exact, finite-sample control of false positives and their minimax optimality when paired with U-statistics. However, standard permutation tests are also expensive, requiring a test statistic to be computed hundreds or thousands of times to detect a separation between distributions. In this work, we offer a simple approach to accelerate testing: group your datapoints into bins and permute only those bins. For U and V-statistics, we prove that these cheap permutation tests have two remarkable properties. First, by storing appropriate sufficient statistics, a cheap test can be run in time comparable to evaluating a single test statistic. Second, cheap permutation power closely approximates standard permutation power. As a result, cheap tests inherit the exact false positive control and minimax optimality of standard permutation tests while running in a fraction of the time. We complement these findings with improved power guarantees for standard permutation testing and experiments demonstrating the benefits of cheap permutations over standard maximum mean discrepancy (MMD), Hilbert-Schmidt independence criterion (HSIC), random Fourier feature, Wilcoxon-Mann-Whitney, cross-MMD, and cross-HSIC tests.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.07672v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Raaz Dwivedi, Lester Mackey</dc:creator>
    </item>
    <item>
      <title>Derivative based global sensitivity analysis and its entropic link</title>
      <link>https://arxiv.org/abs/2310.00551</link>
      <description>arXiv:2310.00551v3 Announce Type: replace-cross 
Abstract: Variance-based Sobol' sensitivity is one of the most well-known measures in global sensitivity analysis (GSA). However, uncertainties with certain distributions, such as highly skewed distributions or those with a heavy tail, cannot be adequately characterised using the second central moment only. Entropy-based GSA can consider the entire probability density function, but its application has been limited because it is difficult to estimate. Here we present a novel derivative-based upper bound for conditional entropies, to efficiently rank uncertain variables and to work as a proxy for entropy-based total effect indices. To overcome the non-desirable issue of negativity for differential entropies as sensitivity indices, we discuss an exponentiation of the total effect entropy and its proxy. Numerical verifications demonstrate that the upper bound is tight for monotonic functions and it provides the same input variable ranking as the entropy-based indices for about three-quarters of the 1000 random functions tested. We found that the new entropy proxy performs similarly to the variance-based proxies for a river flood physics model with 8 inputs of different distributions, and these two proxies are equivalent in the special case of linear functions with Gaussian inputs. We expect the new entropy proxy to increase the variable screening power of derivative-based GSA and to complement Sobol'-indices proxy for a more diverse type of distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00551v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <category>stat.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/00401706.2025.2455143</arxiv:DOI>
      <arxiv:journal_reference>Technometrics 2025</arxiv:journal_reference>
      <dc:creator>Jiannan Yang</dc:creator>
    </item>
    <item>
      <title>Natural Variational Annealing for Multimodal Optimization</title>
      <link>https://arxiv.org/abs/2501.04667</link>
      <description>arXiv:2501.04667v2 Announce Type: replace-cross 
Abstract: We introduce a new multimodal optimization approach called Natural Variational Annealing (NVA) that combines the strengths of three foundational concepts to simultaneously search for multiple global and local modes of black-box nonconvex objectives. First, it implements a simultaneous search by using variational posteriors, such as, mixtures of Gaussians. Second, it applies annealing to gradually trade off exploration for exploitation. Finally, it learns the variational search distribution using natural-gradient learning where updates resemble well-known and easy-to-implement algorithms. The three concepts come together in NVA giving rise to new algorithms and also allowing us to incorporate "fitness shaping", a core concept from evolutionary algorithms. We assess the quality of search on simulations and compare them to methods using gradient descent and evolution strategies. We also provide an application to a real-world inverse problem in planetary science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04667v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>T\^am Le Minh, Julyan Arbel, Thomas M\"ollenhoff, Mohammad Emtiyaz Khan, Florence Forbes</dc:creator>
    </item>
    <item>
      <title>A Tutorial on Markov Renewal and Semi-Markov Proportional Hazards Model</title>
      <link>https://arxiv.org/abs/2502.03479</link>
      <description>arXiv:2502.03479v3 Announce Type: replace-cross 
Abstract: Transition probability estimation plays a critical role in multi-state modeling, especially in clinical research. This paper investigates the application of semi-Markov and Markov renewal frameworks to the EBMT dataset, focusing on six clinical states encountered during hematopoietic stem cell transplantation. By comparing Aalen-Johansen (AJ) and Dabrowska-Sun-Horowitz (DSH) estimators, we demonstrate that semi-Markov models, which incorporate sojourn times, provide a more nuanced and temporally sensitive depiction of patient trajectories compared to memoryless Markov models. The DSH estimator consistently yields smoother probability curves, particularly for transitions involving prolonged states. We use empirical process theory and Burkholder-Davis-Gundy inequality to show weak convergence of the estimator. Future work includes extending the framework to accommodate advanced covariate structures and non-Markovian dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03479v3</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Wed, 12 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eliuvish Cuicizion, Itsugo Ri, Elaine Holmes, Jawad Chern</dc:creator>
    </item>
  </channel>
</rss>
