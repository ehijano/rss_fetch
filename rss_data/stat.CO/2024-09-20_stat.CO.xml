<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 20 Sep 2024 04:01:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Optimizing MCMC-Driven Bayesian Neural Networks for High-Precision Medical Image Classification in Small Sample Sizes</title>
      <link>https://arxiv.org/abs/2409.12355</link>
      <description>arXiv:2409.12355v1 Announce Type: new 
Abstract: This paper discusses the application of a Bayesian neural network based on the Markov Chain Monte Carlo method in medical image classification with small samples. Experimental results on two medical image datasets, including lung X-ray images and breast tissue slice images, show that this MCMC-based BNN model works very well on small-sample data and greatly improves the robustness and accuracy of classification. Model accuracy reached 85% for the lung X-ray dataset and 88% for the breast tissue slice dataset. To this end, we combine data augmentation techniques such as rotation, flipping, and scaling with regularization methods like dropout and weight decay to improve effectively the diversity of the training data and the generalization ability of the model. The performance of the model was evaluated by many indicators of the results, including accuracy, precision, recall, and the F1 score. All of these have proven the advantages of BNN in small-sample medical image classification. This study not only enriches the application of BNN in the field of medical image classification, but also provides specific implementation paths and optimization methods, providing new solutions for future medical image analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12355v1</guid>
      <category>stat.CO</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingyu Sun</dc:creator>
    </item>
    <item>
      <title>CLE-SH: Comprehensive Literal Explanation package for SHapley values by statistical validity</title>
      <link>https://arxiv.org/abs/2409.12578</link>
      <description>arXiv:2409.12578v1 Announce Type: new 
Abstract: Recently, SHapley Additive exPlanations (SHAP) has been widely utilized in various research domains. This is particularly evident in medical applications, where SHAP analysis serves as a crucial tool for identifying biomarkers and assisting in result validation. However, despite its frequent usage, SHAP is often not applied in a manner that maximizes its potential contributions. A review of recent papers employing SHAP reveals that many studies subjectively select a limited number of features as 'important' and analyze SHAP values by approximately observing plots without assessing statistical significance. Such superficial application may hinder meaningful contributions to the applied fields. To address this, we propose a library package designed to simplify the interpretation of SHAP values. By simply inputting the original data and SHAP values, our library provides: 1) the number of important features to analyze, 2) the pattern of each feature via univariate analysis, and 3) the interaction between features. All information is extracted based on its statistical significance and presented in simple, comprehensible sentences, enabling users of all levels to understand the interpretations. We hope this library fosters a comprehensive understanding of statistically valid SHAP results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12578v1</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Youngro Lee, Kyungjin Kim, Jongmo Seo</dc:creator>
    </item>
    <item>
      <title>Stable and Robust Hyper-Parameter Selection Via Robust Information Sharing Cross-Validation</title>
      <link>https://arxiv.org/abs/2409.12890</link>
      <description>arXiv:2409.12890v1 Announce Type: new 
Abstract: Robust estimators for linear regression require non-convex objective functions to shield against adverse affects of outliers. This non-convexity brings challenges, particularly when combined with penalization in high-dimensional settings. Selecting hyper-parameters for the penalty based on a finite sample is a critical task. In practice, cross-validation (CV) is the prevalent strategy with good performance for convex estimators. Applied with robust estimators, however, CV often gives sub-par results due to the interplay between multiple local minima and the penalty. The best local minimum attained on the full training data may not be the minimum with the desired statistical properties. Furthermore, there may be a mismatch between this minimum and the minima attained in the CV folds. This paper introduces a novel adaptive CV strategy that tracks multiple minima for each combination of hyper-parameters and subsets of the data. A matching scheme is presented for correctly evaluating minima computed on the full training data using the best-matching minima from the CV folds. It is shown that the proposed strategy reduces the variability of the estimated performance metric, leads to smoother CV curves, and therefore substantially increases the reliability and utility of robust penalized estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12890v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Kepplinger, Siqi Wei</dc:creator>
    </item>
    <item>
      <title>High-Level Synthetic Data Generation with Data Set Archetypes</title>
      <link>https://arxiv.org/abs/2303.14301</link>
      <description>arXiv:2303.14301v2 Announce Type: replace-cross 
Abstract: Cluster analysis relies on effective benchmarks for evaluating and comparing different algorithms. Simulation studies on synthetic data are popular because important features of the data sets, such as the overlap between clusters, or the variation in cluster shapes, can be effectively varied. Unfortunately, curating evaluation scenarios is often laborious, as practitioners must find lower-level geometric parameters (like cluster covariance matrices) to match a higher-level scenario description like "clusters with very different shapes." To make benchmarks more convenient and informative, we propose synthetic data generation based on data set archetypes. In this paradigm, the user describes an evaluation scenario in a high-level manner, and the software automatically generates data sets with the desired characteristics. Combining such data set archetypes with large language models (LLMs), it is possible to set up benchmarks purely from verbal descriptions of the evaluation scenarios. We provide an open-source Python package, repliclust, that implements this workflow. A demo of data generation from verbal inputs is available at https://demo.repliclust.org.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14301v2</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael J. Zellinger, Peter B\"uhlmann</dc:creator>
    </item>
    <item>
      <title>An accurate percentile method for parametric inference based on asymptotically biased estimators</title>
      <link>https://arxiv.org/abs/2405.05403</link>
      <description>arXiv:2405.05403v2 Announce Type: replace-cross 
Abstract: Inference methods for computing confidence intervals in parametric settings usually rely on consistent estimators of the parameter of interest. However, it may be computationally and/or analytically burdensome to obtain such estimators in various parametric settings, for example when the data exhibit certain features such as censoring, misclassification errors or outliers. To address these challenges, we propose a simulation-based inferential method, called the implicit bootstrap, that remains valid regardless of the potential asymptotic bias of the estimator on which the method is based. We demonstrate that this method allows for the construction of asymptotically valid percentile confidence intervals of the parameter of interest. Additionally, we show that these confidence intervals can also achieve second-order accuracy. We also show that the method is exact in three instances where the standard bootstrap fails. Using simulation studies, we illustrate the coverage accuracy of the method in three examples where standard parametric bootstrap procedures are computationally intensive and less accurate in finite samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05403v2</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samuel Orso, Mucyo Karemera, Maria-Pia Victoria-Feser, St\'ephane Guerrier</dc:creator>
    </item>
    <item>
      <title>Optimizing VarLiNGAM for Scalable and Efficient Time Series Causal Discovery</title>
      <link>https://arxiv.org/abs/2409.05500</link>
      <description>arXiv:2409.05500v2 Announce Type: replace-cross 
Abstract: Causal discovery identifies causal relationships in data, but the task is more complex for multivariate time series due to the computational demands of methods like VarLiNGAM, which combines a Vector Autoregressive Model with a Linear Non-Gaussian Acyclic Model. This study optimizes causal discovery specifically for time series data, which are common in practical applications. Time series causal discovery is particularly challenging because of temporal dependencies and potential time lag effects. By developing a specialized dataset generator and reducing the computational complexity of the VarLiNGAM model from \( O(m^3 \cdot n) \) to \( O(m^3 + m^2 \cdot n) \), this study enhances the feasibility of processing large datasets. The proposed methods were validated on advanced computational platforms and tested on simulated, real-world, and large-scale datasets, demonstrating improved efficiency and performance. The optimized algorithm achieved 7 to 13 times speedup compared to the original and about 4.5 times speedup compared to the GPU-accelerated version on large-scale datasets with feature sizes from 200 to 400. Our methods extend current causal discovery capabilities, making them more robust, scalable, and applicable to real-world scenarios, facilitating advancements in fields like healthcare and finance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.05500v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.PF</category>
      <category>stat.CO</category>
      <pubDate>Fri, 20 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziyang Jiao, Ce Guo, Wayne Luk</dc:creator>
    </item>
  </channel>
</rss>
