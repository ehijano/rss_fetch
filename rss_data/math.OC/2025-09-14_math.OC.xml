<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 15 Sep 2025 04:00:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Sparse Polyak: an adaptive step size rule for high-dimensional M-estimation</title>
      <link>https://arxiv.org/abs/2509.09802</link>
      <description>arXiv:2509.09802v1 Announce Type: new 
Abstract: We propose and study Sparse Polyak, a variant of Polyak's adaptive step size, designed to solve high-dimensional statistical estimation problems where the problem dimension is allowed to grow much faster than the sample size. In such settings, the standard Polyak step size performs poorly, requiring an increasing number of iterations to achieve optimal statistical precision-even when, the problem remains well conditioned and/or the achievable precision itself does not degrade with problem size. We trace this limitation to a mismatch in how smoothness is measured: in high dimensions, it is no longer effective to estimate the Lipschitz smoothness constant. Instead, it is more appropriate to estimate the smoothness restricted to specific directions relevant to the problem (restricted Lipschitz smoothness constant). Sparse Polyak overcomes this issue by modifying the step size to estimate the restricted Lipschitz smoothness constant. We support our approach with both theoretical analysis and numerical experiments, demonstrating its improved performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09802v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianqi Qiao, Marie Maros</dc:creator>
    </item>
    <item>
      <title>Solution of Stochastic Facility Location Problems with Combinatorially many Decision-Dependent Distributions</title>
      <link>https://arxiv.org/abs/2509.09816</link>
      <description>arXiv:2509.09816v1 Announce Type: new 
Abstract: This article describes a model and an exact solution method for facility location problems with decision-dependent uncertainties. The model allows characterizing the probability distribution of the random elements as a function of the choice of open facilities. This, in turn, generates a combinatorial number of potential distributions of the random elements. Though general in the relationship between location decisions and distributions, the proposed model is, however, exponential in size. We show that the problem can be solved efficiently by a recent finitely convergent method for stochastic programs with decision-dependent uncertainty, for which we tight prove cutting planes and efficient valid inequalities. Extensive tests show that facility location problems with up to $2^{17}$ potential distributions and hundreds of thousand scenarios are solved within minutes. These results indentify a promising solution strategy for other combinatorial optimization problems characterized by decision-dependent uncertanty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09816v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giovanni Pantuso</dc:creator>
    </item>
    <item>
      <title>A risk-sensitive ergodic singular stochastic control problem</title>
      <link>https://arxiv.org/abs/2509.09835</link>
      <description>arXiv:2509.09835v1 Announce Type: new 
Abstract: We consider a two-sided singular stochastic control problem with a risk-sensitive ergodic criterion. In particular, we consider a stochastic system whose uncontrolled dynamics are modelled by a linear diffusion. The control that can be applied to the system is modelled by an additive finite variation process. The objective of the control problem is to minimise a risk-sensitive long-term average criterion that penalises deviations of the controlled process from a given interval, as well as the expenditure of control effort. The stochastic control problem has been partly motivated by the problem faced by a central bank who wish to control the exchange rate between its domestic currency and a foreign currency so that this fluctuates within a suitable target zone. We derive the complete solution to the problem under general assumptions by deriving a C2 solution to its HJB equation. To this end, we use the solutions to a suitable family of Sturm-Liouville eigenvalue problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09835v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Gwee, Mihail Zervos</dc:creator>
    </item>
    <item>
      <title>Analysis and Design of Spare Strategy for Large-Scale Satellite Constellation Using Markov Chain</title>
      <link>https://arxiv.org/abs/2509.09957</link>
      <description>arXiv:2509.09957v1 Announce Type: new 
Abstract: This paper presents a method for analyzing and designing an optimal spare-management policy in large-scale satellite constellations using a Markov chain model. To capture the stochastic nature of satellite failures and launch vehicle lead times, we adopt Markov chains to model both failure and replenishment processes. We reinvestigate an indirect spare strategy, modeled as a multi-echelon periodic-review reorder-point/order-quantity policy, in which spares are first delivered to parking orbits and then transferred to constellation planes. The stock levels in constellation and parking orbits are each modeled as independent Markov chains, and a fixed-point iteration yields a consistent joint stationary solution that describes the strategy's average behavior. This approach accurately captures the stochastic interplay within a multi-echelon model driven by orbital mechanics, avoiding the aggregation assumptions of prior works and remaining valid across a wider operating domain. Building on this fast, accurate analysis, we formulate an optimization problem and solve it via a genetic algorithm. Finally, we demonstrate the practical value of both the analysis method and the optimization framework in a real-world mega-constellation case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09957v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungyeop Han, Zachary Grieser, Shoji Yoshikawa, Takumi Noro, Takumi Suda, Koki Ho</dc:creator>
    </item>
    <item>
      <title>New complexity bounds for primal--dual interior-point algorithms in conic optimization</title>
      <link>https://arxiv.org/abs/2509.10263</link>
      <description>arXiv:2509.10263v1 Announce Type: new 
Abstract: We provide improved complexity results for symmetric primal--dual interior-point algorithms in conic optimization. The results follow from new uniform bounds on a key complexity measure for primal--dual metrics at pairs of primal and dual points. The complexity measure is defined as the largest eigenvalue of the product of the Hessians of the primal and dual barrier functions, normalized by the proximity of the points to the central path. For algorithms based on self-scaled barriers for symmetric cones, we determine the exact value of the complexity measure. In the significantly more general case of self-concordant barriers with negative curvature, we provide the asymptotically tight upper bound of 4/3. This result implies $O(\vartheta^{1/2}\ln(1/\epsilon))$ iteration complexity for a variety of symmetric (and some nonsymmetric) primal--dual interior-point algorithms. Finally, in the case of general self-concordant barriers, we give improved bounds for some variants of the complexity measure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10263v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joachim Dahl, Levent Tun\c{c}el, Lieven Vandenberghe</dc:creator>
    </item>
    <item>
      <title>Solutions to Differential Algebraic Inequalities with Composite Bernstein Polynomials</title>
      <link>https://arxiv.org/abs/2509.10340</link>
      <description>arXiv:2509.10340v1 Announce Type: new 
Abstract: The Bernstein polynomial basis sees significant use owing to its unique properties, particularly in the field of optimal control. However, the basis is known to have a slow rate of convergence to the function it approximates. With this in mind, we introduce two collocation methods for solving general ordinary differential equations using composite Bernstein polynomials to preserve the basis properties while improving convergence. Of particular note is the integration based method which uses a minimal number of variables to describe the resulting composite polynomial, reducing computational effort. In addition, we exploit the convex hull property of the Bernstein polynomial basis in order to enforce inequality constraints in differential algebraic inequalities, highlighting the benefits of the basis in function approximation. Solutions to six numerical examples are provided as well as discussion of the advantages and disadvantages of the proposed solution methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10340v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maxwell Hammond, Gage MacLin, Laurent Jay, Venanzio Cichella</dc:creator>
    </item>
    <item>
      <title>Constrained Variational Inference via Safe Particle Flow</title>
      <link>https://arxiv.org/abs/2509.10356</link>
      <description>arXiv:2509.10356v1 Announce Type: new 
Abstract: We propose a control barrier function (CBF) formulation for enforcing equality and inequality constraints in variational inference. The key idea is to define a barrier functional on the space of probability density functions that encode the desired constraints imposed on the variational density. By leveraging the Liouville equation, we establish a connection between the time derivative of the variational density and the particle drift, which enables the systematic construction of corresponding CBFs associated to the particle drift. Enforcing these CBFs gives rise to the safe particle flow and ensures that the variational density satisfies the original constraints imposed by the barrier functional. This formulation provides a principled and computationally tractable solution to constrained variational inference, with theoretical guarantees of constraint satisfaction. The effectiveness of the method is demonstrated through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10356v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinzhuang Yi, Jorge Cort\'es, Nikolay Atanasov</dc:creator>
    </item>
    <item>
      <title>Target Defense Using a Turret and Mobile Defender Team</title>
      <link>https://arxiv.org/abs/2509.09777</link>
      <description>arXiv:2509.09777v1 Announce Type: cross 
Abstract: A scenario is considered wherein a stationary, turn constrained agent (Turret) and a mobile agent (Defender) cooperate to protect the former from an adversarial mobile agent (Attacker). The Attacker wishes to reach the Turret prior to getting captured by either the Defender or Turret, if possible. Meanwhile, the Defender and Turret seek to capture the Attacker as far from the Turret as possible. This scenario is formulated as a differential game and solved using a geometric approach. Necessary and sufficient conditions for the Turret-Defender team winning and the Attacker winning are given. In the case of the Turret-Defender team winning equilibrium strategies for the min max terminal distance of the Attacker to the Turret are given. Three cases arise corresponding to solo capture by the Defender, solo capture by the Turret, and capture simultaneously by both Turret and Defender.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09777v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Von Moll, Dipankar Maity, Meir Pachter, Daigo Shishika, Michael Dorothy</dc:creator>
    </item>
    <item>
      <title>Understanding Outer Optimizers in Local SGD: Learning Rates, Momentum, and Acceleration</title>
      <link>https://arxiv.org/abs/2509.10439</link>
      <description>arXiv:2509.10439v1 Announce Type: cross 
Abstract: Modern machine learning often requires training with large batch size, distributed data, and massively parallel compute hardware (like mobile and other edge devices or distributed data centers). Communication becomes a major bottleneck in such settings but methods like Local Stochastic Gradient Descent (Local SGD) show great promise in reducing this additional communication overhead. Local SGD consists of three parts: a local optimization process, an aggregation mechanism, and an outer optimizer that uses the aggregated updates from the nodes to produce a new model. While there exists an extensive literature on understanding the impact of hyperparameters in the local optimization process, the choice of outer optimizer and its hyperparameters is less clear. We study the role of the outer optimizer in Local SGD, and prove new convergence guarantees for the algorithm. In particular, we show that tuning the outer learning rate allows us to (a) trade off between optimization error and stochastic gradient noise variance, and (b) make up for ill-tuning of the inner learning rate. Our theory suggests that the outer learning rate should sometimes be set to values greater than $1$. We extend our results to settings where we use momentum in the outer optimizer, and we show a similar role for the momentum-adjusted outer learning rate. We also study acceleration in the outer optimizer and show that it improves the convergence rate as a function of the number of communication rounds, improving upon the convergence rate of prior algorithms that apply acceleration locally. Finally, we also introduce a novel data-dependent analysis of Local SGD that yields further insights on outer learning rate tuning. We conduct comprehensive experiments with standard language models and various outer optimizers to validate our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.10439v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmed Khaled, Satyen Kale, Arthur Douillard, Chi Jin, Rob Fergus, Manzil Zaheer</dc:creator>
    </item>
    <item>
      <title>Relaxation methods for pessimistic bilevel optimization</title>
      <link>https://arxiv.org/abs/2412.11416</link>
      <description>arXiv:2412.11416v2 Announce Type: replace 
Abstract: We consider a smooth pessimistic bilevel optimization problem, where the lower-level problem is convex and satisfies the Slater constraint qualification. These assumptions ensure that the Karush-Kuhn-Tucker (KKT) reformulation of our problem is well-defined. We then introduce and study the (i) Scholtes, (ii) Lin and Fukushima, (iii) Kadrani, Dussault and Benchakroun, (iv) Steffensen and Ulbrich, and (v) Kanzow and Schwartz relaxation methods for the KKT reformulation of our pessimistic bilevel program. These relaxations have been extensively studied and compared for mathematical programs with complementatrity constraints (MPCCs). To the best of our knowledge, such a study has not been conducted for the pessimistic bilevel optimization problem, which is completely different from an MPCC, as the complemetatrity conditions are part of the objective function, and not in the feasible set of the problem. After introducing these relaxations, we provide convergence results for global and local optimal solutions, as well as suitable versions of the C- and M-stationarity points of our pessimistic bilevel optimization problem. Numerical results are also provided to illustrate the practical implementation of these relaxation algorithms, as well as some preliminary comparisons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.11416v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Imane Benchouk, Lateef Jolaoso, Khadra Nachi, Alain Zemkoho</dc:creator>
    </item>
    <item>
      <title>A hybrid heuristic algorithm for the resource-constrained project scheduling problem</title>
      <link>https://arxiv.org/abs/2502.18330</link>
      <description>arXiv:2502.18330v2 Announce Type: replace 
Abstract: This study presents a hybrid metaheuristic for the resource-constrained project scheduling problem (RCPSP), which integrates a genetic algorithm (GA) and a neighborhood search strategy (NS). The RCPSP consists of a set of activities that follow precedence relationship and consume resources. The resources are renewable, and the amount of the resources is limited. The objective of RCPSP is to find a schedule of the activities to minimize the project makespan. The algorithm uses two crossovers in the GA and two neighborhoods in the NS, as well as a resource ranking heuristic. The computational results with instances from the PCPLIB library validate the effectiveness of the proposed algorithm. We have obtained some of the best average deviations of the solutions from the critical path lower bound. The best heuristic solutions have been updated for some instances from PCPLIB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18330v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Evgenii Goncharov</dc:creator>
    </item>
    <item>
      <title>Efficient Quadratic Corrections for Frank-Wolfe Algorithms</title>
      <link>https://arxiv.org/abs/2506.02635</link>
      <description>arXiv:2506.02635v3 Announce Type: replace 
Abstract: We develop a Frank-Wolfe algorithm with corrective steps, generalizing previous algorithms including blended conditional gradients, blended pairwise conditional gradients, and fully-corrective Frank-Wolfe. For this, we prove tight convergence guarantees together with an optimal face identification property. Furthermore, we propose two highly efficient corrective steps for convex quadratic objectives based on linear optimization or linear system solving, akin to Wolfe's minimum-norm point, and show that they converge in finite time under suitable conditions. Beyond optimization problems that are directly quadratic, we revisit two algorithms - split conditional gradient and second-order conditional gradient sliding - which can leverage quadratic corrections to accelerate their quadratic subproblems. We demonstrate improved convergence rates for the first and broader applicability for the second, which may be of independent interest. Finally, we show substantial computational speedups for Frank-Wolfe-based algorithms with quadratic corrections across the considered problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02635v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Halbey, Seta Rakotomandimby, Mathieu Besan\c{c}on, S\'ebastien Designolle, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Exact worst-case convergence rates for Douglas--Rachford and Davis--Yin splitting methods</title>
      <link>https://arxiv.org/abs/2506.23475</link>
      <description>arXiv:2506.23475v2 Announce Type: replace 
Abstract: In this work, we aim to establish the exact worst-case convergence rates of Douglas--Rachford splitting (DRS) and Davis--Yin splitting (DYS) when applied to convex optimization problems. Both DRS and DYS have two variants as swapping the roles of the two nonsmooth convex functions in both algorithms yields different sequences of iterates. For both variants of DRS and one variant of DYS, we establish the exact worst-case convergence rates, including the constant factor, using the primal--dual gap function as the performance metric. We provide worst-case examples to verify the tightness of these rates. To the best of our knowledge, this is the first result that establishes the exact worst-case convergence rates for DRS and DYS that include the constant factor. For the other variant of DYS, we establish the best-known convergence rate and provide a concrete example indicating a discrepancy between the convergence rates of the two DYS variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23475v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Edward Duc Hien Nguyen, Jaewook J. Suh, Xin Jiang, Shiqian Ma</dc:creator>
    </item>
    <item>
      <title>Electricity Price-Aware Scheduling of Data Center Cooling</title>
      <link>https://arxiv.org/abs/2508.03160</link>
      <description>arXiv:2508.03160v2 Announce Type: replace 
Abstract: Data centers are becoming a major consumer of electricity on the grid, with cooling accounting for about 40\% of that energy. As electricity prices vary throughout the day and year, there is a need for cooling strategies that adapt to these fluctuations to reduce data center cooling costs. In this paper, we present a model for electricity price-aware cooling scheduling using a Markov Decision Process(MDP) framework to reliably estimate the cooling system operational costs and facilitate investment-phase decision-making. We utilize Quantile Fourier Regression (QFR) fits to classify electricity prices into different regimes while capturing both daily and seasonal patterns. We simulate 14 years of operation using historical electricity price and outdoor temperature data, and compare our model against heuristic baselines. The results demonstrate that our approach consistently achieves lower cooling costs. This model is useful for grid operators interested in demand response programs and data center investors looking to make investment decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03160v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arash Khojaste, Jonathan Pearce, Golbon Zakeri, Yuanrui Sang</dc:creator>
    </item>
    <item>
      <title>Sensitivity of Filter Kernels and Robustness Bounds to Transition and Measurement Kernel Perturbations in Partially Observable Stochastic Control</title>
      <link>https://arxiv.org/abs/2508.10658</link>
      <description>arXiv:2508.10658v3 Announce Type: replace 
Abstract: Studying the stability of partially observed Markov decision processes (POMDPs) with respect to perturbations in either transition or observation kernels is a significant problem. While asymptotic robustness/stability results as approximate transition kernels and/or measurement kernels converge to the true ones have been previously reported, studies on explicit bounds on value differences and mismatch costs have been limited in scope for POMDPs. In this paper, we provide such explicit bounds under both discounted and average cost criteria. To this end, and also as an independent contribution, we first study the perturbations induced on the filter kernels (that is, the kernels of the belief-MDP reduction of POMDPs) as the transition and measurement kernels are perturbed. The bounds are given in terms of Wasserstein and total variation distances between the original and approximate transition and observation kernels. We then show that control policies optimized for approximate models yield performance guarantees when applied to the true model with explicit bounds. As a particular application, we consider the case where the state space and the measurement spaces are quantized to obtain finite models, and we obtain explicit error bounds which decay to zero as the approximations get finer. This provides explicit performance guarantees for model reduction in POMDPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.10658v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunus Emre Demirci, Ali Devran Kara, Serdar Y\"uksel</dc:creator>
    </item>
    <item>
      <title>A qualitative study of the generalized dispersive systems with time-delay: The unbounded case</title>
      <link>https://arxiv.org/abs/2303.06693</link>
      <description>arXiv:2303.06693v4 Announce Type: replace-cross 
Abstract: We study the asymptotic behavior of the solutions of the time-delayed higher-order dispersive nonlinear differential equation \begin{equation*} u_t(x,t)+Au(x,t) +\lambda_0(x) u(x,t)+\lambda(x) u(x,t-\tau )=0 \end{equation*} where \begin{equation*} Au=(-1)^{j+1}\partial_x^{2j+1}u+(-1)^m\partial_x^{2m}u+ \frac{1}{p+1}\partial_xu^{p+1} \end{equation*} with $m\le j$ and $1\le p&lt;2j$. Under suitable assumptions on the time delay coefficients, we prove that the system is exponentially stable if the coefficient of the delay term is bounded from below by a suitable positive constant, without any assumption on the sign of the coefficient of the undelayed feedback. Additionally, in the absence of delay, general results of stabilization are established in $H^s(\mathbb{R})$ for $s\in[0,2j+1]$. Our results generalize several previous theorems for the Korteweg-de Vries type delayed systems in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.06693v4</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Roberto de A. Capistrano Filho, Fernando Gallego, Vilmos Komornik</dc:creator>
    </item>
    <item>
      <title>Maximum Likelihood Identification of Linear Models with Integrating Disturbances for Offset-Free Control</title>
      <link>https://arxiv.org/abs/2406.03760</link>
      <description>arXiv:2406.03760v3 Announce Type: replace-cross 
Abstract: This report addresses the maximum likelihood identification of models for offset-free model predictive control, where linear time-invariant models are augmented with (fictitious) uncontrollable integrating modes, called integrating disturbances. The states and disturbances are typically estimated with a Kalman filter. The disturbance estimates effectively provide integral control, so the quality of the disturbance model (and resulting filter) directly influences the control performance. We implement eigenvalue constraints to protect against undesirable filter behavior (unstable or marginally stable modes, high-frequency oscillations). Specifically, we consider the class of linear matrix inequality (LMI) regions for eigenvalue constraints. These LMI regions are open sets by default, so we introduce a barrier function method to create tightened, but closed, eigenvalue constraints. To solve the resulting nonlinear semidefinite program, we approximate it as a nonlinear program using a Cholesky factorization method that exploits known sparsity structures of semidefinite optimization variables and matrix inequalities. The algorithm is applied to real-world data taken from two physical systems: a low-cost benchmark temperature microcontroller suitable for classroom laboratories, and an industrial-scale chemical reactor at Eastman Chemical's plant in Kingsport, TN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03760v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TAC.2025.3547607</arxiv:DOI>
      <arxiv:journal_reference>in IEEE Transactions on Automatic Control, vol. 70, no. 9, pp. 5675-5689, 2025</arxiv:journal_reference>
      <dc:creator>Steven J. Kuntz, James B. Rawlings</dc:creator>
    </item>
    <item>
      <title>Sparse Actuation for LPV Systems with Full-State Feedback in $\mathcal{H}_2/\mathcal{H}_\infty$ Framework</title>
      <link>https://arxiv.org/abs/2410.01118</link>
      <description>arXiv:2410.01118v3 Announce Type: replace-cross 
Abstract: This paper addresses the sparse actuation problem for nonlinear systems represented in the Linear Parameter-Varying (LPV) form. We propose a convex optimization framework that concurrently determines actuator magnitude limits and the state-feedback law that guarantees a user-specified closed-loop performance in the $\mathcal{H}_2/\mathcal{H}_\infty$ sense. We also demonstrate that sparse actuation is achieved when the actuator magnitude-limits are minimized in the $l_1$ sense. This is the first paper that addresses this problem for LPV systems. The formulation is demonstrated in a vibration control problem for a flexible wing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01118v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 15 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tanay Kumar, Raktim Bhattacharya</dc:creator>
    </item>
  </channel>
</rss>
