<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CG updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CG</link>
    <description>cs.CG updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CG" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 29 Aug 2025 01:29:42 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A goal-driven ruin and recreate heuristic for the 2D variable-sized bin packing problem with guillotine constraints</title>
      <link>https://arxiv.org/abs/2508.19306</link>
      <description>arXiv:2508.19306v1 Announce Type: new 
Abstract: This paper addresses the two-dimensional bin packing problem with guillotine constraints. The problem requires a set of rectangular items to be cut from larger rectangles, known as bins, while only making use of edge-to-edge (guillotine) cuts. The goal is to minimize the total bin area needed to cut all required items. This paper also addresses variants of the problem which permit 90{\deg} rotation of items and/or a heterogeneous set of bins. A novel heuristic is introduced which is based on the ruin and recreate paradigm combined with a goal-driven approach. When applying the proposed heuristic to benchmark instances from the literature, it outperforms the current state-of-the-art algorithms in terms of solution quality for all variants of the problem considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19306v1</guid>
      <category>cs.CG</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.ejor.2021.11.031</arxiv:DOI>
      <arxiv:journal_reference>European Journal of Operational Research, 301(2), 432-444 (2022)</arxiv:journal_reference>
      <dc:creator>Jeroen Gardeyn, Tony Wauters</dc:creator>
    </item>
    <item>
      <title>A Walk on the Wild Side: a Shape-First Methodology for Orthogonal Drawings</title>
      <link>https://arxiv.org/abs/2508.19416</link>
      <description>arXiv:2508.19416v1 Announce Type: new 
Abstract: Several algorithms for the construction of orthogonal drawings of graphs, including those based on the Topology-Shape-Metrics (TSM) paradigm, tend to prioritize the minimization of crossings. This emphasis has two notable side effects: some edges are drawn with unnecessarily long sequences of segments and bends, and the overall drawing area may become excessively large. As a result, the produced drawings often lack geometric uniformity. Moreover, orthogonal crossings are known to have a limited impact on readability, suggesting that crossing minimization may not always be the optimal goal. In this paper, we introduce a methodology that 'subverts' the traditional TSM pipeline by focusing on minimizing bends. Given a graph $G$, we ideally seek to construct a rectilinear drawing of $G$, that is, an orthogonal drawing with no bends. When not possible, we incrementally subdivide the edges of $G$ by introducing dummy vertices that will (possibly) correspond to bends in the final drawing. This process continues until a rectilinear drawing of a subdivision of the graph is found, after which the final coordinates are computed. We tackle the (NP-complete) rectilinear drawability problem by encoding it as a SAT formula and solving it with state-of-the-art SAT solvers. If the SAT formula is unsatisfiable, we use the solver's proof to determine which edge to subdivide. Our implementation, DOMUS, which is fairly simple, is evaluated through extensive experiments on small- to medium-sized graphs. The results show that it consistently outperforms OGDF's TSM-based approach across most standard graph drawing metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19416v1</guid>
      <category>cs.CG</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giordano Andreola, Susanna Caroppo, Giuseppe Di Battista, Fabrizio Grosso, Maurizio Patrignani, Allegra Strippoli</dc:creator>
    </item>
    <item>
      <title>Approximating mixed volumes to arbitrary accuracy</title>
      <link>https://arxiv.org/abs/2508.19582</link>
      <description>arXiv:2508.19582v1 Announce Type: new 
Abstract: We study the problem of approximating the mixed volume $V(P_1^{(\alpha_1)}, \dots, P_k^{(\alpha_k)})$ of an $k$-tuple of convex polytopes $(P_1, \dots, P_k)$, each of which is defined as the convex hull of at most $m_0$ points in $\mathbb{Z}^n$. We design an algorithm that produces an estimate that is within a multiplicative $1 \pm \epsilon$ factor of the true mixed volume with a probability greater than $1 - \delta.$ Let the constant $ \prod_{i=2}^{k} \frac{(\alpha_{i}+1)^{\alpha_{i}+1}}{\alpha_{i}^{\,\alpha_{i}}}$ be denoted by $\tilde{A}$. When each $P_i \subseteq B_\infty(2^L)$, we show in this paper that the time complexity of the algorithm is bounded above by a polynomial in $n, m_0, L, \tilde{A}, \epsilon^{-1}$ and $\log \delta^{-1}$. In fact, a stronger result is proved in this paper, with slightly more involved terminology.
  In particular, we provide the first randomized polynomial time algorithm for computing mixed volumes of such polytopes when $k$ is an absolute constant, but $\alpha_1, \dots, \alpha_k$ are arbitrary. Our approach synthesizes tools from convex optimization, the theory of Lorentzian polynomials, and polytope subdivision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19582v1</guid>
      <category>cs.CG</category>
      <category>math.CO</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hariharan Narayanan, Sourav Roy</dc:creator>
    </item>
    <item>
      <title>Simpler is Faster: Practical Distance Reporting by Sorting Along a Space-Filling Curve</title>
      <link>https://arxiv.org/abs/2508.19891</link>
      <description>arXiv:2508.19891v2 Announce Type: new 
Abstract: Range reporting is a classical problem in computational geometry. A (rectangular) reporting data structure stores a point set $P$ of $n$ points, such that, given a (rectangular) query region $\Delta$, it returns all points in $P \cap \Delta$. A variety of data structures support such queries with differing asymptotic guarantees such as $k$-d trees, range trees, $R$-trees, and quadtrees. A common variant of range queries are distance reporting queries, where the input is a query point $q$ and a radius $\delta$, and the goal is to report all points in $P$ within distance $\delta$ of $q$. Such queries frequently arise as subroutines in geometric data structure construction and in Fr\'echet distance computations. Modern implementations typically reduce distance queries to rectangular range queries using the data structures listed above.
  We revisit a simple and practical heuristic for distance reporting. The approach is straightforward: sort the input point set $P$ along a space-filling curve. Queries then reduce to scanning at most four contiguous ranges along the sorted curve. We show extensive experimental evaluation of modern distance and range reporting data structures. In a static scenario, we show that this simple technique is competitive with all but the most highly optimised range reporting data structures. Notably, these involved structures use space-filling curves themselves to speed up computation. In a dynamic setting, our simpler method even becomes the preferred technique.
  This leads to a perhaps unexpected insight: while modern data structures invest heavily in leveraging space-filling curves for optimising their layout and traversal, it is the curve itself, rather than the surrounding machinery, that delivers much of the performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19891v2</guid>
      <category>cs.CG</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sarita de Berg, Emil Toftegaard G{\ae}de, Ivor van der Hoog, Eva Rotenberg</dc:creator>
    </item>
    <item>
      <title>Internally-Convex Drawings of Outerplanar Graphs in Small Area</title>
      <link>https://arxiv.org/abs/2508.19913</link>
      <description>arXiv:2508.19913v1 Announce Type: new 
Abstract: A well-known result by Kant [Algorithmica, 1996] implies that n-vertex outerplane graphs admit embedding-preserving planar straight-line grid drawings where the internal faces are convex polygons in $O(n^2)$ area. In this paper, we present an algorithm to compute such drawings in $O(n^{1.5})$ area. We also consider outerplanar drawings in which the internal faces are required to be strictly-convex polygons. In this setting, we consider outerplanar graphs whose weak dual is a path and give a drawing algorithm that achieves $\Theta(nk^2)$ area, where $k$ is the maximum size of an internal facial cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19913v1</guid>
      <category>cs.CG</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael A. Bekos, Giordano Da Lozzo, Fabrizio Frati, Giuseppe Liotta, Antonios Symvonis</dc:creator>
    </item>
    <item>
      <title>Visualizing Treewidth</title>
      <link>https://arxiv.org/abs/2508.19935</link>
      <description>arXiv:2508.19935v1 Announce Type: new 
Abstract: A witness drawing of a graph is a visualization that clearly shows a given property of a graph. We study and implement various drawing paradigms for witness drawings to clearly show that graphs have bounded pathwidth or treewidth. Our approach draws the tree decomposition or path decomposition as a tree of bags, with induced subgraphs shown in each bag, and with ''tracks'' for each graph vertex connecting its copies in multiple bags. Within bags, we optimize the vertex layout to avoid crossings of edges and tracks. We implement a visualization prototype for crossing minimization using dynamic programming for graphs of small width and heuristic approaches for graphs of larger width. We introduce a taxonomy of drawing styles, which render the subgraph for each bag as an arc diagram with one or two pages or as a circular layout with straight-line edges, and we render tracks either with straight lines or with orbital-radial paths.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19935v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alvin Chiu, Thomas Depian, David Eppstein, Michael T. Goodrich, Martin N\"ollenburg</dc:creator>
    </item>
    <item>
      <title>Complements of finite unions of convex sets</title>
      <link>https://arxiv.org/abs/2508.19413</link>
      <description>arXiv:2508.19413v1 Announce Type: cross 
Abstract: Finite unions of convex sets are a central object of study in discrete and computational geometry. In this paper we initiate a systematic study of complements of such unions -- i.e., sets of the form $S=\mathbb{R}^d \setminus (\cup_{i=1}^n K_i)$, where $K_i$ are convex sets. In the first part of the paper we study isolated points in $S$, whose number is related to the Betti numbers of $\cup_{i=1}^n K_i$ and to its non-convexity properties.
  We obtain upper bounds on the number of such points, which are sharp for $n=3$ and significantly improve previous bounds of Lawrence and Morris (2009) for all $n \ll \frac{2^d}{d}$. In the second part of the paper we study coverings of $S$ by well-behaved sets. We show that $S$ can be covered by at most $g(d,n)$ flats of different dimensions, in such a way that each $x \in S$ is covered by a flat whose dimension equals the `local dimension' of $S$ in the neighborhood of $x$. Furthermore, we determine the structure of a minimum cover that satisfies this property. Then, we study quantitative aspects of this minimum cover and obtain sharp upper bounds on its size in various settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19413v1</guid>
      <category>math.CO</category>
      <category>cs.CG</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chaya Keller, Micha A. Perles</dc:creator>
    </item>
    <item>
      <title>An algorithm for accurate and simple-looking metaphorical maps</title>
      <link>https://arxiv.org/abs/2508.19810</link>
      <description>arXiv:2508.19810v2 Announce Type: cross 
Abstract: "Metaphorical maps" or "contact representations" are visual representations of vertex-weighted graphs that rely on the geographic map metaphor. The vertices are represented by countries, the weights by the areas of the countries, and the edges by contacts/ boundaries among them. The accuracy with which the weights are mapped to areas and the simplicity of the polygons representing the countries are the two classical optimization goals for metaphorical maps. Mchedlidze and Schnorr [Metaphoric Maps for Dynamic Vertex-weighted Graphs, EuroVis 2022] presented a force-based algorithm that creates metaphorical maps that balance between these two optimization goals. Their maps look visually simple, but the accuracy of the maps is far from optimal - the countries' areas can vary up to 30% compared to required. In this paper, we provide a multi-fold extension of the algorithm in [Metaphoric Maps for Dynamic Vertex-weighted Graphs, EuroVis 2022]. More specifically:
  1. Towards improving accuracy: We introduce the notion of region stiffness and suggest a technique for varying the stiffness based on the current pressure of map regions.
  2. Towards maintaining simplicity: We introduce a weight coefficient to the pressure force exerted on each polygon point based on whether the corresponding point appears along a narrow passage.
  3. Towards generality: We cover, in contrast to [Metaphoric Maps for Dynamic Vertex-weighted Graphs, EuroVis 2022], non-triangulated graphs. This is done by either generating points where more than three regions meet or by introducing holes in the metaphorical map.
  We perform an extended experimental evaluation that, among other results, reveals that our algorithm is able to construct metaphorical maps with nearly perfect area accuracy with a little sacrifice in their simplicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19810v2</guid>
      <category>cs.DM</category>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eleni Katsanou, Tamara Mchedlidze, Antonios Symvonis, Thanos Tolias</dc:creator>
    </item>
    <item>
      <title>Exploratory Notes on Symbolic Constraints in Polyhedral Enclosure and Tetrahedral Decomposition in Genus-0 Polyhedra</title>
      <link>https://arxiv.org/abs/2508.18222</link>
      <description>arXiv:2508.18222v2 Announce Type: replace 
Abstract: I present a coordinate-free, symbolic framework for deciding whether a given set of polygonal faces can form a closed, genus-zero polyhedral surface and for predicting how such a surface could be decomposed into internal tetrahedra. The method uses only discrete incidence variables, such as the number of internal tetrahedra $T$, internal gluing triangles $N_i$, and internal triangulation segments $S_i$, and applies combinatorial feasibility checks before any geometric embedding is attempted. For polyhedra in normal form, I record exact incidence identities linking $V,E,F$ to a flatness parameter $S:=\sum_f(\tmop{deg} f-3)$, and I identify parity-sensitive effects in $E$, $F$, and $S$. The external identities and parity-sensitive bounds hold universally for genus-0 polyhedral graphs. For internal quantities, I prove exact relations $N_i=2T-V+2$ and $T-N_i+S_i=1$ (with $S_i$ taken to be the number of interior edges) and obtain restricted linear ranges within a shell-aligned ladder subclass (SALT), where at most one interior edge is introduced per layer. Consequently, I propose a symbolic workflow that yields rapid pre-checks for structural impossibility, reducing the need for costly geometric validation in computational geometry, graphics, and automated modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.18222v2</guid>
      <category>cs.CG</category>
      <category>math.CO</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moustapha Itani</dc:creator>
    </item>
    <item>
      <title>Interval Decomposition of Persistence Modules over a Principal Ideal Domain</title>
      <link>https://arxiv.org/abs/2310.07971</link>
      <description>arXiv:2310.07971v5 Announce Type: replace-cross 
Abstract: The study of persistent homology has contributed new insights and perspectives into a variety of interesting problems in science and engineering. Work in this domain relies on the result that any finitely-indexed persistence module of finite-dimensional vector spaces admits an interval decomposition -- that is, a decomposition as a direct sum of simpler components called interval modules. This result fails if we replace vector spaces with modules over more general coefficient rings. To address this problem, we introduce an algorithm to determine whether or not a persistence module of pointwise free and finitely-generated modules over a principal ideal domain (PID) splits as a direct sum of interval submodules. If one exists, our algorithm outputs an interval decomposition. When considering persistence modules with coefficients in $\Z$ or $\Q[x]$, our algorithm computes an interval decomposition in polynomial time. This is the first algorithm with these properties of which we are aware. We also show that a persistence module of pointwise free and finitely-generated modules over a PID splits as a direct sum of interval submodules if and only if the cokernel of every structure map is free. This result underpins the formulation of our algorithm. It also complements prior findings by Obayashi and Yoshiwaki regarding persistent homology, including a criterion for field independence and an algorithm to decompose persistence homology modules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07971v5</guid>
      <category>math.AT</category>
      <category>cs.CG</category>
      <category>math.CT</category>
      <pubDate>Thu, 28 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiajie Luo, Gregory Henselman-Petrusek</dc:creator>
    </item>
  </channel>
</rss>
