<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 04:01:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Scalable and Interactive Electricity Grid Expansion Planning</title>
      <link>https://arxiv.org/abs/2410.13055</link>
      <description>arXiv:2410.13055v1 Announce Type: new 
Abstract: Large scale grid expansion planning studies are essential to rapidly and efficiently decarbonizing the electricity sector. These studies help policy makers and grid participants understand which renewable generation, storage, and transmission assets should be built and where they will be most cost effective or have the highest emissions impact. However, these studies are often either too computationally expensive to run repeatedly or too coarsely modeled to give actionable decision information. In this study, we present an implicit gradient descent algorithm to solve expansion planning studies at scale, i.e., problems with many scenarios and large network models. Our algorithm is also interactive: given a base plan, planners can modify assumptions and data then quickly receive an updated plan. This allows the planner to study expansion outcomes for a wide variety of technology cost, weather, and electrification assumptions. We demonstrate the scalability of our tool, solving a case with over a hundred million variables. Then, we show that using warm starts can speed up subsequent runs by as much as 100x. We highlight how this can be used to quickly conduct storage cost uncertainty analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13055v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anthony Degleris, Abbas El Gamal, Ram Rajagopal</dc:creator>
    </item>
    <item>
      <title>Optimal Covariance Steering of Linear Stochastic Systems with Hybrid Transitions</title>
      <link>https://arxiv.org/abs/2410.13222</link>
      <description>arXiv:2410.13222v1 Announce Type: new 
Abstract: This work addresses the problem of optimally steering the state covariance of a linear stochastic system from an initial to a target, subject to hybrid transitions. The nonlinear and discontinuous jump dynamics complicate the control design for hybrid systems. Under uncertainties, stochastic jump timing and state variations further intensify this challenge. This work aims to regulate the hybrid system's state trajectory to stay close to a nominal deterministic one, despite uncertainties and noises. We address this problem by directly controlling state covariances around a mean trajectory, and this problem is termed the Hybrid Covariance Steering (H-CS) problem. The jump dynamics are approximated to the first order by leveraging the Saltation Matrix. When the jump dynamics are nonsingular, we derive an analytical closed-form solution to the H-CS problem. For general jump dynamics with possible singularity and changes in the state dimensions, we reformulate the problem into a convex optimization over path distributions by leveraging Schrodinger's Bridge duality to the smooth covariance control problem. The covariance propagation at hybrid events is enforced as equality constraints to handle singularity issues. The proposed convex framework scales linearly with the number of jump events, ensuring efficient, optimal solutions. This work thus provides a computationally efficient solution to the general H-CS problem. Numerical experiments are conducted to validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13222v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongzhe Yu, Diana Frias Franco, Aaron M. Johnson, Yongxin Chen</dc:creator>
    </item>
    <item>
      <title>Controllability and Observability of Heterogeneous Networked Systems with Non-uniform Node Dimensions and Distinct Inner-Coupling Matrices</title>
      <link>https://arxiv.org/abs/2410.13251</link>
      <description>arXiv:2410.13251v1 Announce Type: new 
Abstract: In this paper we extend the work in the conference paper 'On the Controllability and Observability of Heterogeneous Networked Systems with distinct node dimensions and inner-coupling matrices' wherein the controllability and observability of a heterogeneous networked system with distinct node dimensions were studied. This paper adds to the conference paper a necessary and sufficient condition for controllability of the networked system. The result demonstrates the dependence of controllability of the network on factors like network topology, inner interactions among nodes and nodal dynamics. The result is formulated by characterizing the left eigenvectors of the network state matrix. Another necessary and sufficient condition for controllability, which is a reformulation of the \textit{Popov-Belevitch-Hautus} controllability condition, a necessary and sufficient condition for observability of the networked system and certain necessary conditions for controllability of the networked system are the other results established in this paper. Variants of these results under certain specific network topologies like path, cycle, star and wheel are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13251v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aleena Thomas, Abhijith Ajayakumar, Raju K. George</dc:creator>
    </item>
    <item>
      <title>EOSpython Version 0.0.11: A Framework for Scenario Generation and a Solution System for the Agile Earth Observation Satellite Scheduling Problem</title>
      <link>https://arxiv.org/abs/2410.13462</link>
      <description>arXiv:2410.13462v1 Announce Type: new 
Abstract: EOSpython is a PyPI published Python package that encompass everything within a centralized earth observation satellite scheduling system in terms of customer database setup, scenario generation, pre-processing, problem setup, scheduling solution approach, decision maker preference integration, and visualization. The package is tailored to easily configure internal parameters and contribute with other solution approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13462v1</guid>
      <category>math.OC</category>
      <category>astro-ph.IM</category>
      <category>cs.ET</category>
      <category>cs.NA</category>
      <category>cs.PL</category>
      <category>math.NA</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Elkj{\ae}r Vasegaard, Andreas K\"uhne Larsen</dc:creator>
    </item>
    <item>
      <title>Global Optimization Algorithm through High-Resolution Sampling</title>
      <link>https://arxiv.org/abs/2410.13737</link>
      <description>arXiv:2410.13737v1 Announce Type: new 
Abstract: We present an optimization algorithm that can identify a global minimum of a potentially nonconvex smooth function with high probability, assuming the Gibbs measure of the potential satisfies a logarithmic Sobolev inequality. Our contribution is twofold: on the one hand we propose a global optimization method, which is built on an oracle sampling algorithm producing arbitrarily accurate samples from a given Gibbs measure. On the other hand, we propose a new sampling algorithm, drawing inspiration from both overdamped and underdamped Langevin dynamics, as well as from the high-resolution differential equation known for its acceleration in deterministic settings. While the focus of the paper is primarily theoretical, we demonstrate the effectiveness of our algorithms on the Rastrigin function, where it outperforms recent approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13737v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Cortild, Claire Delplancke, Nadia Oudjane, Juan Peypouquet</dc:creator>
    </item>
    <item>
      <title>Inpatient Overflow Management with Proximal Policy Optimization</title>
      <link>https://arxiv.org/abs/2410.13767</link>
      <description>arXiv:2410.13767v1 Announce Type: new 
Abstract: Overflowing patients to non-primary wards can effectively alleviate congestion in hospitals, while undesired overflow also leads to issues like mismatched service quality. Therefore, we need to trade off between congestion and undesired overflow. This overflow management problem is modeled as a discrete-time Markov Decision Process with large state and action space. To overcome the curse-of-dimensionality, we decompose the action at each time into a sequence of atomic actions and use an actor-critic algorithm, Proximal Policy Optimization (PPO), to guide the atomic actions. Moreover, we tailor the design of neural network which represents policy to account for the daily periodic pattern of the system flows. Under hospital settings of different scales, the PPO policies consistently outperform commonly used state-of-art policies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13767v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Jim Dai (Cornell University), Pengyi Shi (Purdue University), Jingjing Sun (The Chinese University of Hong Kong, Shenzhen)</dc:creator>
    </item>
    <item>
      <title>From Gradient Clipping to Normalization for Heavy Tailed SGD</title>
      <link>https://arxiv.org/abs/2410.13849</link>
      <description>arXiv:2410.13849v1 Announce Type: new 
Abstract: Recent empirical evidence indicates that many machine learning applications involve heavy-tailed gradient noise, which challenges the standard assumptions of bounded variance in stochastic optimization. Gradient clipping has emerged as a popular tool to handle this heavy-tailed noise, as it achieves good performance in this setting both theoretically and practically. However, our current theoretical understanding of non-convex gradient clipping has three main shortcomings. First, the theory hinges on large, increasing clipping thresholds, which are in stark contrast to the small constant clipping thresholds employed in practice. Second, clipping thresholds require knowledge of problem-dependent parameters to guarantee convergence. Lastly, even with this knowledge, current sampling complexity upper bounds for the method are sub-optimal in nearly all parameters. To address these issues, we study convergence of Normalized SGD (NSGD). First, we establish a parameter-free sample complexity for NSGD of $\mathcal{O}\left(\varepsilon^{-\frac{2p}{p-1}}\right)$ to find an $\varepsilon$-stationary point. Furthermore, we prove tightness of this result, by providing a matching algorithm-specific lower bound. In the setting where all problem parameters are known, we show this complexity is improved to $\mathcal{O}\left(\varepsilon^{-\frac{3p-2}{p-1}}\right)$, matching the previously known lower bound for all first-order methods in all problem dependent parameters. Finally, we establish high-probability convergence of NSGD with a mild logarithmic dependence on the failure probability. Our work complements the studies of gradient clipping under heavy tailed noise improving the sample complexities of existing algorithms and offering an alternative mechanism to achieve high probability convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13849v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian H\"ubler, Ilyas Fatkhullin, Niao He</dc:creator>
    </item>
    <item>
      <title>Quantum Boltzmann machine learning of ground-state energies</title>
      <link>https://arxiv.org/abs/2410.12935</link>
      <description>arXiv:2410.12935v1 Announce Type: cross 
Abstract: Estimating the ground-state energy of Hamiltonians is a fundamental task for which it is believed that quantum computers can be helpful. Several approaches have been proposed toward this goal, including algorithms based on quantum phase estimation and hybrid quantum-classical optimizers involving parameterized quantum circuits, the latter falling under the umbrella of the variational quantum eigensolver. Here, we analyze the performance of quantum Boltzmann machines for this task, which is a less explored ansatz based on parameterized thermal states and which is not known to suffer from the barren-plateau problem. We delineate a hybrid quantum-classical algorithm for this task and rigorously prove that it converges to an $\varepsilon$-approximate stationary point of the energy function optimized over parameter space, while using a number of parameterized-thermal-state samples that is polynomial in $\varepsilon^{-1}$, the number of parameters, and the norm of the Hamiltonian being optimized. Our algorithm estimates the gradient of the energy function efficiently by means of a novel quantum circuit construction that combines classical sampling, Hamiltonian simulation, and the Hadamard test, thus overcoming a key obstacle to quantum Boltzmann machine learning that has been left open since [Amin \textit{et al.}, Phys.~Rev.~X \textbf{8}, 021050 (2018)]. Additionally supporting our main claims are calculations of the gradient and Hessian of the energy function, as well as an upper bound on the matrix elements of the latter that is used in the convergence analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12935v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dhrumil Patel, Daniel Koch, Saahil Patel, Mark M. Wilde</dc:creator>
    </item>
    <item>
      <title>modOpt: A modular development environment and library for optimization algorithms</title>
      <link>https://arxiv.org/abs/2410.12942</link>
      <description>arXiv:2410.12942v1 Announce Type: cross 
Abstract: Recent advances in computing hardware and modeling software have given rise to new applications for numerical optimization. These new applications occasionally uncover bottlenecks in existing optimization algorithms and necessitate further specialization of the algorithms. However, such specialization requires expert knowledge of the underlying mathematical theory and the software implementation of existing algorithms. To address this challenge, we present modOpt, an open-source software framework that facilitates the construction of optimization algorithms from modules. The modular environment provided by modOpt enables developers to tailor an existing algorithm for a new application by only altering the relevant modules. modOpt is designed as a platform to support students and beginner developers in quickly learning and developing their own algorithms. With that aim, the entirety of the framework is written in Python, and it is well-documented, well-tested, and hosted open-source on GitHub. Several additional features are embedded into the framework to assist both beginner and advanced developers. In addition to providing stock modules, the framework also includes fully transparent implementations of pedagogical optimization algorithms in Python. To facilitate testing and benchmarking of new algorithms, the framework features built-in visualization and recording capabilities, interfaces to modeling frameworks such as OpenMDAO and CSDL, interfaces to general-purpose optimization algorithms such as SNOPT and SLSQP, an interface to the CUTEst test problem set, etc. In this paper, we present the underlying software architecture of modOpt, review its various features, discuss several educational and performance-oriented algorithms within modOpt, and present numerical studies illustrating its unique benefits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12942v1</guid>
      <category>cs.MS</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anugrah Jo Joshy, John T. Hwang</dc:creator>
    </item>
    <item>
      <title>Optimal Transport for Probabilistic Circuits</title>
      <link>https://arxiv.org/abs/2410.13061</link>
      <description>arXiv:2410.13061v1 Announce Type: cross 
Abstract: We introduce a novel optimal transport framework for probabilistic circuits (PCs). While it has been shown recently that divergences between distributions represented as certain classes of PCs can be computed tractably, to the best of our knowledge, there is no existing approach to compute the Wasserstein distance between probability distributions given by PCs. We consider a Wasserstein-type distance that restricts the coupling measure of the associated optimal transport problem to be a probabilistic circuit. We then develop an algorithm for computing this distance by solving a series of small linear programs and derive the circuit conditions under which this is tractable. Furthermore, we show that we can also retrieve the optimal transport plan between the PCs from the solutions to these linear programming problems. We then consider the empirical Wasserstein distance between a PC and a dataset, and show that we can estimate the PC parameters to minimize this distance through an efficient iterative algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13061v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adrian Ciotinga, YooJung Choi</dc:creator>
    </item>
    <item>
      <title>Two-Timescale Linear Stochastic Approximation: Constant Stepsizes Go a Long Way</title>
      <link>https://arxiv.org/abs/2410.13067</link>
      <description>arXiv:2410.13067v1 Announce Type: cross 
Abstract: Previous studies on two-timescale stochastic approximation (SA) mainly focused on bounding mean-squared errors under diminishing stepsize schemes. In this work, we investigate {\it constant} stpesize schemes through the lens of Markov processes, proving that the iterates of both timescales converge to a unique joint stationary distribution in Wasserstein metric. We derive explicit geometric and non-asymptotic convergence rates, as well as the variance and bias introduced by constant stepsizes in the presence of Markovian noise. Specifically, with two constant stepsizes $\alpha &lt; \beta$, we show that the biases scale linearly with both stepsizes as $\Theta(\alpha)+\Theta(\beta)$ up to higher-order terms, while the variance of the slower iterate (resp., faster iterate) scales only with its own stepsize as $O(\alpha)$ (resp., $O(\beta)$). Unlike previous work, our results require no additional assumptions such as $\beta^2 \ll \alpha$ nor extra dependence on dimensions. These fine-grained characterizations allow tail-averaging and extrapolation techniques to reduce variance and bias, improving mean-squared error bound to $O(\beta^4 + \frac{1}{t})$ for both iterates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13067v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeongyeol Kwon, Luke Dotson, Yudong Chen, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Delegated portfolio management with random default</title>
      <link>https://arxiv.org/abs/2410.13103</link>
      <description>arXiv:2410.13103v1 Announce Type: cross 
Abstract: We are considering the problem of optimal portfolio delegation between an investor and a portfolio manager under a random default time. We focus on a novel variation of the Principal-Agent problem adapted to this framework. We address the challenge of an uncertain investment horizon caused by an exogenous random default time, after which neither the agent nor the principal can access the market. This uncertainty introduces significant complexities in analyzing the problem, requiring distinct mathematical approaches for two cases: when the random default time falls within the initial time frame [0,T] and when it extends beyond this period. We develop a theoretical framework to model the stochastic dynamics of the investment process, incorporating the random default time. We then analyze the portfolio manager's investment decisions and compensation mechanisms for both scenarios. In the first case, where the default time could be unbounded, we apply traditional results from Backward Stochastic Differential Equations (BSDEs) and control theory to address the agent problem. In the second case, where the default time is within the interval [0,T], the problem becomes more intricate due to the degeneracy of the BSDE's driver. For both scenarios, we demonstrate that the contracting problem can be resolved by examining the existence of solutions to integro-partial Hamilton-Jacobi-Bellman (HJB) equations in both situations. We develop a deep-learning algorithm to solve the problem in high-dimension with no access to the optimizer of the Hamiltonian function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13103v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alberto Gennaro, Thibaut Mastrolia</dc:creator>
    </item>
    <item>
      <title>An It\^o-type formula for some measure-valued processes and its application on controlled superprocesses</title>
      <link>https://arxiv.org/abs/2410.13450</link>
      <description>arXiv:2410.13450v1 Announce Type: cross 
Abstract: We derive an It\^o-type formula for a measure-valued process that has a decomposition analogous to a classical semimartingale. The derivation begins with a time partitioning approach similar to the classical proof of It\^o's formula. To address the new challenges arising from the measure-valued setting, we employ symmetric polynomials to approximate the second-order linear derivative of the functional on finite measures, alongside certain localization techniques.
  A controlled superprocess with a binary branching mechanism can be interpreted as a weak solution to a controlled stochastic partial differential equation (SPDE), which naturally leads to such a decomposition. Consequently, this It\^o-type formula makes it possible to derive the Hamilton-Jacobi-Bellman (HJB) equation and the verification theorem for controlled superprocesses with a binary branching mechanism. Additionally, we propose a heuristic definition for the viscosity solution of an equation involving derivatives on finite measures. We prove that a continuous value function is a viscosity solution in this sense and demonstrate the uniqueness of the viscosity solution when the second-order derivative term on the measure vanishes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13450v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shang Li</dc:creator>
    </item>
    <item>
      <title>Strongly connected orientations and integer lattices</title>
      <link>https://arxiv.org/abs/2410.13665</link>
      <description>arXiv:2410.13665v1 Announce Type: cross 
Abstract: Let $D=(V,A)$ be a digraph whose underlying graph is $2$-edge-connected. Let $P$ be the polytope whose vertices are the incidence vectors of arc sets whose reversal makes $D$ strongly connected. $P$ can be described by $0,1$ bounds, and 'cut inequalities' which enforce that every nonempty proper vertex subset has at least one incoming arc after a re-orientation. Let $F$ be any face obtained by setting some cut inequalities to equality. We prove under a mild necessary condition that the integer points in $F$ contain an 'integral basis' $B$, i.e., $B$ is linearly independent, and any integral vector in the linear hull of $F$ is an integral linear combination of $B$. This result is surprising as the integer points in $F$ do not necessarily form a Hilbert basis. Our result is obtained by developing a theory similar to Matching Theory for degree-constrained dijoins in bipartite digraphs.
  Our result has several consequences, including to a famous conjecture by Woodall from the 1970s which states that the minimum size of a 'dicut' of $D$, say $\tau$, is equal to the maximum number of disjoint 'dijoins'. Our result proves a relaxation of this conjecture, by finding for any prime number $p\geq 2$, a $p$-adic packing of dijoins of value $\tau$ and of support size at most $2|A|$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13665v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Abdi, G\'erard Cornu\'ejols, Siyue Liu, Olha Silina</dc:creator>
    </item>
    <item>
      <title>Distributed Stochastic Block Coordinate Descent for Time-Varying Multi-Agent Optimization</title>
      <link>https://arxiv.org/abs/1912.13222</link>
      <description>arXiv:1912.13222v2 Announce Type: replace 
Abstract: In this paper, a class of large-scale distributed nonsmooth convex optimization problem over time-varying multi-agent network is investigated. Specifically, the decision space which can be split into several blocks of convex set is considered. We present a distributed block coordinate descent (DSBCD) method in which for each node, information communication with other agents and a block Bregman projection are performed in each iteration. In contrast to existing work, we do not require the projection is operated on the whole decision space. Instead, in each step, distributed projection procedure is performed on only one random block. The explicit formulation of the convergence level depending on random projection probabilities and network parameters is achieved. An expected $O(1/\sqrt{T})$ rate is achieved. In addition, we obtain an explicit $\mathcal{O}(b^2/\epsilon^2)$ complexity bound with target accuracy $\epsilon$ and characteristic constant factor $b$. The complexity with dependency on $\epsilon$ and $b$ is shown to be the best known in this literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:1912.13222v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhan Yu, Daniel W. C. Ho</dc:creator>
    </item>
    <item>
      <title>Algebraic Algorithms for Fractional Linear Matroid Parity via Non-commutative Rank</title>
      <link>https://arxiv.org/abs/2207.07946</link>
      <description>arXiv:2207.07946v2 Announce Type: replace 
Abstract: Matrix representations are a powerful tool for designing efficient algorithms for combinatorial optimization problems such as matching, and linear matroid intersection and parity. In this paper, we initiate the study of matrix representations using the concept of non-commutative rank (nc-rank), which has recently attracted attention in the research of Edmonds' problem. We reveal that the nc-rank of the matrix representation of linear matroid parity corresponds to the optimal value of fractional linear matroid parity: a half-integral relaxation of linear matroid parity. Based on our representation, we present an algebraic algorithm for the fractional linear matroid parity problem by building a new technique to incorporate the search-to-decision reduction into the half-integral problem represented via the nc-rank. We further present a faster divide-and-conquer algorithm for finding a maximum fractional matroid matching and an algebraic algorithm for finding a dual optimal solution. They together lead to an algebraic algorithm for the weighted fractional linear matroid parity problem. Our algorithms are significantly simpler and faster than the existing algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.07946v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taihei Oki, Tasuku Soma</dc:creator>
    </item>
    <item>
      <title>An output-polynomial time algorithm to determine all supported efficient solutions for multi-objective integer network flow problems</title>
      <link>https://arxiv.org/abs/2305.12867</link>
      <description>arXiv:2305.12867v2 Announce Type: replace 
Abstract: This paper addresses the problem of enumerating all supported efficient solutions for a linear multi-objective integer minimum cost flow problem (MOIMCF).
  First, we highlight an inconsistency in various definitions of supported nondominated vectors for multi-objective integer linear programs (MOILP). Several characterizations for supported nondominated vectors/efficient solutions are used in the literature, which are equivalent in the non-integer case. However, they may lead to different sets of supported nondominated vectors/efficient solutions for MOILPs. This motivates us to summarize equivalent definitions and characterizations for supported efficient solutions and to distinguish between supported and weakly supported efficient solutions.
  In this paper we derive an output-polynomial time algorithm to determine all supported efficient solutions for MOIMCF problems.
  This is the first approach that solves this general problem in output-polynomial time.
  Moreover, we prove that the existence of an output-polynomial time algorithm to determine all weakly supported nondominated vectors (or all weakly supported efficient solutions) for a MOIMCF problem with a fixed number of d&gt;3 objectives can be excluded, unless P = NP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.12867v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David K\"onen, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>Improved Small-Signal L2 Gain Analysis for Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2309.08034</link>
      <description>arXiv:2309.08034v2 Announce Type: replace 
Abstract: TheL2-gain characterizes a dynamical system's input-output properties, but can be difficult to determine for nonlinear systems. Previous work designed a nonconvex optimization problem to simultaneously search for a continuous piecewise affine (CPA) storage function and an upper bound on the small-signal L2-gain of a dynamical system over a triangulated region about the origin. This work improves upon those results by establishing a tighter upper-bound on a system's gain using a convex optimization problem. By reformulating the relationship between the Hamilton-Jacobi inequality and L2-gain as a linear matrix inequality and then developing novel LMI error bounds for a triangulation, tighter gain bounds are derived and computed more efficiently. Additionally, a combined quadratic and CPA storage function is considered to expand the nonlinear systems this optimization problem is applicable to. Numerical results demonstrate the tighter upper bound on a dynamical system's gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08034v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amy Strong, Reza Lavaei, Leila J. Bridgeman</dc:creator>
    </item>
    <item>
      <title>Concurrent Design Optimization of Powertrain Component Modules in a Family of Electric Vehicles</title>
      <link>https://arxiv.org/abs/2311.03167</link>
      <description>arXiv:2311.03167v3 Announce Type: replace 
Abstract: We present a modeling and optimization framework to design powertrains for a family of electric vehicles, focusing on the concurrent sizing of their motors and batteries. Whilst tailoring these component modules to each individual vehicle type can minimize energy consumption, it can result in high production costs due to the variety of component modules to be realized for the family of vehicles, driving the Total Costs of Ownership (TCO) high. Against this backdrop, we explore modularity and standardization strategies whereby we jointly design unique motor and battery modules to be installed in all the vehicles in the family, using a different number of these modules when needed. Such an approach results in higher production volumes of the same component module, entailing significantly lower manufacturing costs due to Economy-of-Scale (EoS) effects, and hence a potentially lower TCO for the family of vehicles. To solve the resulting one-size-fits-all problem, we instantiate a nested framework consisting of an inner convex optimization routine which jointly optimizes the modules' sizes and the powertrain operation of the entire family, for given driving cycles and modules' multiplicities. Likewise, we devise an outer loop comparing each configuration to identify the minimum-TCO solution with global optimality guarantees. Finally, we showcase our framework on a case study for the Tesla vehicle family in a benchmark design problem, considering the Model S, Model 3, Model X, and Model Y. Our results show that, compared to an individually tailored design, the application of our concurrent design optimization framework achieves a significant reduction of the production costs for a minimal increase in operational costs, ultimately lowering the family TCO in the benchmark design problem by 3.5\%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03167v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maurizio Clemente, Mauro Salazar, Theo Hofman</dc:creator>
    </item>
    <item>
      <title>Existence and Density Theorems of Henig Global Proper Efficient Points</title>
      <link>https://arxiv.org/abs/2401.10103</link>
      <description>arXiv:2401.10103v3 Announce Type: replace 
Abstract: In this work, we provide some novel results that establish both the existence of Henig global proper efficient points and their density in the efficient set for vector optimization problems in arbitrary normed spaces. Our results do not require the assumption of convexity, and in certain cases, can be applied to unbounded sets. However, it is important to note that a weak compactness condition on the set (or on a section of it) and a separation property between the order cone and its conical neighborhoods remains necessary. The weak compactness condition ensures that certain convergence properties hold. The separation property enables the interpolation of a family of Bishop-Phelps cones between the order cone and each of its conic neighborhoods. This interpolation, combined with the proper handling of two distinct types of conic neighborhoods, plays a crucial role in the proofs of our results, which include as a particular case other results that have already been established under more restrictive conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10103v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fernando Garc\'ia-Casta\~no, Miguel \'Angel Melguizo-Padial</dc:creator>
    </item>
    <item>
      <title>Chattering Phenomena in Time-Optimal Control for High-Order Chain-of-Integrator Systems with Full State Constraints (Extended Version)</title>
      <link>https://arxiv.org/abs/2403.17675</link>
      <description>arXiv:2403.17675v4 Announce Type: replace 
Abstract: Time-optimal control for high-order chain-of-integrator systems with full state constraints remains an open and challenging problem within the discipline of optimal control. The behavior of optimal control in high-order problems lacks precise characterization, and even the existence of the chattering phenomenon, i.e., the control switches for infinitely many times over a finite period, remains unknown and overlooked. This paper establishes a theoretical framework for chattering phenomena in the considered problem, providing novel findings on the uniqueness of state constraints inducing chattering, the upper bound of switching times in an unconstrained arc during chattering, and the convergence of states and costates to the chattering limit point. For the first time, this paper proves the existence of the chattering phenomenon in the considered problem. The chattering optimal control for 4th-order problems with velocity constraints is precisely solved, providing an approach to plan time-optimal snap-limited trajectories. Other cases of order $n\leq4$ are proved not to allow chattering. The conclusions rectify a longstanding misconception in the industry concerning the time-optimality of S-shaped trajectories with minimal switching times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17675v4</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunan Wang, Chuxiong Hu, Zeyang Li, Yujie Lin, Shize Lin, Suqin He</dc:creator>
    </item>
    <item>
      <title>Continuous-time q-Learning for Jump-Diffusion Models under Tsallis Entropy</title>
      <link>https://arxiv.org/abs/2407.03888</link>
      <description>arXiv:2407.03888v2 Announce Type: replace 
Abstract: This paper studies the continuous-time reinforcement learning in jump-diffusion models by featuring the q-learning (the continuous-time counterpart of Q-learning) under Tsallis entropy regularization. Contrary to the Shannon entropy, the general form of Tsallis entropy renders the optimal policy not necessary a Gibbs measure, where the Lagrange and KKT multipliers naturally arise from some constraints to ensure the learnt policy to be a probability density function. As a consequence, the characterization of the optimal policy using the q-function also involves a Lagrange multiplier. In response, we establish the martingale characterization of the q-function under Tsallis entropy and devise two q-learning algorithms depending on whether the Lagrange multiplier can be derived explicitly or not. In the latter case, we need to consider different parameterizations of the optimal q-function and the optimal policy and update them alternatively in an Actor-Critic manner. We also study two financial applications, namely, an optimal portfolio liquidation problem and a non-LQ control problem. It is interesting to see therein that the optimal policies under the Tsallis entropy regularization can be characterized explicitly, which are distributions concentrated on some compact support. The satisfactory performance of our q-learning algorithms is illustrated in each example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03888v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lijun Bo, Yijie Huang, Xiang Yu, Tingting Zhang</dc:creator>
    </item>
    <item>
      <title>Global convergence of gradient descent for phase retrieval</title>
      <link>https://arxiv.org/abs/2410.09990</link>
      <description>arXiv:2410.09990v2 Announce Type: replace 
Abstract: We propose a tensor-based criterion for benign landscape in phase retrieval and establish boundedness of gradient trajectories. This implies that gradient descent will converge to a global minimum for almost every initial point.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09990v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Th\'eodore Fougereux, C\'edric Josz, Xiaopeng Li</dc:creator>
    </item>
    <item>
      <title>RPCBF: Constructing Safety Filters Robust to Model Error and Disturbances via Policy Control Barrier Functions</title>
      <link>https://arxiv.org/abs/2410.11157</link>
      <description>arXiv:2410.11157v2 Announce Type: replace 
Abstract: Control Barrier Functions (CBFs) have proven to be an effective tool for performing safe control synthesis for nonlinear systems. However, guaranteeing safety in the presence of disturbances and input constraints for high relative degree systems is a difficult problem. In this work, we propose the Robust Policy CBF (RPCBF), a practical method of constructing CBF approximations that is easy to implement and robust to disturbances via the estimation of a value function. We demonstrate the effectiveness of our method in simulation on a variety of high relative degree input-constrained systems. Finally, we demonstrate the benefits of RPCBF in compensating for model errors on a hardware quadcopter platform by treating the model errors as disturbances. The project page can be found at https://oswinso.xyz/rpcbf.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11157v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Luzia Knoedler, Oswin So, Ji Yin, Mitchell Black, Zachary Serlin, Panagiotis Tsiotras, Javier Alonso-Mora, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>The Strong Maximum Circulation Algorithm: A New Method for Aggregating Preference Rankings</title>
      <link>https://arxiv.org/abs/2307.15702</link>
      <description>arXiv:2307.15702v3 Announce Type: replace-cross 
Abstract: We present a new optimization-based method for aggregating preferences in settings where each voter expresses preferences over pairs of alternatives. Our approach to identifying a consensus partial order is motivated by the observation that collections of votes that form a cycle can be treated as collective ties. Our approach then removes unions of cycles of votes, or circulations, from the vote graph and determines aggregate preferences from the remainder. Specifically, we study the removal of maximal circulations attained by any union of cycles the removal of which leaves an acyclic graph. We introduce the strong maximum circulation, the removal of which guarantees a unique outcome in terms of the induced partial order, called the strong partial order. The strong maximum circulation also satisfies strong complementary slackness conditions, and is shown to be solved efficiently as a network flow problem. We further establish the relationship between the dual of the maximum circulation problem and Kemeny's method, a popular optimization-based approach for preference aggregation. We also show that identifying a minimum maximal circulation -- i.e., a maximal circulation containing the smallest number of votes -- is an NP-hard problem. Further an instance of the minimum maximal circulation may have multiple optimal solutions whose removal results in conflicting partial orders.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.15702v3</guid>
      <category>cs.SI</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nathan Atkinson, Scott C. Ganz, Dorit S. Hochbaum, James B. Orlin</dc:creator>
    </item>
    <item>
      <title>Achieving Exponential Asymptotic Optimality in Average-Reward Restless Bandits without Global Attractor Assumption</title>
      <link>https://arxiv.org/abs/2405.17882</link>
      <description>arXiv:2405.17882v2 Announce Type: replace-cross 
Abstract: We consider the infinite-horizon average-reward restless bandit problem. We propose a novel \emph{two-set policy} that maintains two dynamic subsets of arms: one subset of arms has a nearly optimal state distribution and takes actions according to an Optimal Local Control routine; the other subset of arms is driven towards the optimal state distribution and gradually merged into the first subset. We show that our two-set policy is asymptotically optimal with an $O(\exp(-C N))$ optimality gap for an $N$-armed problem, under the mild assumptions of aperiodic-unichain, non-degeneracy, and local stability. Our policy is the first to achieve \emph{exponential asymptotic optimality} under the above set of easy-to-verify assumptions, whereas prior work either requires a strong \emph{global attractor} assumption or only achieves an $O(1/\sqrt{N})$ optimality gap. We further discuss obstacles in weakening the assumptions by demonstrating examples where exponential asymptotic optimality is not achievable when any of the three assumptions is violated. Notably, we prove a lower bound for a large class of locally unstable restless bandits, showing that local stability is particularly fundamental for exponential asymptotic optimality. Finally, we use simulations to demonstrate that the two-set policy outperforms previous policies on certain RB problems and performs competitively overall.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17882v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yige Hong, Qiaomin Xie, Yudong Chen, Weina Wang</dc:creator>
    </item>
    <item>
      <title>Existence and nonexistence of minimizers for classical capillarity problems in presence of nonlocal repulsion and gravity</title>
      <link>https://arxiv.org/abs/2406.02735</link>
      <description>arXiv:2406.02735v3 Announce Type: replace-cross 
Abstract: We investigate, under a volume constraint and among sets contained in a Euclidean half-space, the minimization problem of an energy functional given by the sum of a capillarity perimeter, a nonlocal interaction term and a gravitational potential energy. The capillarity perimeter assigns a constant weight to the portion of the boundary touching the boundary of the half-space. The nonlocal term is represented by a double integral of a positive kernel $g$, while the gravitational term is represented by the integral of a positive potential $G$.
  We first establish existence of volume-constrained minimizers in the small mass regime, together with several qualitative properties of minimizers. The existence result holds for rather general choices of kernels in the nonlocal interaction term, including attractive-repulsive ones. When the nonlocal kernel $g(x)=1/|x|^\beta$ with $\beta \in (0,2]$, we also obtain nonexistence of volume constrained minimizers in the large mass regime. Finally, we prove a generalized existence result of minimizers holding for all masses and general nonlocal interaction terms, meaning that the infimum of the problem is realized by a finite disjoint union of sets thought located at ``infinite distance'' one from the other.
  These results stem from an application of quantitative isoperimetric inequalities for the capillarity problem in a half-space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.02735v3</guid>
      <category>math.AP</category>
      <category>math.DG</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giulio Pascale</dc:creator>
    </item>
    <item>
      <title>Orthogonalized Estimation of Difference of $Q$-functions</title>
      <link>https://arxiv.org/abs/2406.08697</link>
      <description>arXiv:2406.08697v2 Announce Type: replace-cross 
Abstract: Offline reinforcement learning is important in many settings with available observational data but the inability to deploy new policies online due to safety, cost, and other concerns. Many recent advances in causal inference and machine learning target estimation of causal contrast functions such as CATE, which is sufficient for optimizing decisions and can adapt to potentially smoother structure. We develop a dynamic generalization of the R-learner (Nie and Wager 2021, Lewis and Syrgkanis 2021) for estimating and optimizing the difference of $Q^\pi$-functions, $Q^\pi(s,1)-Q^\pi(s,0)$ (which can be used to optimize multiple-valued actions). We leverage orthogonal estimation to improve convergence rates in the presence of slower nuisance estimation rates and prove consistency of policy optimization under a margin condition. The method can leverage black-box nuisance estimators of the $Q$-function and behavior policy to target estimation of a more structured $Q$-function contrast.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08697v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Defu Cao, Angela Zhou</dc:creator>
    </item>
    <item>
      <title>Adjoint Matching: Fine-tuning Flow and Diffusion Generative Models with Memoryless Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2409.08861</link>
      <description>arXiv:2409.08861v3 Announce Type: replace-cross 
Abstract: Dynamical generative models that produce samples through an iterative process, such as Flow Matching and denoising diffusion models, have seen widespread use, but there have not been many theoretically-sound methods for improving these models with reward fine-tuning. In this work, we cast reward fine-tuning as stochastic optimal control (SOC). Critically, we prove that a very specific memoryless noise schedule must be enforced during fine-tuning, in order to account for the dependency between the noise variable and the generated samples. We also propose a new algorithm named Adjoint Matching which outperforms existing SOC algorithms, by casting SOC problems as a regression problem. We find that our approach significantly improves over existing methods for reward fine-tuning, achieving better consistency, realism, and generalization to unseen human preference reward models, while retaining sample diversity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08861v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich, Michal Drozdzal, Brian Karrer, Ricky T. Q. Chen</dc:creator>
    </item>
    <item>
      <title>MALADY: Multiclass Active Learning with Auction Dynamics on Graphs</title>
      <link>https://arxiv.org/abs/2409.09475</link>
      <description>arXiv:2409.09475v2 Announce Type: replace-cross 
Abstract: Active learning enhances the performance of machine learning methods, particularly in semi-supervised cases, by judiciously selecting a limited number of unlabeled data points for labeling, with the goal of improving the performance of an underlying classifier. In this work, we introduce the Multiclass Active Learning with Auction Dynamics on Graphs (MALADY) framework which leverages the auction dynamics algorithm on similarity graphs for efficient active learning. In particular, we generalize the auction dynamics algorithm on similarity graphs for semi-supervised learning in [24] to incorporate a more general optimization functional. Moreover, we introduce a novel active learning acquisition function that uses the dual variable of the auction algorithm to measure the uncertainty in the classifier to prioritize queries near the decision boundaries between different classes. Lastly, using experiments on classification tasks, we evaluate the performance of our proposed method and show that it exceeds that of comparison algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09475v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokul Bhusal, Kevin Miller, Ekaterina Merkurjev</dc:creator>
    </item>
    <item>
      <title>Loss Landscape Characterization of Neural Networks without Over-Parametrization</title>
      <link>https://arxiv.org/abs/2410.12455</link>
      <description>arXiv:2410.12455v2 Announce Type: replace-cross 
Abstract: Optimization methods play a crucial role in modern machine learning, powering the remarkable empirical achievements of deep learning models. These successes are even more remarkable given the complex non-convex nature of the loss landscape of these models. Yet, ensuring the convergence of optimization methods requires specific structural conditions on the objective function that are rarely satisfied in practice. One prominent example is the widely recognized Polyak-Lojasiewicz (PL) inequality, which has gained considerable attention in recent years. However, validating such assumptions for deep neural networks entails substantial and often impractical levels of over-parametrization. In order to address this limitation, we propose a novel class of functions that can characterize the loss landscape of modern deep models without requiring extensive over-parametrization and can also include saddle points. Crucially, we prove that gradient-based optimizers possess theoretical guarantees of convergence under this assumption. Finally, we validate the soundness of our new function class through both theoretical analysis and empirical experimentation across a diverse range of deep learning models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12455v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 18 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rustem Islamov, Niccol\`o Ajroldi, Antonio Orvieto, Aurelien Lucchi</dc:creator>
    </item>
  </channel>
</rss>
