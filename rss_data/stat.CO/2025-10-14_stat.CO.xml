<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 15 Oct 2025 01:46:17 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Great expectations: Unifying Statistical Theory and Programming</title>
      <link>https://arxiv.org/abs/2510.09853</link>
      <description>arXiv:2510.09853v1 Announce Type: new 
Abstract: Beginning in the 1970s, statistician-cum-logician Per Martin-L\"of wrote a series of papers developing what became Martin-L\"of type theory, realizing a system where the distinction between mathematics and programming disappears. Inspired by this vision, this paper introduces dependent type theory (of which Martin-L\"of type theory is an example) to a statistical audience. Examples from statistics and probability theory demonstrate how dependent type theory and an algebraic perspective can unify the theoretical and computational concerns of statistics, ensuring rigorous, machine-checked proofs and executable software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09853v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bradley Saul</dc:creator>
    </item>
    <item>
      <title>Parametric Sensitivity Analysis: Local and Global Approaches in Stochastic Biochemical Models</title>
      <link>https://arxiv.org/abs/2510.10416</link>
      <description>arXiv:2510.10416v1 Announce Type: new 
Abstract: The recent advancements in mathematical modeling of biochemical systems have generated increased interest in sensitivity analysis methodologies. There are two primary approaches for analyzing these mathematical models: the stochastic approach, which employs chemical master equations (CME), and the deterministic approach, which utilizes ordinary differential equations (ODEs). The intractable discrete states present in most biochemical processes render the direct simulation of the CME infeasible. Moment closure approximations are recognized for their numerical efficiency in estimating the statistics of the CME solution. Since classical sensitivity analysis is not directly applicable to stochastic modeling, this work conducts sensitivity analysis using moment-based ordinary differential equations (ODEs) to identify key parameters that significantly influence the dynamics of the model. We conduct numerical tests to evaluate the effectiveness of both local and global sensitivity analyses of the moment-based ODEs. These tests enable us to examine how variations in input parameters influence the model's output.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10416v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kannon Hossain, Roger Sidje, Fahad Mostafa</dc:creator>
    </item>
    <item>
      <title>Spline Interpolation on Compact Riemannian Manifolds</title>
      <link>https://arxiv.org/abs/2510.11239</link>
      <description>arXiv:2510.11239v1 Announce Type: new 
Abstract: Spline interpolation is a widely used class of methods for solving interpolation problems by constructing smooth interpolants that minimize a regularized energy functional involving the Laplacian operator. While many existing approaches focus on Euclidean domains or the sphere, relying on the spectral properties of the Laplacian, this work introduces a method for spline interpolation on general manifolds by exploiting its equivalence with kriging. Specifically, the proposed approach uses finite element approximations of random fields defined over the manifold, based on Gaussian Markov Random Fields and a discretization of the Laplace-Beltrami operator on a triangulated mesh. This framework enables the modeling of spatial fields with local anisotropies through domain deformation. The method is first validated on the sphere using both analytical test cases and a pollution-related study, and is compared to the classical spherical harmonics-based method. Additional experiments on the surface of a cylinder further illustrate the generality of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11239v1</guid>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Charlie Sire, Mike Pereira, Thomas Romary</dc:creator>
    </item>
    <item>
      <title>Interval-Censored Survival Analysis of Grapevine Phenology: Thermal Controls on Flowering and Fruit Ripening</title>
      <link>https://arxiv.org/abs/2510.09702</link>
      <description>arXiv:2510.09702v1 Announce Type: cross 
Abstract: European grapevine (\textit{Vitis vinifera} L.) is a climate-sensitive perennial whose flowering and ripening govern yield and quality. Phenological records from monitoring programs are typically collected at irregular intervals, so true transition dates are interval-censored, and many site-years are right-censored. We develop a reproducible workflow that treats phenology as a time-to-event outcome: Status \&amp; Intensity observations from the USA-NPN are converted to interval bounds, linked to NASA POWER daily weather, and analyzed with parametric accelerated failure time (AFT) models (Weibull and log-logistic). To avoid outcome-dependent bias from aggregating weather up to the event date, antecedent conditions are summarized in fixed pre-season windows and standardized; quality-control filters ensure adequate within-window data coverage. Applied to flowering and ripening of \textit{V.~vinifera}, the framework yields interpretable time-ratio effects and publication-ready tables and figures. Warmer pre-season conditions are associated with earlier ripening, whereas flowering responses are modest and uncertain in these data; precipitation plays, at most, a secondary role. The approach demonstrates how interval-censored survival models with exogenous weather windows can extract robust climate signals from citizen-science phenology while preserving observation uncertainty, and it generalizes readily to other species and networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09702v1</guid>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sara Behnamian, Fatemeh Fogh</dc:creator>
    </item>
    <item>
      <title>AutoGD: Automatic Learning Rate Selection for Gradient Descent</title>
      <link>https://arxiv.org/abs/2510.09923</link>
      <description>arXiv:2510.09923v1 Announce Type: cross 
Abstract: The performance of gradient-based optimization methods, such as standard gradient descent (GD), greatly depends on the choice of learning rate. However, it can require a non-trivial amount of user tuning effort to select an appropriate learning rate schedule. When such methods appear as inner loops of other algorithms, expecting the user to tune the learning rates may be impractical. To address this, we introduce AutoGD: a gradient descent method that automatically determines whether to increase or decrease the learning rate at a given iteration. We establish the convergence of AutoGD, and show that we can recover the optimal rate of GD (up to a constant) for a broad class of functions without knowledge of smoothness constants. Experiments on a variety of traditional problems and variational inference optimization tasks demonstrate strong performance of the method, along with its extensions to AutoBFGS and AutoLBFGS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09923v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikola Surjanovic, Alexandre Bouchard-C\^ot\'e, Trevor Campbell</dc:creator>
    </item>
    <item>
      <title>Efficient Prior Sensitivity and Tipping-point Analysis for Medical Research: Revisiting Sampling Importance Resampling</title>
      <link>https://arxiv.org/abs/2510.10034</link>
      <description>arXiv:2510.10034v1 Announce Type: cross 
Abstract: Bayesian methods have received increasing attention in medical research, where sensitivity analysis of prior distributions is essential. Such analyses typically require the evaluation of the posterior distribution of a parameter under multiple alternative prior settings. When the posterior distribution of the parameter of interest cannot be derived analytically, the standard approach is to re-fit the Markov chain Monte Carlo (MCMC) algorithm for each setting, which incurs substantial computational costs. This issue is particularly relevant in tipping-point analysis, in which the posterior must be evaluated across gradually changing degrees of borrowing. Sampling importance resampling (SIR) provides an efficient alternative by approximating posterior samples under new settings without MCMC re-fitting. However, to our knowledge , its utility has not been evaluated in scenarios involving repeated MCMC -- such as tipping-point analysis -- or in the application of complex Bayesian models. In this study, we re-evaluate the utility of SIR through two case studies: one involving tipping-point analysis under external data borrowing and another involving sensitivity analysis for a nonparametric Bayesian model in meta-analysis. These examples demonstrate that SIR can significantly reduce computational costs while maintaining a reasonable approximation accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10034v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tomohiro Ohigashi, Shonosuke Sugasawa</dc:creator>
    </item>
    <item>
      <title>Examining the Interface Design of Tidyverse</title>
      <link>https://arxiv.org/abs/2510.10382</link>
      <description>arXiv:2510.10382v2 Announce Type: cross 
Abstract: The tidyverse is a popular meta-package comprising several core R packages to aid in various data science tasks, including data import, manipulation and visualisation. Although functionalities offered by the tidyverse can generally be replicated using other packages, its widespread adoption in both teaching and practice indicates there are factors contributing to its preference, despite some debate over its usage. This suggests that particular aspects, such as interface design, may play a significant role in its selection. Examining the interface design can potentially reveal aspects that aid the design process for developers. While Tidyverse has been lauded for adopting a user-centered design, arguably some elements of the design focus on the work domain instead of the end-user. We examine the Tidyverse interface design via the lens of human computer interaction, with an emphasis on data visualisation and data wrangling, to identify factors that might serve as a model for developers designing their packages. We recommend that developers adopt an iterative design that is informed by user feedback, analysis and complete coverage of the work domain, and ensure perceptual visibility of system constraints and relationships.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.10382v2</guid>
      <category>stat.OT</category>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emi Tanaka</dc:creator>
    </item>
    <item>
      <title>StatTestCalculator: A New General Tool for Statistical Analysis in High Energy Physics</title>
      <link>https://arxiv.org/abs/2510.11637</link>
      <description>arXiv:2510.11637v1 Announce Type: cross 
Abstract: We present StatTestCalculator (STC), a new open-source statistical analysis tool designed for analysis high energy physics experiments. STC provides both asymptotic calculations and Monte Carlo simulations for computing the exact statistical significance of a discovery or for setting upper limits on signal model parameters. We review the underlying statistical formalism, including profile likelihood ratio test statistics for discovery and exclusion hypotheses, and the asymptotic distributions that allow quick significance estimates. We explain the relevant formulas for the likelihood functions, test statistic distributions, and significance metrics (both with and without incorporating systematic uncertainties). The implementation and capabilities of STC are described, and we validate its performance against the widely-used CMS Combine tool. We find excellent agreement in both the expected discovery significances and upper limit calculations. STC is a flexible framework that can accommodate systematic uncertainties and user-defined statistical models, making it suitable for a broad range of analyses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11637v1</guid>
      <category>hep-ph</category>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emil Abasov, Lev Dudko, Daniil Gorin, Oleg Vasilevskii</dc:creator>
    </item>
    <item>
      <title>A General Framework for Importance Sampling with Markov Random Walks</title>
      <link>https://arxiv.org/abs/2311.12330</link>
      <description>arXiv:2311.12330v2 Announce Type: replace 
Abstract: Although stochastic models driven by latent Markov processes are widely used, the classical importance sampling methods based on the exponential tilting for these models suffers from the difficulties in computing the eigenvalues and associated eigenfunctions and the plausibility of the indirect asymptotic large deviation regime for the variance of the estimator. We propose a general importance sampling framework that twists the observable and latent processes separately using a link function that directly minimizes the estimator's variance. An optimal choice of the link function is chosen within the locally asymptotically normal family. We show the logarithmic efficiency of the proposed estimator. As applications, we estimate an overflow probability under a pandemic model and the CoVaR, a measurement of the co-dependent financial systemic risk. Both applications are beyond the scope of traditional importance sampling methods due to their nonlinear features.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.12330v2</guid>
      <category>stat.CO</category>
      <category>q-fin.CP</category>
      <category>q-fin.RM</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cheng-Der Fuh, Yanwei Jia, Steven Kou</dc:creator>
    </item>
    <item>
      <title>Stochastic gradient descent estimation of generalized matrix factorization models with application to single-cell RNA sequencing data</title>
      <link>https://arxiv.org/abs/2412.20509</link>
      <description>arXiv:2412.20509v2 Announce Type: replace 
Abstract: Single-cell RNA sequencing allows the quantification of gene expression at the individual cell level, enabling the study of cellular heterogeneity and gene expression dynamics. Dimensionality reduction is a common preprocessing step critical for the visualization, clustering, and phenotypic characterization of samples. This step, often performed using principal component analysis or closely related methods, is challenging because of the size and complexity of the data. In this work, we present a generalized matrix factorization model assuming a general exponential dispersion family distribution and we show that many of the proposed approaches in the single-cell dimensionality reduction literature can be seen as special cases of this model. Furthermore, we propose a scalable adaptive stochastic gradient descent algorithm that allows us to estimate the model efficiently, enabling the analysis of millions of cells. We benchmark the proposed algorithm through extensive numerical experiments against state-of-the-art methods and showcase its use in real-world biological applications. The proposed method systematically outperforms existing methods of both generalized and non-negative matrix factorization, demonstrating faster execution times and parsimonious memory usage, while maintaining, or even enhancing, matrix reconstruction fidelity and accuracy in biological signal extraction. On real data, we show that our method scales seamlessly to millions of cells, enabling dimensionality reduction in large single-cell datasets. Finally, all the methods discussed here are implemented in an efficient open-source R package, sgdGMF, available on CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20509v2</guid>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cristian Castiglione, Alexandre Segers, Lieven Clement, Davide Risso</dc:creator>
    </item>
    <item>
      <title>Non-conjugate variational Bayes for pseudo-likelihood mixed effect models</title>
      <link>https://arxiv.org/abs/2206.09444</link>
      <description>arXiv:2206.09444v5 Announce Type: replace-cross 
Abstract: We propose a unified, yet simple to code, non-conjugate variational Bayes algorithm for posterior approximation of generic Bayesian generalized mixed effect models. Specifically, we consider regression models identified by a linear predictor, eventually transformed using a bijective link, where the prediction misfit is measured using, possibly non-differentiable, loss functions. Examples include generalized linear models, quasi-likelihood models, and robust regression. To address the limitations of non-conjugate settings, we employ an efficient message passing optimization strategy under a Gaussian variational approximation of the posterior. The resulting algorithms automatically account for non-conjugate priors and non-smooth losses, without requiring model-specific data-augmented representations. Besides the general formulation, we provide closed-form updates for popular model specifications, including quantile regression and support vector machines. Overall, theoretical and empirical results highlight the effectiveness of the proposed method, demonstrating its computational efficiency and approximation accuracy as an alternative to existing Bayesian techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.09444v5</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/10618600.2025.2527925</arxiv:DOI>
      <arxiv:journal_reference>Journal of Computational and Graphical Statistics, 1-18 (2025)</arxiv:journal_reference>
      <dc:creator>Cristian Castiglione, Mauro Bernardi</dc:creator>
    </item>
    <item>
      <title>Geometric Ergodicity of Gibbs Algorithms for a Normal Model With a Global-Local Shrinkage Prior</title>
      <link>https://arxiv.org/abs/2503.00538</link>
      <description>arXiv:2503.00538v4 Announce Type: replace-cross 
Abstract: We consider Gibbs samplers for a normal linear regression model with a global-local shrinkage prior and show that they produce geometrically ergodic Markov chains. First, under the horseshoe local prior and a three-parameter beta global prior under some assumptions, we prove geometric ergodicity for a Gibbs algorithm in which it is relatively easy to update the global shrinkage parameter. Second, we consider a more general class of global-local shrinkage priors. Under milder conditions, geometric ergodicity is proved for two- and three-stage Gibbs samplers based on rejection sampling. We also construct a practical rejection sampling method in the horseshoe case. Finally, a simulation study is performed to compare proposed and existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00538v4</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 14 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasuyuki Hamura</dc:creator>
    </item>
  </channel>
</rss>
