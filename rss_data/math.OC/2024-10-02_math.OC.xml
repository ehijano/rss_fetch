<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 03 Oct 2024 02:10:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lattice-Valued Bottleneck Duality</title>
      <link>https://arxiv.org/abs/2410.00315</link>
      <description>arXiv:2410.00315v1 Announce Type: new 
Abstract: This note reformulates certain classical combinatorial duality theorems in the context of order lattices. For source-target networks, we generalize bottleneck path-cut and flow-cut duality results to edges with capacities in a distributive lattice. For posets, we generalize a bottleneck version of Dilworth's theorem, again weighted in a distributive lattice. These results are applicable to a wide array of non-numerical network flow problems, as shown. All results, proofs, and applications were created in collaboration with AI language models. An appendix documents their role and impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00315v1</guid>
      <category>math.OC</category>
      <category>math.CO</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Ghrist, Julian Gould, Miguel Lopez</dc:creator>
    </item>
    <item>
      <title>Energetic Resilience of Linear Driftless Systems</title>
      <link>https://arxiv.org/abs/2410.00323</link>
      <description>arXiv:2410.00323v1 Announce Type: new 
Abstract: When a malfunction causes a control system to lose authority over a subset of its actuators, achieving a task may require spending additional energy in order to compensate for the effect of uncontrolled inputs. To understand this increase in energy, we introduce energetic resilience metrics that quantify the maximal additional energy required to achieve finite-time regulation in linear driftless systems that lose authority over some of their actuators. Using a technical lemma based on the calculus of variations, we first derive optimal control signals and minimum energies to achieve this task in both the nominal and malfunctioning systems. We then obtain a bound on the worst-case energy used by the malfunctioning system, and its exact expression in the special case of loss of authority over one actuator. Further considering this special case, we derive bounds on additive and multiplicative metrics for energetic resilience. A simulation example on a model of an underwater robot demonstrates that these bounds are useful in quantifying the increased energy used by a system suffering a partial loss of control authority.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00323v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ram Padmanabhan, Melkior Ornik</dc:creator>
    </item>
    <item>
      <title>Importance sampling-based gradient method for dimension reduction in Poisson log-normal model</title>
      <link>https://arxiv.org/abs/2410.00476</link>
      <description>arXiv:2410.00476v1 Announce Type: new 
Abstract: High-dimensional count data poses significant challenges for statistical analysis, necessitating effective methods that also preserve explainability. We focus on a low rank constrained variant of the Poisson log-normal model, which relates the observed data to a latent low-dimensional multivariate Gaussian variable via a Poisson distribution. Variational inference methods have become a golden standard solution to infer such a model. While computationally efficient, they usually lack theoretical statistical properties with respect to the model. To address this issue we propose a projected stochastic gradient scheme that directly maximizes the log-likelihood. We prove the convergence of the proposed method when using importance sampling for estimating the gradient. Specifically, we obtain a rate of convergence of $O(T^{-1/2} + N^{-1})$ with $T$ the number of iterations and $N$ the number of Monte Carlo draws. The latter follows from a novel descent lemma for non convex $L$-smooth objective functions, and random biased gradient estimate. We also demonstrate numerically the efficiency of our solution compared to its variational competitor. Our method not only scales with respect to the number of observed samples but also provides access to the desirable properties of the maximum likelihood estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00476v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bastien Batardi\`ere (MIA Paris-Saclay), Julien Chiquet (MIA Paris-Saclay), Joon Kwon (MIA Paris-Saclay), Julien Stoehr (CEREMADE)</dc:creator>
    </item>
    <item>
      <title>On the Oracle Complexity of a Riemannian Inexact Augmented Lagrangian Method for Riemannian Nonsmooth Composite Problems</title>
      <link>https://arxiv.org/abs/2410.00482</link>
      <description>arXiv:2410.00482v2 Announce Type: new 
Abstract: In this paper, we establish for the first time the oracle complexity of a Riemannian inexact augmented Lagrangian (RiAL) method with the classical dual update for solving a class of Riemannian nonsmooth composite problems. By using the Riemannian gradient descent method with a specified stopping criterion for solving the inner subproblem, we show that the RiAL method can find an $\varepsilon$-stationary point of the considered problem with $\mathcal{O}(\varepsilon^{-3})$ calls to the first-order oracle. This achieves the best oracle complexity known to date. Numerical results demonstrate that the use of the classical dual stepsize is crucial to the high efficiency of the RiAL method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00482v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meng Xu, Bo Jiang, Ya-Feng Liu, Anthony Man-Cho So</dc:creator>
    </item>
    <item>
      <title>Optimal Rates for the Last Iterate of the Stochastic subgradient Method under Heavy-Tails</title>
      <link>https://arxiv.org/abs/2410.00573</link>
      <description>arXiv:2410.00573v1 Announce Type: new 
Abstract: In this paper, we provide novel optimal (or near optimal) convergence rates in expectation for the last iterate of a clipped version of the stochastic subgradient method. We consider nonsmooth convex problems, over possibly unbounded domains, under heavy-tailed noise that only possesses the first $p$ moments for $p \in (1,2]$. Our rates are of the order of $(\log k)/k^{(p-1)/p}$ and $1/k^{(p-1)/p}$ for infinite and finite horizon respectively. As a by-product, we also provide novel convergence rates for the average iterate, improving existing results by a $\log k$ factor. Preliminary experiments support our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00573v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniela Angela Parletta, Andrea Paudice, Saverio Salzo</dc:creator>
    </item>
    <item>
      <title>Circuit and Graver Walks and Linear and Integer Programming</title>
      <link>https://arxiv.org/abs/2410.00656</link>
      <description>arXiv:2410.00656v1 Announce Type: new 
Abstract: We show that a circuit walk from a given feasible point of a given linear program to an optimal point can be computed in polynomial time using only linear algebra operations and the solution of the single given linear program.
  We also show that a Graver walk from a given feasible point of a given integer program to an optimal point is polynomial time computable using an integer programming oracle, but without such an oracle, it is hard to compute such a walk even if an optimal solution to the given program is given as well.
  Combining our oracle algorithm with recent results on sparse integer programming, we also show that Graver walks from any point are polynomial time computable over matrices of bounded tree-depth and subdeterminants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00656v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.disopt.2024.100862</arxiv:DOI>
      <arxiv:journal_reference>Discrete Optimization, 54:100862 (7 pages), 2024</arxiv:journal_reference>
      <dc:creator>Shmuel Onn</dc:creator>
    </item>
    <item>
      <title>New Lyapunov functions for systems with source terms</title>
      <link>https://arxiv.org/abs/2410.00671</link>
      <description>arXiv:2410.00671v1 Announce Type: new 
Abstract: Lyapunov functions with exponential weights have been used successfully as a powerful tool for the stability analysis of hyperbolic systems of balance laws. In this paper we extend the class of weight functions to a family of hyperbolic functions and study the advantages in the analysis of $2\times 2$ systems of balance laws. We present cases connected with the study of the limit of stabilizability where the new weights provide Lyapunov functions that show exponential stability for a larger set of problem parameters than classical exponential weights.
  Moreover, we show that sufficiently large time-delays influence the limit of stabilizability in the sense that the parameter set where the system can be stabilized becomes substantially smaller.
  We also demonstrate that the hyperbolic weights are useful in the analysis of the boundary feedback stability of systems of balance laws that are governed by quasilinear hyperbolic partial differential equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00671v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Gugat</dc:creator>
    </item>
    <item>
      <title>Resonance Reduction Against Adversarial Attacks in Dynamic Networks via Eigenspectrum Optimization</title>
      <link>https://arxiv.org/abs/2410.00126</link>
      <description>arXiv:2410.00126v1 Announce Type: cross 
Abstract: Resonance is a well-known phenomenon that happens in systems with second order dynamics. In this paper we address the fundamental question of making a network robust to signal being periodically pumped into it at or near a resonant frequency by an adversarial agent with the aim of saturating the network with the signal. Towards this goal, we develop the notion of network vulnerability, which is measured by the expected resonance amplitude on the network under a stochastically modeled adversarial attack. Assuming a second order dynamics model based on the network graph Laplacian matrix and a known stochastic model for the adversarial attack, we propose two methods for minimizing the network vulnerability that leverage the principle of eigenspectrum optimization. We provide extensive numerical results analyzing the effects of both methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00126v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alp Sahin, Nicolas Kozachuk, Rick S. Blum, Subhrajit Bhattacharya</dc:creator>
    </item>
    <item>
      <title>(Almost) Smooth Sailing: Towards Numerical Stability of Neural Networks Through Differentiable Regularization of the Condition Number</title>
      <link>https://arxiv.org/abs/2410.00169</link>
      <description>arXiv:2410.00169v1 Announce Type: cross 
Abstract: Maintaining numerical stability in machine learning models is crucial for their reliability and performance. One approach to maintain stability of a network layer is to integrate the condition number of the weight matrix as a regularizing term into the optimization algorithm. However, due to its discontinuous nature and lack of differentiability the condition number is not suitable for a gradient descent approach. This paper introduces a novel regularizer that is provably differentiable almost everywhere and promotes matrices with low condition numbers. In particular, we derive a formula for the gradient of this regularizer which can be easily implemented and integrated into existing optimization algorithms. We show the advantages of this approach for noisy classification and denoising of MNIST images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00169v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rossen Nenov, Daniel Haider, Peter Balazs</dc:creator>
    </item>
    <item>
      <title>A Data-Driven Approach To Preserve Safety and Reference Tracking for Constrained Cyber-Physical Systems Under Network Attacks</title>
      <link>https://arxiv.org/abs/2410.00208</link>
      <description>arXiv:2410.00208v1 Announce Type: cross 
Abstract: This paper proposes a worst-case data-driven control architecture capable of ensuring the safety of constrained Cyber-Physical Systems under cyber-attacks while minimizing, whenever possible, potential degradation in tracking performance. To this end, a data-driven robust anomaly detector is designed to detect cyber-attack occurrences. Moreover, an add-on tracking supervisor module allows safe open-loop tracking control operations in case of unreliable measurements. On the plant side, a safety verification module and a local emergency controller are designed to manage severe attack scenarios that cannot be handled on the controller's side. These two modules resort to worst-case reachability and controllability data-driven arguments to detect potential unsafe scenarios and replace, whenever strictly needed, the tracking controller with emergency actions whose objective is to steer the plant's state trajectory in a predefined set of admissible and safe robust control invariant region until an attack-free scenario is restored. The effectiveness of the proposed solution has been shown through a simulation example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00208v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehran Attar, Walter Lucia</dc:creator>
    </item>
    <item>
      <title>Stochastic Inverse Problem: stability, regularization and Wasserstein gradient flow</title>
      <link>https://arxiv.org/abs/2410.00229</link>
      <description>arXiv:2410.00229v1 Announce Type: cross 
Abstract: Inverse problems in physical or biological sciences often involve recovering an unknown parameter that is random. The sought-after quantity is a probability distribution of the unknown parameter, that produces data that aligns with measurements. Consequently, these problems are naturally framed as stochastic inverse problems. In this paper, we explore three aspects of this problem: direct inversion, variational formulation with regularization, and optimization via gradient flows, drawing parallels with deterministic inverse problems. A key difference from the deterministic case is the space in which we operate. Here, we work within probability space rather than Euclidean or Sobolev spaces, making tools from measure transport theory necessary for the study. Our findings reveal that the choice of metric -- both in the design of the loss function and in the optimization process -- significantly impacts the stability and properties of the optimizer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00229v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qin Li, Maria Oprea, Li Wang, Yunan Yang</dc:creator>
    </item>
    <item>
      <title>Quantized and Asynchronous Federated Learning</title>
      <link>https://arxiv.org/abs/2410.00242</link>
      <description>arXiv:2410.00242v1 Announce Type: cross 
Abstract: Recent advances in federated learning have shown that asynchronous variants can be faster and more scalable than their synchronous counterparts. However, their design does not include quantization, which is necessary in practice to deal with the communication bottleneck. To bridge this gap, we develop a novel algorithm, Quantized Asynchronous Federated Learning (QAFeL), which introduces a hidden-state quantization scheme to avoid the error propagation caused by direct quantization. QAFeL also includes a buffer to aggregate client updates, ensuring scalability and compatibility with techniques such as secure aggregation. Furthermore, we prove that QAFeL achieves an $\mathcal{O}(1/\sqrt{T})$ ergodic convergence rate for stochastic gradient descent on non-convex objectives, which is the optimal order of complexity, without requiring bounded gradients or uniform client arrivals. We also prove that the cross-term error between staleness and quantization only affects the higher-order error terms. We validate our theoretical findings on standard benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00242v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Ortega, Hamid Jafarkhani</dc:creator>
    </item>
    <item>
      <title>A Taxonomy of Loss Functions for Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2410.00345</link>
      <description>arXiv:2410.00345v1 Announce Type: cross 
Abstract: Stochastic optimal control (SOC) aims to direct the behavior of noisy systems and has widespread applications in science, engineering, and artificial intelligence. In particular, reward fine-tuning of diffusion and flow matching models and sampling from unnormalized methods can be recast as SOC problems. A recent work has introduced Adjoint Matching (Domingo-Enrich et al., 2024), a loss function for SOC problems that vastly outperforms existing loss functions in the reward fine-tuning setup. The goal of this work is to clarify the connections between all the existing (and some new) SOC loss functions. Namely, we show that SOC loss functions can be grouped into classes that share the same gradient in expectation, which means that their optimization landscape is the same; they only differ in their gradient variance. We perform simple SOC experiments to understand the strengths and weaknesses of different loss functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00345v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carles Domingo-Enrich</dc:creator>
    </item>
    <item>
      <title>Beyond Minimax Rates in Group Distributionally Robust Optimization via a Novel Notion of Sparsity</title>
      <link>https://arxiv.org/abs/2410.00690</link>
      <description>arXiv:2410.00690v1 Announce Type: cross 
Abstract: The minimax sample complexity of group distributionally robust optimization (GDRO) has been determined up to a $\log(K)$ factor, for $K$ the number of groups. In this work, we venture beyond the minimax perspective via a novel notion of sparsity that we dub $(\lambda, \beta)$-sparsity. In short, this condition means that at any parameter $\theta$, there is a set of at most $\beta$ groups whose risks at $\theta$ all are at least $\lambda$ larger than the risks of the other groups. To find an $\epsilon$-optimal $\theta$, we show via a novel algorithm and analysis that the $\epsilon$-dependent term in the sample complexity can swap a linear dependence on $K$ for a linear dependence on the potentially much smaller $\beta$. This improvement leverages recent progress in sleeping bandits, showing a fundamental connection between the two-player zero-sum game optimization framework for GDRO and per-action regret bounds in sleeping bandits. The aforementioned result assumes having a particular $\lambda$ as input. Perhaps surprisingly, we next show an adaptive algorithm which, up to log factors, gets sample complexity that adapts to the best $(\lambda, \beta)$-sparsity condition that holds. Finally, for a particular input $\lambda$, we also show how to get a dimension-free sample complexity result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00690v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quan Nguyen, Nishant A. Mehta, Crist\'obal Guzm\'an</dc:creator>
    </item>
    <item>
      <title>The Sensitivity of the U.S. Presidential Election to Coordinated Voter Relocation</title>
      <link>https://arxiv.org/abs/2410.00697</link>
      <description>arXiv:2410.00697v1 Announce Type: cross 
Abstract: U.S. presidential elections are decided by the Electoral College, established in 1789, and designed to mitigate potential risks arising from the collusion of large groups of citizens. A statewide winner-take-all popular voting system for electors is implemented in all but two states, which has led to instances where narrow victories in key states were decisive in several recent elections. Small groups of voters can significantly impact the election, for example, through voter turnout. However, another dynamic can also influence this: a surprisingly small number of dedicated voters moving short distances across state lines. The extent to which the election's outcome is sensitive to small and well-coordinated movements of people has not been investigated in detail. Using a combination of forecasting, simulation, and optimization, we show that a candidate's probability of winning can be increased by 1% through the strategic relocation of approximately 10,000 people no farther than 100 miles from their current county of residence, less than 0.006% of the eligible voting population. Moreover, an 8% probability increase can be realized by a mere 50,000 voters relocating across state lines, or 0.03% of the voting population. Given the remarkably small number of people involved and the fact that establishing electoral residence in many states takes about a month, this coordinated relocation of voters is not nearly as challenging as previously thought. As it stands, U.S. presidential elections may be vulnerable to the exploitation of the aforementioned loophole. Therefore, we anticipate our findings will have direct consequences on policymaking and campaign strategy, as well as motivate new operations research methods within the political sciences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00697v1</guid>
      <category>physics.soc-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Carlos Cardonha, David Bergman, Andre Cire, Leonardo Lozano, Tallys Yunes</dc:creator>
    </item>
    <item>
      <title>Compressed radiotherapy treatment planning (CompressRTP): A new paradigm for rapid and high-quality treatment planning optimization</title>
      <link>https://arxiv.org/abs/2410.00756</link>
      <description>arXiv:2410.00756v1 Announce Type: cross 
Abstract: Background: Radiotherapy treatment planning involves solving large-scale optimization problems that are often approximated and solved sub-optimally due to time constraints. Central to these problems is the dose influence matrix which quantifies the radiation dose delivered from each beamlet to each voxel. Our findings demonstrate that this matrix is highly compressible, enabling a compact representation of the optimization problems and allowing them to be solved more efficiently and accurately. Methods: We precompute the primary (S) and scattering (L) dose contributions of the dose influence matrix A separately for photon therapy, expressed as: A = S + L. Our analysis reveals that the singular values of the scattering matrix L exhibit exponential decay, indicating that L is a low-rank matrix. This allows us to compress L into two smaller matrices: L=HW, where r is relatively small (approximately 5 to 10). Since the primary dose matrix S is sparse, this supports the use of the well-established "sparse-plus-low-rank" decomposition technique for the influence matrix A, approximated as: A = S + H * W. We introduce an efficient algorithm for sparse-plus-low-rank matrix decomposition, even without direct access to the scattering matrix. This algorithm is applied to optimize treatment plans for ten lung and ten prostate patients, using both compressed and sparsified versions of matrix A. We then evaluate the dose discrepancy between the optimized and final plans. We also integrate this compression technique with our in-house automated planning system, ECHO, and evaluate the dosimetric quality of the generated plans with and without compression.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00756v1</guid>
      <category>physics.med-ph</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mojtaba Tefagh, Gourav Jhanwar, Masoud Zarepisheh</dc:creator>
    </item>
    <item>
      <title>Fast and Reliable $N-k$ Contingency Screening with Input-Convex Neural Networks</title>
      <link>https://arxiv.org/abs/2410.00796</link>
      <description>arXiv:2410.00796v1 Announce Type: cross 
Abstract: Power system operators must ensure that dispatch decisions remain feasible in case of grid outages or contingencies to prevent cascading failures and ensure reliable operation. However, checking the feasibility of all $N - k$ contingencies -- every possible simultaneous failure of $k$ grid components -- is computationally intractable for even small $k$, requiring system operators to resort to heuristic screening methods. Because of the increase in uncertainty and changes in system behaviors, heuristic lists might not include all relevant contingencies, generating false negatives in which unsafe scenarios are misclassified as safe. In this work, we propose to use input-convex neural networks (ICNNs) for contingency screening. We show that ICNN reliability can be determined by solving a convex optimization problem, and by scaling model weights using this problem as a differentiable optimization layer during training, we can learn an ICNN classifier that is both data-driven and has provably guaranteed reliability. Namely, our method can ensure a zero false negative rate. We empirically validate this methodology in a case study on the IEEE 39-bus test network, observing that it yields substantial (10-20x) speedups while having excellent classification accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00796v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Christianson, Wenqi Cui, Steven Low, Weiwei Yang, Baosen Zhang</dc:creator>
    </item>
    <item>
      <title>Geometric shape matching for recovering protein conformations from single-particle Cryo-EM data</title>
      <link>https://arxiv.org/abs/2410.00833</link>
      <description>arXiv:2410.00833v1 Announce Type: cross 
Abstract: We address recovery of the three-dimensional backbone structure of single polypeptide proteins from single-particle cryo-electron microscopy (Cryo-SPA) data. Cryo-SPA produces noisy tomographic projections of electrostatic potentials of macromolecules. From these projections, we use methods from shape analysis to recover the three-dimensional backbone structure. Thus, we view the reconstruction problem as an indirect matching problem, where a point cloud representation of the protein backbone is deformed to match 2D tomography data. The deformations are obtained via the action of a matrix Lie group. By selecting a deformation energy, the optimality conditions are obtained, which lead to computational algorithms for optimal deformations. We showcase our approach on synthetic data, for which we recover the three-dimensional structure of the backbone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00833v1</guid>
      <category>q-bio.BM</category>
      <category>cs.NA</category>
      <category>math.DG</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Jansson, Jonathan Krook, Klas Modin, Ozan \"Oktem</dc:creator>
    </item>
    <item>
      <title>Learning Stochastic Dynamics from Snapshots through Regularized Unbalanced Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.00844</link>
      <description>arXiv:2410.00844v1 Announce Type: cross 
Abstract: Reconstructing dynamics using samples from sparsely time-resolved snapshots is an important problem in both natural sciences and machine learning. Here, we introduce a new deep learning approach for solving regularized unbalanced optimal transport (RUOT) and inferring continuous unbalanced stochastic dynamics from observed snapshots. Based on the RUOT form, our method models these dynamics without requiring prior knowledge of growth and death processes or additional information, allowing them to be learnt directly from data. Theoretically, we explore the connections between the RUOT and Schr\"odinger bridge problem and discuss the key challenges and potential solutions. The effectiveness of our method is demonstrated with a synthetic gene regulatory network. Compared with other methods, our approach accurately identifies growth and transition patterns, eliminates false transitions, and constructs the Waddington developmental landscape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00844v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>physics.comp-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhenyi Zhang, Tiejun Li, Peijie Zhou</dc:creator>
    </item>
    <item>
      <title>Bundle methods with quadratic cuts for deterministic and stochastic strongly convex optimization problems</title>
      <link>https://arxiv.org/abs/1711.04650</link>
      <description>arXiv:1711.04650v5 Announce Type: replace 
Abstract: We introduce two new methods for deterministic convex optimization problems: QCC (Quadratic Cuts for Convex optimization) and QB (Quadratic Bundle method). We prove the complexity of these methods for composite optimization problems which are the sum of a convex function $\tilde h$ and of a strongly convex function $\tilde f$ with parameter $\mu$. These methods use as building blocks quadratic approximations of the strongly convex function $\tilde f$ where the quadratic terms are of form $\frac{\mu}{2}\|\cdot-x_i\|^2$ for trial points $x_i$ computed along iterations (when $\mu=0$ the building blocks are linear approximations). We extend the idea of using quadratic approximations to pieces of the objective for some multistage stochastic optimization problems which have strongly convex recourse functions that we approximate as a maximum of quadratic cuts. We call DASC (Dynamic Approximation for Strongly Convex optimzation) the corresponding optimization method. When the cuts are linear, the method boils down to the popular Stochastic Dual Dynamic Programming (SDDP) method. We provide conditions ensuring strong convexity of the recourse functions and prove the convergence of DASC. Numerical experiments illustrate the performance and correctness of DASC, with DASC being much quicker than SDDP for large values of the constants of strong convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:1711.04650v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vincent Guigues, Adriana Washington</dc:creator>
    </item>
    <item>
      <title>Exponential stability of linear periodic difference-delay equations</title>
      <link>https://arxiv.org/abs/2201.12066</link>
      <description>arXiv:2201.12066v4 Announce Type: replace 
Abstract: This paper deals with the stability of linear periodic difference delay systems, where the value at time $t$ of a solution is a linear combination with periodic coefficients of its values at finitely many delayed instants $t-\tau_1,\ldots,t-\tau_N$. We establish a necessary and sufficient condition for exponential stability of such systems when the coefficients have H\"older-continuous derivative, that generalizes the one obtained for difference delay systems with constant coefficients by Henry and Hale in the 1970s. This condition may be construed as analyticity, in a half plane, of the (operator valued) harmonic transfer function of an associated linear control system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.12066v4</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <category>math.FA</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Baratchart, S\'ebastien Fueyo, Jean-Baptiste Pomet</dc:creator>
    </item>
    <item>
      <title>Alternating minimization for generalized rank one matrix sensing: Sharp predictions from a random initialization</title>
      <link>https://arxiv.org/abs/2207.09660</link>
      <description>arXiv:2207.09660v2 Announce Type: replace 
Abstract: We consider the problem of estimating the factors of a rank-$1$ matrix with i.i.d. Gaussian, rank-$1$ measurements that are nonlinearly transformed and corrupted by noise. Considering two prototypical choices for the nonlinearity, we study the convergence properties of a natural alternating update rule for this nonconvex optimization problem starting from a random initialization. We show sharp convergence guarantees for a sample-split version of the algorithm by deriving a deterministic recursion that is accurate even in high-dimensional problems. Notably, while the infinite-sample population update is uninformative and suggests exact recovery in a single step, the algorithm -- and our deterministic prediction -- converges geometrically fast from a random initialization. Our sharp, non-asymptotic analysis also exposes several other fine-grained properties of this problem, including how the nonlinearity and noise level affect convergence behavior.
  On a technical level, our results are enabled by showing that the empirical error recursion can be predicted by our deterministic sequence within fluctuations of the order $n^{-1/2}$ when each iteration is run with $n$ observations. Our technique leverages leave-one-out tools originating in the literature on high-dimensional $M$-estimation and provides an avenue for sharply analyzing higher-order iterative algorithms from a random initialization in other high-dimensional optimization problems with random data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.09660v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kabir Aladin Chandrasekher, Mengqi Lou, Ashwin Pananjady</dc:creator>
    </item>
    <item>
      <title>Quantifying the Safety of Trajectories using Peak-Minimizing Control</title>
      <link>https://arxiv.org/abs/2303.11896</link>
      <description>arXiv:2303.11896v3 Announce Type: replace 
Abstract: This work quantifies the safety of trajectories of a dynamical system by the perturbation intensity required to render a system unsafe (crash into the unsafe set). Computation of this measure of safety is posed as a peak-minimizing optimal control problem. Convergent lower bounds on the minimal peak value of controller effort are computed using polynomial optimization and the moment-Sum-of-Squares hierarchy. The crash-safety framework is extended towards data-driven safety analysis by measuring safety as the maximum amount of data corruption required to crash into the unsafe set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.11896v3</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jared Miller, Mario Sznaier</dc:creator>
    </item>
    <item>
      <title>A Decentralized Primal-Dual Method with Quasi-Newton Tracking</title>
      <link>https://arxiv.org/abs/2304.01614</link>
      <description>arXiv:2304.01614v4 Announce Type: replace 
Abstract: This paper considers the decentralized optimization problem of minimizing a finite sum of strongly convex and twice continuously differentiable functions over a fixed-connected undirected network. A fully decentralized primal-dual method(DPDM) and its generalization(GDPDM), which allows for multiple primal steps per iteration, are proposed. In our methods, both primal and dual updates use second-order information obtained by quasi-Newton techniques which only involve matrix-vector multiplication. Specifically, the primal update applies a Jacobi relaxation step using the BFGS approximation for both computation and communication efficiency. The dual update employs a new second-order correction step. We show that the decentralized local primal updating direction on each node asymptotically approaches the centralized quasi-Newton direction. Under proper choice of parameters, GDPDM including DPDM has global linear convergence for solving strongly convex decentralized optimization problems. Our numerical results show both GDPDM and DPDM are very efficient compared with other state-of-the-art methods for solving decentralized optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.01614v4</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liping Wang, Hao Wu, Hongchao Zhang</dc:creator>
    </item>
    <item>
      <title>Worst-case analysis of restarted primal-dual hybrid gradient on totally unimodular linear programs</title>
      <link>https://arxiv.org/abs/2309.03988</link>
      <description>arXiv:2309.03988v2 Announce Type: replace 
Abstract: We analyze restarted PDHG on totally unimodular linear programs. In particular, we show that restarted PDHG finds an $\epsilon$-optimal solution in $O( H m_1^{2.5} \sqrt{\textbf{nnz}(A)} \log(H m_2 /\epsilon) )$ matrix-vector multiplies where $m_1$ is the number of constraints, $m_2$ the number of variables, $\textbf{nnz}(A)$ is the number of nonzeros in the constraint matrix, $H$ is the largest absolute coefficient in the right hand side or objective vector, and $\epsilon$ is the distance to optimality of the outputted solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.03988v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Oliver Hinder</dc:creator>
    </item>
    <item>
      <title>Parallel Model Predictive Control for Deterministic Systems</title>
      <link>https://arxiv.org/abs/2309.14560</link>
      <description>arXiv:2309.14560v2 Announce Type: replace 
Abstract: In this note, we consider infinite horizon optimal control problems with deterministic systems. Since exact solutions to these problems are often intractable, we propose a parallel model predictive control (MPC) method that provides an approximate solution. Our method computes multiple lookahead minimization problems at each time, where each minimization may involve a different number of lookahead steps, and terminal cost and constraint. The parallel MPC method then applies the first control of the lookahead minimization with the lowest cost. We show that the proposed method has better performance guarantee than the MPC scheme involving a single lookahead minimization. Moreover, we establish the validity of a parallel implementation of our method in the presence of multiple computing units.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14560v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchao Li, Aren Karapetyan, Niklas Schmid, John Lygeros, Karl H. Johansson, Jonas M{\aa}rtensson</dc:creator>
    </item>
    <item>
      <title>Robust policy iteration for continuous-time stochastic $H_\infty$ control problem with unknown dynamics</title>
      <link>https://arxiv.org/abs/2402.04721</link>
      <description>arXiv:2402.04721v2 Announce Type: replace 
Abstract: In this article, we study a continuous-time stochastic $H_\infty$ control problem based on reinforcement learning (RL) techniques that can be viewed as solving a stochastic linear-quadratic two-person zero-sum differential game (LQZSG). First, we propose an RL algorithm that can iteratively solve stochastic game algebraic Riccati equation based on collected state and control data when all dynamic system information is unknown. In addition, the algorithm only needs to collect data once during the iteration process. Then, we discuss the robustness and convergence of the inner and outer loops of the policy iteration algorithm, respectively, and show that when the error of each iteration is within a certain range, the algorithm can converge to a small neighborhood of the saddle point of the stochastic LQZSG problem. Finally, we applied the proposed RL algorithm to two simulation examples to verify the effectiveness of the algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.04721v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhongshi Sun, Guangyan Jia</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control for setpoint tracking</title>
      <link>https://arxiv.org/abs/2403.02973</link>
      <description>arXiv:2403.02973v2 Announce Type: replace 
Abstract: The main objective of tracking control is to steer the tracking error, that is the difference between the reference and the output, to zero while the plant's operation limits are satisfied. This requires that some assumptions on the evolution of the future values of the reference must be taken into account. Typically a simple evolution of the reference is considered, such as step, ramp, or parabolic reference signals. It is important to notice that the tracking problem considers possible variations in the reference to be tracked, such as steps or slope variations of the ramps. Then the tracking control problem is inherently uncertain, since the reference may differ from what is expected. If the value of the reference is changed, then there is no guarantee that the feasibility and stability properties of the resulting control law hold. This report presents the MPC for tracking (MPCT) approach, which ensures recursive feasibility and asymptotic stability of the setpoint when the value of the reference is changed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02973v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Limon, Antonio Ferramosca, Ignacio Alvarado, Teodoro Alamo</dc:creator>
    </item>
    <item>
      <title>The Power of Extrapolation in Federated Learning</title>
      <link>https://arxiv.org/abs/2405.13766</link>
      <description>arXiv:2405.13766v5 Announce Type: replace 
Abstract: We propose and study several server-extrapolation strategies for enhancing the theoretical and empirical convergence properties of the popular federated learning optimizer FedProx [Li et al., 2020]. While it has long been known that some form of extrapolation can help in the practice of FL, only a handful of works provide any theoretical guarantees. The phenomenon seems elusive, and our current theoretical understanding remains severely incomplete. In our work, we focus on smooth convex or strongly convex problems in the interpolation regime. In particular, we propose Extrapolated FedProx (FedExProx), and study three extrapolation strategies: a constant strategy (depending on various smoothness parameters and the number of participating devices), and two smoothness-adaptive strategies; one based on the notion of gradient diversity (FedExProx-GraDS), and the other one based on the stochastic Polyak stepsize (FedExProx-StoPS). Our theory is corroborated with carefully constructed numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.13766v5</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanmin Li, Kirill Acharya, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Internal Control of The Transition Kernel for Stochastic Lattice Dynamics</title>
      <link>https://arxiv.org/abs/2407.03710</link>
      <description>arXiv:2407.03710v2 Announce Type: replace 
Abstract: In [5], we have designed impulsive and feedback controls for harmonic chains with a point thermostat. In this work, we study the internal control for stochastic lattice dynamics, with the goal of controlling the transition kernel of the kinetic equation in the limit. A major novelty of the work is the introduction of a new geometric combinatorial argument, used to establish paths for the controls.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.03710v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Amirali Hannani, Minh-Nhat Phung, Minh-Binh Tran, Emmanuel Tr\'elat</dc:creator>
    </item>
    <item>
      <title>An optimal boundary control problem related to the time dependent Navier-Stokes equations</title>
      <link>https://arxiv.org/abs/2407.12561</link>
      <description>arXiv:2407.12561v2 Announce Type: replace 
Abstract: In this work, we study a boundary control problem for the evolutionary Navier-Stokes equations, under mixed boundary conditions, in two dimensions. The cost functional here considered is of quadratic type, depending on both state and control variables. We provide a comprehensive theoretical framework to address the analysis and the derivation of a system of first-order optimality conditions that characterizes the solution of the control problem. We take advantage of an adequate treatment of the Dirichlet control through the study of the reduced functional. Despite the fact that this approach is quite common, a detailed analysis for the case of mixed boundary conditions with is still lacking. Finally, solution-finding algorithms of descent type are proposed and illustrated with several simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12561v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Telma Guerra, Irene Mar\'in-Gayte, Jorge Tiago</dc:creator>
    </item>
    <item>
      <title>Optimal Control on Positive Cones</title>
      <link>https://arxiv.org/abs/2407.18774</link>
      <description>arXiv:2407.18774v2 Announce Type: replace 
Abstract: An optimal control problem on finite-dimensional positive cones is stated. Under a critical assumption on the cone, the corresponding Bellman equation is satisfied by a linear function, which can be computed by convex optimization. A separate theorem relates the assumption on the cone to the existence of minimal elements in certain subsets of the dual cone. Three special cases are derived as examples. The first one, where the positive cone is the set of positive semi-definite matrices, reduces to standard linear quadratic control. The second one, where the positive cone is a polyhedron, reduces to a recent result on optimal control of positive systems. The third special case corresponds to linear quadratic control with additional structure, such as spatial invariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18774v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Pates, Anders Rantzer</dc:creator>
    </item>
    <item>
      <title>Volume-preserving geometric shape optimization of the Dirichlet energy using variational neural networks</title>
      <link>https://arxiv.org/abs/2407.19064</link>
      <description>arXiv:2407.19064v4 Announce Type: replace 
Abstract: In this work, we explore the numerical solution of geometric shape optimization problems using neural network-based approaches. This involves minimizing a numerical criterion that includes solving a partial differential equation with respect to a domain, often under geometric constraints like a constant volume. We successfully develop a proof of concept using a flexible and parallelizable methodology to tackle these problems. We focus on a prototypal problem: minimizing the so-called Dirichlet energy with respect to the domain under a volume constraint, involving Poisson's equation in $\mathbb{R}^2$. We use variational neural networks to approximate the solution to Poisson's equation on a given domain, and represent the shape through a neural network that approximates a volume-preserving transformation from an initial shape to an optimal one. These processes are combined in a single optimization algorithm that minimizes the Dirichlet energy. A significant advantage of this approach is its inherent parallelizability, which makes it easy to handle the addition of parameters. Additionally, it does not rely on shape derivative or adjoint calculations. Our approach is tested on Dirichlet and Robin boundary conditions, parametric right-hand sides, and extended to Bernoulli-type free boundary problems. The source code for solving the shape optimization problem is open-source and freely available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.19064v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Amaury B\'eli\`eres--Frendo, Emmanuel Franck, Victor Michel-Dansac, Yannick Privat</dc:creator>
    </item>
    <item>
      <title>A note on the failure of the Faber-Krahn inequality for the vector Laplacian</title>
      <link>https://arxiv.org/abs/2409.07206</link>
      <description>arXiv:2409.07206v2 Announce Type: replace 
Abstract: We consider a natural eigenvalue problem for the vector Laplacian related to stationary Maxwell's equations in a cavity and we prove that an analog of the celebrated Faber-Krahn inequality doesn't hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07206v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.SP</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Krejcirik, Pier Domenico Lamberti, Michele Zaccaron</dc:creator>
    </item>
    <item>
      <title>Tight Lower Bounds under Asymmetric High-Order H\"older Smoothness and Uniform Convexity</title>
      <link>https://arxiv.org/abs/2409.10773</link>
      <description>arXiv:2409.10773v2 Announce Type: replace 
Abstract: In this paper, we provide tight lower bounds for the oracle complexity of minimizing high-order H\"older smooth and uniformly convex functions. Specifically, for a function whose $p^{th}$-order derivatives are H\"older continuous with degree $\nu$ and parameter $H$, and that is uniformly convex with degree $q$ and parameter $\sigma$, we focus on two asymmetric cases: (1) $q &gt; p + \nu$, and (2) $q &lt; p+\nu$. Given up to $p^{th}$-order oracle access, we establish worst-case oracle complexities of $\Omega\left( \left( \frac{H}{\sigma}\right)^\frac{2}{3(p+\nu)-2}\left( \frac{\sigma}{\epsilon}\right)^\frac{2(q-p-\nu)}{q(3(p+\nu)-2)}\right)$ in the first case with an $\ell_\infty$-ball-truncated-Gaussian smoothed hard function and $\Omega\left(\left(\frac{H}{\sigma}\right)^\frac{2}{3(p+\nu)-2}+ \log^2\left(\frac{\sigma^{p+\nu}}{H^q}\right)^\frac{1}{p+\nu-q}\right)$ in the second case, for reaching an $\epsilon$-approximate solution in terms of the optimality gap. Our analysis generalizes previous lower bounds for functions under first- and second-order smoothness as well as those for uniformly convex functions, and furthermore our results match the corresponding upper bounds in the general setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10773v2</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Site Bai, Brian Bullins</dc:creator>
    </item>
    <item>
      <title>Irreducibility of nonsmooth state-space models with an application to CMA-ES</title>
      <link>https://arxiv.org/abs/2409.20107</link>
      <description>arXiv:2409.20107v2 Announce Type: replace 
Abstract: We analyze a stochastic process resulting from the normalization of states in the zeroth-order optimization method CMA-ES. On a specific class of minimization problems where the objective function is scaling-invariant, this process defines a time-homogeneous Markov chain whose convergence at a geometric rate can imply the linear convergence of CMA-ES. However, the analysis of the intricate updates for this process constitute a great mathematical challenge. We establish that this Markov chain is an irreducible and aperiodic T-chain. These contributions represent a first major step for the convergence analysis towards a stationary distribution. We rely for this analysis on conditions for the irreducibility of nonsmooth state-space models on manifolds. To obtain our results, we extend these conditions to address the irreducibility in different hyperparameter settings that define different Markov chains, and to include nonsmooth state spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.20107v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Armand Gissler (CMAP), Shan-Conrad Wolf (CMAP), Anne Auger (CMAP), Nikolaus Hansen (CMAP)</dc:creator>
    </item>
    <item>
      <title>To spike or not to spike: the whims of the Wonham filter in the strong noise regime</title>
      <link>https://arxiv.org/abs/2211.02032</link>
      <description>arXiv:2211.02032v3 Announce Type: replace-cross 
Abstract: We study the celebrated Shiryaev-Wonham filter (1964) in its historical setup where the hidden Markov jump process has two states. We are interested in the weak noise regime for the observation equation. Interestingly, this becomes a strong noise regime for the filtering equations.
  Earlier results of the authors show the appearance of spikes in the filtered process, akin to a metastability phenomenon. This paper is aimed at understanding the smoothed optimal filter, which is relevant for any system with feedback. In particular, we exhibit a sharp phase transition between a spiking regime and a regime with perfect smoothing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.02032v3</guid>
      <category>math.PR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Bernardin, Reda Chhaibi, Joseph Najnudel, Cl\'ement Pellegrini</dc:creator>
    </item>
    <item>
      <title>Robust Multivariate Detection and Estimation with Fault Frequency Content Information</title>
      <link>https://arxiv.org/abs/2310.04922</link>
      <description>arXiv:2310.04922v4 Announce Type: replace-cross 
Abstract: This paper studies the problem of fault detection and estimation (FDE) for linear time-invariant (LTI) systems with a particular focus on frequency content information of faults, possibly as multiple disjoint continuum ranges, and under both disturbances and stochastic noise. To ensure the worst-case fault sensitivity in the considered frequency ranges and mitigate the effects of disturbances and noise, an optimization framework incorporating a mixed H_/H2 performance index is developed to compute the optimal detection filter. Moreover, a thresholding rule is proposed to guarantee both the false alarm rate (FAR) and the fault detection rate (FDR). Next, shifting attention to fault estimation in specific frequency ranges, an exact reformulation of the optimal estimation filter design using the restricted Hinf performance index is derived, which is inherently non-convex. However, focusing on finite frequency samples and fixed poles, a lower bound is established via a highly tractable quadratic programming (QP) problem. This lower bound together with an alternating optimization (AO) approach to the original estimation problem leads to a suboptimality gap for the overall estimation filter design. The effectiveness of the proposed approaches is validated through applications of a non-minimum phase hydraulic turbine system and a multi-area power system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04922v4</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingwei Dong, Kaikai Pan, Sergio Pequito, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>Incentive-Compatible Vertiport Reservation in Advanced Air Mobility: An Auction-Based Approach</title>
      <link>https://arxiv.org/abs/2403.18166</link>
      <description>arXiv:2403.18166v4 Announce Type: replace-cross 
Abstract: The rise of advanced air mobility (AAM) is expected to become a multibillion-dollar industry in the near future. Market-based mechanisms are touted to be an integral part of AAM operations, which comprise heterogeneous operators with private valuations. In this work, we study the problem of designing a mechanism to coordinate the movement of electric vertical take-off and landing (eVTOL) aircraft, operated by multiple operators each having heterogeneous valuations associated with their fleet, between vertiports, while enforcing the arrival, departure, and parking constraints at vertiports. Particularly, we propose an incentive-compatible and individually rational vertiport reservation mechanism that maximizes a social welfare metric, which encapsulates the objective of maximizing the overall valuations of all operators while minimizing the congestion at vertiports. Additionally, we improve the computational tractability of designing the reservation mechanism by proposing a mixed binary linear programming approach that leverages the network flow structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18166v4</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pan-Yang Su, Chinmay Maheshwari, Victoria Tuck, Shankar Sastry</dc:creator>
    </item>
    <item>
      <title>Decoding a mean field game by the Cauchy data around its unknown stationary states</title>
      <link>https://arxiv.org/abs/2405.18943</link>
      <description>arXiv:2405.18943v2 Announce Type: replace-cross 
Abstract: In recent years, mean field games (MFGs) have garnered considerable attention and emerged as a dynamic and actively researched field across various domains, including economics, social sciences, finance, and transportation. The inverse design and decoding of MFGs offer valuable means to extract information from observed data and gain insights into the intricate underlying dynamics and strategies of these complex physical systems. This paper presents a novel approach to the study of inverse problems in MFGs by analyzing the Cauchy data around their unknown stationary states. This study distinguishes itself from existing inverse problem investigations in three key significant aspects: Firstly, we consider MFG problems in a highly general form. Secondly, we address the technical challenge of the probability measure constraint by utilizing Cauchy data in our inverse problem study. Thirdly, we enhance existing high order linearization methods by introducing a novel approach that involves conducting linearization around non-trivial stationary states of the MFG system, which are not a-priori known. These contributions provide new insights and offer promising avenues for studying inverse problems for MFGs. By unraveling the hidden structure of MFGs, researchers and practitioners can make informed decisions, optimize system performance, and address real-world challenges more effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18943v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyu Liu, Catharine W. K. Lo, Shen Zhang</dc:creator>
    </item>
    <item>
      <title>A continuous model of transportation in the Heisenberg group</title>
      <link>https://arxiv.org/abs/2406.09380</link>
      <description>arXiv:2406.09380v2 Announce Type: replace-cross 
Abstract: We present a minimization problem with a horizontal divergence-type constraint in the Heisenberg group. Our study explores its dual formulation and examines its relationship with the congested optimal transport problem, for $1 &lt; p &lt; +\infty$, as well as the Monge-Kantorovich problem, in the limite case $p=1$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.09380v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Michele Circelli, Albert Clop</dc:creator>
    </item>
    <item>
      <title>MDP Geometry, Normalization and Value Free Solvers</title>
      <link>https://arxiv.org/abs/2407.06712</link>
      <description>arXiv:2407.06712v2 Announce Type: replace-cross 
Abstract: The Markov Decision Process (MDP) is a widely used mathematical model for sequential decision-making problems. In this paper, we present a new geometric interpretation of MDPs. Based on this interpretation, we show that MDPs can be divided into equivalence classes with indistinguishable key solving algorithms dynamics. This related normalization procedure enables the development of a novel class of MDP-solving algorithms that find optimal policies without computing policy values. The new algorithms we propose for different settings achieve and, in some cases, improve upon state-of-the-art results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06712v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arsenii Mustafin, Aleksei Pakharev, Alex Olshevsky, Ioannis Ch. Paschalidis</dc:creator>
    </item>
    <item>
      <title>FLeNS: Federated Learning with Enhanced Nesterov-Newton Sketch</title>
      <link>https://arxiv.org/abs/2409.15216</link>
      <description>arXiv:2409.15216v2 Announce Type: replace-cross 
Abstract: Federated learning faces a critical challenge in balancing communication efficiency with rapid convergence, especially for second-order methods. While Newton-type algorithms achieve linear convergence in communication rounds, transmitting full Hessian matrices is often impractical due to quadratic complexity. We introduce Federated Learning with Enhanced Nesterov-Newton Sketch (FLeNS), a novel method that harnesses both the acceleration capabilities of Nesterov's method and the dimensionality reduction benefits of Hessian sketching. FLeNS approximates the centralized Newton's method without relying on the exact Hessian, significantly reducing communication overhead. By combining Nesterov's acceleration with adaptive Hessian sketching, FLeNS preserves crucial second-order information while preserving the rapid convergence characteristics. Our theoretical analysis, grounded in statistical learning, demonstrates that FLeNS achieves super-linear convergence rates in communication rounds - a notable advancement in federated optimization. We provide rigorous convergence guarantees and characterize tradeoffs between acceleration, sketch size, and convergence speed. Extensive empirical evaluation validates our theoretical findings, showcasing FLeNS's state-of-the-art performance with reduced communication requirements, particularly in privacy-sensitive and edge-computing scenarios. The code is available at https://github.com/sunnyinAI/FLeNS</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15216v2</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>cs.DC</category>
      <category>math.OC</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sunny Gupta, Mohit Jindal, Pankhi Kashyap, Pranav Jeevan, Amit Sethi</dc:creator>
    </item>
    <item>
      <title>Almost Sure Convergence of Average Reward Temporal Difference Learning</title>
      <link>https://arxiv.org/abs/2409.19546</link>
      <description>arXiv:2409.19546v3 Announce Type: replace-cross 
Abstract: Tabular average reward Temporal Difference (TD) learning is perhaps the simplest and the most fundamental policy evaluation algorithm in average reward reinforcement learning. After at least 25 years since its discovery, we are finally able to provide a long-awaited almost sure convergence analysis. Namely, we are the first to prove that, under very mild conditions, tabular average reward TD converges almost surely to a sample path dependent fixed point. Key to this success is a new general stochastic approximation result concerning nonexpansive mappings with Markovian and additive noise, built on recent advances in stochastic Krasnoselskii-Mann iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19546v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 02 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Blaser, Shangtong Zhang</dc:creator>
    </item>
  </channel>
</rss>
