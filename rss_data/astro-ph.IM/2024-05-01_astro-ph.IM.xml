<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 02 May 2024 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 02 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Hobby-Eberly Telescope VIRUS Parallel Survey (HETVIPS)</title>
      <link>https://arxiv.org/abs/2405.00585</link>
      <description>arXiv:2405.00585v1 Announce Type: new 
Abstract: The Hobby-Eberly Telescope (HET) VIRUS Parallel Survey (HETVIPS) is a blind spectroscopic program that sparsely covers approximately two-thirds of the celestial sphere and consists of roughly 252 million fiber spectra. The spectra were taken in parallel mode with the Visible Integral-field Replicable Unit Spectrograph (VIRUS) instrument when the HET was observing a primary target with other HET facility instruments. VIRUS can simultaneously obtain approximately 35,000 spectra covering 3470A to 5540A at a spectral resolution of ~800. Although the vast majority of these spectra cover blank sky, we used the Pan-STARRS1 Data Release 2 Stacked Catalog to identify objects encompassed in the HETVIPS pointings and extract their spectra. This paper presents the first HETVIPS data release, containing 493,012 flux-calibrated spectra obtained through 31 March 2023, as well as a description of the data processing technique. Each of the object spectra were classified, resulting in a catalog of 74,196 galaxies, 4,087 quasars, 259,396 stars, and 154,543 unknown sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00585v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-4357/ad35b8</arxiv:DOI>
      <arxiv:journal_reference>2024ApJ...966...14Z</arxiv:journal_reference>
      <dc:creator>Gregory R. Zeimann, Maya H. Debski, Donald P. Schneider, William P. Bowman, Niv Drory, Gary J. Hill, Hanshin Lee, Phillip MacQueen, Matthew Shetrone</dc:creator>
    </item>
    <item>
      <title>HPX with Spack and Singularity Containers: Evaluating Overheads for HPX/Kokkos using an astrophysics application</title>
      <link>https://arxiv.org/abs/2405.00016</link>
      <description>arXiv:2405.00016v1 Announce Type: cross 
Abstract: Cloud computing for high performance computing resources is an emerging topic. This service is of interest to researchers who care about reproducible computing, for software packages with complex installations, and for companies or researchers who need the compute resources only occasionally or do not want to run and maintain a supercomputer on their own. The connection between HPC and containers is exemplified by the fact that Microsoft Azure's Eagle cloud service machine is number three on the November 23 Top 500 list. For cloud services, the HPC application and dependencies are installed in containers, e.g. Docker, Singularity, or something else, and these containers are executed on the physical hardware. Although containerization leverages the existing Linux kernel and should not impose overheads on the computation, there is the possibility that machine-specific optimizations might be lost, particularly machine-specific installs of commonly used packages. In this paper, we will use an astrophysics application using HPX-Kokkos and measure overheads on homogeneous resources, e.g. Supercomputer Fugaku, using CPUs only and on heterogenous resources, e.g. LSU's hybrid CPU and GPU system. We will report on challenges in compiling, running, and using the containers as well as performance performance differences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00016v1</guid>
      <category>cs.DC</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Diehl, Steven R. Brandt, Gregor Dai{\ss}, Hartmut Kaiser</dc:creator>
    </item>
    <item>
      <title>Technosignatures longevity and Lindy's law</title>
      <link>https://arxiv.org/abs/2405.00020</link>
      <description>arXiv:2405.00020v1 Announce Type: cross 
Abstract: The probability of detecting technosignatures (i.e. evidence of technological activity beyond Earth) increases with their longevity, or the time interval over which they manifest. Therefore, the assumed distribution of longevities has some bearing on the chances of success of technosignature searches, as well as on the inferred age of technosignatures following a first contact. Here, we investigate the possibility that the longevity of technosignatures conforms to the so-called Lindy's law, whereby, at any time, their remaining life expectancy is roughly proportional to their age. We show that, if Lindy's law applies, the general tenet that the first detected technosignature ought to be very long lived may be overruled. We conclude by discussing the number of emitters that had to appear, over the history of the Galaxy, in order for one of them to be detectable today from Earth.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00020v1</guid>
      <category>physics.pop-ph</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.3847/1538-3881/ad217d</arxiv:DOI>
      <arxiv:journal_reference>The Astronomical Journal, 167, 119 (2024)</arxiv:journal_reference>
      <dc:creator>A. Balbi, C. Grimaldi</dc:creator>
    </item>
    <item>
      <title>X-Shooting ULLYSES: Massive Stars at Low Metallicity</title>
      <link>https://arxiv.org/abs/2405.00085</link>
      <description>arXiv:2405.00085v1 Announce Type: cross 
Abstract: The Hubble Space Telescope has devoted 500 orbits to observing 250 massive stars with low metallicity in the ultraviolet (UV) range within the framework of the ULLYSES program. The X-Shooting ULLYSES (XShootU) project enhances the legacy value of this UV dataset by providing high-quality optical and near-infrared spectra, which are acquired using the wide-wavelength-coverage X-shooter spectrograph at ESO's Very Large Telescope. XShootU emphasises the importance of combining UV with optical spectra for the consistent determination of key stellar parameters such as effective temperature, surface gravity, luminosity, abundances, and wind characteristics including mass-loss rates as a function of metallicity. Since uncertainties in these parameters have implications across various branches of astrophysics, the data and modelling generated by the XShootU project are poised to significantly advance our understanding of massive stars at low metallicity. This is particularly crucial for confidently interpreting JWST data of the earliest stellar generations, making XShootU a unique resource for comprehending individual spectra of low-metallicity stars.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00085v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.CO</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>ESO Messenger, 2024</arxiv:journal_reference>
      <dc:creator>Jorick S. Vink, Paul Crowther, Alex Fullerton, Miriam Garcia, Fabrice Martins, Nidia Morrell, Lida Oskinova, Nicole St. Louis, Asif ud-Doula, Andreas Sander, Hugues Sana, Jean-Claude Bouret, Brankica Kubatova, Pablo Marchant, Lucimara P. Martins, Aida Wofford, Jacco van Loon, O. Grace Telford, Ylva G\"otberg, Dominic Bowman, Christi Erba, Venu Kalari, The XShootU Collaboration</dc:creator>
    </item>
    <item>
      <title>Astronomy's climate emissions: Global travel to scientific meetings in 2019</title>
      <link>https://arxiv.org/abs/2405.00104</link>
      <description>arXiv:2405.00104v1 Announce Type: cross 
Abstract: Travel to academic conferences -- where international flights are the norm -- is responsible for a sizeable fraction of the greenhouse gas (GHG) emissions associated with academic work. In order to provide a benchmark for comparison with other fields, as well as for future reduction strategies and assessments, we estimate the CO2-equivalent emissions for conference travel in the field of astronomy for the prepandemic year 2019. The GHG emission of the international astronomical community's 362 conferences and schools in 2019 amounted to 42,500 tCO2e, assuming a radiative-forcing index factor of 1.95 for air travel. This equates to an average of 1.0 $\pm$ 0.6 tCO2e per participant per meeting. The total travel distance adds up to roughly 1.5 Astronomical Units, that is, 1.5 times the distance between the Earth and the Sun. We present scenarios for the reduction of this value, for instance with virtual conferencing or hub models, while still prioritizing the benefits conferences bring to the scientific community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00104v1</guid>
      <category>physics.soc-ph</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/pnasnexus/pgae143</arxiv:DOI>
      <arxiv:journal_reference>PNAS Nexus, Volume 3, Issue 5, May 2024, pgae143</arxiv:journal_reference>
      <dc:creator>Andrea Gokus, Knud Jahnke, Paul M Woods, Vanessa A Moss, Volker Ossenkopf-Okada, Elena Sacchi, Adam R H Stevens, Leonard Burtscher, Cenk Kayhan, Hannah Dalgleish, Victoria Grinberg, Travis A Rector, Jan Rybizki, Jacob White</dc:creator>
    </item>
    <item>
      <title>Contribution of PRIDE VLBI products to the joint JUICE-Europa Clipper moons' ephemerides solution</title>
      <link>https://arxiv.org/abs/2405.00562</link>
      <description>arXiv:2405.00562v1 Announce Type: cross 
Abstract: In the coming decade, JUICE and Europa Clipper radio-science will yield the most accurate estimation to date of the Galilean moons' physical parameters and ephemerides. JUICE's PRIDE (Planetary Radio Interferometry and Doppler Experiment) will help achieve such a solution by providing VLBI (Very Long Baseline Interferometry) observations of the spacecraft's lateral position, complementing nominal radio-science measurements. We quantify how PRIDE VLBI can contribute to the moons' ephemerides determination, in terms of attainable solution improvement and validation opportunities. To this end, we simulated both single- and dual-spacecraft VLBI, exploiting the potential simultaneous tracking of JUICE and Europa Clipper. We considered various tracking and data quality scenarios, and compared the formal uncertainties obtained with and without VLBI. This was performed for both global and local (i.e., per-flyby) estimations of the moons' states, as achieving a global solution first requires proceeding arc-per-arc. We showed that both single- and dual-spacecraft VLBI only bring limited improvement to the global state estimation, but significantly contribute to the moons' normal points (i.e., local states at flyby times), most notably in the out-of-plane direction. Additionally, we designed a validation plan exploiting PRIDE VLBI to progressively validate the classical radio-science solution. By improving the local state estimations and offering various validation opportunities, PRIDE will be invaluable in overcoming possible dynamical modelling challenges. It can therefore play a key role in reconstructing a global solution for the Galilean moons' dynamics with the uncertainty levels promised by JUICE-Europa Clipper analyses. This, in turn, is critical to the accurate characterisation of tidal dissipation in the Jovian system, holding the key to the long-term evolution of the Galilean moons.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00562v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.icarus.2024.116101</arxiv:DOI>
      <dc:creator>Marie S. Fayolle, Dominic Dirkx, Giuseppe Cimo, Leonid I. Gurvits, Valery Lainey, Pieter N. A. M. Visser</dc:creator>
    </item>
    <item>
      <title>A novel energy reconstruction method for the MAGIC stereoscopic observation</title>
      <link>https://arxiv.org/abs/2212.03592</link>
      <description>arXiv:2212.03592v2 Announce Type: replace 
Abstract: We present a new gamma ray energy reconstruction method based on Random Forest to be commonly used for the data analysis of the MAGIC Telescopes, a system of two Imaging Atmospheric Cherenkov Telescopes.
  The energy resolution with the new energy reconstruction improves compared to the one obtained with the LUTs method. For standard observations i.e. dark conditions with pointing zenith (Zd) less than 35 deg for a point-like source, the energy resolution goes from $\sim 20\%$ at 100 GeV to $\sim 10\%$ at a few TeV.
  In addition, the new method suppresses the outlier population in the energy error distribution, which is thus better described by a Gaussian distribution. The new energy reconstruction method enhances the reliability especially for the sources with steep spectra, in higher energies and/or in observations at higher Zd pointings.
  We validate the new method in different ways and demonstrate some cases of its remarkable benefit in spectral analysis with simulated observation data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.03592v2</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.HE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.astropartphys.2024.102937</arxiv:DOI>
      <arxiv:journal_reference>Astroparticle Physics Volume 158, June 2024, 102937</arxiv:journal_reference>
      <dc:creator>Kazuma Ishio, David Paneque</dc:creator>
    </item>
    <item>
      <title>The R2D2 deep neural network series paradigm for fast precision imaging in radio astronomy</title>
      <link>https://arxiv.org/abs/2403.05452</link>
      <description>arXiv:2403.05452v3 Announce Type: replace 
Abstract: Radio-interferometric (RI) imaging entails solving high-resolution high-dynamic range inverse problems from large data volumes. Recent image reconstruction techniques grounded in optimization theory have demonstrated remarkable capability for imaging precision, well beyond CLEAN's capability. These range from advanced proximal algorithms propelled by handcrafted regularization operators, such as the SARA family, to hybrid plug-and-play (PnP) algorithms propelled by learned regularization denoisers, such as AIRI. Optimization and PnP structures are however highly iterative, which hinders their ability to handle the extreme data sizes expected from future instruments. To address this scalability challenge, we introduce a novel deep learning approach, dubbed "Residual-to-Residual DNN series for high-Dynamic range imaging". R2D2's reconstruction is formed as a series of residual images, iteratively estimated as outputs of Deep Neural Networks (DNNs) taking the previous iteration's image estimate and associated data residual as inputs. It thus takes a hybrid structure between a PnP algorithm and a learned version of the matching pursuit algorithm that underpins CLEAN. We present a comprehensive study of our approach, featuring its multiple incarnations distinguished by their DNN architectures. We provide a detailed description of its training process, targeting a telescope-specific approach. R2D2's capability to deliver high precision is demonstrated in simulation, across a variety of image and observation settings using the Very Large Array (VLA). Its reconstruction speed is also demonstrated: with only few iterations required to clean data residuals at dynamic ranges up to 100000, R2D2 opens the door to fast precision imaging. R2D2 codes are available in the BASPLib library on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05452v3</guid>
      <category>astro-ph.IM</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Aghabiglou, Chung San Chu, Arwa Dabbech, Yves Wiaux</dc:creator>
    </item>
    <item>
      <title>Adaptation of the Phase Distance Correlation Periodogram to Account for Measurement Uncertainties</title>
      <link>https://arxiv.org/abs/2404.02506</link>
      <description>arXiv:2404.02506v2 Announce Type: replace 
Abstract: We present an improvement of the phase distance correlation (PDC) periodogram to account for uncertainties in the time-series data. The PDC periodogram introduced in our previous papers is based on the statistical concept of distance correlation. By viewing each measurement and its accompanying error estimate as a probability distribution, we are able to use the concept of energy distance to design a distance function (metric) between measurement-uncertainty pairs. We used this metric as the basis for the PDC periodogram,instead of the simple absolute difference. We demonstrate the periodogram's performance using both simulated and real-life data. This adaptation makes the PDC periodogram much more useful, demonstrating it can be helpful in the exploration of large time-resolved astronomical databases, ranging from Gaia radial velocity and photometry data releases to those of smaller surveys, such as APOGEE and LAMOST. We have made a public GitHub repository available, with a Python implementation of the new tools available to the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02506v2</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Avraham Binnenfeld, Sahar Shahaf, Shay Zucker</dc:creator>
    </item>
    <item>
      <title>Mitigating the counterpart selection effect for standard sirens</title>
      <link>https://arxiv.org/abs/2307.10402</link>
      <description>arXiv:2307.10402v2 Announce Type: replace-cross 
Abstract: The disagreement in the Hubble constant measured by different cosmological probes highlights the need for a better understanding of the observations or new physics. The standard siren method, a novel approach using gravitational-wave observations to determine the distance to binary mergers, has great potential to provide an independent measurement of the Hubble constant and shed light on the tension in the next few years. To realize this goal, we must thoroughly understand the sources of potential systematic bias of standard sirens. Among the known sources of systematic uncertainties, selection effects originating from electromagnetic counterpart observations of gravitational-wave sources may dominate the measurements with percent-level bias and no method to mitigate this effect is currently established. In this Letter, we develop a new formalism to mitigate the counterpart selection effect. We show that our formalism can reduce the systematic uncertainty of standard siren Hubble constant measurement to less than the statistical uncertainty with a simulated population of 200 observations ($\lesssim 1\%$) for a realistic electromagnetic emission model. We conclude with how to apply our formalism to different electromagnetic emissions and observing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.10402v2</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hsin-Yu Chen, Colm Talbot, Eve A. Chase</dc:creator>
    </item>
  </channel>
</rss>
