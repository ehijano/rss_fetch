<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Apr 2025 03:05:49 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Efficient Learning on Large Graphs using a Densifying Regularity Lemma</title>
      <link>https://arxiv.org/abs/2504.18273</link>
      <description>arXiv:2504.18273v1 Announce Type: new 
Abstract: Learning on large graphs presents significant challenges, with traditional Message Passing Neural Networks suffering from computational and memory costs scaling linearly with the number of edges. We introduce the Intersecting Block Graph (IBG), a low-rank factorization of large directed graphs based on combinations of intersecting bipartite components, each consisting of a pair of communities, for source and target nodes. By giving less weight to non-edges, we show how to efficiently approximate any graph, sparse or dense, by a dense IBG. Specifically, we prove a constructive version of the weak regularity lemma, showing that for any chosen accuracy, every graph, regardless of its size or sparsity, can be approximated by a dense IBG whose rank depends only on the accuracy. This dependence of the rank solely on the accuracy, and not on the sparsity level, is in contrast to previous forms of the weak regularity lemma. We present a graph neural network architecture operating on the IBG representation of the graph and demonstrating competitive performance on node classification, spatio-temporal graph analysis, and knowledge graph completion, while having memory and computational complexity linear in the number of nodes rather than edges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18273v1</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan Kouchly, Ben Finkelshtein, Michael Bronstein, Ron Levie</dc:creator>
    </item>
    <item>
      <title>Revisiting Algorithmic Audits of TikTok: Poor Reproducibility and Short-term Validity of Findings</title>
      <link>https://arxiv.org/abs/2504.18140</link>
      <description>arXiv:2504.18140v1 Announce Type: cross 
Abstract: Social media platforms are constantly shifting towards algorithmically curated content based on implicit or explicit user feedback. Regulators, as well as researchers, are calling for systematic social media algorithmic audits as this shift leads to enclosing users in filter bubbles and leading them to more problematic content. An important aspect of such audits is the reproducibility and generalisability of their findings, as it allows to draw verifiable conclusions and audit potential changes in algorithms over time. In this work, we study the reproducibility of the existing sockpuppeting audits of TikTok recommender systems, and the generalizability of their findings. In our efforts to reproduce the previous works, we find multiple challenges stemming from social media platform changes and content evolution, but also the research works themselves. These drawbacks limit the audit reproducibility and require an extensive effort altogether with inevitable adjustments to the auditing methodology. Our experiments also reveal that these one-shot audit findings often hold only in the short term, implying that the reproducibility and generalizability of the audits heavily depend on the methodological choices and the state of algorithms and content on the platform. This highlights the importance of reproducible audits that allow us to determine how the situation changes in time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18140v1</guid>
      <category>cs.IR</category>
      <category>cs.SI</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3726302.3730293</arxiv:DOI>
      <dc:creator>Matej Mosnar, Adam Skurla, Branislav Pecher, Matus Tibensky, Jan Jakubcik, Adrian Bindas, Peter Sakalik, Ivan Srba</dc:creator>
    </item>
    <item>
      <title>Information Freshness in Dynamic Gossip Networks</title>
      <link>https://arxiv.org/abs/2504.18504</link>
      <description>arXiv:2504.18504v1 Announce Type: cross 
Abstract: We consider a source that shares updates with a network of $n$ gossiping nodes. The network's topology switches between two arbitrary topologies, with switching governed by a two-state continuous time Markov chain (CTMC) process. Information freshness is well-understood for static networks. This work evaluates the impact of time-varying connections on information freshness. In order to quantify the freshness of information, we use the version age of information metric. If the two networks have static long-term average version ages of $f_1(n)$ and $f_2(n)$ with $f_1(n) \ll f_2(n)$, then the version age of the varying-topologies network is related to $f_1(n)$, $f_2(n)$, and the transition rates in the CTMC. If the transition rates in the CTMC are faster than $f_1(n)$, the average version age of the varying-topologies network is $f_1(n)$. Further, we observe that the behavior of a vanishingly small fraction of nodes can severely impact the long-term average version age of a network in a negative way. This motivates the definition of a typical set of nodes in the network. We evaluate the impact of fast and slow CTMC transition rates on the typical set of nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18504v1</guid>
      <category>cs.IT</category>
      <category>cs.NI</category>
      <category>cs.SI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arunabh Srivastava, Thomas Jacob Maranzatto, Sennur Ulukus</dc:creator>
    </item>
    <item>
      <title>Revealing The Secret Power: How Algorithms Can Influence Content Visibility on Social Media</title>
      <link>https://arxiv.org/abs/2410.17390</link>
      <description>arXiv:2410.17390v2 Announce Type: replace 
Abstract: In recent years, the opaque design and the limited public understanding of social networks' recommendation algorithms have raised concerns about potential manipulation of information exposure. While reducing content visibility, aka shadow banning, may help limit harmful content, it can also be used to suppress dissenting voices. This prompts the need for greater transparency and a better understanding of this practice.
  In this paper, we investigate the presence of visibility alterations through a large-scale quantitative analysis of two Twitter/X datasets comprising over 40 million tweets from more than 9 million users, focused on discussions surrounding the Ukraine-Russia conflict and the 2024 US Presidential Elections. We use view counts to detect patterns of reduced or inflated visibility and examine how these correlate with user opinions, social roles, and narrative framings. Our analysis shows that the algorithm systematically penalizes tweets containing links to external resources, reducing their visibility by up to a factor of eight, regardless of the ideological stance or source reliability. Rather, content visibility may be penalized or favored depending on the specific accounts producing it, as observed when comparing tweets from the Kyiv Independent and RT.com or tweets by Donald Trump and Kamala Harris. Overall, our work highlights the importance of transparency in content moderation and recommendation systems in protecting the integrity of public discourse and ensuring equitable access to online platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17390v2</guid>
      <category>cs.SI</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Galeazzi, Pujan Paudel, Mauro Conti, Emiliano De Cristofaro, Gianluca Stringhini</dc:creator>
    </item>
    <item>
      <title>Forensics and security issues in the Internet of Things</title>
      <link>https://arxiv.org/abs/2309.02707</link>
      <description>arXiv:2309.02707v2 Announce Type: replace-cross 
Abstract: Given the exponential expansion of the internet, the possibilities of security attacks and cybercrimes have increased accordingly. However, poorly implemented security mechanisms in the Internet of Things (IoT) devices make them susceptible to cyberattacks, which can directly affect users. IoT forensics is thus needed to investigate and mitigate such attacks. While many works have examined IoT applications and challenges, only a few have focused on both the forensic and security issues in IoT. Therefore, this paper reviews forensic and security issues associated with IoT in different fields. Prospects and challenges in IoT research and development are also highlighted. As the literature demonstrates, most IoT devices are vulnerable to attacks due to a lack of standardized security measures. Unauthorized users could get access, compromise data, and even benefit from control of critical infrastructure. To fulfill the security-conscious needs of consumers, IoT can be used to develop a smart home system by designing the security-conscious needs of consumers; IoT can be used to create a smart home system by designing an IoT can be used to develop a smart home system by designing a FLIP-based system that is highly scalable and adaptable. A blockchain-based authentication mechanism with a multi-chain structure can provide additional security protection between different trust domains. Deep learning can be utilized to develop a network forensics framework with a high-performing system for detecting and tracking cyberattack incidents. Moreover, researchers should consider limiting the amount of data created and delivered when using big data to develop IoT-based smart systems. The findings of this review will stimulate academics to seek potential solutions for the identified issues, thereby advancing the IoT field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02707v2</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <category>cs.SI</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11276-025-03942-2</arxiv:DOI>
      <arxiv:journal_reference>Wireless Networks, 31, 3431-3466 (2025)</arxiv:journal_reference>
      <dc:creator>Shams Forruque Ahmed, Shanjana Shuravi, Afsana Bhuyian, Shaila Afrin, Aanushka Mehjabin, Sweety Angela Kuldeep, Md. Sakib Bin Alam, Amir H. Gandomi</dc:creator>
    </item>
    <item>
      <title>Symmetry-driven embedding of networks in hyperbolic space</title>
      <link>https://arxiv.org/abs/2406.10711</link>
      <description>arXiv:2406.10711v2 Announce Type: replace-cross 
Abstract: Hyperbolic models are known to produce networks with properties observed empirically in most network datasets, including heavy-tailed degree distribution, high clustering, and hierarchical structures. As a result, several embeddings algorithms have been proposed to invert these models and assign hyperbolic coordinates to network data. Current algorithms for finding these coordinates, however, do not quantify uncertainty in the inferred coordinates. We present BIGUE, a Markov chain Monte Carlo (MCMC) algorithm that samples the posterior distribution of a Bayesian hyperbolic random graph model. We show that the samples are consistent with current algorithms while providing added credible intervals for the coordinates and all network properties. We also show that some networks admit two or more plausible embeddings, a feature that an optimization algorithm can easily overlook.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10711v2</guid>
      <category>stat.CO</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Mon, 28 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon Lizotte, Jean-Gabriel Young, Antoine Allard</dc:creator>
    </item>
  </channel>
</rss>
