<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 16 Jul 2024 04:00:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A posteriori error analysis for a coupled Stokes-poroelastic system with multiple compartments</title>
      <link>https://arxiv.org/abs/2407.09659</link>
      <description>arXiv:2407.09659v1 Announce Type: new 
Abstract: The discretization of fluid-poromechanics systems is typically highly demanding in terms of computational effort. This is particularly true for models of multiphysics flows in the brain, due to the geometrical complexity of the cerebral anatomy - requiring a very fine computational mesh for finite element discretization - and to the high number of variables involved. Indeed, this kind of problems can be modeled by a coupled system encompassing the Stokes equations for the cerebrospinal fluid in the brain ventricles and Multiple-network Poro-Elasticity (MPE) equations describing the brain tissue, the interstitial fluid, and the blood vascular networks at different space scales. The present work aims to rigorously derive a posteriori error estimates for the coupled Stokes-MPE problem, as a first step towards the design of adaptive refinement strategies or reduced order models to decrease the computational demand of the problem. Through numerical experiments, we verify the reliability and optimal efficiency of the proposed a posteriori estimator and identify the role of the different solution variables in its composition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09659v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Fumagalli, Nicola Parolini, Marco Verani</dc:creator>
    </item>
    <item>
      <title>A monotone finite element method for reaction-drift-diffusion equations with discontinuous reaction coefficients</title>
      <link>https://arxiv.org/abs/2407.09660</link>
      <description>arXiv:2407.09660v1 Announce Type: new 
Abstract: We prove an abstract convergence result for a family of dual-mesh based quadrature rules on tensor products of simplical meshes. In the context of the multilinear tensor-product finite element discretization of reaction-drift-diffusion equations, our quadrature rule generalizes the mass-lump rule, retaining its most useful properties; for a nonnegative reaction coefficient, it gives an $O(h^2)$-accurate, nonnegative diagonalization of the reaction operator. The major advantage of our scheme in comparison with the standard mass lumping scheme is that, under mild conditions, it produces an $O(h^2)$ consistency error even when the integrand has a jump discontinuity. The finite-volume-type quadrature rule has been stated in a less general form and applied to systems of reaction-diffusion equations related to particle-based stochastic reaction-diffusion simulations (PBSRD); in this context, the reaction operator is \textit{required} to be an $M$-matrix and a standard model for bimolecular reactions has a discontinuous reaction coefficient. We apply our convergence results to a finite element discretization of scalar drift-diffusion-reaction model problem related to PBSRD systems, and provide new numerical convergence studies confirming the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09660v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Max Heldman</dc:creator>
    </item>
    <item>
      <title>Data Analysis of Decision Support for Sustainable Welfare in The Presence of GDP Threshold Effects: A Case Study of Interactive Data Exploration</title>
      <link>https://arxiv.org/abs/2407.09711</link>
      <description>arXiv:2407.09711v1 Announce Type: new 
Abstract: Energy usage and GDP have been the subject of numerous studies over the past decades. It has been overlooked by previous studies that energy consumption correlates with economic growth in relation to GDP. This study uses threshold regression and Granger causality testing to identify GDP-dependent causality in ten OECD countries over the last 10 years. There is a significant correlation between economic growth and energy consumption. Energy consumption and short-term economic growth are statistically significantly correlated. There is a significant positive effect of energy consumption (EC) on GDP in the short run below the threshold of $10,936 USD since the coefficient is 3.34 and the p-value is 0.0252. There is a -0.0127-correlation coefficient and a 0.0327 p-value associated with GDP Granger-cause EC over the long run. EC and GDP are not causally related for GDP per capita above $10,936 USD. In the long run, GDP Granger causes EC with a coefficient of -0.1638 and a p-value of 0.0675. According to the study, sustainable development requires sustainable use of natural resources, technological investment, foreign direct investment, and gross fixed capital formation. Economic growth can be boosted while adhering to sustainability goals by implementing these recommendations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09711v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fahimeh Asgari, Seyedeh Gol Ara Ghoreishi, Matin Khajavi, Ali Foozoni, Ali Ala, Ahmad Gholizadeh Lonbar</dc:creator>
    </item>
    <item>
      <title>Characterization of the forcing and sub-filter scale terms in the volume-filtering immersed boundary method</title>
      <link>https://arxiv.org/abs/2407.09720</link>
      <description>arXiv:2407.09720v1 Announce Type: new 
Abstract: We present a characterization of the forcing and the sub-filter scale terms produced in the volume-filtering immersed boundary (VF-IB) method by Dave et al, JCP, 2023. The process of volume-filtering produces bodyforces in the form of surface integrals to describe the boundary conditions at the interface. Furthermore, the approach also produces unclosed subfilter scale (SFS) terms. The level of contribution from SFS terms on the numerical solution depends on the filter width. In order to understand these terms better, we take a 2 dimensional, varying coefficient hyperbolic equation shown by Brady &amp; Liverscu, JCP, 2021. This case is chosen for two reasons. First, the case involves 2 distinct regions seperated by an interface, making it an ideal case for the VF-IB method. Second, an existing analytical solution allows us to properly investigate the contribution from SFS term for varying filter sizes. The latter controls how well resolved the interface is. The smaller the filter size, the more resolved the interface will be. A thorough numerical analysis of the method is presented, as well as the effect of the SFS term on the numerical solution. In order to perform a direct comparison, the numerical solution is compared to the filtered analytical solution. Through this, we highlight three important points. First, we present a methodical approach to volume filtering a hyperbolic PDE. Second, we show that the VF-IB method exhibits second order convergence with respect to decreasing filter size (i.e. making the interface sharper). Finally, we show that the SFS term scales with square the filter size. Large filter sizes require modeling the SFS term. However, for sufficiently finer filters, the SFS term can be ignored without any significant reduction in the accuracy of solution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09720v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dave Himanshu, Herrmann Marcus, Brady Peter, M. Houssem Kasbaoui</dc:creator>
    </item>
    <item>
      <title>Implicit learning to determine variable sound speed and the reconstruction operator in photoacoustic tomography</title>
      <link>https://arxiv.org/abs/2407.09749</link>
      <description>arXiv:2407.09749v1 Announce Type: new 
Abstract: Photoacoustic tomography (PAT) is a hybrid medical imaging technique that offer high contrast and a high spatial resolution. One challenging mathematical problem associated with PAT is reconstructing the initial pressure of the wave equation from data collected at the specific surface where the detectors are positioned. The study addresses this problem when PAT is modeled by a wave equation with unknown sound speed $c$, which is a function of spatial variables, and under the assumption that both the Dirichlet and Neumann boundary values on the detector surface are measured. In practical, we introduce a novel implicit learning framework to simultaneously estimate the unknown $c$ and the reconstruction operator using only Dirichlet and Neumann boundary measurement data. The experimental results confirm the success of our proposed framework, demonstrating its ability to accurately estimate variable sound speed and the reconstruction operator in PAT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09749v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gyeongha Hwang, Gihyeon Jeon, Sunghwan Moon, Dabin Park</dc:creator>
    </item>
    <item>
      <title>Optimal Polynomial Smoothers for Parallel AMG</title>
      <link>https://arxiv.org/abs/2407.09848</link>
      <description>arXiv:2407.09848v1 Announce Type: new 
Abstract: In this paper, we propose some Chebyshev polynomials of the 1st-kind which produce optimal bound for a polynomial dependent constant involved in the AMG $V$-cycle error bound and do not require information about the spectrum of matrices. We formulate a variant of a minimax problem already proposed in [J. Lottes, Optimal polynomial smoothers for multigrid V-cycles, Numer. Lin. Alg. with Appl., 30 (2023), p. e2518, https://doi.org/10.1002/nla.2518] and define Chebyshev polynomial of the 1st-kind as acceleration for a weighted-Jacobi smoother; we also describe efficient GPU kernels for the application of the polynomial smoother and compare results with accelerators defined in [J. Lottes, Optimal polynomial smoothers for multigrid V-cycles, Numer. Lin. Alg. with Appl., 30 (2023), p. e2518, https://doi.org/10.1002/nla.2518] on usual benchmarks at very large scales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09848v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pasqua D'Ambra, Fabio Durastante, Salvatore Filippone, Stefano Massei, Stephen Thomas</dc:creator>
    </item>
    <item>
      <title>Some New Convergence Analysis and Applications of POD-Greedy Algorithms</title>
      <link>https://arxiv.org/abs/2407.09933</link>
      <description>arXiv:2407.09933v1 Announce Type: new 
Abstract: In this article, we derive a novel convergence estimate for the weak POD-greedy method with multiple POD modes and variable greedy thresholds in terms of the entropy numbers of the parametric solution manifold. Combining the POD with the empirical interpolation method, we also propose a POD-empirical interpolation method with entropy-based convergence analysis for simultaneously approximating parametrized target functions by separable approximants. Several numerical experiments are presented to demonstrate the effectiveness of the proposed algorithm compared to traditional methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09933v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuwen Li, Yupeng Wang</dc:creator>
    </item>
    <item>
      <title>Distributed computing for physics-based data-driven reduced modeling at scale: Application to a rotating detonation rocket engine</title>
      <link>https://arxiv.org/abs/2407.09994</link>
      <description>arXiv:2407.09994v1 Announce Type: new 
Abstract: High-performance computing (HPC) has revolutionized our ability to perform detailed simulations of complex real-world processes. A prominent contemporary example is from aerospace propulsion, where HPC is used for rotating detonation rocket engine (RDRE) simulations in support of the design of next-generation rocket engines; however, these simulations take millions of core hours even on powerful supercomputers, which makes them impractical for engineering tasks like design exploration and risk assessment. Reduced-order models (ROMs) address this limitation by constructing computationally cheap yet sufficiently accurate approximations that serve as surrogates for the high-fidelity model. This paper contributes a new distributed algorithm that achieves fast and scalable construction of predictive physics-based ROMs trained from sparse datasets of extremely large state dimension. The algorithm learns structured physics-based ROMs that approximate the dynamical systems underlying those datasets. This enables model reduction for problems at a scale and complexity that exceeds the capabilities of existing approaches. We demonstrate our algorithm's scalability using up to $2,048$ cores on the Frontera supercomputer at the Texas Advanced Computing Center. We focus on a real-world three-dimensional RDRE for which one millisecond of simulated physical time requires one million core hours on a supercomputer. Using a training dataset of $2,536$ snapshots each of state dimension $76$ million, our distributed algorithm enables the construction of a predictive data-driven reduced model in just $13$ seconds on $2,048$ cores on Frontera.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09994v1</guid>
      <category>math.NA</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ionut-Gabriel Farcas, Rayomand P. Gundevia, Ramakanth Munipalli, Karen E. Willcox</dc:creator>
    </item>
    <item>
      <title>Numerical Analysis of Penalty-based Ensemble Methods</title>
      <link>https://arxiv.org/abs/2407.10012</link>
      <description>arXiv:2407.10012v1 Announce Type: new 
Abstract: The chaotic nature of fluid flow and the uncertainties in initial conditions limit predictability. Small errors that occur in the initial condition can grow exponentially until they saturate at $\mathcal{O}$(1). Ensemble forecasting averages multiple runs with slightly different initial conditions and other data to produce more accurate results and extend the predictability horizon. However, they can be computationally expensive. We develop a penalty-based ensemble method with a shared coefficient matrix to reduce required memory and computational cost and thereby allow larger ensemble sizes. Penalty methods relax the incompressibility condition to decouple the pressure and velocity, reducing memory requirements. This report gives stability proof and an error estimate of the penalty-based ensemble method, extends it to the Navier-Stokes equations with random variables using Monte Carlo sampling, and validates the method's accuracy and efficiency with three numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10012v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rui Fang</dc:creator>
    </item>
    <item>
      <title>Entropy Increasing Numerical Methods for Prediction of Non-isothermal Electrokinetics in Supercapacitors</title>
      <link>https://arxiv.org/abs/2407.10050</link>
      <description>arXiv:2407.10050v1 Announce Type: new 
Abstract: Accurate characterization of entropy plays a pivotal role in capturing reversible and irreversible heating in supercapacitors during charging/discharging cycles. However, numerical methods that can faithfully capture entropy variation in supercapacitors are still in lack. This work proposes a novel second-order accurate finite-volume scheme for a Poisson--Nernst--Planck--Fourier model developed in our previous work for the description of non-isothermal electrokinetics in supercapacitors. The temporal second-order accuracy with original entropy increase is achieved by modified Crank-Nicolson discretization for the logarithm of both temperature and ionic concentrations. Numerical analysis rigorously proves that the proposed schemes are able to preserve ionic mass conservation and entropy increase for a closed, thermally insulated supercapacitor. Numerical positivity of temperature and ionic concentrations is guaranteed by using logarithmic transformations. Extensive numerical simulations show that the proposed schemes have expected accuracy and robust performance in preserving the desired properties. Temperature oscillation in the charging/discharging processes is successfully predicted, unraveling a quadratic scaling law of temperature rising slope against voltage scanning rate. It is also demonstrated that the variation of ionic entropy contribution, which is the underlying mechanism responsible for reversible heating, is faithfully captured. Our work provides a promising tool in predicting non-isothermal electrokinetics of supercapacitors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10050v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Ding, Xiang Ji, Shenggao Zhou</dc:creator>
    </item>
    <item>
      <title>An asymptotic-preserving and exactly mass-conservative semi-implicit scheme for weakly compressible flows based on compatible finite elements</title>
      <link>https://arxiv.org/abs/2407.10163</link>
      <description>arXiv:2407.10163v1 Announce Type: new 
Abstract: We present a novel asymptotic-preserving semi-implicit finite element method for weakly compressible and incompressible flows based on compatible finite element spaces. The momentum is sought in an $H(\mathrm{div})$-conforming space, ensuring exact pointwise mass conservation at the discrete level. We use an explicit discontinuous Galerkin-based discretization for the convective terms, while treating the pressure and viscous terms implicitly, so that the CFL condition depends only on the fluid velocity. To handle shocks and damp spurious oscillations in the compressible regime, we incorporate an a posteriori limiter that employs artificial viscosity and is based on a discrete maximum principle. By using hybridization, the final algorithm requires solving only symmetric positive definite linear systems. As the Mach number approaches zero and the density remains constant, the method converges to an $H(\mathrm{div})$-based discretization of the incompressible Navier-Stokes equations in the vorticity-velocity-pressure formulation. Several numerical tests validate the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10163v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Enrico Zampa, Michael Dumbser</dc:creator>
    </item>
    <item>
      <title>Sensitivity Analysis and Monte Carlo Based Uncertainty Quantification of the In-process Modal Parameters in Milling</title>
      <link>https://arxiv.org/abs/2407.10202</link>
      <description>arXiv:2407.10202v1 Announce Type: new 
Abstract: The material removal rates during milling operations are affected by the selection of the cutting depth and spindle speed. Poor selection of these parameters can result in chatter or suboptimal material removal rates. Stability Lobe Diagrams (SLDs) are the well-known approach to selecting appropriate chatter-free values for these parameters. The Physics-based stability lobe diagram is usually generated using the structural dynamics and the cutting parameters. However, since the machine dynamics are measured in the static state of the machine (zero speed), the generated SLD is not reliable as the machine behavior may vary during the cutting operations. Besides, measuring structural dynamics parameters under cutting conditions is difficult and needs new equipment. This study proposes a new approach to determining in-process structural dynamics parameters based on a multivariate Newton-Raphson method. The physics-based model is combined with empirical records to extract reliable structural dynamics parameters inversely. Some examples based on synthetic data are presented to illustrate this inverse approach. Also, the performance of the algorithm is evaluated on an empirical data set and its ability to improve the stability boundary is verified. Furthermore, the sensitivity analysis is performed to quantify the exposure of the SLD to the changes in each structural dynamics parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10202v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>M. Hashemitaheri, T. T. Le, T. Khan, H. Cherukuri</dc:creator>
    </item>
    <item>
      <title>Stability of Least Square Approximation under Random Sampling</title>
      <link>https://arxiv.org/abs/2407.10221</link>
      <description>arXiv:2407.10221v1 Announce Type: new 
Abstract: This paper investigates the stability of the least squares approximation $P_m^n$ within the univariate polynomial space of degree $m$, denoted by ${\mathbb P}_m$. The approximation $P_m^n$ entails identifying a polynomial in ${\mathbb P}_m$ that approximates a function $f$ over a domain $X$ based on samples of $f$ taken at $n$ randomly selected points, according to a specified measure $\rho_X$. The primary goal is to determine the sampling rate necessary to ensure the stability of $P_m^n$. Assuming the sampling points are i.i.d. with respect to a Jacobi weight function, we present the sampling rates that guarantee the stability of $P_m^n$. Specifically, for uniform random sampling, we demonstrate that a sampling rate of $n \asymp m^2$ is required to maintain stability. By integrating these findings with those of Cohen-Davenport-Leviatan, we conclude that, for uniform random sampling, the optimal sampling rate for guaranteeing the stability of $P_m^n$ is $n \asymp m^2$, up to a $\log n$ factor. Motivated by this result, we extend the impossibility theorem, previously applicable to equally spaced samples, to the case of random samples, illustrating the balance between accuracy and stability in recovering analytic functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10221v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiqiang Xu, Xinyue Zhang</dc:creator>
    </item>
    <item>
      <title>Nonharmonic multivariate Fourier transforms and matrices: condition numbers and hyperplane geometry</title>
      <link>https://arxiv.org/abs/2407.10313</link>
      <description>arXiv:2407.10313v1 Announce Type: new 
Abstract: Consider an operator that takes the Fourier transform of a discrete measure supported in $\mathcal{X}\subset[-\frac 12,\frac 12)^d$ and restricts it to a compact $\Omega\subset\mathbb{R}^d$. We provide lower bounds for its smallest singular value when $\Omega$ is either a ball or cube of radius $m$, and under different types of geometric assumptions on $\mathcal{X}$. We first show that if distances between points in $\mathcal{X}$ are lower bounded by a $\delta$ that is allowed to be arbitrarily small, then the smallest singular value is at least $Cm^{d/2} (m\delta)^{\lambda-1}$, where $\lambda$ is the maximum number of elements in $\mathcal{X}$ contained within any ball or cube of an explicitly given radius. This estimate communicates a localization effect of the Fourier transform. While it is sharp, the smallest singular value behaves better than expected for many $\mathcal{X}$, including when we dilate a generic set by parameter $\delta$. We next show that if there is a $\eta$ such that, for each $x\in\mathcal{X}$, the set $\mathcal{X}\setminus\{x\}$ locally consists of at most $r$ hyperplanes whose distances to $x$ are at least $\eta$, then the smallest singular value is at least $C m^{d/2} (m\eta)^r$. For dilations of a generic set by $\delta$, the lower bound becomes $C m^{d/2} (m\delta)^{\lceil (\lambda-1)/d\rceil }$. The appearance of a $1/d$ factor in the exponent indicates that compared to worst case scenarios, the condition number of nonharmonic Fourier transforms is better than expected for typical sets and improve with higher dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10313v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weilin Li</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis of the Alternating Anderson-Picard Method for Nonlinear Fixed-point Problems</title>
      <link>https://arxiv.org/abs/2407.10472</link>
      <description>arXiv:2407.10472v1 Announce Type: new 
Abstract: Anderson Acceleration (AA) has been widely used to solve nonlinear fixed-point problems due to its rapid convergence. This work focuses on a variant of AA in which multiple Picard iterations are performed between each AA step, referred to as the Alternating Anderson-Picard (AAP) method. Despite introducing more 'slow' Picard iterations, this method has been shown to be efficient and even more robust in both linear and nonlinear cases. However, there is a lack of theoretical analysis for AAP in the nonlinear case, which this paper aims to address. We show the equivalence between AAP and a multisecant-GMRES method that uses GMRES to solve a multisecant linear system at each iteration. More interestingly, the incorporation of Picard iterations and AA establishes a deep connection between AAP and the Newton-GMRES method. This connection is evident in terms of the multisecant matrix, the approximate Jacobian inverse, search direction, and optimization gain -- an essential factor in the convergence analysis of AA. We show that these terms converge to their corresponding terms in the Newton-GMRES method as the residual approaches zero. Consequently, we build the convergence analysis of AAP. To validate our theoretical findings, numerical examples are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10472v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xue Feng, M. Paul Laiu, Thomas Strohmer</dc:creator>
    </item>
    <item>
      <title>Structure preserving nodal continuous Finite Elements via Global Flux quadrature</title>
      <link>https://arxiv.org/abs/2407.10579</link>
      <description>arXiv:2407.10579v1 Announce Type: new 
Abstract: Numerical methods for hyperbolic PDEs require stabilization. For linear acoustics, divergence-free vector fields should remain stationary, but classical Finite Difference methods add incompatible diffusion that dramatically restricts the set of discrete stationary states of the numerical method. Compatible diffusion should vanish on stationary states, e.g. should be a gradient of the divergence. Some Finite Element methods allow to naturally embed this grad-div structure, e.g. the SUPG method or OSS. We prove here that the particular discretization associated to them still fails to be constraint preserving. We then introduce a new framework on Cartesian grids based on surface (volume in 3D) integrated operators inspired by Global Flux quadrature and related to mimetic approaches. We are able to construct constraint-compatible stabilization operators (e.g. of SUPG-type) and show that the resulting methods are vorticity-preserving. We show that the Global Flux approach is even super-convergent on stationary states, we characterize the kernels of the discrete operators and we provide projections onto them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10579v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wasilij Barsukow, Mario Ricchiuto, Davide Torlo</dc:creator>
    </item>
    <item>
      <title>Spectral Properties of Infinitely Smooth Kernel Matrices in the Single Cluster Limit, with Applications to Multivariate Super-Resolution</title>
      <link>https://arxiv.org/abs/2407.10600</link>
      <description>arXiv:2407.10600v1 Announce Type: new 
Abstract: We study the spectral properties of infinitely smooth multivariate kernel matrices when the nodes form a single cluster. We show that the geometry of the nodes plays an important role in the scaling of the eigenvalues of these kernel matrices. For the multivariate Dirichlet kernel matrix, we establish a criterion for the sampling set ensuring precise scaling of eigenvalues. Additionally, we identify specific sampling sets that satisfy this criterion. Finally, we discuss the implications of these results for the problem of super-resolution, i.e. stable recovery of sparse measures from bandlimited Fourier measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10600v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nuha Diab, Dmitry Batenkov</dc:creator>
    </item>
    <item>
      <title>Exploring incentive strategies and predicting development trends for new energy vehicles</title>
      <link>https://arxiv.org/abs/2407.10611</link>
      <description>arXiv:2407.10611v1 Announce Type: new 
Abstract: To facilitate new energy vehicles (NEVs), we construct a game model between vehicle manufacturers and consumers to explore their interactions. In the model, we propose the Expectation Supply-Demand Game (ESDG), construct the consumer purchasing decision-making process with feedback and analyse the stability of the system under different feedback factors. We processes the data of the model in numerical simulation through Min-Max normalisation and predicts the development of NEVs. The results show that: (1) An evolutionary stabilisation strategy (ESS) emerges in the evolutionary game model with the introduction of feedback. (2) The Min-Max normalisation method is conducive to the accuracy of the model. (3) Excessive advertising and marketing may cause consumer boredom. (4) The establishment of an appropriate battery compensation and replacement insurance is conducive to the development of NEVs. (5) The production and sales ratio of China's NEVs is predicted to reach 37.2\% and 36.9\% respectively in 2024.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10611v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Jin, Yulian Jiang, Xingwen Liu</dc:creator>
    </item>
    <item>
      <title>A recipe based on Lebesgue functions for learning Variably Scaled Kernels via Discontinuous Neural Networks ({\delta}NN-VSKs)</title>
      <link>https://arxiv.org/abs/2407.10651</link>
      <description>arXiv:2407.10651v1 Announce Type: new 
Abstract: The efficacy of interpolating via Variably Scaled Kernels (VSKs) is known to be dependent on the definition of a proper scaling function, but no numerical recipes to construct it are available. Previous works suggest that such a function should mimic the target one, but no theoretical evidence is provided. This paper fills both the gaps: it proves that a scaling function reflecting the target one may lead to enhanced approximation accuracy, and it provides a user-independent tool for learning the scaling function by means of Discontinuous Neural Networks ({\delta}NN), i.e., NNs able to deal with possible discontinuities. Numerical evidence supports our claims, as it shows that the key features of the target function can be clearly recovered in the learned scaling function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10651v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianluca Audone, Francesco Della Santa, Emma Perracchione, Sandra Pieraccini</dc:creator>
    </item>
    <item>
      <title>Inverse Physics-Informed Neural Networks for transport models in porous materials</title>
      <link>https://arxiv.org/abs/2407.10654</link>
      <description>arXiv:2407.10654v1 Announce Type: new 
Abstract: Physics-Informed Neural Networks (PINN) are a machine learning tool that can be used to solve direct and inverse problems related to models described by Partial Differential Equations. This paper proposes an adaptive inverse PINN applied to different transport models, from diffusion to advection-diffusion-reaction problems. Once a suitable PINN is established to solve the forward problem, the transport parameters are added as trainable parameters. We find that, for the inverse problem to converge to the correct solution, the different components of the loss function (data misfit, initial conditions, boundary conditions and residual of the transport equation) need to be weighted adaptively as a function of the training iteration (epoch). Similarly, gradients of trainable parameters are scaled at each epoch accordingly. Several examples are presented for different test cases to support our PINN architecture and its scalability and robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10654v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Berardi, Fabio Difonzo, Matteo Icardi</dc:creator>
    </item>
    <item>
      <title>Ghost-OSD Method on Numerical Max-Plus Algebra</title>
      <link>https://arxiv.org/abs/2407.10682</link>
      <description>arXiv:2407.10682v1 Announce Type: new 
Abstract: In this paper, we introduce a method for reducing the calculation time of matrix exponentiation calculations on numerical max-plus algebra. In particular, we explain Ghost-OSD Method that can quickly calculate the powers of honest matrix. For more information on this abstract, see the PDF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10682v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohei Oshida</dc:creator>
    </item>
    <item>
      <title>A global approximation method for second-kind nonlinear integral equations</title>
      <link>https://arxiv.org/abs/2407.10842</link>
      <description>arXiv:2407.10842v1 Announce Type: new 
Abstract: A global approximation method of Nystr\"om type is explored for the numerical solution of a class of nonlinear integral equations of the second kind. The cases of smooth and weakly singular kernels are both considered. In the first occurrence, the method uses a Gauss-Legendre rule whereas in the second one resorts to a product rule based on Legendre nodes. Stability and convergence are proved in functional spaces equipped with the uniform norm and several numerical tests are given to show the good performance of the proposed method. An application to the interior Neumann problem for the Laplace equation with nonlinear boundary conditions is also considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10842v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luisa Fermo, Anna Lucia Laguardia, Concetta Laurita, Maria Grazia Russo</dc:creator>
    </item>
    <item>
      <title>Convergence analysis of the parareal algorithms for stochastic Maxwell equations driven by additive noise</title>
      <link>https://arxiv.org/abs/2407.10907</link>
      <description>arXiv:2407.10907v1 Announce Type: new 
Abstract: In this paper, we investigate the strong convergence analysis of parareal algorithms for stochastic Maxwell equations with the damping term driven by additive noise. The proposed parareal algorithms proceed as two-level temporal parallelizable integrators with the stochastic exponential integrator as the coarse propagator and both the exact solution integrator and the stochastic exponential integrator as the fine propagator. It is proved that the convergence order of the proposed algorithms linearly depends on the iteration number. Numerical experiments are performed to illustrate the convergence order of the algorithms for different choices of the iteration number, the damping coefficient and the scale of noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10907v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liying Zhang, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>$\textit{A priori}$ and $\textit{a posteriori}$ error identities for the scalar Signorini problem</title>
      <link>https://arxiv.org/abs/2407.10912</link>
      <description>arXiv:2407.10912v1 Announce Type: new 
Abstract: In this paper, on the basis of a (Fenchel) duality theory on the continuous level, we derive an $\textit{a posteriori}$ error identity for arbitrary conforming approximations of the primal formulation and the dual formulation of the scalar Signorini problem. In addition, on the basis of a (Fenchel) duality theory on the discrete level, we derive an $\textit{a priori}$ error identity that applies to the approximation of the primal formulation using the Crouzeix-Raviart element and to the approximation of the dual formulation using the Raviart-Thomas element, and leads to quasi-optimal error decay rates without imposing additional assumptions on the contact set and in arbitrary space dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10912v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Bartels, Thirupathi Gudi, Alex Kaltenbach</dc:creator>
    </item>
    <item>
      <title>On the Cyclostationary Linear Inverse Models: A Mathematical Insight and Implication</title>
      <link>https://arxiv.org/abs/2407.10931</link>
      <description>arXiv:2407.10931v1 Announce Type: new 
Abstract: Cyclostationary linear inverse models (CS-LIMs), generalized versions of the classical (stationary) LIM, are advanced data-driven techniques for extracting the first-order time-dependent dynamics and random forcing relevant information from complex non-linear stochastic processes. Though CS-LIMs lead to a breakthrough in climate sciences, their mathematical background and properties are worth further exploration. This study focuses on the mathematical perspective of CS-LIMs and introduces two variants: e-CS-LIM and l-CS-LIM. The former refines the original CS-LIM using the interval-wise linear Markov approximation, while the latter serves as an analytic inverse model for the linear periodic stochastic systems. Although relying on approximation, e-CS-LIM converges to l-CS-LIM under specific conditions and shows noise-robust performance. Numerical experiments demonstrate that each CS-LIM reveals the temporal structure of the system. The e-CS-LIM optimizes the original model for better dynamics performance, while l-CS-LIM excels in diffusion estimation due to reduced approximation reliance. Moreover, CS-LIMs are applied to real-world ENSO data, yielding a consistent result aligning with observations and current ENSO understanding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10931v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Justin Lien, Yan-Ning Kuo, Hiroyasu Ando</dc:creator>
    </item>
    <item>
      <title>Chebyshev approximation and composition of functions in matrix product states for quantum-inspired numerical analysis</title>
      <link>https://arxiv.org/abs/2407.09609</link>
      <description>arXiv:2407.09609v1 Announce Type: cross 
Abstract: This work explores the representation of univariate and multivariate functions as matrix product states (MPS), also known as quantized tensor-trains (QTT). It proposes an algorithm that employs iterative Chebyshev expansions and Clenshaw evaluations to represent analytic and highly differentiable functions as MPS Chebyshev interpolants. It demonstrates rapid convergence for highly-differentiable functions, aligning with theoretical predictions, and generalizes efficiently to multidimensional scenarios. The performance of the algorithm is compared with that of tensor cross-interpolation (TCI) and multiscale interpolative constructions through a comprehensive comparative study. When function evaluation is inexpensive or when the function is not analytical, TCI is generally more efficient for function loading. However, the proposed method shows competitive performance, outperforming TCI in certain multivariate scenarios. Moreover, it shows advantageous scaling rates and generalizes to a wider range of tasks by providing a framework for function composition in MPS, which is useful for non-linear problems and many-body statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09609v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Jos\'e Rodr\'iguez-Aldavero, Paula Garc\'ia-Molina, Luca Tagliacozzo, Juan Jos\'e Garc\'ia-Ripoll</dc:creator>
    </item>
    <item>
      <title>Acceleration of Tensor-Product Operations with Tensor Cores</title>
      <link>https://arxiv.org/abs/2407.09621</link>
      <description>arXiv:2407.09621v1 Announce Type: cross 
Abstract: In this paper, we explore the acceleration of tensor product operations in finite element methods, leveraging the computational power of the NVIDIA A100 GPU Tensor Cores. We provide an accessible overview of the necessary mathematical background and discuss our implementation strategies. Our study focuses on two common programming approaches for NVIDIA Tensor Cores: the C++ Warp Matrix Functions in nvcuda::wmma and the inline Parallel Thread Execution (PTX) instructions mma.sync.aligned. A significant focus is placed on the adoption of the versatile inline PTX instructions combined with a conflict-free shared memory access pattern, a key to unlocking superior performance. When benchmarked against traditional CUDA Cores, our approach yields a remarkable 2.3-fold increase in double precision performance, achieving 8 TFLOPS/s-45% of the theoretical maximum. Furthermore, in half-precision computations, numerical experiments demonstrate a fourfold enhancement in solving the Poisson equation using the flexible GMRES (FGMRES) method, preconditioned by a multigrid method in 3D. This is achieved while maintaining the same discretization error as observed in double precision computations. These results highlight the considerable benefits of using Tensor Cores for finite element operators with tensor products, achieving an optimal balance between computational speed and precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09621v1</guid>
      <category>cs.MS</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cu Cui</dc:creator>
    </item>
    <item>
      <title>A proximal-gradient inertial algorithm with Tikhonov regularization: strong convergence to the minimal norm solution</title>
      <link>https://arxiv.org/abs/2407.10350</link>
      <description>arXiv:2407.10350v1 Announce Type: cross 
Abstract: We investigate the strong convergence properties of a proximal-gradient inertial algorithm with two Tikhonov regularization terms in connection to the minimization problem of the sum of a convex lower semi-continuous function $f$ and a smooth convex function $g$. For the appropriate setting of the parameters we provide strong convergence of the generated sequence $(x_k)$ to the minimum norm minimizer of our objective function $f+g$. Further, we obtain fast convergence to zero of the objective function values in a generated sequence but also for the discrete velocity and the sub-gradient of the objective function. We also show that for another settings of the parameters the optimal rate of order $\mathcal{O}(k^{-2})$ for the potential energy $(f+g)(x_k)-\min(f+g)$ can be obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10350v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Szil\'ard Csaba L\'aszl\'o</dc:creator>
    </item>
    <item>
      <title>A Study on Lampreys Population Based on Sex-Ratio-Related Growth-Balance Model</title>
      <link>https://arxiv.org/abs/2407.10411</link>
      <description>arXiv:2407.10411v1 Announce Type: cross 
Abstract: Lampreys are one of the oldest species in the world, living longer than dinosaurs, which is related to the ability to change the sex ratio during their lifespan. In this paper, to understand how sex ratio and food quantity affect the population growth rate of lampreys, the researchers draw inspiration from the logistics model and established a model called EcoSexChange(ESC), which results in a population initially increasing and then stabilizing, a reasonable outcome that may apply to other organisms with significant differences in consumption between sexes. Subsequently, this paper develops the Sex Ratio Adaptation Eco Impact (SRAEI) model based on the ESC model using the ABM algorithm to simulate how the population of lampreys, whose lives are divided into seven stages, grows and stabilizes. Then introduces a sudden disaster factor in the middle of the simulation, while also comparing lampreys that cannot adjust their sex ratio. The results of this paper are of great reference significance for people to analyze the population changes of lampreys in different living environments, and they are also easy to apply to other species with large differences between males and females.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10411v1</guid>
      <category>q-bio.PE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.23977/tracam.2024.040107</arxiv:DOI>
      <arxiv:journal_reference>Transactions on Computational and Applied Mathematics. 2024 May 6;4(1):48-55</arxiv:journal_reference>
      <dc:creator>Zuhua Ji, Jiarui Chen, Zihang Wang</dc:creator>
    </item>
    <item>
      <title>Well-Posedness and Finite Element Approximation for the Landau-Lifshitz-Gilbert Equation with Spin-Torques</title>
      <link>https://arxiv.org/abs/2407.10429</link>
      <description>arXiv:2407.10429v1 Announce Type: cross 
Abstract: Spin currents act on ferromagnets by exerting a torque on the magnetisation. This torque is modelled by appending additional terms to the Landau-Lifshitz-Gilbert equation motivating the study of the non-homogeneous Landau-Lifshitz-Gilbert equation. We first prove the existence and uniqueness of high regularity local solutions to this equation using the Faedo-Galerkin method. Then we construct a numerical method for the problem and prove that it converges to a global weak solution of the PDE. Numerical simulations of the problem are also included.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10429v1</guid>
      <category>math.AP</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noah Vinod, Thanh Tran</dc:creator>
    </item>
    <item>
      <title>Splitting techniques for approximating the exponential of commutators</title>
      <link>https://arxiv.org/abs/2407.10533</link>
      <description>arXiv:2407.10533v1 Announce Type: cross 
Abstract: We construct product formulas of orders 3 to 6 approximating the exponential of a commutator of two arbitrary operators in terms of the exponentials of the operators involved. The new schemes require a reduced number of exponentials and thus provide more efficient approximations than other previously published alternatives, whereas they can be still used as a starting methods of recursive procedures to increase the order of approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10533v1</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>F. Casas, A. Escorihuela-Tom\`as</dc:creator>
    </item>
    <item>
      <title>LIP-CAR: contrast agent reduction by a deep learned inverse problem</title>
      <link>https://arxiv.org/abs/2407.10559</link>
      <description>arXiv:2407.10559v1 Announce Type: cross 
Abstract: The adoption of contrast agents in medical imaging protocols is crucial for accurate and timely diagnosis. While highly effective and characterized by an excellent safety profile, the use of contrast agents has its limitation, including rare risk of allergic reactions, potential environmental impact and economic burdens on patients and healthcare systems. In this work, we address the contrast agent reduction (CAR) problem, which involves reducing the administered dosage of contrast agent while preserving the visual enhancement. The current literature on the CAR task is based on deep learning techniques within a fully image processing framework. These techniques digitally simulate high-dose images from images acquired with a low dose of contrast agent. We investigate the feasibility of a ``learned inverse problem'' (LIP) approach, as opposed to the end-to-end paradigm in the state-of-the-art literature.
  Specifically, we learn the image-to-image operator that maps high-dose images to their corresponding low-dose counterparts, and we frame the CAR task as an inverse problem. We then solve this problem through a regularized optimization reformulation. Regularization methods are well-established mathematical techniques that offer robustness and explainability. Our approach combines these rigorous techniques with cutting-edge deep learning tools. Numerical experiments performed on pre-clinical medical images confirm the effectiveness of this strategy, showing improved stability and accuracy in the simulated high-dose images.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10559v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>eess.IV</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Davide Bianchi, Sonia Colombo Serra, Davide Evangelista, Pengpeng Luo, Elena Morotti, Giovanni Valbusa</dc:creator>
    </item>
    <item>
      <title>Data-Guided Physics-Informed Neural Networks for Solving Inverse Problems in Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2407.10836</link>
      <description>arXiv:2407.10836v1 Announce Type: cross 
Abstract: Physics-informed neural networks (PINNs) represent a significant advancement in scientific machine learning by integrating fundamental physical laws into their architecture through loss functions. PINNs have been successfully applied to solve various forward and inverse problems in partial differential equations (PDEs). However, a notable challenge can emerge during the early training stages when solving inverse problems. Specifically, data losses remain high while PDE residual losses are minimized rapidly, thereby exacerbating the imbalance between loss terms and impeding the overall efficiency of PINNs. To address this challenge, this study proposes a novel framework termed data-guided physics-informed neural networks (DG-PINNs). The DG-PINNs framework is structured into two distinct phases: a pre-training phase and a fine-tuning phase. In the pre-training phase, a loss function with only the data loss is minimized in a neural network. In the fine-tuning phase, a composite loss function, which consists of the data loss, PDE residual loss, and, if available, initial and boundary condition losses, is minimized in the same neural network. Notably, the pre-training phase ensures that the data loss is already at a low value before the fine-tuning phase commences. This approach enables the fine-tuning phase to converge to a minimal composite loss function with fewer iterations compared to existing PINNs. To validate the effectiveness, noise-robustness, and efficiency of DG-PINNs, extensive numerical investigations are conducted on inverse problems related to several classical PDEs, including the heat equation, wave equation, Euler--Bernoulli beam equation, and Navier--Stokes equation. The numerical results demonstrate that DG-PINNs can accurately solve these inverse problems and exhibit robustness against noise in training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10836v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei Zhou, Y. F. Xu</dc:creator>
    </item>
    <item>
      <title>Coupling Fluid Plasma and Kinetic Neutral Models using Correlated Monte Carlo Methods</title>
      <link>https://arxiv.org/abs/2407.10936</link>
      <description>arXiv:2407.10936v1 Announce Type: cross 
Abstract: While boundary plasmas in present day tokamaks generally fall in a fluid regime, neutral species near the boundary often require kinetic models due to long mean-free-paths compared to characteristic spatial scales in the region. Monte-Carlo (MC) methods provide a complete, high-fidelity approach to solving kinetic models, and must be coupled to fluid plasma models to simulate the full plasma-neutrals system. The statistical nature of MC methods, however, prevents convergence of coupled fluid-kinetic simulations to an exact self-consistent steady-state. Moreover, this forces the use of explicit methods that can suffer from numerical errors and require huge computational resources.
  Correlated Monte-Carlo (CMC) methods are expected to alleviate these issues, but have historically enjoyed only mixed success. Here, a fully implicit method for coupled plasma-neutral systems is demonstrated in 1D using the UEDGE plasma code and a homemade CMC code. In particular, it is shown that ensuring the CMC method is a differentiable function of the background plasma is sufficient to employ a Jacobian-Free Newton-Krylov solver for implicit time steps. The convergence of the implicit coupling method is explored and compared with explicit coupling and uncorrelated methods. It is shown that ensuring differentiability by controlling random seeds in the MC is sufficient to achieve convergence, and that the use of implicit time-stepping methods has the potential for improved stability and runtimes over explicit coupling methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10936v1</guid>
      <category>physics.plasm-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory J. Parker, Maxim V. Umansky, Benjamin D. Dudson</dc:creator>
    </item>
    <item>
      <title>Pathwise Uniform Convergence of Time Discretisation Schemes for SPDEs</title>
      <link>https://arxiv.org/abs/2303.00411</link>
      <description>arXiv:2303.00411v4 Announce Type: replace 
Abstract: In this paper we prove convergence rates for time discretisation schemes for semi-linear stochastic evolution equations with additive or multiplicative Gaussian noise, where the leading operator $A$ is the generator of a strongly continuous semigroup $S$ on a Hilbert space $X$, and the focus is on non-parabolic problems. The main results are optimal bounds for the uniform strong error $$\mathrm{E}_{k}^{\infty} := \Big(\mathbb{E} \sup_{j\in \{0, \ldots, N_k\}} \|U(t_j) - U^j\|^p\Big)^{1/p},$$ where $p \in [2,\infty)$, $U$ is the mild solution, $U^j$ is obtained from a time discretisation scheme, $k$ is the step size, and $N_k = T/k$. The usual schemes such as the exponential Euler, the implicit Euler, and the Crank-Nicolson method, etc. are included as special cases. Under conditions on the nonlinearity and the noise, we show
  - $\mathrm{E}_{k}^{\infty}\lesssim k \log(T/k)$ (linear equation, additive noise, general $S$);
  - $\mathrm{E}_{k}^{\infty}\lesssim \sqrt{k} \log(T/k)$ (nonlinear equation, multiplicative noise, contractive $S$);
  - $\mathrm{E}_{k}^{\infty}\lesssim k \log(T/k)$ (nonlinear wave equation, multiplicative noise) for a large class of time discretisation schemes. The logarithmic factor can be removed if the exponential Euler method is used with a (quasi)-contractive $S$. The obtained bounds coincide with the optimal bounds for SDEs. Most of the existing literature is concerned with bounds for the simpler pointwise strong error $$\mathrm{E}_k:=\bigg(\sup_{j\in \{0,\ldots,N_k\}}\mathbb{E} \|U(t_j) - U^{j}\|^p\bigg)^{1/p}.$$ Applications to Maxwell equations, Schr\"odinger equations, and wave equations are included. For these equations, our results improve and reprove several existing results with a unified method and provide the first results known for the implicit Euler and the Crank-Nicolson method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.00411v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katharina Klioba, Mark Veraar</dc:creator>
    </item>
    <item>
      <title>Construction of the Kolmogorov-Arnold representation using the Newton-Kaczmarz method</title>
      <link>https://arxiv.org/abs/2305.08194</link>
      <description>arXiv:2305.08194v3 Announce Type: replace 
Abstract: It is known that any continuous multivariate function can be represented exactly by a composition functions of a single variable - the so-called Kolmogorov-Arnold representation. It can be a convenient tool for tasks where it is required to obtain a predictive model that maps some vector input of a black box system into a scalar output. In this case, the representation may not be exact, and it is more correct to refer to such structure as the Kolmogorov-Arnold model (or, as more recently popularised, 'network'). Construction of such model based on the recorded input-output data is a challenging task. In the present paper, it is suggested to decompose the underlying functions of the representation into continuous basis functions and parameters. It is then proposed to find the parameters using the Newton-Kaczmarz method for solving systems of non-linear equations. The algorithm is then modified to support the parallelisation. The paper demonstrates that such approach is also an excellent tool for data-driven solution of partial differential equations. Numerical examples show that for the considered model, the Newton-Kaczmarz method for parameter estimation is efficient and more robust with respect to the section of the initial guess than the straightforward application of the Gauss-Newton method. Furthermore, numerical experiments show that the proposed approach performs faster than neural network training to the same accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.08194v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Poluektov, Andrew Polar</dc:creator>
    </item>
    <item>
      <title>Preconditioned NonSymmetric/Symmetric Discontinuous Galerkin Method for Elliptic Problem with Reconstructed Discontinuous Approximation</title>
      <link>https://arxiv.org/abs/2306.15420</link>
      <description>arXiv:2306.15420v2 Announce Type: replace 
Abstract: In this paper, we propose and analyze an efficient preconditioning method for the elliptic problem based on the reconstructed discontinuous approximation method. We reconstruct a high-order piecewise polynomial space that arbitrary order can be achieved with one degree of freedom per element. This space can be directly used with the symmetric/nonsymmetric interior penalty discontinuous Galerkin method. Compared with the standard DG method, we can enjoy the advantage on the efficiency of the approximation. Besides, we establish an norm equivalence result between the reconstructed high-order space and the piecewise constant space. This property further allows us to construct an optimal preconditioner from the piecewise constant space. The upper bound of the condition number to the preconditioned symmetric/nonsymmetric system is shown to be independent of the mesh size. Numerical experiments are provided to demonstrate the validity of the theory and the efficiency of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.15420v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruo Li, Qicheng Liu, Fanyi Yang</dc:creator>
    </item>
    <item>
      <title>Energy stable and maximum bound principle preserving schemes for the Q-tensor flow of liquid crystals</title>
      <link>https://arxiv.org/abs/2309.02657</link>
      <description>arXiv:2309.02657v2 Announce Type: replace 
Abstract: In this paper, we propose two efficient fully-discrete schemes for Q-tensor flow of liquid crystals by using the first- and second-order stabilized exponential scalar auxiliary variable (sESAV) approach in time and the finite difference method for spatial discretization. The modified discrete energy dissipation laws are unconditionally satisfied for both two constructed schemes. A particular feature is that, for two-dimensional (2D) and a kind of three-dimensional (3D) Q-tensor flows, the unconditional maximum-bound-principle (MBP) preservation of the constructed first-order scheme is successfully established, and the proposed second-order scheme preserves the discrete MBP property with a mild restriction on the time-step sizes. Furthermore, we rigorously derive the corresponding error estimates for the fully-discrete second-order schemes by using the built-in stability results. Finally, various numerical examples validating the theoretical results, such as the orientation of liquid crystal in 2D and 3D, are presented for the constructed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.02657v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dianming Hou, Xiaoli Li, Zhonghua Qiao, Nan Zheng</dc:creator>
    </item>
    <item>
      <title>A review of troubled cell indicators for discontinuous Galerkin method</title>
      <link>https://arxiv.org/abs/2309.11973</link>
      <description>arXiv:2309.11973v2 Announce Type: replace 
Abstract: In this paper, eight different troubled cell indicators (shock detectors) are reviewed for the solution of nonlinear hyperbolic conservation laws using discontinuous Galerkin (DG) method and a WENO limiter on both structured and unstructured meshes. Extensive simulations using one-dimensional and two-dimensional problems (2D Riemann problem and the double Mach reflection) for various orders on the hyperbolic system of Euler equations are used to compare these troubled cell indicators. They are evaluated based on the percentage of cells flagged as troubled cells for various orders and various grid sizes. CPU time taken to test a single cell for discontinuity is also compared. For one-dimensional problems, the performance of Fu and Shu indicator and the modified KXRCF indicator is better than other indicators. For two-dimensional problems, the performance of the artificial neural network (ANN) indicator of Ray and Hesthaven is quite good and the Fu and Shu and the modified KXRCF indicators are also good. These three indicators are suitable candidates for applications of DGM using WENO limiters though it should be noted that the ANN indicator is quite expensive and requires a lot of training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.11973v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S R Siva Prasad Kochi, M Ramakrishna</dc:creator>
    </item>
    <item>
      <title>A Symmetric Multigrid-Preconditioned Krylov Subspace Solver for Stokes Equations</title>
      <link>https://arxiv.org/abs/2312.10615</link>
      <description>arXiv:2312.10615v3 Announce Type: replace 
Abstract: Numerical solution of discrete PDEs corresponding to saddle point problems is highly relevant to physical systems such as Stokes flow. However, scaling up numerical solvers for such systems is often met with challenges in efficiency and convergence. Multigrid is an approach with excellent applicability to elliptic problems such as the Stokes equations, and can be a solution to such challenges of scalability and efficiency. The degree of success of such methods, however, is highly contingent on the design of key components of a multigrid scheme, including the hierarchy of discretizations, and the relaxation scheme used. Additionally, in many practical cases, it may be more effective to use a multigrid scheme as a preconditioner to an iterative Krylov subspace solver, as opposed to striving for maximum efficacy of the relaxation scheme in all foreseeable settings. In this paper, we propose an efficient symmetric multigrid preconditioner for the Stokes Equations on a staggered finite-difference discretization. Our contribution is focused on crafting a preconditioner that (a) is symmetric indefinite, matching the property of the Stokes system itself, (b) is appropriate for preconditioning the SQMR iterative scheme, and (c) has the requisite symmetry properties to be used in this context. In addition, our design is efficient in terms of computational cost and facilitates scaling to large domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.10615v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yutian Tao, Eftychios Sifakis</dc:creator>
    </item>
    <item>
      <title>Unique Ergodicity of Implicit Methods for Monotone SDEs and SPDEs driven by Nondegenerate Multiplicative Noise</title>
      <link>https://arxiv.org/abs/2401.01112</link>
      <description>arXiv:2401.01112v3 Announce Type: replace 
Abstract: We first establish the unique ergodicity of the Markov chain generated by the stochastic theta method (STM) with $\theta \in [1/2, 1]$ for monotone SODEs, without growth restriction on the coefficients, driven by nondegenerate multiplicative noise. The main ingredient of the arguments lies in constructing new Lyapunov functions involving the coefficients, the stepsize, and $\theta$, and the irreducibility and the strong Feller property for the STM. We then generalize the arguments to the temporal drift-implicit Euler (DIE) method and its Galerkin-based full discretizations for a class of monotone SPDEs driven by infinite-dimensional nondegenerate multiplicative trace-class noise. Applying these results to the stochastic Allen--Cahn equation indicates that its DIE scheme is uniquely ergodic for any interface thickness, which gives an affirmative answer to a question proposed in (J. Cui, J. Hong, and L. Sun, Stochastic Process. Appl. (2021): 55--93). Numerical experiments verify our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01112v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhihui Liu, Zhizhou Liu</dc:creator>
    </item>
    <item>
      <title>Cubic equations with 2 Roots in the interval $[-1, 1]$</title>
      <link>https://arxiv.org/abs/2407.01827</link>
      <description>arXiv:2407.01827v2 Announce Type: replace 
Abstract: The conditions for cubic equations, to have 3 real roots and 2 of the roots lie in the closed interval $[-1, 1]$ are given. These conditions are visualized. This question arises in physics in e.g. the theory of tops.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01827v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Helmut Ruhland</dc:creator>
    </item>
    <item>
      <title>Consistency and stability of boundary conditions for a two-velocities lattice Boltzmann scheme</title>
      <link>https://arxiv.org/abs/2407.02009</link>
      <description>arXiv:2407.02009v2 Announce Type: replace 
Abstract: We theoretically explore boundary conditions for lattice Boltzmann methods, focusing on a toy two-velocities scheme. By mapping lattice Boltzmann schemes to Finite Difference schemes, we facilitate rigorous consistency and stability analyses. We develop kinetic boundary conditions for inflows and outflows, highlighting the trade-off between accuracy and stability, which we successfully overcome. Consistency analysis relies on modified equations, whereas stability is assessed using GKS (Gustafsson, Kreiss, and Sundstr{\"o}m) theory and -- when this approach fails on coarse meshes -- spectral and pseudo-spectral analyses of the scheme's matrix that explain effects germane to low resolutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02009v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Bellotti (IRMA)</dc:creator>
    </item>
    <item>
      <title>Conditional gradients for total variation regularization with PDE constraints: a graph cuts approach</title>
      <link>https://arxiv.org/abs/2310.19777</link>
      <description>arXiv:2310.19777v2 Announce Type: replace-cross 
Abstract: Total variation regularization has proven to be a valuable tool in the context of optimal control of differential equations. This is particularly attributed to the observation that TV-penalties often favor piecewise constant minimizers with well-behaved jumpsets. On the downside, their intricate properties significantly complicate every aspect of their analysis, from the derivation of first-order optimality conditions to their discrete approximation and the choice of a suitable solution algorithm. In this paper, we investigate a general class of minimization problems with TV-regularization, comprising both continuous and discretized control spaces, from a convex geometry perspective. This leads to a variety of novel theoretical insights on minimization problems with total variation regularization as well as tools for their practical realization. First, by studying the extremal points of the respective total variation unit balls, we enable their efficient solution by geometry exploiting algorithms, e.g. fully-corrective generalized conditional gradient methods. We give a detailed account on the practical realization of such a method for piecewise constant finite element approximations of the control on triangulations of the spatial domain. Second, in the same setting and for suitable sequences of uniformly refined meshes, it is shown that minimizers to discretized PDE-constrained optimal control problems approximate solutions to a continuous limit problem involving an anisotropic total variation reflecting the fine-scale geometry of the mesh.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.19777v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giacomo Cristinelli, Jos\'e A. Iglesias, Daniel Walter</dc:creator>
    </item>
    <item>
      <title>Low-rank optimization on Tucker tensor varieties</title>
      <link>https://arxiv.org/abs/2311.18324</link>
      <description>arXiv:2311.18324v2 Announce Type: replace-cross 
Abstract: In the realm of tensor optimization, the low-rank Tucker decomposition is crucial for reducing the number of parameters and for saving storage. We explore the geometry of Tucker tensor varieties -- the set of tensors with bounded Tucker rank -- which is notably more intricate than the well-explored matrix varieties. We give an explicit parametrization of the tangent cone of Tucker tensor varieties and leverage its geometry to develop provable gradient-related line-search methods for optimization on Tucker tensor varieties. To the best of our knowledge, this is the first work concerning geometry and optimization on Tucker tensor varieties. In practice, low-rank tensor optimization suffers from the difficulty of choosing a reliable rank parameter. To this end, we incorporate the established geometry and propose a Tucker rank-adaptive method that aims to identify an appropriate rank with guaranteed convergence. Numerical experiments on tensor completion reveal that the proposed methods are in favor of recovering performance over other state-of-the-art methods. The rank-adaptive method performs the best across various rank parameter selections and is indeed able to find an appropriate rank.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18324v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Renfeng Peng, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Stable generative modeling using Schr\"odinger bridges</title>
      <link>https://arxiv.org/abs/2401.04372</link>
      <description>arXiv:2401.04372v2 Announce Type: replace-cross 
Abstract: We consider the problem of sampling from an unknown distribution for which only a sufficiently large number of training samples are available. Such settings have recently drawn considerable interest in the context of generative modelling and Bayesian inference. In this paper, we propose a generative model combining Schr\"odinger bridges and Langevin dynamics. Schr\"odinger bridges over an appropriate reversible reference process are used to approximate the conditional transition probability from the available training samples, which is then implemented in a discrete-time reversible Langevin sampler to generate new samples. By setting the kernel bandwidth in the reference process to match the time step size used in the unadjusted Langevin algorithm, our method effectively circumvents any stability issues typically associated with the time-stepping of stiff stochastic differential equations. Moreover, we introduce a novel split-step scheme, ensuring that the generated samples remain within the convex hull of the training samples. Our framework can be naturally extended to generate conditional samples and to Bayesian inference problems. We demonstrate the performance of our proposed scheme through experiments on synthetic datasets with increasing dimensions and on a stochastic subgrid-scale parametrization conditional sampling problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04372v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georg Gottwald, Fengyi Li, Youssef Marzouk, Sebastian Reich</dc:creator>
    </item>
    <item>
      <title>Retractions on closed sets</title>
      <link>https://arxiv.org/abs/2402.08536</link>
      <description>arXiv:2402.08536v2 Announce Type: replace-cross 
Abstract: On a manifold or a closed subset of a Euclidean vector space, a retraction enables to move in the direction of a tangent vector while staying on the set. Retractions are a versatile tool to perform computational tasks such as optimization, interpolation, and numerical integration. This paper studies two known definitions of retraction on a closed subset of a Euclidean vector space, one being weaker than the other. Specifically, it shows that, in the context of constrained optimization, the weaker definition should be preferred as it inherits the main property of the other while being less restrictive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08536v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier</dc:creator>
    </item>
  </channel>
</rss>
