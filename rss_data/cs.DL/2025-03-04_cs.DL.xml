<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 04 Mar 2025 05:00:39 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Can We Find the Code? An Empirical Study of Google Scholar's Code Retrieval</title>
      <link>https://arxiv.org/abs/2503.01031</link>
      <description>arXiv:2503.01031v1 Announce Type: new 
Abstract: Academic codes associated with research papers are valuable resources for scholars. In specialized fields outside computer science, code availability is often limited, making effective code retrieval essential. Google Scholar is a crucial academic search tool. If a code published in the paper is not retrievable via Google Scholar, its accessibility and impact are significantly reduced. This study takes the term "accelerated degradation" combined with "reliability" as an example, and finds that, for papers published by Elsevier, only GitHub links included in abstracts are comprehensively retrieved by Google Scholar. When such links appear within the main body of a paper, even in the "Data Availability" section, they may be ignored and become unsearchable. These findings highlight the importance of strategically placing GitHub links in abstracts to enhance code discoverability on Google Scholar.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.01031v1</guid>
      <category>cs.DL</category>
      <category>cs.IR</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shi-Shun Chen</dc:creator>
    </item>
    <item>
      <title>Robust Evidence for Declining Disruptiveness: Assessing the Role of Zero-Backward-Citation Works</title>
      <link>https://arxiv.org/abs/2503.00184</link>
      <description>arXiv:2503.00184v1 Announce Type: cross 
Abstract: We respond to Holst et al.'s (HATWG) critique that the observed decline in scientific disruptiveness demonstrated in Park et al. (PLF) stems from including works with zero backward citations (0-bcites). Applying their own advocated dataset, metric, and exclusion criteria, we demonstrate statistically and practically significant declines in disruptiveness that equal major benchmark transformations in science. Notably, we show that HATWG's own regression model -- designed specifically to address their concerns about 0-bcite works -- reveals highly significant declines for both papers (p&lt;0.001) and patents (p&lt;0.001), a finding they neither acknowledge nor interpret. Their critique is undermined by methodological deficiencies, including reliance on visual inspection without statistical assessment, and severe data quality issues in their SciSciNet dataset, which contains nearly three times more 0-bcite papers than our original data. HATWG's departure from established scientometric practices -- notably their inclusion of document types and fields known for poor metadata quality -- invalidates their conclusions. Monte Carlo simulations and additional analyses using multiple disruptiveness measures across datasets further validate the robustness of the declining trend. Our findings collectively demonstrate that the observed decline in disruptiveness is not an artifact of 0-bcite works but represents a substantive change in scientific and technological innovation patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00184v1</guid>
      <category>cs.SI</category>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Park, Erin Leahey, Russell J. Funk</dc:creator>
    </item>
    <item>
      <title>The Academic Midas Touch: An Indicator of Academic Excellence</title>
      <link>https://arxiv.org/abs/2309.14013</link>
      <description>arXiv:2309.14013v2 Announce Type: replace 
Abstract: The recognition of academic excellence is fundamental to the scientific and academic endeavor. However, the term "academic excellence" is often interpreted in different ways, typically, using popular scientometrics such as the H-index, i10-index, and citation counts. In this work, we study an under-explored aspect of academic excellence -- researchers' propensity to produce highly cited publications. We formulate this novel perspective using a simple yet effective indicator termed the "Academic Midas Touch" (AMT). We empirically show that this perspective does not fully align with popular scientometrics and favorably compares to them in distinguishing award-winning scientists.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.14013v2</guid>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ariel Rosenfled, Ariel Alexi, Liel Mushiev, Teddy Lazebnik</dc:creator>
    </item>
    <item>
      <title>Evaluating the quality of published medical research with ChatGPT</title>
      <link>https://arxiv.org/abs/2411.01952</link>
      <description>arXiv:2411.01952v2 Announce Type: replace 
Abstract: Estimating the quality of published research is important for evaluations of departments, researchers, and job candidates. Citation-based indicators sometimes support these tasks, but do not work for new articles and have low or moderate accuracy. Previous research has shown that ChatGPT can estimate the quality of research articles, with its scores correlating positively with an expert scores proxy in all fields, and often more strongly than citation-based indicators, except for clinical medicine. ChatGPT scores may therefore replace citation-based indicators for some applications. This article investigates the clinical medicine anomaly with the largest dataset yet and a more detailed analysis. The results showed that ChatGPT 4o-mini scores for articles submitted to the UK's Research Excellence Framework (REF) 2021 Unit of Assessment (UoA) 1 Clinical Medicine correlated positively (r=0.134, n=9872) with departmental mean REF scores, against a theoretical maximum correlation of r=0.226. ChatGPT 4o and 3.5 turbo also gave positive correlations. At the departmental level, mean ChatGPT scores correlated more strongly with departmental mean REF scores (r=0.395, n=31). For the 100 journals with the most articles in UoA 1, their mean ChatGPT score correlated strongly with their REF score (r=0.495) but negatively with their citation rate (r=-0.148). Journal and departmental anomalies in these results point to ChatGPT being ineffective at assessing the quality of research in prestigious medical journals or research directly affecting human health, or both. Nevertheless, the results give evidence of ChatGPT's ability to assess research quality overall for Clinical Medicine, where it might replace citation-based indicators for new research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01952v2</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Mike Thelwall, Xiaorui Jiang, Peter A. Bath</dc:creator>
    </item>
    <item>
      <title>Expertise diversity of teams predicts originality and long-term impact in science and technology</title>
      <link>https://arxiv.org/abs/2210.04422</link>
      <description>arXiv:2210.04422v2 Announce Type: replace-cross 
Abstract: Despite the growing importance of teams in producing innovative and high-impact science and technology, it remains unclear how expertise diversity among team members relates to the originality and impact of the work they produce. Here, we develop a new method to quantify the expertise distance of researchers based on their prior career histories and apply it to 23 million scientific publications and 4 million patents. We find that across science and technology, expertise-diverse teams tend to produce work with greater originality. Teams with more diverse expertise have no significant impact advantage in the short- (2 years) or mid-term (5 years). Instead, they exhibit substantially higher long-term impact (10 years), increasingly attracting larger cross-disciplinary influence. This impact premium of expertise diversity among team members becomes especially pronounced when other dimensions of team diversity are missing, as teams within the same institution or country appear to disproportionately reap the benefits of expertise diversity. While gender-diverse teams have relatively higher impact on average, teams with varied levels of gender diversity all seem to benefit from increased expertise diversity. Given the growing knowledge demands on individual researchers, implementation of incentives for original research, and the tradeoffs between short-term and long-term impacts, these results may have implications for funding, assembling, and retaining teams with originality and long-lasting impacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.04422v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.DL</category>
      <pubDate>Tue, 04 Mar 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongwei Zheng, Weihua Li</dc:creator>
    </item>
  </channel>
</rss>
