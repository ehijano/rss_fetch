<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Jul 2025 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Weaving the Future: Generative AI and the Reimagining of Fashion Design</title>
      <link>https://arxiv.org/abs/2507.17758</link>
      <description>arXiv:2507.17758v1 Announce Type: new 
Abstract: This paper explores the integration of generative AI into the fashion design process. Drawing on insights from the January 2025 seminar ``Tisser le futur,'' it investigates how AI reshapes creative workflows, from ideation to prototyping, while interrogating the ethical, aesthetic, and labor implications. The paper highlights co-creative dynamics between humans and machines, the potential for aesthetic innovation, and the environmental and cultural challenges of algorithmic design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17758v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Tisser le futur : L'IA g{\'e}n{\'e}rative et le design de mode, Sorbonne Universit{\'e}, Jan 2025, Paris, France</arxiv:journal_reference>
      <dc:creator>Pierre-Marie Chauvin (IFM, AHP-PReST), Ang\`ele Merlin (IFM, AHP-PReST), Xavier Fresquet (IFM, AHP-PReST), Hugo Caselles-Dupr\'e (IFM, AHP-PReST), Benjamin Simmenauer (IFM, AHP-PReST), Mathieu de Fayet</dc:creator>
    </item>
    <item>
      <title>How Instructional Sequence and Personalized Support Impact Diagnostic Strategy Learning</title>
      <link>https://arxiv.org/abs/2507.17760</link>
      <description>arXiv:2507.17760v1 Announce Type: new 
Abstract: Supporting students in developing effective diagnostic reasoning is a key challenge in various educational domains. Novices often struggle with cognitive biases such as premature closure and over-reliance on heuristics. Scenario-based learning (SBL) can address these challenges by offering realistic case experiences and iterative practice, but the optimal sequencing of instruction and problem-solving activities remains unclear. This study examines how personalized support can be incorporated into different instructional sequences and whether providing explicit diagnostic strategy instruction before (I-PS) or after problem-solving (PS-I) improves learning and its transfer. We employ a between-groups design in an online SBL environment called PharmaSim, which simulates real-world client interactions for pharmacy technician apprentices. Results indicate that while both instruction types are beneficial, PS-I leads to significantly higher performance in transfer tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17760v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fatma Bet\"ul G\"ure\c{s}, Tanya Nazaretsky, Bahar Radmehr, Martina Rau, Tanja K\"aser</dc:creator>
    </item>
    <item>
      <title>Countering Privacy Nihilism</title>
      <link>https://arxiv.org/abs/2507.18253</link>
      <description>arXiv:2507.18253v1 Announce Type: new 
Abstract: Of growing concern in privacy scholarship is artificial intelligence (AI), as a powerful producer of inferences. Taken to its limits, AI may be presumed capable of inferring "everything from everything," thereby making untenable any normative scheme, including privacy theory and privacy regulation, which rests on protecting privacy based on categories of data - sensitive versus non-sensitive, private versus public. Discarding data categories as a normative anchoring in privacy and data protection as a result of an unconditional acceptance of AI's inferential capacities is what we call privacy nihilism. An ethically reasoned response to AI inferences requires a sober consideration of AI capabilities rather than issuing an epistemic carte blanche. We introduce the notion of conceptual overfitting to expose how privacy nihilism turns a blind eye toward flawed epistemic practices in AI development. Conceptual overfitting refers to the adoption of norms of convenience that simplify the development of AI models by forcing complex constructs to fit data that are conceptually under-representative or even irrelevant. While conceptual overfitting serves as a helpful device to counter normative suggestions grounded in hyperbolic AI capability claims, AI inferences shake any privacy regulation that hinges protections based on restrictions around data categories. We propose moving away from privacy frameworks that focus solely on data type, neglecting all other factors. Theories like contextual integrity evaluate the normative value of privacy across several parameters, including the type of data, the actors involved in sharing it, and the purposes for which the information is used.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18253v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Conceptions of Data Protection and Privacy. Legal and Philosophical Perspective Hart Publishing 2025</arxiv:journal_reference>
      <dc:creator>Severin Engelmann, Helen Nissenbaum</dc:creator>
    </item>
    <item>
      <title>A Concept for Efficient Scalability of Automated Driving Allowing for Technical, Legal, Cultural, and Ethical Differences</title>
      <link>https://arxiv.org/abs/2507.18326</link>
      <description>arXiv:2507.18326v1 Announce Type: new 
Abstract: Efficient scalability of automated driving (AD) is key to reducing costs, enhancing safety, conserving resources, and maximizing impact. However, research focuses on specific vehicles and context, while broad deployment requires scalability across various configurations and environments. Differences in vehicle types, sensors, actuators, but also traffic regulations, legal requirements, cultural dynamics, or even ethical paradigms demand high flexibility of data-driven developed capabilities. In this paper, we address the challenge of scalable adaptation of generic capabilities to desired systems and environments. Our concept follows a two-stage fine-tuning process. In the first stage, fine-tuning to the specific environment takes place through a country-specific reward model that serves as an interface between technological adaptations and socio-political requirements. In the second stage, vehicle-specific transfer learning facilitates system adaptation and governs the validation of design decisions. In sum, our concept offers a data-driven process that integrates both technological and socio-political aspects, enabling effective scalability across technical, legal, cultural, and ethical differences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18326v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lars Ullrich, Michael Buchholz, Jonathan Petit, Klaus Dietmayer, Knut Graichen</dc:creator>
    </item>
    <item>
      <title>What does the public want their local government to hear? A data-driven case study of public comments across the state of Michigan</title>
      <link>https://arxiv.org/abs/2507.18431</link>
      <description>arXiv:2507.18431v1 Announce Type: new 
Abstract: City council meetings are vital sites for civic participation where the public can speak directly to their local government. By addressing city officials and calling on them to take action, public commenters can potentially influence policy decisions spanning a broad range of concerns, from housing, to sustainability, to social justice. Yet studies of these meetings have often been limited by the availability of large-scale, geographically-diverse data. Relying on local governments' increasing use of YouTube and other technologies to archive their public meetings, we propose a framework that characterizes comments along two dimensions: the local concerns where concerns are situated (e.g., housing, election administration), and the societal concerns raised (e.g., functional democracy, anti-racism). Based on a large record of public comments we collect from 15 cities in Michigan, we produce data-driven taxonomies of the local concerns and societal concerns that these comments cover, and employ machine learning methods to scalably apply our taxonomies across the entire dataset. We then demonstrate how our framework allows us to examine the salient local concerns and societal concerns that arise in our data, as well as how these aspects interact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18431v1</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Chang Ge, Justine Zhang, Haofei Xu, Yanna Krupnikov, Jenna Bednar, Sabina Tomkins</dc:creator>
    </item>
    <item>
      <title>Exploring Communication Strategies for Collaborative LLM Agents in Mathematical Problem-Solving</title>
      <link>https://arxiv.org/abs/2507.17753</link>
      <description>arXiv:2507.17753v1 Announce Type: cross 
Abstract: Large Language Model (LLM) agents are increasingly utilized in AI-aided education to support tutoring and learning. Effective communication strategies among LLM agents improve collaborative problem-solving efficiency and facilitate cost-effective adoption in education. However, little research has systematically evaluated the impact of different communication strategies on agents' problem-solving. Our study examines four communication modes, \textit{teacher-student interaction}, \textit{peer-to-peer collaboration}, \textit{reciprocal peer teaching}, and \textit{critical debate}, in a dual-agent, chat-based mathematical problem-solving environment using the OpenAI GPT-4o model. Evaluated on the MATH dataset, our results show that dual-agent setups outperform single agents, with \textit{peer-to-peer collaboration} achieving the highest accuracy. Dialogue acts like statements, acknowledgment, and hints play a key role in collaborative problem-solving. While multi-agent frameworks enhance computational tasks, effective communication strategies are essential for tackling complex problems in AI education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17753v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Liang Zhang, Xiaoming Zhai, Jionghao Lin, Jionghao Lin, Jennifer Kleiman, Diego Zapata-Rivera, Carol Forsyth, Yang Jiang, Xiangen Hu, Arthur C. Graesser</dc:creator>
    </item>
    <item>
      <title>A Custom-Built Ambient Scribe Reduces Cognitive Load and Documentation Burden for Telehealth Clinicians</title>
      <link>https://arxiv.org/abs/2507.17754</link>
      <description>arXiv:2507.17754v1 Announce Type: cross 
Abstract: Clinician burnout has motivated the growing adoption of ambient medical scribes in the clinic. In this work, we introduce a custom-built ambient scribe application integrated into the EHR system at Included Health, a personalized all-in-one healthcare company offering telehealth services. The application uses Whisper for transcription and a modular in-context learning pipeline with GPT-4o to automatically generate SOAP notes and patient instructions. Testing on mock visit data shows that the notes generated by the application exceed the quality of expert-written notes as determined by an LLM-as-a-judge. The application has been widely adopted by the clinical practice, with over 540 clinicians at Included Health using the application at least once. 94% (n = 63) of surveyed clinicians report reduced cognitive load during visits and 97% (n = 66) report less documentation burden when using the application. Additionally, we show that post-processing notes with a fine-tuned BART model improves conciseness. These findings highlight the potential for AI systems to ease administrative burdens and support clinicians in delivering efficient, high-quality care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17754v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Justin Morse, Kurt Gilbert, Kyle Shin, Rick Cooke, Peyton Rose, Jack Sullivan, Angelo Sisante</dc:creator>
    </item>
    <item>
      <title>Between Filters and Feeds: Investigating Douyin and WeChat's Influence on Chinese Adolescent Body Image</title>
      <link>https://arxiv.org/abs/2507.17755</link>
      <description>arXiv:2507.17755v1 Announce Type: cross 
Abstract: In the digital era, social media platforms play a pivotal role in shaping adolescents' body image perceptions. This study examines how Douyin and WeChat, two contrasting Chinese social media platforms, influence body image among Chinese male adolescents. Employing a platformization perspective, we surveyed 395 male adolescents aged 10 to 24 using the Multidimensional Body-Self Relations Questionnaire-Appearance Scales (MBSRQ-AS) to assess self-evaluation and body satisfaction. Our findings reveal that Douyin usage is significantly correlated with appearance evaluation and body area satisfaction, while WeChat usage shows no significant correlation with any body image dimensions. These results suggest that Douyin's algorithm-driven, video-centric environment intensifies exposure to idealized body standards, impacting users at a cognitive level. This study underscores the importance of considering platform-specific characteristics in understanding social media's impact on body image. It contributes to the broader discourse on how technological design and content modalities mediate psychological outcomes, offering insights for addressing body image concerns among male adolescents in China.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.17755v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianfeng Lan, Yingjia Huang</dc:creator>
    </item>
    <item>
      <title>Agentic AI framework for End-to-End Medical Data Inference</title>
      <link>https://arxiv.org/abs/2507.18115</link>
      <description>arXiv:2507.18115v1 Announce Type: cross 
Abstract: Building and deploying machine learning solutions in healthcare remains expensive and labor-intensive due to fragmented preprocessing workflows, model compatibility issues, and stringent data privacy constraints. In this work, we introduce an Agentic AI framework that automates the entire clinical data pipeline, from ingestion to inference, through a system of modular, task-specific agents. These agents handle both structured and unstructured data, enabling automatic feature selection, model selection, and preprocessing recommendation without manual intervention. We evaluate the system on publicly available datasets from geriatrics, palliative care, and colonoscopy imaging. For example, in the case of structured data (anxiety data) and unstructured data (colonoscopy polyps data), the pipeline begins with file-type detection by the Ingestion Identifier Agent, followed by the Data Anonymizer Agent ensuring privacy compliance, where we first identify the data type and then anonymize it. The Feature Extraction Agent identifies features using an embedding-based approach for tabular data, extracting all column names, and a multi-stage MedGemma-based approach for image data, which infers modality and disease name. These features guide the Model-Data Feature Matcher Agent in selecting the best-fit model from a curated repository. The Preprocessing Recommender Agent and Preprocessing Implementor Agent then apply tailored preprocessing based on data type and model requirements. Finally, the ``Model Inference Agent" runs the selected model on the uploaded data and generates interpretable outputs using tools like SHAP, LIME, and DETR attention maps. By automating these high-friction stages of the ML lifecycle, the proposed framework reduces the need for repeated expert intervention, offering a scalable, cost-efficient pathway for operationalizing AI in clinical environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18115v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Soorya Ram Shimgekar, Shayan Vassef, Abhay Goyal, Navin Kumar, Koustuv Saha</dc:creator>
    </item>
    <item>
      <title>Recommender systems, representativeness, and online music: A psychosocial analysis of Italian listeners</title>
      <link>https://arxiv.org/abs/2507.18169</link>
      <description>arXiv:2507.18169v1 Announce Type: cross 
Abstract: Recommender systems shape music listening worldwide due to their widespread adoption in online platforms. Growing concerns about representational harms that these systems may cause are nowadays part of the scientific and public debate, wherein music listener perspectives are oftentimes reported and discussed from a cognitive-behaviorism perspective, but rarely contextualised under a psychosocial and cultural lens. We proceed in this direction, by interviewing a group of Italian music listeners and analysing their narratives through Emotional Textual Analysis. Thanks to this, we identify shared cultural repertoires that reveal people's complex relationship with listening practices: even when familiar with online platforms, listeners may still lack a critical understanding of recommender systems. Moreover, representational issues, particularly gender disparities, seem not yet fully grasped in the context of online music listening. This study underscores the need for interdisciplinary research to address representational harms, and the role of algorithmic awareness and digital literacy in developing trustworthy recommender systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18169v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lorenzo Porcaro, Chiara Monaldi</dc:creator>
    </item>
    <item>
      <title>PALM: PAnoramic Learning Map Integrating Learning Analytics and Curriculum Map for Scalable Insights Across Courses</title>
      <link>https://arxiv.org/abs/2507.18393</link>
      <description>arXiv:2507.18393v1 Announce Type: cross 
Abstract: This study proposes and evaluates the PAnoramic Learning Map (PALM), a learning analytics (LA) dashboard designed to address the scalability challenges of LA by integrating curriculum-level information. Traditional LA research has predominantly focused on individual courses or learners and often lacks a framework that considers the relationships between courses and the long-term trajectory of learning. To bridge this gap, PALM was developed to integrate multilayered educational data into a curriculum map, enabling learners to intuitively understand their learning records and academic progression. We conducted a system evaluation to assess PALM's effectiveness in two key areas: (1) its impact on students' awareness of their learning behaviors, and (2) its comparative performance against existing systems. The results indicate that PALM enhances learners' awareness of study planning and reflection, particularly by improving perceived behavioral control through the visual presentation of individual learning histories and statistical trends, which clarify the links between learning actions and outcomes. Although PALM requires ongoing refinement as a system, it received significantly higher evaluations than existing systems in terms of visual appeal and usability. By serving as an information resource with previously inaccessible insights, PALM enhances self-regulated learning and engagement, representing a significant step beyond conventional LA toward a comprehensive and scalable approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18393v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahiro Ozaki, Li Chen, Shotaro Naganuma, Valdemar \v{S}v\'abensk\'y, Fumiya Okubo, Atsushi Shimada</dc:creator>
    </item>
    <item>
      <title>Digital Twin Technologies in Predictive Maintenance: Enabling Transferability via Sim-to-Real and Real-to-Sim Transfer</title>
      <link>https://arxiv.org/abs/2507.18449</link>
      <description>arXiv:2507.18449v1 Announce Type: cross 
Abstract: The advancement of the Internet of Things (IoT) and Artificial Intelligence has catalyzed the evolution of Digital Twins (DTs) from conceptual ideas to more implementable realities. Yet, transitioning from academia to industry is complex due to the absence of standardized frameworks. This paper builds upon the authors' previously established functional and informational requirements supporting standardized DT development, focusing on a crucial aspect: transferability. While existing DT research primarily centers on asset transfer, the significance of "sim-to-real transfer" and "real-to-sim transfer"--transferring knowledge between simulations and real-world operations--is vital for comprehensive lifecycle management in DTs. A key challenge in this process is calibrating the "reality gap," the discrepancy between simulated predictions and actual outcomes. Our research investigates the impact of integrating a single Reality Gap Analysis (RGA) module into an existing DT framework to effectively manage both sim-to-real and real-to-sim transfers. This integration is facilitated by data pipelines that connect the RGA module with the existing components of the DT framework, including the historical repository and the simulation model. A case study on a pedestrian bridge at Carnegie Mellon University showcases the performance of different levels of integration of our approach with an existing framework. With full implementation of an RGA module and a complete data pipeline, our approach is capable of bidirectional knowledge transfer between simulations and real-world operations without compromising efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18449v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sizhe Ma, Katherine A. Flanigan, Mario Berg\'es</dc:creator>
    </item>
    <item>
      <title>A Walk across Europe: Development of a high-resolution walkability index</title>
      <link>https://arxiv.org/abs/2504.17897</link>
      <description>arXiv:2504.17897v2 Announce Type: replace 
Abstract: Physical inactivity significantly contributes to obesity and other non-communicable diseases, yet efforts to increase population-wide physical activity levels have met with limited success. The built environment plays a pivotal role in encouraging active behaviors like walking. Walkability indices, which aggregate various environmental features, provide a valuable tool for promoting healthy, walkable environments. However, a standardized, high-resolution walkability index for Europe has been lacking. This study addresses that gap by developing a standardized, high-resolution walkability index for the entire European region. Seven core components were selected to define walkability: walkable street length, intersection density, green spaces, slope, public transport access, land use mix, and 15-minute walking isochrones. These were derived from harmonized, high-resolution datasets such as Sentinel-2, NASA's elevation models, OpenStreetMap, and CORINE Land Cover. A 100 m x 100 m hierarchical grid system and advanced geospatial methods, like network buffers and distance decay, were used at scale to efficiently model real-world density and proximity effects. The resulting index was weighted by population and analyzed at different spatial levels using visual mapping, spatial clustering, and correlation analysis. Findings revealed a distinct urban-to-rural gradient, with high walkability scores concentrated in compact urban centers rich in street connectivity and land use diversity. The index highlighted cities like Barcelona, Berlin, Munich, Paris, and Warsaw as walkability leaders. This standardized, high-resolution walkability index serves as a practical tool for researchers, planners, and policymakers aiming to support active living and public health across diverse European contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17897v2</guid>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nishit Patel, Hoang-Ha Nguyen, Jet van de Geest, Alfred Wagtendonk, Mohan JS Raju, Payam Dadvand, Kees de Hoogh, Marta Cirach, Mark Nieuwenhuijsen, Thao Minh Lam, Jeroen Lakerveld</dc:creator>
    </item>
    <item>
      <title>The Impact of Pseudo-Science in Financial Loans Risk Prediction</title>
      <link>https://arxiv.org/abs/2507.16182</link>
      <description>arXiv:2507.16182v2 Announce Type: replace 
Abstract: We study the societal impact of pseudo-scientific assumptions for predicting the behavior of people in a straightforward application of machine learning to risk prediction in financial lending. This use case also exemplifies the impact of survival bias in loan return prediction. We analyze the models in terms of their accuracy and social cost, showing that the socially optimal model may not imply a significant accuracy loss for this downstream task. Our results are verified for commonly used learning methods and datasets. Our findings also show that there is a natural dynamic when training models that suffer survival bias where accuracy slightly deteriorates, and whose recall and precision improves with time. These results act as an illusion, leading the observer to believe that the system is getting better, when in fact the model is suffering from increasingly more unfairness and survival bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.16182v2</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bruno Scarone, Ricardo Baeza-Yates</dc:creator>
    </item>
    <item>
      <title>Quantifying the Uniqueness and Divisiveness of Presidential Discourse</title>
      <link>https://arxiv.org/abs/2401.01405</link>
      <description>arXiv:2401.01405v2 Announce Type: replace-cross 
Abstract: Do American presidents speak discernibly different from each other? If so, in what ways? And are these differences confined to any single medium of communication? To investigate these questions, this paper introduces a novel metric of uniqueness based on large language models, develops a new lexicon for divisive speech, and presents a framework for assessing the distinctive ways in which presidents speak about their political opponents. Applying these tools to a variety of corpora of presidential speeches, we find considerable evidence that Donald Trump's speech patterns diverge from those of all major party nominees for the presidency in recent history. Trump is significantly more distinctive than his fellow Republicans, whose uniqueness values appear closer to those of the Democrats. Contributing to these differences is Trump's employment of divisive and antagonistic language, particularly when targeting his political opponents. These differences hold across a variety of measurement strategies, arise on both the campaign trail and in official presidential addresses, and do not appear to be an artifact of secular changes in presidential communications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.01405v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1093/pnasnexus/pgae431</arxiv:DOI>
      <arxiv:journal_reference>PNAS Nexus, Volume 3, Issue 10, October 2024</arxiv:journal_reference>
      <dc:creator>Karen Zhou, Alexander A. Meitus, Milo Chase, Grace Wang, Anne Mykland, William Howell, Chenhao Tan</dc:creator>
    </item>
    <item>
      <title>A Principled Approach for Data Bias Mitigation</title>
      <link>https://arxiv.org/abs/2405.12312</link>
      <description>arXiv:2405.12312v4 Announce Type: replace-cross 
Abstract: The widespread use of machine learning and data-driven algorithms for decision making has been steadily increasing over many years. \emph{Bias} in the data can adversely affect this decision-making. We present a new mitigation strategy to address data bias. Our methods are explainable and come with mathematical guarantees of correctness. They can take advantage of new work on table discovery to find new tuples that can be added to a dataset to create real datasets that are unbiased or less biased. Our framework covers data with non-binary labels and with multiple sensitive attributes. Hence, we are able to measure and mitigate bias that does not appear over a single attribute (or feature), but only intersectionally, when considering a combination of attributes. We evaluate our techniques on publicly available datasets and provide a theoretical analysis of our results, highlighting novel insights into data bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12312v4</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bruno Scarone, Alfredo Viola, Ren\'ee J. Miller, Ricardo Baeza-Yates</dc:creator>
    </item>
    <item>
      <title>Identity-related Speech Suppression in Generative AI Content Moderation</title>
      <link>https://arxiv.org/abs/2409.13725</link>
      <description>arXiv:2409.13725v3 Announce Type: replace-cross 
Abstract: Automated content moderation has long been used to help identify and filter undesired user-generated content online. But such systems have a history of incorrectly flagging content by and about marginalized identities for removal. Generative AI systems now use such filters to keep undesired generated content from being created by or shown to users. While a lot of focus has been given to making sure such systems do not produce undesired outcomes, considerably less attention has been paid to making sure appropriate text can be generated. From classrooms to Hollywood, as generative AI is increasingly used for creative or expressive text generation, whose stories will these technologies allow to be told, and whose will they suppress?
  In this paper, we define and introduce measures of speech suppression, focusing on speech related to different identity groups incorrectly filtered by a range of content moderation APIs. Using both short-form, user-generated datasets traditional in content moderation and longer generative AI-focused data, including two datasets we introduce in this work, we create a benchmark for measurement of speech suppression for nine identity groups. Across one traditional and four generative AI-focused automated content moderation services tested, we find that identity-related speech is more likely to be incorrectly suppressed than other speech. We find that reasons for incorrect flagging behavior vary by identity based on stereotypes and text associations, with, e.g., disability-related content more likely to be flagged for self-harm or health-related reasons while non-Christian content is more likely to be flagged as violent or hateful. As generative AI systems are increasingly used for creative work, we urge further attention to how this may impact the creation of identity-related content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13725v3</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Grace Proebsting, Oghenefejiro Isaacs Anigboro, Charlie M. Crawford, Dana\'e Metaxa, Sorelle A. Friedler</dc:creator>
    </item>
    <item>
      <title>On the Complexities of Testing for Compliance with Human Oversight Requirements in AI Regulation</title>
      <link>https://arxiv.org/abs/2504.03300</link>
      <description>arXiv:2504.03300v2 Announce Type: replace-cross 
Abstract: Human oversight requirements are a core component of the European AI Act and in AI governance. In this paper, we highlight key challenges in testing for compliance with these requirements. A central difficulty lies in balancing simple, but potentially ineffective checklist-based approaches with resource-intensive and context-sensitive empirical testing of the effectiveness of human oversight of AI. Questions regarding when to update compliance testing, the context-dependent nature of human oversight requirements, and difficult-to-operationalize standards further complicate compliance testing. We argue that these challenges illustrate broader challenges in the future of sociotechnical AI governance, i.e. a future that shifts from ensuring good technological products to good sociotechnical systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03300v2</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Langer, Veronika Lazar, Kevin Baum</dc:creator>
    </item>
    <item>
      <title>EducationQ: Evaluating LLMs' Teaching Capabilities Through Multi-Agent Dialogue Framework</title>
      <link>https://arxiv.org/abs/2504.14928</link>
      <description>arXiv:2504.14928v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) increasingly serve as educational tools, yet evaluating their teaching capabilities remains challenging due to the resource-intensive, context-dependent, and methodologically complex nature of teacher-student interactions. We introduce EducationQ, a multi-agent dialogue framework that efficiently assesses teaching capabilities through simulated dynamic educational scenarios, featuring specialized agents for teaching, learning, and evaluation. Testing 14 LLMs across major AI Organizations (OpenAI, Meta, Google, Anthropic, and others) on 1,498 questions spanning 13 disciplines and 10 difficulty levels reveals that teaching effectiveness does not correlate linearly with model scale or general reasoning capabilities - with some smaller open-source models outperforming larger commercial counterparts in teaching contexts. This finding highlights a critical gap in current evaluations that prioritize knowledge recall over interactive pedagogy. Our mixed-methods evaluation, combining quantitative metrics with qualitative analysis and expert case studies, identifies distinct pedagogical strengths employed by top-performing models (e.g., sophisticated questioning strategies, adaptive feedback mechanisms). Human expert evaluations show 78% agreement with our automated qualitative analysis of effective teaching behaviors, validating our methodology. EducationQ demonstrates that LLMs-as-teachers require specialized optimization beyond simple scaling, suggesting next-generation educational AI prioritize targeted enhancement of specific pedagogical effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.14928v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.18653/v1/2025.acl-long.1576</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers) (2025) 32799-32828</arxiv:journal_reference>
      <dc:creator>Yao Shi, Rongkeng Liang, Yong Xu</dc:creator>
    </item>
    <item>
      <title>Urban Green Governance: IoT-Driven Management and Enhancement of Urban Green Spaces in Campobasso</title>
      <link>https://arxiv.org/abs/2507.12106</link>
      <description>arXiv:2507.12106v3 Announce Type: replace-cross 
Abstract: The efficient design and management of public green spaces is a key factor in promoting the health and well-being of urban population, as emphasized by the WHO, UNEP, and EEA. These areas serve as the "green lungs" of the urban ecosystem, playing a vital role in enhancing quality of life thanks to the provision of ecosystem services. In this context, the Smart Green City use case in Campobasso municipality, funded by the Italian Ministry of Enterprises (MIMIT), emerges as an innovative model for the sustainable management of green urban areas through the adoption of an advanced system of emerging technologies integrated and interoperable. The project integrates IoT systems and data-driven governance platforms, enabling real-time monitoring of the health status of trees and green areas via a Decision Support System (DSS). It also facilitates the collection and analysis of data from diverse sources, including weather conditions, air quality, soil moisture, pollution levels. The resulting cloud-based platform supports a holistic real time decision making for green urban managers, technical experts and operational staff. It enables intelligent control and management of urban green spaces using Tree Talker sensors, integrated with soil moisture and water potential monitoring systems. Thanks to predictive models based on machine learning algorithms and real time data provided by IoT sensors, irrigation of public parks can be optimized by providing suggestions on when and how much water to apply. Customized alerts layers are also activated warning users when monitored parameters, such as soil temperature, humidity, or water potential, exceed predefined thresholds. This Use Case demonstrates how digitalization, IoT sensors fusion and technological innovation can support sustainable urban governance, fostering environmental resilience and improving citizens quality of life.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12106v3</guid>
      <category>cs.DC</category>
      <category>cs.CY</category>
      <pubDate>Fri, 25 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Salis, Gabriele Troina, Gianluca Boanelli, Marco Ottaviano, Paola Fortini, Soraya Versace</dc:creator>
    </item>
  </channel>
</rss>
