<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 06 Feb 2026 05:00:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Branch-and-price strikes back for the k-vertex cut problem</title>
      <link>https://arxiv.org/abs/2602.04984</link>
      <description>arXiv:2602.04984v1 Announce Type: new 
Abstract: Given an undirected graph, the k-vertex cut problem (k-VCP) asks for a minimum-cost set of vertices whose removal yields at least k connected components in the resulting graph. The k-VCP is an important problem in network optimization, with applications in infrastructure protection and epidemic containment. We present a new extended integer linear programming (ILP) formulation that unifies and strengthens existing models and serves as the foundation for a new branch-and-price algorithm for the k-VCP. An in-depth theoretical study enables us to devise algorithmic components such as tailored branching rules that preserve the structure of the pricing problems, as well as valid inequalities and symmetry-handling techniques. We also show that our new model dominates all previous ILP formulations of the k-VCP in terms of their linear relaxations, which theoretically justifies the computational effectiveness of our approach. Extensive computational experiments against state-of-the-art methods demonstrate substantially improved performance, both in terms of instances solved to proven optimality and running times. On the full benchmark of 608 instances, our algorithm consistently outperforms all competitors and is able to solve 73 previously unsolved instances within the time limit of one hour.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.04984v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Ciccarelli, Fabio Furini, Christopher Hojny, Marco L\"ubbecke</dc:creator>
    </item>
    <item>
      <title>Banach Control Barrier Functions for Large-Scale Swarm Control</title>
      <link>https://arxiv.org/abs/2602.05011</link>
      <description>arXiv:2602.05011v1 Announce Type: new 
Abstract: This paper studies the safe control of very large multi-agent systems via a generalized framework that employs so-called Banach Control Barrier Functions (B-CBFs). Modeling a large swarm as probability distribution over a spatial domain, we show how B-CBFs can be used to appropriately capture a variety of macroscopic constraints that can integrate with large-scale swarm objectives. Leveraging this framework, we define stable and filtered gradient flows for large swarms, paying special attention to optimal transport algorithms. Further, we show how to derive agent-level, microscopical algorithms that are consistent with macroscopic counterparts in the large-scale limit. We then identify conditions for which a group of agents can compute a distributed solution that only requires local information from other agents within a communication range. Finally, we showcase the theoretical results over swarm systems in the simulations section.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05011v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuting Gao, Guillem Pascual, Scott Brown, Sonia Mart\'inez</dc:creator>
    </item>
    <item>
      <title>Decaying Sensitivity of the Zero Solution for a Class of Nonlinear Optimal Control Problems</title>
      <link>https://arxiv.org/abs/2602.05020</link>
      <description>arXiv:2602.05020v1 Announce Type: new 
Abstract: We study spatial decay properties of sensitivities in a nonlinear optimal control problem with a graph--structured interaction topology. For a problem with nonlinear decoupled dynamics and quadratic cost, we show that a localized perturbation of the zero reference leads to an optimal trajectory that decays exponentially with the graph distance. The analysis, based on a nonlinear controllability condition, provides a first step toward extending known spatial decay results from linear--quadratic to nonlinear systems. A numerical example illustrates the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05020v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars Gr\"une, Mario Sperl</dc:creator>
    </item>
    <item>
      <title>Approximation of Singular-Stopping Control Driven by Hawkes Processes via Rescaled MDPs</title>
      <link>https://arxiv.org/abs/2602.05025</link>
      <description>arXiv:2602.05025v1 Announce Type: new 
Abstract: We investigate a singular-optimal stopping stochastic control problem driven by self-exciting dynamics governed by a Hawkes process. In the continuous-time setting, we show that the optimization problem reduces to solving a variational partial differential equation with gradient constraints. We then introduce its discrete-time counterpart, modeled as a Markov Decision Process. We prove that, under an appropriate rescaling procedure, the value function of the discrete-time problem converges to its continuous-time equivalent, implying that the discrete-time optimizers are asymptotically optimal for the continuous-time problem. Finally, we apply these results to an Ornstein-Uhlenbeck stochastic differential equation driven by a Hawkes process with singular control, motivated by optimal power plant investment under cyber threat and we illustrate the theoretical findings through numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05025v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Isabel Agostino, Thibaut Mastrolia</dc:creator>
    </item>
    <item>
      <title>Safe Optimal Control using Log Barrier Constrained iLQR</title>
      <link>https://arxiv.org/abs/2602.05046</link>
      <description>arXiv:2602.05046v1 Announce Type: new 
Abstract: This paper presents a constrained iterative Linear Quadratic Regulator (iLQR) framework for nonlinear optimal control problems with box constraints on both states and control inputs. We incorporate logarithmic barrier functions into the stage cost to enforce box constraints (upper and lower bounds on variables), yielding a smooth interior-point formulation that integrates seamlessly with the standard iLQR backward-forward pass. The Hessian contributions from the log barriers are positive definite, preserving and enhancing the positive definiteness of the quadratic approximations in iLQR and providing an intrinsic regularization effect that improves numerical stability and convergence. Moreover, since the negative logarithm is convex, the addition of log barrier terms preserves convexity if the cost is already convex. We further analyze how the barrier-augmented iLQR naturally adapts feedback gains near constraint boundaries. In particular, at convergence, the feedback terms associated with saturated control channels go to zero, recovering a purely feedforward behavior whenever control is saturated. Numerical examples on constrained nonlinear control problems demonstrate that the proposed method reliably respects box constraints and maintains favorable convergence properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05046v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator> Abhijeet, Suman Chakravorty</dc:creator>
    </item>
    <item>
      <title>An Adaptive Framework for Robust Structural Shape Optimization under Uncertainty</title>
      <link>https://arxiv.org/abs/2602.05054</link>
      <description>arXiv:2602.05054v1 Announce Type: new 
Abstract: This work proposes an adaptive framework to solve a robust structural shape optimization problem governed by linear elasticity models that account for uncertainties in the loading and material inputs. A posteriori error estimators are constructed to adjust the sample size, mesh size, and step length. The size of the sample set in the stochastic gradient approximation is dynamically determined depending on the variance of the shape derivative. When constructing the a posteriori error estimator in the physical domain, errors arising from the discretization of the deformation bilinear form, which provides a descent direction, are considered, in addition to errors from the discretization of the linear elasticity system. The step length in gradient-based optimization is also adaptively adjusted by estimating the Lipschitz constant of the stochastic shape derivative. Moreover, an analysis of the existence and distributed-form derivation of the stochastic shape derivative is provided. Finally, the proposed estimation-based adaptive stochastic optimization framework is validated on leg-like structural components, demonstrating its effectiveness in minimizing touchdown compliance under uncertain contact forces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05054v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>O\u{g}uz Han Alt{\i}nta\c{s}, Hamdullah Y\"ucel</dc:creator>
    </item>
    <item>
      <title>Optimal Risk-Sharing Rules in Network-based Decentralized Insurance</title>
      <link>https://arxiv.org/abs/2602.05155</link>
      <description>arXiv:2602.05155v1 Announce Type: new 
Abstract: This paper studies decentralized risk-sharing on networks. In particular, we consider a model where agents are nodes in a given network structure. Agents directly connected by edges in the network are referred to as friends. We study actuarially fair risk-sharing under the assumption that only friends can share risk, and we characterize the optimal signed linear risk-sharing rule in this network setting. Subsequently, we consider a special case of this model where all the friends of an agent take on an equal share of the agent's risk, and establish a connection to the graph Laplacian. Our results are illustrated with several examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05155v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <category>q-fin.RM</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Heather N. Fogarty, Sooie-Hoe Loke, Nicholas F. Marshall, Enrique A. Thomann</dc:creator>
    </item>
    <item>
      <title>From Sequential to Parallel: Reformulating Dynamic Programming as GPU Kernels for Large-Scale Stochastic Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2602.05179</link>
      <description>arXiv:2602.05179v1 Announce Type: new 
Abstract: A major bottleneck in scenario-based Sample Average Approximation (SAA) for stochastic programming (SP) is the cost of solving an exact second-stage problem for every scenario, especially when each scenario contains an NP-hard combinatorial structure. This has led much of the SP literature to restrict the second stage to linear or simplified models. We develop a GPU-based framework that makes full-fidelity integer second-stage models tractable at scale. The key innovation is a set of hardware-aware, scenario-batched GPU kernels that expose parallelism across scenarios, dynamic-programming (DP) layers, and route or action options, enabling Bellman updates to be executed in a single pass over more than 1,000,000 realizations. We evaluate the approach in two representative SP settings: a vectorized split operator for stochastic vehicle routing and a DP for inventory reinsertion. Implementation scales nearly linearly in the number of scenarios and achieves a one-two to four-five orders of magnitude speedup, allowing far larger scenario sets and reliably stronger first-stage decisions. The computational leverage directly improves decision quality: much larger scenario sets and many more first-stage candidates can be evaluated within fixed time budgets, consistently yielding stronger SAA solutions. Our results show that full-fidelity integer second-stage models are tractable at scales previously considered impossible, providing a practical path to large-scale, realistic stochastic discrete optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05179v1</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyi Zhao, Linxin Yang, Haohua Zhang, Tian Ding</dc:creator>
    </item>
    <item>
      <title>Inverse Optimization Without Inverse Optimization: Direct Solution Prediction with Transformer Models</title>
      <link>https://arxiv.org/abs/2602.05306</link>
      <description>arXiv:2602.05306v1 Announce Type: new 
Abstract: We present an end-to-end framework for generating solutions to combinatorial optimization problems with unknown components using transformer-based sequence-to-sequence neural networks. Our framework learns directly from past solutions and incorporates the known components, such as hard constraints, via a constraint reasoning module, yielding a constrained learning scheme. The trained model generates new solutions that are structurally similar to past solutions and are guaranteed to respect the known constraints. We apply our approach to three combinatorial optimization problems with unknown components: the knapsack problem with an unknown reward function, the bipartite matching problem with an unknown objective function, and the single-machine scheduling problem with release times and unknown precedence constraints, with the objective of minimizing average completion time. We demonstrate that transformer models have remarkably strong performance and often produce near-optimal solutions in a fraction of a second. They can be particularly effective in the presence of more complex underlying objective functions and unknown implicit constraints compared to an LSTM-based alternative and inverse optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05306v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Macarena Navarro, Willem-Jan van Hoeve, Karan Singh</dc:creator>
    </item>
    <item>
      <title>Twice Epi-Differentiability of Spectral Functions and its applications</title>
      <link>https://arxiv.org/abs/2602.05357</link>
      <description>arXiv:2602.05357v1 Announce Type: new 
Abstract: Second-order variational properties have been shown to play important theoretical and numerical roles for different classes of optimization problems. Among such properties, twice epi-differentiability has a special place because of its ubiquitous presence in various classes of extended-real-valued functions that are important for optimization problems. We provide a useful characterization of this property for spectral functions by demonstrating that it can be characterized via the same property of the symmetric part of the spectral representation of an eigenvalue function. Our approach allows us to bypass the rather restrictive convexity assumption, used in many recent works that targeted second-order variational properties of spectral functions. By this theoretical tool, several applications on the proto-differentiability of subgradient mappings, the directional differentiability of the proximal mapping of spectral functions are achieved. We finally use our established theory to study twice epi-differentiability of leading eigenvalue functions and practical regularization terms that have important applications in statistics and the robust PCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05357v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chao Ding, Ebrahim Sarabi, Shiwei Wang</dc:creator>
    </item>
    <item>
      <title>Relationship between MP and DPP for Risk-Sensitive Stochastic Optimal Control Problems: Viscosity Solution Framework</title>
      <link>https://arxiv.org/abs/2602.05361</link>
      <description>arXiv:2602.05361v1 Announce Type: new 
Abstract: In this paper, we study the relationship between general maximum principle and dynamic programming principle for risk-sensitive stochastic optimal control problems, where the control domain is not necessarily convex. The original problem is equivalent to a stochastic recursive optimal control problem of a forward-backward system with quadratic generators. Relations among the adjoint processes, the generalized Hamiltonian function and the value function are proved under the framework of viscosity solutions. Some examples are given to illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05361v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Huanqing Dong, Jingtao Shi</dc:creator>
    </item>
    <item>
      <title>Hybrid Quantum-Classical Optimization for Multi-Objective Supply Chain Logistics</title>
      <link>https://arxiv.org/abs/2602.05364</link>
      <description>arXiv:2602.05364v1 Announce Type: new 
Abstract: A multi-objective logistics optimization problem from a real-world supply chain is formulated as a Quadratic Unconstrained Binary Optimization Problem (QUBO) that minimizes cost, emissions, and delivery time, while maintaining target distributions of supplier workshare. The model incorporates realistic constraints, including part dependencies, double sourcing, and multimodal transport. Two hybrid quantum-classical solvers are proposed: a structure-aware informed tree search (IQTS) and a modular bilevel framework (HBS), combining quantum subroutines with classical heuristics. Experimental results on IonQ's Aria-1 hardware demonstrate a methodology to map real-world logistics problems onto emerging combinatorial optimization-specialized hardware, yielding high-quality, Pareto-optimal solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05364v1</guid>
      <category>math.OC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Raoul Heese, Timoth\'ee Leleu, Sam Reifenstein, Christian Nietner, Yoshihisa Yamamoto</dc:creator>
    </item>
    <item>
      <title>Distributed Model Predictive Control for Energy and Comfort Optimization in Large Buildings Using Piecewise Affine Approximation</title>
      <link>https://arxiv.org/abs/2602.05376</link>
      <description>arXiv:2602.05376v1 Announce Type: new 
Abstract: The control of large buildings encounters challenges in computational efficiency due to their size and nonlinear components. To address these issues, this paper proposes a Piecewise Affine (PWA)-based distributed scheme for Model Predictive Control (MPC) that optimizes energy and comfort through PWA-based quadratic programming. We utilize the Alternating Direction Method of Multipliers (ADMM) for effective decomposition and apply the PWA technique to handle the nonlinear components. To solve the resulting large-scale nonconvex problems, the paper introduces a convex ADMM algorithm that transforms the nonconvex problem into a series of smaller convex problems, significantly enhancing computational efficiency. Furthermore, we demonstrate that the convex ADMM algorithm converges to a local optimum of the original problem. A case study involving 36 zones validates the effectiveness of the proposed method. Our proposed method reduces execution time by 86\% compared to the centralized version.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05376v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongyi Li, Jun Xu, Jinfeng Liu</dc:creator>
    </item>
    <item>
      <title>Optimistic Bilevel Optimization with Composite Lower-Level Problem</title>
      <link>https://arxiv.org/abs/2602.05417</link>
      <description>arXiv:2602.05417v1 Announce Type: new 
Abstract: This paper introduces a novel double regularization scheme for bilevel optimization problems whose lower-level problem is composite and convex, but not necessarily strongly convex, in the lower-level variable. The analysis focuses on the primal-dual solution mapping of the regularized lower-level problem and exploits its properties to derive an almost-everywhere formula for the gradient of the regularized hyper-objective under mild assumptions. The paper then establishes conditions under which the hyper-objective of the actual problem is well defined and shows that its gradient can be approximated by the gradient of the regularized hyper-objective. Building on these results, a gradient sampling-based algorithm computes approximately stationary points of the regularized hyper-objective, and we prove its convergence to stationary points of the actual problem. Two numerical examples from machine learning demonstrate the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05417v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mattia Solla, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Relaxation in infinite convex programming under Slater-type regularity conditions</title>
      <link>https://arxiv.org/abs/2602.05457</link>
      <description>arXiv:2602.05457v1 Announce Type: new 
Abstract: The main purpose of this paper is to close the gap between the optimal values of an infinite convex program and that of its biconjugate relaxation. It is shown that Slater and continuity-type conditions guarantee such a zero-duality gap. The approach uses calculus rules for the conjugation and biconjugation of the sum and pointwise supremum operations. A second important objective of this work is to exploit these results on relaxation by applying them in the context of duality theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05457v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael Correa, Abderrahim Hantoute, Marco A. L\'opez</dc:creator>
    </item>
    <item>
      <title>Convergence Rate of the Last Iterate of Stochastic Proximal Algorithms</title>
      <link>https://arxiv.org/abs/2602.05489</link>
      <description>arXiv:2602.05489v1 Announce Type: new 
Abstract: We analyze two classical algorithms for solving additively composite convex optimization problems where the objective is the sum of a smooth term and a nonsmooth regularizer: proximal stochastic gradient method for a single regularizer; and the randomized incremental proximal method, which uses the proximal operator of a randomly selected function when the regularizer is given as the sum of many nonsmooth functions. We focus on relaxing the bounded variance assumption that is common, yet stringent, for getting last iterate convergence rates. We prove the $\widetilde{O}(1/\sqrt{T})$ rate of convergence for the last iterate of both algorithms under componentwise convexity and smoothness, which is optimal up to log terms. Our results apply directly to graph-guided regularizers that arise in multi-task and federated learning, where the regularizer decomposes as a sum over edges of a collaboration graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05489v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kevin Kurian Thomas Vaidyan, Michael P. Friedlander, Ahmet Alacaoglu</dc:creator>
    </item>
    <item>
      <title>Continuized Nesterov Momentum Achieves the $O(\varepsilon^{-7/4})$ Complexity without Additional Mechanisms</title>
      <link>https://arxiv.org/abs/2602.05504</link>
      <description>arXiv:2602.05504v1 Announce Type: new 
Abstract: For first-order optimization of non-convex functions with Lipschitz continuous gradient and Hessian, the best known complexity for reaching an $\varepsilon$-approximation of a stationary point is $O(\varepsilon^{-7/4})$. Existing algorithms achieving this bound are based on momentum, but are always complemented with safeguard mechanisms, such as restarts or negative-curvature exploitation steps. Whether such mechanisms are fundamentally necessary has remained an open question. Leveraging the continuized method, we show that a Nesterov momentum algorithm with stochastic parameters alone achieves the same complexity in expectation. This result holds up to a multiplicative stochastic factor with unit expectation and a restriction to a subset of the realizations, both of which are independent of the objective function. We empirically verify that these constitute mild limitations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05504v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julien Hermant, Jean-Fran\c{c}ois Aujol, Charles Dossal, Lorick Huang, Aude Rondepierre</dc:creator>
    </item>
    <item>
      <title>Solving Stochastic Variational Inequalities without the Bounded Variance Assumption</title>
      <link>https://arxiv.org/abs/2602.05531</link>
      <description>arXiv:2602.05531v1 Announce Type: new 
Abstract: We analyze algorithms for solving stochastic variational inequalities (VI) without the bounded variance or bounded domain assumptions, where our main focus is min-max optimization with possibly unbounded constraint sets. We focus on two classes of problems: monotone VIs; and structured nonmonotone VIs that admit a solution to the weak Minty VI. The latter assumption allows us to solve structured nonconvex-nonconcave min-max problems. For both classes of VIs, to make the expected residual norm less than $\varepsilon$, we show an oracle complexity of $\widetilde{O}(\varepsilon^{-4})$, which is the best-known for constrained VIs. In our setting, this complexity had been obtained with the bounded variance assumption in the literature, which is not even satisfied for bilinear min-max problems with an unbounded domain. We obtain this complexity for stochastic oracles whose variance can grow as fast as the squared norm of the optimization variable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05531v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ahmet Alacaoglu, Jun-Hyun Kim</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Robust Markov Decision Processes with $s$-Rectangular Ambiguity Sets</title>
      <link>https://arxiv.org/abs/2602.05591</link>
      <description>arXiv:2602.05591v1 Announce Type: new 
Abstract: Robust Markov decision processes (MDPs) have attracted significant interest due to their ability to protect MDPs from poor out-of-sample performance in the presence of ambiguity. In contrast to classical MDPs, which account for stochasticity by modeling the dynamics through a stochastic process with a known transition kernel, a robust MDP additionally accounts for ambiguity by optimizing against the most adverse transition kernel from an ambiguity set constructed via historical data. In this paper, we develop a unified solution framework for a broad class of robust MDPs with $s$-rectangular ambiguity sets, where the most adverse transition probabilities are considered independently for each state. Using our algorithms, we show that $s$-rectangular robust MDPs with $1$- and $2$-norm as well as $\phi$-divergence ambiguity sets can be solved several orders of magnitude faster than with state-of-the-art commercial solvers, and often only a logarithmic factor slower than classical MDPs. We demonstrate the favorable scaling properties of our algorithms on a range of synthetically generated as well as standard benchmark instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05591v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chin Pang Ho, Marek Petrik, Wolfram Wiesemann</dc:creator>
    </item>
    <item>
      <title>Nonsmooth Optimization with Zeroth Order Comparison Feedback</title>
      <link>https://arxiv.org/abs/2602.05622</link>
      <description>arXiv:2602.05622v1 Announce Type: new 
Abstract: We study unconstrained optimization problems of nonsmooth, nonconvex Lipschitz functions, using only noisy pairwise comparisons governed by a known link function. Our goal is to compute a $(\delta,\varepsilon)$-Goldstein stationary point. We combine randomized smoothing with a novel unbiased reduction from comparisons to local value differences. By leveraging a Russian-roulette truncation on the Bernoulli-product expansion of the inverse link, we construct an exactly unbiased estimator for directional differences. This estimator has finite expected cost and variance scaling quadratically with the function gap, $\mathcal{O}(B^2)$, under mild conditions. Plugging this into the smoothed gradient identity enables a standard nonconvex SGD analysis, yielding explicit comparison-complexity bounds for common symmetric links such as logistic, probit, and cauchit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05622v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Bakkali, El Mahdi Chayti, Omar Saadi</dc:creator>
    </item>
    <item>
      <title>A Smooth Locally Exact Penalty Method for Optimization Problems over Generalized Stiefel Manifolds</title>
      <link>https://arxiv.org/abs/2602.05631</link>
      <description>arXiv:2602.05631v1 Announce Type: new 
Abstract: In this paper, we consider a class of optimization problems constrained to the generalized Stiefel manifold. Such problems are fundamental to a wide range of real-world applications, including generalized canonical correlation analysis, linear discriminant analysis, and electronic structure calculations. Existing works mainly focuses on cases where the generalized orthogonality constraint is induced by a symmetric positive definite matrix M, a setting where the geometry essentially reduces to that of the standard Stiefel manifold. However, many practical scenarios involve a singular M, which introduces significant analytical and computational challenges. Therefore, we propose a Smooth Locally Exact Penalty model (SLEP) and establish its equivalence to the original problem in the aspect of stationary points under a finitly large penalty parameter. This penalty model admits the direct application of various unconstrained optimization techniques, with convergence guarantees inherited from established results. Compared to Riemannian optimization approaches, our proposed penalty mode eliminates the need for retractions and vector transports, hence significantly reducing per-iteration computational costs. Extensive numerical experiments validate our theoretical results and demonstrate the effectiveness and practical potential of the proposed penalty model SLEP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05631v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Linshuo Jiang, Nachuan Xiao, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Characterizations of the Aubin property of the KKT-mapping in composite optimization by SC derivatives and quadratic bundles</title>
      <link>https://arxiv.org/abs/2602.05684</link>
      <description>arXiv:2602.05684v1 Announce Type: new 
Abstract: For general set-valued mappings, the Aubin property is ultimately tied to limiting coderivatives by the Mordukhovich criterion. Likewise, the existence of single-valued Lipschitzian localizations is related to strict graphical derivatives. In this paper we will show that for the special case of the KKT-mapping from composite optimization, the Aubin property and the existence of single-valued Lipschitzian localizations can be characterized by SC derivatives and quadratic bundles, respectively, which are easier accessible than limiting coderivatives and strict graphical derivatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05684v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Helmut Gfrerer, Jiri V. Outrata</dc:creator>
    </item>
    <item>
      <title>On Circuit Diameter and Straight Line Complexity</title>
      <link>https://arxiv.org/abs/2602.05699</link>
      <description>arXiv:2602.05699v1 Announce Type: new 
Abstract: The circuit diameter of a polyhedron is the maximum length (number of steps) of a shortest circuit walk between any two vertices of the polyhedron. Introduced by Borgwardt, Finhold and Hemmecke (SIDMA 2015), it is a relaxation of the combinatorial diameter of a polyhedron. These two notions of diameter lower bound the number of iterations taken by circuit augmentation algorithms and the simplex method respectively for solving linear programs.
  Recently, an analogous lower bound for path-following interior point methods was introduced by Allamigeon, Dadush, Loho, Natura and V\'egh (SICOMP 2025). Termed straight line complexity, it refers to the minimum number of pieces of any piecewise linear curve that traverses a specified neighborhood of the central path.
  In this paper, we study the relationship between circuit diameter and straight line complexity. For a polyhedron $P:=\{x\in \mathbb{R}^n: Ax = b, x\geq \mathbf{0}\}$, we show that its circuit diameter is up to a $\mathrm{poly}(n)$ factor upper bounded by the straight line complexity of linear programs defined over $P$. This yields a strongly polynomial circuit diameter bound for polyhedra with at most 2 variables per inequality. We also give a circuit augmentation algorithm with matching iteration complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05699v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Dadush, Stefan Kober, Zhuan Khye Koh</dc:creator>
    </item>
    <item>
      <title>Non-Stationary Inventory Control with Lead Times</title>
      <link>https://arxiv.org/abs/2602.05799</link>
      <description>arXiv:2602.05799v1 Announce Type: new 
Abstract: We study non-stationary single-item, periodic-review inventory control problems in which the demand distribution is unknown and may change over time. We analyze how demand non-stationarity affects learning performance across inventory models, including systems with demand backlogging or lost-sales, both with and without lead times. For each setting, we propose an adaptive online algorithm that optimizes over the class of base-stock policies and establish performance guarantees in terms of dynamic regret relative to the optimal base-stock policy at each time step. Our results reveal a sharp separation across inventory models. In backlogging systems and lost-sales models with zero lead time, we show that it is possible to adapt to demand changes without incurring additional performance loss in stationary environments, even without prior knowledge of the demand distributions or the number of demand shifts. In contrast, for lost-sales systems with positive lead times, we establish weaker guarantees that reflect fundamental limitations imposed by delayed replenishment in combination with censored feedback. Our algorithms leverage the convexity and one-sided feedback structure of inventory costs to enable counterfactual policy evaluation despite demand censoring. We complement the theoretical analysis with simulation results showing that our methods significantly outperform existing benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05799v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nele H. Amiri, Sean R. Sinclair, Maximiliano Udenio</dc:creator>
    </item>
    <item>
      <title>Objective-Function Free Multi-Objective Optimization: Rate of Convergence and Performance of an Adagrad-like algorithm</title>
      <link>https://arxiv.org/abs/2602.05893</link>
      <description>arXiv:2602.05893v1 Announce Type: new 
Abstract: We propose an Adagrad-like algorithm for multi-objective unconstrained optimization that relies on the computation of a common descent direction only. Unlike classical local algorithms for multi-objective optimization, our approach does not rely on the dominance property to accept new iterates, which allows for a flexible and function-free optimization framework. New points are obtained using an adaptive stepsize that does not require neither knowledge of Lipschitz constants nor the use of line search procedures. The rate of convergence is analyzed and is shown to be $\mathcal{O}(1 / \sqrt{ k+1})$ with respect to the norm of the common descent direction. The method is extensively validated on a broad class of unconstrained multi-objective problems and simple multi-task learning instances, and compared against a first-order line search algorithm. Additionally, we present a preliminary study of the behavior under noisy multi-objective settings, highlighting the robustness of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05893v1</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marianna De Santis, Gabriele Eichfelder, Margherita Porcelli</dc:creator>
    </item>
    <item>
      <title>Normalization of ReLU Dual for Cut Generation in Stochastic Mixed-Integer Programs</title>
      <link>https://arxiv.org/abs/2602.05974</link>
      <description>arXiv:2602.05974v1 Announce Type: new 
Abstract: We study the Rectified Linear Unit (ReLU) dual, an existing dual formulation for stochastic programs that reformulates non-anticipativity constraints using ReLU functions to generate tight, non-convex, and mixed-integer representable cuts. While this dual reformulation guarantees convergence with mixed-integer state variables, it admits multiple optimal solutions that can yield weak cuts. To address this issue, we propose normalizing the dual in the extended space to identify solutions that yield stronger cuts. We prove that the resulting normalized cuts are tight and Pareto-optimal in the original state space. We further compare normalization with existing regularization-based approaches for handling dual degeneracy and explain why normalization offers key advantages. In particular, we show that normalization can recover any cut obtained via regularization, whereas the converse does not hold. Computational experiments demonstrate that the proposed approach outperforms existing methods by consistently yielding stronger cuts and reducing solution times on harder instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05974v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Akul Bansal, Simge K\"u\c{c}\"ukyavuz</dc:creator>
    </item>
    <item>
      <title>The Signed Wasserstein Barycenter Problem</title>
      <link>https://arxiv.org/abs/2602.05976</link>
      <description>arXiv:2602.05976v1 Announce Type: new 
Abstract: Barycenter problems encode important geometric information about a metric space. While these problems are typically studied with positive weight coefficients associated to each distance term, more general signed Wasserstein barycenter problems have recently drawn a great deal of interest. These mixed sign problems have appeared in statistical inference setting as a way to generalize least squares regression to measure valued outputs and have appeared in numerical methods to improve the accuracy of Wasserstein gradient flow solvers. Unfortunately, the presence of negatively weighted distance terms destroys the Euclidean convexity of the unsigned problem, resulting in a much more challenging optimization task. The main focus of this work is to study properties of the signed barycenter problem for a general transport cost with a focus on establishing uniqueness of solutions. In particular, when there is only one positive weight, we extend the uniqueness result of Tornabene et al. (2025) to any cost satisfying a certain convexity property. In the case of arbitrary weights, we introduce the dual problem in terms of Kantorovich potentials and provide a sufficient condition for a stationary solution of the dual problem to induce an optimal signed barycenter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05976v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matt Jacobs, Bohan Zhou</dc:creator>
    </item>
    <item>
      <title>Does SGD Seek Flatness or Sharpness? An Exactly Solvable Model</title>
      <link>https://arxiv.org/abs/2602.05065</link>
      <description>arXiv:2602.05065v1 Announce Type: cross 
Abstract: A large body of theory and empirical work hypothesizes a connection between the flatness of a neural network's loss landscape during training and its performance. However, there have been conceptually opposite pieces of evidence regarding when SGD prefers flatter or sharper solutions during training. In this work, we partially but causally clarify the flatness-seeking behavior of SGD by identifying and exactly solving an analytically solvable model that exhibits both flattening and sharpening behavior during training. In this model, the SGD training has no \textit{a priori} preference for flatness, but only a preference for minimal gradient fluctuations. This leads to the insight that, at least within this model, it is data distribution that uniquely determines the sharpness at convergence, and that a flat minimum is preferred if and only if the noise in the labels is isotropic across all output dimensions. When the noise in the labels is anisotropic, the model instead prefers sharpness and can converge to an arbitrarily sharp solution, depending on the imbalance in the noise in the labels spectrum. We reproduce this key insight in controlled settings with different model architectures such as MLP, RNN, and transformers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05065v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yizhou Xu, Pierfrancesco Beneventano, Isaac Chuang, Liu Ziyin</dc:creator>
    </item>
    <item>
      <title>Unbiased Single-Queried Gradient for Combinatorial Objective</title>
      <link>https://arxiv.org/abs/2602.05119</link>
      <description>arXiv:2602.05119v1 Announce Type: cross 
Abstract: In a probabilistic reformulation of a combinatorial problem, we often face an optimization over a hypercube, which corresponds to the Bernoulli probability parameter for each binary variable in the primal problem. The combinatorial nature suggests that an exact gradient computation requires multiple queries. We propose a stochastic gradient that is unbiased and requires only a single query of the combinatorial function. This method encompasses a well-established REINFORCE (through an importance sampling), as well as including a class of new stochastic gradients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05119v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thanawat Sornwanee</dc:creator>
    </item>
    <item>
      <title>Logarithmic-time Schedules for Scaling Language Models with Momentum</title>
      <link>https://arxiv.org/abs/2602.05298</link>
      <description>arXiv:2602.05298v1 Announce Type: cross 
Abstract: In practice, the hyperparameters $(\beta_1, \beta_2)$ and weight-decay $\lambda$ in AdamW are typically kept at fixed values. Is there any reason to do otherwise? We show that for large-scale language model training, the answer is yes: by exploiting the power-law structure of language data, one can design time-varying schedules for $(\beta_1, \beta_2, \lambda)$ that deliver substantial performance gains.
  We study logarithmic-time scheduling, in which the optimizer's gradient memory horizon grows with training time. Although naive variants of this are unstable, we show that suitable damping mechanisms restore stability while preserving the benefits of longer memory. Based on this, we present ADANA, an AdamW-like optimizer that couples log-time schedules with explicit damping to balance stability and performance. We empirically evaluate ADANA across transformer scalings (45M to 2.6B parameters), comparing against AdamW, Muon, and AdEMAMix.
  When properly tuned, ADANA achieves up to 40% compute efficiency relative to a tuned AdamW, with gains that persist--and even improve--as model scale increases. We further show that similar benefits arise when applying logarithmic-time scheduling to AdEMAMix, and that logarithmic-time weight-decay alone can yield significant improvements. Finally, we present variants of ADANA that mitigate potential failure modes and improve robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05298v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Damien Ferbach, Courtney Paquette, Gauthier Gidel, Katie Everett, Elliot Paquette</dc:creator>
    </item>
    <item>
      <title>A Short and Unified Convergence Analysis of the SAG, SAGA, and IAG Algorithms</title>
      <link>https://arxiv.org/abs/2602.05304</link>
      <description>arXiv:2602.05304v1 Announce Type: cross 
Abstract: Stochastic variance-reduced algorithms such as Stochastic Average Gradient (SAG) and SAGA, and their deterministic counterparts like the Incremental Aggregated Gradient (IAG) method, have been extensively studied in large-scale machine learning. Despite their popularity, existing analyses for these algorithms are disparate, relying on different proof techniques tailored to each method. Furthermore, the original proof of SAG is known to be notoriously involved, requiring computer-aided analysis. Focusing on finite-sum optimization with smooth and strongly convex objective functions, our main contribution is to develop a single unified convergence analysis that applies to all three algorithms: SAG, SAGA, and IAG. Our analysis features two key steps: (i) establishing a bound on delays due to stochastic sub-sampling using simple concentration tools, and (ii) carefully designing a novel Lyapunov function that accounts for such delays. The resulting proof is short and modular, providing the first high-probability bounds for SAG and SAGA that can be seamlessly extended to non-convex objectives and Markov sampling. As an immediate byproduct of our new analysis technique, we obtain the best known rates for the IAG algorithm, significantly improving upon prior bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05304v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng Zhu, Robert W. Heath Jr., Aritra Mitra</dc:creator>
    </item>
    <item>
      <title>A Data Driven Structural Decomposition of Dynamic Games via Best Response Maps</title>
      <link>https://arxiv.org/abs/2602.05324</link>
      <description>arXiv:2602.05324v1 Announce Type: cross 
Abstract: Dynamic games are powerful tools to model multi-agent decision-making, yet computing Nash (generalized Nash) equilibria remains a central challenge in such settings. Complexity arises from tightly coupled optimality conditions, nested optimization structures, and poor numerical conditioning. Existing game-theoretic solvers address these challenges by directly solving the joint game, typically requiring explicit modeling of all agents' objective functions and constraints, while learning-based approaches often decouple interaction through prediction or policy approximation, sacrificing equilibrium consistency. This paper introduces a conceptually novel formulation for dynamic games by restructuring the equilibrium computation. Rather than solving a fully coupled game or decoupling agents through prediction or policy approximation, a data-driven structural reduction of the game is proposed that removes nested optimization layers and derivative coupling by embedding an offline-compiled best-response map as a feasibility constraint. Under standard regularity conditions, when the best-response operator is exact, any converged solution of the reduced problem corresponds to a local open-loop Nash (GNE) equilibrium of the original game; with a learned surrogate, the solution is approximately equilibrium-consistent up to the best-response approximation error. The proposed formulation is supported by mathematical proofs, accompanying a large-scale Monte Carlo study in a two-player open-loop dynamic game motivated by the autonomous racing problem. Comparisons are made against state-of-the-art joint game solvers, and results are reported on solution quality, computational cost, and constraint satisfaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05324v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdis Rabbani, Navid Mojahed, Shima Nazari</dc:creator>
    </item>
    <item>
      <title>On Path-based Marginal Cost of Heterogeneous Traffic Flow for General Networks</title>
      <link>https://arxiv.org/abs/2602.05565</link>
      <description>arXiv:2602.05565v1 Announce Type: cross 
Abstract: Path marginal cost (PMC) is a crucial component in solving path-based system-optimal dynamic traffic assignment (SO-DTA), dynamic origin-destination demand estimation (DODE), and network resilience analysis. However, accurately evaluating PMC in heterogeneous traffic conditions poses significant challenges. Previous studies often focus on homogeneous traffic flow of single vehicle class and do not well address the interactive effect of heterogeneous traffic flows and the resultant computational issues. This study proposes a novel but simple method for approximately evaluating PMC in complex heterogeneous traffic condition. The method decomposes PMC into intra-class and inter-class terms and uses conversion factor derived from heterogeneous link dynamics to explicitly model the intricate relationships between vehicle classes. Additionally, the method considers the non-differentiable issue that arises when mixed traffic flow approaches system optimum conditions. The proposed method is tested on a small corridor network with synthetic demand and a large-scale network with calibrated demand from real-world data. Results demonstrated that our method exhibits superior performance in solving bi-class SO-DTA problems, yielding lower total travel cost and capturing the multi-class flow competition at the system optimum state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05565v1</guid>
      <category>cs.CE</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jiachao Liu, Sean Qian</dc:creator>
    </item>
    <item>
      <title>Tight Long-Term Tail Decay of (Clipped) SGD in Non-Convex Optimization</title>
      <link>https://arxiv.org/abs/2602.05657</link>
      <description>arXiv:2602.05657v1 Announce Type: cross 
Abstract: The study of tail behaviour of SGD-induced processes has been attracting a lot of interest, due to offering strong guarantees with respect to individual runs of an algorithm. While many works provide high-probability guarantees, quantifying the error rate for a fixed probability threshold, there is a lack of work directly studying the probability of failure, i.e., quantifying the tail decay rate for a fixed error threshold. Moreover, existing results are of finite-time nature, limiting their ability to capture the true long-term tail decay which is more informative for modern learning models, typically trained for millions of iterations. Our work closes these gaps, by studying the long-term tail decay of SGD-based methods through the lens of large deviations theory, establishing several strong results in the process. First, we provide an upper bound on the tails of the gradient norm-squared of the best iterate produced by (vanilla) SGD, for non-convex costs and bounded noise, with long-term decay at rate $e^{-t/\log(t)}$. Next, we relax the noise assumption by considering clipped SGD (c-SGD) under heavy-tailed noise with bounded moment of order $p \in (1,2]$, showing an upper bound with long-term decay at rate $e^{-t^{\beta_p}/\log(t)}$, where $\beta_p = \frac{4(p-1)}{3p-2}$ for $p \in (1,2)$ and $e^{-t/\log^2(t)}$ for $p = 2$. Finally, we provide lower bounds on the tail decay, at rate $e^{-t}$, showing that our rates for both SGD and c-SGD are tight, up to poly-logarithmic factors. Notably, our results demonstrate an order of magnitude faster long-term tail decay compared to existing work based on finite-time bounds, which show rates $e^{-\sqrt{t}}$ and $e^{-t^{\beta_p/2}}$, $p \in (1,2]$, for SGD and c-SGD, respectively. As such, we uncover regimes where the tails decay much faster than previously known, providing stronger long-term guarantees for individual runs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05657v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Dragana Bajovi\'c, Du\v{s}an Jakoveti\'c, Soummya Kar, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Muon in Associative Memory Learning: Training Dynamics and Scaling Laws</title>
      <link>https://arxiv.org/abs/2602.05725</link>
      <description>arXiv:2602.05725v1 Announce Type: cross 
Abstract: Muon updates matrix parameters via the matrix sign of the gradient and has shown strong empirical gains, yet its dynamics and scaling behavior remain unclear in theory. We study Muon in a linear associative memory model with softmax retrieval and a hierarchical frequency spectrum over query-answer pairs, with and without label noise. In this setting, we show that Gradient Descent (GD) learns frequency components at highly imbalanced rates, leading to slow convergence bottlenecked by low-frequency components. In contrast, the Muon optimizer mitigates this imbalance, leading to faster and more uniform progress. Specifically, in the noiseless case, Muon achieves an exponential speedup over GD; in the noisy case with a power-decay frequency spectrum, we derive Muon's optimization scaling law and demonstrate its superior scaling efficiency over GD. Furthermore, we show that Muon can be interpreted as an implicit matrix preconditioner arising from adaptive task alignment and block-symmetric gradient structure. In contrast, the preconditioner with coordinate-wise sign operator could match Muon under oracle access to unknown task representations, which is infeasible for SignGD in practice. Experiments on synthetic long-tail classification and LLaMA-style pre-training corroborate the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05725v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Binghui Li, Kaifei Wang, Han Zhong, Pinyan Lu, Liwei Wang</dc:creator>
    </item>
    <item>
      <title>Where Does Warm-Up Come From? Adaptive Scheduling for Norm-Constrained Optimizers</title>
      <link>https://arxiv.org/abs/2602.05813</link>
      <description>arXiv:2602.05813v1 Announce Type: cross 
Abstract: We study adaptive learning rate scheduling for norm-constrained optimizers (e.g., Muon and Lion). We introduce a generalized smoothness assumption under which local curvature decreases with the suboptimality gap and empirically verify that this behavior holds along optimization trajectories. Under this assumption, we establish convergence guarantees under an appropriate choice of learning rate, for which warm-up followed by decay arises naturally from the proof rather than being imposed heuristically.
  Building on this theory, we develop a practical learning rate scheduler that relies only on standard hyperparameters and adapts the warm-up duration automatically at the beginning of training. We evaluate this method on large language model pretraining with LLaMA architectures and show that our adaptive warm-up selection consistently outperforms or at least matches the best manually tuned warm-up schedules across all considered setups, without additional hyperparameter search. Our source code is available at https://github.com/brain-lab-research/llm-baselines/tree/warmup</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05813v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Artem Riabinin, Andrey Veprikov, Arman Bolatov, Martin Tak\'a\v{c}, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Beyond Manual Planning: Seating Allocation for Large Organizations</title>
      <link>https://arxiv.org/abs/2602.05875</link>
      <description>arXiv:2602.05875v1 Announce Type: cross 
Abstract: We introduce the Hierarchical Seating Allocation Problem (HSAP) which addresses the optimal assignment of hierarchically structured organizational teams to physical seating arrangements on a floor plan. This problem is driven by the necessity for large organizations with large hierarchies to ensure that teams with close hierarchical relationships are seated in proximity to one another, such as ensuring a research group occupies a contiguous area. Currently, this problem is managed manually leading to infrequent and suboptimal replanning efforts. To alleviate this manual process, we propose an end-to-end framework to solve the HSAP. A scalable approach to calculate the distance between any pair of seats using a probabilistic road map (PRM) and rapidly-exploring random trees (RRT) which is combined with heuristic search and dynamic programming approach to solve the HSAP using integer programming. We demonstrate our approach under different sized instances by evaluating the PRM framework and subsequent allocations both quantitatively and qualitatively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05875v1</guid>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anton Ipsen, Michael Cashmore, Kirsty Fielding, Nicolas Marchesotti, Parisa Zehtabi, Daniele Magazzeni, Manuela Veloso</dc:creator>
    </item>
    <item>
      <title>Escaping Local Minima Provably in Non-convex Matrix Sensing: A Deterministic Framework via Simulated Lifting</title>
      <link>https://arxiv.org/abs/2602.05887</link>
      <description>arXiv:2602.05887v1 Announce Type: cross 
Abstract: Low-rank matrix sensing is a fundamental yet challenging nonconvex problem whose optimization landscape typically contains numerous spurious local minima, making it difficult for gradient-based optimizers to converge to the global optimum. Recent work has shown that over-parameterization via tensor lifting can convert such local minima into strict saddle points, an insight that also partially explains why massive scaling can improve generalization and performance in modern machine learning. Motivated by this observation, we propose a Simulated Oracle Direction (SOD) escape mechanism that simulates the landscape and escape direction of the over-parametrized space, without resorting to actually lifting the problem, since that would be computationally intractable. In essence, we designed a mathematical framework to project over-parametrized escape directions onto the original parameter space to guarantee a strict decrease of objective value from existing local minima. To the best of the our knowledge, this represents the first deterministic framework that could escape spurious local minima with guarantee, especially without using random perturbations or heuristic estimates. Numerical experiments demonstrate that our framework reliably escapes local minima and facilitates convergence to global optima, while incurring minimal computational cost when compared to explicit tensor over-parameterization. We believe this framework has non-trivial implications for nonconvex optimization beyond matrix sensing, by showcasing how simulated over-parameterization can be leveraged to tame challenging optimization landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.05887v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianqi Shen, Jinji Yang, Junze He, Kunhan Gao, Ziye Ma</dc:creator>
    </item>
    <item>
      <title>Optimism Stabilizes Thompson Sampling for Adaptive Inference</title>
      <link>https://arxiv.org/abs/2602.06014</link>
      <description>arXiv:2602.06014v1 Announce Type: cross 
Abstract: Thompson sampling (TS) is widely used for stochastic multi-armed bandits, yet its inferential properties under adaptive data collection are subtle. Classical asymptotic theory for sample means can fail because arm-specific sample sizes are random and coupled with the rewards through the action-selection rule. We study this phenomenon in the $K$-armed Gaussian bandit and identify \emph{optimism} as a key mechanism for restoring \emph{stability}, a sufficient condition for valid asymptotic inference requiring each arm's pull count to concentrate around a deterministic scale. First, we prove that variance-inflated TS \citep{halder2025stable} is stable for any $K \ge 2$, including the challenging regime where multiple arms are optimal. This resolves the open question raised by \citet{halder2025stable} through extending their results from the two-armed setting to the general $K$-armed setting. Second, we analyze an alternative optimistic modification that keeps the posterior variance unchanged but adds an explicit mean bonus to posterior mean, and establish the same stability conclusion. In summary, suitably implemented optimism stabilizes Thompson sampling and enables asymptotically valid inference in multi-armed bandits, while incurring only a mild additional regret cost.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.06014v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shunxing Yan, Han Zhong</dc:creator>
    </item>
    <item>
      <title>On a conjecture with implications for multicriteria decision making</title>
      <link>https://arxiv.org/abs/2502.05180</link>
      <description>arXiv:2502.05180v3 Announce Type: replace 
Abstract: I prove Richard Soland's conjecture that for an efficient solution to a multicriteria optimization problem, there need not exist a continuous, strictly increasing and strictly concave criterion space function that attains its maximum at the vector of criteria values achieved by that solution. I work out an important implication of this result for multicriteria decision making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05180v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anas Mifrani</dc:creator>
    </item>
    <item>
      <title>Equilibrium models to analyse the impact of different coordination schemes between TSO and DSOs on market power in sequentially-cleared energy and ancillary services markets under load and renewable generation uncertainty</title>
      <link>https://arxiv.org/abs/2505.15168</link>
      <description>arXiv:2505.15168v2 Announce Type: replace 
Abstract: The current massive installation of distributed resources in electricity distribution systems is transforming these systems into active dispatching subjects. At the same time, the need to compensate for the intermittent generation of an increasing amount of renewable sources creates the need to acquire more ancillary services. Flexible resources in the distribution system could provide these services not only within the perimeter of the distribution network to which they are connected but also for the benefit of the transmission system. However, this requires Transmission System Operators (TSOs) and Distribution System Operators (DSOs) to coordinate their dispatching actions effectively. One critical aspect of this coordination is establishing a market architecture that limits market power. This paper presents an innovative game-theoretic approach to compare different TSO-DSO coordination models for acquiring ancillary services from distribution resources. Several schemes are considered: some with coordinated market management by TSOs and DSOs, others with sequential or independent local markets. For each scheme, the dispatching problem is formulated as a two-stage stochastic sequential game, where the first stage is the day-ahead market and the second stage is the balancing market. Nash equilibrium solutions are obtained by iteratively solving the profit maximization problem of each market player. Numerical tests on a CIGRE benchmark network show that coordination schemes enabling distribution resources to provide ancillary services to the transmission system can significantly increase system costs when congestion occurs in the transmission network.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.15168v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Giovanni Micheli, Maria Teresa Vespucci, Gianluigi Migliavacca, Dario Siface</dc:creator>
    </item>
    <item>
      <title>PolarGrad: A Class of Matrix-Gradient Optimizers from a Unifying Preconditioning Perspective</title>
      <link>https://arxiv.org/abs/2505.21799</link>
      <description>arXiv:2505.21799v4 Announce Type: replace 
Abstract: The ever-growing scale of deep learning models and training data underscores the critical importance of efficient optimization methods. While preconditioned gradient methods such as Adam and AdamW are the de facto optimizers for training neural networks and large language models, structure-aware preconditioned optimizers like Shampoo and Muon, which utilize the matrix structure of gradients, have demonstrated promising evidence of faster convergence. In this paper, we introduce a unifying framework for analyzing "matrix-aware" preconditioned methods, which not only sheds light on the effectiveness of Muon and related optimizers but also leads to a class of new structure-aware preconditioned methods. A key contribution of this framework is its precise distinction between preconditioning strategies that treat neural network weights as vectors (addressing curvature anisotropy) versus those that consider their matrix structure (addressing gradient anisotropy). This perspective provides new insights into several empirical phenomena in language model pre-training, including Adam's training instabilities, Muon's accelerated convergence, and the necessity of learning rate warmup for Adam. Building upon this framework, we introduce PolarGrad, a new class of preconditioned optimization methods based on the polar decomposition of matrix-valued gradients. As a special instance, PolarGrad includes Muon with updates scaled by the nuclear norm of the gradients. We provide numerical implementations of these methods, leveraging efficient numerical polar decomposition algorithms for enhanced convergence. Our extensive evaluations across diverse matrix optimization problems and language model pre-training tasks demonstrate that PolarGrad outperforms both Adam and Muon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21799v4</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tim Tsz-Kit Lau, Qi Long, Weijie Su</dc:creator>
    </item>
    <item>
      <title>An infinite horizon sufficient stochastic maximum principle for regime switching diffusions and applications</title>
      <link>https://arxiv.org/abs/2506.11523</link>
      <description>arXiv:2506.11523v2 Announce Type: replace 
Abstract: This paper is concerned with a discounted stochastic optimal control problem for regime switching diffusion in an infinite horizon. First, as a preliminary with particular interests in its own right, the global well-posedness of infinite horizon forward and backward stochastic differential equations with Markov chains and the asymptotic property of their solutions when time goes to infinity are obtained. Then, a sufficient stochastic maximum principle for optimal controls is established via a dual method under certain convexity condition of the Hamiltonian. As an application of our maximum principle, a linear quadratic production planning problem is solved with an explicit feedback optimal production rate. The existence and uniqueness of a non-negative solution to the associated algebraic Riccati equation are proved. Numerical experiments are reported to illustrate the theoretical results, especially, the monotonicity of the value function on various model parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11523v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Ding, Xun Li, Siyu Lv, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of Classical Regression Methods for Optimal Switching Problems</title>
      <link>https://arxiv.org/abs/2506.15436</link>
      <description>arXiv:2506.15436v2 Announce Type: replace 
Abstract: Simple regression methods provide robust, near-optimal solutions for optimal switching problems, including high-dimensional ones (up to 50). While the theory requires solving intractable PDE systems, the Longstaff-Schwartz algorithm with classical regression methods achieves excellent switching decisions without extensive hyperparameter tuning. Testing linear models (OLS, Ridge, LASSO), tree-based methods (random forests, gradient boosting), $k$-nearest neighbors, and feedforward neural networks on four benchmark problems, we find that several simple methods maintain stable performance across diverse problem characteristics, outperforming the neural networks we tested against. In our comparison, $k$-NN regression performs consistently well, and with minimal hyperparameter tuning. We establish concentration bounds for this regressor and show that PCA enables $k$-NN to scale to high dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15436v2</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Andersson, Benny Avelin, Marcus Olofsson</dc:creator>
    </item>
    <item>
      <title>Accelerating Single-Point Zeroth-Order Optimization with Regression-Based Gradient Surrogates</title>
      <link>https://arxiv.org/abs/2507.04223</link>
      <description>arXiv:2507.04223v2 Announce Type: replace 
Abstract: Zeroth-order optimization (ZO) is widely used for solving black-box optimization and control problems. In particular, single-point ZO (SZO) is well-suited to online or dynamic problem settings due to its requirement of only a single function evaluation per iteration. However, SZO suffers from high gradient estimation variance and slow convergence, which severely limit its practical applicability. To overcome this limitation, we propose a novel yet simple SZO framework termed regression-based SZO (ReSZO), which substantially enhances the convergence rate. Specifically, ReSZO constructs a surrogate function via regression using historical function evaluations and employs the gradient of this surrogate function for iterative updates. Two instantiations of ReSZO, which fit linear and quadratic surrogate functions respectively, are introduced. Moreover, we provide a non-asymptotic convergence analysis for the linear instantiation of ReSZO, showing that its convergence rates are comparable to those of two-point ZO methods. Extensive numerical experiments demonstrate that ReSZO empirically converges two to three times faster than two-point ZO in terms of function query complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04223v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xin Chen, Zhaolin Ren</dc:creator>
    </item>
    <item>
      <title>On the geometry of flat minima</title>
      <link>https://arxiv.org/abs/2509.11386</link>
      <description>arXiv:2509.11386v2 Announce Type: replace 
Abstract: What does it mean to be flat? We propose to define it by measuring the maximal variation around a point, or from a dual perspective, the distance to neighboring level sets. After developing some calculus rules, we show how flat minima, conservation laws, and symmetries are intertwined. Gradient flows of conserved quantities are of particular interest, due to their flattening properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11386v2</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>Lyapunov stability of the Euler method</title>
      <link>https://arxiv.org/abs/2509.11415</link>
      <description>arXiv:2509.11415v3 Announce Type: replace 
Abstract: We extend the Lyapunov stability criterion to Euler discretizations of differential inclusions. It relies on a pair of Lyapunov functions, one in continuous time and one in discrete time. In the context of optimization, this yields sufficient conditions for the stability of nonisolated local minima when using the Bouligand subgradient method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.11415v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'edric Josz</dc:creator>
    </item>
    <item>
      <title>A Single-Loop First-Order Algorithm for Linearly Constrained Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2510.24710</link>
      <description>arXiv:2510.24710v3 Announce Type: replace 
Abstract: We study bilevel optimization problems where the lower-level problems are strongly convex and have coupled linear constraints. To overcome the potential non-smoothness of the hyper-objective and the computational challenges associated with the Hessian matrix, we utilize penalty and augmented Lagrangian methods to reformulate the original problem as a single-level one. Especially, we establish a strong theoretical connection between the reformulated function and the original hyper-objective by characterizing the closeness of their values and derivatives. Based on this reformulation, we propose a single-loop, first-order algorithm for linearly constrained bilevel optimization (SFLCB). We provide rigorous analyses of its non-asymptotic convergence rates, showing an improvement over prior double-loop algorithms -- form $O(\epsilon^{-3}\log(\epsilon^{-1}))$ to $O(\epsilon^{-3})$. The experiments corroborate our theoretical findings and demonstrate the practical efficiency of the proposed SFLCB algorithm. Simulation code is provided at https://github.com/ShenGroup/SFLCB.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24710v3</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wei Shen, Jiawei Zhang, Minhui Huang, Cong Shen</dc:creator>
    </item>
    <item>
      <title>Boundary control systems on a one-dimension spatial domain</title>
      <link>https://arxiv.org/abs/2601.01634</link>
      <description>arXiv:2601.01634v3 Announce Type: replace 
Abstract: The aim of this paper is to investigate the well-posedness of a class of boundary control and observation systems on a one dimensional spatial domain. We derive a necessary and sufficient condition characterizing the well-posedness of these systems. Furthermore, we show that the well-posedness and full control and observation implies exact controllability and exact observability. The theoretical results are illustrated using Euler-Bernoulli beam models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.01634v3</guid>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bouchra Elghazi, Birgit Jacob, Hans Zwart</dc:creator>
    </item>
    <item>
      <title>Arcade Processes for Informed Martingale Interpolation</title>
      <link>https://arxiv.org/abs/2301.05936</link>
      <description>arXiv:2301.05936v3 Announce Type: replace-cross 
Abstract: Arcade processes are a class of continuous stochastic processes that interpolate in a strong sense, i.e., omega by omega, between zeros at fixed pre-specified times. Their additive randomisation allows one to match any finite sequence of target random variables, indexed by the given fixed dates, on the whole probability space. The randomised arcade processes (RAPs) can thus be interpreted as a generalisation of anticipative stochastic bridges. The filtrations generated by these processes are utilised to construct a class of martingales that interpolate between the given target random variables. These so-called filtered arcade martingales (FAMs) are almost-sure solutions to the martingale interpolation problem and reveal an underlying stochastic filtering structure. In the special case of conditionally Markov randomised arcade processes, the dynamics of FAMs are informed by Bayesian updating. The same ideas are applied to filtered arcade reverse-martingales, which are constructed in a similar fashion, using reverse-filtrations of RAPs, instead. Several explicit examples for RAPs and FAMs are provided and simulated. This paper concludes with an outlook on potential connections between FAMs and martingale optimal transport, and related applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.05936v3</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Georges Kassis, Andrea Macrina</dc:creator>
    </item>
    <item>
      <title>Lipschitz stability for an inverse source problem of the wave equation with kinetic boundary conditions</title>
      <link>https://arxiv.org/abs/2402.12902</link>
      <description>arXiv:2402.12902v2 Announce Type: replace-cross 
Abstract: In this paper, we present a refined approach to establish a global Lipschitz stability for an inverse source problem concerning the determination of forcing terms in the wave equation with mixed boundary conditions. It consists of boundary conditions incorporating a dynamic boundary condition and Dirichlet boundary condition on disjoint subsets of the boundary. The primary contribution of this article is the rigorous derivation of a sharp Carleman estimate for the wave system with a dynamic boundary condition. In particular, our findings complete and drastically improve the earlier results established by Gal and Tebou [SIAM J. Control Optim., 55 (2017), 324-364]. This is achieved by using a different weight function to overcome some relevant difficulties. As for the stability proof, we extend to dynamic boundary conditions a recent argument avoiding cut-off functions. Finally, we also show that our developed Carleman estimate yields a sharp boundary controllability result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12902v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>S. E. Chorfi, G. El Guermai, L. Maniar, W. Zouhair</dc:creator>
    </item>
    <item>
      <title>A Differential and Pointwise Control Approach to Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2404.15617</link>
      <description>arXiv:2404.15617v4 Announce Type: replace-cross 
Abstract: Reinforcement learning (RL) in continuous state-action spaces remains challenging in scientific computing due to poor sample efficiency and lack of pathwise physical consistency. We introduce Differential Reinforcement Learning (Differential RL), a novel framework that reformulates RL from a continuous-time control perspective via a differential dual formulation. This induces a Hamiltonian structure that embeds physics priors and ensures consistent trajectories without requiring explicit constraints. To implement Differential RL, we develop Differential Policy Optimization (dfPO), a pointwise, stage-wise algorithm that refines local movement operators along the trajectory for improved sample efficiency and dynamic alignment. We establish pointwise convergence guarantees, a property not available in standard RL, and derive a competitive theoretical regret bound of $\mathcal{O}(K^{5/6})$. Empirically, dfPO outperforms standard RL baselines on representative scientific computing tasks, including surface modeling, grid control, and molecular dynamics, under low-data and physics-constrained conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15617v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minh Nguyen, Chandrajit Bajaj</dc:creator>
    </item>
    <item>
      <title>A Sliced Learning Framework for Online Disturbance Identification in Quadrotor SO(3) Attitude Control</title>
      <link>https://arxiv.org/abs/2508.14422</link>
      <description>arXiv:2508.14422v3 Announce Type: replace-cross 
Abstract: This paper introduces a dimension-decomposed geometric learning framework called Sliced Learning for disturbance identification in quadrotor geometric attitude control. Instead of conventional learning-from-states, this framework adopts a learning-from-error strategy by using the Lie-algebraic error representation as the input feature, enabling axis-wise space decomposition (``slicing") while preserving the SO(3) structure. This is highly consistent with the geometric mechanism of cognitive control observed in neuroscience, where neural systems organize adaptive representations within structured subspaces to enable cognitive flexibility and efficiency. Based on this framework, we develop a lightweight and structurally interpretable Sliced Adaptive-Neuro Mapping (SANM) module. The high-dimensional mapping for online identification is axially ``sliced" into multiple low-dimensional submappings (``slices"), implemented by shallow neural networks and adaptive laws. These neural networks and adaptive laws are updated online via Lyapunov-based adaptation within their respective shared subspaces. To enhance interpretability, we prove exponential convergence despite time-varying disturbances and inertia uncertainties. To our knowledge, Sliced Learning is among the first frameworks to demonstrate lightweight online neural adaptation at 400 Hz on resource-constrained microcontroller units (MCUs), such as STM32, with real-world experimental validation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14422v3</guid>
      <category>eess.SY</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianhua Gao, Masashi Izumita, Kohji Tomita, Akiya Kamimura</dc:creator>
    </item>
    <item>
      <title>A Sketch-and-Project Analysis of Subsampled Natural Gradient Algorithms</title>
      <link>https://arxiv.org/abs/2508.21022</link>
      <description>arXiv:2508.21022v2 Announce Type: replace-cross 
Abstract: Subsampled natural gradient descent (SNG) has been used to enable high-precision scientific machine learning, but standard analyses based on stochastic preconditioning fail to provide insight into realistic small-sample settings. We overcome this limitation by instead analyzing SNG as a sketch-and-project method. Motivated by this lens, we discard the usual theoretical proxy which decouples gradients and preconditioners using two independent mini-batches, and we replace it with a new proxy based on squared volume sampling. Under this new proxy we show that the expectation of the SNG direction becomes equal to a preconditioned gradient descent step even in the presence of coupling, leading to (i) global convergence guarantees when using a single mini-batch of any size, and (ii) an explicit characterization of the convergence rate in terms of quantities related to the sketch-and-project structure. These findings in turn yield new insights into small-sample settings, for example by suggesting that the advantage of SNG over SGD is that it can more effectively exploit spectral decay in the model Jacobian. We also extend these ideas to explain a popular structured momentum scheme for SNG, known as SPRING, by showing that it arises naturally from accelerated sketch-and-project methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.21022v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gil Goldshlager, Jiang Hu, Lin Lin</dc:creator>
    </item>
    <item>
      <title>Sharpness-Aware Minimization Can Hallucinate Minimizers</title>
      <link>https://arxiv.org/abs/2509.21818</link>
      <description>arXiv:2509.21818v2 Announce Type: replace-cross 
Abstract: Sharpness-Aware Minimization (SAM) is widely used to seek flatter minima -- often linked to better generalization. In its standard implementation, SAM updates the current iterate using the loss gradient evaluated at a point perturbed by distance $\rho$ along the normalized gradient direction. We show that, for some choices of $\rho$, SAM can stall at points where this shifted (perturbed-point) gradient vanishes despite a nonzero original gradient, and therefore, they are not stationary points of the original loss. We call these points hallucinated minimizers, prove their existence under simple nonconvex landscape conditions (e.g., the presence of a local minimizer and a local maximizer), and establish sufficient conditions for local convergence of the SAM iterates to them. We corroborate this failure mode in neural network training and observe that it aligns with SAM's performance degradation often seen at large $\rho$. Finally, as a practical safeguard, we find that a short initial SGD warm-start before enabling SAM mitigates this failure mode and reduces sensitivity to the choice of $\rho$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.21818v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chanwoong Park, Uijeong Jang, Ernest K. Ryu, Insoon Yang</dc:creator>
    </item>
    <item>
      <title>The Optimal Strategy for Playing Lucky 13</title>
      <link>https://arxiv.org/abs/2510.03234</link>
      <description>arXiv:2510.03234v2 Announce Type: replace-cross 
Abstract: The game show Lucky 13 differs from other television game shows in that contestants are required to place a bet on their own knowledge of trivia by selecting a range that contains the number of questions that they answered correctly. We present a model for this game show using binomial random variables and generate tables outlining the optimal range the player should select based on maximization of two different utility functions. After analyzing the decisions made by some actual contestants on this show, we present a numerical simulation for how many questions an average player is expected to answer correctly based on question categories observed for two sample contestants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.03234v2</guid>
      <category>math.HO</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Steven Berger, Daniel Conus</dc:creator>
    </item>
    <item>
      <title>High-probability Convergence Guarantees of Decentralized SGD</title>
      <link>https://arxiv.org/abs/2510.06141</link>
      <description>arXiv:2510.06141v3 Announce Type: replace-cross 
Abstract: Convergence in high-probability (HP) has attracted increasing interest, due to implying exponentially decaying tail bounds and strong guarantees for individual runs of an algorithm. While many works study HP guarantees in centralized settings, much less is understood in the decentralized setup, where existing works require strong assumptions, like uniformly bounded gradients, or asymptotically vanishing noise. This results in a significant gap between the assumptions used to establish convergence in the HP and the mean-squared error (MSE) sense, and is also contrary to centralized settings, where it is known that $\mathtt{SGD}$ converges in HP under the same conditions on the cost function as needed for MSE convergence. Motivated by these observations, we study the HP convergence of Decentralized $\mathtt{SGD}$ ($\mathtt{DSGD}$) in the presence of light-tailed noise, providing several strong results. First, we show that $\mathtt{DSGD}$ converges in HP under the same conditions on the cost as in the MSE sense, removing the restrictive assumptions used in prior works. Second, our sharp analysis yields order-optimal rates for both non-convex and strongly convex costs. Third, we establish a linear speed-up in the number of users, leading to matching, or strictly better transient times than those obtained from MSE results, further underlining the tightness of our analysis. To the best of our knowledge, this is the first work that shows $\mathtt{DSGD}$ achieves a linear speed-up in the HP sense. Our relaxed assumptions and sharp rates stem from several technical results of independent interest, including a result on the variance-reduction effect of decentralized methods in the HP sense, as well as a novel bound on the MGF of strongly convex costs, which is of interest even in centralized settings. Finally, we provide experiments that validate our theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06141v3</guid>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandar Armacki, Ali H. Sayed</dc:creator>
    </item>
    <item>
      <title>Threshold graphs are globally synchronizing</title>
      <link>https://arxiv.org/abs/2511.12646</link>
      <description>arXiv:2511.12646v5 Announce Type: replace-cross 
Abstract: The Kuramoto model can be formulated as a gradient flow on a nonconvex energy landscape of the form $E(\boldsymbol{\theta}) := \frac{1}{2} \sum_{1\le i,j\le n} A_{ij}\bigl(1-\cos(\theta_i-\theta_j)\bigr).$ A fundamental question is to identify graph structures for which this landscape is benign, in the sense that every second-order stationary point corresponds to a fully synchronized state. This property guarantees that all trajectories of the Kuramoto model converge to a fully synchronized state except for a measure-zero set of initial conditions, a phenomenon known as global synchronization. Existing guarantees typically require that each node be connected to a sufficiently large fraction of the other nodes, enforcing high graph density. In this work, we show that threshold graphs lie well outside this regime while still exhibiting global synchronization. In particular, threshold graphs realize arbitrary edge densities and have degree sequences that are extremal in the sense of majorization. Our analysis is based on a phasor--geometric characterization of stationary points that exploits the structural and geometric symmetries induced by threshold graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.12646v5</guid>
      <category>math.DS</category>
      <category>math.CA</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hongjin Wu, Ulrik Brandes</dc:creator>
    </item>
    <item>
      <title>Generalized Logarithmic Sobolev Inequality by the JKO Scheme</title>
      <link>https://arxiv.org/abs/2601.16620</link>
      <description>arXiv:2601.16620v2 Announce Type: replace-cross 
Abstract: Using a discrete Bakry-{\'E}mery method based on the JKO scheme, relying on the dissipation of entropy and Fisher information along a discrete flow, we establish new generalized logarithmic Sobolev inequality for log-concave measures of the form $e^{-V}$ under strict convexity assumptions on $V$ . We then show how this method recovers some well-known inequalities. This approach can be viewed as interpolating between the Bakry-{\'E}mery method and optimal transport techniques based on geodesic convexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.16620v2</guid>
      <category>math.AP</category>
      <category>math.OC</category>
      <pubDate>Fri, 06 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thibault Caillet (IUT Saint-Denis), Fanch Coudreuse (ICJ, UCBL, MMCS)</dc:creator>
    </item>
  </channel>
</rss>
