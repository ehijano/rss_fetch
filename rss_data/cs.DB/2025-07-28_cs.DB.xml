<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 29 Jul 2025 02:14:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ApproxJoin: Approximate Matching for Efficient Verification in Fuzzy Set Similarity Join</title>
      <link>https://arxiv.org/abs/2507.18891</link>
      <description>arXiv:2507.18891v1 Announce Type: new 
Abstract: The set similarity join problem is a fundamental problem in data processing and discovery, relying on exact similarity measures between sets. In the presence of alterations, such as misspellings on string data, the fuzzy set similarity join problem instead approximately matches pairs of elements based on the maximum weighted matching of the bipartite graph representation of sets. State-of-the-art methods within this domain improve performance through efficient filtering methods within the filter-verify framework, primarily to offset high verification costs induced by the usage of the Hungarian algorithm - an optimal matching method. Instead, we directly target the verification process to assess the efficacy of more efficient matching methods within candidate pair pruning.
  We present ApproxJoin, the first work of its kind in applying approximate maximum weight matching algorithms for computationally expensive fuzzy set similarity join verification. We comprehensively test the performance of three approximate matching methods: the Greedy, Locally Dominant and Paz Schwartzman methods, and compare with the state-of-the-art approach using exact matching. Our experimental results show that ApproxJoin yields performance improvements of 2-19x the state-of-the-art with high accuracy (99% recall).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18891v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Mandulak, S M Ferdous, Sayan Ghosh, Mahantesh Halappanavar, George Slota</dc:creator>
    </item>
    <item>
      <title>Big Data Energy Systems: A Survey of Practices and Associated Challenges</title>
      <link>https://arxiv.org/abs/2507.19154</link>
      <description>arXiv:2507.19154v1 Announce Type: new 
Abstract: Energy systems generate vast amounts of data in extremely short time intervals, creating challenges for efficient data management. Traditional data management methods often struggle with scalability and accessibility, limiting their usefulness. More advanced solutions, such as NoSQL databases and cloud-based platforms, have been adopted to address these issues. Still, even these advanced solutions can encounter bottlenecks, which can impact the efficiency of data storage, retrieval, and analysis. This review paper explores the research trends in big data management for energy systems, highlighting the practices, opportunities and challenges. Also, the data regulatory demands are highlighted using chosen reference architectures. The review, in particular, explores the limitations of current storage and data integration solutions and examines how new technologies are applied to the energy sector. Novel insights into emerging technologies, including data spaces, various data management architectures, peer-to-peer data management, and blockchains, are provided, along with practical recommendations for achieving enhanced data sharing and regulatory compliance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19154v1</guid>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lunodzo J. Mwinuka, Massimo Cafaro, Lucas Pereira, Hugo Morais</dc:creator>
    </item>
    <item>
      <title>DBMS-LLM Integration Strategies in Industrial and Business Applications: Current Status and Future Challenges</title>
      <link>https://arxiv.org/abs/2507.19254</link>
      <description>arXiv:2507.19254v1 Announce Type: new 
Abstract: Modern enterprises are increasingly driven by the DATA+AI paradigm, in which Database Management Systems (DBMSs) and Large Language Models (LLMs) have become two foundational infrastructures powering a wide range of industrial and business applications, such as enterprise analytics, intelligent customer service, and data-driven decision-making. The efficient integration of DBMSs and LLMs within a unified system offers significant opportunities but also introduces new technical challenges. This paper surveys recent developments in DBMS+LLM integration and identifies key future challenges. Specifically, we categorize five representative architectural patterns based on their core design principles, strengths, and trade-offs. Based on this analysis, we further highlight several critical open challenges. We aim to provide a systematic understanding of the current integration landscape and to outline the unresolved issues that must be addressed to achieve scalable and efficient integration of traditional data management and advanced language reasoning in future intelligent applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19254v1</guid>
      <category>cs.DB</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zhengtong Yan, Gongsheng Yuan, Qingsong Guo, Jiaheng Lu</dc:creator>
    </item>
    <item>
      <title>Properties for Paths in Graph Databases</title>
      <link>https://arxiv.org/abs/2507.19329</link>
      <description>arXiv:2507.19329v1 Announce Type: new 
Abstract: This paper presents a formalism for defining properties of paths in graph databases, which can be used to restrict the number of solutions to navigational queries. In particular, our formalism allows us to define quantitative properties such as length or accumulated cost, which can be used as query filters. Furthermore, it enables the identification and removal of paths that may be considered ill-formed.
  The new formalism is defined in terms of an operational semantics for the query language that incorporates these new constructs, demonstrating its soundness and completeness by proving its compatibility with a simple logical semantics. We also analyze its expressive power, showing that path properties are more expressive than register automata. Finally, after discussing some complexity issues related to this new approach, we present an empirical analysis carried out using our prototype implementation of the graph database that serves as a running example throughout the paper. The results show that queries using path properties as filters outperform standard queries that do not use them.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.19329v1</guid>
      <category>cs.DB</category>
      <category>cs.LO</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fernando Orejas, Elvira Pino, Renzo Angles, E. Pasarella, Nikos Milonakis</dc:creator>
    </item>
    <item>
      <title>Optimally Rewriting Formulas and Database Queries: A Confluence of Term Rewriting, Structural Decomposition, and Complexity</title>
      <link>https://arxiv.org/abs/2411.10229</link>
      <description>arXiv:2411.10229v2 Announce Type: replace-cross 
Abstract: A central computational task in database theory, finite model theory, and computer science at large is the evaluation of a first-order sentence on a finite structure. In the context of this task, the \emph{width} of a sentence, defined as the maximum number of free variables over all subformulas, has been established as a crucial measure, where minimizing width of a sentence (while retaining logical equivalence) is considered highly desirable. An undecidability result rules out the possibility of an algorithm that, given a first-order sentence, returns a logically equivalent sentence of minimum width; this result motivates the study of width minimization via syntactic rewriting rules, which is this article's focus. For a number of common rewriting rules (which are known to preserve logical equivalence), including rules that allow for the movement of quantifiers, we present an algorithm that, given a positive first-order sentence $\phi$, outputs the minimum-width sentence obtainable from $\phi$ via application of these rules. We thus obtain a complete algorithmic understanding of width minimization up to the studied rules; this result is the first one -- of which we are aware -- that establishes this type of understanding in such a general setting. Our result builds on the theory of term rewriting and establishes an interface among this theory, query evaluation, and structural decomposition theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10229v2</guid>
      <category>cs.LO</category>
      <category>cs.DB</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hubie Chen, Stefan Mengel</dc:creator>
    </item>
    <item>
      <title>Why Isn't Relational Learning Taking Over the World?</title>
      <link>https://arxiv.org/abs/2507.13558</link>
      <description>arXiv:2507.13558v2 Announce Type: replace-cross 
Abstract: AI seems to be taking over the world with systems that model pixels, words, and phonemes. The world is arguably made up, not of pixels, words, and phonemes but of entities (objects, things, including events) with properties and relations among them. Surely we should model these, not the perception or description of them. You might suspect that concentrating on modeling words and pixels is because all of the (valuable) data in the world is in terms of text and images. If you look into almost any company you will find their most valuable data is in spreadsheets, databases and other relational formats. These are not the form that are studied in introductory machine learning, but are full of product numbers, student numbers, transaction numbers and other identifiers that can't be interpreted naively as numbers. The field that studies this sort of data has various names including relational learning, statistical relational AI, and many others. This paper explains why relational learning is not taking over the world -- except in a few cases with restricted relations -- and what needs to be done to bring it to it's rightful prominence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13558v2</guid>
      <category>cs.AI</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Mon, 28 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David Poole</dc:creator>
    </item>
  </channel>
</rss>
