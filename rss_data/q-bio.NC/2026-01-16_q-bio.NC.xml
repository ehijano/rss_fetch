<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 16 Jan 2026 05:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High-Density Multi-Depth Human Recordings Using 45 mm Long Neuropixels Probes</title>
      <link>https://arxiv.org/abs/2601.09912</link>
      <description>arXiv:2601.09912v1 Announce Type: new 
Abstract: Neuropixels probes, initially developed for use in small animal models, have transformed basic neuroscience by enabling high-density, single-cell resolution recordings across multiple brain regions simultaneously. The recent development of Neuropixels 1.0 NHP Long, a longer probe designed for non-human primates, has expanded this capability, enabling unprecedented simultaneous access to multiple cortical layers and deep brain structures of large-brained animals. Here, we report the first use of these probes in humans, aiming to establish safe intraoperative use and assess feasibility for clinical and research applications. Nine patients undergoing neurosurgical procedures, including epilepsy or tumor resection and deep brain stimulation (DBS) implantation, were enrolled. Successful intraoperative recordings were obtained from surface and deep cortical structures without probe breakage or adverse events. Compared with conventional electrodes, the Neuropixels probe enabled dense sampling across multiple parenchymal depths with submillisecond temporal resolution. Recordings were obtained from deep targets including the hippocampus and cingulate cortex, as well as from regions that are challenging to access with single-unit precision, such as the superior frontal sulcus. Custom tools and refined workflows lowered technical barriers for operative use and improved recording stability. Neural activity was observed across all recordings. Neuropixels 1.0-NHP Long probes can be deployed in the human operating room, enabling simultaneous recordings from multiple brain structures at single-neuron resolution. These methods expand opportunities for studying human brain function and pathology in vivo, and may ultimately support the development of more precise neurosurgical interventions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.09912v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daril E. Brown II (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA), Elizaveta Okorokova (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA), Carrina Iacobacci (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA), Brian Coughlin (Center for Neurotechnology and Neurorecovery, Department of Neurology, Massachusetts General Hospital, Boston, MA, USA, Department of Neurology, Harvard Medical School, Boston, MA, USA), Orin Bloch (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA), Eric M. Trautmann (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA), Sydney S. Cash (Center for Neurotechnology and Neurorecovery, Department of Neurology, Massachusetts General Hospital, Boston, MA, USA, Department of Neurology, Harvard Medical School, Boston, MA, USA), Angelique C. Paulk (Center for Neurotechnology and Neurorecovery, Department of Neurology, Massachusetts General Hospital, Boston, MA, USA, Department of Neurology, Harvard Medical School, Boston, MA, USA), Sergey D. Stavisky (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA), David M. Brandman (Department of Neurological Surgery, University of California Davis Health, Davis, CA, USA)</dc:creator>
    </item>
    <item>
      <title>Macroscopic dynamics of quadratic integrate-and-fire neurons subject to correlated noise</title>
      <link>https://arxiv.org/abs/2601.10032</link>
      <description>arXiv:2601.10032v1 Announce Type: new 
Abstract: The presence of correlated noise, arising from a mixture of independent fluctuations and a common noisy input shared across the neural population, is a ubiquitous feature of neural circuits, yet its impact on collective network dynamics remains poorly understood. We analyze a network of quadratic integrate-and-fire neurons driven by Gaussian noise with a tunable degree of correlation. Using the cumulant expansion method, we derive a reduced set of effective mean-field equations that accurately describe the evolution of the population's mean firing rate and membrane potential. Our analysis reveals a counterintuitive phenomenon: increasing the noise correlation strength suppresses the mean network activity, an effect we term correlated-noise-inhibited spiking. Furthermore, within a specific parameter regime, the network exhibits metastability, manifesting itself as spontaneous, noise-driven transitions between distinct high- and low-activity states. These results provide a theoretical framework for reducing the dynamics of complex stochastic networks and demonstrate how correlated noise can fundamentally regulate macroscopic neural activity, with implications for understanding state transitions in biological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10032v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.AO</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hui Wang, Chunming Zheng</dc:creator>
    </item>
    <item>
      <title>A Unified Dynamical Field Theory of Learning, Inference, and Emergence</title>
      <link>https://arxiv.org/abs/2601.10221</link>
      <description>arXiv:2601.10221v1 Announce Type: new 
Abstract: Learning, inference, and emergence in biological and artificial systems are often studied within disparate theoretical frameworks, ranging from energy-based models to recurrent and attention-based architectures. Here we develop a unified dynamical field theory in which learning and inference are governed by a minimal stochastic dynamical equation admitting a Martin--Siggia--Rose--Janssen--de Dominicis formulation. Within this framework, inference corresponds to saddle-point trajectories of the associated action, while fluctuation-induced loop corrections render collective modes dynamically emergent and generate nontrivial dynamical time scales. A central result of this work is that cognitive function is controlled not by microscopic units or precise activity patterns, but by the collective organization of dynamical time scales. We introduce the \emph{time-scale density of states} (TDOS) as a compact diagnostic that characterizes the distribution of collective relaxation modes governing inference dynamics. Learning and homeostatic regulation are naturally interpreted as processes that reshape the TDOS, selectively generating slow collective modes that support stable inference, memory, and context-dependent computation despite stochasticity and structural irregularity. This framework unifies energy-based models, recurrent neural networks, transformer architectures, and biologically motivated homeostatic dynamics within a single physical description, and provides a principled route toward understanding cognition as an emergent dynamical phenomenon.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10221v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Byung Gyu Chae</dc:creator>
    </item>
    <item>
      <title>How Intrinsic Motivation Underlies Embodied Open-Ended Behavior</title>
      <link>https://arxiv.org/abs/2601.10276</link>
      <description>arXiv:2601.10276v1 Announce Type: new 
Abstract: Although most theories posit that natural behavior can be explained as maximizing some form of extrinsic reward, often called utility, some behaviors appear to be reward independent. For instance, spontaneous motor babbling in human newborns and curiosity in little kids and other animals seem to elude a simple explanation in terms of extrinsic reward maximization. Rooted in these observations, intrinsic motivation has emerged as a potentially major driver of behavior. However, only recently have several quantitative and foundational theories of intrinsic motivation been put forward. We first provide a general framework to understand behavior as being organized hierarchically: objective--intrinsic reward, or motivation--drives, goals and extrinsic reward. We next review the main formalizations of intrinsic motivation, including empowerment, the free energy principle, information-gain maximization, and the maximum occupancy principle. These theories produce complex behavior by promoting, in various ways, entropic action-state paths. The presence of a single intrinsic motivation objective breaks infinite regress, as drives and goals act only temporarily to serve the objective. Extrinsic rewards, such as sugar or protein, are just a means to achieve the objective. Bounded cognition and embodiment impose constraints and boundary conditions for the intrinsic motivation objective. By virtue of their capability to generate complex behavior in a task-agnostic manner, theories of intrinsic motivation promise to become successful generative models of open-ended, embodied behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10276v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rub\'en Moreno-Bote, Ralf Haefner, Jordi Galiano-Landeira, Tianming Yang, Pedro Maldonado</dc:creator>
    </item>
    <item>
      <title>Reshaping Neural Representation via Associative, Presynaptic Short-Term Plasticity</title>
      <link>https://arxiv.org/abs/2601.10397</link>
      <description>arXiv:2601.10397v1 Announce Type: new 
Abstract: Short-term synaptic plasticity (STP) is traditionally viewed as a purely presynaptic filter of incoming spike trains, independent of postsynaptic activity. Recent experiments, however, reveal an associative form of STP in which presynaptic release probability changes alongside long-term potentiation, implying a richer computational role for presynaptic plasticity. Here we develop a normative theory of associative STP using an information-theoretic framework. Extending Fisher-information-based learning to Tsodyks-Markram synapses, we derive analytic update rules for baseline synaptic strength and release probability that maximize encoded stimulus information under resource constraints. The learning rules separate into a conventional postsynaptic term tracking local firing and a distinct presynaptic term with a phase-advanced structure that selectively detects stimulus onset; critically, differences between plasticity of baseline strength and release probability arise within this presynaptic component. For stimulus variations slower than the EPSP time constant, onset sensitivity biases optimal connectivity toward anti-causal associations, strengthening synapses from neurons activated later to those activated earlier. In recurrent circuits, these rules yield ramp-like sustained representations and reverse replay after drive removal. Linear-response analysis further shows that STP confers frequency-dependent phase selectivity on presynaptic drive and that constraints on total release probability systematically tune temporal asymmetry. Together, our results provide a principled account of associative STP and identify presynaptic plasticity of release probability as a substrate for rapidly reconfigurable temporal coding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10397v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Genki Shimizu, Taro Toyoizumi</dc:creator>
    </item>
    <item>
      <title>Convex Efficient Coding</title>
      <link>https://arxiv.org/abs/2601.10482</link>
      <description>arXiv:2601.10482v1 Announce Type: new 
Abstract: Why do neurons encode information the way they do? Normative answers to this question model neural activity as the solution to an optimisation problem; for example, the celebrated efficient coding hypothesis frames neural activity as the optimal encoding of information under efficiency constraints. Successful normative theories have varied dramatically in complexity, from simple linear models (Atick &amp; Redlich '90), to complex deep neural networks (Lindsay '21). What complex models gain in flexibility, they lose in tractability and often understandability. Here, we split the difference by constructing a set of tractable but flexible normative representational theories. Instead of optimising the neural activities directly, following Sengupta et al. '18, we optimise the representational similarity, a matrix formed from the dot products of each pair of neural responses. Using this, we show that a large family of interesting optimisation problems are convex. This family includes problems corresponding to linear and some non-linear neural networks, and problems from the literature not previously recognised as convex, such as modified versions of semi-nonnegative matrix factorisation or nonnegative sparse coding. We put these findings to work in three ways. First, we provide the first necessary and sufficient identifiability result for a form of semi-nonnegative matrix factorisation. Second, we show that if neural tunings are `different enough' then they are uniquely linked to the optimal representational similarity, partially justifying the use of single neuron tuning analysis in neuroscience. Finally, we use the tractable nonlinearity of some of our problems to explain why dense retinal codes, but not sparse cortical codes, optimally split the coding of a single variable into ON &amp; OFF channels. In sum, we identify a space of convex problems, and use them to derive neural coding results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10482v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>William Dorrell, Peter E. Latham, James Whittington</dc:creator>
    </item>
    <item>
      <title>Testing three models of cognitive stress effects: A psychopharmacological randomized controlled trial of acute stress and stress hormones across visual perception, response inhibition and cognitive flexibility</title>
      <link>https://arxiv.org/abs/2601.10515</link>
      <description>arXiv:2601.10515v1 Announce Type: new 
Abstract: Acute stress alters cognitive performance, yet competing models make divergent predictions regarding the mechanisms, scope, and temporal dynamics of these effects. This large-scale randomized controlled trial tested predications from three influential stress-effect models using a broad cognitive task battery embedded within a psychopharmacological stress paradigm. Across 606 testing sessions, 303 healthy male participants completed both the Maastricht Acute Stress Test (MAST) and its non-stress control condition. To independently manipulate acute stress and stress hormone availability, participants were additionally randomized to receive atomoxetine (40 mg; to prolong norepinephrine availability), hydrocortisone (10 mg; to increase cortisol availability), or placebo. Cognitive performance was assessed over 80-minutes (post-stress) using tasks targeting visual perception (rapid serial visual presentation), response inhibition (stop-signal), and cognitive flexibility (dual and switch tasks). MAST exposure selectively impaired response inhibition, reflected in shorter stop-signal delays, lower probabilities of successful stopping and prolonged stop-signal reaction times, particularly during later testing phases (40-80 minutes post-stress). MAST exposure did not affect visual perception or task-switching performance but buffered time-related declines in processing efficiency at the expense of task prioritization in the dual task. Pharmacological manipulation of norepinephrine or cortisol availability was effective but did not moderate cognitive stress effects. Overall, this pattern of task-specific impairment alongside stabilized processing efficiency cannot be fully explained by any tested model, highlighting the need to refine existing models and adopt more integrative approaches to advance our mechanistic understanding of cognitive stress-effects in laboratory and real-world contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10515v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lisa Weckesser, Charlotte Grosskopf, Benjamin Weber, Selen Soylu, Tanja Endrass, Robert Miller</dc:creator>
    </item>
    <item>
      <title>Sporadic Creutzfeldt Jakob disease presenting with cerebral atrophy following traumatic brain injury mimicking hydrocephalus a case report and literature review</title>
      <link>https://arxiv.org/abs/2601.10663</link>
      <description>arXiv:2601.10663v1 Announce Type: new 
Abstract: Introduction Sporadic Creutzfeldt Jakob disease sCJD is a rapidly progressive neurodegenerative disease without effective treatment that usually results in death within one year. The recently applied methods have improved the accuracy of the disease diagnosis and the specific radiological findings provide the necessary information for differential diagnosis. Research question The research is aimed to provide a different perspective on the development of CJD and associated literature review. Materials and methods The study presents a case who presented cognitive deficits, gait instability, and urinary and fecal incontinence suffered from traumatic brain injury eight months ago before admission with cerebral ventricle dilation on CT images. Furthermore, studies describe relevant cases are also included. Results The patients symptoms got deteriorated. Further examinations, including 14-3-3 and tau proteins in the cerebrospinal fluid CSF, MRI, and EEG, confirmed the patients diagnosis of sCJD. He returned to the local hospital for the conservative treatment without effective medical intervention. Conclusion This case illustrates the diagnostic process of CJD and underscores the importance of distinguishing rare disorders from common conditions to achieve a comprehensive understanding of the disease.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10663v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 16 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chun Zeng, Dezhu Gao, Liang Wu</dc:creator>
    </item>
  </channel>
</rss>
