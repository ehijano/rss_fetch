<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Jul 2025 01:26:33 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Bayesian Regression Analysis with the Drift-Diffusion Model</title>
      <link>https://arxiv.org/abs/2507.01177</link>
      <description>arXiv:2507.01177v1 Announce Type: new 
Abstract: The Drift-Diffusion Model (DDM) is widely used in neuropsychological studies to understand the decision process by incorporating both reaction times and subjects' responses. Various models have been developed to estimate DDM parameters, with some employing Bayesian inference. However, when examining associations between phenotypes of interest and DDM parameters, most studies adopt a two-step approach: first estimating DDM parameters, then applying a separate statistical model to the estimated values. Despite the potential for bias, this practice remains common, primarily due to researchers' unfamiliarity with Bayesian modeling. To address this issue, this tutorial presents the implementations and advantages of fitting a unified Bayesian hierarchical regression model that integrates trial-level drift-diffusion modeling and subject-level regression between DDM parameters and other variables. The R package RegDDM, developed and demonstrated in this tutorial, facilitates this integrated modeling approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01177v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Zekai Jin (Mental Health Data Science, New York State Psychiatric Institute, New York, USA), Yaakov Stern (Departments of Neurology, Columbia University Irving Medical Center, New York, USA), Seonjoo Lee (Mental Health Data Science, New York State Psychiatric Institute, New York, USA, Department of Biostatistics, Columbia University Irving Medical Center, New York, USA)</dc:creator>
    </item>
    <item>
      <title>Swinging, Fast and Slow: Interpreting variation in baseball swing tracking metrics</title>
      <link>https://arxiv.org/abs/2507.01238</link>
      <description>arXiv:2507.01238v1 Announce Type: new 
Abstract: In 2024, Major League Baseball released new bat tracking data, reporting swing-by-swing bat speed and swing length measured at the point of contact. While exciting, the data present challenges for their interpretation. The timing of the batter's swing relative to the pitch determines the point of measurement relative to the full swing path. The relationship between swing metrics and swing outcomes is confounded by the batter's pitch recognition. We introduce a framework for interpreting bat tracking data in which we first estimate the batter's intention conditional on ball-strike count and pitch location using a Bayesian hierarchical skew-normal model with random intercept and random slopes for batter. This yields batter-specific effects of count on swing metrics, which we leverage via instrumental variables regression to estimate causal effects of bat speed and swing length on contact and power outcomes. Finally, we valuate the tradeoff between contact and power due to bat speed by modeling a plate appearance as a Markov chain. We conclude that batters can reduce their strikeout rate by reducing bat speed as strikes increase, but the tradeoff in reduced power approximately counteracts the benefit to the average batter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01238v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Scott Powers, Ronald Yurko</dc:creator>
    </item>
    <item>
      <title>Bayesian Modeling of Long-Term Dynamics in Indian Temperature Extremes</title>
      <link>https://arxiv.org/abs/2507.01540</link>
      <description>arXiv:2507.01540v1 Announce Type: new 
Abstract: Annual maximum temperature data provides crucial insights into the impacts of climate change, especially for regions like India, where temperature variations have significant implications for agriculture, health, and infrastructure. In this study, we propose the Coupled Continuous Time Random Walk (CTRW) model to analyze annual maximum temperature data in India from 1901 to 2017 and compare its performance with the Bayesian Spectral Analysis Regression (BSAR) model. The CTRW model extends the standard framework by coupling temperature changes (jumps) and waiting times, capturing complex dynamics such as memory effects and non-Markovian behavior. The BSAR model, in contrast, combines a linear trend component with a non-linear isotonic function, modeled using a Gaussian Process (GP) prior, to account for smooth and flexible non-linear variations in temperature. By applying both models to the temperature data, we evaluate their ability to capture long-term trends and seasonal fluctuations, offering valuable insights into the effects of climate change on temperature dynamics in India. The comparison highlights the strengths and limitations of each approach in modeling temperature extremes and provides a robust framework for understanding climate variability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01540v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chitradipa Chakraborty</dc:creator>
    </item>
    <item>
      <title>The Hybrid Renewable Energy Forecasting and Trading Competition 2024</title>
      <link>https://arxiv.org/abs/2507.01579</link>
      <description>arXiv:2507.01579v1 Announce Type: new 
Abstract: The Hybrid Energy Forecasting and Trading Competition challenged participants to forecast and trade the electricity generation from a 3.6GW portfolio of wind and solar farms in Great Britain for three months in 2024. The competition mimicked operational practice with participants required to submit genuine forecasts and market bids for the day-ahead on a daily basis. Prizes were awarded for forecasting performance measured by Pinball Score, trading performance measured by total revenue, and combined performance based on rank in the other two tracks. Here we present an analysis of the participants' performance and the learnings from the competition. The forecasting track reaffirms the competitiveness of popular gradient boosted tree algorithms for day-ahead wind and solar power forecasting, though other methods also yielded strong results, with performance in all cases highly dependent on implementation. The trading track offers insight into the relationship between forecast skill and value, with trading strategy and underlying forecasts influencing performance. All competition data, including power production, weather forecasts, electricity market data, and participants' submissions are shared for further analysis and benchmarking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01579v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jethro Browell, Dennis van der Meer, Henrik K\"alvegren, Sebastian Haglund, Edoardo Simioni, Ricardo J. Bessa, Yi Wang</dc:creator>
    </item>
    <item>
      <title>Simulation and evaluation of local daily temperature and precipitation series derived by stochastic downscaling of ERA5 reanalysis</title>
      <link>https://arxiv.org/abs/2507.01692</link>
      <description>arXiv:2507.01692v1 Announce Type: new 
Abstract: Reanalysis products such as the ERA5 reanalysis are commonly used as proxies for observed atmospheric conditions. These products are convenient to use due to their global coverage, the large number of available atmospheric variables and the physical consistency between these variables, as well as their relatively high spatial and temporal resolutions. However, despite the continuous improvements in accuracy and increasing spatial and temporal resolutions of reanalysis products, they may not always capture local atmospheric conditions, especially for highly localised variables such as precipitation. This paper proposes a computationally efficient stochastic downscaling of ERA5 temperature and precipitation. The method combines information from ERA5 and surface observations from nearby stations in a non-linear regression framework that combines generalised additive models (GAMs) with regression splines and auto-regressive moving average (ARMA) models to produce realistic time series of local daily temperature and precipitation. Using a wide range of evaluation criteria that address different properties of the data, the proposed framework is shown to improve the representation of local temperature and precipitation compared to ERA5 at over 4000 locations in Europe over a period of 60 years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01692v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Silius M. Vandeskog, Thordis L. Thorarinsdottir, Alex Lenkoski</dc:creator>
    </item>
    <item>
      <title>Modeling the Deterioration of Pavement Skid Resistance and Surface Texture After Preventive Maintenance</title>
      <link>https://arxiv.org/abs/2507.01842</link>
      <description>arXiv:2507.01842v1 Announce Type: new 
Abstract: This study investigates the deterioration of skid resistance and surface macrotexture following preventive maintenance using micro-milling techniques. Field data were collected from 31 asphalt pavement sections located across four climatic zones in Texas, encompassing a variety of surface types, milling depths, operational speeds, and drum configurations. A standardized data collection protocol was followed, with measurements taken before milling, immediately after treatment, and at 3, 6, 12, and 18 months post-treatment. Skid number and Mean Profile Depth (MPD) were used to evaluate surface friction and texture characteristics. The dataset was reformatted into a time-series structure with 930 observations, incorporating contextual variables such as climatic zone, treatment parameters, and baseline surface condition. A comparative modeling framework was applied to predict the deterioration trends of both skid resistance and macrotexture over time. Eight regression models, including linear, tree-based, and ensemble methods, were evaluated alongside a sequence-to-one transformer model. Results show that the transformer model achieved the highest prediction accuracy for skid resistance (R2=0.981), while Random Forest performing best for macrotexture prediction (R2 = 0.838). The findings indicate that the degradation of surface characteristics after preventive maintenance is nonlinear and influenced by a combination of environmental and operational factors. This study demonstrates the effectiveness of data-driven modeling in supporting transportation agencies with pavement performance forecasting and maintenance planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01842v1</guid>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lu Gao, Zia Din, Kinam Kim, Ahmed Senouci</dc:creator>
    </item>
    <item>
      <title>Mixtures of Neural Network Experts with Application to Phytoplankton Flow Cytometry Data</title>
      <link>https://arxiv.org/abs/2507.01375</link>
      <description>arXiv:2507.01375v1 Announce Type: cross 
Abstract: Flow cytometry is a valuable technique that measures the optical properties of particles at a single-cell resolution. When deployed in the ocean, flow cytometry allows oceanographers to study different types of photosynthetic microbes called phytoplankton. It is of great interest to study how phytoplankton properties change in response to environmental conditions. In our work, we develop a nonlinear mixture of experts model for simultaneous clustering and regression utilizing random-weight neural networks. Our model allows one to flexibly estimate how cell properties and relative abundances depend on environmental covariates, without the computational burden of backpropagation. We show that the proposed model provides superior predictive performance in simulated examples compared to a mixture of linear experts. Also, applying our model to real data, we show that our model has (1) comparable out-of-sample prediction performance, and (2) more realistic estimates of phytoplankton behavior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01375v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ethan Pawl, Fran\c{c}ois Ribalet, Paul A. Parker, Sangwon Hyun</dc:creator>
    </item>
    <item>
      <title>Targeted tuning of random forests for quantile estimation and prediction intervals</title>
      <link>https://arxiv.org/abs/2507.01430</link>
      <description>arXiv:2507.01430v1 Announce Type: cross 
Abstract: We present a novel tuning procedure for random forests (RFs) that improves the accuracy of estimated quantiles and produces valid, relatively narrow prediction intervals. While RFs are typically used to estimate mean responses (conditional on covariates), they can also be used to estimate quantiles by estimating the full distribution of the response. However, standard approaches for building RFs often result in excessively biased quantile estimates. To reduce this bias, our proposed tuning procedure minimizes "quantile coverage loss" (QCL), which we define as the estimated bias of the marginal quantile coverage probability estimate based on the out-of-bag sample. We adapt QCL tuning to handle censored data and demonstrate its use with random survival forests. We show that QCL tuning results in quantile estimates with more accurate coverage probabilities than those achieved using default parameter values or traditional tuning (using MSPE for uncensored data and C-index for censored data), while also reducing the estimated MSE of these coverage probabilities. We discuss how the superior performance of QCL tuning is linked to its alignment with the estimation goal. Finally, we explore the validity and width of prediction intervals created using this method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01430v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew Berkowitz, Rachel MacKay Altman, Thomas M. Loughin</dc:creator>
    </item>
    <item>
      <title>Reduced Efficiency in the Attentional Network During Distractor Suppression in Mild Cognitive Impairment</title>
      <link>https://arxiv.org/abs/2507.01433</link>
      <description>arXiv:2507.01433v2 Announce Type: cross 
Abstract: Mild Cognitive Impairment (MCI) is a critical transitional stage between normal cognitive aging and dementia, making its early detection essential. This study investigates the neural mechanisms of distractor suppression in MCI patients using EEG and behavioral data during an attention-cueing Eriksen flanker task. A cohort of 56 MCIs and 26 healthy controls (HCs) performed tasks with congruent and incongruent stimuli of varying saliency levels. During these tasks, EEG data were analyzed for alpha band coherence's functional connectivity, focusing on Global Efficiency (GE), while Reaction Time (RT) and Hit Rate (HR) were also collected.
  Our findings reveal significant interactions between congruency, saliency, and cognitive status on GE, RT, and HR. In HCs, congruent conditions resulted in higher GE (p = 0.0114, multivariate t-distribution correction, MVT), faster RTs (p &lt; 0.0001, MVT), and higher HRs (p &lt; 0.0001, MVT) compared to incongruent conditions. HCs also showed increased GE in salient conditions for incongruent trials (p = 0.0406, MVT). MCIs exhibited benefits from congruent conditions with shorter RTs and higher HRs (both p &lt; 0.0001, MVT) compared to incongruent conditions but showed reduced adaptability in GE, with no significant GE differences between conditions.
  These results highlight the potential of alpha band coherence and GE as early markers for cognitive impairment. By integrating GE, RT, and HR, this study provides insights into the interplay between neural efficiency, processing speed, and task accuracy. This approach offers valuable insights into cognitive load management and interference effects, indicating benefits for interventions aimed at improving attentional control and processing speed in MCIs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01433v2</guid>
      <category>q-bio.NC</category>
      <category>cs.SI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jatupong Oboun, Piyanon Charoenpoonpanich, Anna Raksapatcharawong, Chaipat Chunharas, Itthi Chatnuntawech, Chainarong Amornbunchornvej, Sirawaj Itthipuripat</dc:creator>
    </item>
    <item>
      <title>Parsimonious Gaussian mixture models with piecewise-constant eigenvalue profiles</title>
      <link>https://arxiv.org/abs/2507.01542</link>
      <description>arXiv:2507.01542v1 Announce Type: cross 
Abstract: Gaussian mixture models (GMMs) are ubiquitous in statistical learning, particularly for unsupervised problems. While full GMMs suffer from the overparameterization of their covariance matrices in high-dimensional spaces, spherical GMMs (with isotropic covariance matrices) certainly lack flexibility to fit certain anisotropic distributions. Connecting these two extremes, we introduce a new family of parsimonious GMMs with piecewise-constant covariance eigenvalue profiles. These extend several low-rank models like the celebrated mixtures of probabilistic principal component analyzers (MPPCA), by enabling any possible sequence of eigenvalue multiplicities. If the latter are prespecified, then we can naturally derive an expectation-maximization (EM) algorithm to learn the mixture parameters. Otherwise, to address the notoriously-challenging issue of jointly learning the mixture parameters and hyperparameters, we propose a componentwise penalized EM algorithm, whose monotonicity is proven. We show the superior likelihood-parsimony tradeoffs achieved by our models on a variety of unsupervised experiments: density fitting, clustering and single-image denoising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01542v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom Szwagier, Pierre-Alexandre Mattei, Charles Bouveyron, Xavier Pennec</dc:creator>
    </item>
    <item>
      <title>Using Wavelet Domain Fingerprints to Improve Source Camera Identification</title>
      <link>https://arxiv.org/abs/2507.01712</link>
      <description>arXiv:2507.01712v1 Announce Type: cross 
Abstract: Camera fingerprint detection plays a crucial role in source identification and image forensics, with wavelet denoising approaches proving to be particularly effective in extracting sensor pattern noise (SPN). In this article, we propose a modification to wavelet-based SPN extraction. Rather than constructing the fingerprint as an image, we introduce the notion of a wavelet domain fingerprint. This avoids the final inversion step of the denoising algorithm and allows fingerprint comparisons to be made directly in the wavelet domain. As such, our modification streamlines the extraction and comparison process. Experimental results on real-world datasets demonstrate that our method not only achieves higher detection accuracy but can also significantly improve processing speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.01712v1</guid>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinle Tian, Matthew Nunes, Emiko Dupont, Shaunagh Downing, Freddie Lichtenstein, Matt Burns</dc:creator>
    </item>
    <item>
      <title>New stochastic highway capacity estimation method and why product limit method is unsuitable</title>
      <link>https://arxiv.org/abs/2003.05355</link>
      <description>arXiv:2003.05355v2 Announce Type: replace 
Abstract: Kaplan-Meier estimate, commonly known as product limit method (PLM), and maximum likelihood estimate (MLE) methods in general are often cited as means of stochastic highway capacity estimation. This article discusses their unsuitability for such application as properties of traffic flow do not meet the assumptions for use of the methods. They assume the observed subject has a history which it went through and did not fail. However, due to its nature, each traffic flow measurement behaves as a separate subject which did not go through all the lower levels of intensity (did not "age"). An alternative method is proposed. It fits the resulting cumulative frequency of breakdowns with respect to the traffic flow intensity leading to the breakdown instead of directly estimating the underlying probability distribution of capacity. Analyses of accuracy and sensitivity to data quantity and censoring rate of the new method are provided along with comparison to the PLM. The results prove unsuitability of the PLM and MLE methods in general. The new method is then used in a case study which compares capacity of a work-zone with and without a traffic flow speed harmonisation system installed. The results confirm positive effect of harmonisation on capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2003.05355v2</guid>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Igor Mikolasek</dc:creator>
    </item>
    <item>
      <title>Inference on the state process of periodically inhomogeneous hidden Markov models for animal behavior</title>
      <link>https://arxiv.org/abs/2312.14583</link>
      <description>arXiv:2312.14583v2 Announce Type: replace-cross 
Abstract: Over the last decade, hidden Markov models (HMMs) have become increasingly popular in statistical ecology, where they constitute natural tools for studying animal behavior based on complex sensor data. Corresponding analyses sometimes explicitly focus on - and in any case need to take into account - periodic variation, for example by quantifying the activity distribution over the daily cycle or seasonal variation such as migratory behavior. For HMMs including periodic components, we establish important mathematical properties that allow for comprehensive statistical inference related to periodic variation, thereby also providing guidance for model building and model checking. Specifically, we derive the periodically varying unconditional state distribution as well as the time-varying and overall state dwell-time distributions - all of which are of key interest when the inferential focus lies on the dynamics of the state process. We use the associated novel inference and model-checking tools to investigate changes in the diel activity patterns of fruit flies in response to changing light conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14583v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan-Ole Koslik, Carlina C. Feldmann, Sina Mews, Rouven Michels, Roland Langrock</dc:creator>
    </item>
    <item>
      <title>Source Enumeration using the Distribution of Angles: A Robust and Parameter-Free Approach</title>
      <link>https://arxiv.org/abs/2409.06563</link>
      <description>arXiv:2409.06563v2 Announce Type: replace-cross 
Abstract: Source enumeration, the task of estimating the number of sources from the signal received by the array of antennas, is a critical problem in array signal processing. Numerous methods have been proposed to estimate the number of sources under white or colored Gaussian noise. However, their performance degrades significantly in the presence of a limited number of observations and/or a large number of sources. In this work, we propose a method leveraging the distribution of angles that performs well in (a) independent Gaussian, (b) spatially colored Gaussian, and (c) heavy-tailed noise, even when the number of sources is large. We support the supremacy of our algorithm over state-of-the-art methods with extensive simulation results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06563v2</guid>
      <category>eess.SP</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gokularam Muthukrishnan, Siva Shanmugam, Sheetal Kalyani</dc:creator>
    </item>
    <item>
      <title>Adapting Probabilistic Risk Assessment for AI</title>
      <link>https://arxiv.org/abs/2504.18536</link>
      <description>arXiv:2504.18536v3 Announce Type: replace-cross 
Abstract: Modern general-purpose artificial intelligence (AI) systems present an urgent risk management challenge, as their rapidly evolving capabilities and potential for catastrophic harm outpace our ability to reliably assess their risks. Current methods often rely on selective testing and undocumented assumptions about risk priorities, frequently failing to make a serious attempt at assessing the set of pathways through which AI systems pose direct or indirect risks to society and the biosphere. This paper introduces the probabilistic risk assessment (PRA) for AI framework, adapting established PRA techniques from high-reliability industries (e.g., nuclear power, aerospace) for the new challenges of advanced AI. The framework guides assessors in identifying potential risks, estimating likelihood and severity bands, and explicitly documenting evidence, underlying assumptions, and analyses at appropriate granularities. The framework's implementation tool synthesizes the results into a risk report card with aggregated risk estimates from all assessed risks. It introduces three methodological advances: (1) Aspect-oriented hazard analysis provides systematic hazard coverage guided by a first-principles taxonomy of AI system aspects (e.g. capabilities, domain knowledge, affordances); (2) Risk pathway modeling analyzes causal chains from system aspects to societal impacts using bidirectional analysis and incorporating prospective techniques; and (3) Uncertainty management employs scenario decomposition, reference scales, and explicit tracing protocols to structure credible projections with novelty or limited data. Additionally, the framework harmonizes diverse assessment methods by integrating evidence into comparable, quantified absolute risk estimates for lifecycle decisions. We have implemented this as a workbook tool for AI developers, evaluators, and regulators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.18536v3</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Katariina Wisakanto, Joe Rogero, Avyay M. Casheekar, Richard Mallah</dc:creator>
    </item>
    <item>
      <title>Inherited or produced? Inferring protein production kinetics when protein counts are shaped by a cell's division history</title>
      <link>https://arxiv.org/abs/2506.09374</link>
      <description>arXiv:2506.09374v3 Announce Type: replace-cross 
Abstract: Inferring protein production kinetics for dividing cells is complicated due to protein inheritance from the mother cell. For instance, fluorescence measurements -- commonly used to assess gene activation -- may reflect not only newly produced proteins but also those inherited through successive cell divisions. In such cases, observed protein levels in any given cell are shaped by its division history. As a case study, we examine activation of the glc3 gene in yeast involved in glycogen synthesis and expressed under nutrient-limiting conditions. We monitor this activity using snapshot fluorescence measurements via flow cytometry, where GFP expression reflects glc3 promoter activity. A na\"ive analysis of flow cytometry data ignoring cell division suggests many cells are active with low expression. Explicitly accounting for the (non-Markovian) effects of cell division and protein inheritance makes it impossible to write down a tractable likelihood -- a key ingredient in physics-inspired inference, defining the probability of observing data given a model. The dependence on a cell's division history breaks the assumptions of standard (Markovian) master equations, rendering traditional likelihood-based approaches inapplicable. Instead, we adapt conditional normalizing flows (a class of neural network models designed to learn probability distributions) to approximate otherwise intractable likelihoods from simulated data. In doing so, we find that glc3 is mostly inactive under stress, showing that while cells occasionally activate the gene, expression is brief and transient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09374v3</guid>
      <category>q-bio.QM</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Pedro Pessoa, Juan Andres Martinez, Vincent Vandenbroucke, Frank Delvigne, Steve Press\'e</dc:creator>
    </item>
  </channel>
</rss>
