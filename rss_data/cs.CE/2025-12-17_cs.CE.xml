<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Dec 2025 02:36:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Probabilistic Predictions of Process-Induced Deformation in Carbon/Epoxy Composites Using a Deep Operator Network</title>
      <link>https://arxiv.org/abs/2512.13746</link>
      <description>arXiv:2512.13746v1 Announce Type: new 
Abstract: Fiber reinforcement and polymer matrix respond differently to manufacturing conditions due to mismatch in coefficient of thermal expansion and matrix shrinkage during curing of thermosets. These heterogeneities generate residual stresses over multiple length scales, whose partial release leads to process-induced deformation (PID), requiring accurate prediction and mitigation via optimized non-isothermal cure cycles. This study considers a unidirectional AS4 carbon fiber/amine bi-functional epoxy prepreg and models PID using a two-mechanism framework that accounts for thermal expansion/shrinkage and cure shrinkage. The model is validated against manufacturing trials to identify initial and boundary conditions, then used to generate PID responses for a diverse set of non-isothermal cure cycles (time-temperature profiles). Building on this physics-based foundation, we develop a data-driven surrogate based on Deep Operator Networks (DeepONets). A DeepONet is trained on a dataset combining high-fidelity simulations with targeted experimental measurements of PID. We extend this to a Feature-wise Linear Modulation (FiLM) DeepONet, where branch-network features are modulated by external parameters, including the initial degree of cure, enabling prediction of time histories of degree of cure, viscosity, and deformation. Because experimental data are available only at limited time instances (for example, final deformation), we use transfer learning: simulation-trained trunk and branch networks are fixed and only the final layer is updated using measured final deformation. Finally, we augment the framework with Ensemble Kalman Inversion (EKI) to quantify uncertainty under experimental conditions and to support optimization of cure schedules for reduced PID in composites.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13746v1</guid>
      <category>cs.CE</category>
      <category>cond-mat.mtrl-sci</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Elham Kiyani, Amit Makarand Deshpande, Madhura Limaye, Zhiwei Gao, Sai Aditya Pradeep, Srikanth Pilla, Gang Li, Zhen Li, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Co-simulation errors due to step size changes</title>
      <link>https://arxiv.org/abs/2512.13845</link>
      <description>arXiv:2512.13845v1 Announce Type: new 
Abstract: When two simulation units in a continuous-time co-simulation are connected via some variable $q$, and both simulation units have an internal state which represents the time integral of $q$, there will generally be a discrepancy between those states due to extrapolation errors. Normally, such extrapolation errors diminish if the macro time step size is reduced. Here we show that, under certain circumstances, step size changes can cause such discrepancies to increase even when the change is towards smaller steps.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13845v1</guid>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars T. Kyllingstad</dc:creator>
    </item>
    <item>
      <title>Dynamic stacking ensemble learning with investor knowledge representations for stock market index prediction based on multi-source financial data</title>
      <link>https://arxiv.org/abs/2512.14042</link>
      <description>arXiv:2512.14042v1 Announce Type: new 
Abstract: The patterns of different financial data sources vary substantially, and accordingly, investors exhibit heterogeneous cognition behavior in information processing. To capture different patterns, we propose a novel approach called the two-stage dynamic stacking ensemble model based on investor knowledge representations, which aims to effectively extract and integrate the features from multi-source financial data. In the first stage, we identify different financial data property from global stock market indices, industrial indices, and financial news based on the perspective of investors. And then, we design appropriate neural network architectures tailored to these properties to generate effective feature representations. Based on learned feature representations, we design multiple meta-classifiers and dynamically select the optimal one for each time window, enabling the model to effectively capture and learn the distinct patterns that emerge across different temporal periods. To evaluate the performance of the proposed model, we apply it to predicting the daily movement of Shanghai Securities Composite index, SZSE Component index and Growth Enterprise index in Chinese stock market. The experimental results demonstrate the effectiveness of our model in improving the prediction performance. In terms of accuracy metric, our approach outperforms the best competing models by 1.42%, 7.94%, and 7.73% on the SSEC, SZEC, and GEI indices, respectively. In addition, we design a trading strategy based on the proposed model. The economic results show that compared to the competing trading strategies, our strategy delivers a superior performance in terms of the accumulated return and Sharpe ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14042v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruize Gao, Mei Yang, Yu Wang, Shaoze Cui</dc:creator>
    </item>
    <item>
      <title>Transfer Learning-Based Surrogate Modeling for Nonlinear Time-History Response Analysis of High-Fidelity Structural Models</title>
      <link>https://arxiv.org/abs/2512.14161</link>
      <description>arXiv:2512.14161v1 Announce Type: new 
Abstract: In a performance based earthquake engineering (PBEE) framework, nonlinear time-history response analysis (NLTHA) for numerous ground motions are required to assess the seismic risk of buildings or civil engineering structures. However, such numerical simulations are computationally expensive, limiting the real-world practical application of the framework. To address this issue, previous studies have used machine learning to predict the structural responses to ground motions with low computational costs. These studies typically conduct NLTHAs for a few hundreds ground motions and use the results to train and validate surrogate models. However, most of the previous studies focused on computationally-inexpensive response analysis models such as single degree of freedom. Surrogate models of high-fidelity response analysis are required to enrich the quantity and diversity of information used for damage assessment in PBEE. Notably, the computational cost of creating training and validation datasets increases if the fidelity of response analysis model becomes higher. Therefore, methods that enable surrogate modeling of high-fidelity response analysis without a large number of training samples are needed. This study proposes a framework that uses transfer learning to construct the surrogate model of a high-fidelity response analysis model. This framework uses a surrogate model of low-fidelity response analysis as the pretrained model and transfers its knowledge to construct surrogate models for high-fidelity response analysis with substantially reduced computational cost. As a case study, surrogate models that predict responses of a 20-story steel moment frame were constructed with only 20 samples as the training dataset. The responses to the ground motions predicted by constructed surrogate model were consistent with a site-specific time-based hazard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14161v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keiichi Ishikawa, Yuma Matsumoto, Taro Yaoyama, Sangwon Lee, Tatsuya Itoi</dc:creator>
    </item>
    <item>
      <title>A data-physics hybrid generative model for patient-specific post-stroke motor rehabilitation using wearable sensor data</title>
      <link>https://arxiv.org/abs/2512.14329</link>
      <description>arXiv:2512.14329v1 Announce Type: new 
Abstract: Dynamic prediction of locomotor capacity after stroke is crucial for tailoring rehabilitation, yet current assessments provide only static impairment scores and do not indicate whether patients can safely perform specific tasks such as slope walking or stair climbing. Here, we develop a data-physics hybrid generative framework that reconstructs an individual stroke survivor's neuromuscular control from a single 20 m level-ground walking trial and predicts task-conditioned locomotion across rehabilitation scenarios. The system combines wearable-sensor kinematics, a proportional-derivative physics controller, a population Healthy Motion Atlas, and goal-conditioned deep reinforcement learning with behaviour cloning and generative adversarial imitation learning to generate physically plausible, patient-specific gait simulations for slopes and stairs. In 11 stroke survivors, the personalized controllers preserved idiosyncratic gait patterns while improving joint-angle and endpoint fidelity by 4.73% and 12.10%, respectively, and reducing training time to 25.56% relative to a physics-only baseline. In a multicentre pilot involving 21 inpatients, clinicians who used our locomotion predictions to guide task selection and difficulty obtained larger gains in Fugl-Meyer lower-extremity scores over 28 days of standard rehabilitation than control clinicians (mean change 6.0 versus 3.7 points). These findings indicate that our generative, task-predictive framework can augment clinical decision-making in post-stroke gait rehabilitation and provide a template for dynamically personalized motor recovery strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14329v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanning Dai, Chenyu Tang, Ruizhi Zhang, Wenyu Yang, Yilan Zhang, Yuhui Wang, Junliang Chen, Xuhang Chen, Ruimou Xie, Yangyue Cao, Qiaoying Li, Jin Cao, Tao Li, Hubin Zhao, Yu Pan, Arokia Nathan, Xin Gao, Peter Smielewski, Shuo Gao</dc:creator>
    </item>
    <item>
      <title>BridgeNet: A Dataset of Graph-based Bridge Structural Models for Machine Learning Applications</title>
      <link>https://arxiv.org/abs/2512.14496</link>
      <description>arXiv:2512.14496v1 Announce Type: new 
Abstract: Machine learning (ML) is increasingly used in structural engineering and design, yet its broader adoption is hampered by the lack of openly accessible datasets of structural systems. We introduce BridgeNet, a publicly available graph-based dataset of 20,000 form-found bridge structures aimed at enabling Graph ML and multi-modal learning in the context of conceptual structural design. Each datapoint consists of (i) a pin-jointed equilibrium wireframe model generated with the Combinatorial Equilibrium Modeling (CEM) form-finding method, (ii) a volumetric 3D mesh obtained through force-informed materialization, and (iii) rendered images from two canonical camera angles. The resulting dataset is modality-rich and application-agnostic, supporting tasks such as CEM-specific edge classification and parameter inference, surrogate modeling of form-finding, cross-modal reconstruction between graphs, meshes and images, and generative structural design. BridgeNet addresses a key bottleneck in data-driven applications for structural engineering and design by providing a dataset that facilitates the development of new ML-based approaches for equilibrium bridge structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.14496v1</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lazlo Bleker, Mustafa Cem G\"une\c{s}, Pierluigi D'Acunto</dc:creator>
    </item>
    <item>
      <title>Numerical optimization of aviation decarbonization scenarios: balancing traffic and emissions with maturing energy carriers and aircraft technology</title>
      <link>https://arxiv.org/abs/2503.22435</link>
      <description>arXiv:2503.22435v3 Announce Type: replace 
Abstract: Despite being considered a hard-to-abate sector, aviation's emissions will play an important role in long-term climate mitigation of transportation. The introduction of low-carbon energy carriers and the deployment of new aircraft in the current fleet are modeled as technology-centered decarbonization policies, while supply constraints in targeted market segments are modeled as demand-side policies. Shared Socioeconomic Pathways (SSPs) are used to estimate trend-mitigation traffic demand and to limit the sectoral consumption of electricity and biomass. Mitigation scenarios are formulated as optimization problems, and three applications are demonstrated: no-policy baselines, single-policy optimization, and scenario-robust policies. Results show that the choice of energy carrier is highly dependent on assumptions regarding aircraft technology and the background energy system. Across all SSP-based scenarios, emissions peak by around 2040, but achieving alignment with the Paris Agreement requires either targeted demand management or additional low-carbon energy supply. The use of gradient-based optimization within a multidisciplinary framework enables the efficient resolution of these nonlinear, high-dimensional problems while reducing implementation effort.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22435v3</guid>
      <category>cs.CE</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ian Costa-Alves (ISAE-SUPAERO), Nicolas Gourdain (ISAE-SUPAERO), Fran\c{c}ois Gallard (ISAE-SUPAERO, ENAC), Anne Gazaix (ISAE-SUPAERO, ENAC), Yri Amandine Kambiri (ISAE-SUPAERO, ENAC), Thierry Druot (ENAC)</dc:creator>
    </item>
    <item>
      <title>Optimal Sizing and Material Choice for Additively Manufactured Compact Plate Heat Exchangers</title>
      <link>https://arxiv.org/abs/2504.03372</link>
      <description>arXiv:2504.03372v2 Announce Type: replace 
Abstract: Advances in additive manufacturing (AM) enable new opportunities to design compact heat exchangers (cHEXs) by leveraging flexible geometries to improve energy and material efficiency. However, it is well known that reducing size in counterflow cHEXs can degrade effectiveness due to axial heat conduction through the solid material, which depends strongly on material thermal conductivity and wall thickness. Understanding the interaction between fundamental heat transfer mechanisms and manufacturing constraints is essential for designing next generation compact thermal systems that fully exploit AM's shaping flexibility. This study investigates how material selection and AM thin wall limitations influence the maximum achievable power density in compact plate heat exchangers. An optimization framework evaluates six materials including plastic, austenitic steel, Al2O3, AlN, aluminum, and copper under fixed pressure drop and effectiveness, while accounting for AM specific thickness constraints and a minimum plate spacing to address fouling risks. Results show that copper consistently yields the lowest power density despite having the highest thermal conductivity, whereas plastic achieves the highest power density across most optimization scenarios. Without manufacturing or fouling constraints, plastic outperforms the baseline steel design by nearly three orders of magnitude. With uniform plate thickness or fouling constraints, the performance gap narrows, making plastic and austenitic steel comparable. When material specific thickness limits are applied, plastic again leads in compactness due to its superior thin wall manufacturability. These findings highlight that AM constraints strongly affect cHEX compactness and that lower conductivity materials can outperform metals such as copper in power dense heat exchanger designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03372v2</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehmet Basaran, Frederik Rogiers, Martine Baelmans, Maarten Blommaert</dc:creator>
    </item>
    <item>
      <title>Geospatial Soil Quality Analysis: A Roadmap for Integrated Systems</title>
      <link>https://arxiv.org/abs/2512.09817</link>
      <description>arXiv:2512.09817v2 Announce Type: replace 
Abstract: Soil quality (SQ) plays a crucial role in sustainable agriculture, environmental conservation, and land-use planning. Traditional SQ assessment techniques rely on costly, labor-intensive sampling and laboratory analysis, limiting their spatial and temporal coverage. Advances in Geographic Information Systems (GIS), remote sensing, and machine learning (ML) enabled efficient SQ evaluation. This paper presents a comprehensive roadmap distinguishing it from previous reviews by proposing a unified and modular pipeline that integrates multi-source soil data, GIS and remote sensing tools, and machine learning techniques to support transparent and scalable soil quality assessment. It also includes practical applications. Contrary to existing studies that predominantly target isolated soil parameters or specific modeling methodologies, this approach consolidates recent advancements in Geographic Information Systems (GIS), remote sensing technologies, and machine learning algorithms within the entire soil quality assessment pipeline. It also addresses existing challenges and limitations while exploring future developments and emerging trends in the field that can deliver the next generation of soil quality systems making them more transparent, adaptive, and aligned with sustainable land management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.09817v2</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Habiba Ben Abderrahmane, Slimane Oulad-Naoui, Benameur Ziani</dc:creator>
    </item>
    <item>
      <title>Optimizing Large Language Models for ESG Activity Detection in Financial Texts</title>
      <link>https://arxiv.org/abs/2502.21112</link>
      <description>arXiv:2502.21112v2 Announce Type: replace-cross 
Abstract: The integration of Environmental, Social, and Governance (ESG) factors into corporate decision-making is a fundamental aspect of sustainable finance. However, ensuring that business practices align with evolving regulatory frameworks remains a persistent challenge. AI-driven solutions for automatically assessing the alignment of sustainability reports and non-financial disclosures with specific ESG activities could greatly support this process. Yet, this task remains complex due to the limitations of general-purpose Large Language Models (LLMs) in domain-specific contexts and the scarcity of structured, high-quality datasets. In this paper, we investigate the ability of current-generation LLMs to identify text related to environmental activities. Furthermore, we demonstrate that their performance can be significantly enhanced through fine-tuning on a combination of original and synthetically generated data. To this end, we introduce ESG-Activities, a benchmark dataset containing 1,325 labelled text segments classified according to the EU ESG taxonomy. Our experimental results show that fine-tuning on ESG-Activities significantly enhances classification accuracy, with open models such as Llama 7B and Gemma 7B outperforming large proprietary solutions in specific configurations. These findings have important implications for financial analysts, policymakers, and AI researchers seeking to enhance ESG transparency and compliance through advanced natural language processing techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.21112v2</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3768292.3770371</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the ACM International Conference on AI in Finance (ICAIF), 2024, ACM</arxiv:journal_reference>
      <dc:creator>Mattia Birti, Andrea Maurino, Francesco Osborne</dc:creator>
    </item>
    <item>
      <title>CiRL: Open-Source Environments for Reinforcement Learning in Circular Economy and Net Zero</title>
      <link>https://arxiv.org/abs/2505.21536</link>
      <description>arXiv:2505.21536v2 Announce Type: replace-cross 
Abstract: The demand of finite raw materials will keep increasing as they fuel modern society. Simultaneously, solutions for stopping carbon emissions in the short term are not available, thus making the net zero target extremely challenging to achieve at scale. The circular economy (CE) paradigm is gaining attention as a solution to address climate change and the uncertainties of supplies of critical materials. Hence, in this paper, we introduce CiRL, a deep reinforcement learning (DRL) library of environments focused on the circularity control of both solid and fluid materials. The integration of DRL into the design of material circularity is possible thanks to the formalism of thermodynamical material networks, which is underpinned by compartmental dynamical thermodynamics. Along with the focus on circularity, this library has three more features: the new CE-oriented environments are in the state-space form, which is typically used in dynamical systems analysis and control design; it is based on a state-of-the-art Python library of DRL algorithms, namely, Stable-Baselines3; and it is developed in Google Colaboratory to be accessible to researchers from different disciplines and backgrounds as is often the case for circular economy researchers and engineers. CiRL is intended to be a tool to generate AI-driven actions for optimizing the circularity of supply-recovery chains and to be combined with human-driven decisions derived from material flow analysis (MFA) studies. CiRL is publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.21536v2</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 17 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Federico Zocco, Andrea Corti, Monica Malvezzi</dc:creator>
    </item>
  </channel>
</rss>
