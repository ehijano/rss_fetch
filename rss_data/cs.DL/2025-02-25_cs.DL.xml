<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DL</link>
    <description>cs.DL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 26 Feb 2025 02:55:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>ACL-rlg: A Dataset for Reading List Generation</title>
      <link>https://arxiv.org/abs/2502.15692</link>
      <description>arXiv:2502.15692v1 Announce Type: new 
Abstract: Familiarizing oneself with a new scientific field and its existing literature can be daunting due to the large amount of available articles. Curated lists of academic references, or reading lists, compiled by experts, offer a structured way to gain a comprehensive overview of a domain or a specific scientific challenge. In this work, we introduce ACL-rlg, the largest open expert-annotated reading list dataset. We also provide multiple baselines for evaluating reading list generation and formally define it as a retrieval task. Our qualitative study highlights the fact that traditional scholarly search engines and indexing methods perform poorly on this task, and GPT-4o, despite showing better results, exhibits signs of potential data contamination.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15692v1</guid>
      <category>cs.DL</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The 31st International Conference on Computational Linguistics, Jan 2025, Abu Dhabi, United Arab Emirates</arxiv:journal_reference>
      <dc:creator>Julien Aubert-B\'educhaud (LS2N), Florian Boudin (LS2N, JFLI), B\'eatrice Daille (LS2N), Richard Dufour (LS2N)</dc:creator>
    </item>
    <item>
      <title>iTRI-QA: a Toolset for Customized Question-Answer Dataset Generation Using Language Models for Enhanced Scientific Research</title>
      <link>https://arxiv.org/abs/2502.15721</link>
      <description>arXiv:2502.15721v1 Announce Type: cross 
Abstract: The exponential growth of AI in science necessitates efficient and scalable solutions for retrieving and preserving research information. Here, we present a tool for the development of a customized question-answer (QA) dataset, called Interactive Trained Research Innovator (iTRI) - QA, tailored for the needs of researchers leveraging language models (LMs) to retrieve scientific knowledge in a QA format. Our approach integrates curated QA datasets with a specialized research paper dataset to enhance responses' contextual relevance and accuracy using fine-tuned LM. The framework comprises four key steps: (1) the generation of high-quality and human-generated QA examples, (2) the creation of a structured research paper database, (3) the fine-tuning of LMs using domain-specific QA examples, and (4) the generation of QA dataset that align with user queries and the curated database. This pipeline provides a dynamic and domain-specific QA system that augments the utility of LMs in academic research that will be applied for future research LM deployment. We demonstrate the feasibility and scalability of our tool for streamlining knowledge retrieval in scientific contexts, paving the way for its integration into broader multi-disciplinary applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15721v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DL</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiming Liu, Zhongzheng Niu, Siting Liu, Mao Tian</dc:creator>
    </item>
    <item>
      <title>On the Effectiveness of Large Language Models in Automating Categorization of Scientific Texts</title>
      <link>https://arxiv.org/abs/2502.15745</link>
      <description>arXiv:2502.15745v1 Announce Type: cross 
Abstract: The rapid advancement of Large Language Models (LLMs) has led to a multitude of application opportunities. One traditional task for Information Retrieval systems is the summarization and classification of texts, both of which are important for supporting humans in navigating large literature bodies as they e.g. exist with scientific publications. Due to this rapidly growing body of scientific knowledge, recent research has been aiming at building research information systems that not only offer traditional keyword search capabilities, but also novel features such as the automatic detection of research areas that are present at knowledge intensive organizations in academia and industry. To facilitate this idea, we present the results obtained from evaluating a variety of LLMs in their ability to sort scientific publications into hierarchical classifications systems. Using the FORC dataset as ground truth data, we have found that recent LLMs (such as Meta Llama 3.1) are able to reach an accuracy of up to 0.82, which is up to 0.08 better than traditional BERT models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15745v1</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gautam Kishore Shahi, Oliver Hummel</dc:creator>
    </item>
    <item>
      <title>Automatic Detection of Research Values from Scientific Abstracts Across Computer Science Subfields</title>
      <link>https://arxiv.org/abs/2502.16390</link>
      <description>arXiv:2502.16390v1 Announce Type: cross 
Abstract: The field of Computer science (CS) has rapidly evolved over the past few decades, providing computational tools and methodologies to various fields and forming new interdisciplinary communities. This growth in CS has significantly impacted institutional practices and relevant research communities. Therefore, it is crucial to explore what specific \textbf{research values}, known as \textbf{basic and fundamental beliefs that guide or motivate research attitudes or actions}, CS-related research communities promote. Prior research has manually analyzed research values from a small sample of machine learning papers \cite{facct}. No prior work has studied the automatic detection of research values in CS from large-scale scientific texts across different research subfields. This paper introduces a detailed annotation scheme featuring \textbf{ten research values} that guide CS-related research. Based on the scheme, we build value classifiers to scale up the analysis and present a systematic study over 226,600 paper abstracts from 32 CS-related subfields and 86 popular publishing venues over ten years.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16390v1</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hang Jiang, Tal August, Luca Soldaini, Kyle Lo, Maria Antoniak</dc:creator>
    </item>
    <item>
      <title>Optimal Salaries of Researchers with Motivational Emergence</title>
      <link>https://arxiv.org/abs/2502.17271</link>
      <description>arXiv:2502.17271v1 Announce Type: cross 
Abstract: In the context of scientific policy and science management, this study examines the system of nonuniform wage distribution for researchers. A nonlinear mathematical model of optimal remuneration for scientific workers has been developed, considering key and additive aspects of scientific activity: basic qualifications, research productivity, collaborative projects, skill enhancement, distinctions, and international collaborations. Unlike traditional linear schemes, the proposed approach is based on exponential and logarithmic dependencies, allowing for the consideration of saturation effects and preventing artificial wage growth due to mechanical increases in scientific productivity indicators.
  The study includes detailed calculations of optimal, minimum, and maximum wages, demonstrating a fair distribution of remuneration on the basis of researcher productivity. A linear increase in publication activity or grant funding should not lead to uncontrolled salary growth, thus avoiding distortions in the motivational system. The results of this study can be used to reform and modernize the wage system for researchers in Kazakhstan and other countries, as well as to optimize grant-based science funding mechanisms. The proposed methodology fosters scientific motivation, long-term productivity, and the internationalization of research while also promoting self-actualization and ultimately forming an adequate and authentic reward system for the research community.
  Specifically, in resource-limited scientific systems, science policy should focus on the qualitative development of individual researchers rather than quantitative expansion (e.g., increasing the number of scientists). This can be achieved through the productive progress of their motivation and self-actualization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17271v1</guid>
      <category>econ.EM</category>
      <category>cs.DL</category>
      <category>econ.TH</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eldar Knar</dc:creator>
    </item>
    <item>
      <title>Author Intent: Eliminating Ambiguity in MathML</title>
      <link>https://arxiv.org/abs/2407.06720</link>
      <description>arXiv:2407.06720v2 Announce Type: replace 
Abstract: MathML has been successful in improving the accessibility of mathematical notation on the web. All major screen readers support MathML to generate speech, allow navigation of the math, and generate braille. A troublesome area remains: handling ambiguous notations such as \( \vert x\vert\). While it is possible to speak this syntactically, anecdotal evidence indicates most people prefer semantic speech such as ``absolute value of x'' or ``determinant of x'' instead of ``vertical bar x vertical bar'' when first hearing an expression. Several heuristics to infer semantics have improved speech, but ultimately, the author is the one who definitively knows how an expression is meant to be spoken. The W3C Math Working Group is in the process of allowing authors to convey their intent in MathML markup via an intent attribute. This paper describes that work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06720v2</guid>
      <category>cs.DL</category>
      <category>cs.HC</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Carlisle, Paul Libbrecht, Moritz Schubotz, Neil Soiffer</dc:creator>
    </item>
    <item>
      <title>Applying the FAIR Principles to computational workflows</title>
      <link>https://arxiv.org/abs/2410.03490</link>
      <description>arXiv:2410.03490v2 Announce Type: replace 
Abstract: Recent trends within computational and data sciences show an increasing recognition and adoption of computational workflows as tools for productivity and reproducibility that also democratize access to platforms and processing know-how. As digital objects to be shared, discovered, and reused, computational workflows benefit from the FAIR principles, which stand for Findable, Accessible, Interoperable, and Reusable. The Workflows Community Initiative's FAIR Workflows Working Group (WCI-FW), a global and open community of researchers and developers working with computational workflows across disciplines and domains, has systematically addressed the application of both FAIR data and software principles to computational workflows. We present recommendations with commentary that reflects our discussions and justifies our choices and adaptations. These are offered to workflow users and authors, workflow management system developers, and providers of workflow services as guidelines for adoption and fodder for discussion. The FAIR recommendations for workflows that we propose in this paper will maximize their value as research assets and facilitate their adoption by the wider community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03490v2</guid>
      <category>cs.DL</category>
      <category>cs.SE</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41597-025-04451-9</arxiv:DOI>
      <dc:creator>Sean R. Wilkinson, Meznah Aloqalaa, Khalid Belhajjame, Michael R. Crusoe, Bruno de Paula Kinoshita, Luiz Gadelha, Daniel Garijo, Ove Johan Ragnar Gustafsson, Nick Juty, Sehrish Kanwal, Farah Zaib Khan, Johannes K\"oster, Karsten Peters-von Gehlen, Line Pouchard, Randy K. Rannow, Stian Soiland-Reyes, Nicola Soranzo, Shoaib Sufi, Ziheng Sun, Baiba Vilne, Merridee A. Wouters, Denis Yuen, Carole Goble</dc:creator>
    </item>
    <item>
      <title>VTechAGP: An Academic-to-General-Audience Text Paraphrase Dataset and Benchmark Models</title>
      <link>https://arxiv.org/abs/2411.04825</link>
      <description>arXiv:2411.04825v2 Announce Type: replace-cross 
Abstract: Existing text simplification or paraphrase datasets mainly focus on sentence-level text generation in a general domain. These datasets are typically developed without using domain knowledge. In this paper, we release a novel dataset, VTechAGP, which is the first academic-to-general-audience text paraphrase dataset consisting of document-level these and dissertation academic and general-audience abstract pairs from 8 colleges authored over 25 years. We also propose a novel dynamic soft prompt generative language model, DSPT5. For training, we leverage a contrastive-generative loss function to learn the keyword vectors in the dynamic prompt. For inference, we adopt a crowd-sampling decoding strategy at both semantic and structural levels to further select the best output candidate. We evaluate DSPT5 and various state-of-the-art large language models (LLMs) from multiple perspectives. Results demonstrate that the SOTA LLMs do not provide satisfactory outcomes, while the lightweight DSPT5 can achieve competitive results. To the best of our knowledge, we are the first to build a benchmark dataset and solutions for academic-to-general-audience text paraphrase dataset. Models will be public after acceptance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04825v2</guid>
      <category>cs.CL</category>
      <category>cs.DL</category>
      <category>cs.LG</category>
      <pubDate>Tue, 25 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ming Cheng, Jiaying Gong, Chenhan Yuan, William A. Ingram, Edward Fox, Hoda Eldardiry</dc:creator>
    </item>
  </channel>
</rss>
