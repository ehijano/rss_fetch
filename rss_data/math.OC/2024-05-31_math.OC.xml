<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 31 May 2024 04:00:26 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 31 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tropical Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.19551</link>
      <description>arXiv:2405.19551v1 Announce Type: new 
Abstract: We propose a gradient descent method for solving optimisation problems arising in settings of tropical geometry - a variant of algebraic geometry that has become increasingly studied in applications such as computational biology, economics, and computer science. Our approach takes advantage of the polyhedral and combinatorial structures arising in tropical geometry to propose a versatile approach for approximating local minima in tropical statistical optimisation problems - a rapidly growing body of work in recent years. Theoretical results establish global solvability for 1-sample problems and a convergence rate of $O(1/\sqrt{k})$. Numerical experiments demonstrate the method's superior performance over classical descent for tropical optimisation problems which exhibit tropical convexity but not classical convexity. Notably, tropical descent seamlessly integrates into advanced optimisation methods, such as Adam, offering improved overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19551v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roan Talbut, Anthea Monod</dc:creator>
    </item>
    <item>
      <title>The High Line: Exact Risk and Learning Rate Curves of Stochastic Adaptive Learning Rate Algorithms</title>
      <link>https://arxiv.org/abs/2405.19585</link>
      <description>arXiv:2405.19585v1 Announce Type: new 
Abstract: We develop a framework for analyzing the training and learning rate dynamics on a large class of high-dimensional optimization problems, which we call the high line, trained using one-pass stochastic gradient descent (SGD) with adaptive learning rates. We give exact expressions for the risk and learning rate curves in terms of a deterministic solution to a system of ODEs. We then investigate in detail two adaptive learning rates -- an idealized exact line search and AdaGrad-Norm -- on the least squares problem. When the data covariance matrix has strictly positive eigenvalues, this idealized exact line search strategy can exhibit arbitrarily slower convergence when compared to the optimal fixed learning rate with SGD. Moreover we exactly characterize the limiting learning rate (as time goes to infinity) for line search in the setting where the data covariance has only two distinct eigenvalues. For noiseless targets, we further demonstrate that the AdaGrad-Norm learning rate converges to a deterministic constant inversely proportional to the average eigenvalue of the data covariance matrix, and identify a phase transition when the covariance density of eigenvalues follows a power law distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19585v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Elizabeth Collins-Woodfin, Inbar Seroussi, Bego\~na Garc\'ia Malaxechebarr\'ia, Andrew W. Mackenzie, Elliot Paquette, Courtney Paquette</dc:creator>
    </item>
    <item>
      <title>Bilevel reinforcement learning via the development of hyper-gradient without lower-level convexity</title>
      <link>https://arxiv.org/abs/2405.19697</link>
      <description>arXiv:2405.19697v1 Announce Type: new 
Abstract: Bilevel reinforcement learning (RL), which features intertwined two-level problems, has attracted growing interest recently. The inherent non-convexity of the lower-level RL problem is, however, to be an impediment to developing bilevel optimization methods. By employing the fixed point equation associated with the regularized RL, we characterize the hyper-gradient via fully first-order information, thus circumventing the assumption of lower-level convexity. This, remarkably, distinguishes our development of hyper-gradient from the general AID-based bilevel frameworks since we take advantage of the specific structure of RL problems. Moreover, we propose both model-based and model-free bilevel reinforcement learning algorithms, facilitated by access to the fully first-order hyper-gradient. Both algorithms are provable to enjoy the convergence rate $\mathcal{O}(\epsilon^{-1})$. To the best of our knowledge, this is the first time that AID-based bilevel RL gets rid of additional assumptions on the lower-level problem. In addition, numerical experiments demonstrate that the hyper-gradient indeed serves as an integration of exploitation and exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19697v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Yang, Bin Gao, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Generalized Bayesian Nash Equilibrium with Continuous Type and Action Spaces</title>
      <link>https://arxiv.org/abs/2405.19721</link>
      <description>arXiv:2405.19721v1 Announce Type: new 
Abstract: Bayesian game is a strategic decision-making model where each player's type parameter characterizing its own objective is private information: each player knows its own type but not its rivals' types, and Bayesian Nash equilibrium (BNE) is an outcome of this game where each player makes a strategic optimal decision according to its own type under the Nash conjecture. In this paper, we advance the literature by considering a generalized Bayesian game where each player's action space depends on its own type parameter and the rivals' actions. This reflects the fact that in practical applications, a firm's feasible action is often related to its own type (e.g. marginal cost) and the rivals' actions (e.g. common resource constraints in a competitive market). Under some moderate conditions, we demonstrate existence of continuous generalized Bayesian Nash equilibria (GBNE) and uniqueness of such an equilibrium when each player's action space is only dependent on its type. In the case that each player's action space is also dependent on rivals' actions, we give a simple example to show that uniqueness of GBNE is not guaranteed under standard monotone conditions. To compute an approximate GBNE, we restrict each player's response function to the space of polynomial functions of its type parameter and consequently convert the GBNE problem to a stochastic generalized Nash equilibrium problem (SGNE). To justify the approximation, we discuss convergence of the approximation scheme. Some preliminary numerical test results show that the approximation scheme works well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19721v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Tao, Huifu Xu</dc:creator>
    </item>
    <item>
      <title>MIP-DD: A Delta Debugger for Mixed Integer Programming Solvers</title>
      <link>https://arxiv.org/abs/2405.19770</link>
      <description>arXiv:2405.19770v1 Announce Type: new 
Abstract: The recent performance improvements in mixed-integer programming (MIP) went along with a significantly increased complexity of the codes of MIP solvers, which poses challenges in fixing implementation errors. Traditionally, debugging in MIP solvers is done by either adding assertions, debug solution checks, or using a bidirectional debugger. Especially in larger instances, none of these approaches guarantees success since still a deep understanding of the code is required. In this paper, we introduce MIP-DD, a solver-independent tool, which is, to the best of our knowledge, the first open-source delta debugger for MIP. Delta debugging is a hypothesis-trial-result approach to isolate the cause of a solver failure. MIP-DD simplifies MIP instances while maintaining the undesired behavior and already supported and motivated fixes for many bugs in the SCIP releases 8.0.4, 8.1.0, and 9.0.0. This translates to an increase of approximately 71.% more bugfixes than in the same time period before and including some fixes of long-known issues. As we highlight in selected case studies, instances triggering fundamental bugs in SCIP can typically be reduced to a few variables and constraints in less than an hour. This makes it significantly easier to manually trace and check the solution process on the resulting simplified instances. A promising future application of MIP-DD is the analysis of performance bottlenecks, which could very well benefit from simple adversarial instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19770v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Hoen, Dominik Kamp, Ambros Gleixner</dc:creator>
    </item>
    <item>
      <title>Study of the behaviour of Nesterov Accelerated Gradient in a non convex setting: the strongly quasar convex case</title>
      <link>https://arxiv.org/abs/2405.19809</link>
      <description>arXiv:2405.19809v1 Announce Type: new 
Abstract: We study the convergence of Nesterov Accelerated Gradient (NAG) minimization algorithm applied to a class of non convex functions called strongly quasar convex functions, which can exhibit highly non convex behaviour.    We show that in the case of strongly quasar convex functions, NAG can achieve an accelerated convergence speed at the cost of a lower curvature assumption. We provide a continuous analysis through high resolution ODEs, in which negative friction may appear. Finally, we investigate connections with a weaker class of non convex functions (smooth Polyak-\L ojasiewicz functions) by characterizing the gap between this class and the one of smooth strongly quasar convex functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19809v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>J Hermant (IMB), J. -F Aujol (IMB), C Dossal (INSA Toulouse, IMT), A Rondepierre (INSA Toulouse, IMT)</dc:creator>
    </item>
    <item>
      <title>A structured L-BFGS method with diagonal scaling and its application to image registration</title>
      <link>https://arxiv.org/abs/2405.19834</link>
      <description>arXiv:2405.19834v1 Announce Type: new 
Abstract: We devise an L-BFGS method for optimization problems in which the objective is the sum of two functions, where the Hessian of the first function is computationally unavailable while the Hessian of the second function has a computationally available approximation that allows for cheap matrix-vector products. This is a prototypical setting for many inverse problems. The proposed L-BFGS method exploits the structure of the objective to construct a more accurate Hessian approximation than in standard L-BFGS. In contrast to existing works on structured L-BFGS, we choose the first part of the seed matrix, which approximates the Hessian of the first function, as a diagonal matrix rather than a multiple of the identity. We derive two suitable formulas for the coefficients of the diagonal matrix and show that this boosts performance on real-life image registration problems, which are highly non-convex inverse problems. The new method converges globally and linearly on non-convex problems under mild assumptions in a general Hilbert space setting, making it applicable to a broad class of inverse problems. An implementation of the method is freely available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19834v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Mannel, Hari Om Aggrawal</dc:creator>
    </item>
    <item>
      <title>A Simple Linear Convergence Analysis of the Point-SAGA Algorithm</title>
      <link>https://arxiv.org/abs/2405.19951</link>
      <description>arXiv:2405.19951v1 Announce Type: new 
Abstract: Point-SAGA is a randomized algorithm for minimizing a sum of convex functions using their proximity operators (proxs), proposed by Defazio (2016). At every iteration, the prox of only one randomly chosen function is called. We generalize the algorithm to any number of prox calls per iteration, not only one, and propose a simple proof of linear convergence when the functions are smooth and strongly convex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19951v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Condat, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Analyzing the impact of forecast errors in the planning of wine grape harvesting operations using a multi-stage stochastic model approach</title>
      <link>https://arxiv.org/abs/2405.19997</link>
      <description>arXiv:2405.19997v1 Announce Type: new 
Abstract: Forecasts and future beliefs play a critical role in the harvest labor hiring planning, especially when errors in them entails fixing previous made decisions, which can carry extra costs or losses. In this article, we study the effect that errors in the forecast/belief can have in the wine grape harvest planning process and the losses of the product. Errors are reflected in the prediction of yields and in the estimation of rain transition probabilities have on the value and losses of product. Also, using a multi-stage stochastic optimization model we can study the effect that second stage decisions have on the ability fix the planning decisions, reduce product losses and generate value. In a first step, we develop a multi-stage stochastic model which considers grape growth uncertainty given a belief in future events. The model decisions variables are: hiring, firing and maintaining harvest labor through periods, and also the harvested quantities in each period and block. Once the model defines the plan for the coming epoch, some decisions are implemented and a deviation in the forecast is revealed and the decision maker can adjust future decisions and beliefs. Results indicate that the effect of the errors in yield determination is not symmetrical; underestimations of the yields have a more significant negative effect on the objective function, while overestimation does not. Flexibility to revise hiring decisions does not make a significant difference if the yields are overestimated. The model significantly reduces losses of the better-quality grapes, since they correspond to a significant proportion of the income and account for the largest portion of income loss. Last, grapes that have an early improvement of their quality give the decision-maker an extra level of flexibility to adjust the harvesting plan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19997v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alejandro Milani, Alejandro Mac Cawley</dc:creator>
    </item>
    <item>
      <title>Control in the Coefficients of an Obstacle Problem</title>
      <link>https://arxiv.org/abs/2405.20074</link>
      <description>arXiv:2405.20074v1 Announce Type: new 
Abstract: In this work, we consider optimality conditions of an optimal control problem governed by an obstacle problem. Here, we focus on introducing a, matrix valued, control variable as the coefficients of the obstacle problem. As it is well known, obstacle problems can be formulated as a complementarity system and consequently the associated solution operator is not Gateaux differentiable. As a consequence, we utilize a regularization approach to obtain optimality conditions as the limit of optimality conditions of a family of regularized problems.
  Due to the coupling of the controlled coefficient with the gradients of the solution to the obstacle problem, weak convergence arguments can not be applied and we need to argue by $H$-convergence. We show, that, based on initial $H$-convergence, a bootstrapping argument can be utilized to prove strong $L^p$-convergence of the control and thus enable the passage to the limit in the optimality conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20074v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolai Simon, Winnifried Wollner</dc:creator>
    </item>
    <item>
      <title>Complexity of Zeroth- and First-order Stochastic Trust-Region Algorithms</title>
      <link>https://arxiv.org/abs/2405.20116</link>
      <description>arXiv:2405.20116v1 Announce Type: new 
Abstract: Model update (MU) and candidate evaluation (CE) are classical steps incorporated inside many stochastic trust-region (TR) algorithms. The sampling effort exerted within these steps, often decided with the aim of controlling model error, largely determines a stochastic TR algorithm's sample complexity. Given that MU and CE are amenable to variance reduction, we investigate the effect of incorporating common random numbers (CRN) within MU and CE on complexity. Using ASTRO and ASTRO-DF as prototype first-order and zeroth-order families of algorithms, we demonstrate that CRN's effectiveness leads to a range of complexities depending on sample-path regularity and the oracle order. For instance, we find that in first-order oracle settings with smooth sample paths, CRN's effect is pronounced -- ASTRO with CRN achieves $\tilde{O}(\epsilon^{-2})$ a.s. sample complexity compared to $\tilde{O}(\epsilon^{-6})$ a.s. in the generic no-CRN setting. By contrast, CRN's effect is muted when the sample paths are not Lipschitz, with the sample complexity improving from $\tilde{O}(\epsilon^{-6})$ a.s. to $\tilde{O}(\epsilon^{-5})$ and $\tilde{O}(\epsilon^{-4})$ a.s. in the zeroth- and first-order settings, respectively. Since our results imply that improvements in complexity are largely inherited from generic aspects of variance reduction, e.g., finite-differencing for zeroth-order settings and sample-path smoothness for first-order settings within MU, we anticipate similar trends in other contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20116v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunsoo Ha, Sara Shashaani, Raghu Pasupathy</dc:creator>
    </item>
    <item>
      <title>Exact resolution of a simultaneous vehicle routing and crew scheduling problem in long-haul transport</title>
      <link>https://arxiv.org/abs/2405.20123</link>
      <description>arXiv:2405.20123v1 Announce Type: new 
Abstract: This work focuses on exact methods for a Simultaneous Vehicle Routing and Crew Scheduling Problem in long-haul transport. Pickup-and-delivery requests with time windows must be fullfiled over a multi-day planning horizon. Unlike some classic approaches, the correspondence between trucks and drivers is not fixed and they can be exchanged in some locations and at any time. Drivers can also travel for free as truck passengers or take external taxis for an additional cost. The objective is to minimise the truck and taxi travel costs and the penalties for late deliveries. Routes for trucks and drivers are represented separately as directed paths in certain digraphs and then synchronised in time and space. Three compact Integer Linear Programming formulations are proposed and many families of valid inequalities are described. Extensive computational experiments are conducted on randomly generated instances. The formulations are experimentally compared and the effectiveness of the proposed valid inequalities as cutting planes in a branch-and-cut algorithm is evaluated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20123v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mauro Lucci, Daniel Severin, Paula Zabala</dc:creator>
    </item>
    <item>
      <title>SPAM: Stochastic Proximal Point Method with Momentum Variance Reduction for Non-convex Cross-Device Federated Learning</title>
      <link>https://arxiv.org/abs/2405.20127</link>
      <description>arXiv:2405.20127v1 Announce Type: new 
Abstract: Cross-device training is a crucial subfield of federated learning, where the number of clients can reach into the billions. Standard approaches and local methods are prone to issues such as client drift and insensitivity to data similarities. We propose a novel algorithm (SPAM) for cross-device federated learning with non-convex losses, which solves both issues. We provide sharp analysis under second-order (Hessian) similarity, a condition satisfied by a variety of machine learning problems in practice. Additionally, we extend our results to the partial participation setting, where a cohort of selected clients communicate with the server at each communication round. Our method is the first in its kind, that does not require the smoothness of the objective and provably benefits from clients having similar data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20127v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Avetik Karagulyan, Egor Shulgin, Abdurakhmon Sadiev, Peter Richt\'arik</dc:creator>
    </item>
    <item>
      <title>Convergence Analysis for A Stochastic Maximum Principle Based Data Driven Feedback Control Algorithm</title>
      <link>https://arxiv.org/abs/2405.20182</link>
      <description>arXiv:2405.20182v1 Announce Type: new 
Abstract: This paper presents convergence analysis of a novel data-driven feedback control algorithm designed for generating online controls based on partial noisy observational data. The algorithm comprises a particle filter-enabled state estimation component, estimating the controlled system's state via indirect observations, alongside an efficient stochastic maximum principle type optimal control solver. By integrating weak convergence techniques for the particle filter with convergence analysis for the stochastic maximum principle control solver, we derive a weak convergence result for the optimization procedure in search of optimal data-driven feedback control. Numerical experiments are performed to validate the theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20182v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siming Liang, Hui Sun, Richard Archibald, Feng Bao</dc:creator>
    </item>
    <item>
      <title>Lasso-based state estimation for cyber-physical systems under sensor attacks</title>
      <link>https://arxiv.org/abs/2405.20209</link>
      <description>arXiv:2405.20209v1 Announce Type: new 
Abstract: The development of algorithms for secure state estimation in vulnerable cyber-physical systems has been gaining attention in the last years. A consolidated assumption is that an adversary can tamper a relatively small number of sensors. In the literature, block-sparsity methods exploit this prior information to recover the attack locations and the state of the system.
  In this paper, we propose an alternative, Lasso-based approach and we analyse its effectiveness. In particular, we theoretically derive conditions that guarantee successful attack/state recovery, independently of established time sparsity patterns. Furthermore, we develop a sparse state observer, by starting from the iterative soft thresholding algorithm for Lasso, to perform online estimation.
  Through several numerical experiments, we compare the proposed methods to the state-of-the-art algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20209v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Vito Cerone, Sophie M. Fosson, Diego Regruto, Francesco Ripa</dc:creator>
    </item>
    <item>
      <title>Entropy annealing for policy mirror descent in continuous time and space</title>
      <link>https://arxiv.org/abs/2405.20250</link>
      <description>arXiv:2405.20250v1 Announce Type: new 
Abstract: Entropy regularization has been extensively used in policy optimization algorithms to regularize the optimization landscape and accelerate convergence; however, it comes at the cost of introducing an additional regularization bias. This work quantifies the impact of entropy regularization on the convergence of policy gradient methods for stochastic exit time control problems. We analyze a continuous-time policy mirror descent dynamics, which updates the policy based on the gradient of an entropy-regularized value function and adjusts the strength of entropy regularization as the algorithm progresses. We prove that with a fixed entropy level, the dynamics converges exponentially to the optimal solution of the regularized problem. We further show that when the entropy level decays at suitable polynomial rates, the annealed flow converges to the solution of the unregularized problem at a rate of $\mathcal O(1/S)$ for discrete action spaces and, under suitable conditions, at a rate of $\mathcal O(1/\sqrt{S})$ for general action spaces, with $S$ being the gradient flow time. This paper explains how entropy regularization improves policy optimization, even with the true gradient, from the perspective of convergence rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20250v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deven Sethi, David \v{S}i\v{s}ka, Yufei Zhang</dc:creator>
    </item>
    <item>
      <title>Sampling Theorem and interpolation formula for non-vanishing signals</title>
      <link>https://arxiv.org/abs/2405.10007</link>
      <description>arXiv:2405.10007v4 Announce Type: cross 
Abstract: The paper establishes an analog Whittaker-Shannon-Kotelnikov sampling theorem with fast decreasing coefficient, as well as a new modification of the corresponding interpolation formula applicable for general type non-vanishing bounded continuous signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10007v4</guid>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolai Dokuchaev</dc:creator>
    </item>
    <item>
      <title>On the Convergence of Multi-objective Optimization under Generalized Smoothness</title>
      <link>https://arxiv.org/abs/2405.19440</link>
      <description>arXiv:2405.19440v1 Announce Type: cross 
Abstract: Multi-objective optimization (MOO) is receiving more attention in various fields such as multi-task learning. Recent works provide some effective algorithms with theoretical analysis but they are limited by the standard $L$-smooth or bounded-gradient assumptions, which are typically unsatisfactory for neural networks, such as recurrent neural networks (RNNs) and transformers. In this paper, we study a more general and realistic class of $\ell$-smooth loss functions, where $\ell$ is a general non-decreasing function of gradient norm. We develop two novel single-loop algorithms for $\ell$-smooth MOO problems, Generalized Smooth Multi-objective Gradient descent (GSMGrad) and its stochastic variant, Stochastic Generalized Smooth Multi-objective Gradient descent (SGSMGrad), which approximate the conflict-avoidant (CA) direction that maximizes the minimum improvement among objectives. We provide a comprehensive convergence analysis of both algorithms and show that they converge to an $\epsilon$-accurate Pareto stationary point with a guaranteed $\epsilon$-level average CA distance (i.e., the gap between the updating direction and the CA direction) over all iterations, where totally $\mathcal{O}(\epsilon^{-2})$ and $\mathcal{O}(\epsilon^{-4})$ samples are needed for deterministic and stochastic settings, respectively. Our algorithms can also guarantee a tighter $\epsilon$-level CA distance in each iteration using more samples. Moreover, we propose a practical variant of GSMGrad named GSMGrad-FA using only constant-level time and space, while achieving the same performance guarantee as GSMGrad. Our experiments validate our theory and demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19440v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qi Zhang, Peiyao Xiao, Kaiyi Ji, Shaofeng Zou</dc:creator>
    </item>
    <item>
      <title>Stochastic Optimization Algorithms for Instrumental Variable Regression with Streaming Data</title>
      <link>https://arxiv.org/abs/2405.19463</link>
      <description>arXiv:2405.19463v1 Announce Type: cross 
Abstract: We develop and analyze algorithms for instrumental variable regression by viewing the problem as a conditional stochastic optimization problem. In the context of least-squares instrumental variable regression, our algorithms neither require matrix inversions nor mini-batches and provides a fully online approach for performing instrumental variable regression with streaming data. When the true model is linear, we derive rates of convergence in expectation, that are of order $\mathcal{O}(\log T/T)$ and $\mathcal{O}(1/T^{1-\iota})$ for any $\iota&gt;0$, respectively under the availability of two-sample and one-sample oracles, respectively, where $T$ is the number of iterations. Importantly, under the availability of the two-sample oracle, our procedure avoids explicitly modeling and estimating the relationship between confounder and the instrumental variables, demonstrating the benefit of the proposed approach over recent works based on reformulating the problem as minimax optimization problems. Numerical experiments are provided to corroborate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19463v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuxing Chen, Abhishek Roy, Yifan Hu, Krishnakumar Balasubramanian</dc:creator>
    </item>
    <item>
      <title>Decentralized Optimization in Time-Varying Networks with Arbitrary Delays</title>
      <link>https://arxiv.org/abs/2405.19513</link>
      <description>arXiv:2405.19513v1 Announce Type: cross 
Abstract: We consider a decentralized optimization problem for networks affected by communication delays. Examples of such networks include collaborative machine learning, sensor networks, and multi-agent systems. To mimic communication delays, we add virtual non-computing nodes to the network, resulting in directed graphs. This motivates investigating decentralized optimization solutions on directed graphs. Existing solutions assume nodes know their out-degrees, resulting in limited applicability. To overcome this limitation, we introduce a novel gossip-based algorithm, called DT-GO, that does not need to know the out-degrees. The algorithm is applicable in general directed networks, for example networks with delays or limited acknowledgment capabilities. We derive convergence rates for both convex and non-convex objectives, showing that our algorithm achieves the same complexity order as centralized Stochastic Gradient Descent. In other words, the effects of the graph topology and delays are confined to higher-order terms. Additionally, we extend our analysis to accommodate time-varying network topologies. Numerical simulations are provided to support our theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19513v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tomas Ortega, Hamid Jafarkhani</dc:creator>
    </item>
    <item>
      <title>One-Shot Safety Alignment for Large Language Models via Optimal Dualization</title>
      <link>https://arxiv.org/abs/2405.19544</link>
      <description>arXiv:2405.19544v1 Announce Type: cross 
Abstract: The growing safety concerns surrounding Large Language Models (LLMs) raise an urgent need to align them with diverse human preferences to simultaneously enhance their helpfulness and safety. A promising approach is to enforce safety constraints through Reinforcement Learning from Human Feedback (RLHF). For such constrained RLHF, common Lagrangian-based primal-dual policy optimization methods are computationally expensive and often unstable. This paper presents a dualization perspective that reduces constrained alignment to an equivalent unconstrained alignment problem. We do so by pre-optimizing a smooth and convex dual function that has a closed form. This shortcut eliminates the need for cumbersome primal-dual policy iterations, thus greatly reducing the computational burden and improving training stability. Our strategy leads to two practical algorithms in model-based and preference-based scenarios (MoCAN and PeCAN, respectively). A broad range of experiments demonstrate the effectiveness of our methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19544v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinmeng Huang, Shuo Li, Edgar Dobriban, Osbert Bastani, Hamed Hassani, Dongsheng Ding</dc:creator>
    </item>
    <item>
      <title>Convex Optimization of Initial Perturbations toward Quantitative Weather Control</title>
      <link>https://arxiv.org/abs/2405.19546</link>
      <description>arXiv:2405.19546v1 Announce Type: cross 
Abstract: We propose a convex optimization approach to determine perturbations in the initial conditions of a weather phenomenon as control inputs for quantitative weather control. We first construct a sensitivity matrix of outputs, such as accumulated precipitation, to the initial conditions, such as temperature and humidity, through sensitivity analysis of a numerical weather prediction model. We then solve a convex optimization problem to find optimal perturbations in the initial conditions to realize the desired spatial distribution of the targeting outputs. We implement the proposed method in a benchmark of a warm bubble experiment and show that it realizes desired spatial distributions of accumulated precipitation, such as a reference distribution and the reduced maximum value.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19546v1</guid>
      <category>physics.ao-ph</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshiyuki Ohtsuka, Atsushi Okazaki, Masaki Ogura, Shunji Kotsuki</dc:creator>
    </item>
    <item>
      <title>Few for Many: Tchebycheff Set Scalarization for Many-Objective Optimization</title>
      <link>https://arxiv.org/abs/2405.19650</link>
      <description>arXiv:2405.19650v1 Announce Type: cross 
Abstract: Multi-objective optimization can be found in many real-world applications where some conflicting objectives can not be optimized by a single solution. Existing optimization methods often focus on finding a set of Pareto solutions with different optimal trade-offs among the objectives. However, the required number of solutions to well approximate the whole Pareto optimal set could be exponentially large with respect to the number of objectives, which makes these methods unsuitable for handling many optimization objectives. In this work, instead of finding a dense set of Pareto solutions, we propose a novel Tchebycheff set scalarization method to find a few representative solutions (e.g., 5) to cover a large number of objectives (e.g., $&gt;100$) in a collaborative and complementary manner. In this way, each objective can be well addressed by at least one solution in the small solution set. In addition, we further develop a smooth Tchebycheff set scalarization approach for efficient optimization with good theoretical guarantees. Experimental studies on different problems with many optimization objectives demonstrate the effectiveness of our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19650v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xi Lin, Yilu Liu, Xiaoyuan Zhang, Fei Liu, Zhenkun Wang, Qingfu Zhang</dc:creator>
    </item>
    <item>
      <title>Efficient Trajectory Inference in Wasserstein Space Using Consecutive Averaging</title>
      <link>https://arxiv.org/abs/2405.19679</link>
      <description>arXiv:2405.19679v1 Announce Type: cross 
Abstract: Capturing data from dynamic processes through cross-sectional measurements is seen in many fields such as computational biology. Trajectory inference deals with the challenge of reconstructing continuous processes from such observations. In this work, we propose methods for B-spline approximation and interpolation of point clouds through consecutive averaging that is instrinsic to the Wasserstein space. Combining subdivision schemes with optimal transport-based geodesic, our methods carry out trajectory inference at a chosen level of precision and smoothness, and can automatically handle scenarios where particles undergo division over time. We rigorously evaluate our method by providing convergence guarantees and testing it on simulated cell data characterized by bifurcations and merges, comparing its performance against state-of-the-art trajectory inference and interpolation methods. The results not only underscore the effectiveness of our method in inferring trajectories, but also highlight the benefit of performing interpolation and approximation that respect the inherent geometric properties of the data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19679v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amartya Banerjee, Harlin Lee, Nir Sharon, Caroline Moosm\"uller</dc:creator>
    </item>
    <item>
      <title>OpenTM: An Open-source, Single-GPU, Large-scale Thermal Microstructure Design Framework</title>
      <link>https://arxiv.org/abs/2405.19991</link>
      <description>arXiv:2405.19991v1 Announce Type: cross 
Abstract: Thermal microstructures are artificially engineered materials designed to manipulate and control heat flow in unconventional ways. This paper presents an educational framework, called \emph{OpenTM}, to use a single GPU for designing periodic 3D high-resolution thermal microstructures to match the predefined thermal conductivity matrices with volume fraction constraints. Specifically, we use adaptive volume fraction to make the Optimality Criteria (OC) method run stably to obtain the thermal microstructures without a large memory overhead.Practical examples with a high resolution $128 \times 128 \times 128$ run under 90 seconds per structure on an NVIDIA GeForce GTX 4070Ti GPU with a peak GPU memory of 355 MB. Our open-source, high-performance implementation is publicly accessible at \url{https://github.com/quanyuchen2000/OPENTM}, and it is easy to install using Anaconda. Moreover, we provide a Python interface to make OpenTM well-suited for novices in C/C++.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19991v1</guid>
      <category>cs.CE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuchen Quan, Xiaoya Zhai, Xiao-Ming Fu</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Bipartite Quantum Systems</title>
      <link>https://arxiv.org/abs/2405.20034</link>
      <description>arXiv:2405.20034v1 Announce Type: cross 
Abstract: Closed bipartite quantum systems subject to fast local unitary control are studied using quantum optimal control theory and a method of reduced control systems based on the Schmidt decomposition. Particular focus is given to the time-optimal generation of maximally entangled states and product states, as well as to the problem of stabilizing quantum states with a certain amount of entanglement. Explicit analytical solutions are given for general systems consisting of two qubits (as well as for bosonic and fermionic analogues) and also for a class of systems consisting of two coupled qutrits which is studied using the Pontryagin Maximum Principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20034v1</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emanuel Malvetti, L\'eo Van Damme</dc:creator>
    </item>
    <item>
      <title>Near Optimal Decentralized Optimization with Compression and Momentum Tracking</title>
      <link>https://arxiv.org/abs/2405.20114</link>
      <description>arXiv:2405.20114v1 Announce Type: cross 
Abstract: Communication efficiency has garnered significant attention as it is considered the main bottleneck for large-scale decentralized Machine Learning applications in distributed and federated settings. In this regime, clients are restricted to transmitting small amounts of quantized information to their neighbors over a communication graph. Numerous endeavors have been made to address this challenging problem by developing algorithms with compressed communication for decentralized non-convex optimization problems. Despite considerable efforts, the current results suffer from various issues such as non-scalability with the number of clients, requirements for large batches, or bounded gradient assumption. In this paper, we introduce MoTEF, a novel approach that integrates communication compression with Momentum Tracking and Error Feedback. Our analysis demonstrates that MoTEF achieves most of the desired properties, and significantly outperforms existing methods under arbitrary data heterogeneity. We provide numerical experiments to validate our theoretical findings and confirm the practical superiority of MoTEF.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20114v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rustem Islamov, Yuan Gao, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>A Geometric Unification of Distributionally Robust Covariance Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set</title>
      <link>https://arxiv.org/abs/2405.20124</link>
      <description>arXiv:2405.20124v1 Announce Type: cross 
Abstract: The state-of-the-art methods for estimating high-dimensional covariance matrices all shrink the eigenvalues of the sample covariance matrix towards a data-insensitive shrinkage target. The underlying shrinkage transformation is either chosen heuristically - without compelling theoretical justification - or optimally in view of restrictive distributional assumptions. In this paper, we propose a principled approach to construct covariance estimators without imposing restrictive assumptions. That is, we study distributionally robust covariance estimation problems that minimize the worst-case Frobenius error with respect to all data distributions close to a nominal distribution, where the proximity of distributions is measured via a divergence on the space of covariance matrices. We identify mild conditions on this divergence under which the resulting minimizers represent shrinkage estimators. We show that the corresponding shrinkage transformations are intimately related to the geometrical properties of the underlying divergence. We also prove that our robust estimators are efficiently computable and asymptotically consistent and that they enjoy finite-sample performance guarantees. We exemplify our general methodology by synthesizing explicit estimators induced by the Kullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical experiments based on synthetic and real data show that our robust estimators are competitive with state-of-the-art estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20124v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Man-Chung Yue, Yves Rychener, Daniel Kuhn, Viet Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>Deep Learning the Efficient Frontier of Convex Vector Optimization Problems</title>
      <link>https://arxiv.org/abs/2205.07077</link>
      <description>arXiv:2205.07077v4 Announce Type: replace 
Abstract: In this paper, we design a neural network architecture to approximate the weakly efficient frontier of convex vector optimization problems (CVOP) satisfying Slater's condition. The proposed machine learning methodology provides both an inner and outer approximation of the weakly efficient frontier, as well as an upper bound to the error at each approximated efficient point. In numerical case studies we demonstrate that the proposed algorithm is effectively able to approximate the true weakly efficient frontier of CVOPs. This remains true even for large problems (i.e., many objectives, variables, and constraints) and thus overcoming the curse of dimensionality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.07077v4</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10898-024-01408-x</arxiv:DOI>
      <dc:creator>Zachary Feinstein, Birgit Rudloff</dc:creator>
    </item>
    <item>
      <title>Time-Varying Convex Optimization: A Contraction and Equilibrium Tracking Approach</title>
      <link>https://arxiv.org/abs/2305.15595</link>
      <description>arXiv:2305.15595v2 Announce Type: replace 
Abstract: In this article, we provide a novel and broadly-applicable contraction-theoretic approach to continuous-time time-varying convex optimization. For any parameter-dependent contracting dynamics, we show that the tracking error is asymptotically proportional to the rate of change of the parameter with proportionality constant upper bounded by Lipschitz constant in which the parameter appears divided by the contraction rate of the dynamics squared. We additionally establish that any parameter-dependent contracting dynamics can be augmented with a feedforward prediction term to ensure that the tracking error converges to zero exponentially quickly. To apply these results to time-varying convex optimization problems, we establish the strong infinitesimal contractivity of dynamics solving three canonical problems, namely monotone inclusions, linear equality-constrained problems, and composite minimization problems. For each of these problems, we prove the sharpest-known rates of contraction and provide explicit tracking error bounds between solution trajectories and minimizing trajectories. We validate our theoretical results on three numerical examples including an application to control-barrier function based controller design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.15595v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Davydov, Veronica Centorrino, Anand Gokhale, Giovanni Russo, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>Convergence guarantees for adaptive model predictive control with kinky inference</title>
      <link>https://arxiv.org/abs/2312.11329</link>
      <description>arXiv:2312.11329v2 Announce Type: replace 
Abstract: We analyze the convergence properties of a robust adaptive model predictive control algorithm used to control an unknown nonlinear system. We show that by employing a standard quadratic stabilizing cost function, and by recursively updating the nominal model through kinky inference, the resulting controller ensures convergence of the true system to the origin, despite the presence of model uncertainty. We illustrate our theoretical findings through a numerical simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.11329v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Zuliani, Raffaele Soloperto, John Lygeros</dc:creator>
    </item>
    <item>
      <title>Gradient Descent for Noisy Optimization</title>
      <link>https://arxiv.org/abs/2405.06539</link>
      <description>arXiv:2405.06539v2 Announce Type: replace 
Abstract: We study the use of gradient descent with backtracking line search (GD-BLS) to solve the noisy optimization problem $\theta_\star:=\mathrm{argmin}_{\theta\in\mathbb{R}^d} \mathbb{E}[f(\theta,Z)]$, imposing that the function $F(\theta):=\mathbb{E}[f(\theta,Z)]$ is strictly convex. Assuming that $\mathbb{E}[\|\nabla_\theta f(\theta_\star,Z)\|^2]&lt;\infty$ and that $F$ is locally $L$-smooth, we first prove that sample average approximation based on GD-BLS allows to estimate $\theta_\star$ with an error of size $\mathcal{O}_{\mathbb{P}}(B^{-0.25})$, where $B$ is the available computational budget. We then show that we can improve upon this rate by stopping the optimization process earlier when the gradient of the objective function is sufficiently close to zero, and use the residual computational budget to optimize, again with GD-BLS, a finer approximation of $F$. By iteratively applying this strategy $J$ times, we establish that we can estimate $\theta_\star$ with an error of size $\mathcal{O}_{\mathbb{P}}(B^{-\frac{1}{2}(1-\delta^{J})})$, where $\delta\in(1/2,1)$ is a user-specified parameter. More generally, we show that if $\mathbb{E}[\|\nabla_\theta f(\theta_\star,Z)\|^{1+\alpha}]&lt;\infty$ for some known $\alpha\in (0,1]$ then this approach, which can be seen as a retrospective approximation algorithm with a fixed computational budget, allows to learn $\theta_\star$ with an error of size $\mathcal{O}_{\mathbb{P}}(B^{-\frac{\alpha}{1+\alpha}(1-\delta^{J})})$, where $\delta\in(2\alpha/(1+3\alpha),1)$ is a tuning parameter. Beyond knowing $\alpha$, achieving the aforementioned convergence rates do not require to tune the algorithms parameters according to the specific functions $F$ and $f$ at hand, and we exhibit a simple noisy optimization problem for which stochastic gradient is not guaranteed to converge while the algorithms discussed in this work are.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06539v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Annie Hu, Mathieu Gerber</dc:creator>
    </item>
    <item>
      <title>Single-loop Stochastic Algorithms for Difference of Max-Structured Weakly Convex Functions</title>
      <link>https://arxiv.org/abs/2405.18577</link>
      <description>arXiv:2405.18577v2 Announce Type: replace 
Abstract: In this paper, we study a class of non-smooth non-convex problems in the form of $\min_{x}[\max_{y\in Y}\phi(x, y) - \max_{z\in Z}\psi(x, z)]$, where both $\Phi(x) = \max_{y\in Y}\phi(x, y)$ and $\Psi(x)=\max_{z\in Z}\psi(x, z)$ are weakly convex functions, and $\phi(x, y), \psi(x, z)$ are strongly concave functions in terms of $y$ and $z$, respectively. It covers two families of problems that have been studied but are missing single-loop stochastic algorithms, i.e., difference of weakly convex functions and weakly convex strongly-concave min-max problems. We propose a stochastic Moreau envelope approximate gradient method dubbed SMAG, the first single-loop algorithm for solving these problems, and provide a state-of-the-art non-asymptotic convergence rate. The key idea of the design is to compute an approximate gradient of the Moreau envelopes of $\Phi, \Psi$ using only one step of stochastic gradient update of the primal and dual variables. Empirically, we conduct experiments on positive-unlabeled (PU) learning and partial area under ROC curve (pAUC) optimization with an adversarial fairness regularizer to validate the effectiveness of our proposed algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18577v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quanqi Hu, Qi Qi, Zhaosong Lu, Tianbao Yang</dc:creator>
    </item>
    <item>
      <title>Understanding Adam Optimizer via Online Learning of Updates: Adam is FTRL in Disguise</title>
      <link>https://arxiv.org/abs/2402.01567</link>
      <description>arXiv:2402.01567v2 Announce Type: replace-cross 
Abstract: Despite the success of the Adam optimizer in practice, the theoretical understanding of its algorithmic components still remains limited. In particular, most existing analyses of Adam show the convergence rate that can be simply achieved by non-adative algorithms like SGD. In this work, we provide a different perspective based on online learning that underscores the importance of Adam's algorithmic components. Inspired by Cutkosky et al. (2023), we consider the framework called online learning of updates/increments, where we choose the updates/increments of an optimizer based on an online learner. With this framework, the design of a good optimizer is reduced to the design of a good online learner. Our main observation is that Adam corresponds to a principled online learning framework called Follow-the-Regularized-Leader (FTRL). Building on this observation, we study the benefits of its algorithmic components from the online learning perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.01567v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwangjun Ahn, Zhiyu Zhang, Yunbum Kook, Yan Dai</dc:creator>
    </item>
    <item>
      <title>Learning Neural Contracting Dynamics: Extended Linearization and Global Guarantees</title>
      <link>https://arxiv.org/abs/2402.08090</link>
      <description>arXiv:2402.08090v3 Announce Type: replace-cross 
Abstract: Global stability and robustness guarantees in learned dynamical systems are essential to ensure well-behavedness of the systems in the face of uncertainty. We present Extended Linearized Contracting Dynamics (ELCD), the first neural network-based dynamical system with global contractivity guarantees in arbitrary metrics. The key feature of ELCD is a parametrization of the extended linearization of the nonlinear vector field. In its most basic form, ELCD is guaranteed to be (i) globally exponentially stable, (ii) equilibrium contracting, and (iii) globally contracting with respect to some metric. To allow for contraction with respect to more general metrics in the data space, we train diffeomorphisms between the data space and a latent space and enforce contractivity in the latent space, which ensures global contractivity in the data space. We demonstrate the performance of ELCD on the high dimensional LASA, multi-link pendulum, and Rosenbrock datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08090v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sean Jaffe, Alexander Davydov, Deniz Lapsekili, Ambuj Singh, Francesco Bullo</dc:creator>
    </item>
    <item>
      <title>On the Last-Iterate Convergence of Shuffling Gradient Methods</title>
      <link>https://arxiv.org/abs/2403.07723</link>
      <description>arXiv:2403.07723v2 Announce Type: replace-cross 
Abstract: Shuffling gradient methods are widely implemented in practice, particularly including three popular algorithms: Random Reshuffle (RR), Shuffle Once (SO), and Incremental Gradient (IG). Compared to the empirical success, the theoretical guarantee of shuffling gradient methods was not well-understood for a long time. Until recently, the convergence rates had just been established for the average iterate for convex functions and the last iterate for strongly convex problems (using squared distance as the metric). However, when using the function value gap as the convergence criterion, existing theories cannot interpret the good performance of the last iterate in different settings (e.g., constrained optimization). To bridge this gap between practice and theory, we prove the first last-iterate convergence rates for shuffling gradient methods with respect to the objective value even without strong convexity. Our new results either (nearly) match the existing last-iterate lower bounds or are as fast as the previous best upper bounds for the average iterate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07723v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijian Liu, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>A random-key GRASP for combinatorial optimization</title>
      <link>https://arxiv.org/abs/2405.18681</link>
      <description>arXiv:2405.18681v2 Announce Type: replace-cross 
Abstract: This paper proposes a problem-independent GRASP metaheuristic using the random-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search procedure) is a metaheuristic for combinatorial optimization that repeatedly applies a semi-greedy construction procedure followed by a local search procedure. The best solution found over all iterations is returned as the solution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for continuous optimization in the unit hypercube. A random-key optimizer (RKO) uses a vector of random keys to encode a solution to a combinatorial optimization problem. It uses a decoder to evaluate a solution encoded by the vector of random keys. A random-key GRASP is a C-GRASP where points in the unit hypercube are evaluated employing a decoder. We describe random key GRASP consisting of a problem-independent component and a problem-dependent decoder. As a proof of concept, the random-key GRASP is tested on five NP-hard combinatorial optimization problems: traveling salesman problem, tree of hubs location problem, Steiner triple covering problem, node capacitated graph partitioning problem, and job sequencing and tool switching problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.18681v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio A. Chaves, Mauricio G. C. Resende, Ricardo M. A. Silva</dc:creator>
    </item>
  </channel>
</rss>
