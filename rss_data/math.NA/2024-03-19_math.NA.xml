<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Mar 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A fast low-rank inversion algorithm of dielectric matrix in GW approximation</title>
      <link>https://arxiv.org/abs/2403.12340</link>
      <description>arXiv:2403.12340v1 Announce Type: new 
Abstract: The dielectric response function and its inverse are crucial physical quantities in materials science. We propose an accurate and efficient strategy to invert the dielectric function matrix. The GW approximation, a powerful approach to accurately describe many-body excited states, is taken as an application to demonstrate accuracy and efficiency. We incorporate the interpolative separable density fitting (ISDF) algorithm with Sherman--Morrison--Woodbury (SMW) formula to accelerate the inversion process by exploiting low-rank properties of dielectric function in plane-wave GW calculations. Our ISDF--SMW strategy produces accurate quasiparticle energies with $O(N_{\mathrm{r}}N_{\mathrm{e}}^2)$ computational cost $(N_{\mathrm{e}}$ is the number of electrons and $N_{\mathrm{r}}=100$--$1000N_{\mathrm{e}}$ is the number of grid points) with negligible small error of $0.03$~eV for both complex molecules and solids. This new strategy for inverting the dielectric matrix can be \(50\times\) faster than the current state-of-the-art implementation in BerkeleyGW, resulting in two orders of magnitude speedup for total GW calculations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12340v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhengbang Zhou, Huanhuan Ma, Wentiao Wu, Weiguo Gao, Jinlong Yang, Meiyue Shao, Wei Hu</dc:creator>
    </item>
    <item>
      <title>Stochastic variance reduced gradient method for linear ill-posed inverse problems</title>
      <link>https://arxiv.org/abs/2403.12460</link>
      <description>arXiv:2403.12460v1 Announce Type: new 
Abstract: In this paper we apply the stochastic variance reduced gradient (SVRG) method, which is a popular variance reduction method in optimization for accelerating the stochastic gradient method, to solve large scale linear ill-posed systems in Hilbert spaces. Under {\it a priori} choices of stopping indices, we derive a convergence rate result when the sought solution satisfies a benchmark source condition and establish a convergence result without using any source condition. To terminate the method in an {\it a posteriori} manner, we consider the discrepancy principle and show that it terminates the method in finite many iteration steps almost surely. Various numerical results are reported to test the performance of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12460v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qinian Jin, Liuhong Chen</dc:creator>
    </item>
    <item>
      <title>Multilevel Markov Chain Monte Carlo for Bayesian inverse problems for Navier Stokes equation with Lagrangian Observations</title>
      <link>https://arxiv.org/abs/2403.12501</link>
      <description>arXiv:2403.12501v1 Announce Type: new 
Abstract: In this paper, we extend our work to the Bayesian inverse problems for inferring unknown forcing and initial condition of the forward Navier-Stokes equation coupled with tracer equation with noisy Lagrangian observation on the positions of the tracers. We consider the Navier-Stokes equations in the two dimensional periodic torus with a tracer equation which is a simple ordinary differential equation. We developed rigorously the theory for the case of the uniform prior where the forcing and the initial condition depend linearly on a countable set of random variables which are uniformly distributed in a compact interval. Numerical experiment using the MLMCMC method produces approximations for posterior expectation of quantities of interest which are in agreement with the theoretical optimal convergence rate established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12501v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juntao Yang</dc:creator>
    </item>
    <item>
      <title>Numerical approximation of a class of constrained Hamilton-Jacobi equations</title>
      <link>https://arxiv.org/abs/2403.12557</link>
      <description>arXiv:2403.12557v1 Announce Type: new 
Abstract: In this paper, we introduce a framework for the discretization of a class of constrained Hamilton-Jacobi equations, a system coupling a Hamilton-Jacobi equation with a Lagrange multiplier determined by the constraint. The equation is non-local, and the constraint has bounded variations. We show that, under a set of general hypothesis, the approximation obtained with a finite-differences monotonic scheme, converges towards the viscosity solution of the constrained Hamilton-Jacobi equation.
  Constrained Hamilton-Jacobi equations often arise as the long time and small mutation asymptotics of population models in quantitative genetics. As an example, we detail the construction of a scheme for the limit of an integral Lotka-Volterra equation. We also construct and analyze an Asymptotic-Preserving (AP) scheme for the model outside of the asymptotics. We prove that it is stable along the transition towards the asymptotics.
  The theoretical analysis of the schemes is illustrated and discussed with numerical simulations. The AP scheme is also used to conjecture the asymptotic behavior of the integral Lotka-Volterra equation, when the environment varies in time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12557v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Beno\^it Gaudeul, H\'el\`ene Hivert</dc:creator>
    </item>
    <item>
      <title>Rate-optimal higher-order adaptive conforming FEM for biharmonic eigenvalue problems on polygonal domains</title>
      <link>https://arxiv.org/abs/2403.12577</link>
      <description>arXiv:2403.12577v1 Announce Type: new 
Abstract: The a posteriori error analysis of the classical Argyris finite element methods dates back to 1996, while the optimal convergence rates of associated adaptive finite element schemes are established only very recently in 2021. It took a long time to realise the necessity of an extension of the classical finite element spaces to make them hierarchical. This paper establishes the novel adaptive schemes for the biharmonic eigenvalue problems and provides a mathematical proof of optimal convergence rates towards a simple eigenvalue and numerical evidence thereof. This makes the suggested algorithm highly competitive and clearly justifies the higher computational and implementational costs compared to low-order nonconforming schemes. The numerical experiments provide overwhelming evidence that higher polynomial degrees pay off with higher convergence rates and underline that adaptive mesh-refining is mandatory. Five computational benchmarks display accurate reference eigenvalues up to 30 digits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12577v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Carsten Carstensen, Benedikt Gr\"a{\ss}le</dc:creator>
    </item>
    <item>
      <title>MOCCA: A Fast Algorithm for Parallel MRI Reconstruction Using Model Based Coil Calibration</title>
      <link>https://arxiv.org/abs/2403.12611</link>
      <description>arXiv:2403.12611v1 Announce Type: new 
Abstract: We propose a new fast algorithm for simultaneous recovery of the coil sensitivities and the magnetization image from incomplete Fourier measurements in parallel MRI. Our approach is based on suitable parameter models for both, the magnetization image and the sensitivities. The derived MOCCA algorithm provides perfect reconstruction results if the model assumptions are satisfied. Moreover, it has low computational complexity and achieves very good performance for incomplete MRI data. We present a complete mathematical analysis of the proposed reconstruction method. Most importantly, MOCCA leads to a better understanding of the connections between subspace methods and sensitivity modeling which will provide us the with the opportunity to improve also existing algorithms as ESPIRiT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12611v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gerlind Plonka, Yannick Riebe</dc:creator>
    </item>
    <item>
      <title>Adaptive Multilevel Neural Networks for Parametric PDEs with Error Estimation</title>
      <link>https://arxiv.org/abs/2403.12650</link>
      <description>arXiv:2403.12650v1 Announce Type: new 
Abstract: To solve high-dimensional parameter-dependent partial differential equations (pPDEs), a neural network architecture is presented. It is constructed to map parameters of the model data to corresponding finite element solutions. To improve training efficiency and to enable control of the approximation error, the network mimics an adaptive finite element method (AFEM). It outputs a coarse grid solution and a series of corrections as produced in an AFEM, allowing a tracking of the error decay over successive layers of the network. The observed errors are measured by a reliable residual based a posteriori error estimator, enabling the reduction to only few parameters for the approximation in the output of the network. This leads to a problem adapted representation of the solution on locally refined grids. Furthermore, each solution of the AFEM is discretized in a hierarchical basis. For the architecture, convolutional neural networks (CNNs) are chosen. The hierarchical basis then allows to handle sparse images for finely discretized meshes. Additionally, as corrections on finer levels decrease in amplitude, i.e., importance for the overall approximation, the accuracy of the network approximation is allowed to decrease successively. This can either be incorporated in the number of generated high fidelity samples used for training or the size of the network components responsible for the fine grid outputs. The architecture is described and preliminary numerical examples are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12650v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Janina E. Sch\"utte, Martin Eigel</dc:creator>
    </item>
    <item>
      <title>Stabilizing DG Methods Using Dafermos' Entropy Rate Criterion: III -- Unstructured Grids</title>
      <link>https://arxiv.org/abs/2403.12689</link>
      <description>arXiv:2403.12689v1 Announce Type: new 
Abstract: The approach presented in the second installment of this series is extended to multidimensional systems of conservation laws that are approximated via a Discontinuous Galerkin method on unstructured (triangular) grids. Special attention is paid to predicting the entropy dissipation from boundaries. The resulting schemes are free of tunable viscosity parameters and tested on the Euler equations. The trinity of testcases is the spreading of thermal energy from a point source, transsonic and supersonic flows around airfoils, and supersonic air inlets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12689v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon-Christian Klein</dc:creator>
    </item>
    <item>
      <title>A second-order iterative time integration scheme for linear poroelasticity</title>
      <link>https://arxiv.org/abs/2403.12699</link>
      <description>arXiv:2403.12699v1 Announce Type: new 
Abstract: We propose a novel time stepping method for linear poroelasticity by extending a recent iterative decoupling approach to the second-order case. This results in a two-step scheme with an inner iteration and a relaxation step. We prove second-order convergence for a prescribed number of inner iteration steps, only depending on the coupling strength of the elastic and the flow equation. The efficiency of the scheme is illustrated by a number of numerical experiments, including a simulation of three-dimensional brain tissue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12699v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>R. Altmann, M. Deiml</dc:creator>
    </item>
    <item>
      <title>To blow-up or not to blow-up for a granular kinetic equation</title>
      <link>https://arxiv.org/abs/2403.12735</link>
      <description>arXiv:2403.12735v1 Announce Type: new 
Abstract: A simplified kinetic description of rapid granular media leads to a nonlocal Vlasov-type equation with a convolution integral operator that is of the same form as the continuity equations for aggregation-diffusion macroscopic dynamics. While the singular behavior of these nonlinear continuity equations is well studied in the literature, the extension to the corresponding granular kinetic equation is highly nontrivial. The main question is whether the singularity formed in velocity direction will be enhanced or mitigated by the shear in phase space due to free transport. We present a preliminary study through a meticulous numerical investigation and heuristic arguments. We have numerically developed a structure-preserving method with adaptive mesh refinement that can effectively capture potential blow-up behavior in the solution for granular kinetic equations. We have analytically constructed a finite-time blow-up infinite mass solution and discussed how this can provide insights into the finite mass scenario.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12735v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e A. Carrillo, Ruiwen Shu, Li Wang, Wuzhe Xu</dc:creator>
    </item>
    <item>
      <title>Importance sampling for rare event tracking within the ensemble Kalman filtering framework</title>
      <link>https://arxiv.org/abs/2403.12793</link>
      <description>arXiv:2403.12793v1 Announce Type: new 
Abstract: In this work we employ importance sampling (IS) techniques to track a small over-threshold probability of a running maximum associated with the solution of a stochastic differential equation (SDE) within the framework of ensemble Kalman filtering (EnKF). Between two observation times of the EnKF, we propose to use IS with respect to the initial condition of the SDE, IS with respect to the Wiener process via a stochastic optimal control formulation, and combined IS with respect to both initial condition and Wiener process. Both IS strategies require the approximation of the solution of Kolmogorov Backward equation (KBE) with boundary conditions. In multidimensional settings, we employ a Markovian projection dimension reduction technique to obtain an approximation of the solution of the KBE by just solving a one dimensional PDE. The proposed ideas are tested on two illustrative examples: Double Well SDE and Langevin dynamics, and showcase a significant variance reduction compared to the standard Monte Carlo method and another sampling-based IS technique, namely, multilevel cross entropy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12793v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nadhir Ben Rached, Erik von Schwerin, Gaukhar Shaimerdenova, Raul Tempone</dc:creator>
    </item>
    <item>
      <title>Cross Algorithms for Cost-Effective Time Integration of Nonlinear Tensor Differential Equations on Low-Rank Tucker Tensor and Tensor Train Manifolds</title>
      <link>https://arxiv.org/abs/2403.12826</link>
      <description>arXiv:2403.12826v1 Announce Type: new 
Abstract: Dynamical low-rank approximation (DLRA) provides a rigorous, cost-effective mathematical framework for solving high-dimensional tensor differential equations (TDEs) on low-rank tensor manifolds. Despite their effectiveness, DLRA-based low-rank approximations lose their computational efficiency when applied to nonlinear TDEs, particularly those exhibiting non-polynomial nonlinearity. In this paper, we present a novel algorithm for the time integration of TDEs on the tensor train and Tucker tensor low-rank manifolds, which are the building blocks of many tensor network decompositions. This paper builds on our previous work (Donello et al., Proceedings of the Royal Society A, Vol. 479, 2023) on solving nonlinear matrix differential equations on low-rank matrix manifolds using CUR decompositions. The methodology we present offers multiple advantages: (i) it leverages cross algorithms based on the discrete empirical interpolation method to strategically sample sparse entries of the time-discrete TDEs to advance the solution in low-rank form. As a result, it offers near-optimal computational savings both in terms of memory and floating-point operations. (ii) The time integration is robust in the presence of small or zero singular values. (iii) The algorithm is remarkably easy to implement, as it requires the evaluation of the full-order model TDE at strategically selected entries and it does not use tangent space projections, whose efficient implementation is intrusive and time-consuming. (iv) We develop high-order explicit Runge-Kutta schemes for the time integration of TDEs on low-rank manifolds. We demonstrate the efficiency of the presented algorithm for several test cases, including a 100-dimensional TDE with non-polynomial nonlinearity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12826v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Behzad Ghahremani, Hessam Babaee</dc:creator>
    </item>
    <item>
      <title>Local reconstruction analysis of inverting the Radon transform in the plane from noisy discrete data</title>
      <link>https://arxiv.org/abs/2403.12909</link>
      <description>arXiv:2403.12909v1 Announce Type: new 
Abstract: In this paper, we investigate the reconstruction error, $N_\e^{\text{rec}}(x)$, when a linear, filtered back-projection (FBP) algorithm is applied to noisy, discrete Radon transform data with sampling step size $\epsilon$ in two-dimensions. Specifically, we analyze $N_\e^{\text{rec}}(x)$ for $x$ in small, $O(\e)$-sized neighborhoods around a generic fixed point, $x_0$, in the plane, where the measurement noise values, $\eta_{k,j}$ (i.e., the errors in the sinogram space), are random variables. The latter are independent, but not necessarily identically distributed. We show, under suitable assumptions on the first three moments of the $\eta_{k,j}$, that the following limit exists: $N^{\text{rec}}(\chx;x_0) = \lim_{\e\to0}N_\e^{\text{rec}}(x_0+\e\chx)$, for $\check x$ in a bounded domain. Here, $N_\e^{\text{rec}}$ and $ N^{\text{rec}}$ are viewed as continuous random variables, and the limit is understood in the sense of distributions. Once the limit is established, we prove that $N^{\text{rec}}$ is a zero mean Gaussian random field and compute explicitly its covariance. In addition, we validate our theory using numerical simulations and pseudo random noise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12909v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anuj Abhishek, Alexander Katsevich, James W. Webber</dc:creator>
    </item>
    <item>
      <title>Damped energy-norm a posteriori error estimates for fully discrete approximations of the wave equation using C2-reconstructions</title>
      <link>https://arxiv.org/abs/2403.12954</link>
      <description>arXiv:2403.12954v1 Announce Type: new 
Abstract: We derive a posteriori error estimates for the the scalar wave equation discretized in space by continuous finite elements and in time by the explicit leapfrog scheme. Our analysis combines the idea of invoking extra time-regularity for the right-hand side, as previously introduced in the space semi-discrete setting, with a novel, piecewise quartic, globally twice-differentiable time-reconstruction of the fully discrete solution. Our main results show that the proposed estimator is reliable and efficient in a damped energy norm. These properties are illustrated in a series of numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12954v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>T. Chaumont-Frelet, A. Ern</dc:creator>
    </item>
    <item>
      <title>Useful Compact Representations for Data-Fitting</title>
      <link>https://arxiv.org/abs/2403.12206</link>
      <description>arXiv:2403.12206v1 Announce Type: cross 
Abstract: For minimization problems without 2nd derivative information, methods that estimate Hessian matrices can be very effective. However, conventional techniques generate dense matrices that are prohibitive for large problems. Limited-memory compact representations express the dense arrays in terms of a low rank representation and have become the state-of-the-art for software implementations on large deterministic problems. We develop new compact representations that are parameterized by a choice of vectors and that reduce to existing well known formulas for special choices. We demonstrate effectiveness of the compact representations for large eigenvalue computations, tensor factorizations and nonlinear regressions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12206v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes J. Brust</dc:creator>
    </item>
    <item>
      <title>Stochastic Rounding Implicitly Regularizes Tall-and-Thin Matrices</title>
      <link>https://arxiv.org/abs/2403.12278</link>
      <description>arXiv:2403.12278v1 Announce Type: cross 
Abstract: Motivated by the popularity of stochastic rounding in the context of machine learning and the training of large-scale deep neural network models, we consider stochastic nearness rounding of real matrices $\mathbf{A}$ with many more rows than columns. We provide novel theoretical evidence, supported by extensive experimental evaluation that, with high probability, the smallest singular value of a stochastically rounded matrix is well bounded away from zero -- regardless of how close $\mathbf{A}$ is to being rank deficient and even if $\mathbf{A}$ is rank-deficient. In other words, stochastic rounding \textit{implicitly regularizes} tall and skinny matrices $\mathbf{A}$ so that the rounded version has full column rank. Our proofs leverage powerful results in random matrix theory, and the idea that stochastic rounding errors do not concentrate in low-dimensional column spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12278v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gregory Dexter, Christos Boutsikas, Linkai Ma, Ilse C. F. Ipsen, Petros Drineas</dc:creator>
    </item>
    <item>
      <title>Neural Parameter Regression for Explicit Representations of PDE Solution Operators</title>
      <link>https://arxiv.org/abs/2403.12764</link>
      <description>arXiv:2403.12764v1 Announce Type: cross 
Abstract: We introduce Neural Parameter Regression (NPR), a novel framework specifically developed for learning solution operators in Partial Differential Equations (PDEs). Tailored for operator learning, this approach surpasses traditional DeepONets (Lu et al., 2021) by employing Physics-Informed Neural Network (PINN, Raissi et al., 2019) techniques to regress Neural Network (NN) parameters. By parametrizing each solution based on specific initial conditions, it effectively approximates a mapping between function spaces. Our method enhances parameter efficiency by incorporating low-rank matrices, thereby boosting computational efficiency and scalability. The framework shows remarkable adaptability to new initial and boundary conditions, allowing for rapid fine-tuning and inference, even in cases of out-of-distribution examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12764v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Konrad Mundinger, Max Zimmer, Sebastian Pokutta</dc:creator>
    </item>
    <item>
      <title>Multispectral Image Restoration by Generalized Opponent Transformation Total Variation</title>
      <link>https://arxiv.org/abs/2403.12770</link>
      <description>arXiv:2403.12770v1 Announce Type: cross 
Abstract: Multispectral images (MSI) contain light information in different wavelengths of objects, which convey spectral-spatial information and help improve the performance of various image processing tasks. Numerous techniques have been created to extend the application of total variation regularization in restoring multispectral images, for example, based on channel coupling and adaptive total variation regularization. The primary contribution of this paper is to propose and develop a new multispectral total variation regularization in a generalized opponent transformation domain instead of the original multispectral image domain. Here opponent transformations for multispectral images are generalized from a well-known opponent transformation for color images. We will explore the properties of generalized opponent transformation total variation (GOTTV) regularization and the corresponding optimization formula for multispectral image restoration. To evaluate the effectiveness of the new GOTTV method, we provide numerical examples that showcase its superior performance compared to existing multispectral image total variation methods, using criteria such as MPSNR and MSSIM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12770v1</guid>
      <category>cs.CV</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhantao Ma, Michael K. Ng</dc:creator>
    </item>
    <item>
      <title>Implicit Adaptive Mesh Refinement for Dispersive Tsunami Propagation</title>
      <link>https://arxiv.org/abs/2307.05816</link>
      <description>arXiv:2307.05816v2 Announce Type: replace 
Abstract: We present an algorithm to solve the dispersive depth-averaged Serre-Green-Naghdi (SGN) equations using patch-based adaptive mesh refinement. These equations require adding additional higher derivative terms to the nonlinear shallow water equations. This has been implemented as a new component of the open source GeoClaw software that is widely used for modeling tsunamis, storm surge, and related hazards, improving its accuracy on shorter wavelength phenomena. We use a formulation that requires solving an elliptic system of equations at each time step, making the method implicit. The adaptive algorithm allows different time steps on different refinement levels, and solves the implicit equations level by level. Computational examples are presented to illustrate the stability and accuracy on a radially symmetric test case and two realistic tsunami modeling problems, including a hypothetical asteroid impact creating a short wavelength tsunami for which dispersive terms are necessary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.05816v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.ao-ph</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marsha J. Berger, Randall J. LeVeque</dc:creator>
    </item>
    <item>
      <title>Stability of step size control based on a posteriori error estimates</title>
      <link>https://arxiv.org/abs/2307.12677</link>
      <description>arXiv:2307.12677v2 Announce Type: replace 
Abstract: A posteriori error estimates based on residuals can be used for reliable error control of numerical methods. Here, we consider them in the context of ordinary differential equations and Runge-Kutta methods. In particular, we take the approach of Dedner &amp; Giesselmann (2016) and investigate it when used to select the time step size. We focus on step size control stability when combined with explicit Runge-Kutta methods and demonstrate that a standard I controller is unstable while more advanced PI and PID controllers can be designed to be stable. We compare the stability properties of residual-based estimators and classical error estimators based on an embedded Runge-Kutta method both analytically and in numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.12677v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Ranocha, Jan Giesselmann</dc:creator>
    </item>
    <item>
      <title>Neural Networks are Integrable</title>
      <link>https://arxiv.org/abs/2310.14394</link>
      <description>arXiv:2310.14394v2 Announce Type: replace 
Abstract: In this study, we explore the integration of Neural Networks, a powerful class of functions known for their exceptional approximation capabilities. Our primary emphasis is on the integration of multi-layer Neural Networks, a challenging task within this domain. To tackle this challenge, we introduce a novel numerical method that consist of a forward algorithm and a corrective procedure. Our experimental results demonstrate the accuracy achieved through our integration approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.14394v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yucong Liu</dc:creator>
    </item>
    <item>
      <title>Multiderivative time integration methods preserving nonlinear functionals via relaxation</title>
      <link>https://arxiv.org/abs/2311.03883</link>
      <description>arXiv:2311.03883v2 Announce Type: replace 
Abstract: We combine the recent relaxation approach with multiderivative Runge-Kutta methods to preserve conservation or dissipation of entropy functionals for ordinary and partial differential equations. Relaxation methods are minor modifications of explicit and implicit schemes, requiring only the solution of a single scalar equation per time step in addition to the baseline scheme. We demonstrate the robustness of the resulting methods for a range of test problems including the 3D compressible Euler equations. In particular, we point out improved error growth rates for certain entropy-conservative problems including nonlinear dispersive wave equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03883v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hendrik Ranocha, Jochen Sch\"utz</dc:creator>
    </item>
    <item>
      <title>The stabilizer free weak Galerkin mixed finite elements method for the biharmonic equation</title>
      <link>https://arxiv.org/abs/2311.06465</link>
      <description>arXiv:2311.06465v2 Announce Type: replace 
Abstract: In this article, the stabilizer free weak Galerkin (SFWG) finite element method is applied to the Ciarlet-Raviart mixed form of the Biharmonic equation. We utilize the SFWG solutions of the second elliptic problems to define projection operators, build error equations, and further derive the error estimates. Finally, numerical examples support the results reached by the theory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06465v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shanshan Gu, Fuchang Huo, Shicheng Liu</dc:creator>
    </item>
    <item>
      <title>A bubble VEM-fully discrete polytopal scheme for mixed-dimensional poromechanics with frictional contact at matrix fracture interfaces</title>
      <link>https://arxiv.org/abs/2312.09319</link>
      <description>arXiv:2312.09319v2 Announce Type: replace 
Abstract: The objective of this article is to address the discretisation of fractured/faulted poromechanical models using 3D polyhedral meshes in order to cope with the geometrical complexity of faulted geological models.
  A polytopal scheme is proposed for contact-mechanics, based on a mixed formulation combining a fully discrete space and suitable reconstruction operators for the displacement field with a face-wise constant approximation of the Lagrange multiplier accounting for the surface tractions along the fracture/fault network. To ensure the inf--sup stability of the mixed formulation, a bubble-like degree of freedom is included in the discrete space of displacements (and taken into account in the reconstruction operators). It is proved that this fully discrete scheme for the displacement is equivalent to a low-order Virtual Element scheme, with a bubble enrichment of the VEM space. This $\mathbb{P}^1$-bubble VEM--$\mathbb{P}^0$ mixed discretization is combined with an Hybrid Finite Volume scheme for the Darcy flow. All together, the proposed approach is adapted to complex geometry accounting for network of planar faults/fractures including corners, tips and intersections; it leads to efficient semi-smooth Newton solvers for the contact-mechanics and preserve the dissipative properties of the fully coupled model. Our approach is investigated in terms of convergence and robustness on several 2D and 3D test cases using either analytical or numerical reference solutions both for the stand alone static contact mechanical model and the fully coupled poromechanical model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.09319v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cma.2024.116838</arxiv:DOI>
      <arxiv:journal_reference>Comput. Methods Appl. Mech. Engrg. 422, Paper no. 116838, 25p, 2024</arxiv:journal_reference>
      <dc:creator>J\'er\^ome Droniou, Guillaume Ench\'ery, Isabelle Faille, Ali Haidar, Roland Masson</dc:creator>
    </item>
    <item>
      <title>Convergence of a spatial semidiscretization for a three-dimensional stochastic Allen-Cahn equation with multiplicative noise</title>
      <link>https://arxiv.org/abs/2401.09834</link>
      <description>arXiv:2401.09834v3 Announce Type: replace 
Abstract: This paper studies the convergence of a spatial semidiscretization of a three-dimensional stochastic Allen-Cahn equation with multiplicative noise. For non-smooth initial values, the regularity of the mild solution is investigated, and an error estimate is derived with the spatial $ L^2 $-norm. For smooth initial values, two error estimates with the general spatial $ L^q $-norms are established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09834v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Binjie Li, Qin Zhou</dc:creator>
    </item>
    <item>
      <title>Adaptive stepsize algorithms for Langevin dynamics</title>
      <link>https://arxiv.org/abs/2403.11993</link>
      <description>arXiv:2403.11993v2 Announce Type: replace 
Abstract: We discuss the design of an invariant measure-preserving transformed dynamics for the numerical treatment of Langevin dynamics based on rescaling of time, with the goal of sampling from an invariant measure. Given an appropriate monitor function which characterizes the numerical difficulty of the problem as a function of the state of the system, this method allows the stepsizes to be reduced only when necessary, facilitating efficient recovery of long-time behavior. We study both the overdamped and underdamped Langevin dynamics. We investigate how an appropriate correction term that ensures preservation of the invariant measure should be incorporated into a numerical splitting scheme. Finally, we demonstrate the use of the technique in several model systems, including a Bayesian sampling problem with a steep prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11993v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alix Leroy, Benedict Leimkuhler, Jonas Latz, Desmond J. Higham</dc:creator>
    </item>
    <item>
      <title>Accelerating Data Generation for Neural Operators via Krylov Subspace Recycling</title>
      <link>https://arxiv.org/abs/2401.09516</link>
      <description>arXiv:2401.09516v2 Announce Type: replace-cross 
Abstract: Learning neural operators for solving partial differential equations (PDEs) has attracted great attention due to its high inference efficiency. However, training such operators requires generating a substantial amount of labeled data, i.e., PDE problems together with their solutions. The data generation process is exceptionally time-consuming, as it involves solving numerous systems of linear equations to obtain numerical solutions to the PDEs. Many existing methods solve these systems independently without considering their inherent similarities, resulting in extremely redundant computations. To tackle this problem, we propose a novel method, namely Sorting Krylov Recycling (SKR), to boost the efficiency of solving these systems, thus significantly accelerating data generation for neural operators training. To the best of our knowledge, SKR is the first attempt to address the time-consuming nature of data generation for learning neural operators. The working horse of SKR is Krylov subspace recycling, a powerful technique for solving a series of interrelated systems by leveraging their inherent similarities. Specifically, SKR employs a sorting algorithm to arrange these systems in a sequence, where adjacent systems exhibit high similarities. Then it equips a solver with Krylov subspace recycling to solve the systems sequentially instead of independently, thus effectively enhancing the solving efficiency. Both theoretical analysis and extensive experiments demonstrate that SKR can significantly accelerate neural operator data generation, achieving a remarkable speedup of up to 13.9 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.09516v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Wang, Zhongkai Hao, Jie Wang, Zijie Geng, Zhen Wang, Bin Li, Feng Wu</dc:creator>
    </item>
    <item>
      <title>Surrogate models for vibrational entropy based on a spatial decomposition</title>
      <link>https://arxiv.org/abs/2402.12744</link>
      <description>arXiv:2402.12744v3 Announce Type: replace-cross 
Abstract: The temperature-dependent behavior of defect densities within a crystalline structure is intricately linked to the phenomenon of vibrational entropy. Traditional methods for evaluating vibrational entropy are computationally intensive, limiting their practical utility. We show that total entropy can be decomposed into atomic site contributions and rigorously estimate the locality of site entropy. This analysis suggests that vibrational entropy can be effectively predicted using a surrogate model for site entropy. We employ machine learning to develop such a surrogate models employing the Atomic Cluster Expansion model. We supplement our rigorous analysis with an empirical convergence study. In addition we demonstrate the performance of our method for predicting vibrational formation entropy and attempt frequency of the transition rates, on point defects such as vacancies and interstitials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12744v3</guid>
      <category>physics.comp-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tina Torabi, Yangshuai Wang, Christoph Ortner</dc:creator>
    </item>
    <item>
      <title>Formalization of Complexity Analysis of the First-order Optimization Algorithms</title>
      <link>https://arxiv.org/abs/2403.11437</link>
      <description>arXiv:2403.11437v2 Announce Type: replace-cross 
Abstract: The convergence rate of various first-order optimization algorithms is a pivotal concern within the numerical optimization community, as it directly reflects the efficiency of these algorithms across different optimization problems. Our goal is making a significant step forward in the formal mathematical representation of optimization techniques using the Lean4 theorem prover. We first formalize the gradient for smooth functions and the subgradient for convex functions on a Hilbert space, laying the groundwork for the accurate formalization of algorithmic structures. Then, we extend our contribution by proving several properties of differentiable convex functions that have not yet been formalized in Mathlib. Finally, a comprehensive formalization of these algorithms is presented. These developments are not only noteworthy on their own but also serve as essential precursors to the formalization of a broader spectrum of numerical algorithms and their applications in machine learning as well as many other areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11437v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chenyi Li, Ziyu Wang, Wanyi He, Yuxuan Wu, Shengyang Xu, Zaiwen Wen</dc:creator>
    </item>
  </channel>
</rss>
