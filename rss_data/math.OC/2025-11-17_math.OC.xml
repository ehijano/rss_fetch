<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Nov 2025 04:06:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Non-Convex Global Optimization as an Optimal Stabilization Problem: Dynamical Properties</title>
      <link>https://arxiv.org/abs/2511.10815</link>
      <description>arXiv:2511.10815v1 Announce Type: new 
Abstract: We study global optimization of non-convex functions through optimal control theory. Our main result establishes that (quasi-)optimal trajectories of a discounted control problem converge globally and practically asymptotically to the set of global minimizers. Specifically, for any tolerance $\eta &gt; 0$, there exist parameters $\lambda$ (discount rate) and $t$ (time horizon) such that trajectories remain within an $\eta$-neighborhood of the global minimizers after some finite time $\tau$. This convergence is achieved directly, without solving ergodic Hamilton-Jacobi-Bellman equations. We prove parallel results for three problem formulations: evolutive discounted, stationary discounted, and evolutive non-discounted cases. The analysis relies on occupation measures to quantify the fraction of time trajectories spend away from the minimizer set, establishing both reachability and stability properties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10815v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Huang, Dante Kalise, Hicham Kouhkouh</dc:creator>
    </item>
    <item>
      <title>On the accuracy of the model predictive control method</title>
      <link>https://arxiv.org/abs/2511.11098</link>
      <description>arXiv:2511.11098v1 Announce Type: new 
Abstract: The paper investigates the accuracy of the Model Predictive Control (MPC) method for finding online approximate optimal feedback control for Bolza type problems on a fixed finite horizon. The predictions for the dynamics, the state measurements, and the solution of the auxiliary open-loop control problems that appear at every step of the MPC method may be inaccurate. The main result provides an error estimate of the MPC-generated solution compared with the optimal open-loop solution of the ``ideal'' problem, where all predictions and measurements are exact. The technique of proving the estimate involves an extension of the notion of strong metric sub-regularity of set-valued maps and utilization of a specific new metric in the control space, which makes the proof non-standard. The result is specialized for two problem classes: coercive problems, and affine problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11098v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/21M1460430</arxiv:DOI>
      <arxiv:journal_reference>SIAM J. Control Optim. 60 (2022), no. 4, 2469-2487</arxiv:journal_reference>
      <dc:creator>Georgi Angelov, Alberto Dom\'inguez Corella, Vladimir Veliov</dc:creator>
    </item>
    <item>
      <title>Non-Convex Global Optimization as an Optimal Stabilization Problem: Convergence Rates</title>
      <link>https://arxiv.org/abs/2511.11122</link>
      <description>arXiv:2511.11122v1 Announce Type: new 
Abstract: We propose a discounted infinite-horizon optimal control formulation that generates trajectories converging to the set of global minimizers of a continuous, non-convex function. The analysis provides explicit convergence rates for both the variational behavior of the value function and the pathwise convergence of the optimal trajectories. This paper is a companion to our previous work, where a more general framework was introduced; here, we focus on a specific setting in which sharper and more detailed results can be established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11122v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuyang Huang, Dante Kalise, Hicham Kouhkouh</dc:creator>
    </item>
    <item>
      <title>Integrating Aggregated Electric Vehicle Flexibilities in Unit Commitment Models using Submodular Optimization</title>
      <link>https://arxiv.org/abs/2511.11191</link>
      <description>arXiv:2511.11191v1 Announce Type: new 
Abstract: The Unit Commitment (UC) problem consists in controlling a large fleet of heterogeneous electricity production units in order to minimize the total production cost while satisfying consumer demand. Electric Vehicles (EVs) are used as a source of flexibility and are often aggregated for problem tractability. We develop a new approach to integrate EV flexibilities in the UC problem and exploit the generalized polymatroid structure of aggregated flexibilities of a large population of users to develop an exact optimization algorithm, combining a cutting-plane approach and submodular optimization. We show in particular that the UC can be solved exactly in a time which scales linearly, up to a logarithmic factor, in the number of EV users when each production unit is subject to convex constraints. We illustrate our approach by solving a real instance of a long-term UC problem, combining open-source data of the European grid (European Resource Adequacy Assessment project) and data originating from a survey of user behavior of the French EV fleet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11191v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>H\'el\`ene Arvis, Olivier Beaude, Nicolas Gast, St\'ephane Gaubert, Bruno Gaujal</dc:creator>
    </item>
    <item>
      <title>TSP integrality gap via 2-edge-connected multisubgraph problem under coincident IP optima</title>
      <link>https://arxiv.org/abs/2511.11215</link>
      <description>arXiv:2511.11215v1 Announce Type: new 
Abstract: Determining the integrality gap of the linear programming (LP) relaxation of the metric traveling salesman problem (TSP) remains a long-standing open problem. We introduce a transfer principle: when the integer optimum of the 2-edge-connected multisubgraph problem (2ECM) is a unique Hamiltonian cycle $T$, any $\alpha$-approximation algorithm for 2ECM that outputs a Hamiltonian cycle yields an $\alpha$-approximation for TSP. We further develop a cut-margin uniqueness framework that certifies $T$ as the unique integer optimum for both problems and is stable under $\ell_\infty$-bounded perturbations. We show that, if instances exist where the 2ECM has both a unique Hamiltonian cycle integer optimum and a half-integral LP solution, then the TSP integrality gap is at most 4/3 by the algorithm of Boyd et al. (SIAM Journal on Discrete Mathematics 36:1730--1747, 2022). Constructing such instances remains an open problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11215v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Toshiaki Yamanaka</dc:creator>
    </item>
    <item>
      <title>Risk averse deterministic Kalman filters for uncertain dynamical systems</title>
      <link>https://arxiv.org/abs/2511.11350</link>
      <description>arXiv:2511.11350v1 Announce Type: new 
Abstract: Taking a deterministic viewpoint this work investigates extensions of the Kalman-Bucy filter for state reconstruction to systems containing parametric uncertainty in the state operator. The emphasis lies on risk averse designs reducing the probability of large reconstruction errors. In a theoretical analysis error bounds in terms of the variance of the uncertainties are derived. The article concludes with a numerical implementation of two examples allowing for a comparison of risk neutral and risk averse estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11350v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karl Kunisch, Jesper Schr\"oder</dc:creator>
    </item>
    <item>
      <title>Linear-Space Extragradient Methods for Fast, Large-Scale Optimal Transport</title>
      <link>https://arxiv.org/abs/2511.11359</link>
      <description>arXiv:2511.11359v1 Announce Type: new 
Abstract: Optimal transport (OT) and its entropy-regularized form (EOT) have become increasingly prominent computational problems, with applications in machine learning and statistics. Recent years have seen a commensurate surge in first-order methods aiming to improve the complexity of large-scale (E)OT. However, there has been a consistent tradeoff: attaining state-of-the-art rates requires $\mathcal{O}(n^2)$ storage to enable ergodic primal averaging. In this work, we demonstrate that recently proposed primal-dual extragradient methods (PDXG) can be implemented entirely in the dual with $\mathcal{O}(n)$ storage. Additionally, we prove that regularizing the reformulated OT problem is equivalent to EOT with extensions to entropy-regularized barycenter problems, further widening the applications of the proposed method. The proposed dual-only extragradient method (DXG) is the first algorithm to achieve $\mathcal{O}(n^2\varepsilon^{-1})$ complexity for $\varepsilon$-approximate OT with $\mathcal{O}(n)$ memory. Numerical experiments demonstrate that the dual extragradient method scales favorably in non/weakly-regularized regimes compared to existing algorithms, though future work is needed to improve performance in certain problem classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11359v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthew X. Burns, Jiaming Liang</dc:creator>
    </item>
    <item>
      <title>Optimal Dividend, Reinsurance and Capital Injection Strategies for Collaborating Business Lines: The Case of Excess-of-Loss Reinsurance</title>
      <link>https://arxiv.org/abs/2511.11383</link>
      <description>arXiv:2511.11383v1 Announce Type: new 
Abstract: This paper considers an insurer with two collaborating business lines that must make three critical decisions: (1) dividend payout, (2) a combination of proportional and excess-of-loss reinsurance coverage, and (3) capital injection between the lines. The reserve level of each line is modeled using a diffusion approximation, with the insurer's objective being to maximize the weighted total discounted dividends paid until the first ruin time. We obtain the value function and the optimal strategies in closed form. We then prove that the optimal dividend payout strategy for bounded dividend rates is of threshold type, while for unbounded dividend rates it is of barrier type. The optimal combination of proportional and excess-of-loss reinsurance is shown to be pure excess-of-loss reinsurance. We also show that the optimal level of risk ceded to the reinsurer decreases as the aggregate reserve level increases. The optimal capital injection strategy involves transferring reserves to prevent the ruin of one line. Finally, numerical examples are presented to illustrate these optimal strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11383v1</guid>
      <category>math.OC</category>
      <category>q-fin.MF</category>
      <category>q-fin.RM</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tim J. Boonen, Engel John C. Dela Vega</dc:creator>
    </item>
    <item>
      <title>On Characterizations of Strong Quasiconvexity</title>
      <link>https://arxiv.org/abs/2511.11384</link>
      <description>arXiv:2511.11384v1 Announce Type: new 
Abstract: We revisit classical gradient characterizations of quasiconvexity and provide corrected proofs that close gaps in earlier arguments. For the differentiable case of $\sigma$-quasiconvexity, we establish the full equivalence between several first-order conditions, resolving a remaining implication left open in the recent literature. Our approach yields a concise, self-contained proof of a classical characterization originally stated in the 1970s and sharpens the first-order theory for strong quasiconvexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11384v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Xuan Duy Bao, Nguyen Mau Nam</dc:creator>
    </item>
    <item>
      <title>Lispchitz modulus of the argmin mapping in convex quadratic optimization</title>
      <link>https://arxiv.org/abs/2511.11455</link>
      <description>arXiv:2511.11455v1 Announce Type: new 
Abstract: This paper was initially motivated by the computation of the Lipschitz modulus of the metric projection on polyhedral convex sets in the Euclidean space when both the reference point and the polyhedron where it is projected are subject to perturbations. The paper tackles the more general problem of computing the Lipschitz modulus of the argmin mapping in the framework of canonically perturbed convex quadratic problems. We point out the fact that a point-based formula (depending only on the nominal data) for such a modulus is provided. In this way, the paper extends to the current quadratic setting some results previously developed in linear programming. As an application, we provide a point-based formula for the Lipschitz modulus of the metric projection on a polyhedral convex set.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11455v1</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mar\'ia Josefa C\'anovas, Masao Fukushima, Juan Parra</dc:creator>
    </item>
    <item>
      <title>Non-Euclidean SGD for Structured Optimization: Unified Analysis and Improved Rates</title>
      <link>https://arxiv.org/abs/2511.11466</link>
      <description>arXiv:2511.11466v1 Announce Type: new 
Abstract: Recently, several instances of non-Euclidean SGD, including SignSGD, Lion, and Muon, have attracted significant interest from the optimization community due to their practical success in training deep neural networks. Consequently, a number of works have attempted to explain this success by developing theoretical convergence analyses. Unfortunately, these results cannot properly justify the superior performance of these methods, as they could not beat the convergence rate of vanilla Euclidean SGD. We resolve this important open problem by developing a new unified convergence analysis under the structured smoothness and gradient noise assumption. In particular, our results indicate that non-Euclidean SGD (i) can exploit the sparsity or low-rank structure of the upper bounds on the Hessian and gradient noise, (ii) can provably benefit from popular algorithmic tools such as extrapolation or momentum variance reduction, and (iii) can match the state-of-the-art convergence rates of adaptive and more complex optimization algorithms such as AdaGrad and Shampoo.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11466v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Kovalev, Ekaterina Borodich</dc:creator>
    </item>
    <item>
      <title>Distributed Optimization of Pairwise Polynomial Graph Spectral Functions via Subgraph Optimization</title>
      <link>https://arxiv.org/abs/2511.11517</link>
      <description>arXiv:2511.11517v1 Announce Type: new 
Abstract: We study distributed optimization of finite-degree polynomial Laplacian spectral objectives under fixed topology and a global weight budget, targeting the collective behavior of the entire spectrum rather than a few extremal eigenvalues. By re-formulating the global cost in a bilinear form, we derive local subgraph problems whose gradients approximately align with the global descent direction via an SVD-based test on the $ZC$ matrix. This leads to an iterate-and-embed scheme over disjoint 1-hop neighborhoods that preserves feasibility by construction (positivity and budget) and scales to large geometric graphs. For objectives that depend on pairwise eigenvalue differences $h(\lambda_i-\lambda_j)$, we obtain a quadratic upper bound in the degree vector, which motivates a ``warm-start'' by degree-regularization. The warm start uses randomized gossip to estimate global average degree, accelerating subsequent local descent while maintaining decentralization, and realizing $\sim95\%{}$ of the performance with respect to centralized optimization. We further introduce a learning-based proposer that predicts one-shot edge updates on maximal 1-hop embeddings, yielding immediate objective reductions. Together, these components form a practical, modular pipeline for spectrum-aware weight tuning that preserves constraints and applies across a broader class of whole-spectrum costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11517v1</guid>
      <category>math.OC</category>
      <category>cs.SI</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jitian Liu, Nicolas Kozachuk, Subhrajit Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Drone Swarm Energy Management</title>
      <link>https://arxiv.org/abs/2511.11557</link>
      <description>arXiv:2511.11557v1 Announce Type: new 
Abstract: This note presents an analytical framework for decision-making in drone swarm systems operating under uncertainty, based on the integration of Partially Observable Markov Decision Processes (POMDP) with Deep Deterministic Policy Gradient (DDPG) reinforcement learning. The proposed approach enables adaptive control and cooperative behavior of unmanned aerial vehicles (UAVs) within a cognitive AI platform, where each agent learns optimal energy management and navigation policies from dynamic environmental states. We extend the standard DDPG architecture with a belief-state representation derived from Bayesian filtering, allowing for robust decision-making in partially observable environments. In this paper, for the Gaussian case, we numerically compare the performance of policies derived from DDPG to optimal policies for discretized versions of the original continuous problem. Simulation results demonstrate that the POMDP-DDPG-based swarm control model significantly improves mission success rates and energy efficiency compared to baseline methods. The developed framework supports distributed learning and decision coordination across multiple agents, providing a foundation for scalable cognitive swarm autonomy. The outcomes of this research contribute to the advancement of energy-aware control algorithms for intelligent multi-agent systems and can be applied in security, environmental monitoring, and infrastructure inspection scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11557v1</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michael Z. Zgurovsky, Pavlo O. Kasyanov, Liliia S. Paliichuk</dc:creator>
    </item>
    <item>
      <title>Dynamical Sampling: A Survey</title>
      <link>https://arxiv.org/abs/2511.10769</link>
      <description>arXiv:2511.10769v1 Announce Type: cross 
Abstract: This paper aims to present a unified survey of dynamical sampling and its interplay with frame theory. We summarize a range of recent developments and outline a number of open problems and potential avenues for further investigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10769v1</guid>
      <category>math.FA</category>
      <category>math.DS</category>
      <category>math.OA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akram Aldroubi, Carlos Cabrelli, Ilya Krishtal, Ursula Molter</dc:creator>
    </item>
    <item>
      <title>What the flock knows that the birds do not: exploring the emergence of joint agency in multi-agent active inference</title>
      <link>https://arxiv.org/abs/2511.10835</link>
      <description>arXiv:2511.10835v1 Announce Type: cross 
Abstract: Collective behavior pervades biological systems, from flocks of birds to neural assemblies and human societies. Yet, how such collectives acquire functional properties -- such as joint agency or knowledge -- that transcend those of their individual components remains an open question. Here, we combine active inference and information-theoretic analyses to explore how a minimal system of interacting agents can give rise to joint agency and collective knowledge. We model flocking dynamics using multiple active inference agents, each minimizing its own free energy while coupling reciprocally with its neighbors. We show that as agents self-organize, their interactions define higher-order statistical boundaries (Markov blankets) enclosing a ``flock'' that can be treated as an emergent agent with its own sensory, active, and internal states. When exposed to external perturbations (a ``predator''), the flock exhibits faster, coordinated responses than individual agents, reflecting collective sensitivity to environmental change. Crucially, analyses of synergistic information reveal that the flock encodes information about the predator's location that is not accessible to every individual bird, demonstrating implicit collective knowledge. Together, these results show how informational coupling among active inference agents can generate new levels of autonomy and inference, providing a framework for understanding the emergence of (implicit) collective knowledge and joint agency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10835v1</guid>
      <category>nlin.AO</category>
      <category>cs.MA</category>
      <category>math.OC</category>
      <category>q-bio.NC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Domenico Maisto, Davide Nuzzi, Giovanni Pezzulo</dc:creator>
    </item>
    <item>
      <title>Two Generalized Derivative-free Methods to Solve Large Scale Nonlinear Equations with Convex Constraints</title>
      <link>https://arxiv.org/abs/2511.10928</link>
      <description>arXiv:2511.10928v1 Announce Type: cross 
Abstract: In this work, we propose two derivative-free methods to address the problem of large-scale nonlinear equations with convex constraints. These algorithms satisfy the sufficient descent condition. The search directions can be considered generalizations of the Modified Optimal Perry conjugate gradient method and the conjugate gradient projection method or the Spectral Modified Optimal Perry conjugate gradient method and the Spectral Conjugate Gradient Projection method. The global convergence of the former does not depend on the Lipschitz continuity of G. In contrast, the latter's global convergence depends on the Lipschitz continuity of G. The numerical results show the efficiency of the algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10928v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kabenge Hamiss, Mohammed M. Alshahrani, Mujahid N. Syed</dc:creator>
    </item>
    <item>
      <title>Autocovariance and Optimal Design for Random Walk Metropolis-Hastings Algorithm</title>
      <link>https://arxiv.org/abs/2511.10967</link>
      <description>arXiv:2511.10967v1 Announce Type: cross 
Abstract: The Metropolis-Hastings algorithm has been extensively studied in the estimation and simulation literature, with most prior work focusing on convergence behavior and asymptotic theory. However, its covariance structure-an important statistical property for both theory and implementation-remains less understood. In this work, we provide new theoretical insights into the scalar case, focusing primarily on symmetric unimodal target distributions with symmetric random walk proposals, where we also establish an optimal proposal design. In addition, we derive some more general results beyond this setting. For the high-dimensional case, we relate the covariance matrix to the classical 0.23 average acceptance rate tuning criterion.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10967v1</guid>
      <category>stat.CO</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyi Zhang, James C. Spall</dc:creator>
    </item>
    <item>
      <title>Autonomous motion in changing environment, fibrations and reaction mechanisms</title>
      <link>https://arxiv.org/abs/2511.11042</link>
      <description>arXiv:2511.11042v1 Announce Type: cross 
Abstract: In this paper we develop further the formalism of fibrations of configuration spaces as a tool for modelling motion of autonomous systems in variable environments. We analyse the situations when the external conditions may change during the motion of the system and analyse two possibilities: (a) when the behaviour of the external conditions is known in advance; and (b) when the future changes of the external conditions are unknown but we can measure the current state and the current velocity of the external conditions, at every moment of time. We prove that in the case (a) the complexity of the motion algorithm is the same as in the case of constant external conditions; this generalises the result of \cite{FGY}. In case (b) we introduce a new concept of a reaction mechanism which allows to take into account unexpected and unpredictable changes in the environment. A reaction mechanism is mathematically an infinitesimal lifting function on a fibre bundle, a nonlinear generalisation of the classical concept of an Ehresmann connection. We illustrate these notions by examples which show that nonlinear infinitesimal lifting function (reaction mechanisms) appear naturally, are inevitable and ubiquitous.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11042v1</guid>
      <category>math.AT</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Farber, Stefan Kurz, Mathias Pillin</dc:creator>
    </item>
    <item>
      <title>Extended-Krylov-subspace methods for trust-region and norm-regularization subproblems</title>
      <link>https://arxiv.org/abs/2511.11135</link>
      <description>arXiv:2511.11135v1 Announce Type: cross 
Abstract: We consider an effective new method for solving trust-region and norm-regularization problems that arise as subproblems in many optimization applications. We show that the solutions to such subproblems lie on a manifold of approximately very low rank as a function of their controlling parameters (trust-region radius or regularization weight). Based on this, we build a basis for this manifold using an efficient extended-Krylov-subspace iteration that involves a single matrix factorization. The problems within the subspace using such a basis may be solved at very low cost using effective high-order root-finding methods. This then provides an alternative to common methods using multiple factorizations or standard Krylov subspaces. We provide numerical results to illustrate the effectiveness of our {\tt TREK}/{\tt NREK} approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11135v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hussam Al Daas, Nicholas I. M. Gould</dc:creator>
    </item>
    <item>
      <title>A Best-of-Both-Worlds Proof for Tsallis-INF without Fenchel Conjugates</title>
      <link>https://arxiv.org/abs/2511.11211</link>
      <description>arXiv:2511.11211v1 Announce Type: cross 
Abstract: In this short note, we present a simple derivation of the best-of-both-world guarantee for the Tsallis-INF multi-armed bandit algorithm from J. Zimmert and Y. Seldin. Tsallis-INF: An optimal algorithm for stochastic and adversarial bandits. Journal of Machine Learning Research, 22(28):1-49, 2021. URL https://jmlr.csail.mit.edu/papers/volume22/19-753/19-753.pdf. In particular, the proof uses modern tools from online convex optimization and avoid the use of conjugate functions. Also, we do not optimize the constants in the bounds in favor of a slimmer proof.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11211v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wei-Cheng Lee, Francesco Orabona</dc:creator>
    </item>
    <item>
      <title>An Efficient Algorithm for Minimizing Ordered Norms in Fractional Load Balancing</title>
      <link>https://arxiv.org/abs/2511.11237</link>
      <description>arXiv:2511.11237v1 Announce Type: cross 
Abstract: We study the problem of minimizing an ordered norm of a load vector (indexed by a set of $d$ resources), where a finite number $n$ of customers $c$ contribute to the load of each resource by choosing a solution $x_c$ in a convex set $X_c \subseteq \mathbb{R}^d_{\geq 0}$; so we minimize $||\sum_{c}x_c||$ for some fixed ordered norm $||\cdot||$. We devise a randomized algorithm that computes a $(1+\varepsilon)$-approximate solution to this problem and makes, with high probability, $\mathcal{O}((n+d) (\varepsilon^{-2}+\log\log d)\log (n+d))$ calls to oracles that minimize linear functions (with non-negative coefficients) over $X_c$. While this has been known for the $\ell_{\infty}$ norm via the multiplicative weights update method, existing proof techniques do not extend to arbitrary ordered norms. Our algorithm uses a resource price mechanism that is motivated by the follow-the-regularized-leader paradigm, and is expressed by smooth approximations of ordered norms. We need and show that these have non-trivial stability properties, which may be of independent interest. For each customer, we define dynamic cost budgets, which evolve throughout the algorithm, to determine the allowed step sizes. This leads to non-uniform updates and may even reject certain oracle solutions. Using non-uniform sampling together with a martingale argument, we can guarantee sufficient expected progress in each iteration, and thus bound the total number of oracle calls with high probability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11237v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Blankenburg, Antonia Ellerbrock, Thomas Kesselheim, Jens Vygen</dc:creator>
    </item>
    <item>
      <title>Policy Optimization for Unknown Systems using Differentiable Model Predictive Control</title>
      <link>https://arxiv.org/abs/2511.11308</link>
      <description>arXiv:2511.11308v1 Announce Type: cross 
Abstract: Model-based policy optimization often struggles with inaccurate system dynamics models, leading to suboptimal closed-loop performance. This challenge is especially evident in Model Predictive Control (MPC) policies, which rely on the model for real-time trajectory planning and optimization. We introduce a novel policy optimization framework for MPC-based policies combining differentiable optimization with zeroth-order optimization. Our method combines model-based and model-free gradient estimation approaches, achieving faster transient performance compared to fully data-driven approaches while maintaining convergence guarantees, even under model uncertainty. We demonstrate the effectiveness of the proposed approach on a nonlinear control task involving a 12-dimensional quadcopter model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11308v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Zuliani, Efe C. Balta, John Lygeros</dc:creator>
    </item>
    <item>
      <title>A Method of the Quasidifferential Descent in a Problem of Bringing a Nonsmooth System from One Point to Another</title>
      <link>https://arxiv.org/abs/2205.00223</link>
      <description>arXiv:2205.00223v3 Announce Type: replace 
Abstract: The paper considers the problem of constructing program control for an object described by a system with a quasidifferentiable right-hand side. The control aim is to bring the system from a given initial position to a given final state in given finite time. The admissible controls are piecewise continuous vector-functions with values from a parallelepiped. The original problem is reduced to unconditional minimization of a functional. Herewith, the new technical idea is implemented to consider phase trajectory and its derivative as independent variables (and to take the natural relation between them into account via a special penalty function). This idea qualitatively simplified the quasidifferential structure and allowed to overcome the principal difficulties in constructing the steepest descent direction. The quasidifferentiability of the functional is proved, necessary conditions for its minimum are obtained in terms of quasidifferential. In contrast to the existing ones, due to the mentioned idea to ``separate'' the trajectory and its derivative the obtained optimality conditions in the paper are pointwise. In order to solve the obtained minimization problem in the functional space the quasidifferential descent method is applied. Then the discretization is implemented. In contrast to majority of existing methods when the initial problem is discretized, here the discretization is implemented after the quasidifferential is already obtained. The quasidifferential descent directions are calculated independently at each time moment of discretization due to the comparatively simple quasidifferential structure, possible to obtain via the technical idea noted. The algorithm developed is demonstrated by examples. The proposed method can be applied to nonsmooth optimal control problem in Lagrange form (additionally the integral with a quasidifferentiable integrand is to be minimized).</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.00223v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Fominyh</dc:creator>
    </item>
    <item>
      <title>Strong Duality in Risk-Constrained Nonconvex Functional Programming</title>
      <link>https://arxiv.org/abs/2206.11948</link>
      <description>arXiv:2206.11948v4 Announce Type: replace 
Abstract: We show that a wide class of risk-constrained nonconvex functional optimization problems exhibit strong duality, regardless of nonconvexity. We develop two novel results under distinct sets of assumptions, establishing strong duality over both decomposable policy spaces (matching and extending prior work in the risk neutral case), and nondecomposable policy spaces with structure (e.g., continuity or smoothness), including certain universal finite-dimensional (fixed depth/width) neural network parametrizations as special cases (improving established results in the risk-neutral setting as well). We consider constraints featuring convex and positively homogeneous risk measures with bounded risk envelopes, generalizing expectations. Popular risk measures supported within our setting include the conditional value-at-risk (CVaR), the (even non-monotone) mean-absolute deviation (MAD), certain distributionally robust representations and more generally all real-valued coherent risk measures on the space $L_1$. We further discuss various generalizations of our base model, extensions for risk measures supported on $L_{p&gt;1}$, implications in the context of mean-risk tradeoff models, as well as applications in wireless systems resource allocation, and supervised constrained learning. Our core proof technique appears to be new and relies on risk conjugate duality in tandem with J. J. Uhl's weak extension of A. A. Lyapunov's convexity theorem for vector measures taking values in infinite-dimensional Banach spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.11948v4</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dionysis Kalogerias, Spyridon Pougkakiotis</dc:creator>
    </item>
    <item>
      <title>Mirror Descent Algorithms with Nearly Dimension-Independent Rates for Differentially-Private Stochastic Saddle-Point Problems</title>
      <link>https://arxiv.org/abs/2403.02912</link>
      <description>arXiv:2403.02912v2 Announce Type: replace 
Abstract: We study the problem of differentially-private (DP) stochastic (convex-concave) saddle-points in the $\ell_1$ setting. We propose $(\varepsilon, \delta)$-DP algorithms based on stochastic mirror descent that attain nearly dimension-independent convergence rates for the expected duality gap, a type of guarantee that was known before only for bilinear objectives. For convex-concave and first-order-smooth stochastic objectives, our algorithms attain a rate of $\sqrt{\log(d)/n} + (\log(d)^{3/2}/[n\varepsilon])^{1/3}$, where $d$ is the dimension of the problem and $n$ the dataset size. Under an additional second-order-smoothness assumption, we show that the duality gap is bounded by $\sqrt{\log(d)/n} + \log(d)/\sqrt{n\varepsilon}$ with high probability, by using bias-reduced gradient estimators. This rate provides evidence of the near-optimality of our approach, since a lower bound of $\sqrt{\log(d)/n} + \log(d)^{3/4}/\sqrt{n\varepsilon}$ exists. Finally, we show that combining our methods with acceleration techniques from online learning leads to the first algorithm for DP Stochastic Convex Optimization in the $\ell_1$ setting that is not based on Frank-Wolfe methods. For convex and first-order-smooth stochastic objectives, our algorithms attain an excess risk of $\sqrt{\log(d)/n} + \log(d)^{7/10}/[n\varepsilon]^{2/5}$, and when additionally assuming second-order-smoothness, we improve the rate to $\sqrt{\log(d)/n} + \log(d)/\sqrt{n\varepsilon}$. Instrumental to all of these results are various extensions of the classical Maurey Sparsification Lemma \cite{Pisier:1980}, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02912v2</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom\'as Gonz\'alez, Crist\'obal Guzm\'an, Courtney Paquette</dc:creator>
    </item>
    <item>
      <title>Tropical Gradient Descent</title>
      <link>https://arxiv.org/abs/2405.19551</link>
      <description>arXiv:2405.19551v3 Announce Type: replace 
Abstract: We propose a gradient descent method for solving optimization problems arising in settings of tropical geometry - a variant of algebraic geometry that has attracted growing interest in applications such as computational biology, economics, and computer science. Our approach takes advantage of the polyhedral and combinatorial structures arising in tropical geometry to propose a versatile method for approximating local minima in tropical statistical optimization problems - a rapidly growing body of work in recent years. Theoretical results establish global solvability for 1-sample problems and a convergence rate matching classical gradient descent. Numerical experiments demonstrate the method's superior performance compared to classical gradient descent for tropical optimization problems which exhibit tropical convexity but not classical convexity. We also demonstrate the seamless integration of tropical descent into advanced optimization methods, such as Adam, offering improved overall accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19551v3</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>J Glob Optim 93 (2025) 413-449</arxiv:journal_reference>
      <dc:creator>Roan Talbut, Anthea Monod</dc:creator>
    </item>
    <item>
      <title>Domain decomposition for entropic unbalanced optimal transport</title>
      <link>https://arxiv.org/abs/2410.08859</link>
      <description>arXiv:2410.08859v3 Announce Type: replace 
Abstract: Solving large scale entropic optimal transport problems with the Sinkhorn algorithm remains challenging, and domain decomposition has been shown to be an efficient strategy for problems on large grids. Unbalanced optimal transport is a versatile variant of the balanced transport problem and its entropic regularization can be solved with an adapted Sinkhorn algorithm. However, it is a priori unclear how to apply domain decomposition to unbalanced problems since the independence of the cell problems is lost. In this article we show how this difficulty can be overcome at a theoretical and practical level and demonstrate with experiments that domain decomposition is also viable and efficient on large unbalanced entropic transport problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08859v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ismael Medina, The Sang Nguyen, Bernhard Schmitzer</dc:creator>
    </item>
    <item>
      <title>Global and Robust Optimization for Non-Convex Quadratic Programs</title>
      <link>https://arxiv.org/abs/2503.07310</link>
      <description>arXiv:2503.07310v3 Announce Type: replace 
Abstract: This paper presents a novel algorithm integrating global and robust optimization methods to solve continuous non-convex quadratic problems under convex uncertainty sets. The proposed Robust spatial branch-and-bound (RsBB) algorithm combines the principles of spatial branch-and-bound (sBB) with robust cutting planes. We apply the RsBB algorithm to quadratically constrained quadratic programming (QCQP) problems, utilizing McCormick envelopes to obtain convex lower bounds. The performance of the RsBB algorithm is compared with stateof-the-art methods that rely on global solvers. As computational test bed for our proposed approach we focus on pooling problems under different types and sizes of uncertainty sets. The findings of our work highlight the efficiency of the RsBB algorithm in terms of computational time and optimality convergence and provide insights to the advantages of combining robustness and optimality search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07310v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Asimina Marousi, Vassilis M. Charitopoulos</dc:creator>
    </item>
    <item>
      <title>Projection-based curve pattern search for black-box optimization over smooth convex sets</title>
      <link>https://arxiv.org/abs/2503.20616</link>
      <description>arXiv:2503.20616v2 Announce Type: replace 
Abstract: In this paper, we deal with the problem of optimizing a black-box smooth function over a full-dimensional smooth convex set. We study sets of feasible curves that allow to properly characterize stationarity of a solution and possibly carry out sound backtracking curvilinear searches. We then propose a general pattern search algorithmic framework that exploits curves of this type to carry out poll steps and for which we prove properties of asymptotic convergence to stationary points. We particularly point out that the proposed framework covers the case where search curves are arcs induced by the Euclidean projection of coordinate directions. The method is finally proved to arguably be superior, on smooth problems, than other recent projection-based algorithms and is competitive with state-of-the-art methods from the literature on constrained black-box optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20616v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoxi Jia, Matteo Lapucci, Pierluigi Mansueto</dc:creator>
    </item>
    <item>
      <title>Reconciling Discrete-Time Mixed Policies and Continuous-Time Relaxed Controls in Reinforcement Learning and Stochastic Control</title>
      <link>https://arxiv.org/abs/2504.21793</link>
      <description>arXiv:2504.21793v2 Announce Type: replace 
Abstract: Reinforcement learning (RL) is currently one of the most prominent methods for optimizing dynamical systems, with breakthrough results across various fields. The framework is based on the concept of a Markov decision process (MDP), leading to a discrete-time optimal control problem. In the RL literature, such problems are typically formulated and solved using mixed policies, from which random actions are sampled at each time step. Recently, part of the optimal control community has begun investigating continuous-time versions of RL algorithms, replacing MDPs with continuous-time stochastic processes governed by relaxed controls, and asserting a full analogy between the two formulations. In this work, we examine the limitations of this analogy and rigorously establish a connection between the two problems in the case where only the drift term of the continuous-time model is controlled. We prove strong convergence of the RL implementation of mixed strategies as the time discretization mesh tends to zero. We also discuss the technical challenges posed by the possible presence of control in the diffusion component of the state.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.21793v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rene Carmona, Mathieu Lauriere</dc:creator>
    </item>
    <item>
      <title>History-Aware Adaptive High-Order Tensor Regularization</title>
      <link>https://arxiv.org/abs/2511.05788</link>
      <description>arXiv:2511.05788v3 Announce Type: replace 
Abstract: In this paper, we develop a new adaptive regularization method for minimizing a composite function, which is the sum of a $p$th-order ($p \ge 1$) Lipschitz continuous function and a simple, convex, and possibly nonsmooth function. We use a history of local Lipschitz estimates to adaptively select the current regularization parameter, an approach we shall term the {\it history-aware adaptive regularization method}. We explore how the selection of an appropriate volume of historical information affects both the theoretical and practical performance. By using all the historical information, our method matches the complexity guarantees of the standard $p$th-order tensor methods that require a known Lipschitz constant, for both convex and nonconvex objectives. In the nonconvex case, the number of iterations required to find an $(\epsilon_g,\epsilon_H)$-approximate second-order stationary point is bounded by $\mathcal{O}(\max\{\epsilon_g^{-(p+1)/p}, \epsilon_H^{-(p+1)/(p-1)}\})$. For convex functions, we establish an $\mathcal{O}(\epsilon^{-1/p})$ iteration complexity for finding an $\epsilon$-approximate optimal point and further propose an accelerated variant attaining an iteration complexity of $\mathcal{O}(\epsilon^{-1/(p+1)})$. For practical consideration, we propose several variants of this method with only part of historical information. We introduce cyclic and sliding-window strategies for choosing historical Lipschitz estimates, which mitigate the limitation of overly conservative updates. As long as a rough upper bound of the Lipschitz constant is known, these two variants achieve the same iteration complexity guarantees in terms of the input accuracy as the method using full historical information. Finally, extensive numerical experiments are conducted to demonstrate the effectiveness of our adaptive approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.05788v3</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chang He, Bo Jiang, Yuntian Jiang, Chuwen Zhang, Shuzhong Zhang</dc:creator>
    </item>
    <item>
      <title>Dual MPC for Active Learning of Nonparametric Uncertainties</title>
      <link>https://arxiv.org/abs/2511.08542</link>
      <description>arXiv:2511.08542v2 Announce Type: replace 
Abstract: This manuscript presents a dual model predictive controller (MPC) that balances the two objectives of dual control, namely, system identification and control. In particular, we propose a Gaussian process (GP)-based MPC that uses the posterior GP covariance for active learning. The dual MPC can steer the system towards states with high covariance, or to the setpoint, thereby balancing system identification and control performance (exploration vs. exploitation). We establish robust constraint satisfaction of the novel dual MPC through a contingency plan. We demonstrate the dual MPC in a numerical study of a nonlinear system with nonparametric uncertainties.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08542v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tren Baltussen, Maurice Heemels, Alexander Katriniok</dc:creator>
    </item>
    <item>
      <title>Locally Linear Convergence for Nonsmooth Convex Optimization via Coupled Smoothing and Momentum</title>
      <link>https://arxiv.org/abs/2511.10239</link>
      <description>arXiv:2511.10239v2 Announce Type: replace 
Abstract: We propose an adaptive accelerated smoothing technique for a nonsmooth convex optimization problem where the smoothing update rule is coupled with the momentum parameter. We also extend the setting to the case where the objective function is the sum of two nonsmooth functions. With regard to convergence rate, we provide the global (optimal) sublinear convergence guarantees of O(1/k), which is known to be provably optimal for the studied class of functions, along with a local linear rate if the nonsmooth term fulfills a so-call locally strong convexity condition. We validate the performance of our algorithm on several problem classes, including regression with the l1-norm (the Lasso problem), sparse semidefinite programming (the MaxCut problem), Nuclear norm minimization with application in model free fault diagnosis, and l_1-regularized model predictive control to showcase the benefits of the coupling. An interesting observation is that although our global convergence result guarantees O(1/k) convergence, we consistently observe a practical transient convergence rate of O(1/k^2), followed by asymptotic linear convergence as anticipated by the theoretical result. This two-phase behavior can also be explained in view of the proposed smoothing rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.10239v2</guid>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Reza Rahimi Baghbadorani, Sergio Grammatico, Peyman Mohajerin Esfahani</dc:creator>
    </item>
    <item>
      <title>On bounds for norms of reparameterized ReLU artificial neural network parameters: sums of fractional powers of the Lipschitz norm control the network parameter vector</title>
      <link>https://arxiv.org/abs/2206.13646</link>
      <description>arXiv:2206.13646v2 Announce Type: replace-cross 
Abstract: It is an elementary fact in the scientific literature that the Lipschitz norm of the realization function of a feedforward fully-connected rectified linear unit (ReLU) artificial neural network (ANN) can, up to a multiplicative constant, be bounded from above by sums of powers of the norm of the ANN parameter vector. Roughly speaking, in this work we reveal in the case of shallow ANNs that the converse inequality is also true. More formally, we prove that the norm of the equivalence class of ANN parameter vectors with the same realization function is, up to a multiplicative constant, bounded from above by the sum of powers of the Lipschitz norm of the ANN realization function (with the exponents $ 1/2 $ and $ 1 $). Moreover, we prove that this upper bound only holds when employing the Lipschitz norm but does neither hold for H\"older norms nor for Sobolev-Slobodeckij norms. Furthermore, we prove that this upper bound only holds for sums of powers of the Lipschitz norm with the exponents $ 1/2 $ and $ 1 $ but does not hold for the Lipschitz norm alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.13646v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnulf Jentzen, Timo Kr\"oger</dc:creator>
    </item>
    <item>
      <title>Understanding Deep Representation Learning via Layerwise Feature Compression and Discrimination</title>
      <link>https://arxiv.org/abs/2311.02960</link>
      <description>arXiv:2311.02960v4 Announce Type: replace-cross 
Abstract: Over the past decade, deep learning has proven to be a highly effective tool for learning meaningful features from raw data. However, it remains an open question how deep networks perform hierarchical feature learning across layers. In this work, we attempt to unveil this mystery by investigating the structures of intermediate features. Motivated by our empirical findings that linear layers mimic the roles of deep layers in nonlinear networks for feature learning, we explore how deep linear networks transform input data into output by investigating the output (i.e., features) of each layer after training in the context of multi-class classification problems. Toward this goal, we first define metrics to measure within-class compression and between-class discrimination of intermediate features, respectively. Through theoretical analysis of these two metrics, we show that the evolution of features follows a simple and quantitative pattern from shallow to deep layers when the input data is nearly orthogonal and the network weights are minimum-norm, balanced, and approximate low-rank: Each layer of the linear network progressively compresses within-class features at a geometric rate and discriminates between-class features at a linear rate with respect to the number of layers that data have passed through. To the best of our knowledge, this is the first quantitative characterization of feature evolution in hierarchical representations of deep linear networks. Empirically, our extensive experiments not only validate our theoretical results numerically but also reveal a similar pattern in deep nonlinear networks which aligns well with recent empirical studies. Moreover, we demonstrate the practical implications of our results in transfer learning. Our code is available at https://github.com/Heimine/PNC_DLN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.02960v4</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Wang, Xiao Li, Can Yaras, Zhihui Zhu, Laura Balzano, Wei Hu, Qing Qu</dc:creator>
    </item>
    <item>
      <title>Self-Supervised Learning of Iterative Solvers for Constrained Optimization</title>
      <link>https://arxiv.org/abs/2409.08066</link>
      <description>arXiv:2409.08066v2 Announce Type: replace-cross 
Abstract: The real-time solution of parametric optimization problems is critical for applications that demand high accuracy under tight real-time constraints, such as model predictive control. To this end, this work presents a learning-based iterative solver for constrained optimization, comprising a neural network predictor that generates initial primal-dual solution estimates, followed by a learned iterative solver that refines these estimates to reach high accuracy. We introduce a novel loss function based on Karush-Kuhn-Tucker (KKT) optimality conditions, enabling fully self-supervised training without pre-sampled optimizer solutions. Theoretical guarantees ensure that the training loss function attains minima exclusively at KKT points. A convexification procedure enables application to nonconvex problems while preserving these guarantees. Experiments on two nonconvex case studies demonstrate speedups of up to one order of magnitude compared to state-of-the-art solvers such as IPOPT, while achieving orders of magnitude higher accuracy than competing learning-based approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08066v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lukas L\"uken, Sergio Lucia</dc:creator>
    </item>
    <item>
      <title>Evolutionary Retrofitting</title>
      <link>https://arxiv.org/abs/2410.11330</link>
      <description>arXiv:2410.11330v2 Announce Type: replace-cross 
Abstract: AfterLearnER (After Learning Evolutionary Retrofitting) consists in applying evolutionary optimization to refine fully trained machine learning models by optimizing a set of carefully chosen parameters or hyperparameters of the model, with respect to some actual, exact, and hence possibly non-differentiable error signal, performed on a subset of the standard validation set. The efficiency of AfterLearnER is demonstrated by tackling non-differentiable signals such as threshold-based criteria in depth sensing, the word error rate in speech re-synthesis, the number of kills per life at Doom, computational accuracy or BLEU in code translation, image quality in 3D generative adversarial networks (GANs), and user feedback in image generation via Latent Diffusion Models (LDM). This retrofitting can be done after training, or dynamically at inference time by taking into account the user feedback. The advantages of AfterLearnER are its versatility, the possibility to use non-differentiable feedback, including human evaluations (i.e., no gradient is needed), the limited overfitting supported by a theoretical study, and its anytime behavior. Last but not least, AfterLearnER requires only a small amount of feedback, i.e., a few dozen to a few hundred scalars, compared to the tens of thousands needed in most related published works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11330v2</guid>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mathurin Videau (TAU), Mariia Zameshina (LIGM), Alessandro Leite (TAU), Laurent Najman (LIGM, KUSTAR), Marc Schoenauer (TAU), Olivier Teytaud (TAU)</dc:creator>
    </item>
    <item>
      <title>Optimal Modified Feedback Strategies in LQ Games under Control Imperfections</title>
      <link>https://arxiv.org/abs/2503.19200</link>
      <description>arXiv:2503.19200v3 Announce Type: replace-cross 
Abstract: Game-theoretic approaches and Nash equilibrium have been widely applied across various engineering domains. However, practical challenges such as disturbances, delays, and actuator limitations can hinder the precise execution of Nash equilibrium strategies. This work investigates the impact of such implementation imperfections on game trajectories and players' costs in the context of a two-player finite-horizon linear quadratic (LQ) nonzero-sum game. Specifically, we analyze how small deviations by one player, measured or estimated at each stage, affect the state and cost function of the other player. To mitigate these effects, we propose an adjusted control policy that optimally compensates for the deviations under the stated information structure and can, under certain conditions, exploit them to improve performance. Rigorous mathematical analysis and proofs are provided, and the effectiveness of the proposed method is demonstrated through a representative numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.19200v3</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdis Rabbani, Navid Mojahed, Shima Nazari</dc:creator>
    </item>
    <item>
      <title>Interpolation Conditions for Data Consistency and Prediction in Noisy Linear Systems</title>
      <link>https://arxiv.org/abs/2504.08484</link>
      <description>arXiv:2504.08484v2 Announce Type: replace-cross 
Abstract: We develop an interpolation-based framework for noisy linear systems with unknown system matrix with bounded norm (implying bounded growth or non-increasing energy), and bounded process noise energy. The proposed approach characterizes all trajectories consistent with the measured data and these prior bounds in a purely data-driven manner. This characterization enables data-consistency verification, inference, and one-step ahead prediction, which can be leveraged for safety verification and cost minimization. Ultimately, this work represents a preliminary step toward exploiting interpolation conditions in data-driven control, offering a systematic way to characterize trajectories consistent with a dynamical system within a given class and enabling their use in control design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.08484v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martina Vanelli, Nima Monshizadeh, Julien M. Hendrickx</dc:creator>
    </item>
    <item>
      <title>Beyond $\tilde{O}(\sqrt{T})$ Constraint Violation for Online Convex Optimization with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2505.06709</link>
      <description>arXiv:2505.06709v2 Announce Type: replace-cross 
Abstract: We study Online Convex Optimization with adversarial constraints (COCO). At each round a learner selects an action from a convex decision set and then an adversary reveals a convex cost and a convex constraint function. The goal of the learner is to select a sequence of actions to minimize both regret and the cumulative constraint violation (CCV) over a horizon of length $T$. The best-known policy for this problem achieves $O(\sqrt{T})$ regret and $\tilde{O}(\sqrt{T})$ CCV. In this paper, we improve this by trading off regret to achieve substantially smaller CCV. This trade-off is especially important in safety-critical applications, where satisfying the safety constraints is non-negotiable. Specifically, for any bounded convex cost and constraint functions, we propose an online policy that achieves $\tilde{O}(\sqrt{dT}+ T^\beta)$ regret and $\tilde{O}(dT^{1-\beta})$ CCV, where $d$ is the dimension of the decision set and $\beta \in [0,1]$ is a tunable parameter. We begin with a special case, called the $\textsf{Constrained Expert}$ problem, where the decision set is a probability simplex and the cost and constraint functions are linear. Leveraging a new adaptive small-loss regret bound, we propose a computationally efficient policy for the $\textsf{Constrained Expert}$ problem, that attains $O(\sqrt{T\ln N}+T^{\beta})$ regret and $\tilde{O}(T^{1-\beta} \ln N)$ CCV for $N$ number of experts. The original problem is then reduced to the $\textsf{Constrained Expert}$ problem via a covering argument. Finally, with an additional $M$-smoothness assumption, we propose a computationally efficient first-order policy attaining $O(\sqrt{MT}+T^{\beta})$ regret and $\tilde{O}(MT^{1-\beta})$ CCV.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.06709v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abhishek Sinha, Rahul Vaze</dc:creator>
    </item>
    <item>
      <title>Cautious Optimism: A Meta-Algorithm for Near-Constant Regret in General Games</title>
      <link>https://arxiv.org/abs/2506.05005</link>
      <description>arXiv:2506.05005v2 Announce Type: replace-cross 
Abstract: We introduce Cautious Optimism, a framework for substantially faster regularized learning in general games. Cautious Optimism, as a variant of Optimism, adaptively controls the learning pace in a dynamic, non-monotone manner to accelerate no-regret learning dynamics. Cautious Optimism takes as input any instance of Follow-the-Regularized-Leader (FTRL) and outputs an accelerated no-regret learning algorithm (COFTRL) by pacing the underlying FTRL with minimal computational overhead. Importantly, it retains uncoupledness, that is, learners do not need to know other players' utilities. Cautious Optimistic FTRL (COFTRL) achieves near-optimal $O_T(\log T)$ regret in diverse self-play (mixing and matching regularizers) while preserving the optimal $O_T(\sqrt{T})$ regret in adversarial scenarios. In contrast to prior works (e.g., Syrgkanis et al. [2015], Daskalakis et al. [2021]), our analysis does not rely on monotonic step sizes, showcasing a novel route for fast learning in general games. Moreover, instances of COFTRL achieve new state-of-the-art regret minimization guarantees in general convex games, exponentially improving the dependence on the dimension of the action space $d$ over previous works [Farina et al., 2022a].</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05005v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>math.OC</category>
      <pubDate>Mon, 17 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashkan Soleymani, Georgios Piliouras, Gabriele Farina</dc:creator>
    </item>
  </channel>
</rss>
