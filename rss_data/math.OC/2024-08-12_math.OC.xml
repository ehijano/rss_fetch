<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 13 Aug 2024 02:22:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 12 Aug 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Single-Loop Finite-Time Convergent Policy Optimization Algorithm for Mean Field Games (and Average-Reward Markov Decision Processes)</title>
      <link>https://arxiv.org/abs/2408.04780</link>
      <description>arXiv:2408.04780v2 Announce Type: new 
Abstract: We study the problem of finding an equilibrium of a mean field game (MFG) -- a policy performing optimally in a Markov decision process (MDP) determined by the induced mean field, where the mean field is a distribution over a population of agents and a function of the policy itself. Prior solutions to MFGs are built upon either the contraction assumption on a mean field optimality-consistency operator or strict weak monotonicity. The class of problems satisfying these assumptions represent only a small subset of MFGs, to which any MFG admitting more than one equilibrium does not belong. In this work, we expand the class of solvable MFGs by introducing a "herding condition" and propose a direct gradient-based policy optimization algorithm that provably finds an (not necessarily unique) equilibrium within the class. The algorithm, named Accelerated Single-loop Actor Critic Algorithm for Mean Field Games (ASAC-MFG), is data-driven, single-loop, and single-sample-path. We characterize the finite-time and finite-sample convergence of ASAC-MFG to a mean field equilibrium building on a novel multi-time-scale analysis. We support the theoretical results with illustrative numerical simulations.
  As an additional contribution, we show how the developed novel analysis can benefit the literature on average-reward MDPs. An MFG reduces to a standard MDP when the transition kernel and reward are independent of the mean field. As a byproduct of our analysis for MFGs, we get an actor-critic algorithm for finding the optimal policy in average-reward MDPs, with a convergence guarantee matching the state-of-the-art. The prior bound is derived under the assumption that the Bellman operator is contractive, which never holds in average-reward MDPs. Our analysis removes this assumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04780v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sihan Zeng, Sujay Bhatt, Alec Koppel, Sumitra Ganesh</dc:creator>
    </item>
    <item>
      <title>Cost Attribution And Risk-Averse Unit Commitment In Power Grids Using Integrated Gradient</title>
      <link>https://arxiv.org/abs/2408.04830</link>
      <description>arXiv:2408.04830v1 Announce Type: new 
Abstract: This paper introduces a novel approach to addressing uncertainty and associated risks in power system management, focusing on the discrepancies between forecasted and actual values of load demand and renewable power generation. By employing Economic Dispatch (ED) with both day-ahead forecasts and actual values, we derive two distinct system costs, revealing the financial risks stemming from uncertainty. We present a numerical algorithm inspired by the Integrated Gradients (IG) method to attribute the contribution of stochastic components to the difference in system costs. This method, originally developed for machine learning, facilitates the understanding of individual input features' impact on the model's output prediction. By assigning numeric values to represent the influence of variability on operational costs, our method provides actionable insights for grid management. As an application, we propose a risk-averse unit commitment framework, leveraging our cost attribution algorithm to adjust the capacity of renewable generators, thus mitigating system risk. Simulation results on the RTS-GMLC grid demonstrate the efficacy of our approach in improving grid reliability and reducing operational costs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04830v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rene Carmona, Ronnie Sircar, Xinshuo Yang</dc:creator>
    </item>
    <item>
      <title>A Vectorized Positive Semidefinite Penalty Method for Unconstrained Binary Quadratic Programming</title>
      <link>https://arxiv.org/abs/2408.04875</link>
      <description>arXiv:2408.04875v1 Announce Type: new 
Abstract: The unconstrained binary quadratic programming (UBQP) problem is a class of problems of significant importance in many practical applications, such as in combinatorial optimization, circuit design, and other fields. The positive semidefinite penalty (PSDP) method originated from research on semidefinite relaxation, where the introduction of an exact penalty function improves the efficiency and accuracy of problem solving. In this paper, we propose a vectorized PSDP method for solving the UBQP problem, which optimizes computational efficiency by vectorizing matrix variables within a PSDP framework. Algorithmic enhancements in penalty updating and initialization are implemented, along with the introduction of two algorithms that integrate the proximal point algorithm and the projection alternating BB method for subproblem resolution. Properties of the penalty function and algorithm convergence are analyzed. Numerical experiments show the superior performance of the method in providing high-quality solutions and satisfactory solution times compared to the semidefinite relaxation method and other established methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04875v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xinyue Huo, Ran Gu</dc:creator>
    </item>
    <item>
      <title>Hybrid Minimum-Seeking in Synergistic Lyapunov Functions: Robust Global Stabilization under Unknown Control Directions</title>
      <link>https://arxiv.org/abs/2408.04882</link>
      <description>arXiv:2408.04882v1 Announce Type: new 
Abstract: We consider the problem of robust global stabilization for a control-affine systems with dynamic uncertainty in the control directions and in the presence of topological obstructions that preclude the existence of smooth global control Lyapunov functions. By leveraging a recent Lie-bracket averaging result for hybrid dynamic inclusions introduced in \cite{abdelgalil2023lie}, we propose a novel universal hybrid feedback law that induces robust global practical stability by seeking the minimum point of a collection of suitable synergistic Lyapunov functions. As concrete applications of our results, we present novel hybrid high-frequency high-amplitude feedback laws for the solution of robust global stabilization problems on different types of manifolds under unknown control directions, as well as controllers for obstacle avoidance problems in vehicles characterized by kinematic models describing both holonomic and non-holonomic models. By leveraging Lie-bracket averaging for hybrid systems, we show how the proposed hybrid minimum-seeking feedback laws can overcome lack of controllability during persistent (bounded) periods of time. Numerical simulation results are presented to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04882v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahmoud Abdelgalil, Jorge I. Poveda</dc:creator>
    </item>
    <item>
      <title>Tight Time Complexities in Parallel Stochastic Optimization with Arbitrary Computation Dynamics</title>
      <link>https://arxiv.org/abs/2408.04929</link>
      <description>arXiv:2408.04929v1 Announce Type: new 
Abstract: In distributed stochastic optimization, where parallel and asynchronous methods are employed, we establish optimal time complexities under virtually any computation behavior of workers/devices/CPUs/GPUs, capturing potential disconnections due to hardware and network delays, time-varying computation powers, and any possible fluctuations and trends of computation speeds. These real-world scenarios are formalized by our new universal computation model. Leveraging this model and new proof techniques, we discover tight lower bounds that apply to virtually all synchronous and asynchronous methods, including Minibatch SGD, Asynchronous SGD (Recht et al., 2011), and Picky SGD (Cohen et al., 2021). We show that these lower bounds, up to constant factors, are matched by the optimal Rennala SGD and Malenia SGD methods (Tyurin &amp; Richt\'arik, 2023).</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04929v1</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Tyurin</dc:creator>
    </item>
    <item>
      <title>Two-norm discrepancy and convergence of the stochastic gradient method with application to shape optimization</title>
      <link>https://arxiv.org/abs/2408.05021</link>
      <description>arXiv:2408.05021v1 Announce Type: new 
Abstract: The present article is dedicated to proving convergence of the stochastic gradient method in case of random shape optimization problems. To that end, we consider Bernoulli's exterior free boundary problem with a random interior boundary. We recast this problem into a shape optimization problem by means of the minimization of the expected Dirichlet energy. By restricting ourselves to the class of convex, sufficiently smooth domains of bounded curvature, the shape optimization problem becomes strongly convex with respect to an appropriate norm. Since this norm is weaker than the differentiability norm, we are confronted with the so-called two-norm discrepancy, a well-known phenomenon from optimal control. We therefore need to adapt the convergence theory of the stochastic gradient method to this specific setting correspondingly. The theoretical findings are supported and validated by numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05021v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marc Dambrine, Caroline Geiersbach, Helmut Harbrecht</dc:creator>
    </item>
    <item>
      <title>A network model for urban planning</title>
      <link>https://arxiv.org/abs/2408.05140</link>
      <description>arXiv:2408.05140v1 Announce Type: new 
Abstract: We study a mathematical model to describe the evolution of a city, which is determined by the interaction of two large populations of agents, workers and firms. The map of the city is described by a network with the edges representing at the same time residential areas and communication routes. The two populations compete for space while interacting through the labour market. The resulting model is described by a two population Mean-Field Game system coupled with an Optimal Transport problem.We prove existence and uniqueness of the solution and we provide several numerical simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05140v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fabio Camilli, Adriano Festa, Luciano Marzufero</dc:creator>
    </item>
    <item>
      <title>Quadratic optimal transportation problem with a positive semi definite structure on the cost function</title>
      <link>https://arxiv.org/abs/2408.05161</link>
      <description>arXiv:2408.05161v1 Announce Type: new 
Abstract: Optimal transportation problem seeks for a coupling $\pi$ of two probability measures $\mu$ and $\nu$ which minimize the total cost $\int c d\pi$, which is linear in $\pi$. In this paper, we introduce a variation of optimal transportation problem which we call quadratic transportation problem that considers a total cost $\iint c d\pi d\pi$ which is quadratic in $\pi$. We compare this problem with other variations of optimal transportation problem, and prove some properties of the solutions to the problem. Then, we introduce squared cost function, which let us consider the total cost $\iint c d\pi d\pi$ as a positive semi-definite bilinear operator on probability measures, and show Kantorovich duality formula when we have a squared cost function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05161v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Seonghyeon Jeong</dc:creator>
    </item>
    <item>
      <title>A Geometric Nash Approach in Tuning the Learning Rate in Q-Learning Algorithm</title>
      <link>https://arxiv.org/abs/2408.04911</link>
      <description>arXiv:2408.04911v1 Announce Type: cross 
Abstract: This paper proposes a geometric approach for estimating the $\alpha$ value in Q learning. We establish a systematic framework that optimizes the {\alpha} parameter, thereby enhancing learning efficiency and stability. Our results show that there is a relationship between the learning rate and the angle between a vector T (total time steps in each episode of learning) and R (the reward vector for each episode). The concept of angular bisector between vectors T and R and Nash Equilibrium provide insight into estimating $\alpha$ such that the algorithm minimizes losses arising from exploration-exploitation trade-off.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04911v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kwadwo Osei Bonsu</dc:creator>
    </item>
    <item>
      <title>Some notes concerning preconditioning of linear parabolic optimal control problems</title>
      <link>https://arxiv.org/abs/2408.04954</link>
      <description>arXiv:2408.04954v1 Announce Type: cross 
Abstract: In this paper we study the conditioning of optimal control problems constrained by linear parabolic equations with Neumann boundaries. While we concentrate on a given end-time target function the results hold also when the target function is given over the whole time horizon. When implicit time discretization and conforming finite elements in space are employed we show that the reduced problem formulation has condition numbers which are bounded independently of the discretization level in arbitrary space dimension. In addition we propose for the all-at-once approach, i.e. for the first order conditions of the unreduced system a preconditioner based on work by Greif and Sch\"otzau, which provides also bounds on the eigenvalue distribution independently of the discretization level. Numerical experiments demonstrate the obtained results and the efficiency of the suggested preconditioners.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04954v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Luise Blank</dc:creator>
    </item>
    <item>
      <title>BoFire: Bayesian Optimization Framework Intended for Real Experiments</title>
      <link>https://arxiv.org/abs/2408.05040</link>
      <description>arXiv:2408.05040v1 Announce Type: cross 
Abstract: Our open-source Python package BoFire combines Bayesian Optimization (BO) with other design of experiments (DoE) strategies focusing on developing and optimizing new chemistry. Previous BO implementations, for example as they exist in the literature or software, require substantial adaptation for effective real-world deployment in chemical industry. BoFire provides a rich feature-set with extensive configurability and realizes our vision of fast-tracking research contributions into industrial use via maintainable open-source software. Owing to quality-of-life features like JSON-serializability of problem formulations, BoFire enables seamless integration of BO into RESTful APIs, a common architecture component for both self-driving laboratories and human-in-the-loop setups. This paper discusses the differences between BoFire and other BO implementations and outlines ways that BO research needs to be adapted for real-world use in a chemistry setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05040v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes P. D\"urholt, Thomas S. Asche, Johanna Kleinekorte, Gabriel Mancino-Ball, Benjamin Schiller, Simon Sung, Julian Keupp, Aaron Osburg, Toby Boyne, Ruth Misener, Rosona Eldred, Wagner Steuer Costa, Chrysoula Kappatou, Robert M. Lee, Dominik Linzner, David Walz, Niklas Wulkow, Behrang Shafei</dc:creator>
    </item>
    <item>
      <title>Generalised rank-constrained approximations of Hilbert-Schmidt operators on separable Hilbert spaces and applications</title>
      <link>https://arxiv.org/abs/2408.05104</link>
      <description>arXiv:2408.05104v1 Announce Type: cross 
Abstract: In this work we solve, for given bounded operators $B,C$ and Hilbert--Schmidt operator $M$ acting on potentially infinite-dimensional separable Hilbert spaces, the reduced rank approximation problem, $
  \text{min}\{\Vert{M-BXC}\Vert_{HS}:\ \text{dim}\ \text{ran}(X)\leq r\}. $ This extends the result of Sondermann (Statistische Hefte, 1986) and Friedland and Torokhti (SIAM J. Matrix Analysis and Applications, 2007), which studies this problem in the case of matrices $M$, $B$, $C$, $X$, and the analysis involves the Moore-Penrose inverse. In classical approximation problems which can be solved by the singular value decomposition or Moore-Penrose inverse, the solution satisfies a minimal norm property. Friedland and Torokhti also state such a minimal norm property of the solution. However, we show that this minimal norm property does not hold in general and give a modified minimality property that is satisfied in general. We also show that the solution may be discontinuous in infinite-dimensional settings. Necessary and sufficient conditions for continuity of the solutions are given and continuous approximations are constructed when such conditions are not met. Finally, we show that our results can be used in signal processing, reduced rank regression and linear operator learning under a rank constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05104v1</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giuseppe Carere, Han Cheng Lie</dc:creator>
    </item>
    <item>
      <title>Efficient Unit Commitment Constraint Screening under Uncertainty</title>
      <link>https://arxiv.org/abs/2408.05185</link>
      <description>arXiv:2408.05185v1 Announce Type: cross 
Abstract: Day-ahead unit commitment (UC) is a fundamental task for power system operators, where generator statuses and power dispatch are determined based on the forecasted nodal net demands. The uncertainty inherent in renewables and load forecasting requires the use of techniques in optimization under uncertainty to find more resilient and reliable UC solutions. However, the solution procedure of such specialized optimization may differ from the deterministic UC. The original constraint screening approach can be unreliable and inefficient for them. Thus, in this work we design a novel screening approach under the forecasting uncertainty. Our approach accommodates such uncertainties in both chance-constrained and robust forms, and can greatly reduce the UC instance size by screening out non-binding constraints. To further improve the screening efficiency, we utilize the multi-parametric programming theory to convert the underlying optimization problem of the screening model to a piecewise affine function. A multi-area screening approach is further developed to handle the computational intractability issues for large-scale problems. We verify the proposed method's performance on a variety of UC setups and uncertainty situations. Experimental results show that our robust screening procedure can guarantee better feasibility, while the CC screening can produce more efficient reduced models. The average screening time for a single line flow constraint can be accelerated by 71.2X to 131.3X using our proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.05185v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuan He, Honglin Wen, Yufan Zhang, Yize Chen, Danny H. K. Tsang</dc:creator>
    </item>
    <item>
      <title>Adaptive Partitioning for Chance-Constrained Problems with Finite Support</title>
      <link>https://arxiv.org/abs/2312.13180</link>
      <description>arXiv:2312.13180v2 Announce Type: replace 
Abstract: This paper studies chance-constrained stochastic optimization problems with finite support. It presents an iterative method that solves reduced-size chance-constrained models obtained by partitioning the scenario set. Each reduced problem is constructed to yield a bound on the optimal value of the original problem. We show how to adapt the partitioning of the scenario set so that our adaptive method returns the optimal solution of the original chance-constrained problem in a finite number of iterations. At the heart of the method lie two fundamental operations: refinement and merging. A refinement operation divides a subset of the partition, whereas a merging operation combines a group of subsets into one. We describe how to use these operations to enhance the bound obtained in each step of the method while preserving the small size of the reduced model. Under mild conditions, we prove that, for specific refinement and merge operations, the bound obtained after solving each reduced model strictly improves throughout the iterative process. Our general method allows the seamless integration of various computational enhancements, significantly reducing the computational time required to solve the reduced chance-constrained problems. The method's efficiency is assessed through numerical experiments on chance-constrained multidimensional knapsack problems. We study the impact of our method's components and compare its performance against other methods from the recent literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13180v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marius Roland, Alexandre Forel, Thibaut Vidal</dc:creator>
    </item>
    <item>
      <title>Randomized Feasibility-Update Algorithms for Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2402.05462</link>
      <description>arXiv:2402.05462v2 Announce Type: replace 
Abstract: This paper considers a variational inequality (VI) problem arising from a game among multiple agents, where each agent aims to minimize its own cost function subject to its constrained set represented as the intersection of a (possibly infinite) number of convex functional level sets. A direct projection-based approach or Lagrangian-based techniques for such a problem can be computationally expensive if not impossible to implement. To deal with the problem, we consider randomized methods that avoid the projection step on the whole constraint set by employing random feasibility updates. In particular, we propose and analyze such random methods for solving VIs based on the projection method, Korpelevich method, and Popov method. We establish the almost sure convergence of the methods and, also, provide their convergence rate guarantees. We illustrate the performance of the methods in simulations for two-agent games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05462v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abhishek Chakraborty, Angelia Nedi\'c</dc:creator>
    </item>
    <item>
      <title>Linear quadratic control of nonlinear systems with Koopman operator learning and the Nystr\"om method</title>
      <link>https://arxiv.org/abs/2403.02811</link>
      <description>arXiv:2403.02811v2 Announce Type: replace 
Abstract: In this paper, we study how the Koopman operator framework can be combined with kernel methods to effectively control nonlinear dynamical systems. While kernel methods have typically large computational requirements, we show how random subspaces (Nystr\"om approximation) can be used to achieve huge computational savings while preserving accuracy. Our main technical contribution is deriving theoretical guarantees on the effect of the Nystr\"om approximation. More precisely, we study the linear quadratic regulator problem, showing that the approximated Riccati operator converges at the rate $m^{-1/2}$, and the regulator objective, for the associated solution of the optimal control problem, converges at the rate $m^{-1}$, where $m$ is the random subspace size. Theoretical findings are complemented by numerical experiments corroborating our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02811v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Caldarelli, Antoine Chatalic, Adri\`a Colom\'e, Cesare Molinari, Carlos Ocampo-Martinez, Carme Torras, Lorenzo Rosasco</dc:creator>
    </item>
    <item>
      <title>Achieving Robust Data-driven Contextual Decision Making in a Data Augmentation Way</title>
      <link>https://arxiv.org/abs/2408.04469</link>
      <description>arXiv:2408.04469v2 Announce Type: replace 
Abstract: This paper focuses on the contextual optimization problem where a decision is subject to some uncertain parameters and covariates that have some predictive power on those parameters are available before the decision is made. More specifically, we focus on solving the Wasserstein-distance-based distributionally robust optimization (DRO) model for the problem, which maximizes the worst-case expected objective over an uncertainty set including all distributions closed enough to a nominal distribution with respect to the Wasserstein distance. We develop a stochastic gradient descent algorithm based on the idea of data augmentation to solve the model efficiently. The algorithm iteratively a) does a bootstrapping sample from the nominal distribution; b) perturbs the adversarially and c) updates decisions. Accordingly, the computational time of the algorithm is only determined by the number of iterations and the complexity of computing the gradient of a single sample. Except for efficiently solving the model, the algorithm provide additional advantages that the proposed algorithm can cope with any nominal distributions and therefore is extendable to solve the problem in an online setting. We also prove that the algorithm converges to the optimal solution of the DRO model at a rate of a $O(1/\sqrt{T})$, where $T$ is the number of iterations of bootstrapping. Consequently, the performance guarantee of the algorithm is that of the DRO model plus $O(1/\sqrt{T})$. Through extensive numerical experiments, we demonstrate the superior performance of the proposed algorithm to several benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04469v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoen Li, Maoqi Liu, Zhi-Hai Zhang</dc:creator>
    </item>
    <item>
      <title>Discrete nonlinear functions: formulations and applications in retail revenue management</title>
      <link>https://arxiv.org/abs/2408.04562</link>
      <description>arXiv:2408.04562v2 Announce Type: replace 
Abstract: This paper examines nonlinear optimization problems that incorporate discrete decisions. We introduce new improved formulation techniques that take advantage of the simplotope structure present in the domain of the binarization variables. Our technique identifies new polynomially solvable instances for price promotion problem initially studied by Cohen et al. (2021) and allows us to develop a linear programming (LP) formulation for inventory optimization problem under a choice model proposed by Boada-Collado and Martinez-de Albeniz (2020). The techniques we develop rely on ideal formulations for submodular and fractional compositions of discrete functions, improving prior formulations for bilinear products suggested by Adams and Henry (2012). Submodular compositions also generalize L natural functions over bounded domains and our construction provides new insights into Lovasz-extension based formulations for this class of problems while expanding the class of nonlinear discrete optimization problems amenable to linear programming based techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04562v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Taotao He, Mohit Tawarmalani</dc:creator>
    </item>
    <item>
      <title>Optimization Dynamics of Equivariant and Augmented Neural Networks</title>
      <link>https://arxiv.org/abs/2303.13458</link>
      <description>arXiv:2303.13458v4 Announce Type: replace-cross 
Abstract: We investigate the optimization of neural networks on symmetric data, and compare the strategy of constraining the architecture to be equivariant to that of using data augmentation. Our analysis reveals that that the relative geometry of the admissible and the equivariant layers, respectively, plays a key role. Under natural assumptions on the data, network, loss, and group of symmetries, we show that compatibility of the spaces of admissible layers and equivariant layers, in the sense that the corresponding orthogonal projections commute, implies that the sets of equivariant stationary points are identical for the two strategies. If the linear layers of the network also are given a unitary parametrization, the set of equivariant layers is even invariant under the gradient flow for augmented models. Our analysis however also reveals that even in the latter situation, stationary points may be unstable for augmented training although they are stable for the manifestly equivariant models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13458v4</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Oskar Nordenfors, Fredrik Ohlsson, Axel Flinth</dc:creator>
    </item>
    <item>
      <title>On Building Myopic MPC Policies using Supervised Learning</title>
      <link>https://arxiv.org/abs/2401.12546</link>
      <description>arXiv:2401.12546v2 Announce Type: replace-cross 
Abstract: The application of supervised learning techniques in combination with model predictive control (MPC) has recently generated significant interest, particularly in the area of approximate explicit MPC, where function approximators like deep neural networks are used to learn the MPC policy via optimal state-action pairs generated offline. While the aim of approximate explicit MPC is to closely replicate the MPC policy, substituting online optimization with a trained neural network, the performance guarantees that come with solving the online optimization problem are typically lost. This paper considers an alternative strategy, where supervised learning is used to learn the optimal value function offline instead of learning the optimal policy. This can then be used as the cost-to-go function in a myopic MPC with a very short prediction horizon, such that the online computation burden reduces significantly without affecting the controller performance. This approach differs from existing work on value function approximations in the sense that it learns the cost-to-go function by using offline-collected state-value pairs, rather than closed-loop performance data. The cost of generating the state-value pairs used for training is addressed using a sensitivity-based data augmentation scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12546v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christopher A. Orrico, Bokan Yang, Dinesh Krishnamoorthy</dc:creator>
    </item>
    <item>
      <title>A Parallel Vector-form $LDL^\top$ Decomposition for Accelerating Execution-time-certified $\ell_1$-penalty Soft-constrained MPC</title>
      <link>https://arxiv.org/abs/2403.18235</link>
      <description>arXiv:2403.18235v3 Announce Type: replace-cross 
Abstract: Handling possible infeasibility and providing an execution time certificate are two pressing requirements of real-time Model Predictive Control (MPC). To meet these two requirements simultaneously, this paper proposes an $\ell_1$-penalty soft-constrained MPC formulation that is globally feasible and solvable with an execution time certificate using our proposed algorithm. This paper proves for the first time that $\ell_1$-penalty soft-constrained MPC problems can be equivalently transformed into a box-constrained quadratic programming (Box-QP) and then our previous execution-time-certified algorithm \cite{wu2023direct} (only limited to Box-QP) can be applied. However, our previous Box-QP algorithm \cite{wu2023direct}, which provides a theoretical execution-time certificate, is conservative in its iteration analysis, thus sacrificing computation efficiency. To this end, this paper proposes a novel $LDL^\top$ decomposition for the first time, to accelerate the computation of Newton step at each iteration. The speedup of our $LDL^\top$ decomposition comes from two-fold: \textit{i)} exploitation of the fact that the number of inequality constraints is generally larger than the number of variables in condensed MPC formulations, \textit{ii)} vectorized and parallel implementation based on based on its vector-wise operations, instead of element-wise operations of previous decomposition methods. Numerical experiments demonstrate great speedups of the proposed $LDL^\top$ decomposition (even up to 1000-fold, compared to the standard Choleksky method), which thus helps our solver achieve comparable computation performance to the state-of-the-art solvers such as IPOPT and OSQP. Code is available at \url{https://github.com/liangwu2019/L1-penalty-QP}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18235v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liang Wu, Liwei Zhou, Richard D. Braatz</dc:creator>
    </item>
  </channel>
</rss>
