<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Sep 2025 04:00:06 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Normalized Square Root: Sharper Matrix Factorization Bounds for Differentially Private Continual Counting</title>
      <link>https://arxiv.org/abs/2509.14334</link>
      <description>arXiv:2509.14334v1 Announce Type: new 
Abstract: The factorization norms of the lower-triangular all-ones $n \times n$ matrix, $\gamma_2(M_{count})$ and $\gamma_{F}(M_{count})$, play a central role in differential privacy as they are used to give theoretical justification of the accuracy of the only known production-level private training algorithm of deep neural networks by Google. Prior to this work, the best known upper bound on $\gamma_2(M_{count})$ was $1 + \frac{\log n}{\pi}$ by Mathias (Linear Algebra and Applications, 1993), and the best known lower bound was $\frac{1}{\pi}(2 + \log(\frac{2n+1}{3})) \approx 0.507 + \frac{\log n}{\pi}$ (Matou\v{s}ek, Nikolov, Talwar, IMRN 2020), where $\log$ denotes the natural logarithm. Recently, Henzinger and Upadhyay (SODA 2025) gave the first explicit factorization that meets the bound of Mathias (1993) and asked whether there exists an explicit factorization that improves on Mathias' bound. We answer this question in the affirmative. Additionally, we improve the lower bound significantly. More specifically, we show that $$
  0.701 + \frac{\log n}{\pi} + o(1) \;\leq\; \gamma_2(M_{count}) \;\leq\; 0.846 + \frac{\log n}{\pi} + o(1). $$ That is, we reduce the gap between the upper and lower bound to $0.14 + o(1)$.
  We also show that our factors achieve a better upper bound for $\gamma_{F}(M_{count})$ compared to prior work, and we establish an improved lower bound: $$
  0.701 + \frac{\log n}{\pi} + o(1) \;\leq\; \gamma_{F}(M_{count}) \;\leq\; 0.748 + \frac{\log n}{\pi} + o(1). $$ That is, the gap between the lower and upper bound provided by our explicit factorization is $0.047 + o(1)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14334v1</guid>
      <category>cs.DS</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Monika Henzinger, Nikita P. Kalinin, Jalaj Upadhyay</dc:creator>
    </item>
    <item>
      <title>Fast and Compact Sketch-Based Dynamic Connectivity</title>
      <link>https://arxiv.org/abs/2509.14433</link>
      <description>arXiv:2509.14433v1 Announce Type: new 
Abstract: We study the dynamic connectivity problem for massive, dense graphs. Our goal is to build a system for dense graphs that simultaneously answers connectivity queries quickly, maintains a fast update throughput, and a uses a small amount of memory. Existing systems at best achieve two of these three performance goals at once.
  We present a parallel dynamic connectivity algorithm using graph sketching techniques that has space complexity $O(V \log^3 V)$ and query complexity $O(\log V/\log\log V)$. Its updates are fast and parallel: in the worst case, it performs updates in $O(\log^2 V)$ depth and $O(\log^4 V)$ work. For updates which don't change the spanning forests maintained by our data structure, the update complexity is $O(\log V)$ depth and $O(\log^2 V)$ work.
  We also present CUPCaKE (Compact Updating Parallel Connectivity and Sketching Engine), a dynamic connectivity system based on our parallel algorithm. It uses an order of magnitude less memory than the best lossless systems on dense graph inputs, answers queries with microsecond latency, and ingests millions of updates per second on dense graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14433v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Quinten De Man, Qamber Jafri, Daniel Delayo, Evan T. West, Michael A. Bender, David Tench</dc:creator>
    </item>
    <item>
      <title>Kronecker Powers, Orthogonal Vectors, and the Asymptotic Spectrum</title>
      <link>https://arxiv.org/abs/2509.14489</link>
      <description>arXiv:2509.14489v1 Announce Type: new 
Abstract: We study circuits for computing depth-2 linear transforms defined by Kronecker power matrices. Recent works have improved on decades-old constructions in this area using a new ''rebalancing'' approach [Alman, Guan and Padaki, SODA'23; Sergeev'22], but it was unclear how to apply this approach optimally.
  We find that Strassen's theory of asymptotic spectra can be applied to capture the design of these circuits. In particular, in hindsight, we find that the techniques of recent work on rebalancing were proving special cases of the duality theorem, which is central to Strassen's theory. We carefully outline a collection of ''obstructions'' to designing small depth-2 circuits using a rebalancing approach, and apply Strassen's theory to show that our obstructions are complete.
  Using this connection, combined with other algorithmic techniques, we give new improved circuit constructions as well as other applications, including:
  - The $N \times N$ disjointness matrix has a depth-2 linear circuit of size $O(N^{1.2495})$ over any field. This also yield smaller circuits for many families of matrices using reductions to disjointness.
  - The Strong Exponential Time Hypothesis implies an $N^{1 + \Omega(1)}$ size lower bound for depth-2 linear circuits computing the Walsh--Hadamard transform (and the disjointness matrix with a technical caveat), and proving a $N^{1 + \Omega(1)}$ depth-2 size lower bound would also imply breakthrough threshold circuit lower bounds.
  - The Orthogonal Vectors (OV) problem in moderate dimension $d$ can be solved in deterministic time $\tilde{O}(n \cdot 1.155^d)$, derandomizing an algorithm of Nederlof and W\k{e}grzycki [STOC'21], and the counting problem can be solved in time $\tilde{O}(n \cdot 1.26^d)$, improving an algorithm of Williams [FOCS'24] which runs in time $\tilde{O}(n \cdot 1.35^d)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14489v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Josh Alman, Baitian Li</dc:creator>
    </item>
    <item>
      <title>Efficient Algorithms for Disjoint Shortest Paths Problem and its Extensions</title>
      <link>https://arxiv.org/abs/2509.14588</link>
      <description>arXiv:2509.14588v1 Announce Type: new 
Abstract: We study the 2-Disjoint Shortest Paths (2-DSP) problem: given a directed weighted graph and two terminal pairs $(s_1,t_1)$ and $(s_2,t_2)$, decide whether there exist vertex-disjoint shortest paths between each pair.
  Building on recent advances in disjoint shortest paths for DAGs and undirected graphs (Akmal et al. 2024), we present an $O(mn \log n)$ time algorithm for this problem in weighted directed graphs that do not contain negative or zero weight cycles. This algorithm presents a significant improvement over the previously known $O(m^5n)$ time bound (Berczi et al. 2017). Our approach exploits the algebraic structure of polynomials that enumerate shortest paths between terminal pairs. A key insight is that these polynomials admit a recursive decomposition, enabling efficient evaluation via dynamic programming over fields of characteristic two. Furthermore, we demonstrate how to report the corresponding paths in $O(mn^2 \log n)$ time.
  In addition, we extend our techniques to a more general setting: given two terminal pairs $(s_1, t_1)$ and $(s_2, t_2)$ in a directed graph, find minimum possible number of vertex intersections between any shortest path from $s_1$ to $t_1$ and $s_2$ to $t_2$. We call this the Minimum 2-Disjoint Shortest Paths (Min-2-DSP) problem. We provide in this paper the first efficient algorithm for this problem, including an $O(m^2 n^3)$ time algorithm for directed graphs with positive edge weights, and an $O(m+n)$ time algorithm for DAGs and undirected graphs. Moreover, if the number of intersecting vertices is at least one, we show that it is possible to report the paths in the same $O(m+n)$ time. This is somewhat surprising, as there is no known $o(mn)$ time algorithm for explicitly reporting the paths if they are vertex disjoint, and is left as an open problem in (Akmal et al. 2024).</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14588v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keerti Choudhary, Amit Kumar, Lakshay Saggi</dc:creator>
    </item>
    <item>
      <title>Streaming periodicity with mismatches, wildcards, and edits</title>
      <link>https://arxiv.org/abs/2509.14898</link>
      <description>arXiv:2509.14898v1 Announce Type: new 
Abstract: In this work, we study the problem of detecting periodic trends in strings. While detecting exact periodicity has been studied extensively, real-world data is often noisy, where small deviations or mismatches occur between repetitions. This work focuses on a generalized approach to period detection that efficiently handles noise. Given a string $S$ of length $n$, the task is to identify integers $p$ such that the prefix and the suffix of $S$, each of length $n-p+1$, are similar under a given distance measure. Erg\"un et al. [APPROX-RANDOM 2017] were the first to study this problem in the streaming model under the Hamming distance. In this work, we combine, in a non-trivial way, the Hamming distance sketch of Clifford et al. [SODA 2019] and the structural description of the $k$-mismatch occurrences of a pattern in a text by Charalampopoulos et al. [FOCS 2020] to present a more efficient streaming algorithm for period detection under the Hamming distance. As a corollary, we derive a streaming algorithm for detecting periods of strings which may contain wildcards, a special symbol that match any character of the alphabet. Our algorithm is not only more efficient than that of Erg\"un et al. [TCS 2020], but it also operates without their assumption that the string must be free of wildcards in its final characters. Additionally, we introduce the first two-pass streaming algorithm for computing periods under the edit distance by leveraging and extending the Bhattacharya-Kouck\'y's grammar decomposition technique [STOC 2023].</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14898v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Taha El Ghazi, Tatiana Starikovskaya</dc:creator>
    </item>
    <item>
      <title>Fast and Optimal Incremental Parametric Procedure for the Densest Subgraph Problem: An Experimental Study</title>
      <link>https://arxiv.org/abs/2509.14993</link>
      <description>arXiv:2509.14993v1 Announce Type: new 
Abstract: The Densest Subgraph Problem (DSP) is widely used to identify community structures and patterns in networks such as bioinformatics and social networks. While solvable in polynomial time, traditional exact algorithms face computational and scalability limitations, leading to the adoption of faster, but non-optimal, heuristic methods. This work presents the first experimental study of the recently devised Incremental Parametric Cut (IPC) algorithm, which is an exact method for DSP and other "monotone ratio problems". Our findings demonstrate that IPC not only overcomes the limitations of previous exact approaches but also substantially outperforms leading state-of-the-art heuristics in both speed and solution quality. IPC's performance is also evaluated here for other "monotone ratio problems" related to conductance, Cheeger constant and normalized cut. For these, our experimental study on large-scale instances demonstrate exceptional computational speed. In particular, comparing IPC with the "fully parametric cut" algorithm, which is the only other efficient known optimization algorithm for such problems, demonstrate the superior performance of IPC. We provide here code and benchmarks, establishing IPC as a fast, scalable, and optimal solution framework for densest subgraph and related monotone ratio problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14993v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dorit S. Hochbaum, Ayleen Irribarra-Cort\'es, Olivier Goldschmidt, Roberto As\'in-Ach\'a</dc:creator>
    </item>
    <item>
      <title>Minimum Sum Coloring with Bundles in Trees and Bipartite Graphs</title>
      <link>https://arxiv.org/abs/2509.15080</link>
      <description>arXiv:2509.15080v1 Announce Type: new 
Abstract: The minimum sum coloring problem with bundles was introduced by Darbouy and Friggstad (SWAT 2024) as a common generalization of the minimum coloring problem and the minimum sum coloring problem. During their presentation, the following open problem was raised: whether the minimum sum coloring problem with bundles could be solved in polynomial time for trees. We answer their question in the negative by proving that the minimum sum coloring problem with bundles is NP-hard even for paths. We complement this hardness by providing algorithms of the following types. First, we provide a fixed-parameter algorithm for trees when the number of bundles is a parameter; this can be extended to graphs of bounded treewidth. Second, we provide a polynomial-time algorithm for trees when bundles form a partition of the vertex set and the difference between the number of vertices and the number of bundles is constant. Third, we provide a polynomial-time algorithm for trees when bundles form a partition of the vertex set and each bundle induces a connected subgraph. We further show that for bipartite graphs, the problem with weights is NP-hard even when the number of bundles is at least three, but is polynomial-time solvable when the number of bundles is at most two. The threshold shifts to three versus four for the problem without weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15080v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takehiro Ito, Naonori Kakimura, Naoyuki Kamiyama, Yusuke Kobayashi, Yoshio Okamoto</dc:creator>
    </item>
    <item>
      <title>Balanced Spanning Tree Distributions Have Separation Fairness</title>
      <link>https://arxiv.org/abs/2509.15137</link>
      <description>arXiv:2509.15137v1 Announce Type: new 
Abstract: Sampling-based methods such as ReCom are widely used to audit redistricting plans for fairness, with the balanced spanning tree distribution playing a central role since it favors compact, contiguous, and population-balanced districts. However, whether such samples are truly representative or exhibit hidden biases remains an open question. In this work, we introduce the notion of separation fairness, which asks whether adjacent geographic units are separated with at most a constant probability (bounded away from one) in sampled redistricting plans. Focusing on grid graphs and two-district partitions, we prove that a smooth variant of the balanced spanning tree distribution satisfies separation fairness. Our results also provide theoretical support for popular MCMC methods like ReCom, suggesting that they maintain fairness at a granular level in the sampling process. Along the way, we develop tools for analyzing loop-erased random walks and partitions that may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15137v1</guid>
      <category>cs.DS</category>
      <category>cs.CY</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harry Chen, Kamesh Munagala, Govind S. Sankar</dc:creator>
    </item>
    <item>
      <title>Decoded Quantum Interferometry Requires Structure</title>
      <link>https://arxiv.org/abs/2509.14509</link>
      <description>arXiv:2509.14509v1 Announce Type: cross 
Abstract: We study the performance of Decoded Quantum Interferometry (DQI) on typical instances of MAX-$k$-XOR-SAT when the transpose of the constraint matrix is drawn from a standard ensemble of LDPC parity check matrices. We prove that if the decoding step of DQI corrects up to the folklore efficient decoding threshold for LDPC codes, then DQI is obstructed by a topological feature of the near-optimal space of solutions known as the overlap gap property (OGP). As the OGP is widely conjectured to exactly characterize the performance of state-of-the-art classical algorithms, this result suggests that DQI has no quantum advantage in optimizing unstructured MAX-$k$-XOR-SAT instances. We also give numerical evidence supporting this conjecture by showing that approximate message passing (AMP)--a classical algorithm conjectured to saturate the OGP threshold--outperforms DQI on a related ensemble of MAX-$k$-XOR-SAT instances. Finally, we prove that depth-$1$ QAOA outperforms DQI at sufficiently large $k$ under the same decoding threshold assumption.
  Our result follows by showing that DQI is approximately Lipschitz under the quantum Wasserstein metric over many standard ensembles of codes. We then prove that MAX-$k$-XOR-SAT exhibits both an OGP and a related topological obstruction known as the chaos property; this is the first known OGP threshold for MAX-$k$-XOR-SAT at fixed $k$, which may be of independent interest. Finally, we prove that both of these topological properties inhibit approximately Lipschitz algorithms such as DQI from optimizing MAX-$k$-XOR-SAT to large approximation ratio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14509v1</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric R. Anschuetz, David Gamarnik, Jonathan Z. Lu</dc:creator>
    </item>
    <item>
      <title>The Complexity of Finding and Counting Subtournaments</title>
      <link>https://arxiv.org/abs/2509.14807</link>
      <description>arXiv:2509.14807v1 Announce Type: cross 
Abstract: We study the complexity of counting and finding small tournament patterns inside large tournaments. Given a fixed tournament $T$ of order $k$, we write ${\#}\text{IndSub}_{\text{To}}(\{T\})$ for the problem whose input is a tournament $G$ and the task is to compute the number of subtournaments of $G$ that are isomorphic to $T$. Previously, Yuster [Yus25] obtained that ${\#}\text{IndSub}_{\text{To}}(\{T\})$ is hard to compute for random tournaments $T$. We consider a new approach that uses linear combinations of subgraph-counts [CDM17] to obtain a finer analysis of the complexity of ${\#}\text{IndSub}_{\text{To}}(\{T\})$.
  We show that for all tournaments $T$ of order $k$ the problem ${\#}\text{IndSub}_{\text{To}}(\{T\})$ is always at least as hard as counting $\lfloor 3k/4 \rfloor$-cliques. This immediately yields tight bounds under ETH. Further, we consider the parameterized version of ${\#}\text{IndSub}_{\text{To}}(\mathcal{T})$ where we only consider patterns $T \in \mathcal{T}$ and that is parameterized by the pattern size $|V(T)|$. We show that ${\#}\text{IndSub}_{\text{To}}(\mathcal{T})$ is ${\#}W[1]$-hard as long as $\mathcal{T}$ contains infinitely many tournaments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14807v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon D\"oring, Sarah Houdaigoui, Lucas Picasarri-Arrieta, Philip Wellnitz</dc:creator>
    </item>
    <item>
      <title>Efficient Computation of Time-Index Powered Weighted Sums Using Cascaded Accumulators</title>
      <link>https://arxiv.org/abs/2509.15069</link>
      <description>arXiv:2509.15069v1 Announce Type: cross 
Abstract: This letter presents a novel approach for \mbox{efficiently} computing time-index powered weighted sums of the form $\sum_{n=0}^{N-1} n^{K} v[n]$ using cascaded accumulators. Traditional direct computation requires $K{\times}N$ general multiplications, which become prohibitive for large $N$, while alternative strategies based on lookup tables or signal reversal require storing entire data blocks. By exploiting accumulator properties, the proposed method eliminates the need for such storage and reduces the multiplicative cost to only $K{+}1$ constant multiplications, enabling efficient real-time implementation. The approach is particularly useful when such sums need to be efficiently computed in sample-by-sample processing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15069v1</guid>
      <category>eess.SP</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Deijany Rodriguez Linares, Oksana Moryakova, H{\aa}kan Johansson</dc:creator>
    </item>
    <item>
      <title>New Complexity and Algorithmic Bounds for Minimum Consistent Subsets</title>
      <link>https://arxiv.org/abs/2404.15487</link>
      <description>arXiv:2404.15487v2 Announce Type: replace-cross 
Abstract: In the Minimum Consistent Subset (MCS) problem, we are presented with a connected simple undirected graph $G=(V,E)$, consisting of a vertex set $V$ of size $n$ and an edge set $E$. Each vertex in $V$ is assigned a color from the set $\{1,2,\ldots, c\}$. The objective is to determine a subset $V' \subseteq V$ with minimum possible cardinality, such that for every vertex $v \in V$, at least one of its nearest neighbors in $V'$ (measured in terms of the hop distance) shares the same color as $v$. A variant of MCS is the minimum strict consistent subset (MSCS) in which instead of requiring at least one nearest neighbor of $v$, all the nearest neighbors of $v$ in $V'$ must have the same color as $v$. The decision version for MCS problem as well as for MSCS problem asks whether there exists a subset $V'$ of cardinality at most $l$ for some positive integer $l$. The MCS problem is known to be NP-complete for planar graphs.
  In this paper, we establish that the MCS problem for trees, when the number of colors $c$ is considered an input parameter, is NP-complete. We propose a fixed-parameter tractable (FPT) algorithm for MCS on trees running in $O(2^{6c}n^6)$ time, significantly improving the currently best-known algorithm whose running time is $O(2^{4c}n^{2c+3})$. In an effort to comprehensively understand the computational complexity of the MCS problem across different graph classes, we extend our investigation to interval graphs. We show that it remains NP-complete for interval graphs, thus enriching graph classes where MCS remains intractable.
  We also show that the MSCS problem is log-APX-hard on general graphs and NP-complete on planar graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.15487v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aritra Banik, Sayani Das, Anil Maheshwari, Bubai Manna, Subhas C Nandy, Krishna Priya K M, Bodhayan Roy, Sasanka Roy, Abhishek Sahu</dc:creator>
    </item>
    <item>
      <title>jXBW: Fast Substructure Search for Large-Scale JSONL Datasets with LLM Applications</title>
      <link>https://arxiv.org/abs/2508.12536</link>
      <description>arXiv:2508.12536v2 Announce Type: replace-cross 
Abstract: JSON Lines (JSONL) is widely used for managing large collections of semi-structured data, ranging from large language model (LLM) prompts to chemical compound records and geospatial datasets. A key operation is substructure search, which identifies all JSON objects containing a query pattern. This task underpins applications such as drug discovery (querying compounds for functional groups), prompt engineering (extracting prompts with schema fragments), and geospatial analytics (finding entities with nested attributes). However, existing methods are inefficient: traversal requires exhaustive tree matching, succinct JSON representations save space but do not accelerate search, and XML-based approaches incur conversion overhead and semantic mismatches. We present jXBW, a compressed index for efficient substructure search over JSONL. jXBW introduces three innovations: (i) a merged tree representation that consolidates repeated structures, (ii) a succinct tree index based on the eXtended Burrows--Wheeler Transform (XBW), and (iii) a three-phase algorithm for substructure search. These enable query-dependent complexity, where cost depends on query characteristics rather than dataset size, while retaining succinct space. This resolves a key bottleneck in retrieval-augmented generation (RAG) systems requiring structure-aware retrieval. Experiments on seven real datasets, including PubChem (1M compounds) and OSM geospatial data (6.6M objects), achieve up to 4,700$\times$ speedup over tree-based methods and over $6\times 10^6$ speedup relative to XML-based approaches. jXBW makes JSONL substructure search practical for the first time, opening opportunities for large-scale LLM-based analytics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12536v2</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <category>cs.IR</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasuo Tabei</dc:creator>
    </item>
  </channel>
</rss>
