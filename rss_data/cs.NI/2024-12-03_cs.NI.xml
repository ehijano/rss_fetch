<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Dec 2024 02:52:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Lazy Eye Inspection: Capturing the State of Happy Eyeballs Implementations</title>
      <link>https://arxiv.org/abs/2412.00263</link>
      <description>arXiv:2412.00263v1 Announce Type: new 
Abstract: Happy Eyeballs (HE) started out by describing a mechanism that prefers IPv6 connections while ensuring a fast fallback to IPv4 when IPv6 fails. The IETF is currently working on the third version of HE. While the standards include recommendations for HE parameters choices, it is up to the client and OS to implement HE. In this paper we investigate the state of HE in various clients, particularly web browsers and recursive resolvers. We introduce a framework to analyze and measure client's HE implementations and parameter choices. According to our evaluation, only Safari supports all HE features. Safari is also the only client implementation in our study that uses a dynamic IPv4 connection attempt delay, a resolution delay, and interlaces addresses. We further show that problems with the DNS A record lookup can even delay and interrupt the network connectivity despite a fully functional IPv6 setup with Chrome and Firefox. We publish our testbed measurement framework and a web-based tool to test HE properties on arbitrary browsers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00263v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Patrick Sattler, Matthias Kirstein, Lars W\"ustrich, Johannes Zirngibl, Georg Carle</dc:creator>
    </item>
    <item>
      <title>Unlocking Diversity of Fast-Switched Optical Data Center Networks with Unified Routing</title>
      <link>https://arxiv.org/abs/2412.00266</link>
      <description>arXiv:2412.00266v1 Announce Type: new 
Abstract: Optical data center networks (DCNs) are emerging as a promising solution for cloud infrastructure in the post-Moore's Law era, particularly with the advent of 'fast-switched' optical architectures capable of circuit reconfiguration at microsecond or even nanosecond scales. However, frequent reconfiguration of optical circuits introduces a unique challenge: in-flight packets risk loss during these transitions, hindering the deployment of many mature optical hardware designs due to the lack of suitable routing solutions. In this paper, we present Unified Routing for Optical networks (URO), a general routing framework designed to support fast-switched optical DCNs across various hardware architectures. URO combines theoretical modeling of this novel routing problem with practical implementation on programmable switches, enabling precise, time-based packet transmission. Our prototype on Intel Tofino2 switches achieves a minimum circuit duration of 2us, ensuring end-to-end, loss-free application performance. Large-scale simulations using production DCN traffic validate URO's generality across different hardware configurations, demonstrating its effectiveness and efficient system resource utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00266v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jialong Li, Federico De Marchi, Yiming Lei, Raj Joshi, Balakrishnan Chandrasekaran, Yiting Xia</dc:creator>
    </item>
    <item>
      <title>Dynamic Interference Suppression for Radar and Communication Cohabitation</title>
      <link>https://arxiv.org/abs/2412.00697</link>
      <description>arXiv:2412.00697v1 Announce Type: new 
Abstract: We propose the joint dynamic power allocation and multi-relay selection for the cohabitation of high-priority military radar and low-priority commercial 5G communication. To improve the 5G network performance, we design the full-duplex underlay cognitive radio network for the low-priority commercial 5G network, where multiple relays are selected for concurrently receive the signal from the source and send it to the destination. Then, we propose the interference suppression at the high-priority radar system by using both non-coherent and coherent relay cases. In particular, we formulate the optimization problem for maximizing the system rate, with the consideration of the power constraints at the 5G users and the interference constraint at the radar system. Then, we propose the mathematical analysis model to evaluate the rate performance, considering the impacts of self-interference at the relays and derive the algorithms of joint power allocation and relay selection. Our numerical results demonstrate the characteristic of the optimal configuration and the significant performance gain of coherent case with respect to the non-coherent case and the existing algorithms with single relay selections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00697v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.SI</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tan Le, Van Le</dc:creator>
    </item>
    <item>
      <title>Overview of NR Enhancements for Extended Reality (XR) in 3GPP 5G-Advanced</title>
      <link>https://arxiv.org/abs/2412.00741</link>
      <description>arXiv:2412.00741v1 Announce Type: new 
Abstract: Extended reality (XR) is unlocking numerous possibilities and continues attracting individuals and larger groups across different business sectors. With Virtual reality (VR), Augmented reality (AR), or Mixed reality (MR) it is possible to improve the way we access, deliver and exchange information in education, health care, entertainment, and many other aspects of our daily lives. However, to fully exploit the potential of XR, it is important to provide reliable, fast and secure wireless connectivity to the users of XR and that requires refining existing solutions and tailoring those to support XR services. This article presents a tutorial on 3GPP 5G-Advanced Release 18 XR activities, summarizing physical as well as higher layer enhancements introduced for New Radio considering the specifics of XR. In addition, we also describe enhancements across 5G system architecture that impacted radio access network. Furthermore, the paper provides system-level simulation results for several Release 18 enhancements to show their benefits in terms of XR capacity and power saving gains. Finally, it concludes with an overview of future work in Release 19 that continues developing features to support XR services.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00741v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Margarita Gapeyenko, Stefano Paris, Markus Isomaki, Boyan Yanakiev, Abolfazl Amiri, Benoist S\'ebire, Jorma Kaikkonen, Chunli Wu, Klaus I. Pedersen</dc:creator>
    </item>
    <item>
      <title>Non-Terrestrial Networking for 6G: Evolution, Opportunities, and Future Directions</title>
      <link>https://arxiv.org/abs/2412.00820</link>
      <description>arXiv:2412.00820v1 Announce Type: new 
Abstract: From 5G onwards, Non-Terrestrial Networks (NTNs) have emerged as a key component of future network architectures. Leveraging Low Earth Orbit (LEO) satellite constellations, NTNs are capable of building a space Internet and present a paradigm shift in delivering mobile services to even the most remote regions on Earth. However, the extensive coverage and rapid movement of LEO satellites pose unique challenges for NTN networking, including user equipment (UE) access and inter-satellite delivery, which directly impact the quality of service (QoS) and data transmission continuity. This paper offers an in-depth review of advanced NTN management technologies in the context of 6G evolution, focusing on radio resource management, mobility management, and dynamic network slicing. Building on this foundation and considering the latest trends in NTN development, we then present some innovative perspectives to emerging challenges in satellite beamforming, handover mechanisms, and inter-satellite transmissions. Lastly, we identify open research issues and propose future directions aimed at advancing satellite Internet deployment and enhancing NTN performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00820v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Wang, Shengyu Zhang, Huiting Yang, Tony Q. S. Quek</dc:creator>
    </item>
    <item>
      <title>Age of Information in Random Access Networks with Energy Harvesting</title>
      <link>https://arxiv.org/abs/2412.01192</link>
      <description>arXiv:2412.01192v2 Announce Type: new 
Abstract: We study the age of information (AoI) in a random access network consisting of multiple source-destination pairs, where each source node is empowered by energy harvesting capability. Every source node transmits a sequence of data packets to its destination using only the harvested energy. Each data packet is encoded with finite-length codewords, characterizing the nature of short codeword transmissions in random access networks. By combining tools from bulk-service Markov chains with stochastic geometry, we derive an analytical expression for the network average AoI and obtain closed-form results in two special cases, i.e., the small and large energy buffer size scenarios. Our analysis reveals the trade-off between energy accumulation time and transmission success probability. We then optimize the network average AoI by jointly adjusting the update rate and the blocklength of the data packet. Our findings indicate that the optimal update rate should be set to one in the energy-constrained regime where the energy consumption rate exceeds the energy arrival rate. This also means if the optimal blocklength of the data packet is pre-configured, an energy buffer size supporting only one transmission is sufficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01192v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangming Zhao, Nikolaos Pappas, Meng Zhang, Howard H. Yang</dc:creator>
    </item>
    <item>
      <title>Optimizing Microservices Placement in the Cloud-to-Edge Continuum: A Comparative Analysis of App and Service Based Approaches</title>
      <link>https://arxiv.org/abs/2412.01412</link>
      <description>arXiv:2412.01412v1 Announce Type: new 
Abstract: In the ever-evolving landscape of computing, the advent of edge and fog computing has revolutionized data processing by bringing it closer to end-users. While cloud computing offers numerous advantages, including mobility, flexibility and scalability, it introduces challenges such as latency. Fog and edge computing emerge as complementary solutions, bridging the gap and enhancing services' proximity to users. The pivotal challenge addressed in this paper revolves around optimizing the placement of application microservices to minimize latency in the cloud-to-edge continuum, where a proper node selection may influence the app's performance. Therefore, this task gains complexity due to the paradigm shift from monolithic to microservices-based architectures. Two distinct placement approaches, app-based and service-based, are compared through four different placement algorithms based on criteria such as link latency, node resources, and gateway proximity. App-based allocates all the services of one app sequentially, while service-based allocates one service of each app at a time. The study, conducted using YAFS (Yet Another Fog Simulator), evaluates the impact of these approaches on latency and load balance. The findings consistently confirm the hypothesis that strategies utilizing a service-based approach outperformed or performed equally well compared to app-based approaches, offering valuable insights into trade-offs and performance differences among the algorithms and each approach in the context of efficient microservices placement in cloud-to-edge environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01412v1</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1109/MELECON56669.2024.10608552</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 22nd Mediterranean Electrotechnical Conference (MELECON), Porto, Portugal, 2024, pp. 1321-1326</arxiv:journal_reference>
      <dc:creator>Miguel Mota-Cruz, Jo\~ao H Santos, Jos\'e F Macedo, Karima Velasquez, David Perez Abreu</dc:creator>
    </item>
    <item>
      <title>EH from V2X Communications: the Price of Uncertainty and the Impact of Platooning</title>
      <link>https://arxiv.org/abs/2412.01502</link>
      <description>arXiv:2412.01502v1 Announce Type: new 
Abstract: In this paper, we explore how radio frequency energy from vehicular communications can be exploited by an energy harvesting device (EHD) placed alongside the road to deliver data packets through wireless connection to a remote Access Point.
  Based on updated local topology knowledge, we propose a cycle-based strategy to balance harvest and transmit phases at the EHD, in order to maximize the average throughput.
  A theoretical derivation is carried out to determine the optimal strategy parameters setting, and used to investigate the effectiveness of the proposed approach over different scenarios, taking into account the road traffic intensity, the EHD battery capacity, the transmit power and the data rate. Results show that regular traffic patterns, as those created by vehicles platooning, can increase the obtained throughput by more than 30% with respect to irregular ones with the same average intensity.
  Black out probability is also derived for the former scenario. The resulting tradeoff between higher average throughput and lower black out probability shows that the proposed approach can be adopted for different applications by properly tuning the strategy parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01502v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2023.3310582</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Vehicular Technology, vol. 73, no. 1, pp. 385-401, Jan. 2024,</arxiv:journal_reference>
      <dc:creator>Federico Librino, Paolo Santi</dc:creator>
    </item>
    <item>
      <title>Outstanding framework for simulating and generating anchor trajectory in wireless sensor networks</title>
      <link>https://arxiv.org/abs/2412.01520</link>
      <description>arXiv:2412.01520v1 Announce Type: new 
Abstract: This paper proposes a framework that has the ability to animate and generate different scenarios for the mobility of a movable anchor which can follow various paths in wireless sensor networks (WSNs). When the researchers use NS-2 to simulate a single anchor-assisted localization model, they face the problem of creating the movement file of the movable anchor. The proposed framework solved this problem by allowing them to create the movement scenario regarding different trajectories. The proposed framework lets the researcher set the needed parameters for simulating various static path models, which can be displayed through the graphical user interface. The researcher can also view the mobility of the movable anchor with control of its speed and communication range. The proposed framework has been validated by comparing its results to NS-2 outputs plus comparing it against existing tools. Finally, this framework has been published on the Code Project website and downloaded by many users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01520v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5121/ijcnc.2024.16602</arxiv:DOI>
      <arxiv:journal_reference>International Journal of Computer Networks &amp; Communications (IJCNC) vol 16, No 6, November 2024</arxiv:journal_reference>
      <dc:creator>Abdelhady Naguib</dc:creator>
    </item>
    <item>
      <title>Enhanced Time Division Duplexing Slot Allocation and Scheduling in Non-Terrestrial Networks</title>
      <link>https://arxiv.org/abs/2412.01570</link>
      <description>arXiv:2412.01570v1 Announce Type: new 
Abstract: The integration of non-terrestrial networks (NTNs) and terrestrial networks (TNs) is fundamental for extending connectivity to rural and underserved areas that lack coverage from traditional cellular infrastructure. However, this integration presents several challenges. For instance, TNs mainly operate in Time Division Duplexing (TDD). However, for NTN via satellites, TDD is complicated due to synchronization problems in large cells, and the significant impact of guard periods and long propagation delays. In this paper, we propose a novel slot allocation mechanism to enable TDD in NTN. This approach permits to allocate additional transmissions during the guard period between a downlink slot and the corresponding uplink slot to reduce the overhead, provided that they do not interfere with other concurrent transmissions. Moreover, we propose two scheduling methods to select the users that transmit based on considerations related to the Signal-to-Noise Ratio (SNR) or the propagation delay. Simulations demonstrate that our proposal can increase the network capacity compared to a benchmark scheme that does not schedule transmissions in guard periods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01570v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Traspadini, Marco Giordani, Michele Zorzi</dc:creator>
    </item>
    <item>
      <title>Optimizing LoRa for Edge Computing with TinyML Pipeline for Channel Hopping</title>
      <link>https://arxiv.org/abs/2412.01609</link>
      <description>arXiv:2412.01609v1 Announce Type: new 
Abstract: We propose to integrate long-distance LongRange (LoRa) communication solution for sending the data from IoT to the edge computing system, by taking advantage of its unlicensed nature and the potential for open source implementations that are common in edge computing. We propose a channel hoping optimization model and apply TinyML-based channel hoping model based for LoRa transmissions, as well as experimentally study a fast predictive algorithm to find free channels between edge and IoT devices. In the open source experimental setup that includes LoRa, TinyML and IoT-edge-cloud continuum, we integrate a novel application workflow and cloud-friendly protocol solutions in a case study of plant recommender application that combines concepts of microfarming and urban computing. In a LoRa-optimized edge computing setup, we engineer the application workflow, and apply collaborative filtering and various machine learning algorithms on application data collected to identify and recommend the planting schedule for a specific microfarm in an urban area. In the LoRa experiments, we measure the occurrence of packet loss, RSSI, and SNR, using a random channel hoping scheme to compare with our proposed TinyML method. The results show that it is feasible to use TinyML in microcontrollers for channel hopping, while proving the effectiveness of TinyML in learning to predict the best channel to select for LoRa transmission, and by improving the RSSI by up to 63 %, SNR by up to 44 % in comparison with a random hopping mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01609v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.DM</category>
      <category>cs.LG</category>
      <category>cs.PF</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marla Grunewald, Mounir Bensalem, Admela Jukan</dc:creator>
    </item>
    <item>
      <title>Seldom: An Anonymity Network with Selective Deanonymization</title>
      <link>https://arxiv.org/abs/2412.00990</link>
      <description>arXiv:2412.00990v1 Announce Type: cross 
Abstract: While anonymity networks such as Tor provide invaluable privacy guarantees to society, they also enable all kinds of criminal activities. Consequently, many blameless citizens shy away from protecting their privacy using such technology for the fear of being associated with criminals. To grasp the potential for alternative privacy protection for those users, we design Seldom, an anonymity network with integrated selective deanonymization that disincentivizes criminal activity. Seldom enables law enforcement agencies to selectively access otherwise anonymized identities of misbehaving users, while providing technical guarantees preventing these access rights from being misused. Seldom further ensures translucency, as each access request is approved by a trustworthy consortium of impartial entities and eventually disclosed to the public (without interfering with ongoing investigations). To demonstrate Seldom's feasibility and applicability, we base our implementation on Tor, the most widely used anonymity network. Our evaluation indicates minimal latency, processing, and bandwidth overheads compared to Tor, while Seldom's main costs stem from storing flow records and encrypted identities. With at most 636 TB of storage required in total to retain the encrypted identifiers of a Tor-sized network for two years, Seldom provides a practical and deployable technical solution to the inherent problem of criminal activities in anonymity networks. As such, Seldom sheds new light on the potentials and limitations when integrating selective deanonymization into anonymity networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.00990v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Wagner, Roman Matzutt, Martin Henze</dc:creator>
    </item>
    <item>
      <title>A slot-based energy storage decision-making approach for optimal Off-Grid telecommunication operator</title>
      <link>https://arxiv.org/abs/2412.01731</link>
      <description>arXiv:2412.01731v1 Announce Type: cross 
Abstract: This paper proposes a slot-based energy storage approach for decision-making in the context of an Off-Grid telecommunication operator. We consider network systems powered by solar panels, where harvest energy is stored in a battery that can also be sold when fully charged. To reflect real-world conditions, we account for non-stationary energy arrivals and service demands that depend on the time of day, as well as the failure states of PV panel. The network operator we model faces two conflicting objectives: maintaining the operation of its infrastructure and selling (or supplying to other networks) surplus energy from fully charged batteries. To address these challenges, we developed a slot-based Markov Decision Process (MDP) model that incorporates positive rewards for energy sales, as well as penalties for energy loss and battery depletion. This slot-based MDP follows a specific structure we have previously proven to be efficient in terms of computational performance and accuracy. From this model, we derive the optimal policy that balances these conflicting objectives and maximizes the average reward function. Additionally, we present results comparing different cities and months, which the operator can consider when deploying its infrastructure to maximize rewards based on location-specific energy availability and seasonal variations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.01731v1</guid>
      <category>math.OC</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Youssef Ait El Mahjoub, Jean-Michel Fourneau</dc:creator>
    </item>
    <item>
      <title>A Survey on Semantic Communication Networks: Architecture, Security, and Privacy</title>
      <link>https://arxiv.org/abs/2405.01221</link>
      <description>arXiv:2405.01221v2 Announce Type: replace 
Abstract: With the rapid advancement and deployment of intelligent agents and artificial general intelligence (AGI), a fundamental challenge for future networks is enabling efficient communications among agents. Unlike traditional human-centric, data-driven communication networks, the primary goal of agent-based communication is to facilitate coordination among agents. Therefore, task comprehension and collaboration become the key objectives of communications, rather than data synchronization. Semantic communication (SemCom) aims to align information and knowledge among agents to expedite task comprehension. While significant research has been conducted on SemCom for two-agent systems, the development of semantic communication networks (SemComNet) for multi-agent systems remains largely unexplored. In this paper, we provide a comprehensive and up-to-date survey of SemComNet, focusing on their fundamentals, security, and privacy aspects. We introduce a novel three-layer architecture for multi-agent interaction, comprising the control layer, semantic transmission layer, and cognitive sensing layer. We explore working modes and enabling technologies, and present a taxonomy of security and privacy threats, along with state-of-the-art defense mechanisms. Finally, we outline future research directions, paving the way toward intelligent, robust, and energy-efficient SemComNet. This survey represents the first comprehensive analysis of SemComNet, offering detailed insights into its core principles as well as associated security and privacy challenges.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01221v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaolong Guo (Sherman), Yuntao Wang (Sherman), Ning Zhang (Sherman), Zhou Su (Sherman), Tom H. Luan (Sherman), Zhiyi Tian (Sherman),  Xuemin (Sherman),  Shen</dc:creator>
    </item>
    <item>
      <title>Matter: IoT Interoperability for Smart Homes</title>
      <link>https://arxiv.org/abs/2405.01618</link>
      <description>arXiv:2405.01618v2 Announce Type: replace 
Abstract: The smart home is a major Internet of Things (IoT) application domain with tremendous market expectations. However, communication solutions for smart home devices have exhibited a lack of interoperability, challenging the success of the smart home concept. Aiming to overcome this problem, crucial industry organizations have collaborated to produce Matter, a connectivity solution intended as a universal smart home standard. This paper overviews, evaluates and discusses Matter, focusing on its design, features, performance, and future directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.01618v2</guid>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Saeid Madadi-Barough, Pau Ruiz-Blanco, Jiadeng Lin, Rafael Vidal, Carles Gomez</dc:creator>
    </item>
    <item>
      <title>Strategic Demand-Planning in Wireless Networks: Can Generative-AI Save Spectrum and Energy?</title>
      <link>https://arxiv.org/abs/2407.02292</link>
      <description>arXiv:2407.02292v2 Announce Type: replace 
Abstract: Generative-AI (GenAI), a novel technology capable of producing various types of outputs, including text, images, and videos, offers significant potential for wireless communications. This article introduces the concept of strategic demand-planning through demand-labeling, demand-shaping, and demand-rescheduling. Accordingly, GenAI is proposed as a powerful tool to facilitate demand-shaping in wireless networks. More specifically, GenAI is used to compress and convert the content of various types (e.g., from a higher bandwidth mode to a lower one, such as from a video to text), which subsequently enhances performance of wireless networks in various usage scenarios, such as cell-switching, user association and load balancing, interference management, as well as disasters and unusual gatherings. Therefore, GenAI can serve a function in saving energy and spectrum in wireless networks. With recent advancements in AI, including sophisticated algorithms like large language models and the development of more powerful hardware built exclusively for AI tasks, such as AI accelerators, the concept of demand-planning, particularly demand-shaping through GenAI, becomes increasingly relevant. Furthermore, recent efforts to make GenAI accessible on devices, such as user terminals, make the implementation of this concept even more straightforward and feasible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.02292v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Berk \c{C}ilo\u{g}lu, G\"orkem Berkay Ko\c{c}, Afsoon Alidadi Shamsabadi, Metin Ozturk, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>Exploring the 6G Potentials: Immersive, Hyper Reliable, and Low-Latency Communication</title>
      <link>https://arxiv.org/abs/2407.11051</link>
      <description>arXiv:2407.11051v2 Announce Type: replace 
Abstract: The transition towards the sixth-generation (6G) wireless telecommunications networks introduces significant challenges for researchers and industry stakeholders. The 6G technology aims to enhance existing usage scenarios through supporting innovative applications that require stringent key performance indicators (KPIs). In some critical use cases of 6G, multiple KPIs, including immersive throughput, with an envisioned peak data rate of $1$ Tbps, hyper-reliability, in the range of $10^{-5}$ to $10^{-7}$, and hyper low-latency, between $0.1$ and $1$ ms, must be achieved simultaneously to deliver the expected service experience. However, this is challenging due to the conflicting nature of these KPIs. This article proposes a new service class of 6G as immersive, hyper reliable, and low-latency communication (IHRLLC), and introduces a potential network architecture to achieve the associated KPIs. Specifically, enhanced technologies, such as ultra-massive multiple-input multiple-output (umMIMO)-aided terahertz (THz) communications, reconfigurable intelligent surfaces (RIS), and non-terrestrial networks (NTN), are viewed as the key enablers for achieving immersive data rates and hyper reliability. Given the computational complexity involved in employing these technologies, we propose mathematical and computational enabling technologies, such as learn-to-optimize (L2O), generative-AI (GenAI), quantum computing, and network digital twin (NDT), to complement the proposed architecture and optimize the latency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.11051v2</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Afsoon Alidadi Shamsabadi, Animesh Yadav, Yasser Gadallah, Halim Yanikomeroglu</dc:creator>
    </item>
    <item>
      <title>JC5A: Service Delay Minimization for Aerial MEC-assisted Industrial Cyber-Physical Systems</title>
      <link>https://arxiv.org/abs/2411.04762</link>
      <description>arXiv:2411.04762v2 Announce Type: replace 
Abstract: In the era of the sixth generation (6G) and industrial Internet of Things (IIoT), an industrial cyber-physical system (ICPS) drives the proliferation of sensor devices and computing-intensive tasks. To address the limited resources of IIoT sensor devices, unmanned aerial vehicle (UAV)-assisted mobile edge computing (MEC) has emerged as a promising solution, providing flexible and cost-effective services in close proximity of IIoT sensor devices (ISDs). However, leveraging aerial MEC to meet the delay-sensitive and computation-intensive requirements of the ISDs could face several challenges, including the limited communication, computation and caching (3C) resources, stringent offloading requirements for 3C services, and constrained on-board energy of UAVs. To address these issues, we first present a collaborative aerial MEC-assisted ICPS architecture by incorporating the computing capabilities of the macro base station (MBS) and UAVs. We then formulate a service delay minimization optimization problem (SDMOP). Since the SDMOP is proved to be an NP-hard problem, we propose a joint computation offloading, caching, communication resource allocation, computation resource allocation, and UAV trajectory control approach (JC5A). Specifically, JC5A consists of a block successive upper bound minimization method of multipliers (BSUMM) for computation offloading and service caching, a convex optimization-based method for communication and computation resource allocation, and a successive convex approximation (SCA)-based method for UAV trajectory control. Moreover, we theoretically prove the convergence and polynomial complexity of JC5A. Simulation results demonstrate that the proposed approach can achieve superior system performance compared to the benchmark approaches and algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.04762v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Geng Sun, Jiaxu Wu, Zemin Sun, Long He, Jiacheng Wang, Dusit Niyato, Abbas Jamalipour, Shiwen Mao</dc:creator>
    </item>
    <item>
      <title>A Survey on Task Allocation and Scheduling in Robotic Network Systems</title>
      <link>https://arxiv.org/abs/2303.12876</link>
      <description>arXiv:2303.12876v3 Announce Type: replace-cross 
Abstract: Cloud Robotics is helping to create a new generation of robots that leverage the nearly unlimited resources of large data centers (i.e., the cloud), overcoming the limitations imposed by on-board resources. Different processing power, capabilities, resource sizes, energy consumption, and so forth, make scheduling and task allocation critical components. The basic idea of task allocation and scheduling is to optimize performance by minimizing completion time, energy consumption, delays between two consecutive tasks, along with others, and maximizing resource utilization, number of completed tasks in a given time interval, and suchlike. In the past, several works have addressed various aspects of task allocation and scheduling. In this paper, we provide a comprehensive overview of task allocation and scheduling strategies and related metrics suitable for robotic network cloud systems. We discuss the issues related to allocation and scheduling methods and the limitations that need to be overcome. The literature review is organized according to three different viewpoints: Architectures and Applications, Methods and Parameters. In addition, the limitations of each method are highlighted for future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.12876v3</guid>
      <category>cs.RO</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/JIOT.2024.3491944</arxiv:DOI>
      <dc:creator>Saeid Alirezazadeh, Lu\'is A. Alexandre</dc:creator>
    </item>
    <item>
      <title>Preserving Data Privacy for ML-driven Applications in Open Radio Access Networks</title>
      <link>https://arxiv.org/abs/2402.09710</link>
      <description>arXiv:2402.09710v2 Announce Type: replace-cross 
Abstract: Deep learning offers a promising solution to improve spectrum access techniques by utilizing data-driven approaches to manage and share limited spectrum resources for emerging applications. For several of these applications, the sensitive wireless data (such as spectrograms) are stored in a shared database or multistakeholder cloud environment and are therefore prone to privacy leaks. This paper aims to address such privacy concerns by examining the representative case study of shared database scenarios in 5G Open Radio Access Network (O-RAN) networks where we have a shared database within the near-real-time (near-RT) RAN intelligent controller. We focus on securing the data that can be used by machine learning (ML) models for spectrum sharing and interference mitigation applications without compromising the model and network performances. The underlying idea is to leverage a (i) Shuffling-based learnable encryption technique to encrypt the data, following which, (ii) employ a custom Vision transformer (ViT) as the trained ML model that is capable of performing accurate inferences on such encrypted data. The paper offers a thorough analysis and comparisons with analogous convolutional neural networks (CNN) as well as deeper architectures (such as ResNet-50) as baselines. Our experiments showcase that the proposed approach significantly outperforms the baseline CNN with an improvement of 24.5% and 23.9% for the percent accuracy and F1-Score respectively when operated on encrypted data. Though deeper ResNet-50 architecture is obtained as a slightly more accurate model, with an increase of 4.4%, the proposed approach boasts a reduction of parameters by 99.32%, and thus, offers a much-improved prediction time by nearly 60%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09710v2</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pranshav Gajjar, Azuka Chiejina, Vijay K. Shah</dc:creator>
    </item>
    <item>
      <title>Combining Threat Intelligence with IoT Scanning to Predict Cyber Attack</title>
      <link>https://arxiv.org/abs/2411.17931</link>
      <description>arXiv:2411.17931v2 Announce Type: replace-cross 
Abstract: While the Web has become a worldwide platform for communication, hackers and hacktivists share their ideology and communicate with members on the "Dark Web"-the reverse of the Web. Currently, the problems of information overload and difficulty to obtain a comprehensive picture of hackers and cyber-attackers hinder the effective analysis of predicting their activities on the Web. Also, there are currently more objects connected to the internet than there are people in the world and this gap will continue to grow as more and more objects gain ability to directly interface with the Internet. Many technical communities are vigorously pursuing research topics that contribute to the Internet of Things (IoT). In this paper I have proposed a novel methodology for collecting and analyzing the Dark Web information to identify websites of hackers from the Web sea, and how this information can help us in predicting IoT vulnerabilities. This methodology incorporates information collection, analysis, visualization techniques, and exploits some of the IoT devices. Through this research I want to contribute to the existing literature on cyber-security that could potentially guide in both policy-making and intelligence research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.17931v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.NI</category>
      <pubDate>Tue, 03 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jubin Abhishek Soni</dc:creator>
    </item>
  </channel>
</rss>
