<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Solving the Correlation Cluster LP in Sublinear Time</title>
      <link>https://arxiv.org/abs/2503.20883</link>
      <description>arXiv:2503.20883v1 Announce Type: new 
Abstract: Correlation Clustering is a fundamental and widely-studied problem in unsupervised learning and data mining. The input is a graph and the goal is to construct a clustering minimizing the number of inter-cluster edges plus the number of missing intra-cluster edges.
  CCL+24 introduced the cluster LP for Correlation Clustering, which they argued captures the problem much more succinctly than previous linear programming formulations. However, the Cluster LP has exponential size, with a variable for every possible set of vertices in the input graph. Nevertheless, CCL+24 showed how to find a feasible solution for the Cluster LP in time O(n^{\text{poly}(1/\eps)}) with objective value at most (1+\epsilon) times the value of an optimal solution for the respective Correlation Clustering instance. Furthermore, they showed how to round a solution to the Cluster LP, yielding a (1.437+\eps)-approximation algorithm for the Correlation Clustering problem.
  The main technical result of this paper is a new approach to find a feasible solution for the Cluster LP with objective value at most (1+\epsilon) of the optimum in time \widetilde O(2^{\text{poly}(1/\eps)} n), where n is the number of vertices in the graph. We also show how to implement the rounding within the same time bounds, thus achieving a fast (1.437+\epsilon)-approximation algorithm for the Correlation Clustering problem. This bridges the gap between state-of-the-art methods for approximating Correlation Clustering and the recent focus on fast algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20883v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3717823.3718181</arxiv:DOI>
      <dc:creator>Nairen Cao, Vincent Cohen-Addad, Shi Li, Euiwoong Lee, David Rasmussen Lolck, Alantha Newman, Mikkel Thorup, Lukas Vogl, Shuyi Yan, Hanwen Zhang</dc:creator>
    </item>
    <item>
      <title>Deterministic Vertex Connectivity via Common-Neighborhood Clustering and Pseudorandomness</title>
      <link>https://arxiv.org/abs/2503.20985</link>
      <description>arXiv:2503.20985v1 Announce Type: new 
Abstract: We give a deterministic algorithm for computing a global minimum vertex cut in a vertex-weighted graph $n$ vertices and $m$ edges in $\widehat O(mn)$ time. This breaks the long-standing $\widehat \Omega(n^{4})$-time barrier in dense graphs, achievable by trivially computing all-pairs maximum flows. Up to subpolynomial factors, we match the fastest randomized $\tilde O(mn)$-time algorithm by [Henzinger, Rao, and Gabow'00], and affirmatively answer the question by [Gabow'06] whether deterministic $O(mn)$-time algorithms exist even for unweighted graphs. Our algorithm works in directed graphs, too.
  In unweighted undirected graphs, we present a faster deterministic $\widehat O(m\kappa)$-time algorithm where $\kappa\le n$ is the size of the global minimum vertex cut. For a moderate value of $\kappa$, this strictly improves upon all previous deterministic algorithms in unweighted graphs with running time $\widehat
  O(m(n+\kappa^{2}))$ [Even'75], $\widehat O(m(n+\kappa\sqrt{n}))$ [Gabow'06], and $\widehat O(m2^{O(\kappa^{2})})$ [Saranurak and Yingchareonthawornchai'22]. Recently, a linear-time algorithm has been shown by [Korhonen'24] for very small $\kappa$.
  Our approach applies the common-neighborhood clustering, recently introduced by [Blikstad, Jiang, Mukhopadhyay, Yingchareonthawornchai'25], in novel ways, e.g., on top of weighted graphs and on top of vertex-expander decomposition. We also exploit pseudorandom objects often used in computational complexity communities, including crossing families based on dispersers from [Wigderson and Zuckerman'99; TaShma, Umans and Zuckerman'01] and selectors based on linear lossless condensers [Guruswwami, Umans and Vadhan'09; Cheraghchi'11]. To our knowledge, this is the first application of selectors in graph algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20985v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonggang Jiang, Chaitanya Nalam, Thatchaphol Saranurak, Sorrachai Yingchareonthawornchai</dc:creator>
    </item>
    <item>
      <title>On the Hardness Hierarchy for the $O(n \sqrt{\log n})$ Complexity in the Word RAM</title>
      <link>https://arxiv.org/abs/2503.21049</link>
      <description>arXiv:2503.21049v1 Announce Type: new 
Abstract: In this work, we study the relative hardness of fundamental problems with state-of-the-art word RAM algorithms that take $O(n\sqrt{\log n})$ time for instances described in $\Theta(n)$ machine words ($\Theta(n\log n)$ bits). This complexity class, one of six hardness levels identified by Chan and P\u{a}tra\c{s}cu [SODA 2010], includes diverse problems from several domains: Counting Inversions, string processing problems (BWT Construction, LZ77 Factorization, Longest Common Substring, Batched Longest Previous Factor Queries, Batched Inverse Suffix Array Queries), and computational geometry tasks (Orthogonal Range Counting, Orthogonal Segment Intersection). We offer two main contributions:
  We establish new links between the above string problems and Dictionary Matching, a classic task solvable using the Aho-Corasick automaton. We restrict Dictionary Matching to instances with $O(n)$ binary patterns of length $m = O(\log n)$ each, and we prove that, unless these instances can be solved in $o(n\sqrt{\log n})$ time, the aforementioned string problems cannot be solved faster either.
  Via further reductions, we extend this hardness to Counting Inversions (a fundamental component in geometric algorithms) and thus to Orthogonal Range Counting and Orthogonal Segment Intersection. This hinges on String Nesting, a new problem which is equivalent to Dictionary Matching and can be reduced to Counting Inversions in three steps.
  Together, our results unveil a single problem, with two equivalent formulations, that underlies the hardness of nearly all major problems currently occupying the $O(n\sqrt{\log n})$ level of hardness. These results drastically funnel further efforts to improve the complexity of near-linear problems. As an auxiliary outcome of our framework, we also prove that the alphabet in several central string problems can be efficiently reduced to binary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21049v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dominik Kempa, Tomasz Kociumaka</dc:creator>
    </item>
    <item>
      <title>A Quantum Constraint Generation Framework for Binary Linear Programs</title>
      <link>https://arxiv.org/abs/2503.21222</link>
      <description>arXiv:2503.21222v1 Announce Type: new 
Abstract: We propose a new approach to utilize quantum computers for binary linear programming (BLP), which can be extended to general integer linear programs (ILP). Quantum optimization algorithms, hybrid or quantum-only, are currently general purpose, standalone solvers for ILP. However, to consider them practically useful, we expect them to overperform the current state of the art classical solvers. That expectation is unfair to quantum algorithms: in classical ILP solvers, after many decades of evolution, many different algorithms work together as a robust machine to get the best result. This is the approach we would like to follow now with our quantum 'solver' solutions. In this study we wrap any suitable quantum optimization algorithm into a quantum informed classical constraint generation framework. First we relax our problem by dropping all constraints and encode it into an Ising Hamiltonian for the quantum optimization subroutine. Then, by sampling from the solution state of the subroutine, we obtain information about constraint violations in the initial problem, from which we decide which coupling terms we need to introduce to the Hamiltonian. The coupling terms correspond to the constraints of the initial binary linear program. Then we optimize over the new Hamiltonian again, until we reach a feasible solution, or other stopping conditions hold. Since one can decide how many constraints they add to the Hamiltonian in a single step, our algorithm is at least as efficient as the (hybrid) quantum optimization algorithm it wraps. We support our claim with results on small scale minimum cost exact cover problem instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21222v1</guid>
      <category>cs.DS</category>
      <category>quant-ph</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andr\'as Cz\'egel, Bogl\'arka G. -T\'oth</dc:creator>
    </item>
    <item>
      <title>A Tolerant Independent Set Tester</title>
      <link>https://arxiv.org/abs/2503.21441</link>
      <description>arXiv:2503.21441v1 Announce Type: new 
Abstract: We give nearly optimal bounds on the sample complexity of $(\widetilde{\Omega}(\epsilon),\epsilon)$-tolerant testing the $\rho$-independent set property in the dense graph setting. In particular, we give an algorithm that inspects a random subgraph on $\widetilde{O}(\rho^3/\epsilon^2)$ vertices and, for some constant $c,$ distinguishes between graphs that have an induced subgraph of size $\rho n$ with fewer than $\frac{\epsilon}{c \log^4(1/\epsilon)} n^2$ edges from graphs for which every induced subgraph of size $\rho n$ has at least $\epsilon n^2$ edges. Our sample complexity bound matches, up to logarithmic factors, the recent upper bound by Blais and Seth (2023) for the non-tolerant testing problem, which is known to be optimal for the non-tolerant testing problem based on a lower bound by Feige, Langberg and Schechtman (2004).
  Our main technique is a new graph container lemma for sparse subgraphs instead of independent sets. We also show that our new lemma can be used to generalize one of the classic applications of the container method, that of counting independent sets in regular graphs, to counting sparse subgraphs in regular graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21441v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cameron Seth</dc:creator>
    </item>
    <item>
      <title>Output-sensitive approximate counting via a measure-bounded hyperedge oracle, or: How asymmetry helps estimate $k$-clique counts faster</title>
      <link>https://arxiv.org/abs/2503.21655</link>
      <description>arXiv:2503.21655v1 Announce Type: new 
Abstract: Dell, Lapinskas and Meeks [DLM SICOMP 2022] presented a general reduction from approximate counting to decision for a class of fine-grained problems that can be viewed as hyperedge counting or detection problems in an implicit hypergraph, thus obtaining tight equivalences between approximate counting and decision for many key problems such as $k$-clique, $k$-sum and more. Their result is a reduction from approximately counting the number of hyperedges in an implicit $k$-partite hypergraph to a polylogarithmic number of calls to a hyperedge oracle that returns whether a given subhypergraph contains an edge.
  The main result of this paper is a generalization of the DLM result for {\em output-sensitive} approximate counting, where the running time of the desired counting algorithm is inversely proportional to the number of witnesses. Our theorem is a reduction from approximately counting the (unknown) number of hyperedges in an implicit $k$-partite hypergraph to a polylogarithmic number of calls to a hyperedge oracle called only on subhypergraphs with a small ``measure''. If a subhypergraph has $u_i$ nodes in the $i$th node partition of the $k$-partite hypergraph, then its measure is $\prod_i u_i$.
  Using the new general reduction and by efficiently implementing measure-bounded colorful independence oracles, we obtain new improved output-sensitive approximate counting algorithms for $k$-clique, $k$-dominating set and $k$-sum. In graphs with $n^t$ $k$-cliques, for instance, our algorithm $(1\pm \epsilon)$-approximates the $k$-clique count in time
  $$\tilde{O}_\epsilon(n^{\omega(\frac{k-t-1}{3},\frac{k-t}{3},\frac{k-t+2}{3}) }+n^2),$$ where $\omega(a,b,c)$ is the exponent of $n^a\times n^b$ by $n^b\times n^c$ matrix multiplication. For large $k$ and $t&gt;2$, this is a substantial improvement over prior work, even if $\omega=2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21655v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keren Censor-Hillel, Tomer Even, Virginia Vassilevska Williams</dc:creator>
    </item>
    <item>
      <title>Fully dynamic biconnectivity in $\tilde{\mathcal{O}}(\log^2 n)$ time</title>
      <link>https://arxiv.org/abs/2503.21733</link>
      <description>arXiv:2503.21733v1 Announce Type: new 
Abstract: We present a deterministic fully-dynamic data structure for maintaining information about the cut-vertices in a graph; i.e. the vertices whose removal would disconnect the graph. Our data structure supports insertion and deletion of edges, as well as queries to whether a pair of connected vertices are either biconnected, or can be separated by a cutvertex, and in the latter case we support access to separating cutvertices. All update operations are supported in amortized $O(\log^2 n \log^2 \log n)$ time, and queries take worst-case $O(\log n \log^2 \log n)$ time. Note that these time bounds match the current best for deterministic dynamic connectivity up to $\log \log n$ factors.
  We obtain our improved running time by a series of reductions from the original problem into well-defined data structure problems. While we do apply the well-known techniques for improving running time of two-edge connectivity [STOC'00, SODA'18], these techniques alone do not lead to an update time of $\tilde{O}(\log^3 n)$, let alone the $\tilde{O}(\log^2 n)$ we give as a final result.
  Our contributions include a formally defined transient expose operation, which can be thought of as a cheaper read-only expose operation on a top tree. For each vertex in the graph, we maintain a data structure over its neighbors, and in this data structure we apply biasing (twice) to save two $\tilde{O}(\log n)$ factors. One of these biasing techniques is a new biased disjoint sets data structure, which may be of independent interest. Moreover, in this neighborhood data structure, we facilitate that the vertex can select two VIP neighbors that get special treatment, corresponding to its potentially two neighbors on an exposed path, improving a $\log n$-time operation down to constant time. It is this combination of VIP neighbors with the transient expose that saves an $\tilde{O}(\log n)$-factor from another bottleneck.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21733v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jacob Holm, Wojciech Nadara, Eva Rotenberg, Marek Soko{\l}owski</dc:creator>
    </item>
    <item>
      <title>History-Independent Concurrent Hash Tables</title>
      <link>https://arxiv.org/abs/2503.21016</link>
      <description>arXiv:2503.21016v1 Announce Type: cross 
Abstract: A history-independent data structure does not reveal the history of operations applied to it, only its current logical state, even if its internal state is examined. This paper studies history-independent concurrent dictionaries, in particular, hash tables, and establishes inherent bounds on their space requirements.
  This paper shows that there is a lock-free history-independent concurrent hash table, in which each memory cell stores two elements and two bits, based on Robin Hood hashing. Our implementation is linearizable, and uses the shared memory primitive LL/SC. The expected amortized step complexity of the hash table is $O(c)$, where $c$ is an upper bound on the number of concurrent operations that access the same element, assuming the hash table is not overpopulated. We complement this positive result by showing that even if we have only two concurrent processes, no history-independent concurrent dictionary that supports sets of any size, with wait-free membership queries and obstruction-free insertions and deletions, can store only two elements of the set and a constant number of bits in each memory cell. This holds even if the step complexity of operations on the dictionary is unbounded.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21016v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hagit Attiya, Michael A. Bender, Mart\'in Farach-Colton, Rotem Oshman, Noa Schiller</dc:creator>
    </item>
    <item>
      <title>A Theoretical Framework for Distribution-Aware Dataset Search</title>
      <link>https://arxiv.org/abs/2503.21235</link>
      <description>arXiv:2503.21235v1 Announce Type: cross 
Abstract: Effective data discovery is a cornerstone of modern data-driven decision-making. Yet, identifying datasets with specific distributional characteristics, such as percentiles or preferences, remains challenging. While recent proposals have enabled users to search based on percentile predicates, much of the research in data discovery relies on heuristics. This paper presents the first theoretically backed framework that unifies data discovery under centralized and decentralized settings.
  Let $\mathcal{P}=\{P_1,...,P_N\}$ be a repository of $N$ datasets, where $P_i\subset \mathbb{R}^d$, for $d=O(1)$ . We study the percentile indexing (Ptile) problem and the preference indexing (Pref) problem under the centralized and the federated setting. In the centralized setting we assume direct access to the datasets. In the federated setting we assume access to a synopsis of each dataset. The goal of Ptile is to construct a data structure such that given a predicate (rectangle $R$ and interval $\theta$) report all indexes $J$ such that $j\in J$ iff $|P_j\cap R|/|P_j|\in\theta$. The goal of Pref is to construct a data structure such that given a predicate (vector $v$ and interval $\theta$) report all indexes $J$ such that $j\in J$ iff $\omega(P_j,v)\in \theta$, where $\omega(P_j,v)$ is the inner-product of the $k$-th largest projection of $P_j$ on $v$. We first show that we cannot hope for near-linear data structures with polylogarithmic query time in the centralized setting. Next we show $\tilde{O}(N)$ space data structures that answer Ptile and Pref queries in $\tilde{O}(1+OUT)$ time, where $OUT$ is the output size. Each data structure returns a set of indexes $J$ such that i) for every $P_i$ that satisfies the predicate, $i\in J$ and ii) if $j\in J$ then $P_j$ satisfies the predicate up to an additive error $\varepsilon+2\delta$, where $\varepsilon\in(0,1)$ and $\delta$ is the error of synopses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.21235v1</guid>
      <category>cs.DB</category>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>PODS 2025</arxiv:journal_reference>
      <dc:creator>Aryan Esmailpour, Sainyam Galhotra, Rahul Raychaudhury, Stavros Sintos</dc:creator>
    </item>
    <item>
      <title>The Power of Greedy for Online Minimum Cost Matching on the Line</title>
      <link>https://arxiv.org/abs/2210.03166</link>
      <description>arXiv:2210.03166v3 Announce Type: replace 
Abstract: We consider the online minimum cost matching problem on the line, in which there are $n$ servers and, at each of $n$ time steps, a request arrives and must be irrevocably matched to a server that has not yet been matched to, with the goal of minimizing the sum of the distances between the matched pairs. Despite achieving a worst-case competitive ratio that is exponential in $n$, the simple greedy algorithm, which matches each request to its nearest available free server, performs very well in practice. A major question is thus to explain greedy's strong empirical performance. In this paper, we aim to understand the performance of greedy over instances that are at least partially random. When both the requests and the servers are drawn uniformly and independently from $[0,1]$, we show that greedy is constant competitive, which improves over the previously best-known $O(\sqrt{n})$ bound. We extend this constant competitive ratio to a setting with a linear excess of servers, which improves over the previously best-known $O(\log^3{n})$ bound. We moreover show that in the semi-random model where the requests are still drawn uniformly and independently but where the servers are chosen adversarially, greedy achieves an $O(\log{n})$ competitive ratio. When the requests arrive in a random order but are chosen adversarially, it was previously known that greedy is $O(n)$-competitive. Even though this one-sided randomness allows a large improvement in greedy's competitive ratio compared to the model where requests are adversarial and arrive in a random order, we show that it is not sufficient to obtain a constant competitive ratio by giving a tight $\Omega(\log{n})$ lower bound. These results invite further investigation about how much randomness is necessary and sufficient to obtain strong theoretical guarantees for the greedy algorithm for online minimum cost matching, on the line and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.03166v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eric Balkanski, Yuri Faenza, Noemie Perivier</dc:creator>
    </item>
    <item>
      <title>Optimal Static Dictionary with Worst-Case Constant Query Time</title>
      <link>https://arxiv.org/abs/2412.10655</link>
      <description>arXiv:2412.10655v2 Announce Type: replace 
Abstract: In this paper, we design a new succinct static dictionary with worst-case constant query time. A dictionary data structure stores a set of key-value pairs with distinct keys in $[U]$ and values in $[\sigma]$, such that given a query $x\in [U]$, it quickly returns if $x$ is one of the input keys, and if so, also returns its associated value. The textbook solution to dictionaries is hash tables. On the other hand, the (information-theoretical) optimal space to encode such a set of key-value pairs is only $\text{OPT} := \log\binom{U}{n}+n\log \sigma$.
  We construct a dictionary that uses $\text{OPT} + n^{\epsilon}$ bits of space, and answers queries in constant time in worst case. Previously, constant-time dictionaries are only known with $\text{OPT} + n/\text{poly}\log n$ space [P\v{a}tra\c{s}cu 2008], or with $\text{OPT}+n^{\epsilon}$ space but expected constant query time [Yu 2020]. We emphasize that most of the extra $n^{\epsilon}$ bits are used to store a lookup table that does not depend on the input, and random bits for hash functions. The "main" data structure only occupies $\text{OPT}+\text{poly}\log n$ bits.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10655v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Hu, Jingxun Liang, Huacheng Yu, Junkai Zhang, Renfei Zhou</dc:creator>
    </item>
    <item>
      <title>Host Community Respecting Refugee Housing</title>
      <link>https://arxiv.org/abs/2302.13997</link>
      <description>arXiv:2302.13997v3 Announce Type: replace-cross 
Abstract: We propose a novel model for refugee housing respecting the preferences of the accepting community and refugees themselves. In particular, we are given a topology representing the local community, a set of inhabitants occupying some vertices of the topology, and a set of refugees that should be housed on the empty vertices of the graph. Both the inhabitants and the refugees have preferences over the structure of their neighborhood.
  We are specifically interested in the problem of finding housing such that the preferences of every individual are met; using game-theoretical words, we are looking for housing that is stable with respect to some well-defined notion of stability. We investigate conditions under which the existence of equilibria is guaranteed and study the computational complexity of finding such a stable outcome. As the problem is NP-hard even in very simple settings, we employ the parameterized complexity framework to give a finer-grained view of the problem's complexity with respect to natural parameters and structural restrictions of the given topology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13997v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Du\v{s}an Knop, \v{S}imon Schierreich</dc:creator>
    </item>
    <item>
      <title>Brooks-type colourings of digraphs in linear time</title>
      <link>https://arxiv.org/abs/2405.05222</link>
      <description>arXiv:2405.05222v2 Announce Type: replace-cross 
Abstract: Brooks' Theorem is a fundamental result on graph colouring, stating that the chromatic number of a graph is almost always upper bounded by its maximal degree. Lov\'asz showed that such a colouring may then be computed in linear time when it exists. Many analogues are known for variants of (di)graph colouring, notably for list-colouring and partitions into subgraphs with prescribed degeneracy. One of the most general results of this kind is due to Borodin, Kostochka, and Toft, when asking for classes of colours to satisfy "variable degeneracy" constraints. An extension of this result to digraphs has recently been proposed by Bang-Jensen, Schweser, and Stiebitz, by considering colourings as partitions into "variable weakly degenerate" subdigraphs. Unlike earlier variants, there exists no linear-time algorithm to produce colourings for these generalisations.
  We introduce the notion of (variable) bidegeneracy for digraphs, capturing multiple (di)graph degeneracy variants. We define the corresponding concept of $F$-dicolouring, where $F = (f_1,...,f_s)$ is a vector of functions, and an $F$-dicolouring requires vertices coloured $i$ to induce a "strictly-$f_i$-bidegenerate" subdigraph. We prove an analogue of Brooks' theorem for $F$-dicolouring, generalising the result of Bang-Jensen et al., and earlier analogues in turn.
  Our new approach provides a linear-time algorithm that, given a digraph $D$, either produces an $F$-dicolouring of $D$, or correctly certifies that none exist. This yields the first linear-time algorithms to compute (di)colourings corresponding to the aforementioned generalisations of Brooks' theorem. In turn, it gives an unified framework to compute such colourings for various intermediate generalisations of Brooks' theorem such as list-(di)colouring and partitioning into (variable) degenerate sub(di)graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05222v2</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Gon\c{c}alves, Lucas Picasarri-Arrieta, Amadeus Reinald</dc:creator>
    </item>
    <item>
      <title>Structure and Independence in Hyperbolic Uniform Disk Graphs</title>
      <link>https://arxiv.org/abs/2407.09362</link>
      <description>arXiv:2407.09362v2 Announce Type: replace-cross 
Abstract: We consider intersection graphs of disks of radius $r$ in the hyperbolic plane. Unlike the Euclidean setting, these graph classes are different for different values of $r$, where very small $r$ corresponds to an almost-Euclidean setting and $r \in \Omega(\log n)$ corresponds to a firmly hyperbolic setting. We observe that larger values of $r$ create simpler graph classes, at least in terms of separators and the computational complexity of the \textsc{Independent Set} problem.
  First, we show that intersection graphs of disks of radius $r$ in the hyperbolic plane can be separated with $\mathcal{O}((1+1/r)\log n)$ cliques in a balanced manner. Our second structural insight concerns Delaunay complexes in the hyperbolic plane and may be of independent interest. We show that for any set $S$ of $n$ points with pairwise distance at least $2r$ in the hyperbolic plane the corresponding Delaunay complex has outerplanarity $1+\mathcal{O}(\frac{\log n}{r})$, which implies a similar bound on the balanced separators and treewidth of such Delaunay complexes.
  Using this outerplanarity (and treewidth) bound we prove that \textsc{Independent Set} can be solved in $n^{\mathcal{O}(1+\frac{\log n}{r})}$ time. The algorithm is based on dynamic programming on some unknown sphere cut decomposition that is based on the solution. The resulting algorithm is a far-reaching generalization of a result of Kisfaludi-Bak (SODA 2020), and it is tight under the Exponential Time Hypothesis. In particular, \textsc{Independent Set} is polynomial-time solvable in the firmly hyperbolic setting of $r\in \Omega(\log n)$. Finally, in the case when the disks have ply (depth) at most $\ell$, we give a PTAS for \textsc{Maximum Independent Set} that has only quasi-polynomial dependence on $1/\varepsilon$ and $\ell$. Our PTAS is a further generalization of our exact algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09362v2</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Bl\"asius, Jean-Pierre von der Heydt, S\'andor Kisfaludi-Bak, Marcus Wilhelm, Geert van Wordragen</dc:creator>
    </item>
    <item>
      <title>Renaming in distributed certification</title>
      <link>https://arxiv.org/abs/2409.15404</link>
      <description>arXiv:2409.15404v2 Announce Type: replace-cross 
Abstract: Local certification is the area of distributed network computing asking the following question: How to certify to the nodes of a network that a global property holds, if they are limited to a local verification?
  In this area, it is often essential to have identifiers, that is, unique integers assigned to the nodes. In this short paper, we show how to reduce the range of the identifiers, in three different settings. More precisely, we show how to rename identifiers in the classical local certification setting, when we can (resp.\ cannot) choose the new identifiers, and we show how a global certificate can help to encode very compactly a new identifier assignment that is not injective in general, but still useful in applications.
  We conclude with a number of applications of these results: For every $\ell$, there are local certification schemes for the properties of having clique number at most $\ell$, having diameter at most $\ell$, and having independence number at most~2, with certificates of size $O(n)$. We also show that there is a global certification scheme for bipartiteness with certificates of size $O(n)$. All these results are optimal.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15404v2</guid>
      <category>cs.DC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Bousquet, Louis Esperet, Laurent Feuilloley, S\'ebastien Zeitoun</dc:creator>
    </item>
    <item>
      <title>On the formalization of the notion of a concurrent algorithm</title>
      <link>https://arxiv.org/abs/2410.17821</link>
      <description>arXiv:2410.17821v2 Announce Type: replace-cross 
Abstract: Previous papers give accounts of quests for satisfactory formalizations of the classical informal notion of an algorithm and the contemporary informal notion of an interactive algoritm. In this paper, an attempt is made to generalize the results of the former quest to the contemporary informal notion of a concurrent algorithm. The notion of a concurrent proto-algorithm is introduced. The thought is that concurrent algorithms are equivalence classes of concurrent proto-algorithms under an appropriate equivalence relation. Three equivalence relations are defined. Two of them are deemed to be bounds for an appropriate equivalence relation and the third is likely an appropriate one. The connection between concurrency and non-determinism in the presented setting is also addressed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.17821v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LO</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>C. A. Middelburg</dc:creator>
    </item>
    <item>
      <title>An Exponential Separation Between Quantum and Quantum-Inspired Classical Algorithms for Linear Systems</title>
      <link>https://arxiv.org/abs/2411.02087</link>
      <description>arXiv:2411.02087v3 Announce Type: replace-cross 
Abstract: Achieving a provable exponential quantum speedup for an important machine learning task has been a central research goal since the seminal HHL quantum algorithm for solving linear systems and the subsequent quantum recommender systems algorithm by Kerenidis and Prakash. These algorithms were initially believed to be strong candidates for exponential speedups, but a lower bound ruling out similar classical improvements remained absent. In breakthrough work by Tang, it was demonstrated that this lack of progress in classical lower bounds was for good reasons. Concretely, she gave a classical counterpart of the quantum recommender systems algorithm, reducing the quantum advantage to a mere polynomial. Her approach is quite general and was named quantum-inspired classical algorithms. Since then, almost all the initially exponential quantum machine learning speedups have been reduced to polynomial via new quantum-inspired classical algorithms. From the current state-of-affairs, it is unclear whether we can hope for exponential quantum speedups for any natural machine learning task.
  In this work, we present the first such provable exponential separation between quantum and quantum-inspired classical algorithms for the basic problem of solving a linear system when the input matrix is well-conditioned and has sparse rows and columns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.02087v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Allan Gr{\o}nlund, Kasper Green Larsen</dc:creator>
    </item>
    <item>
      <title>Solving Modular Linear Systems with a Constraint by parallel decomposition of the Smith form and extended Euclidean division modulo powers of primes divisors</title>
      <link>https://arxiv.org/abs/2503.10158</link>
      <description>arXiv:2503.10158v2 Announce Type: replace-cross 
Abstract: Integral linear systems $Ax=b$ with matrices $A$, $b$ and solutions $x$ are also required to be in integers, can be solved using invariant factors of $A$ (by computing the Smith Canonical Form of $A$). This paper explores a new problem which arises in applications, that of obtaining conditions for solving the Modular Linear System $Ax=b\rem n$ given $A,b$ in $\zz_n$ for $x$ in $\zz_n$ along with the constraint that the value of the linear function $\phi(x)=\la w,x\ra$ is coprime to $n$ for some solution $x$. In this paper we develop decomposition of the system to coprime moduli $p^{r(p)}$ which are divisors of $n$ and show how such a decomposition simplifies the computation of Smith form. This extends the well known index calculus method of computing the discrete logarithm where the moduli over which the linear system is reduced were assumed to be prime (to solve the reduced systems over prime fields) to the case when the factors of the modulus are prime powers $p^{r(p)}$. It is shown how this problem can be addressed effciently using the invariant factors and Smith form of the augmented matrix $[A,-p^{r(p)}I]$ and conditions modulo $p$ satisfied by $w$, where $p^{r(p)}$ vary over all divisors of $n$ with $p$ prime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.10158v2</guid>
      <category>math.NT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Virendra Sule</dc:creator>
    </item>
    <item>
      <title>Follow-the-Regularized-Leader with Adversarial Constraints</title>
      <link>https://arxiv.org/abs/2503.13366</link>
      <description>arXiv:2503.13366v2 Announce Type: replace-cross 
Abstract: Constrained Online Convex Optimization (COCO) can be seen as a generalization of the standard Online Convex Optimization (OCO) framework. At each round, a cost function and constraint function are revealed after a learner chooses an action. The goal is to minimize both the regret and cumulative constraint violation (CCV) against an adaptive adversary. We show for the first time that is possible to obtain the optimal $O(\sqrt{T})$ bound on both regret and CCV, improving the best known bounds of $O \left( \sqrt{T} \right)$ and $\~{O} \left( \sqrt{T} \right)$ for the regret and CCV, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13366v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Fri, 28 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ricardo N. Ferreira, Cl\'audia Soares</dc:creator>
    </item>
  </channel>
</rss>
