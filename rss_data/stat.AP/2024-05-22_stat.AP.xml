<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 22 May 2024 04:00:57 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 22 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A canonical polyadic tensor basis for fast Bayesian estimation of multi-subject fMRI activation patterns</title>
      <link>https://arxiv.org/abs/2405.12325</link>
      <description>arXiv:2405.12325v1 Announce Type: new 
Abstract: Task-evoked functional magnetic resonance imaging studies, such as the Human Connectome Project (HCP), are a powerful tool for exploring how brain activity is influenced by cognitive tasks like memory retention, decision-making, and language processing. A fast Bayesian function-on-scalar model is proposed for estimating population-level activation maps linked to the working memory task. The model is based on the canonical polyadic (CP) tensor decomposition of coefficient maps obtained for each subject. This decomposition effectively yields a tensor basis capable of extracting both common features and subject-specific features from the coefficient maps. These subject-specific features, in turn, are modeled as a function of covariates of interest using a Bayesian model that accounts for the correlation of the CP-extracted features. The dimensionality reduction achieved with the tensor basis allows for a fast MCMC estimation of population-level activation maps. This model is applied to one hundred unrelated subjects from the HCP dataset, yielding significant insights into brain signatures associated with working memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12325v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michelle F. Miranda</dc:creator>
    </item>
    <item>
      <title>An Introduction on Solar Imaging Data Analytic Challenges and Opportunities for Statisticians</title>
      <link>https://arxiv.org/abs/2405.12331</link>
      <description>arXiv:2405.12331v1 Announce Type: new 
Abstract: We give a gentle introduction to solar imaging data, focusing on challenges and opportunities of data-driven approaches for solar eruptions. The various solar phenomena prediction problems that might benefit from statistical methods are presented. Available data and software will be described. State-of-art solar eruption forecasting with data driven approaches are summarized and discussed. Based on the characteristics of the datasets and state-of-art approaches, we point out several promising directions to explore from statistical modeling and computational perspectives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12331v1</guid>
      <category>stat.AP</category>
      <category>astro-ph.IM</category>
      <category>astro-ph.SR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yang Chen, Ward Manchester, Meng Jin, Alexei Pevtsov</dc:creator>
    </item>
    <item>
      <title>Considerations for Single-Arm Trials to Support Accelerated Approval of Oncology Drugs</title>
      <link>https://arxiv.org/abs/2405.12437</link>
      <description>arXiv:2405.12437v1 Announce Type: new 
Abstract: In the last two decades, single-arm trials (SATs) have been effectively used to study anticancer therapies in well-defined patient populations using durable response rates as an objective and interpretable clinical endpoints. With a growing trend of regulatory accelerated approval (AA) requiring randomized controlled trials (RCTs), some confusions have arisen about the roles of SATs in AA. This paper is intended to elucidate conditions under which an SAT may be considered reasonable for AA. Specifically, the paper describes (1) two necessary conditions for designing an SAT, (2) three sufficient conditions that help either optimize the study design or interpret the study results, (3) four conditions that demonstrate substantial evidence of clinical benefits of the drug, and (4) a plan of a confirmatory RCT to verify the clinical benefits. Some further considerations are discussed to help design a scientifically sound SAT and communicate with regulatory agencies. Conditions presented in this paper may serve as a set of references for sponsors using SATs for regulatory decision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12437v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feinan Lu, Tao Wang, Ying Lu, Jie Chen</dc:creator>
    </item>
    <item>
      <title>An analysis of factors impacting team strengths in the Australian Football League using time-variant Bradley-Terry models</title>
      <link>https://arxiv.org/abs/2405.12588</link>
      <description>arXiv:2405.12588v1 Announce Type: new 
Abstract: Australian Rules Football is a field invasion game where two teams attempt to score the highest points to win. Complex machine learning algorithms have been developed to predict match outcomes post-game, but their lack of interpretability hampers an understanding of the factors that affect a team's performance. Using data from the male competition of the Australian Football League, seasons 2015 to 2023, we estimate team strengths and the factors impacting them by fitting flexible Bradley-Terry models. We successfully identify teams significantly stronger or weaker than the average, with stronger teams placing higher in the previous seasons' ladder and leading the activity in the Forward 50 zone, goal shots and scoring over their opponents. Playing at home is confirmed to create an advantage regardless of team strengths. The ability of the model to predict game results in advance is tested, with models accounting for team-specific, time-variant features predicting up to 71.5% of outcomes. Therefore, our approach can provide an interpretable understanding of team strengths and competitive game predictions, making it optimal for data-driven strategies and training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12588v1</guid>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Rafael Gonzalez Soffner, Manuele Leonelli</dc:creator>
    </item>
    <item>
      <title>Particle swarm optimization with Applications to Maximum Likelihood Estimation and Penalized Negative Binomial Regression</title>
      <link>https://arxiv.org/abs/2405.12386</link>
      <description>arXiv:2405.12386v1 Announce Type: cross 
Abstract: General purpose optimization routines such as nlminb, optim (R) or nlmixed (SAS) are frequently used to estimate model parameters in nonstandard distributions. This paper presents Particle Swarm Optimization (PSO), as an alternative to many of the current algorithms used in statistics. We find that PSO can not only reproduce the same results as the above routines, it can also produce results that are more optimal or when others cannot converge. In the latter case, it can also identify the source of the problem or problems. We highlight advantages of using PSO using four examples, where: (1) some parameters in a generalized distribution are unidentified using PSO when it is not apparent or computationally manifested using routines in R or SAS; (2) PSO can produce estimation results for the log-binomial regressions when current routines may not; (3) PSO provides flexibility in the link function for binomial regression with LASSO penalty, which is unsupported by standard packages like GLM and GENMOD in Stata and SAS, respectively, and (4) PSO provides superior MLE estimates for an EE-IW distribution compared with those from the traditional statistical methods that rely on moments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12386v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sisi Shao, Junhyung Park, Weng Kee Wong</dc:creator>
    </item>
    <item>
      <title>A Metric-based Principal Curve Approach for Learning One-dimensional Manifold</title>
      <link>https://arxiv.org/abs/2405.12390</link>
      <description>arXiv:2405.12390v1 Announce Type: cross 
Abstract: Principal curve is a well-known statistical method oriented in manifold learning using concepts from differential geometry. In this paper, we propose a novel metric-based principal curve (MPC) method that learns one-dimensional manifold of spatial data. Synthetic datasets Real applications using MNIST dataset show that our method can learn the one-dimensional manifold well in terms of the shape.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12390v1</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elvis Han Cui, Sisi Shao</dc:creator>
    </item>
    <item>
      <title>Efficient modeling of sub-kilometer surface wind with Gaussian processes and neural networks</title>
      <link>https://arxiv.org/abs/2405.12614</link>
      <description>arXiv:2405.12614v1 Announce Type: cross 
Abstract: Accurately representing surface weather at the sub-kilometer scale is crucial for optimal decision-making in a wide range of applications. This motivates the use of statistical techniques to provide accurate and calibrated probabilistic predictions at a lower cost compared to numerical simulations. Wind represents a particularly challenging variable to model due to its high spatial and temporal variability. This paper presents a novel approach that integrates Gaussian processes (GPs) and neural networks to model surface wind gusts, leveraging multiple data sources, including numerical weather prediction (NWP) models, digital elevation models (DEM), and in-situ measurements. Results demonstrate the added value of modeling the multivariate covariance structure of the variable of interest, as opposed to only applying a univariate probabilistic regression approach. Modeling the covariance enables the optimal integration of observed measurements from ground stations, which is shown to reduce the continuous ranked probability score compared to the baseline. Moreover, it allows the direct generation of realistic fields that are also marginally calibrated, aided by scalable techniques such as Random Fourier Features (RFF) and pathwise conditioning. We discuss the effect of different modeling choices, as well as different degrees of approximation, and present our results for a case study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12614v1</guid>
      <category>physics.ao-ph</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Zanetta, Daniele Nerini, Matteo Buzzi, Henry Moss</dc:creator>
    </item>
    <item>
      <title>Spatio-temporal modeling of co-dynamics of smallpox, measles and pertussis in pre-healthcare Finland</title>
      <link>https://arxiv.org/abs/2310.06538</link>
      <description>arXiv:2310.06538v2 Announce Type: replace 
Abstract: Infections are known to interact as previous infections may have an effect on risk of succumbing to a new infection. The co-dynamics can be mediated by immunosuppression or -modulation, shared environmental or climatic drivers, or competition for susceptible hosts. Research and statistical methods in epidemiology often concentrate on large pooled datasets, or high quality data from cities, leaving rural areas underrepresented in literature. Data considering rural populations are typically sparse and scarce, especially in the case of historical data sources, which may introduce considerable methodological challenges. In order to overcome many obstacles due to such data, we present a general Bayesian spatio-temporal model for disease co-dynamics. Applying the proposed model on historical (1820-1850) Finnish parish register data, we study the spread of infectious diseases in pre-healthcare Finland. We observe that measles, pertussis, and smallpox exhibit positively correlated dynamics, which could be attributed to immunosuppressive effects or, for example, the general weakening of the population due to recurring infections or poor nutritional conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06538v2</guid>
      <category>stat.AP</category>
      <category>q-bio.PE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tiia-Maria Pasanen, Jouni Helske, Harri H\"ogmander, Tarmo Ketola</dc:creator>
    </item>
    <item>
      <title>Leveraging text data for causal inference using electronic health records</title>
      <link>https://arxiv.org/abs/2307.03687</link>
      <description>arXiv:2307.03687v2 Announce Type: replace-cross 
Abstract: In studies that rely on data from electronic health records (EHRs), unstructured text data such as clinical progress notes offer a rich source of information about patient characteristics and care that may be missing from structured data. Despite the prevalence of text in clinical research, these data are often ignored for the purposes of quantitative analysis due their complexity. This paper presents a unified framework for leveraging text data to support causal inference with electronic health data at multiple stages of analysis. In particular, we consider how natural language processing and statistical text analysis can be combined with standard inferential techniques to address common challenges due to missing data, confounding bias, and treatment effect heterogeneity. Through an application to a recent EHR study investigating the effects of a non-randomized medical intervention on patient outcomes, we show how incorporating text data in a traditional matching analysis can help strengthen the validity of an estimated treatment effect and identify patient subgroups that may benefit most from treatment. We believe these methods have the potential to expand the scope of secondary analysis of clinical data to domains where structured EHR data is limited, such as in developing countries. To this end, we provide code and open-source replication materials to encourage adoption and broader exploration of these techniques in clinical research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03687v2</guid>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Reagan Mozer, Aaron R. Kaufman, Leo A. Celi, Luke Miratrix</dc:creator>
    </item>
    <item>
      <title>TimeGPT-1</title>
      <link>https://arxiv.org/abs/2310.03589</link>
      <description>arXiv:2310.03589v2 Announce Type: replace-cross 
Abstract: In this paper, we introduce TimeGPT, the first foundation model for time series, capable of generating accurate predictions for diverse datasets not seen during training. We evaluate our pre-trained model against established statistical, machine learning, and deep learning methods, demonstrating that TimeGPT zero-shot inference excels in performance, efficiency, and simplicity. Our study provides compelling evidence that insights from other domains of artificial intelligence can be effectively applied to time series analysis. We conclude that large-scale time series models offer an exciting opportunity to democratize access to precise predictions and reduce uncertainty by leveraging the capabilities of contemporary advancements in deep learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.03589v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azul Garza, Cristian Challu, Max Mergenthaler-Canseco</dc:creator>
    </item>
    <item>
      <title>Evaluating Binary Outcome Classifiers Estimated from Survey Data</title>
      <link>https://arxiv.org/abs/2311.00596</link>
      <description>arXiv:2311.00596v3 Announce Type: replace-cross 
Abstract: Surveys are commonly used to facilitate research in epidemiology, health, and the social and behavioral sciences. Often, these surveys are not simple random samples, and respondents are given weights reflecting their probability of selection into the survey. It is well known that analysts can use these survey weights to produce unbiased estimates of population quantities like totals. In this article, we show that survey weights also can be beneficial for evaluating the quality of predictive models when splitting data into training and test sets. In particular, we characterize model assessment statistics, such as sensitivity and specificity, as finite population quantities, and compute survey-weighted estimates of these quantities with sample test data comprising a random subset of the original data.Using simulations with data from the National Survey on Drug Use and Health and the National Comorbidity Survey, we show that unweighted metrics estimated with sample test data can misrepresent population performance, but weighted metrics appropriately adjust for the complex sampling design. We also show that this conclusion holds for models trained using upsampling for mitigating class imbalance. The results suggest that weighted metrics should be used when evaluating performance on sample test data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.00596v3</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Adway S. Wadekar, Jerome P. Reiter</dc:creator>
    </item>
    <item>
      <title>Precision Mars Entry Navigation with Atmospheric Density Adaptation via Neural Networks</title>
      <link>https://arxiv.org/abs/2401.14411</link>
      <description>arXiv:2401.14411v2 Announce Type: replace-cross 
Abstract: Spacecraft entering Mars require precise navigation algorithms capable of accurately estimating the vehicle's position and velocity in dynamic and uncertain atmospheric environments. Discrepancies between the true Martian atmospheric density and the onboard density model can significantly impair the performance of spacecraft entry navigation filters. This work introduces a new approach to online filtering for Martian entry using a neural network to estimate atmospheric density and employing a consider analysis to account for the uncertainty in the estimate. The network is trained on an exponential atmospheric density model, and its parameters are dynamically adapted in real time to account for any mismatch between the true and estimated densities. The adaptation of the network is formulated as a maximum likelihood problem by leveraging the measurement innovations of the filter to identify optimal network parameters. Within the context of the maximum likelihood approach, incorporating a neural network enables the use of stochastic optimizers known for their efficiency in the machine learning domain. Performance comparisons are conducted against two online adaptive approaches, covariance matching and state augmentation and correction, in various realistic Martian entry navigation scenarios. The results show superior estimation accuracy compared to other approaches, and precise alignment of the estimated density with a broad selection of realistic Martian atmospheres sampled from perturbed Mars-GRAM data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14411v2</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felipe Giraldo-Grueso, Andrey A. Popov, Renato Zanetti</dc:creator>
    </item>
  </channel>
</rss>
