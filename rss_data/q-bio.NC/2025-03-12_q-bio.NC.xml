<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Mar 2025 04:00:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Abstraction requires breadth: a renormalisation group approach</title>
      <link>https://arxiv.org/abs/2407.01656</link>
      <description>arXiv:2407.01656v3 Announce Type: cross 
Abstract: Abstraction is the process of extracting the essential features from raw data while ignoring irrelevant details. This is similar to the process of focusing on large-scale properties, systematically removing irrelevant small-scale details, implemented in the renormalisation group of statistical physics. This analogy is suggestive because the fixed points of the renormalisation group offer an ideal candidate of a truly abstract -- i.e. data independent -- representation. It has been observed that abstraction emerges with depth in neural networks. Deep layers of neural network capture abstract characteristics of data, such as "cat-ness" or "dog-ness" in images, by combining the lower level features encoded in shallow layers (e.g. edges). Yet we argue that depth alone is not enough to develop truly abstract representations. We advocate that the level of abstraction crucially depends on how broad the training set is. We address the issue within a renormalisation group approach where a representation is expanded to encompass a broader set of data. We take the unique fixed point of this transformation -- the Hierarchical Feature Model -- as a candidate for an abstract representation. This theoretical picture is tested in numerical experiments based on Deep Belief Networks trained on data of different breadth. These show that representations in deep layers of neural networks approach the Hierarchical Feature Model as the data gets broader, in agreement with theoretical predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01656v3</guid>
      <category>cs.LG</category>
      <category>cond-mat.dis-nn</category>
      <category>physics.data-an</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carlo Orientale Caputo, Elias Seiffert, Matteo Marsili</dc:creator>
    </item>
    <item>
      <title>Performance Modeling for Correlation-based Neural Decoding of Auditory Attention to Speech</title>
      <link>https://arxiv.org/abs/2503.09349</link>
      <description>arXiv:2503.09349v1 Announce Type: cross 
Abstract: Correlation-based auditory attention decoding (AAD) algorithms exploit neural tracking mechanisms to determine listener attention among competing speech sources via, e.g., electroencephalography signals. The correlation coefficients between the decoded neural responses and encoded speech stimuli of the different speakers then serve as AAD decision variables. A critical trade-off exists between the temporal resolution (the decision window length used to compute these correlations) and the AAD accuracy. This trade-off is typically characterized by evaluating AAD accuracy across multiple window lengths, leading to the performance curve. We propose a novel method to model this trade-off curve using labeled correlations from only a single decision window length. Our approach models the (un)attended correlations with a normal distribution after applying the Fisher transformation, enabling accurate AAD accuracy prediction across different window lengths. We validate the method on two distinct AAD implementations: a linear decoder and the non-linear VLAAI deep neural network, evaluated on separate datasets. Results show consistently low modeling errors of approximately 2 percent points, with 94% of true accuracies falling within estimated 95%-confidence intervals. The proposed method enables efficient performance curve modeling without extensive multi-window length evaluation, facilitating practical applications in, e.g., performance tracking in neuro-steered hearing devices to continuously adapt the system parameters over time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09349v1</guid>
      <category>eess.SP</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>q-bio.NC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Geirnaert, Jonas Vanthornhout, Tom Francart, Alexander Bertrand</dc:creator>
    </item>
    <item>
      <title>Quantifying wave propagation in a chain of FitzHugh-Nagumo neurons</title>
      <link>https://arxiv.org/abs/2409.16414</link>
      <description>arXiv:2409.16414v2 Announce Type: replace 
Abstract: Understanding how external stimuli propagate in neural systems is an important challenge in the fields of neuroscience and nonlinear dynamics. Despite extensive studies over several decades, this problem remains poorly understood. In this work, we examine a simple ``toy model'' of an excitable medium, a linear chain of diffusely coupled FitzHugh-Nagumo neurons, and analyze the transmission of a sinusoidal signal injected into one of the neurons at the ends of the chain. We measure to what extent the propagation of the wave reaching the opposite end is affected by the frequency and amplitude of the signal, the number of neurons in the chain and the strength of their mutual diffusive coupling. To quantify these effects, we measure the cross-correlation between the time-series of the membrane potentials of the end neurons. This measure allows us to detect the values of the parameters that delimit different propagation regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16414v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1063/5.0239976</arxiv:DOI>
      <arxiv:journal_reference>Chaos 35, 033110 (2025)</arxiv:journal_reference>
      <dc:creator>L. Messee Goulefack, C. Masoller, R. Yamapi, C. Anteneodo</dc:creator>
    </item>
    <item>
      <title>Modeling Dynamic Neural Activity by combining Naturalistic Video Stimuli and Stimulus-independent Latent Factors</title>
      <link>https://arxiv.org/abs/2410.16136</link>
      <description>arXiv:2410.16136v2 Announce Type: replace 
Abstract: Understanding how visual processing of natural stimuli and internal brain states interact in populations of neurons remains an open question in neuroscience. Currently there are no dynamic encoding models that explicitly model a latent state and the entire neuronal response distribution. We address this gap by proposing a probabilistic model that predicts the joint distribution of the neuronal responses from video stimuli and stimulus-independent latent factors. After training and testing our model on mouse V1 neuronal responses, we find that it outperforms video-only models in terms of log-likelihood and achieves improvements in likelihood and correlation when conditioned on responses from other neurons. Furthermore, we find that the learned latent factors strongly correlate with mouse behavior and that they exhibits patterns related to the neurons position on visual cortex, although the model was trained without behavior and cortical coordinates. Our findings demonstrate that unsupervised learning of latent factors from population responses can reveal biologically meaningful structure that bridges sensory processing and behavior, without requiring explicit behavioral annotations during training. Code will be available upon publication.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.16136v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Finn Schmidt, Polina Turishcheva, Suhas Shrinivasan, Fabian H. Sinz</dc:creator>
    </item>
    <item>
      <title>On Questions of Predictability and Control of an Intelligent System Using Probabilistic State-Transitions</title>
      <link>https://arxiv.org/abs/2503.06374</link>
      <description>arXiv:2503.06374v2 Announce Type: replace 
Abstract: One of the central aims of neuroscience is to reliably predict the behavioral response of an organism using its neural activity. If possible, this implies we can causally manipulate the neural response and design brain-computer-interface systems to alter behavior, and vice-versa. Hence, predictions play an important role in both fundamental neuroscience and its applications. Can we predict the neural and behavioral states of an organism at any given time? Can we predict behavioral states using neural states, and vice-versa, and is there a memory-component required to reliably predict such states? Are the predictions computable within a given timescale to meaningfully stimulate and make the system reach the desired states? Through a series of mathematical treatments, such conjectures and questions are discussed. Answering them might be key for future developments in understanding intelligence and designing brain-computer-interfaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.06374v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth R Taranath</dc:creator>
    </item>
    <item>
      <title>RAID-Database: human Responses to Affine Image Distortions</title>
      <link>https://arxiv.org/abs/2412.10211</link>
      <description>arXiv:2412.10211v2 Announce Type: replace-cross 
Abstract: Image quality databases are used to train models for predicting subjective human perception. However, most existing databases focus on distortions commonly found in digital media and not in natural conditions. Affine transformations are particularly relevant to study, as they are among the most commonly encountered by human observers in everyday life. This Data Descriptor presents a set of human responses to suprathreshold affine image transforms (rotation, translation, scaling) and Gaussian noise as convenient reference to compare with previously existing image quality databases. The responses were measured using well established psychophysics: the Maximum Likelihood Difference Scaling method. The set contains responses to 864 distorted images. The experiments involved 105 observers and more than 20000 comparisons of quadruples of images. The quality of the dataset is ensured because (a) it reproduces the classical Pi\'eron's law, (b) it reproduces classical absolute detection thresholds, and (c) it is consistent with conventional image quality databases but improves them according to Group-MAD experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10211v2</guid>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 13 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Paula Daud\'en-Oliver, David Agost-Beltran, Emilio Sansano-Sansano, Valero Laparra, Jes\'us Malo, Marina Mart\'inez-Garcia</dc:creator>
    </item>
  </channel>
</rss>
