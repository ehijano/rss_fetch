<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Jun 2024 04:00:18 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 28 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Binding in hippocampal-entorhinal circuits enables compositionality in cognitive maps</title>
      <link>https://arxiv.org/abs/2406.18808</link>
      <description>arXiv:2406.18808v1 Announce Type: new 
Abstract: We propose a normative model for spatial representation in the hippocampal formation that combines optimality principles, such as maximizing coding range and spatial information per neuron, with an algebraic framework for computing in distributed representation. Spatial position is encoded in a residue number system, with individual residues represented by high-dimensional, complex-valued vectors. These are composed into a single vector representing position by a similarity-preserving, conjunctive vector-binding operation. Self-consistency between the representations of the overall position and of the individual residues is enforced by a modular attractor network whose modules correspond to the grid cell modules in entorhinal cortex. The vector binding operation can also associate different contexts to spatial representations, yielding a model for entorhinal cortex and hippocampus. We show that the model achieves normative desiderata including superlinear scaling of patterns with dimension, robust error correction, and hexagonal, carry-free encoding of spatial position. These properties in turn enable robust path integration and association with sensory inputs. More generally, the model formalizes how compositional computations could occur in the hippocampal formation and leads to testable experimental predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.18808v1</guid>
      <category>q-bio.NC</category>
      <category>cs.NE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Christopher J. Kymn, Sonia Mazelet, Anthony Thomas, Denis Kleyko, E. Paxon Frady, Friedrich T. Sommer, Bruno A. Olshausen</dc:creator>
    </item>
    <item>
      <title>Multiscale Functional Connectivity: Exploring the brain functional connectivity at different timescales</title>
      <link>https://arxiv.org/abs/2406.19041</link>
      <description>arXiv:2406.19041v1 Announce Type: new 
Abstract: Human brains exhibit highly organized multiscale neurophysiological dynamics. Understanding those dynamic changes and the neuronal networks involved is critical for understanding how the brain functions in health and disease. Functional Magnetic Resonance Imaging (fMRI) is a prevalent neuroimaging technique for studying these complex interactions. However, analyzing fMRI data poses several challenges. Furthermore, most approaches for analyzing Functional Connectivity (FC) still rely on preprocessing or conventional methods, often built upon oversimplified assumptions. On top of that, those approaches often ignore frequency-related information despite evidence showing that fMRI data contain rich information that spans multiple timescales. This study introduces a novel methodology, Multiscale Functional Connectivity (MFC), to analyze fMRI data by decomposing the fMRI into their intrinsic modes, allowing us to separate the neurophysiological activation patterns at multiple timescales while separating them from other interfering components. Additionally, the proposed approach accounts for the natural nonlinear and nonstationary nature of fMRI and the particularities of each individual in a data-driven way. We evaluated the performance of our proposed methodology using three fMRI experiments. Our results demonstrate that our novel approach effectively separates the fMRI data into different timescales while identifying highly reliable functional connectivity patterns across individuals. In addition, we further extended our knowledge of how the FC for these three experiments spans among different timescales.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19041v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Manuel Morante, Kristian Fr{\o}lich, Naveed ur Rehman</dc:creator>
    </item>
    <item>
      <title>Evolving reservoir computers reveals bidirectional coupling between predictive power and emergent dynamics</title>
      <link>https://arxiv.org/abs/2406.19201</link>
      <description>arXiv:2406.19201v1 Announce Type: new 
Abstract: Biological neural networks can perform complex computations to predict their environment, far above the limited predictive capabilities of individual neurons. While conventional approaches to understanding these computations often focus on isolating the contributions of single neurons, here we argue that a deeper understanding requires considering emergent dynamics - dynamics that make the whole system "more than the sum of its parts". Specifically, we examine the relationship between prediction performance and emergence by leveraging recent quantitative metrics of emergence, derived from Partial Information Decomposition, and by modelling the prediction of environmental dynamics in a bio-inspired computational framework known as reservoir computing. Notably, we reveal a bidirectional coupling between prediction performance and emergence, which generalises across task environments and reservoir network topologies, and is recapitulated by three key results: 1) Optimising hyperparameters for performance enhances emergent dynamics, and vice versa; 2) Emergent dynamics represent a near sufficient criterion for prediction success in all task environments, and an almost necessary criterion in most environments; 3) Training reservoir computers on larger datasets results in stronger emergent dynamics, which contain task-relevant information crucial for performance. Overall, our study points to a pivotal role of emergence in facilitating environmental predictions in a bio-inspired computational architecture.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19201v1</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanna M. Tolle, Andrea I Luppi, Anil K. Seth, Pedro A. M. Mediano</dc:creator>
    </item>
    <item>
      <title>Networks with many structural scales: a Renormalization Group perspective</title>
      <link>https://arxiv.org/abs/2406.19104</link>
      <description>arXiv:2406.19104v1 Announce Type: cross 
Abstract: Scale invariance profoundly influences the dynamics and structure of complex systems, spanning from critical phenomena to network architecture. Here, we propose a precise definition of scale-invariant networks by leveraging the concept of a constant entropy loss rate across scales in a renormalization-group coarse-graining setting. This framework enables us to differentiate between scale-free and scale-invariant networks, revealing distinct characteristics within each class. Furthermore, we offer a comprehensive inventory of genuinely scale-invariant networks, both natural and artificially constructed, demonstrating, e.g., that the human connectome exhibits notable features of scale invariance. Our findings open new avenues for exploring the scale-invariant structural properties crucial in biological and socio-technological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19104v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cond-mat.dis-nn</category>
      <category>nlin.AO</category>
      <category>q-bio.NC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anna Poggialini, Pablo Villegas, Miguel A. Mu\~noz, Andrea Gabrielli</dc:creator>
    </item>
    <item>
      <title>Quantifying stimulus-relevant representational drift using cross-modality contrastive learning</title>
      <link>https://arxiv.org/abs/2305.11953</link>
      <description>arXiv:2305.11953v2 Announce Type: replace 
Abstract: Previous works investigating representational drift from sensory to central nervous systems converged to show that neural coding, especially at the population level, readily overcomes these session-to-session fluctuations. However, representational drift in the primary visual cortex is more prominent when presenting naturalistic stimuli than artificial stimuli. Animals continuously navigate natural environments during the evolutionary timescale. Why did evolution not get rid of representational drift if it was just an inconvenience? Here, we investigate how representational drift simultaneously influences the encoding of multiple behaviorally relevant features in a natural movie stimulus. Because natural environments contain multiple interacting spatio-temporal features, previous works only provided incomplete understanding of representational drift because of such simplification. Here, we use cross modality contrastive learning to learn an embedding of neural activity that retains only those relevant components of the natural movie stimulus. We also observe that our learned embedding is near-optimal in decoding a whole suite of natural features (scene, optic flow, complex spatio-temporal features, and time) and generalizable to decode those features from single-trial or novel hold-out data. Using this embedding as a surrogate model, we observe that representational drift perturbs the local geometry of the embedding, and this results in various changes in performance when we decode from a different session (90 min later) even at the population level. Our work further suggests that a separate compensation mechanism may be necessary for the optic flow features, as their autocorrelation scale is shorter than the minimum time needed to discriminate scene texture features. Thus, representational drift may encourage neural processing flexibility rather than be a mere nuisance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.11953v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siwei Wang, Elizabeth A de Laittre, Jason MacLean, Stephanie E Palmer</dc:creator>
    </item>
    <item>
      <title>Gromov-Wasserstein unsupervised alignment reveals structural correspondences between the color similarity structures of humans and large language models</title>
      <link>https://arxiv.org/abs/2308.04381</link>
      <description>arXiv:2308.04381v2 Announce Type: replace 
Abstract: Large Language Models (LLMs), such as the General Pre-trained Transformer (GPT), have shown remarkable performance in various cognitive tasks. However, it remains unclear whether these models have the ability to accurately infer human perceptual representations. Previous research has addressed this question by quantifying correlations between similarity response patterns of humans and LLMs. Correlation provides a measure of similarity, but it relies pre-defined item labels and does not distinguish category- and item- level similarity, falling short of characterizing detailed structural correspondence between humans and LLMs. To assess their structural equivalence in more detail, we propose the use of an unsupervised alignment method based on Gromov-Wasserstein optimal transport (GWOT). GWOT allows for the comparison of similarity structures without relying on pre-defined label correspondences and can reveal fine-grained structural similarities and differences that may not be detected by simple correlation analysis. Using a large dataset of similarity judgments of 93 colors, we compared the color similarity structures of humans (color-neurotypical and color-atypical participants) and two GPT models (GPT-3.5 and GPT-4). Our results show that the similarity structure of color-neurotypical participants can be remarkably well aligned with that of GPT-4 and, to a lesser extent, to that of GPT-3.5.These results contribute to the methodological advancements of comparing LLMs with human perception, and highlight the potential of unsupervised alignment methods to reveal detailed structural correspondences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.04381v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Genji Kawakita, Ariel Zeleznikow-Johnston, Naotsugu Tsuchiya, Masafumi Oizumi</dc:creator>
    </item>
    <item>
      <title>Brain Morphology Normative modelling platform for abnormality and Centile estimation: Brain MoNoCle</title>
      <link>https://arxiv.org/abs/2406.01107</link>
      <description>arXiv:2406.01107v2 Announce Type: replace 
Abstract: Normative models of brain structure estimate the effects of covariates such as age and sex using large samples of healthy controls. These models can then be applied to smaller clinical cohorts to distinguish disease effects from other covariates. However, these advanced statistical modelling approaches can be difficult to access, and processing large healthy cohorts is computationally demanding. Thus, accessible platforms with pre-trained normative models are needed.
  We present such a platform for brain morphology analysis as an open-source web application https://cnnplab.shinyapps.io/normativemodelshiny/, with six key features: (i) user-friendly web interface, (ii) individual and group outputs, (iii) multi-site analysis, (iv) regional and whole-brain analysis, (v) integration with existing tools, and (vi) featuring multiple morphology metrics.
  Using a diverse sample of 3,276 healthy controls across 21 sites, we pre-trained normative models on various metrics. We validated the models with a small clinical sample of individuals with bipolar disorder, showing outputs that aligned closely with existing literature only after applying our normative modelling. Further validation with a cohort of temporal lobe epilepsy showed agreement with previous group-level findings and individual-level seizure lateralisation. Finally, with the ability to investigate multiple morphology measures in the same framework, we found that biological covariates are better explained in specific morphology measures, and for clinical applications, only some measures are sensitive to the disease process.
  Our platform offers a comprehensive framework to analyse brain morphology in clinical and research settings. Validations confirm the superiority of normative models and the advantage of investigating a range of brain morphology metrics together.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01107v2</guid>
      <category>q-bio.NC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bethany Little, Nida Alyas, Alexander Surtees, Gavin P Winston, John S Duncan, David A Cousins, John-Paul Taylor, Peter Taylor, Karoline Leiberg, Yujiang Wang</dc:creator>
    </item>
  </channel>
</rss>
