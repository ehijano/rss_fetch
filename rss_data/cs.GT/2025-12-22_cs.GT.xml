<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Dec 2025 05:00:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fairly Dividing Non-identical Random Items: Just Sample or Match</title>
      <link>https://arxiv.org/abs/2512.17238</link>
      <description>arXiv:2512.17238v1 Announce Type: new 
Abstract: We study the question of existence and fast computation of fair and efficient allocations of indivisible resources among agents with additive valuations. As such allocations may not exist for arbitrary instances, we ask if they exist for \textit{typical} or \textit{random} instances, meaning when the utility values of agents for the resources are drawn from certain distributions. If such allocations exist with high probability for typical instances, and furthermore if they can be computed efficiently, this would imply that we could quickly resolve a real world resource allocation scenario in a fair and efficient manner with high probability. This implication has made this setting popular and well studied in fair resource allocation.
  In this paper, we extend the previously studied formal models of this problem to non-identical items. We assume that every item is associated with a distribution $\mathcal{U}_j$, and every agent's utility value for the item is drawn independently from $\mathcal{U}_j$. We show that envy-free fair and maximum social welfare efficient allocations exist with high probability in the asymptotic setting, meaning when the number of agents $n$ and items $m$ are large. Further we show that when $m=O(n\log n),$ then by only sampling $O(\log m)$ or $O((\log m)^2)$ utility values per item instead of all the $n,$ we can compute these allocations in $\tilde{O}(m)$ time. Finally, we simulate our algorithms on randomly generated instances and show that even for small instances, we suffer small multiplicative losses in the fairness and efficiency guarantees even for small sized instances, and converge to fully optimal guarantees quickly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17238v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aprup Kale, Rucha Kulkarni, Navya Garg</dc:creator>
    </item>
    <item>
      <title>Analytical Stackelberg Resource Allocation in Sequential Attacker--Defender Games</title>
      <link>https://arxiv.org/abs/2512.17284</link>
      <description>arXiv:2512.17284v1 Announce Type: new 
Abstract: We develop an analytical Stackelberg game framework for optimal resource allocation in a sequential attacker--defender setting with a finite set of assets and probabilistic attacks. The defender commits to a mixed protection strategy, after which the attacker best-responds via backward induction. Closed-form expressions for equilibrium protection and attack strategies are derived for general numbers of assets and defensive resources. Necessary constraints on rewards and costs are established to ensure feasibility of the probability distributions. Three distinct payoff regimes for the defender are identified and analysed. An eight-asset numerical example illustrates the equilibrium structure and reveals a unique Pareto-dominant attack configuration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17284v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Azhar Iqbal, James M. Chappell, Derek Abbott</dc:creator>
    </item>
    <item>
      <title>Deterministic implementation in single-item auctions</title>
      <link>https://arxiv.org/abs/2512.17386</link>
      <description>arXiv:2512.17386v1 Announce Type: new 
Abstract: Deterministic auctions are attractive in practice due to their transparency, simplicity, and ease of implementation, motivating a sharp understanding of when they match randomized designs. We study deterministic implementation in single-item auctions under two outcome notions: (revenue, welfare) pairs and interim allocations. For (revenue, welfare) pairs, we show a discrete separation: there exists a pair implementable by a deterministic Bayesian incentive-compatible (BIC) auction but not by any deterministic dominant-strategy incentive-compatible (DSIC) auction. For continuous atomless priors, we identify conditions under which deterministic DSIC auctions are implementationally equivalent to randomized BIC auctions in terms of achievable outcomes. For interim allocations, we establish a deterministic analogue of Border's theorem for two bidders, providing a necessary and sufficient condition for deterministic DSIC implementability, and use it to exhibit an interim allocation implementable by a deterministic BIC auction but not by any deterministic DSIC auction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17386v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Liu, Zeyu Ren, Pingzhong Tang, Zihe Wang, Yulong Zeng, Jie Zhang</dc:creator>
    </item>
    <item>
      <title>Comparing the Fairness of Recursively Balanced Picking Sequences</title>
      <link>https://arxiv.org/abs/2512.17604</link>
      <description>arXiv:2512.17604v1 Announce Type: new 
Abstract: Picking sequences are well-established methods for allocating indivisible goods. Among the various picking sequences, recursively balanced picking sequences -- whereby each agent picks one good in every round -- are notable for guaranteeing allocations that satisfy envy-freeness up to one good. In this paper, we compare the fairness of different recursively balanced picking sequences using two key measures. Firstly, we demonstrate that all such sequences have the same price in terms of egalitarian welfare relative to other picking sequences. Secondly, we characterize the approximate maximin share (MMS) guarantees of these sequences. In particular, we show that compensating the agent who picks last in the first round by letting her pick first in every subsequent round yields the best MMS guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17604v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karen Frilya Celine, Warut Suksompong, Sheung Man Yuen</dc:creator>
    </item>
    <item>
      <title>MAPPO-LCR: Multi-Agent Policy Optimization with Local Cooperation Reward in Spatial Public Goods Games</title>
      <link>https://arxiv.org/abs/2512.17187</link>
      <description>arXiv:2512.17187v1 Announce Type: cross 
Abstract: Spatial public goods games model collective dilemmas where individual payoffs depend on population-level strategy configurations. Most existing studies rely on evolutionary update rules or value-based reinforcement learning methods. These approaches struggle to represent payoff coupling and non-stationarity in large interacting populations. This work introduces Multi-Agent Proximal Policy Optimization (MAPPO) into spatial public goods games for the first time. In these games, individual returns are intrinsically coupled through overlapping group interactions. Proximal Policy Optimization (PPO) treats agents as independent learners and ignores this coupling during value estimation. MAPPO addresses this limitation through a centralized critic that evaluates joint strategy configurations. To study neighborhood-level cooperation signals under this framework, we propose MAPPO with Local Cooperation Reward, termed MAPPO-LCR. The local cooperation reward aligns policy updates with surrounding cooperative density without altering the original game structure. MAPPO-LCR preserves decentralized execution while enabling population-level value estimation during training. Extensive simulations demonstrate stable cooperation emergence and reliable convergence across enhancement factors. Statistical analyses further confirm the learning advantage of MAPPO over PPO in spatial public goods games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.17187v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoqilin Yang, Axin Xiang, Kedi Yang, Tianjun Liu, Youliang Tian</dc:creator>
    </item>
    <item>
      <title>Raising Bidders' Awareness in Second-Price Auctions</title>
      <link>https://arxiv.org/abs/2412.12676</link>
      <description>arXiv:2412.12676v2 Announce Type: replace-cross 
Abstract: When bidders bid on complex objects, they might be unaware of characteristics effecting their valuations. We assume that each buyer's valuation is a sum of independent random variables, one for each characteristic. When a bidder is unaware of a characteristic, he omits the random variable from the sum. We study the seller's decision to raise bidders' awareness of characteristics before a second-price auction with entry fees. Optimal entry fees capture an additional unawareness rent due to unaware bidders misperceiving their probability of winning and the price to be paid upon winning. When raising a bidder's individual awareness of a characteristic with positive expected value, the seller faces a trade-off between positive effects on the expected first order statistic and unawareness rents of remaining unaware bidders on one hand and the loss of the unawareness rent from the newly aware bidder on the other. We present characterization results on raising public awareness together with no versus full information. We discuss the winner's curse due to unawareness of characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.12676v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ying Xue Li, Burkhard C. Schipper</dc:creator>
    </item>
    <item>
      <title>Language Self-Play For Data-Free Training</title>
      <link>https://arxiv.org/abs/2509.07414</link>
      <description>arXiv:2509.07414v3 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have advanced rapidly in recent years, driven by scale, abundant high-quality training data, and reinforcement learning. Yet this progress faces a fundamental bottleneck: the need for ever more data from which models can continue to learn. In this work, we propose a reinforcement learning approach that removes this dependency by enabling models to improve without additional data. Our method leverages a game-theoretic framework of self-play, where a model's capabilities are cast as performance in a competitive game and stronger policies emerge by having the model play against itself-a process we call Language Self-Play (LSP). Experiments with Llama-3.2-3B-Instruct on instruction-following, mathematics, and coding benchmarks show that pretrained models can be effectively improved with self-play alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07414v3</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jakub Grudzien Kuba, Mengting Gu, Qi Ma, Yuandong Tian, Vijai Mohan, Jason Chen</dc:creator>
    </item>
    <item>
      <title>Look-Ahead Reasoning on Learning Platforms</title>
      <link>https://arxiv.org/abs/2511.14745</link>
      <description>arXiv:2511.14745v2 Announce Type: replace-cross 
Abstract: On many learning platforms, the optimization criteria guiding model training reflect the priorities of the designer rather than those of the individuals they affect. Consequently, users may act strategically to obtain more favorable outcomes. While past work has studied strategic user behavior on learning platforms, the focus has largely been on strategic responses to a deployed model, without considering the behavior of other users. In contrast, look-ahead reasoning takes into account that user actions are coupled, and -- at scale -- impact future predictions. Within this framework, we first formalize level-k thinking, a concept from behavioral economics, where users aim to outsmart their peers by looking one step ahead. We show that, while convergence to an equilibrium is accelerated, the equilibrium remains the same, providing no benefit of higher-level reasoning for individuals in the long run. Then, we focus on collective reasoning, where users take coordinated actions by optimizing through their joint impact on the model. By contrasting collective with selfish behavior, we characterize the benefits and limits of coordination; a new notion of alignment between the learner's and the users' utilities emerges as a key concept. Look-ahead reasoning can be seen as a generalization of algorithmic collective action; we thus offer the first results characterizing the utility trade-offs of coordination when contesting algorithmic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.14745v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Mon, 22 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Haiqing Zhu, Tijana Zrnic, Celestine Mendler-D\"unner</dc:creator>
    </item>
  </channel>
</rss>
