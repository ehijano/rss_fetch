<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Sep 2024 01:58:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On the Effectiveness of Neural Operators at Zero-Shot Weather Downscaling</title>
      <link>https://arxiv.org/abs/2409.13955</link>
      <description>arXiv:2409.13955v1 Announce Type: new 
Abstract: Machine learning (ML) methods have shown great potential for weather downscaling. These data-driven approaches provide a more efficient alternative for producing high-resolution weather datasets and forecasts compared to physics-based numerical simulations. Neural operators, which learn solution operators for a family of partial differential equations (PDEs), have shown great success in scientific ML applications involving physics-driven datasets. Neural operators are grid-resolution-invariant and are often evaluated on higher grid resolutions than they are trained on, i.e., zero-shot super-resolution. Given their promising zero-shot super-resolution performance on dynamical systems emulation, we present a critical investigation of their zero-shot weather downscaling capabilities, which is when models are tasked with producing high-resolution outputs using higher upsampling factors than are seen during training. To this end, we create two realistic downscaling experiments with challenging upsampling factors (e.g., 8x and 15x) across data from different simulations: the European Centre for Medium-Range Weather Forecasts Reanalysis version 5 (ERA5) and the Wind Integration National Dataset Toolkit (WTK). While neural operator-based downscaling models perform better than interpolation and a simple convolutional baseline, we show the surprising performance of an approach that combines a powerful transformer-based model with parameter-free interpolation at zero-shot weather downscaling. We find that this Swin-Transformer-based approach mostly outperforms models with neural operator layers, and suggest its use in future work as a strong baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13955v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Saumya Sinha, Brandon Benton, Patrick Emami</dc:creator>
    </item>
    <item>
      <title>A Large Language Model and Denoising Diffusion Framework for Targeted Design of Microstructures with Commands in Natural Language</title>
      <link>https://arxiv.org/abs/2409.14473</link>
      <description>arXiv:2409.14473v1 Announce Type: new 
Abstract: Microstructure plays a critical role in determining the macroscopic properties of materials, with applications spanning alloy design, MEMS devices, and tissue engineering, among many others. Computational frameworks have been developed to capture the complex relationship between microstructure and material behavior. However, despite these advancements, the steep learning curve associated with domain-specific knowledge and complex algorithms restricts the broader application of these tools. To lower this barrier, we propose a framework that integrates Natural Language Processing (NLP), Large Language Models (LLMs), and Denoising Diffusion Probabilistic Models (DDPMs) to enable microstructure design using intuitive natural language commands. Our framework employs contextual data augmentation, driven by a pretrained LLM, to generate and expand a diverse dataset of microstructure descriptors. A retrained NER model extracts relevant microstructure descriptors from user-provided natural language inputs, which are then used by the DDPM to generate microstructures with targeted mechanical properties and topological features. The NLP and DDPM components of the framework are modular, allowing for separate training and validation, which ensures flexibility in adapting the framework to different datasets and use cases. A surrogate model system is employed to rank and filter generated samples based on their alignment with target properties. Demonstrated on a database of nonlinear hyperelastic microstructures, this framework serves as a prototype for accessible inverse design of microstructures, starting from intuitive natural language commands.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14473v1</guid>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nikita Kartashov, Nikolaos N. Vlassis</dc:creator>
    </item>
    <item>
      <title>A Novel Multivariate Bi-LSTM model for Short-Term Equity Price Forecasting</title>
      <link>https://arxiv.org/abs/2409.14693</link>
      <description>arXiv:2409.14693v1 Announce Type: new 
Abstract: Prediction models are crucial in the stock market as they aid in forecasting future prices and trends, enabling investors to make informed decisions and manage risks more effectively. In the Indian stock market, where volatility is often high, accurate predictions can provide a significant edge in capitalizing on market movements. While various models like regression and Artificial Neural Networks (ANNs) have been explored for this purpose, studies have shown that Long Short-Term Memory networks (LSTMs) are the most effective. This is because they can capture complex temporal dependencies present in financial data. This paper presents a Bidirectional Multivariate LSTM model designed to predict short-term stock prices of Indian companies in the NIFTY 100 across four major sectors. Both Univariate LSTM and Univariate Bidirectional LSTM models were evaluated based on R2 score, RMSE, MSE, MAE, and MAPE. To improve predictive accuracy, the analysis was extended to multivariate data. Additionally, 12 technical indicators, having high correlation values with the close price(greater than 0.99) including EMA5, SMA5, TRIMA5, KAMA10 and the Bollinger Bands were selected as variables to further optimize the prediction models. The proposed Bidirectional Multivariate LSTM model, when applied to a dataset containing these indicators, achieved an exceptionally high average R2 score of 99.4779% across the four stocks, which is 3.9833% higher than that of the Unidirectional Multivariate LSTM without technical indicators. The proposed model has an average RMSE of 0.0103955, an average MAE of 0.007485 and an average MAPE of 1.1635%. This highlights the model's exceptional forecasting accuracy and emphasizes its potential to improve short-term trading strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14693v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Omkar Oak, Rukmini Nazre, Rujuta Budke, Yogita Mahatekar</dc:creator>
    </item>
    <item>
      <title>Integrating Optimal Transport and Structural Inference Models for GRN Inference from Single-cell Data</title>
      <link>https://arxiv.org/abs/2409.15080</link>
      <description>arXiv:2409.15080v1 Announce Type: new 
Abstract: We introduce a novel gene regulatory network (GRN) inference method that integrates optimal transport (OT) with a deep-learning structural inference model. Advances in next-generation sequencing enable detailed yet destructive gene expression assays at the single-cell level, resulting in the loss of cell evolutionary trajectories. Due to technological and cost constraints, single-cell experiments often feature cells sampled at irregular and sparse time points with a small sample size. Although trajectory-based structural inference models can accurately reveal the underlying interaction graph from observed data, their efficacy depends on the inputs of thousands of regularly sampled trajectories. The irregularly-sampled nature of single-cell data precludes the direct use of these powerful models for reconstructing GRNs. Optimal transport, a classical mathematical framework that minimize transportation costs between distributions, has shown promise in multi-omics data integration and cell fate prediction. Utilizing OT, our method constructs mappings between consecutively sampled cells to form cell-level trajectories, which are given as input to a structural inference model that recovers the GRN from single-cell data. Through case studies in two synthetic datasets, we demonstrate the feasibility of our proposed method and its promising performance over eight state-of-the-art GRN inference methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.15080v1</guid>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tsz Pan Tong, Aoran Wang, George Panagopoulos, Jun Pang</dc:creator>
    </item>
    <item>
      <title>Nonlinear Inverse Design of Mechanical Multi-Material Metamaterials Enabled by Video Denoising Diffusion and Structure Identifier</title>
      <link>https://arxiv.org/abs/2409.13908</link>
      <description>arXiv:2409.13908v1 Announce Type: cross 
Abstract: Metamaterials, synthetic materials with customized properties, have emerged as a promising field due to advancements in additive manufacturing. These materials derive unique mechanical properties from their internal lattice structures, which are often composed of multiple materials that repeat geometric patterns. While traditional inverse design approaches have shown potential, they struggle to map nonlinear material behavior to multiple possible structural configurations. This paper presents a novel framework leveraging video diffusion models, a type of generative artificial Intelligence (AI), for inverse multi-material design based on nonlinear stress-strain responses. Our approach consists of two key components: (1) a fields generator using a video diffusion model to create solution fields based on target nonlinear stress-strain responses, and (2) a structure identifier employing two UNet models to determine the corresponding multi-material 2D design. By incorporating multiple materials, plasticity, and large deformation, our innovative design method allows for enhanced control over the highly nonlinear mechanical behavior of metamaterials commonly seen in real-world applications. It offers a promising solution for generating next-generation metamaterials with finely tuned mechanical characteristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.13908v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jaewan Park, Shashank Kushwaha, Junyan He, Seid Koric, Qibang Liu, Iwona Jasiuk, Diab Abueidda</dc:creator>
    </item>
    <item>
      <title>Higher-order-ReLU-KANs (HRKANs) for solving physics-informed neural networks (PINNs) more accurately, robustly and faster</title>
      <link>https://arxiv.org/abs/2409.14248</link>
      <description>arXiv:2409.14248v1 Announce Type: cross 
Abstract: Finding solutions to partial differential equations (PDEs) is an important and essential component in many scientific and engineering discoveries. One of the common approaches empowered by deep learning is Physics-informed Neural Networks (PINNs). Recently, a new type of fundamental neural network model, Kolmogorov-Arnold Networks (KANs), has been proposed as a substitute of Multilayer Perceptions (MLPs), and possesses trainable activation functions. To enhance KANs in fitting accuracy, a modification of KANs, so called ReLU-KANs, using "square of ReLU" as the basis of its activation functions has been suggested. In this work, we propose another basis of activation functions, namely, Higher-order-ReLU, which is simpler than the basis of activation functions used in KANs, namely, B-splines; allows efficient KAN matrix operations; and possesses smooth and non-zero higher-order derivatives, essential for physics-informed neural networks. Our detailed experiments on two standard and typical PDEs, namely, the linear Poisson equation and nonlinear Burgers' equation with viscosity, reveal that our proposed Higher-order-ReLU-KANs (HRKANs) achieve the highest fitting accuracy and training robustness and lowest training time significantly among KANs, ReLUKANs and HRKANs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14248v1</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chi Chiu So, Siu Pang Yung</dc:creator>
    </item>
    <item>
      <title>Oscillating Magnetic Effect in BiFeO$_3$</title>
      <link>https://arxiv.org/abs/2409.14533</link>
      <description>arXiv:2409.14533v1 Announce Type: cross 
Abstract: The development of electric vehicles has led to a growing need for more efficient and environmentally friendly batteries. As a result, there is significant interest in researching new materials and techniques to enhance battery efficiency. One such material being explored is bismuth ferrite (BiFeO$_3$ or BFO), a perovskite with versatile properties. Researchers are particularly intrigued by the potential to control its antiferromagnetic magnetization using magnetic or electric fields. Here, a comprehensive analysis of BFO was conducted, with a focus on its behavior when subjected to oscillating magnetic fields. The research revealed that BFO is sensitive to the frequency and shape of these magnetic fields, leading to the discovery of a new effect related to the transmission of electromagnetic signals on its surface. This effect resulted in a significant increase in the power of the electromagnetic signal, representing a major technological breakthrough. According to the findings, this gain in power has not been observed in any system of this kind before. The study also demonstrated that BFO has the ability to detect magnetic fields through electrical output signals and vice versa, which is crucial for assessing the state and efficiency of batteries, thus contributing to significant advancements in energy storage technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14533v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>cond-mat.mes-hall</category>
      <category>cs.CE</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Ferro, Adrielson Dias, Maria Clara, Luana Hildever, Jos\'e Holanda</dc:creator>
    </item>
    <item>
      <title>Image memorability enhances social media virality</title>
      <link>https://arxiv.org/abs/2409.14659</link>
      <description>arXiv:2409.14659v1 Announce Type: cross 
Abstract: Certain social media contents can achieve widespread virality. Prior research has identified that emotion and morality may play a role in this phenomenon. Yet, due to the variability in subjective perception of these factors, they may not consistently predict virality. Recent work in vision and memory has identified a property intrinsic to images - memorability - that can automatically drive human memory. Here, we present evidence that memorability can enhance social media virality by analyzing a naturalistic dataset from Reddit, a widely used social media platform. Specifically, we discover that more memorable images (as judged automatically by neural network ResMem) cause more comments and higher upvotes, and this effect replicates across three different timepoints. To uncover the mechanism of this effect, we employ natural language processing techniques finding that memorable images tend to evoke abstract and less emotional comments. Leveraging an object recognition neural network, we discover that memorable images result in comments directed to information external to the image, which causes them to be more abstract. Further analysis quantifying the representations within the ResMem neural network reveals that images with more semantically distinct features are more likely to be memorable, and consequently, more likely to go viral. These findings reveal that images that are easier to remember become more viral, offering new future directions such as the creation of predictive models of content virality or the application of these insights to enhance the design of impactful visual content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14659v1</guid>
      <category>cs.HC</category>
      <category>cs.CE</category>
      <category>cs.SI</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shikang Peng (Department of Psychology, University of Toronto, Rotman Research Institute, Baycrest Health Sciences, Department of Psychology, University of Chicago), Wilma A. Bainbridge (Department of Psychology, University of Chicago, Neuroscience Institute, University of Chicago)</dc:creator>
    </item>
    <item>
      <title>A Bi-criterion Steiner Traveling Salesperson Problem with Time Windows for Last-Mile Electric Vehicle Logistics</title>
      <link>https://arxiv.org/abs/2409.14848</link>
      <description>arXiv:2409.14848v1 Announce Type: cross 
Abstract: This paper addresses the problem of energy-efficient and safe routing of last-mile electric freight vehicles. With the rising environmental footprint of the transportation sector and the growing popularity of E-Commerce, freight companies are likely to benefit from optimal time-window-feasible tours that minimize energy usage while reducing traffic conflicts at intersections and thereby improving safety. We formulate this problem as a Bi-criterion Steiner Traveling Salesperson Problem with Time Windows (BSTSPTW) with energy consumed and the number of left turns at intersections as the two objectives while also considering regenerative braking capabilities. We first discuss an exact mixed-integer programming model with scalarization to enumerate points on the efficiency frontier for small instances. For larger networks, we develop an efficient local search-based heuristic, which uses several operators to intensify and diversify the search process. We demonstrate the utility of the proposed methods using benchmark data and real-world instances from Amazon delivery routes in Austin, US. Comparisons with state-of-the-art solvers shows that our heuristics can generate near-optimal solutions within reasonable time budgets, effectively balancing energy efficiency and safety under practical delivery constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.14848v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.DM</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Prateek Agarwal, Debojjal Bagchi, Tarun Rambha, Venktesh Pandey</dc:creator>
    </item>
    <item>
      <title>A Dataset of Uniswap daily transaction indices by network</title>
      <link>https://arxiv.org/abs/2312.02660</link>
      <description>arXiv:2312.02660v2 Announce Type: replace-cross 
Abstract: Decentralized Finance (DeFi) is reshaping traditional finance by enabling direct transactions without intermediaries, creating a rich source of open financial data. Layer 2 (L2) solutions are emerging to enhance the scalability and efficiency of the DeFi ecosystem, surpassing Layer 1 (L1) systems. However, the impact of L2 solutions is still underexplored, mainly due to the lack of comprehensive transaction data indices for economic analysis. This study bridges that gap by analyzing over 50 million transactions from Uniswap, a major decentralized exchange, across both L1 and L2 networks. We created a set of daily indices from blockchain data on Ethereum, Optimism, Arbitrum, and Polygon, offering insights into DeFi adoption, scalability, decentralization, and wealth distribution. Additionally, we developed an open-source Python framework for calculating decentralization indices, making this dataset highly useful for advanced machine learning research. Our work provides valuable resources for data scientists and contributes to the growth of the intelligent Web3 ecosystem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.02660v2</guid>
      <category>econ.GN</category>
      <category>cs.CE</category>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nir Chemaya, Lin William Cong, Emma Jorgensen, Dingyue Liu, Luyao Zhang</dc:creator>
    </item>
    <item>
      <title>SocialEyes: Scaling mobile eye-tracking to multi-person social settings</title>
      <link>https://arxiv.org/abs/2407.06345</link>
      <description>arXiv:2407.06345v2 Announce Type: replace-cross 
Abstract: Eye movements provide a window into human behaviour, attention, and interaction dynamics. Challenges in real-world, multi-person environments have, however, restrained eye-tracking research predominantly to single-person, in-lab settings. We developed a system to stream, record, and analyse synchronised data from multiple mobile eye-tracking devices during collective viewing experiences (e.g., concerts, films, lectures). We implemented lightweight operator interfaces for real-time-monitoring, remote-troubleshooting, and gaze-projection from individual egocentric perspectives to a common coordinate space for shared gaze analysis. We tested the system in a live concert and a film screening with 30 simultaneous viewers during each of two public events (N=60). We observe precise time-synchronisation between devices measured through recorded clock-offsets, and accurate gaze-projection in challenging dynamic scenes. Our novel analysis metrics and visualizations illustrate the potential of collective eye-tracking data for understanding collaborative behaviour and social interaction. This advancement promotes ecological validity in eye-tracking research and paves the way for innovative interactive tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06345v2</guid>
      <category>cs.HC</category>
      <category>cs.CE</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shreshth Saxena, Areez Visram, Neil Lobo, Zahid Mirza, Mehak Rafi Khan, Biranugan Pirabaharan, Alexander Nguyen, Lauren K. Fink</dc:creator>
    </item>
    <item>
      <title>A Resolution Independent Neural Operator</title>
      <link>https://arxiv.org/abs/2407.13010</link>
      <description>arXiv:2407.13010v2 Announce Type: replace-cross 
Abstract: The Deep operator network (DeepONet) is a powerful yet simple neural operator architecture that utilizes two deep neural networks to learn mappings between infinite-dimensional function spaces. This architecture is highly flexible, allowing the evaluation of the solution field at any location within the desired domain. However, it imposes a strict constraint on the input space, requiring all input functions to be discretized at the same locations; this limits its practical applications. In this work, we introduce RINO, which provides a framework to make DeepONet resolution-independent, enabling it to handle input functions that are arbitrarily, but sufficiently finely, discretized. To this end, we propose two dictionary learning algorithms to adaptively learn a set of appropriate continuous basis functions, parameterized as implicit neural representations (INRs), from correlated signals defined on arbitrary point cloud data. These basis functions are then used to project arbitrary input function data as a point cloud onto an embedding space (i.e., a vector space of finite dimensions) with dimensionality equal to the dictionary size, which DeepONet can directly use without any architectural changes. In particular, we utilize sinusoidal representation networks (SIRENs) as trainable INR basis functions. The introduced dictionary learning algorithms can be used in a similar way to learn an appropriate dictionary of basis functions for the output function data. This approach can be seen as an extension of POD DeepONet for cases where the realizations of the output functions have different discretizations, making the Proper Orthogonal Decomposition (POD) approach inapplicable. We demonstrate the robustness and applicability of RINO in handling arbitrarily (but sufficiently richly) sampled input and output functions during both training and inference through several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13010v2</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahador Bahmani, Somdatta Goswami, Ioannis G. Kevrekidis, Michael D. Shields</dc:creator>
    </item>
  </channel>
</rss>
