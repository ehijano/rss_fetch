<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Sep 2025 04:00:23 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Cost-Performance Analysis: A Comparative Study of CPU-Based Serverless and GPU-Based Training Architectures</title>
      <link>https://arxiv.org/abs/2509.14920</link>
      <description>arXiv:2509.14920v1 Announce Type: new 
Abstract: The field of distributed machine learning (ML) faces increasing demands for scalable and cost-effective training solutions, particularly in the context of large, complex models. Serverless computing has emerged as a promising paradigm to address these challenges by offering dynamic scalability and resource-efficient execution. Building upon our previous work, which introduced the Serverless Peer Integrated for Robust Training (SPIRT) architecture, this paper presents a comparative analysis of several serverless distributed ML architectures. We examine SPIRT alongside established architectures like ScatterReduce, AllReduce, and MLLess, focusing on key metrics such as training time efficiency, cost-effectiveness, communication overhead, and fault tolerance capabilities. Our findings reveal that SPIRT provides significant improvements in reducing training times and communication overhead through strategies such as parallel batch processing and in-database operations facilitated by RedisAI. However, traditional architectures exhibit scalability challenges and varying degrees of vulnerability to faults and adversarial attacks. The cost analysis underscores the long-term economic benefits of SPIRT despite its higher initial setup costs. This study not only highlights the strengths and limitations of current serverless ML architectures but also sets the stage for future research aimed at developing new models that combine the most effective features of existing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14920v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The 26th International Conference on Parallel and Distributed Computing, Applications and Technologies 2025</arxiv:journal_reference>
      <dc:creator>Amine Barrak, Fabio Petrillo, Fehmi Jaafar</dc:creator>
    </item>
    <item>
      <title>Conditional Prior-based Non-stationary Channel Estimation Using Accelerated Diffusion Models</title>
      <link>https://arxiv.org/abs/2509.15182</link>
      <description>arXiv:2509.15182v1 Announce Type: new 
Abstract: Wireless channels in motion-rich urban microcell (UMi) settings are non-stationary; mobility and scatterer dynamics shift the distribution over time, degrading classical and deep estimators. This work proposes conditional prior diffusion for channel estimation, which learns a history-conditioned score to denoise noisy channel snapshots. A temporal encoder with cross-time attention compresses a short observation window into a context vector, which captures the channel's instantaneous coherence and steers the denoiser via feature-wise modulation. In inference, an SNR-matched initialization selects the diffusion step whose marginal aligns with the measured input SNR, and the process follows a shortened, geometrically spaced schedule, preserving the signal-to-noise trajectory with far fewer iterations. Temporal self-conditioning with the previous channel estimate and a training-only smoothness penalty further stabilizes evolution without biasing the test-time estimator. Evaluations on a 3GPP benchmark show lower NMSE across all SNRs than LMMSE, GMM, LSTM, and LDAMP baselines, demonstrating stable performance and strong high SNR fidelity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15182v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ahmed Mohsin, Ahsan Bilal, Muhammad Umer, Asad Aali, Muhammad Ali Jamshed, Dean F. Hougen, John M. Cioffi</dc:creator>
    </item>
    <item>
      <title>Channel Prediction under Network Distribution Shift Using Continual Learning-based Loss Regularization</title>
      <link>https://arxiv.org/abs/2509.15192</link>
      <description>arXiv:2509.15192v1 Announce Type: new 
Abstract: Modern wireless networks face critical challenges when mobile users traverse heterogeneous network configurations with varying antenna layouts, carrier frequencies, and scattering statistics. Traditional predictors degrade under distribution shift, with NMSE rising by 37.5\% during cross-configuration handovers. This work addresses catastrophic forgetting in channel prediction by proposing a continual learning framework based on loss regularization. The approach augments standard training objectives with penalty terms that selectively preserve network parameters essential for previous configurations while enabling adaptation to new environments. Two prominent regularization strategies are investigated: Elastic Weight Consolidation (EWC) and Synaptic Intelligence (SI). Across 3GPP scenarios and multiple architectures, SI lowers the high-SNR NMSE floor by up to 1.8 dB ($\approx$32--34\%), while EWC achieves up to 1.4 dB ($\approx$17--28\%). Notably, standard EWC incurs $\mathcal{O}(MK)$ complexity (storing $M$ Fisher diagonal entries and corresponding parameter snapshots across $K$ tasks) unless consolidated, whereas SI maintains $\mathcal{O}(M)$ memory complexity (storing $M$ model parameters), independent of task sequence length, making it suitable for resource-constrained wireless infrastructure</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.15192v1</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammad Ahmed Mohsin, Muhammad Umer, Ahsan Bilal, Muhammad Ibtsaam Qadir, Muhammad Ali Jamshed, Dean F. Hougen, John M. Cioffi</dc:creator>
    </item>
    <item>
      <title>Taming Serverless Cold Starts Through OS Co-Design</title>
      <link>https://arxiv.org/abs/2509.14292</link>
      <description>arXiv:2509.14292v1 Announce Type: cross 
Abstract: Serverless computing promises fine-grained elasticity and operational simplicity, fueling widespread interest from both industry and academia. Yet this promise is undercut by the cold setart problem, where invoking a function after a period of inactivity triggers costly initialization before any work can begin. Even with today's high-speed storage, the prevailing view is that achieving sub-millisecond cold starts requires keeping state resident in memory.
  This paper challenges that assumption. Our analysis of existing snapshot/restore mechanisms show that OS-level limitations, not storage speed, are the real barrier to ultra-fast restores from disk. These limitations force current systems to either restore state piecemeal in a costly manner or capture too much state, leading to longer restore times and unpredictable performance. Futhermore, current memory primitives exposed by the OS make it difficult to reliably fetch data into memory and avoid costly runtime page faults.
  To overcome these barriers, we present Spice, an execution engine purpose-built for serverless snapshot/restore. Spice integrates directly with the OS to restore kernel state without costly replay and introduces dedicated primitives for restoring memory mappings efficiently and reliably. As a result, Spice delivers near-warm performance on cold restores from disk, reducing latency by up to 14.9x over state-of-the-art process-based systems and 10.6x over VM-based systems. This proves that high performance and memory elasticity no longer need to be a trade-off in serverless computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14292v1</guid>
      <category>cs.OS</category>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ben Holmes, Baltasar Dinis, Lana Honcharuk, Joshua Fried, Adam Belay</dc:creator>
    </item>
    <item>
      <title>Scaling Hybrid Quantum-HPC Applications with the Quantum Framework</title>
      <link>https://arxiv.org/abs/2509.14470</link>
      <description>arXiv:2509.14470v1 Announce Type: cross 
Abstract: Hybrid quantum-high performance computing (Q-HPC) workflows are emerging as a key strategy for running quantum applications at scale in current noisy intermediate-scale quantum (NISQ) devices. These workflows must operate seamlessly across diverse simulators and hardware backends since no single simulator offers the best performance for every circuit type. Simulation efficiency depends strongly on circuit structure, entanglement, and depth, making a flexible and backend-agnostic execution model essential for fair benchmarking, informed platform selection, and ultimately the identification of quantum advantage opportunities. In this work, we extend the Quantum Framework (QFw), a modular and HPC-aware orchestration layer, to integrate multiple local backends (Qiskit Aer, NWQ-Sim, QTensor, and TN-QVM) and a cloud-based quantum backend (IonQ) under a unified interface. Using this integration, we execute a number of non-variational as well as variational workloads. The results highlight workload-specific backend advantages: while Qiskit Aer's matrix product state excels for large Ising models, NWQ-Sim not only leads on large-scale entanglement and Hamiltonian but also shows the benefits of concurrent subproblem execution in a distributed manner for optimization problems. These findings demonstrate that simulator-agnostic, HPC-aware orchestration is a practical path toward scalable, reproducible, and portable Q-HPC ecosystems, thereby accelerating progress toward demonstrating quantum advantage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14470v1</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srikar Chundury, Amir Shehata, Seongmin Kim, Muralikrishnan Gopalakrishnan Meena, Chao Lu, Kalyana Gottiparthi, Eduardo Antonio Coello Perez, Frank Mueller, In-Saeng Suh</dc:creator>
    </item>
    <item>
      <title>{\lambda}Scale: Enabling Fast Scaling for Serverless Large Language Model Inference</title>
      <link>https://arxiv.org/abs/2502.09922</link>
      <description>arXiv:2502.09922v2 Announce Type: replace 
Abstract: Serverless computing has emerged as a compelling solution for cloud-based model inference. However, as modern large language models (LLMs) continue to grow in size, existing serverless platforms often face substantial model startup overhead. This poses a significant challenge in efficiently scaling model instances to accommodate dynamic, bursty workloads commonly observed in real-world inference services. In this paper, we introduce {\lambda}Scale, an efficient serverless inference system to achieve fast model scaling. The key idea behind {\lambda}Scale is to leverage high-speed RDMA networks between GPU nodes for fast model multicast, while enabling distributed inference execution during model transmission -- referred to as "execute-while-load". {\lambda}Scale proposes an efficient model scaling scheme, {\lambda}Pipe, which supports adaptive model multicast and dynamically constructs execution pipelines across receiving nodes for collaborative, distributed inference. Additionally, {\lambda}Scale supports efficient model management across GPU and host memory, allowing fast scaling for models across different storage tiers. Evaluation results show that {\lambda}Scale enables fast model scaling and effectively handles load spikes, achieving up to 5x tail-latency improvement and 31.3% cost reduction compared to state-of-the-art solutions on real-world LLM inference traces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.09922v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minchen Yu, Rui Yang, Chaobo Jia, Zhaoyuan Su, Sheng Yao, Tingfeng Lan, Yuchen Yang, Yue Cheng, Wei Wang, Ao Wang, Ruichuan Chen</dc:creator>
    </item>
    <item>
      <title>SwarmSearch: Decentralized Search Engine with Self-Funding Economy</title>
      <link>https://arxiv.org/abs/2505.07452</link>
      <description>arXiv:2505.07452v2 Announce Type: replace 
Abstract: Centralized search engines control what we see, read, believe, and vote. Consequently, they raise concerns over information control, censorship, and bias. Decentralized search engines offer a remedy to this problem, but their adoption has been hindered by their inferior quality and lack of a self-sustaining economic framework. We present SwarmSearch, a fully decentralized, AI-powered search engine with a self-funding architecture. Our system is designed for deployment within the decentralized file-sharing software Tribler. SwarmSearch integrates volunteer-based with profit-driven mechanisms to foster an implicit marketplace for resources. Employing the state-of-the-art of AI-based retrieval and relevance ranking, we also aim to close the quality gap between decentralized search and centralized alternatives. Our system demonstrates high retrieval accuracy while showing robustness in the presence of 50% adversarial nodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.07452v2</guid>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LCN65610.2025.11146295</arxiv:DOI>
      <arxiv:journal_reference>M. Gregoriadis, R. M. Chotkan, P. Neague and J. Pouwelse, "SwarmSearch: Decentralized Search Engine with Self-Funding Economy," 2025 IEEE 50th Conference on Local Computer Networks (LCN), Sydney, Australia, 2025, pp. 1-10</arxiv:journal_reference>
      <dc:creator>Marcel Gregoriadis, Rowdy Chotkan, Petru Neague, Johan Pouwelse</dc:creator>
    </item>
    <item>
      <title>DSperse: A Framework for Targeted Verification in Zero-Knowledge Machine Learning</title>
      <link>https://arxiv.org/abs/2508.06972</link>
      <description>arXiv:2508.06972v3 Announce Type: replace-cross 
Abstract: DSperse is a modular framework for distributed machine learning inference with strategic cryptographic verification. Operating within the emerging paradigm of distributed zero-knowledge machine learning, DSperse avoids the high cost and rigidity of full-model circuitization by enabling targeted verification of strategically chosen subcomputations. These verifiable segments, or "slices", may cover part or all of the inference pipeline, with global consistency enforced through audit, replication, or economic incentives. This architecture supports a pragmatic form of trust minimization, localizing zero-knowledge proofs to the components where they provide the greatest value. We evaluate DSperse using multiple proving systems and report empirical results on memory usage, runtime, and circuit behavior under sliced and unsliced configurations. By allowing proof boundaries to align flexibly with the model's logical structure, DSperse supports scalable, targeted verification strategies suited to diverse deployment needs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.06972v3</guid>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dan Ivanov, Tristan Freiberg, Shirin Shahabi, Jonathan Gold, Haruna Isah</dc:creator>
    </item>
    <item>
      <title>Resource-Aware Aggregation and Sparsification in Heterogeneous Ensemble Federated Learning</title>
      <link>https://arxiv.org/abs/2508.08552</link>
      <description>arXiv:2508.08552v2 Announce Type: replace-cross 
Abstract: Federated learning (FL) enables distributed training with private client data, but its convergence is hindered by system heterogeneity under realistic communication scenarios. Most FL schemes addressing system heterogeneity utilize global pruning or ensemble distillation, yet often overlook typical constraints required for communication efficiency. Meanwhile, deep ensembles can aggregate predictions from individually trained models to improve performance, but current ensemble-based FL methods fall short in fully capturing diversity of model predictions. In this work, we propose \textbf{SHEFL}, a global ensemble-based FL framework suited for clients with diverse computational capacities. We allocate different numbers of global models to clients based on their available resources. We introduce a novel aggregation scheme that mitigates the training bias between clients and dynamically adjusts the sparsification ratio across clients to reduce the computational burden of training deep ensembles. Extensive experiments demonstrate that our method effectively addresses computational heterogeneity, significantly improving accuracy and stability compared to existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.08552v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Keumseo Ryum, Jinu Gong, Joonhyuk Kang</dc:creator>
    </item>
    <item>
      <title>A Closeness Centrality-based Circuit Partitioner for Quantum Simulations</title>
      <link>https://arxiv.org/abs/2509.14098</link>
      <description>arXiv:2509.14098v2 Announce Type: replace-cross 
Abstract: Simulating quantum circuits (QC) on high-performance computing (HPC) systems has become an essential method to benchmark algorithms and probe the potential of large-scale quantum computation despite the limitations of current quantum hardware. However, these simulations often require large amounts of resources, necessitating the use of large clusters with thousands of compute nodes and large memory footprints. In this work, we introduce an end-to-end framework that provides an efficient partitioning scheme for large-scale QCs alongside a flexible code generator to offer a portable solution that minimizes data movement between compute nodes. By formulating the distribution of quantum states and circuits as a graph problem, we apply closeness centrality to assess gate importance and design a fast, scalable partitioning method. The resulting partitions are compiled into highly optimized codes that run seamlessly on a wide range of supercomputers, providing critical insights into the performance and scalability of quantum algorithm simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14098v2</guid>
      <category>quant-ph</category>
      <category>cs.DC</category>
      <pubDate>Fri, 19 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Doru Thom Popovici, Harlin Lee, Mauro Del Ben, Naoki Yoshioka, Nobuyasu Ito, Katherine Klymko, Daan Camps, Anastasiia Butko</dc:creator>
    </item>
  </channel>
</rss>
