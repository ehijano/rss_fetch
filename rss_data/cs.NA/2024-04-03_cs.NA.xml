<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NA</link>
    <description>cs.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 03 Apr 2024 08:05:35 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 03 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convergence Acceleration of Favre-Averaged Non-Linear Harmonic Method</title>
      <link>https://arxiv.org/abs/2404.01407</link>
      <description>arXiv:2404.01407v1 Announce Type: new 
Abstract: This paper develops a numerical procedure to accelerate the convergence of the Favre-averaged Non-Linear Harmonic (FNLH) method. The scheme provides a unified mathematical framework for solving the sparse linear systems formed by the mean flow and the time-linearized harmonic flows of FNLH in an explicit or implicit fashion. The approach explores the similarity of the sparse linear systems of FNLH and leads to a memory efficient procedure, so that its memory consumption does not depend on the number of harmonics to compute. The proposed method has been implemented in the industrial CFD solver HYDRA. Two test cases are used to conduct a comparative study of explicit and implicit schemes in terms of convergence, computational efficiency, and memory consumption. Comparisons show that the implicit scheme yields better convergence than the explicit scheme and is also roughly 7 to 10 times more computationally efficient than the explicit scheme with 4 levels of multigrid. Furthermore, the implicit scheme consumes only approximately $50\%$ of the explicit scheme with four levels of multigrid. Compared with the full annulus unsteady Reynolds averaged Navier-Stokes (URANS) simulations, the implicit scheme produces comparable results to URANS with computational time and memory consumption that are two orders of magnitude smaller.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01407v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Feng Wang, Kurt Webber, David Radford, Luca di Mare, Marcus Meyer</dc:creator>
    </item>
    <item>
      <title>Estimates of discrete time derivatives for the parabolic-parabolic Robin-Robin coupling method</title>
      <link>https://arxiv.org/abs/2404.01594</link>
      <description>arXiv:2404.01594v1 Announce Type: new 
Abstract: We consider a loosely coupled, non-iterative Robin-Robin coupling method proposed and analyzed in [J. Numer. Math., 31(1):59--77, 2023] for a parabolic-parabolic interface problem and prove estimates for the discrete time derivatives of the scalar field in different norms. When the interface is flat and perpendicular to two of the edges of the domain we prove error estimates in the $H^2$-norm. Such estimates are key ingredients to analyze a defect correction method for the parabolic-parabolic interface problem. Numerical results are shown to support our findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01594v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Burman, Rebecca Durst, Miguel A. Fern\'andez, Johnny Guzm\'an, Sijing Liu</dc:creator>
    </item>
    <item>
      <title>A second-order correction method for loosely coupled discretizations applied to parabolic-parabolic interface problems</title>
      <link>https://arxiv.org/abs/2404.01599</link>
      <description>arXiv:2404.01599v1 Announce Type: new 
Abstract: We consider a parabolic-parabolic interface problem and construct a loosely coupled prediction-correction scheme based on the Robin-Robin splitting method analyzed in [J. Numer. Math., 31(1):59--77, 2023]. We show that the errors of the correction step converge at $\mathcal O((\Delta t)^2)$, under suitable convergence rate assumptions on the discrete time derivative of the prediction step, where $\Delta t$ stands for the time-step length. Numerical results are shown to support our analysis and the assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01599v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erik Burman, Rebecca Durst, Miguel A. Fern\'andez, Johnny Guzm\'an, Sijing Liu</dc:creator>
    </item>
    <item>
      <title>A simple collocation-type approach to numerical stochastic homogenization</title>
      <link>https://arxiv.org/abs/2404.01732</link>
      <description>arXiv:2404.01732v1 Announce Type: new 
Abstract: This paper proposes a novel collocation-type numerical stochastic homogenization method for prototypical stochastic homogenization problems with random coefficient fields of small correlation lengths. The presented method is based on a recently introduced localization technique that enforces a super-exponential decay of the basis functions relative to the underlying coarse mesh, resulting in considerable computational savings during the sampling phase. More generally, the collocation-type structure offers a particularly simple and computationally efficient construction in the stochastic setting with minimized communication between the patches where the basis functions of the method are computed. An error analysis that bridges numerical homogenization and the quantitative theory of stochastic homogenization is performed. In a series of numerical experiments, we study the effect of the correlation length and the discretization parameters on the approximation quality of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01732v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Moritz Hauck, Hannah Mohr, Daniel Peterseim</dc:creator>
    </item>
    <item>
      <title>A Posteriori Single- and Multi-Goal Error Control and Adaptivity for Partial Differential Equations</title>
      <link>https://arxiv.org/abs/2404.01738</link>
      <description>arXiv:2404.01738v1 Announce Type: new 
Abstract: This work reviews goal-oriented a posteriori error control, adaptivity and solver control for finite element approximations to boundary and initial-boundary value problems for stationary and non-stationary partial differential equations, respectively. In particular, coupled field problems with different physics may require simultaneously the accurate evaluation of several quantities of interest, which is achieved with multi-goal oriented error control. Sensitivity measures are obtained by solving an adjoint problem. Error localization is achieved with the help of a partition-of-unity. We also review and extend theoretical results for efficiency and reliability by employing a saturation assumption. The resulting adaptive algorithms allow to balance discretization and non-linear iteration errors, and are demonstrated for four applications: Poisson's problem, non-linear elliptic boundary value problems, stationary incompressible Navier-Stokes equations, and regularized parabolic $p$-Laplace initial-boundary value problems. Therein, different finite element discretizations in two different software libraries are utilized, which are partially accompanied with open-source implementations on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01738v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bernhard Endtmayer, Ulrich Langer, Thomas Richter, Andreas Schafelner, Thomas Wick</dc:creator>
    </item>
    <item>
      <title>Improving the accuracy and consistency of the energy quadratization method with an energy-optimized technique</title>
      <link>https://arxiv.org/abs/2404.01747</link>
      <description>arXiv:2404.01747v1 Announce Type: new 
Abstract: We propose an energy-optimized invariant energy quadratization method to solve the gradient flow models in this paper, which requires only one linear energy-optimized step to correct the auxiliary variables on each time step. In addition to inheriting the benefits of the baseline and relaxed invariant energy quadratization method, our approach has several other advantages. Firstly, in the process of correcting auxiliary variables, we can directly solve linear programming problem by the energy-optimized technique, which greatly simplifies the nonlinear optimization problem in the previous relaxed invariant energy quadratization method. Secondly, we construct new linear unconditionally energy stable schemes by applying backward Euler formulas and Crank-Nicolson formula, so that the accuracy in time can reach the first- and second-order. Thirdly, comparing with relaxation technique, the modified energy obtained by energy-optimized technique is closer to the original energy, meanwhile the accuracy and consistency of the numerical solutions can be improved. Ample numerical examples have been presented to demonstrate the accuracy, efficiency and energy stability of the proposed schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01747v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoqing Meng, Aijie Cheng, Zhengguang Liu</dc:creator>
    </item>
    <item>
      <title>Mathematical modeling and numerical multigoal-oriented a posteriori error control and adaptivity for a stationary, nonlinear, coupled flow temperature model with temperature dependent density</title>
      <link>https://arxiv.org/abs/2404.01823</link>
      <description>arXiv:2404.01823v1 Announce Type: new 
Abstract: In this work, we develop adaptive schemes using goal-oriented error control for a highly nonlinear flow temperature model with temperature dependent density. The dual-weighted residual method for computing error indicators to steer mesh refinement and solver control is employed. The error indicators are used to employ adaptive algorithms, which are substantiated with several numerical tests. Therein, error reductions and effectivity indices are consulted to establish the robustness and efficiency of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01823v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sven Beuchler, Ayhan Demircan, Bernhard Endtmayer, Uwe Morgner, Thomas Wick</dc:creator>
    </item>
    <item>
      <title>Adaptive Gradient Enhanced Gaussian Process Surrogates for Inverse Problems</title>
      <link>https://arxiv.org/abs/2404.01864</link>
      <description>arXiv:2404.01864v1 Announce Type: new 
Abstract: Generating simulated training data needed for constructing sufficiently accurate surrogate models to be used for efficient optimization or parameter identification can incur a huge computational effort in the offline phase. We consider a fully adaptive greedy approach to the computational design of experiments problem using gradient-enhanced Gaussian process regression as surrogates. Designs are incrementally defined by solving an optimization problem for accuracy given a certain computational budget. We address not only the choice of evaluation points but also of required simulation accuracy, both of values and gradients of the forward model. Numerical results show a significant reduction of the computational effort compared to just position-adaptive and static designs as well as a clear benefit of including gradient information into the surrogate training.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01864v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Phillip Semler, Martin Weiser</dc:creator>
    </item>
    <item>
      <title>Multidimensional deconvolution with shared bases</title>
      <link>https://arxiv.org/abs/2404.01870</link>
      <description>arXiv:2404.01870v1 Announce Type: new 
Abstract: We address the estimation of seismic wavefields by means of Multidimensional Deconvolution (MDD) for various redatuming applications. While offering more accuracy than conventional correlation-based redatuming methods, MDD faces challenges due to the ill-posed nature of the underlying inverse problem and the requirement to handle large, dense, complex-valued matrices. These obstacles have long limited the adoption of MDD in the geophysical community. Recent interest in this technology has spurred the development of new strategies to enhance the robustness of the inversion process and reduce its computational overhead. We present a novel approach that extends the concept of block low-rank approximations, usually applied to linear operators, to simultaneously compress the operator, right-hand side, and unknowns. This technique greatly alleviates the data-heavy nature of MDD. Moreover, since in 3d applications the matrices do not lend themselves to global low rank approximations, we introduce a novel H2-like approximation. We aim to streamline MDD implementations, fostering efficiency and controlling accuracy in wavefield reconstruction. This innovation holds potential for broader applications in the geophysical domain, possibly revolutionizing the analysis of multi-dimensional seismic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01870v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daria Sushnikova, Matteo Ravasi, David Keyes</dc:creator>
    </item>
    <item>
      <title>Comparison of Different Elastic Strain Definitions for Largely Deformed SEI of Chemo-Mechanically Coupled Silicon Battery Particles</title>
      <link>https://arxiv.org/abs/2404.01884</link>
      <description>arXiv:2404.01884v1 Announce Type: new 
Abstract: Amorphous silicon is a highly promising anode material for next-generation lithium-ion batteries. Large volume changes of the silicon particle have a critical effect on the surrounding solid-electrolyte interphase (SEI) due to repeated fracture and healing during cycling. Based on a thermodynamically consistent chemo-elasto-plastic continuum model we investigate the stress development inside the particle and the SEI. Using the example of a particle with SEI, we apply a higher order finite element method together with a variable-step, variable-order time integration scheme on a nonlinear system of partial differential equations. Starting from a single silicon particle setting, the surrounding SEI is added in a first step with the typically used elastic Green--St-Venant (GSV) strain definition for a purely elastic deformation. For this type of deformation, the definition of the elastic strain is crucial to get reasonable simulation results. In case of the elastic GSV strain, the simulation aborts. We overcome the simulation failure by using the definition of the logarithmic Hencky strain. However, the particle remains unaffected by the elastic strain definitions in the particle domain. Compared to GSV, plastic deformation with the Hencky strain is straightforward to take into account. For the plastic SEI deformation, a rate-independent and a rate-dependent plastic deformation are newly introduced and numerically compared for three half cycles for the example of a radial symmetric particle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01884v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Raphael Schoof, Giuseppe Fabian Castelli, Willy D\"orfler</dc:creator>
    </item>
    <item>
      <title>A Stabilized Parametric Finite Element Method for Surface Diffusion with an Arbitrary Surface Energy</title>
      <link>https://arxiv.org/abs/2404.02083</link>
      <description>arXiv:2404.02083v1 Announce Type: new 
Abstract: We proposed a structure-preserving stabilized parametric finite element method (SPFEM) for the evolution of closed curves under anisotropic surface diffusion with an arbitrary surface energy $\hat{\gamma}(\theta)$. By introducing a non-negative stabilizing function $k(\theta)$ depending on $\hat{\gamma}(\theta)$, we obtained a novel stabilized conservative weak formulation for the anisotropic surface diffusion. A SPFEM is presented for the discretization of this weak formulation. We construct a comprehensive framework to analyze and prove the unconditional energy stability of the SPFEM under a very mild condition on $\hat{\gamma}(\theta)$. This method can be applied to simulate solid-state dewetting of thin films with arbitrary surface energies, which are characterized by anisotropic surface diffusion and contact line migration. Extensive numerical results are reported to demonstrate the efficiency, accuracy and structure-preserving properties of the proposed SPFEM with anisotropic surface energies $\hat{\gamma}(\theta)$ arising from different applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02083v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yulin Zhang, Yifei Li, Wenjun Ying</dc:creator>
    </item>
    <item>
      <title>Numerical simulation of the Gross-Pitaevskii equation via vortex tracking</title>
      <link>https://arxiv.org/abs/2404.02133</link>
      <description>arXiv:2404.02133v1 Announce Type: new 
Abstract: This paper deals with the numerical simulation of the Gross-Pitaevskii (GP) equation, for which a well-known feature is the appearance of quantized vortices with core size of the order of a small parameter $\varepsilon$. Without a magnetic field and with suitable initial conditions, these vortices interact, in the singular limit $\varepsilon\to0$, through an explicit Hamiltonian dynamics. Using this analytical framework, we develop and analyze a numerical strategy based on the reduced-order Hamiltonian system to efficiently simulate the infinite-dimensional GP equation for small, but finite, $\varepsilon$. This method allows us to avoid numerical stability issues in solving the GP equation, where small values of $\varepsilon$ typically require very fine meshes and time steps. We also provide a mathematical justification of our method in terms of rigorous error estimates of the error in the supercurrent, together with numerical illustrations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02133v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thiago Carvalho Corso (IANS-NMH, Stuttgart University), Gaspard Kemlin (LAMFA, UPJV), Christof Melcher (AA, RWTH), Benjamin Stamm (IANS-NMH, Stuttgart University)</dc:creator>
    </item>
    <item>
      <title>Convergence of overlapping domain decomposition methods with PML transmission conditions applied to nontrapping Helmholtz problems</title>
      <link>https://arxiv.org/abs/2404.02156</link>
      <description>arXiv:2404.02156v1 Announce Type: new 
Abstract: We study overlapping Schwarz methods for the Helmholtz equation posed in any dimension with large, real wavenumber and smooth variable wave speed. The radiation condition is approximated by a Cartesian perfectly-matched layer (PML). The domain-decomposition subdomains are overlapping hyperrectangles with Cartesian PMLs at their boundaries. The overlaps of the subdomains and the widths of the PMLs are all taken to be independent of the wavenumber.
  For both parallel (i.e., additive) and sequential (i.e., multiplicative) methods, we show that after a specified number of iterations -- depending on the behaviour of the geometric-optic rays -- the error is smooth and smaller than any negative power of the wavenumber. For the parallel method, the specified number of iterations is less than the maximum number of subdomains, counted with their multiplicity, that a geometric-optic ray can intersect.
  These results, which are illustrated by numerical experiments, are the first wavenumber-explicit results about convergence of overlapping Schwarz methods for the Helmholtz equation, and the first wavenumber-explicit results about convergence of any domain-decomposition method for the Helmholtz equation with a non-trivial scatterer (here a variable wave speed).</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02156v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jeffrey Galkowski, Shihua Gong, Ivan G. Graham, David Lafontaine, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>When are Unbiased Monte Carlo Estimators More Preferable than Biased Ones?</title>
      <link>https://arxiv.org/abs/2404.01431</link>
      <description>arXiv:2404.01431v1 Announce Type: cross 
Abstract: Due to the potential benefits of parallelization, designing unbiased Monte Carlo estimators, primarily in the setting of randomized multilevel Monte Carlo, has recently become very popular in operations research and computational statistics. However, existing work primarily substantiates the benefits of unbiased estimators at an intuitive level or using empirical evaluations. The intuition being that unbiased estimators can be replicated in parallel enabling fast estimation in terms of wall-clock time. This intuition ignores that, typically, bias will be introduced due to impatience because most unbiased estimators necesitate random completion times. This paper provides a mathematical framework for comparing these methods under various metrics, such as completion time and overall computational cost. Under practical assumptions, our findings reveal that unbiased methods typically have superior completion times - the degree of superiority being quantifiable through the tail behavior of their running time distribution - but they may not automatically provide substantial savings in overall computational costs. We apply our findings to Markov Chain Monte Carlo and Multilevel Monte Carlo methods to identify the conditions and scenarios where unbiased methods have an advantage, thus assisting practitioners in making informed choices between unbiased and biased methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01431v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanyang Wang, Jose Blanchet, Peter W. Glynn</dc:creator>
    </item>
    <item>
      <title>A multicore parallel algorithm for multiscale modelling of an entire human blood circulation network</title>
      <link>https://arxiv.org/abs/2404.01680</link>
      <description>arXiv:2404.01680v1 Announce Type: cross 
Abstract: The presented multi-scale, closed-loop blood circulation model includes arterial, venous, and portal venous systems, heart-pulmonary circulation, and micro-circulation in capillaries. One-dimensional models simulate large blood vessel flow, whereas zerodimensional models are used for simulating blood flow in vascular subsystems corresponding to peripheral arteries and organs. Transmission conditions at bifurcation and confluence are solved using Riemann invariants. Blood circulation simulation in the portal venous system and related organs (liver, stomach, spleen, pancreas, intestine) is particularly targeted. Those organs play important roles in metabolic system dynamics. The proposed efficient parallel algorithms for multicore environments solve these equations much faster than serial computations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01680v1</guid>
      <category>physics.med-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiawei Liu, Hiroshi Suito</dc:creator>
    </item>
    <item>
      <title>Hyperviscosity stabilisation of the RBF-FD solution to natural convection</title>
      <link>https://arxiv.org/abs/2404.01919</link>
      <description>arXiv:2404.01919v1 Announce Type: cross 
Abstract: The numerical stability of fluid flow is an important topic in computational fluid dynamics as fluid flow simulations usually become numerically unstable in the turbulent regime. Many mesh-based methods have already established numerical dissipation procedures that dampen the effects of the unstable advection term. When it comes to meshless methods, the prominent stabilisation scheme is hyperviscosity. It introduces numerical dissipation in the form of a higher-order Laplacian operator. Many papers have already discussed the general effects of hyperviscosity and its parameters. However, hyperviscosity in flow problems has not yet been analyzed in depth. In this paper, we discuss the effects of hyperviscosity on natural convection flow problems as we approach the turbulent regime.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01919v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>physics.comp-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\v{Z}iga Vaupoti\v{c}, Miha Rot, Gregor Kosec</dc:creator>
    </item>
    <item>
      <title>Singularity formation of vortex sheets in 2D Euler equations using the characteristic mapping method</title>
      <link>https://arxiv.org/abs/2404.02008</link>
      <description>arXiv:2404.02008v1 Announce Type: cross 
Abstract: The goal of this numerical study is to get insight into singular solutions of the two-dimensional (2D) Euler equations for non-smooth initial data, in particular for vortex sheets. To this end high resolution computations of vortex layers in 2D incompressible Euler flows are performed using the characteristic mapping method (CMM). This semi-Lagrangian method evolves the flow map using the gradient-augmented level set method (GALS). The semi-group structure of the flow map allows its decomposition into sub-maps (each over a finite time interval), and thus the precision can be controlled by choosing appropriate remapping times. Composing the flow map yields exponential resolution in linear time, a unique feature of CMM, and thus fine scale flow structures can be resolved in great detail. Here the roll-up process of vortex layers is studied varying the thickness of the layer showing its impact on the growth of palinstrophy and possible blow up of absolute vorticity. The curvature of the vortex sheet shows a singular-like behavior. The self-similar structure of the vortex core is investigated in the vanishing thickness limit. Conclusions on the non-uniqueness of weak solutions of 2D Euler for non-smooth initial data are drawn and the presence of flow singularities is revealed tracking them in the complex plane.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.02008v1</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julius Bergmann (Bruce), Thibault Maurel-Oujia (Bruce),  Xi-Yuan (Bruce),  Yin, Jean-Christophe Nave, Kai Schneider</dc:creator>
    </item>
    <item>
      <title>Analysis and Numerical Approximation of Stationary Second-Order Mean Field Game Partial Differential Inclusions</title>
      <link>https://arxiv.org/abs/2209.00303</link>
      <description>arXiv:2209.00303v4 Announce Type: replace 
Abstract: The formulation of Mean Field Games (MFG) typically requires continuous differentiability of the Hamiltonian in order to determine the advective term in the Kolmogorov--Fokker--Planck equation for the density of players. However, in many cases of practical interest, the underlying optimal control problem may exhibit bang-bang controls, which typically lead to nondifferentiable Hamiltonians. We develop the analysis and numerical analysis of stationary MFG for the general case of convex, Lipschitz, but possibly nondifferentiable Hamiltonians. In particular, we propose a generalization of the MFG system as a Partial Differential Inclusion (PDI) based on interpreting the derivative of the Hamiltonian in terms of subdifferentials of convex functions. We establish existence of a weak solution to the MFG PDI system, and we further prove uniqueness under a similar monotonicity condition to the one considered by Lasry and Lions. We then propose a monotone finite element discretization of the problem, and we prove strong $H^1$-norm convergence of the approximations to the value function and strong $L^q$-norm convergence of the approximations of the density function. We illustrate the performance of the numerical method in numerical experiments featuring nonsmooth solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.00303v4</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1137/22M1519274</arxiv:DOI>
      <arxiv:journal_reference>SIAM Journal on Numerical Analysis, Vol. 62, No. 1, pp. 138-166, 2024</arxiv:journal_reference>
      <dc:creator>Yohance A. P. Osborne, Iain Smears</dc:creator>
    </item>
    <item>
      <title>Finite element approximation of time-dependent mean field games with nondifferentiable Hamiltonians</title>
      <link>https://arxiv.org/abs/2306.13174</link>
      <description>arXiv:2306.13174v3 Announce Type: replace 
Abstract: The standard formulation of the PDE system of Mean Field Games (MFG) requires the differentiability of the Hamiltonian. However in many cases, the structure of the underlying optimal problem leads to a convex but nondifferentiable Hamiltonian. For time-dependent MFG systems, we introduce a generalization of the problem as a Partial Differential Inclusion (PDI) by interpreting the derivative of the Hamiltonian in terms of the subdifferential set. In particular, we prove the existence and uniqueness of weak solutions to the resulting MFG PDI system under standard assumptions in the literature. We propose a monotone stabilized finite element discretization of the problem, using conforming affine elements in space and an implicit Euler discretization in time with mass-lumping. We prove the strong convergence in $L^2(H^1)$ of the value function approximations, and strong convergence in $L^p(L^2)$ of the density function approximations, together with strong $L^2$-convergence of the value function approximations at the initial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13174v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yohance A. P. Osborne, Iain Smears</dc:creator>
    </item>
    <item>
      <title>Fast parametric analysis of trimmed multi-patch isogeometric Kirchhoff-Love shells using a local reduced basis method</title>
      <link>https://arxiv.org/abs/2307.09113</link>
      <description>arXiv:2307.09113v2 Announce Type: replace 
Abstract: This contribution presents a model order reduction framework for real-time efficient solution of trimmed, multi-patch isogeometric Kirchhoff-Love shells. In several scenarios, such as design and shape optimization, multiple simulations need to be performed for a given set of physical or geometrical parameters. This step can be computationally expensive in particular for real world, practical applications. We are interested in geometrical parameters and take advantage of the flexibility of splines in representing complex geometries. In this case, the operators are geometry-dependent and generally depend on the parameters in a non-affine way. Moreover, the solutions obtained from trimmed domains may vary highly with respect to different values of the parameters. Therefore, we employ a local reduced basis method based on clustering techniques and the Discrete Empirical Interpolation Method to construct affine approximations and efficient reduced order models. In addition, we discuss the application of the reduction strategy to parametric shape optimization. Finally, we demonstrate the performance of the proposed framework to parameterized Kirchhoff-Love shells through benchmark tests on trimmed, multi-patch meshes including a complex geometry. The proposed approach is accurate and achieves a significant reduction of the online computational cost in comparison to the standard reduced basis method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.09113v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Margarita Chasapi, Pablo Antolin, Annalisa Buffa</dc:creator>
    </item>
    <item>
      <title>On the nature of the boundary resonance error in numerical homogenization and its reduction</title>
      <link>https://arxiv.org/abs/2308.07563</link>
      <description>arXiv:2308.07563v2 Announce Type: replace 
Abstract: Numerical homogenization of multiscale equations typically requires taking an average of the solution to a microscale problem. Both the boundary conditions and domain size of the microscale problem play an important role in the accuracy of the homogenization procedure. In particular, imposing naive boundary conditions leads to a $\mathcal{O}(\epsilon/\eta)$ error in the computation, where $\epsilon$ is the characteristic size of the microscopic fluctuations in the heterogeneous media, and $\eta$ is the size of the microscopic domain. This so-called boundary, or ``cell resonance" error can dominate discretization error and pollute the entire homogenization scheme. There exist several techniques in the literature to reduce the error. Most strategies involve modifying the form of the microscale cell problem. Below we present an alternative procedure based on the observation that the resonance error itself is an oscillatory function of domain size $\eta$. After rigorously characterizing the oscillatory behavior for one dimensional and quasi-one dimensional microscale domains, we present a novel strategy to reduce the resonance error. Rather than modifying the form of the cell problem, the original problem is solved for a sequence of domain sizes, and the results are averaged against kernels satisfying certain moment conditions and regularity properties. Numerical examples in one and two dimensions illustrate the utility of the approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07563v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sean P. Carney, Milica Dussinger, Bjorn Engquist</dc:creator>
    </item>
    <item>
      <title>A new provably stable weighted state redistribution algorithm</title>
      <link>https://arxiv.org/abs/2308.16332</link>
      <description>arXiv:2308.16332v2 Announce Type: replace 
Abstract: We propose a practical finite volume method on cut cells using state redistribution. Our algorithm is provably monotone, total variation diminishing, and GKS stable in many situations, and shuts off continuously as the cut cell size approaches a target value. Our analysis reveals why original state redistribution works so well: it results in a monotone scheme for most configurations, though at times subject to a slightly smaller CFL condition. Our analysis also explains why a pre-merging step is beneficial. We show computational experiments in two and three dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16332v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marsha Berger, Andrew Giuliani</dc:creator>
    </item>
    <item>
      <title>Model reduction on manifolds: A differential geometric framework</title>
      <link>https://arxiv.org/abs/2312.01963</link>
      <description>arXiv:2312.01963v3 Announce Type: replace 
Abstract: Using nonlinear projections and preserving structure in model order reduction (MOR) are currently active research fields. In this paper, we provide a novel differential geometric framework for model reduction on smooth manifolds, which emphasizes the geometric nature of the objects involved. The crucial ingredient is the construction of an embedding for the low-dimensional submanifold and a compatible reduction map, for which we discuss several options. Our general framework allows capturing and generalizing several existing MOR techniques, such as structure preservation for Lagrangian- or Hamiltonian dynamics, and using nonlinear projections that are, for instance, relevant in transport-dominated problems. The joint abstraction can be used to derive shared theoretical properties for different methods, such as an exact reproduction result. To connect our framework to existing work in the field, we demonstrate that various techniques for data-driven construction of nonlinear projections can be included in our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.01963v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patrick Buchfink, Silke Glas, Bernard Haasdonk, Benjamin Unger</dc:creator>
    </item>
    <item>
      <title>Residual Based Error Estimator for Chemical-Mechanically Coupled Battery Active Particles</title>
      <link>https://arxiv.org/abs/2401.10135</link>
      <description>arXiv:2401.10135v2 Announce Type: replace 
Abstract: Adaptive finite element methods are a powerful tool to obtain numerical simulation results in a reasonable time. Due to complex chemical and mechanical couplings in lithium-ion batteries, numerical simulations are very helpful to investigate promising new battery active materials such as amorphous silicon featuring a higher energy density than graphite. Based on a thermodynamically consistent continuum model with large deformation and chemo-mechanically coupled approach, we compare three different spatial adaptive refinement strategies: Kelly-, gradient recovery- and residual based error estimation. For the residual based case, the strong formulation of the residual is explicitly derived. With amorphous silicon as example material, we investigate two 3D representative host particle geometries, reduced with symmetry assumptions to a 1D unit interval and a 2D elliptical domain. Our numerical studies show that the Kelly estimator overestimates the error, whereas the gradient recovery estimator leads to lower refinement levels and a good capture of the change of the lithium flux. The residual based error estimator reveals a strong dependency on the cell error part which can be improved by a more suitable choice of constants to be more efficient. In a 2D domain, the concentration has a larger influence on the mesh distribution than the Cauchy stress.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.10135v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Raphael Schoof, Lennart Fl\"ur, Florian Tuschner, Willy D\"orfler</dc:creator>
    </item>
    <item>
      <title>Refined generalization analysis of the Deep Ritz Method and Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2401.12526</link>
      <description>arXiv:2401.12526v2 Announce Type: replace 
Abstract: In this paper, we present refined generalization bounds for the Deep Ritz Method (DRM) and Physics-Informed Neural Networks (PINNs). For the DRM, we focus on two prototype elliptic PDEs: Poisson equation and static Schr\"odinger equation on the $d$-dimensional unit hypercube with the Neumann boundary condition. And sharper generalization bounds are derived based on the localization techniques under the assumptions that the exact solutions of the PDEs lie in the Barron spaces or the general Sobolev spaces. For the PINNs, we investigate the general linear second elliptic PDEs with Dirichlet boundary condition via the local Rademacher complexity in the multi-task learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12526v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xianliang Xu, Zhongyi Huang</dc:creator>
    </item>
    <item>
      <title>Bayesian D-Optimal Experimental Designs via Column Subset Selection</title>
      <link>https://arxiv.org/abs/2402.16000</link>
      <description>arXiv:2402.16000v2 Announce Type: replace 
Abstract: This paper tackles optimal sensor placement for Bayesian linear inverse problems, a popular version of the more general Optimal Experiment Design (OED) problem, using the D-optimality criterion. This is done by establishing connections between sensor placement and Column Subset Selection Problem (CSSP), which is a well-studied problem in Numerical Linear Algebra (NLA). In particular, we use the Golub-Klema-Stewart (GKS) approach which involves computing the truncated Singular Value Decomposition (SVD) followed by a pivoted QR factorization on the right singular vectors. The algorithms are further accelerated by using randomization to compute the low-rank approximation as well as for sampling the indices. The resulting algorithms are robust, computationally efficient, amenable to parallelization, require virtually no parameter tuning, and come with strong theoretical guarantees. One of the proposed algorithms is also adjoint-free which is beneficial in situations, where the adjoint is expensive to evaluate or is not available. Additionally, we develop a method for data completion without solving the inverse problem. Numerical experiments on model inverse problems involving the heat equation and seismic tomography in two spatial dimensions demonstrate the performance of our approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.16000v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Srinivas Eswar, Vishwas Rao, Arvind K. Saibaba</dc:creator>
    </item>
    <item>
      <title>CP-PINNs: Data-Driven Changepoints Detection in PDEs Using Online Optimized Physics-Informed Neural Networks</title>
      <link>https://arxiv.org/abs/2208.08626</link>
      <description>arXiv:2208.08626v3 Announce Type: replace-cross 
Abstract: We investigate the inverse problem for Partial Differential Equations (PDEs) in scenarios where the parameters of the given PDE dynamics may exhibit changepoints at random time. We employ Physics-Informed Neural Networks (PINNs) - universal approximators capable of estimating the solution of any physical law described by a system of PDEs, which serves as a regularization during neural network training, restricting the space of admissible solutions and enhancing function approximation accuracy. We demonstrate that when the system exhibits sudden changes in the PDE dynamics, this regularization is either insufficient to accurately estimate the true dynamics, or it may result in model miscalibration and failure. Consequently, we propose a PINNs extension using a Total-Variation penalty, which allows to accommodate multiple changepoints in the PDE dynamics and significantly improves function approximation. These changepoints can occur at random locations over time and are estimated concurrently with the solutions. Additionally, we introduce an online learning method for re-weighting loss function terms dynamically. Through empirical analysis using examples of various equations with parameter changes, we showcase the advantages of our proposed model. In the absence of changepoints, the model reverts to the original PINNs model. However, when changepoints are present, our approach yields superior parameter estimation, improved model fitting, and reduced training error compared to the original PINNs model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.08626v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.DS</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhikang Dong, Pawel Polak</dc:creator>
    </item>
    <item>
      <title>Samplet basis pursuit: Multiresolution scattered data approximation with sparsity constraints</title>
      <link>https://arxiv.org/abs/2306.10180</link>
      <description>arXiv:2306.10180v4 Announce Type: replace-cross 
Abstract: We consider scattered data approximation in samplet coordinates with $\ell_1$-regularization. The application of an $\ell_1$-regularization term enforces sparsity of the coefficients with respect to the samplet basis. Samplets are wavelet-type signed measures, which are tailored to scattered data. Therefore, samplets enable the use of well-established multiresolution techniques on general scattered data sets. They provide similar properties as wavelets in terms of localization, multiresolution analysis, and data compression. By using the Riesz isometry, we embed samplets into reproducing kernel Hilbert spaces and discuss the properties of the resulting functions. We argue that the class of signals that are sparse with respect to the embedded samplet basis is considerably larger than the class of signals that are sparse with respect to the basis of kernel translates. Vice versa, every signal that is a linear combination of only a few kernel translates is sparse in samplet coordinates.
  We propose the rapid solution of the problem under consideration by combining soft-shrinkage with the semi-smooth Newton method. Leveraging on the sparse representation of kernel matrices in samplet coordinates, this approach converges faster than the fast iterative shrinkage thresholding algorithm and is feasible for large-scale data. Numerical benchmarks are presented and demonstrate the superiority of the multiresolution approach over the single-scale approach. As large-scale applications, the surface reconstruction from scattered data and the reconstruction of scattered temperature data using a dictionary of multiple kernels are considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.10180v4</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Davide Baroli, Helmut Harbrecht, Michael Multerer</dc:creator>
    </item>
    <item>
      <title>Investigating the Ability of PINNs To Solve Burgers' PDE Near Finite-Time BlowUp</title>
      <link>https://arxiv.org/abs/2310.05169</link>
      <description>arXiv:2310.05169v2 Announce Type: replace-cross 
Abstract: Physics Informed Neural Networks (PINNs) have been achieving ever newer feats of solving complicated PDEs numerically while offering an attractive trade-off between accuracy and speed of inference. A particularly challenging aspect of PDEs is that there exist simple PDEs which can evolve into singular solutions in finite time starting from smooth initial conditions. In recent times some striking experiments have suggested that PINNs might be good at even detecting such finite-time blow-ups. In this work, we embark on a program to investigate this stability of PINNs from a rigorous theoretical viewpoint. Firstly, we derive generalization bounds for PINNs for Burgers' PDE, in arbitrary dimensions, under conditions that allow for a finite-time blow-up. Then we demonstrate via experiments that our bounds are significantly correlated to the $\ell_2$-distance of the neurally found surrogate from the true blow-up solution, when computed on sequences of PDEs that are getting increasingly close to a blow-up.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05169v2</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dibyakanti Kumar, Anirbit Mukherjee</dc:creator>
    </item>
    <item>
      <title>A quick probability-oriented introduction to operator splitting methods</title>
      <link>https://arxiv.org/abs/2401.00123</link>
      <description>arXiv:2401.00123v2 Announce Type: replace-cross 
Abstract: This paper is an extended and reworked version of a short course given by the author at ''Uzbekistan-Ukrainian readings in stochastic processes'', Tashkent-Kyiv, 2022, and was prepared for a special issue of ''Theory of stochastic processes'', devoted to publishing lecture notes from the aforementioned workshop.
  The survey is devoted to operator splitting methods in the abstract formulation and their applications in probability. While the survey is focused on multiplicative methods, the BCH formula is used to discuss exponential splitting methods and a short informal introduction to additive splitting is presented. We introduce frameworks and available deterministic and probabilistic results and concentrate on constructing a wide picture of the field of operator splitting methods, providing a rigorous description in the setting of abstract Cauchy problems and an informal discussion for further and parallel advances. Some limitations and common difficulties are listed, as well as examples of works that provide solutions or hints. No new results are given. The bibliography contains illustrative deterministic examples and a selection of probability-related works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00123v2</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. B. Vovchanskyi</dc:creator>
    </item>
    <item>
      <title>Covering convection with thermal blankets: formation of supercontinents</title>
      <link>https://arxiv.org/abs/2404.01172</link>
      <description>arXiv:2404.01172v2 Announce Type: replace-cross 
Abstract: The continental plates of Earth are known to drift over a geophysical timescale, and their interactions have lead to some of the most spectacular geoformations of our planet while also causing natural disasters such as earthquakes and volcanic activity. Understanding the dynamics of interacting continental plates is thus significant. In this work, we present a fluid mechanical investigation of the plate motion, interaction, and dynamics. Through numerical experiments, we examine the coupling between a convective fluid and plates floating on top of it. With physical modeling, we show the coupling is both mechanical and thermal, leading to the thermal blanket effect: the floating plate is not only transported by the fluid flow beneath, it also prevents the heat from leaving the fluid, leading to a convective flow that further affects the plate motion. By adding several plates to such a coupled fluid-structure interaction, we also investigate how floating plates interact with each other and show that, under proper conditions, small plates can converge into a supercontinent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01172v2</guid>
      <category>physics.flu-dyn</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinzi Mac Huang</dc:creator>
    </item>
  </channel>
</rss>
