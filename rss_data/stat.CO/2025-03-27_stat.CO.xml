<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 28 Mar 2025 01:55:44 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fast and accurate emulation of complex dynamic simulators</title>
      <link>https://arxiv.org/abs/2503.20250</link>
      <description>arXiv:2503.20250v1 Announce Type: new 
Abstract: While dynamic simulators, which are computational models that evolve over time and are governed by differential equations, are essential in scientific and engineering applications, their emulation remains challenging due to the unpredictable behavior of complex systems. To address this challenge, this paper introduces a fast and accurate Gaussian Process (GP)-based emulation method for complex dynamic simulators. By integrating linked GPs into the one-step-ahead emulation framework, the proposed algorithm enables exact analytical computations of the posterior mean and variance, eliminating the need for computationally expensive Monte Carlo approximations. This significantly reduces computation time while maintaining or improving predictive accuracy. Furthermore, the method extends naturally to systems with forcing inputs by incorporating them as additional variables within the GP framework. Numerical experiments on the Lotka-Volterra model and the Lorenz system demonstrate the efficiency and computational advantages of the proposed approach. An \textsf{R} package, \textsf{dynemu}, implementing the one-step-ahead emulation approach, is available on \textsf{CRAN}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20250v1</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junoh Heo</dc:creator>
    </item>
    <item>
      <title>On the Utility of Equal Batch Sizes for Inference in Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2303.07706</link>
      <description>arXiv:2303.07706v3 Announce Type: replace 
Abstract: Stochastic gradient descent (SGD) is an estimation tool for large data employed in machine learning and statistics. Due to the Markovian nature of the SGD process, inference is a challenging problem. An underlying asymptotic normality of the averaged SGD (ASGD) estimator allows for the construction of a batch-means estimator of the asymptotic covariance matrix. Instead of the usual increasing batch-size strategy, we propose a memory efficient equal batch-size strategy and show that under mild conditions, the batch-means estimator is consistent. A key feature of the proposed batching technique is that it allows for bias-correction of the variance, at no additional cost to memory. Further, since joint inference for large dimensional problems may be undesirable, we present marginal-friendly simultaneous confidence intervals, and show through an example on how covariance estimators of ASGD can be employed for improved predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.07706v3</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rahul Singh, Abhinek Shukla, Dootika Vats</dc:creator>
    </item>
    <item>
      <title>A Proximal Newton Adaptive Importance Sampler</title>
      <link>https://arxiv.org/abs/2412.16558</link>
      <description>arXiv:2412.16558v2 Announce Type: replace 
Abstract: Adaptive importance sampling (AIS) algorithms are a rising methodology in signal processing, statistics, and machine learning. An effective adaptation of the proposals is key for the success of AIS. Recent works have shown that gradient information about the involved target density can greatly boost performance, but its applicability is restricted to differentiable targets. In this paper, we propose a proximal Newton adaptive importance sampler for the estimation of expectations with respect to non-smooth target distributions. We implement a scaled Newton proximal gradient method to adapt the proposal distributions, enabling efficient and optimized moves even when the target distribution lacks differentiability. We show the good performance of the algorithm in two scenarios: one with convex constraints and another with non-smooth sparse priors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16558v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>V\'ictor Elvira, \'Emilie Chouzenoux, O. Deniz Akyildiz</dc:creator>
    </item>
    <item>
      <title>Nonparametric Smoothing of Directional and Axial Data</title>
      <link>https://arxiv.org/abs/2501.17463</link>
      <description>arXiv:2501.17463v2 Announce Type: replace-cross 
Abstract: We discuss generalized linear models for directional data where the conditional distribution of the response is a von Mises-Fisher distribution in arbitrary dimension or a Bingham distribution on the unit circle. To do this properly, we parametrize von Mises-Fisher distributions by Euclidean parameters and investigate computational aspects of this parametrization. Then we modify this approach for local polynomial regression as a means of nonparametric smoothing of distributional data. The methods are illustrated with simulated data and a data set from planetary sciences involving covariate vectors on a sphere with axial response.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17463v2</guid>
      <category>stat.ME</category>
      <category>astro-ph.EP</category>
      <category>stat.CO</category>
      <pubDate>Thu, 27 Mar 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lutz Duembgen, Caroline Haslebacher</dc:creator>
    </item>
  </channel>
</rss>
