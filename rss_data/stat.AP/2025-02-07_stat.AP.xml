<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.AP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.AP</link>
    <description>stat.AP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.AP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 07 Feb 2025 05:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Tutorial on Markov Renewal and Semi-Markov Proportional Hazards Model</title>
      <link>https://arxiv.org/abs/2502.03479</link>
      <description>arXiv:2502.03479v1 Announce Type: new 
Abstract: Transition probability estimation plays a critical role in multi-state modeling, especially in clinical research. This paper investigates the application of semi-Markov and Markov renewal frameworks to the EBMT dataset, focusing on six clinical states encountered during hematopoietic stem cell transplantation. By comparing Aalen-Johansen (AJ) and Dabrowska-Sun-Horowitz (DSH) estimators, we demonstrate that semi-Markov models, which incorporate sojourn times, provide a more nuanced and temporally sensitive depiction of patient trajectories compared to memoryless Markov models. The DSH estimator consistently yields smoother probability curves, particularly for transitions involving prolonged states. These findings underscore the importance of selecting appropriate models and estimators in multi-state analysis. Future work includes extending the framework to accommodate advanced covariate structures and non-Markovian dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03479v1</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elvis Han Cui</dc:creator>
    </item>
    <item>
      <title>Foundation for unbiased cross-validation of spatio-temporal models for species distribution modeling</title>
      <link>https://arxiv.org/abs/2502.03480</link>
      <description>arXiv:2502.03480v1 Announce Type: new 
Abstract: Species Distribution Models (SDMs) often suffer from spatial autocorrelation (SAC), leading to biased performance estimates. We tested cross-validation (CV) strategies - random splits, spatial blocking with varied distances, environmental (ENV) clustering, and a novel spatio-temporal method - under two proposed training schemes: LAST FOLD, widely used in spatial CV at the cost of data loss, and RETRAIN, which maximizes data usage but risks reintroducing SAC. LAST FOLD consistently yielded lower errors and stronger correlations. Spatial blocking at an optimal distance (SP 422) and ENV performed best, achieving Spearman and Pearson correlations of 0.485 and 0.548, respectively, although ENV may be unsuitable for long-term forecasts involving major environmental shifts. A spatio-temporal approach yielded modest benefits in our moderately variable dataset, but may excel with stronger temporal changes. These findings highlight the need to align CV approaches with the spatial and temporal structure of SDM data, ensuring rigorous validation and reliable predictive outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03480v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Diana Koldasbayeva, Alexey Zaytsev</dc:creator>
    </item>
    <item>
      <title>Market-based insurance ratemaking: application to pet insurance</title>
      <link>https://arxiv.org/abs/2502.04082</link>
      <description>arXiv:2502.04082v1 Announce Type: new 
Abstract: This paper introduces a method for pricing insurance policies using market data. The approach is designed for scenarios in which the insurance company seeks to enter a new market, in our case: pet insurance, lacking historical data. The methodology involves an iterative two-step process. First, a suitable parameter is proposed to characterize the underlying risk. Second, the resulting pure premium is linked to the observed commercial premium using an isotonic regression model. To validate the method, comprehensive testing is conducted on synthetic data, followed by its application to a dataset of actual pet insurance rates. To facilitate practical implementation, we have developed an R package called IsoPriceR. By addressing the challenge of pricing insurance policies in the absence of historical data, this method helps enhance pricing strategies in emerging markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04082v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Pierre-Olivier Goffard, Pierrick Piette, Gareth W. Peters</dc:creator>
    </item>
    <item>
      <title>Accurate Estimates of Ultimate 100-Meter Records</title>
      <link>https://arxiv.org/abs/2502.04085</link>
      <description>arXiv:2502.04085v1 Announce Type: new 
Abstract: We employ the novel theory of heterogeneous extreme value statistics to accurately estimate the ultimate world records for the 100-m running race, for men and for women. For this aim we collected data from 1991 through 2023 from thousands of top athletes, using multiple fast times per athlete. We consider the left endpoint of the probability distribution of the running times of a top athlete and define the ultimate world record as the minimum, over all top athletes, of all these endpoints. For men we estimate the ultimate world record to be 9.56 seconds. More prudently, employing this heterogeneous extreme value theory we construct an accurate asymptotic 95% lower confidence bound on the ultimate world record of 9.49 seconds, still quite close to the present world record of 9.58. For the women's 100-meter dash our point estimate of the ultimate world record is 10.34 seconds, somewhat lower than the world record of 10.49. The more prudent 95% lower confidence bound on the women's ultimate world record is 10.20.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04085v1</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Einmahl, Yi He</dc:creator>
    </item>
    <item>
      <title>A Pseudo Markov-Chain Model and Time-Elapsed Measures of Mobility from Collective Data</title>
      <link>https://arxiv.org/abs/2502.04162</link>
      <description>arXiv:2502.04162v1 Announce Type: new 
Abstract: In this paper we develop a pseudo Markov-chain model to understand time-elapsed flows, over multiple intervals, from time and space aggregated collective inter-location trip data, given as a time-series. Building on the model, we develop measures of mobility that parallel those known for individual mobility data, such as the radius of gyration. We apply these measures to the NetMob 2024 Data Challenge data, and obtain interesting results that are consistent with published statistics and commuting patterns in cities. Besides building a new framework, we foresee applications of this approach to an improved understanding of human mobility in the context of environmental changes and sustainable development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.04162v1</guid>
      <category>stat.AP</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <category>stat.ML</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Alisha Foster, David A. Meyer, Asif Shakeel</dc:creator>
    </item>
    <item>
      <title>Efficient Image Restoration via Latent Consistency Flow Matching</title>
      <link>https://arxiv.org/abs/2502.03500</link>
      <description>arXiv:2502.03500v1 Announce Type: cross 
Abstract: Recent advances in generative image restoration (IR) have demonstrated impressive results. However, these methods are hindered by their substantial size and computational demands, rendering them unsuitable for deployment on edge devices. This work introduces ELIR, an Efficient Latent Image Restoration method. ELIR operates in latent space by first predicting the latent representation of the minimum mean square error (MMSE) estimator and then transporting this estimate to high-quality images using a latent consistency flow-based model. Consequently, ELIR is more than 4x faster compared to the state-of-the-art diffusion and flow-based approaches. Moreover, ELIR is also more than 4x smaller, making it well-suited for deployment on resource-constrained edge devices. Comprehensive evaluations of various image restoration tasks show that ELIR achieves competitive results, effectively balancing distortion and perceptual quality metrics while offering improved efficiency in terms of memory and computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.03500v1</guid>
      <category>eess.IV</category>
      <category>cs.AI</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elad Cohen, Idan Achituve, Idit Diamant, Arnon Netzer, Hai Victor Habi</dc:creator>
    </item>
    <item>
      <title>Bayesian Signal Matching for Transfer Learning in ERP-Based Brain Computer Interface</title>
      <link>https://arxiv.org/abs/2401.07111</link>
      <description>arXiv:2401.07111v2 Announce Type: replace 
Abstract: An Event-Related Potential (ERP)-based Brain-Computer Interface (BCI) Speller System assists people with disabilities to communicate by decoding electroencephalogram (EEG) signals. A P300-ERP embedded in EEG signals arises in response to a rare, but relevant event (target) among a series of irrelevant events (non-target). Different machine learning methods have constructed binary classifiers to detect target events, known as calibration. The existing calibration strategy uses data from participants themselves with lengthy training time. Participants feel bored and distracted, which causes biased P300 estimation and decreased prediction accuracy. To resolve this issue, we propose a Bayesian signal matching (BSM) framework to calibrate EEG signals from a new participant using data from source participants. BSM specifies the joint distribution of stimulus-specific EEG signals among source participants via a Bayesian hierarchical mixture model. We apply the inference strategy. If source and new participants are similar, they share the same set of model parameters; otherwise, they keep their own sets of model parameters; we predict on the testing data using parameters of the baseline cluster directly. Our hierarchical framework can be generalized to other base classifiers with parametric forms. We demonstrate the advantages of BSM using simulations and focus on the real data analysis among participants with neuro-degenerative diseases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07111v2</guid>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tianwen Ma, Jane E. Huggins, Jian Kang</dc:creator>
    </item>
    <item>
      <title>Some statistical aspects of the Covid-19 response</title>
      <link>https://arxiv.org/abs/2409.06473</link>
      <description>arXiv:2409.06473v2 Announce Type: replace 
Abstract: This paper discusses some statistical aspects of the U.K. Covid-19 pandemic response, focussing particularly on cases where we believe that a statistically questionable approach or presentation has had a substantial impact on public perception, or government policy, or both. We discuss the presentation of statistics relating to Covid risk, and the risk of the response measures, arguing that biases tended to operate in opposite directions, overplaying Covid risk and underplaying the response risks. We also discuss some issues around presentation of life loss data, excess deaths and the use of case data. The consequences of neglect of most individual variability from epidemic models, alongside the consequences of some other statistically important omissions are also covered. Finally the evidence for full stay at home lockdowns having been necessary to reverse waves of infection is examined, with new analyses provided for a number of European countries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06473v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Simon N. Wood, Ernst C. Wit, Paul M. McKeigue, Danshu Hu, Beth Flood, Lauren Corcoran, Thea Abou Jawad</dc:creator>
    </item>
    <item>
      <title>Enhancing the use of family planning service statistics using a Bayesian modelling approach to inform estimates of modern contraceptive use in low- and middle-income countries</title>
      <link>https://arxiv.org/abs/2412.08606</link>
      <description>arXiv:2412.08606v2 Announce Type: replace 
Abstract: Monitoring family planning indicators, such as modern contraceptive prevalence rate (mCPR), is essential for family planning programming. The Family Planning Estimation Tool (FPET) uses survey data to estimate and forecast family planning indicators, including mCPR, over time. However, sole reliance on large-scale surveys, carried out on average every 3-5 years, can lead to data gaps. Service statistics are a readily available data source, routinely collected in conjunction with service delivery. Various service statistics data types can be used to derive a family planning indicator called Estimated Modern Use (EMU). In a number of countries, annual rates of change in EMU have been found to be predictive of true rates of change in mCPR. However, it has been challenging to capture the varying levels of uncertainty associated with the EMU indicator across different countries and service statistics data types and to subsequently quantify this uncertainty when using EMU in FPET. We present a new approach to using EMUs in FPET to inform mCPR estimates, using annual EMU rates of change as input, and accounting for uncertainty associated with the EMU derivation process. The approach also considers additional country-type-specific uncertainty. We assess the EMU type-specific uncertainty at the country level, via a Bayesian hierarchical modelling approach. Validation results and anonymised country-level case studies highlight improved predictive performance and provide insights into the impact of including EMU data on mCPR estimates compared to using survey data alone. Together, they demonstrate that EMUs can help countries monitor progress toward their family planning goals more effectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.08606v2</guid>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shauna Mooney, Leontine Alkema, Emily Sonneveldt, Kristin Bietsch, Jessica Williamson, Niamh Cahill</dc:creator>
    </item>
    <item>
      <title>Had enough of experts? Quantitative knowledge retrieval from large language models</title>
      <link>https://arxiv.org/abs/2402.07770</link>
      <description>arXiv:2402.07770v2 Announce Type: replace-cross 
Abstract: Large language models (LLMs) have been extensively studied for their abilities to generate convincing natural language sequences, however their utility for quantitative information retrieval is less well understood. Here we explore the feasibility of LLMs as a mechanism for quantitative knowledge retrieval to aid two data analysis tasks: elicitation of prior distributions for Bayesian models and imputation of missing data. We introduce a framework that leverages LLMs to enhance Bayesian workflows by eliciting expert-like prior knowledge and imputing missing data. Tested on diverse datasets, this approach can improve predictive accuracy and reduce data requirements, offering significant potential in healthcare, environmental science and engineering applications. We discuss the implications and challenges of treating LLMs as 'experts'.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.07770v2</guid>
      <category>cs.IR</category>
      <category>cs.CL</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Selby, Kai Spriestersbach, Yuichiro Iwashita, Mohammad Saad, Dennis Bappert, Archana Warrier, Sumantrak Mukherjee, Koichi Kise, Sebastian Vollmer</dc:creator>
    </item>
    <item>
      <title>A Personalized Predictive Model that Jointly Optimizes Discrimination and Calibration</title>
      <link>https://arxiv.org/abs/2403.17132</link>
      <description>arXiv:2403.17132v2 Announce Type: replace-cross 
Abstract: Precision medicine is accelerating rapidly in the field of health research. This includes fitting predictive models for individual patients based on patient similarity in an attempt to improve model performance. We propose an algorithm which fits a personalized predictive model (PPM) using an optimal size of a similar subpopulation that jointly optimizes model discrimination and calibration, as it is criticized that calibration is not assessed nearly as often as discrimination despite poorly calibrated models being potentially misleading. We define a mixture loss function that considers model discrimination and calibration, and allows for flexibility in emphasizing one performance measure over another. We empirically show that the relationship between the size of subpopulation and calibration is quadratic, which motivates the development of our jointly optimized model. We also investigate the effect of within-population patient weighting on performance and conclude that the size of subpopulation has a larger effect on the predictive performance of the PPM compared to the choice of weight function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.17132v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tatiana Krikella, Joel A. Dubin</dc:creator>
    </item>
    <item>
      <title>A novel longitudinal rank-sum test for multiple primary endpoints in clinical trials: Applications to neurodegenerative disorders</title>
      <link>https://arxiv.org/abs/2410.19190</link>
      <description>arXiv:2410.19190v2 Announce Type: replace-cross 
Abstract: Neurodegenerative disorders such as Alzheimer's disease (AD) present a significant global health challenge, characterized by cognitive decline, functional impairment, and other debilitating effects. Current AD clinical trials often assess multiple longitudinal primary endpoints to comprehensively evaluate treatment efficacy. Traditional methods, however, may fail to capture global treatment effects, require larger sample sizes due to multiplicity adjustments, and may not fully exploit multivariate longitudinal data. To address these limitations, we introduce the Longitudinal Rank Sum Test (LRST), a novel nonparametric rank-based omnibus test statistic. The LRST enables a comprehensive assessment of treatment efficacy across multiple endpoints and time points without multiplicity adjustments, effectively controlling Type I error while enhancing statistical power. It offers flexibility against various data distributions encountered in AD research and maximizes the utilization of longitudinal data. Extensive simulations and real-data applications demonstrate the LRST's performance, underscoring its potential as a valuable tool in AD clinical trials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.19190v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1080/19466315.2025.2458018</arxiv:DOI>
      <dc:creator>Xiaoming Xu, Dhrubajyoti Ghosh, Sheng Luo</dc:creator>
    </item>
    <item>
      <title>BiDepth Multimodal Neural Network: Bidirectional Depth Deep Learning Architecture for Spatial-Temporal Prediction</title>
      <link>https://arxiv.org/abs/2501.08411</link>
      <description>arXiv:2501.08411v2 Announce Type: replace-cross 
Abstract: Accurate prediction of spatial-temporal (ST) information in dynamic systems, such as urban mobility and weather patterns, is a crucial yet challenging problem. The complexity stems from the intricate interplay between spatial proximity and temporal relevance, where both long-term trends and short-term fluctuations are present in convoluted patterns. Existing approaches, including traditional statistical methods and conventional neural networks, may provide inaccurate results due to the lack of an effective mechanism that simultaneously incorporates information at variable temporal depths while maintaining spatial context, resulting in a trade-off between comprehensive long-term historical analysis and responsiveness to short-term new information. To bridge this gap, this paper proposes the BiDepth Multimodal Neural Network (BDMNN) with bidirectional depth modulation that enables a comprehensive understanding of both long-term seasonality and short-term fluctuations, adapting to the complex ST context. Case studies with real-world public data demonstrate significant improvements in prediction accuracy, with a 12% reduction in Mean Squared Error for urban traffic prediction and a 15% improvement in rain precipitation forecasting compared to state-of-the-art benchmarks, without demanding extra computational resources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.08411v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sina Ehsani, Fenglian Pan, Qingpei Hu, Jian Liu</dc:creator>
    </item>
    <item>
      <title>Sequential Methods for Error Correction of Probabilistic Wind Power Forecasts</title>
      <link>https://arxiv.org/abs/2501.14805</link>
      <description>arXiv:2501.14805v2 Announce Type: replace-cross 
Abstract: Reliable probabilistic production forecasts are required to better manage the uncertainty that the rapid build-out of wind power capacity adds to future energy systems. In this article, we consider sequential methods to correct errors in power production forecast ensembles derived from numerical weather predictions. We propose combining neural networks with time-adaptive quantile regression to enhance the accuracy of wind power forecasts. We refer to this approach as Neural Adaptive Basis for (time-adaptive) Quantile Regression or NABQR. First, we use NABQR to correct power production ensembles with neural networks. We find that Long Short-Term Memory networks are the most effective architecture for this purpose. Second, we apply time-adaptive quantile regression to the corrected ensembles to obtain optimal median predictions along with quantiles of the forecast distribution. With the suggested method we achieve accuracy improvements up to 40% in mean absolute terms in an application to day-ahead forecasting of on- and offshore wind power production in Denmark. In addition, we explore the value of our method for applications in energy trading. We have implemented the NABQR method as an open-source Python package to support applications in renewable energy forecasting and future research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14805v2</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <pubDate>Fri, 07 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bastian Schmidt J{\o}rgensen, Jan Kloppenborg M{\o}ller, Peter Nystrup, Henrik Madsen</dc:creator>
    </item>
  </channel>
</rss>
