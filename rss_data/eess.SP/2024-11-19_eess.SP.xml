<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>eess.SP updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/eess.SP</link>
    <description>eess.SP updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/eess.SP" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Nov 2024 05:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Dataset Refinement for Improving the Generalization Ability of the EEG Decoding Model</title>
      <link>https://arxiv.org/abs/2411.10450</link>
      <description>arXiv:2411.10450v1 Announce Type: new 
Abstract: Electroencephalography (EEG) is a generally used neuroimaging approach in brain-computer interfaces due to its non-invasive characteristics and convenience, making it an effective tool for understanding human intentions. Therefore, recent research has focused on decoding human intentions from EEG signals utilizing deep learning methods. However, since EEG signals are highly susceptible to noise during acquisition, there is a high possibility of the existence of noisy data in the dataset. Although pioneer studies have generally assumed that the dataset is well-curated, this assumption is not always met in the EEG dataset. In this paper, we addressed this issue by designing a dataset refinement algorithm that can eliminate noisy data based on metrics evaluating data influence during the training process. We applied the proposed algorithm to two motor imagery EEG public datasets and three different models to perform dataset refinement. The results indicated that retraining the model with the refined dataset consistently led to better generalization performance compared to using the original dataset. Hence, we demonstrated that removing noisy data from the training dataset alone can effectively improve the generalization performance of deep learning models in the EEG domain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10450v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sung-Jin Kim, Dae-Hyeok Lee, Hyeon-Taek Han</dc:creator>
    </item>
    <item>
      <title>Neural decoding from stereotactic EEG: accounting for electrode variability across subjects</title>
      <link>https://arxiv.org/abs/2411.10458</link>
      <description>arXiv:2411.10458v1 Announce Type: new 
Abstract: Deep learning based neural decoding from stereotactic electroencephalography (sEEG) would likely benefit from scaling up both dataset and model size. To achieve this, combining data across multiple subjects is crucial. However, in sEEG cohorts, each subject has a variable number of electrodes placed at distinct locations in their brain, solely based on clinical needs. Such heterogeneity in electrode number/placement poses a significant challenge for data integration, since there is no clear correspondence of the neural activity recorded at distinct sites between individuals. Here we introduce seegnificant: a training framework and architecture that can be used to decode behavior across subjects using sEEG data. We tokenize the neural activity within electrodes using convolutions and extract long-term temporal dependencies between tokens using self-attention in the time dimension. The 3D location of each electrode is then mixed with the tokens, followed by another self-attention in the electrode dimension to extract effective spatiotemporal neural representations. Subject-specific heads are then used for downstream decoding tasks. Using this approach, we construct a multi-subject model trained on the combined data from 21 subjects performing a behavioral task. We demonstrate that our model is able to decode the trial-wise response time of the subjects during the behavioral task solely from neural data. We also show that the neural representations learned by pretraining our model across individuals can be transferred in a few-shot manner to new subjects. This work introduces a scalable approach towards sEEG data integration for multi-subject model training, paving the way for cross-subject generalization for sEEG decoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10458v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Georgios Mentzelopoulos, Evangelos Chatzipantazis, Ashwin G. Ramayya, Michelle J. Hedlund, Vivek P. Buch, Kostas Daniilidis, Konrad P. Kording, Flavia Vitale</dc:creator>
    </item>
    <item>
      <title>Deep Learning-Based Image Compression for Wireless Communications: Impacts on Reliability,Throughput, and Latency</title>
      <link>https://arxiv.org/abs/2411.10650</link>
      <description>arXiv:2411.10650v1 Announce Type: new 
Abstract: In wireless communications, efficient image transmission must balance reliability, throughput, and latency, especially under dynamic channel conditions. This paper presents an adaptive and progressive pipeline for learned image compression (LIC)-based architectures tailored to such environments. We investigate two state-of-the-art learning-based models: the hyperprior model and Vector Quantized Generative Adversarial Network (VQGAN). The hyperprior model achieves superior compression performance through lossless compression in the bottleneck but is susceptible to bit errors, necessitating the use of error correction or retransmission mechanisms. In contrast, the VQGAN decoder demonstrates robust image reconstruction capabilities even in the absence of channel coding, enhancing reliability in challenging transmission scenarios. We propose progressive versions of both models, enabling partial image transmission and decoding under imperfect channel conditions. This progressive approach not only maintains image integrity under poor channel conditions but also significantly reduces latency by allowing immediate partial image availability. We evaluate our pipeline using the Kodak high-resolution image dataset under a Rayleigh fading wireless channel model simulating dynamic conditions. The results indicate that the progressive transmission framework enhances reliability and latency while maintaining or improving throughput compared to non-progressive counterparts across various Signal-to-Noise Ratio (SNR) levels. Specifically, the progressive-hyperprior model consistently outperforms others in latency metrics, particularly in the 99.9th percentile waiting time-a measure indicating the maximum waiting time experienced by 99.9% of transmission instances-across all SNRs, and achieves higher throughput in low SNR scenarios. where Adaptive WebP fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10650v1</guid>
      <category>eess.SP</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mostafa Naseri, Pooya Ashtari, Mohamed Seif, Eli De Poorter, H. Vincent Poor, Adnan Shahid</dc:creator>
    </item>
    <item>
      <title>Brain-to-Text Decoding with Context-Aware Neural Representations and Large Language Models</title>
      <link>https://arxiv.org/abs/2411.10657</link>
      <description>arXiv:2411.10657v1 Announce Type: new 
Abstract: Decoding attempted speech from neural activity offers a promising avenue for restoring communication abilities in individuals with speech impairments. Previous studies have focused on mapping neural activity to text using phonemes as the intermediate target. While successful, decoding neural activity directly to phonemes ignores the context dependent nature of the neural activity-to-phoneme mapping in the brain, leading to suboptimal decoding performance. In this work, we propose the use of diphone - an acoustic representation that captures the transitions between two phonemes - as the context-aware modeling target. We integrate diphones into existing phoneme decoding frameworks through a novel divide-and-conquer strategy in which we model the phoneme distribution by marginalizing over the diphone distribution. Our approach effectively leverages the enhanced context-aware representation of diphones while preserving the manageable class size of phonemes, a key factor in simplifying the subsequent phoneme-to-text conversion task. We demonstrate the effectiveness of our approach on the Brain-to-Text 2024 benchmark, where it achieves state-of-the-art Phoneme Error Rate (PER) of 15.34% compared to 16.62% PER of monophone-based decoding. When coupled with finetuned Large Language Models (LLMs), our method yields a Word Error Rate (WER) of 5.77%, significantly outperforming the 8.93% WER of the leading method in the benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10657v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyuan Li, Trung Le, Chaofei Fan, Mingfei Chen, Eli Shlizerman</dc:creator>
    </item>
    <item>
      <title>Performance Analysis and Power Allocation for Massive MIMO ISAC Systems</title>
      <link>https://arxiv.org/abs/2411.10723</link>
      <description>arXiv:2411.10723v1 Announce Type: new 
Abstract: Integrated sensing and communications (ISAC) is envisioned as a key feature in future wireless communications networks. Its integration with massive multiple-input-multiple-output (MIMO) techniques promises to leverage substantial spatial beamforming gains for both functionalities. In this work, we consider a massive MIMO-ISAC system employing a uniform planar array with zero-forcing and maximum-ratio downlink transmission schemes combined with monostatic radar-type sensing. Our focus lies on deriving closed-form expressions for the achievable communications rate and the Cram\'er--Rao lower bound (CRLB), which serve as performance metrics for communications and sensing operations, respectively. The expressions enable us to investigate important operational characteristics of massive MIMO-ISAC, including the mutual effects of communications and sensing as well as the advantages stemming from using a very large antenna array for each functionality. Furthermore, we devise a power allocation strategy based on successive convex approximation to maximize the communications rate while guaranteeing the CRLB constraints and transmit power budget. Extensive numerical results are presented to validate our theoretical analyses and demonstrate the efficiency of the proposed power allocation approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10723v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nhan Thanh Nguyen, Van-Dinh Nguyen, Hieu V. Nguyen, Hien Quoc Ngo, A. Lee Swindlehurst, Markku Juntti</dc:creator>
    </item>
    <item>
      <title>Adaptive Soft Actor-Critic Framework for RIS-Assisted and UAV-Aided Communication</title>
      <link>https://arxiv.org/abs/2411.10882</link>
      <description>arXiv:2411.10882v1 Announce Type: new 
Abstract: In this work, we explore UAV-assisted reconfigurable intelligent surface (RIS) technology to enhance downlink communications in wireless networks. By integrating RIS on both UAVs and ground infrastructure, we aim to boost network coverage, fairness, and resilience against challenges such as UAV jitter. To maximize the minimum achievable user rate, we formulate a joint optimization problem involving beamforming, phase shifts, and UAV trajectory. To address this problem, we propose an adaptive soft actor-critic (ASAC) framework. In this approach, agents are built using adaptive sparse transformers with attentive feature refinement (ASTAFER), enabling dynamic feature processing that adapts to real-time network conditions. The ASAC model learns optimal solutions to the coupled subproblems in real time, delivering an end-to-end solution without relying on iterative or relaxation-based methods. Simulation results demonstrate that our ASAC-based approach achieves better performance compared to the conventional SAC. This makes it a robust, adaptable solution for real-time, fair, and efficient downlink communication in UAV-RIS networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10882v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abuzar B. M. Adam, Elhadj Moustapha Diallo, Mohammed A. M. Elhassan</dc:creator>
    </item>
    <item>
      <title>Body-Resonance Human Body Communication</title>
      <link>https://arxiv.org/abs/2411.10905</link>
      <description>arXiv:2411.10905v1 Announce Type: new 
Abstract: Seamless interaction between Humans and AI-empowered battery-operated miniaturized electronic devices, exponentially transforming the wearable technology industry while forming an anthropomorphic artificial nervous system for distributed computing around the human body, demands high-speed low-power connectivity. If interconnected via radio frequency (RF) based wireless communication techniques, that being radiative, incur substantial absorption losses from the body during non-line-of-sight scenarios and consume higher power (more than 10s of mW). Although as a promising alternative with its non-radiative nature that resulted in 100X improvement in energy efficiency (sub-10 pJ/bit) and better signal confinement, Electro-Quasistatic Human Body Communication (EQS HBC) incurs moderate path loss (60-70 dB), limited data rate (less than 20 Mbps), making it less suitable for applications demanding fast connectivity like HD audio-video streaming, AR-VR-based products, distributed computing with wearable AI devices. Hence, to meet the requirement of energy-efficient connectivity at 100s of Mbps between wearables, we propose Body-Resonance (BR) HBC, which operates in the near-intermediate field and utilizes the transmission-line-like behavior of the body channel to offer 30X improvement in channel capacity. Our work sheds new light on the wireless communication system for wearables with potential to increase the channel gain by 20 dB with a 10X improvement in bandwidth compared to the EQS HBC for communication over on-body channels (whole-body coverage area). Experimentally demonstrating BR HBC, we presented low-loss (40-50 dB) and wide-band (hundreds of MHz) body channels that are 10X less leaky than radiative wireless communication, hence, can revolutionize the design of wireless communication system for several applications with wearables from healthcare, defense, to consumer electronics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10905v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Samyadip Sarkar, Qi Huang, Sarthak Antal, Mayukh Nath, Shreyas Sen</dc:creator>
    </item>
    <item>
      <title>Decentralized Localization of Distributed Antenna Array Elements Using an Evolutionary Algorithm</title>
      <link>https://arxiv.org/abs/2411.10907</link>
      <description>arXiv:2411.10907v1 Announce Type: new 
Abstract: Distributed phased arrays have recently garnered interest in applications such as satellite communications and high-resolution remote sensing. High-performance coherent distributed operations such as distributed beamforming are dependent on the ability to synchronize the spatio-electrical states of the elements in the array to the order of the operational wavelength, so that coherent signal summation can be achieved at any arbitrary target destination. In this paper, we address the fundamental challenge of precise distributed array element localization to enable coherent operation, even in complex environments where the array may not be capable of directly estimating all nodal link distances. We employ a two-way time transfer technique to synchronize the nodes of the array and perform internode ranging. We implement the classical multidimensional scaling algorithm to recover a decentralized array geometry from a set of range estimates. We also establish the incomplete set of range estimates as a multivariable non-convex optimization problem, and define the differential evolution algorithm which searches the solution space to complete the set of ranges. We experimentally demonstrate wireless localization using a spectrally-sparse pulsed two-tone waveform with 40 MHz tone separation in a laboratory environment, achieving a mean localization error vector magnitude of 0.82 mm in an environment with an average link SNR of 34 dB, theoretically supporting distributed beamforming operation up to 24.3 GHz.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10907v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthew J. Dula, Naim Shandi, Jeffrey A. Nanzer</dc:creator>
    </item>
    <item>
      <title>Modeling blockage in high directional wireless. systems</title>
      <link>https://arxiv.org/abs/2411.11007</link>
      <description>arXiv:2411.11007v1 Announce Type: new 
Abstract: While the wireless word moves towards higher frequency bands, new challenges arises, due to the inherent characteristics of the transmission links, such as high path and penetration losses. Penetration losses causes blockages that in turn can significantly reduce the signal strength at the receiver. Most published contributions consider a binary blockage stage, i.e. either fully blocked or blockage-free links. However, in realistic scenarios, a link can be partially blocked. Motivated by this, in this paper, we present two low-complexity models that are based on tight approximations and accommodates the impact of partial blockage in high-frequency links. To demonstrate the applicability of the derived framework, we present closed-form expressions for the outage probability for the case in which the distance between the center of the receiver plane and the blocker's shadow center follow uniform distribution. Numerical results verify the derived framework and reveal how the transmission parameters affect blockage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11007v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Evangelos Koutsonas, Alexandros-Apostolos A. Boulogeorgos, Stylianos E. Trevlakis, Tanweer Ali, Theodoros A. Tsiftis</dc:creator>
    </item>
    <item>
      <title>Rate Splitting Multiple Access for RIS-aided URLLC MIMO Broadcast Channels</title>
      <link>https://arxiv.org/abs/2411.11028</link>
      <description>arXiv:2411.11028v1 Announce Type: new 
Abstract: The performance of modern wireless communication systems is typically limited by interference. The impact of interference can be even more severe in ultra-reliable and low-latency communication (URLLC) use cases. A powerful tool for managing interference is rate splitting multiple access (RSMA), which encompasses many multiple-access technologies like non-orthogonal multiple access (NOMA), spatial division multiple access (SDMA), and broadcasting. Another effective technology to enhance the performance of URLLC systems and mitigate interference is constituted by reconfigurable intelligent surfaces (RISs). This paper develops RSMA schemes for multi-user multiple-input multiple-output (MIMO) RIS-aided broadcast channels (BCs) based on finite block length (FBL) coding. We show that RSMA and RISs can substantially improve the spectral efficiency (SE) and energy efficiency (EE) of MIMO RIS-aided URLLC systems. Additionally, the gain of employing RSMA and RISs noticeably increases when the reliability and latency constraints are more stringent. Furthermore, RISs impact RSMA differently, depending on the user load. If the system is underloaded, RISs are able to manage the interference sufficiently well, making the gains of RSMA small. However, when the user load is high, RISs and RSMA become synergetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11028v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mohammad Soleymani, Ignacio Santamaria, Eduard Jorswieck, Marco Di Renzo, Robert Schober, Lajos Hanzo</dc:creator>
    </item>
    <item>
      <title>IREE Oriented Active RIS-Assisted Green communication System with Outdated CSI</title>
      <link>https://arxiv.org/abs/2411.11030</link>
      <description>arXiv:2411.11030v1 Announce Type: new 
Abstract: The rapid evolution of communication technologies has spurred a growing demand for energy-efficient network architectures and performance metrics. Active Reconfigurable Intelligent Surfaces (RIS) are emerging as a key component in green network architectures. Compared to passive RIS, active RIS are equipped with amplifiers on each reflecting element, allowing them to simultaneously reflect and amplify signals, thereby overcoming the double multiplicative fading in the phase response, and improving both system coverage and performance. Additionally, the Integrated Relative Energy Efficiency (IREE) metric, as introduced in [1], addresses the dynamic variations in traffic and capacity over time and space, enabling more energy-efficient wireless systems. Building on these advancements, this paper investigates the problem of maximizing IREE in active RIS-assisted green communication systems. However, acquiring perfect Channel State Information (CSI) in practical systems poses significant challenges and costs. To address this, we derive the average achievable rate based on outdated CSI and formulated the corresponding IREE maximization problem, which is solved by jointly optimizing beamforming at both the base station and RIS. Given the non-convex nature of the problem, we propose an Alternating Optimization Successive Approximation (AOSO) algorithm. By applying quadratic transform and relaxation techniques, we simplify the original problem and alternately optimize the beamforming matrices at the base station and RIS. Furthermore, to handle the discrete constraints of the RIS reflection coefficients, we develop a successive approximation method. Experimental results validate our theoretical analysis of the algorithm's convergence , demonstrating the effectiveness of the proposed algorithm and highlighting the superiority of IREE in enhancing the performance of green communication networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11030v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kai Cao, Tao Yu, Jihong Li, Xiaojing Chen, Yanzan Sun, Qingqing Wu, Wen Chen, Shunqing Zhang</dc:creator>
    </item>
    <item>
      <title>Non-Invasive Glucose Level Monitoring from PPG using a Hybrid CNN-GRU Deep Learning Network</title>
      <link>https://arxiv.org/abs/2411.11094</link>
      <description>arXiv:2411.11094v1 Announce Type: new 
Abstract: Every year, humanity loses about 1.5 million persons due to diabetic disease. Therefore continuous monitoring of diabetes is highly needed, but the conventional approach, i.e., fingertip pricking, causes mental and physical pain to the patient. This work introduces painless and cheaper non-invasive blood glucose level monitoring, Exploiting the advancement and huge progress in deep learning to develop a hybrid convolution neural network (CNN) - gate recurrent unit (GRU) network to hit the targeted system, The proposed system deploys CNN for extracting spatial patterns in the photoplethysmogram (PPG) signal and GRU is used for detecting the temporal patterns. The performance of the proposed system achieves a Mean Absolute Error (MAE) of 2.96 mg/dL, a mean square error (MSE) of 15.53 mg/dL, a root mean square Error (RMSE) of 3.94 mg/dL, and a coefficient of determination ($R^2$ score) of 0.97 on the test dataset. According to the Clarke Error Grid analysis, 100% of points fall within the clinically acceptable zone (Class A)</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11094v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Abdelrhman Y. Soliman, Ahmed M. Nor, Octavian Fratu, Simona Halunga, Osama A. Omer, Ahmed S. Mubark</dc:creator>
    </item>
    <item>
      <title>Robust and Constrained Estimation of State-Space Models: A Majorization-Minimization Approach</title>
      <link>https://arxiv.org/abs/2411.11320</link>
      <description>arXiv:2411.11320v1 Announce Type: new 
Abstract: In this paper, we present a novel optimization algorithm designed specifically for estimating state-space models to deal with heavy-tailed measurement noise and constraints. Our algorithm addresses two significant limitations found in existing approaches: susceptibility to measurement noise outliers and difficulties in incorporating constraints into state estimation. By formulating constrained state estimation as an optimization problem and employing the Majorization-Minimization (MM) approach, our framework provides a unified solution that enhances the robustness of the Kalman filter. Experimental results demonstrate high accuracy and computational efficiency achieved by our proposed approach, establishing it as a promising solution for robust and constrained state estimation in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11320v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Yu, Shengjie Xiu, Daniel P. Palomar</dc:creator>
    </item>
    <item>
      <title>Optimizing Clustered Cell-Free Networking for Sum Ergodic Capacity Maximization with Joint Processing Constraint</title>
      <link>https://arxiv.org/abs/2411.11499</link>
      <description>arXiv:2411.11499v1 Announce Type: new 
Abstract: Clustered cell-free networking has been considered as an effective scheme to trade off between the low complexity of current cellular networks and the superior performance of fully cooperative networks. With clustered cell-free networking, the wireless network is decomposed into a number of disjoint parallel operating subnetworks with joint processing adopted inside each subnetwork independently for intra-subnetwork interference mitigation. Different from the existing works that aim to maximize the number of subnetworks without considering the limited processing capability of base-stations (BSs), this paper investigates the clustered cell-free networking problem with the objective of maximizing the sum ergodic capacity while imposing a limit on the number of user equipments (UEs) in each subnetwork to constrain the joint processing complexity. By successfully transforming the combinatorial NP-hard clustered cell-free networking problem into an integer convex programming problem, the problem is solved by the branch-and-bound method. To further reduce the computational complexity, a bisection clustered cell-free networking (BC^2F-Net) algorithm is proposed to decompose the network hierarchically. Simulation results show that compared to the branch-and-bound based scheme, the proposed BC^2F-Net algorithm significantly reduces the computational complexity yet achieves nearly the same network decomposition result. Moreover, our BC^2F-Net algorithm achieves near-optimal performance and outperforms the state-of-the-art benchmarks with up to 25% capacity gain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11499v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Funing Xia, Junyuan Wang, Lin Dai</dc:creator>
    </item>
    <item>
      <title>Hybrid Data-Driven SSM for Interpretable and Label-Free mmWave Channel Prediction</title>
      <link>https://arxiv.org/abs/2411.11576</link>
      <description>arXiv:2411.11576v1 Announce Type: new 
Abstract: Accurate prediction of mmWave time-varying channels is essential for mitigating the issue of channel aging in complex scenarios owing to high user mobility. Existing channel prediction methods have limitations: classical model-based methods often struggle to track highly nonlinear channel dynamics due to limited expert knowledge, while emerging data-driven methods typically require substantial labeled data for effective training and often lack interpretability. To address these issues, this paper proposes a novel hybrid method that integrates a data-driven neural network into a conventional model-based workflow based on a state-space model (SSM), implicitly tracking complex channel dynamics from data without requiring precise expert knowledge. Additionally, a novel unsupervised learning strategy is developed to train the embedded neural network solely with unlabeled data. Theoretical analyses and ablation studies are conducted to interpret the enhanced benefits gained from the hybrid integration. Numerical simulations based on the 3GPP mmWave channel model corroborate the superior prediction accuracy of the proposed method, compared to state-of-the-art methods that are either purely model-based or data-driven. Furthermore, extensive experiments validate its robustness against various challenging factors, including among others severe channel variations and high noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11576v1</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yiyong Sun, Jiajun He, Zhidi Lin, Wenqiang Pu, Feng Yin, Hing Cheung So</dc:creator>
    </item>
    <item>
      <title>LiTformer: Efficient Modeling and Analysis of High-Speed Link Transmitters Using Non-Autoregressive Transformer</title>
      <link>https://arxiv.org/abs/2411.11699</link>
      <description>arXiv:2411.11699v1 Announce Type: new 
Abstract: High-speed serial links are fundamental to energy-efficient and high-performance computing systems such as artificial intelligence, 5G mobile and automotive, enabling low-latency and high-bandwidth communication. Transmitters (TXs) within these links are key to signal quality, while their modeling presents challenges due to nonlinear behavior and dynamic interactions with links. In this paper, we propose LiTformer: a Transformer-based model for high-speed link TXs, with a non-sequential encoder and a Transformer decoder to incorporate link parameters and capture long-range dependencies of output signals. We employ a non-autoregressive mechanism in model training and inference for parallel prediction of the signal sequence. LiTformer achieves precise TX modeling considering link impacts including crosstalk from multiple links, and provides fast prediction for various long-sequence signals with high data rates. Experimental results show that LiTformer achieves 148-456$\times$ speedup for 2-link TXs and 404-944$\times$ speedup for 16-link with mean relative errors of 0.68-1.25%, supporting 4-bit signals at Gbps data rates of single-ended and differential TXs, as well as PAM4 TXs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11699v1</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Songyu Sun, Xiao Dong, Yanliang Sha, Quan Chen, Cheng Zhuo</dc:creator>
    </item>
    <item>
      <title>Robust Communication Design in RIS-Assisted THz Channels</title>
      <link>https://arxiv.org/abs/2411.10524</link>
      <description>arXiv:2411.10524v1 Announce Type: cross 
Abstract: Terahertz (THz) communication offers the necessary bandwidth to meet the high data rate demands of next-generation wireless systems. However, it faces significant challenges, including severe path loss, dynamic blockages, and beam misalignment, which jeopardize communication reliability. Given that many 6G use cases require both high data rates and strong reliability, robust transmission schemes that achieve high throughput under these challenging conditions are essential for the effective use of high-frequency bands. In this context, we propose a novel mixed-criticality superposition coding scheme for reconfigurable intelligent surface (RIS)-assisted THz systems. This scheme leverages both the strong but intermittent direct line-of-sight link and the more reliable, yet weaker, RIS path to ensure robust delivery of high-criticality data while maintaining high overall throughput. We model a mixed-criticality queuing system and optimize transmit power to meet reliability and queue stability constraints. Simulation results show that our approach significantly reduces queuing delays for critical data while sustaining high overall throughput, outperforming conventional time-sharing methods. Additionally, we examine the impact of blockage, beam misalignment, and beamwidth adaptation on system performance. These results demonstrate that our scheme effectively balances reliability and throughput under challenging conditions, while also underscoring the need for robust beamforming techniques to mitigate the impact of misalignment in RIS-assisted channels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10524v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yasemin Karacora, Adam Umra, Aydin Sezgin</dc:creator>
    </item>
    <item>
      <title>Electrical Load Forecasting in Smart Grid: A Personalized Federated Learning Approach</title>
      <link>https://arxiv.org/abs/2411.10619</link>
      <description>arXiv:2411.10619v1 Announce Type: cross 
Abstract: Electric load forecasting is essential for power management and stability in smart grids. This is mainly achieved via advanced metering infrastructure, where smart meters (SMs) are used to record household energy consumption. Traditional machine learning (ML) methods are often employed for load forecasting but require data sharing which raises data privacy concerns. Federated learning (FL) can address this issue by running distributed ML models at local SMs without data exchange. However, current FL-based approaches struggle to achieve efficient load forecasting due to imbalanced data distribution across heterogeneous SMs. This paper presents a novel personalized federated learning (PFL) method to load prediction under non-independent and identically distributed (non-IID) metering data settings. Specifically, we introduce meta-learning, where the learning rates are manipulated using the meta-learning idea to maximize the gradient for each client in each global round. Clients with varying processing capacities, data sizes, and batch sizes can participate in global model aggregation and improve their local load forecasting via personalized learning. Simulation results show that our approach outperforms state-of-the-art ML and FL methods in terms of better load forecasting accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10619v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ratun Rahman, Neeraj Kumar, Dinh C. Nguyen</dc:creator>
    </item>
    <item>
      <title>Wireless Resource Allocation with Collaborative Distributed and Centralized DRL under Control Channel Attacks</title>
      <link>https://arxiv.org/abs/2411.10702</link>
      <description>arXiv:2411.10702v1 Announce Type: cross 
Abstract: In this paper, we consider a wireless resource allocation problem in a cyber-physical system (CPS) where the control channel, carrying resource allocation commands, is subjected to denial-of-service (DoS) attacks. We propose a novel concept of collaborative distributed and centralized (CDC) resource allocation to effectively mitigate the impact of these attacks. To optimize the CDC resource allocation policy, we develop a new CDC-deep reinforcement learning (DRL) algorithm, whereas existing DRL frameworks only formulate either centralized or distributed decision-making problems. Simulation results demonstrate that the CDC-DRL algorithm significantly outperforms state-of-the-art DRL benchmarks, showcasing its ability to address resource allocation problems in large-scale CPSs under control channel attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10702v1</guid>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ke Wang, Wanchun Liu, Teng Joon Lim</dc:creator>
    </item>
    <item>
      <title>Hybrid Attention Model Using Feature Decomposition and Knowledge Distillation for Glucose Forecasting</title>
      <link>https://arxiv.org/abs/2411.10703</link>
      <description>arXiv:2411.10703v1 Announce Type: cross 
Abstract: The availability of continuous glucose monitors as over-the-counter commodities have created a unique opportunity to monitor a person's blood glucose levels, forecast blood glucose trajectories and provide automated interventions to prevent devastating chronic complications that arise from poor glucose control. However, forecasting blood glucose levels is challenging because blood glucose changes consistently in response to food intake, medication intake, physical activity, sleep, and stress. It is particularly difficult to accurately predict BGL from multimodal and irregularly sampled data and over long prediction horizons. Furthermore, these forecasting models must operate in real-time on edge devices to provide in-the-moment interventions. To address these challenges, we propose GlucoNet, an AI-powered sensor system for continuously monitoring behavioral and physiological health and robust forecasting of blood glucose patterns. GlucoNet devises a feature decomposition-based transformer model that incorporates patients' behavioral and physiological data and transforms sparse and irregular patient data (e.g., diet and medication intake data) into continuous features using a mathematical model, facilitating better integration with the BGL data. Given the non-linear and non-stationary nature of BG signals, we propose a decomposition method to extract both low and high-frequency components from the BGL signals, thus providing accurate forecasting. To reduce the computational complexity, we also propose to employ knowledge distillation to compress the transformer model. GlucoNet achieves a 60% improvement in RMSE and a 21% reduction in the number of parameters, using data obtained involving 12 participants with T1-Diabetes. These results underscore GlucoNet's potential as a compact and reliable tool for real-world diabetes prevention and management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10703v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ebrahim Farahmand, Shovito Barua Soumma, Nooshin Taheri Chatrudi, Hassan Ghasemzadeh</dc:creator>
    </item>
    <item>
      <title>FlowScope: Enhancing Decision Making by Time Series Forecasting based on Prediction Optimization using HybridFlow Forecast Framework</title>
      <link>https://arxiv.org/abs/2411.10716</link>
      <description>arXiv:2411.10716v1 Announce Type: cross 
Abstract: Time series forecasting is crucial in several sectors, such as meteorology, retail, healthcare, and finance. Accurately forecasting future trends and patterns is crucial for strategic planning and making well-informed decisions. In this case, it is crucial to include many forecasting methodologies. The strengths of Auto-regressive Integrated Moving Average (ARIMA) for linear time series, Seasonal ARIMA models (SARIMA) for seasonal time series, Exponential Smoothing State Space Models (ETS) for handling errors and trends, and Long Short-Term Memory (LSTM) Neural Network model for complex pattern recognition have been combined to create a comprehensive framework called FlowScope. SARIMA excels in capturing seasonal variations, whereas ARIMA ensures effective handling of linear time series. ETS models excel in capturing trends and correcting errors, whereas LSTM networks excel in reflecting intricate temporal connections. By combining these methods from both machine learning and deep learning, we propose a deep-hybrid learning approach FlowScope which offers a versatile and robust platform for predicting time series data. This empowers enterprises to make informed decisions and optimize long-term strategies for maximum performance.
  Keywords: Time Series Forecasting, HybridFlow Forecast Framework, Deep-Hybrid Learning, Informed Decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10716v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nitin Sagar Boyeena, Begari Susheel Kumar</dc:creator>
    </item>
    <item>
      <title>On-device Anomaly Detection in Conveyor Belt Operations</title>
      <link>https://arxiv.org/abs/2411.10729</link>
      <description>arXiv:2411.10729v1 Announce Type: cross 
Abstract: Mining 4.0 leverages advancements in automation, digitalization, and interconnected technologies from Industry 4.0 to address the unique challenges of the mining sector, enhancing efficiency, safety, and sustainability. Conveyor belts are crucial in mining operations by enabling the continuous and efficient movement of bulk materials over long distances, which directly impacts productivity. While detecting anomalies in specific conveyor belt components, such as idlers, pulleys, and belt surfaces, has been widely studied, identifying the root causes of these failures remains critical due to factors like changing production conditions and operator errors. Continuous monitoring of mining conveyor belt work cycles for anomaly detection is still at an early stage and requires robust solutions. This study proposes two distinctive pattern recognition approaches for real-time anomaly detection in the operational cycles of mining conveyor belts, combining feature extraction, threshold-based cycle detection, and tiny machine-learning classification. Both approaches outperformed a state-of-the-art technique on two datasets for duty cycle classification in terms of F1-scores. The first approach, with 97.3% and 80.2% for normal and abnormal cycles, respectively, reaches the highest performance in the first dataset while the second approach excels on the second dataset, scoring 91.3% and 67.9%. Implemented on two low-power microcontrollers, the methods demonstrated efficient, real-time operation with energy consumption of 13.3 and 20.6 ${\mu}$J during inference. These results offer valuable insights for detecting mechanical failure sources, supporting targeted preventive maintenance, and optimizing production cycles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10729v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Luciano S. Martinez-Rau, Yuxuan Zhang, Bengt Oelmann, Sebastian Bader</dc:creator>
    </item>
    <item>
      <title>A Wearable Gait Monitoring System for 17 Gait Parameters Based on Computer Vision</title>
      <link>https://arxiv.org/abs/2411.10739</link>
      <description>arXiv:2411.10739v1 Announce Type: cross 
Abstract: We developed a shoe-mounted gait monitoring system capable of tracking up to 17 gait parameters, including gait length, step time, stride velocity, and others. The system employs a stereo camera mounted on one shoe to track a marker placed on the opposite shoe, enabling the estimation of spatial gait parameters. Additionally, a Force Sensitive Resistor (FSR) affixed to the heel of the shoe, combined with a custom-designed algorithm, is utilized to measure temporal gait parameters. Through testing on multiple participants and comparison with the gait mat, the proposed gait monitoring system exhibited notable performance, with the accuracy of all measured gait parameters exceeding 93.61%. The system also demonstrated a low drift of 4.89% during long-distance walking. A gait identification task conducted on participants using a trained Transformer model achieved 95.7% accuracy on the dataset collected by the proposed system, demonstrating that our hardware has the potential to collect long-sequence gait data suitable for integration with current Large Language Models (LLMs). The system is cost-effective, user-friendly, and well-suited for real-life measurements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10739v1</guid>
      <category>eess.SY</category>
      <category>cs.CV</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiangang Chen, Yung-Hong Sun, Kristen Pickett, Barbara King, Yu Hen Hu, Hongrui Jiang</dc:creator>
    </item>
    <item>
      <title>Steam Turbine Anomaly Detection: An Unsupervised Learning Approach Using Enhanced Long Short-Term Memory Variational Autoencoder</title>
      <link>https://arxiv.org/abs/2411.10765</link>
      <description>arXiv:2411.10765v1 Announce Type: cross 
Abstract: As core thermal power generation equipment, steam turbines incur significant expenses and adverse effects on operation when facing interruptions like downtime, maintenance, and damage. Accurate anomaly detection is the prerequisite for ensuring the safe and stable operation of steam turbines. However, challenges in steam turbine anomaly detection, including inherent anomalies, lack of temporal information analysis, and high-dimensional data complexity, limit the effectiveness of existing methods. To address these challenges, we proposed an Enhanced Long Short-Term Memory Variational Autoencoder using Deep Advanced Features and Gaussian Mixture Model (ELSTMVAE-DAF-GMM) for precise unsupervised anomaly detection in unlabeled datasets. Specifically, LSTMVAE, integrating LSTM with VAE, was used to project high-dimensional time-series data to a low-dimensional phase space. The Deep Autoencoder-Local Outlier Factor (DAE-LOF) sample selection mechanism was used to eliminate inherent anomalies during training, further improving the model's precision and reliability. The novel deep advanced features (DAF) hybridize latent embeddings and reconstruction discrepancies from the LSTMVAE model and provide a more comprehensive data representation within a continuous and structured phase space, significantly enhancing anomaly detection by synergizing temporal dynamics with data pattern variations. These DAF were incorporated into GMM to ensure robust and effective unsupervised anomaly detection. We utilized real operating data from industry steam turbines and conducted both comparison and ablation experiments, demonstrating superior anomaly detection outcomes characterized by high accuracy and minimal false alarm rates compared with existing methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10765v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weiming Xu, Peng Zhang</dc:creator>
    </item>
    <item>
      <title>Digital Twin for Advanced Network Planning: Tackling Interference</title>
      <link>https://arxiv.org/abs/2411.11034</link>
      <description>arXiv:2411.11034v1 Announce Type: cross 
Abstract: Operational data in next-generation networks offers a valuable resource for Mobile Network Operators to autonomously manage their systems and predict potential network issues. Machine Learning and Digital Twin can be applied to gain important insights for intelligent decision-making. This paper proposes a framework for Radio Frequency planning and failure detection using Digital Twin reducing the level of manual intervention. In this study, we propose a methodology for analyzing Radio Frequency issues as external interference employing clustering techniques in operational networks, and later incorporating this in the planning process. Simulation results demonstrate that the architecture proposed can improve planning operations through a data-aided anomaly detection strategy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11034v1</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Carlos Estrada-Jimenez, Valdemar Ramon Farre-Guijarro, Diana Carolina Alvarez-Paredes, Marie-Laure Watrinet</dc:creator>
    </item>
    <item>
      <title>Joint Precoding and AP Selection for Energy Efficient RIS-aided Cell-Free Massive MIMO Using Multi-agent Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2411.11070</link>
      <description>arXiv:2411.11070v1 Announce Type: cross 
Abstract: Cell-free (CF) massive multiple-input multiple-output (mMIMO) and reconfigurable intelligent surface (RIS) are two advanced transceiver technologies for realizing future sixth-generation (6G) networks. In this paper, we investigate the joint precoding and access point (AP) selection for energy efficient RIS-aided CF mMIMO system. To address the associated computational complexity and communication power consumption, we advocate for user-centric dynamic networks in which each user is served by a subset of APs rather than by all of them. Based on the user-centric network, we formulate a joint precoding and AP selection problem to maximize the energy efficiency (EE) of the considered system. To solve this complex nonconvex problem, we propose an innovative double-layer multi-agent reinforcement learning (MARL)-based scheme. Moreover, we propose an adaptive power threshold-based AP selection scheme to further enhance the EE of the considered system. To reduce the computational complexity of the RIS-aided CF mMIMO system, we introduce a fuzzy logic (FL) strategy into the MARL scheme to accelerate convergence. The simulation results show that the proposed FL-based MARL cooperative architecture effectively improves EE performance, offering a 85\% enhancement over the zero-forcing (ZF) method, and achieves faster convergence speed compared with MARL. It is important to note that increasing the transmission power of the APs or the number of RIS elements can effectively enhance the spectral efficiency (SE) performance, which also leads to an increase in power consumption, resulting in a non-trivial trade-off between the quality of service and EE performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11070v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enyu Shi, Jiayi Zhang, Ziheng Liu, Yiyang Zhu, Chau Yuen, Derrick Wing Kwan Ng, Marco Di Renzo, Bo Ai</dc:creator>
    </item>
    <item>
      <title>Low-Rank Conjugate Gradient-Net for Accelerated Cardiac MR Imaging</title>
      <link>https://arxiv.org/abs/2411.11175</link>
      <description>arXiv:2411.11175v1 Announce Type: cross 
Abstract: Cardiovascular diseases (CVDs) remain the leading cause of mortality and morbidity worldwide. Both diagnosis and prognosis of these diseases benefit from high-quality imaging, which cardiac magnetic resonance imaging provides. CMR imaging requires lengthy acquisition times and multiple breath-holds for a complete exam, which can lead to patient discomfort and frequently results in image artifacts. In this work, we present a Low-rank tensor U-Net method (LowRank-CGNet) that rapidly reconstructs highly undersampled data with a variety of anatomy, contrast, and undersampling artifacts. The model uses conjugate gradient data consistency to solve for the spatial and temporal bases and employs a U-Net to further regularize the basis vectors. Currently, model performance is superior to a standard U-Net, but inferior to conventional compressed sensing methods. In the future, we aim to further improve model performance by increasing the U-Net size, extending the training duration, and dynamically updating the tensor rank for different anatomies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11175v1</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jaykumar H. Patel, Brenden T. Kadota, Calder D. Sheagren, Mark Chiew, Graham A. Wright</dc:creator>
    </item>
    <item>
      <title>Uncovering the role of semantic and acoustic cues in normal and dichotic listening</title>
      <link>https://arxiv.org/abs/2411.11308</link>
      <description>arXiv:2411.11308v1 Announce Type: cross 
Abstract: Despite extensive research, the precise role of acoustic and semantic cues in complex speech perception tasks remains unclear. In this study, we propose a paradigm to understand the encoding of these cues in electroencephalogram (EEG) data, using match-mismatch (MM) classification task. The MM task involves determining whether the stimulus and response correspond to each other or not. We design a multi-modal sequence model, based on long short term memory (LSTM) architecture, to perform the MM task. The model is input with acoustic stimulus (derived from the speech envelope), semantic stimulus (derived from textual representations of the speech content), and neural response (derived from the EEG data). Our experiments are performed on two separate conditions, i) natural passive listening condition and, ii) an auditory attention based dichotic listening condition. Using the MM task as the analysis framework, we observe that - a) speech perception is fragmented based on word boundaries, b) acoustic and semantic cues offer similar levels of MM task performance in natural listening conditions, and c) semantic cues offer significantly improved MM classification over acoustic cues in dichotic listening task. Further, the study provides evidence of right ear advantage in dichotic listening conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11308v1</guid>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Akshara Soman, Sai Samrat Kankanala, Sriram Ganapathy</dc:creator>
    </item>
    <item>
      <title>Zero-Shot Load Forecasting with Large Language Models</title>
      <link>https://arxiv.org/abs/2411.11350</link>
      <description>arXiv:2411.11350v1 Announce Type: cross 
Abstract: Deep learning models have shown strong performance in load forecasting, but they generally require large amounts of data for model training before being applied to new scenarios, which limits their effectiveness in data-scarce scenarios. Inspired by the great success of pre-trained language models (LLMs) in natural language processing, this paper proposes a zero-shot load forecasting approach using an advanced LLM framework denoted as the Chronos model. By utilizing its extensive pre-trained knowledge, the Chronos model enables accurate load forecasting in data-scarce scenarios without the need for extensive data-specific training. Simulation results across five real-world datasets demonstrate that the Chronos model significantly outperforms nine popular baseline models for both deterministic and probabilistic load forecasting with various forecast horizons (e.g., 1 to 48 hours), even though the Chronos model is neither tailored nor fine-tuned to these specific load datasets. Notably, Chronos reduces root mean squared error (RMSE), continuous ranked probability score (CRPS), and quantile score (QS) by approximately 7.34%-84.30%, 19.63%-60.06%, and 22.83%-54.49%, respectively, compared to baseline models. These results highlight the superiority and flexibility of the Chronos model, positioning it as an effective solution in data-scarce scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11350v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Wenlong Liao, Zhe Yang, Mengshuo Jia, Christian Rehtanz, Jiannong Fang, Fernando Port\'e-Agel</dc:creator>
    </item>
    <item>
      <title>Fluid Antenna-Aided Rate-Splitting Multiple Access</title>
      <link>https://arxiv.org/abs/2411.11453</link>
      <description>arXiv:2411.11453v1 Announce Type: cross 
Abstract: This letter considers a fluid antenna system (FAS)-aided rate-splitting multiple access (RSMA) approach for downlink transmission. In particular, a base station (BS) equipped with a single traditional antenna system (TAS) uses RSMA signaling to send information to several mobile users (MUs) each equipped with FAS. To understand the achievable performance, we first present the distribution of the equivalent channel gain based on the joint multivariate t-distribution and then derive a compact analytical expression for the outage probability (OP). Moreover, we obtain the asymptotic OP in the high signal-to-noise ratio (SNR) regime. Numerical results show that combining FAS with RSMA significantly outperforms TAS and conventional multiple access schemes, such as non-orthogonal multiple access (NOMA), in terms of OP. The results also indicate that FAS can be the tool that greatly improves the practicality of RSMA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11453v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farshad Rostami Ghadi, Kai-Kit Wong, F. Javier Lopez-Martinez, Lajos Hanzo, Chan-Byoung Chae</dc:creator>
    </item>
    <item>
      <title>Channel Capacity-Aware Distributed Encoding for Multi-View Sensing and Edge Inference</title>
      <link>https://arxiv.org/abs/2411.11539</link>
      <description>arXiv:2411.11539v1 Announce Type: cross 
Abstract: Integrated sensing and communication (ISAC) unifies wireless communication and sensing by sharing spectrum and hardware, which often incurs trade-offs between two functions due to limited resources. However, this paper shifts focus to exploring the synergy between communication and sensing, using WiFi sensing as an exemplary scenario where communication signals are repurposed to probe the environment without dedicated sensing waveforms, followed by data uploading to the edge server for inference. While increased device participation enhances multi-view sensing data, it also imposes significant communication overhead between devices and the edge server. To address this challenge, we aim to maximize the sensing task performance, measured by mutual information, under the channel capacity constraint. The information-theoretic optimization problem is solved by the proposed ADE-MI, a novel framework that employs a two-stage optimization two-stage optimization approach: (1) adaptive distributed encoding (ADE) at the device, which ensures transmitted bits are most relevant to sensing tasks, and (2) multi-view Inference (MI) at the edge server, which orchestrates multi-view data from distributed devices. Our experimental results highlight the synergy between communication and sensing, showing that more frequent communication from WiFi access points to edge devices improves sensing inference accuracy. The proposed ADE-MI achieves 92\% recognition accuracy with over $10^4$-fold reduction in latency compared to schemes with raw data communication, achieving both high sensing inference accuracy and low communication latency simultaneously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11539v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingjie Yang, Guangming Liang, Dongzhu Liu, Lei Zhang, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>FERT: Real-Time Facial Expression Recognition with Short-Range FMCW Radar</title>
      <link>https://arxiv.org/abs/2411.11619</link>
      <description>arXiv:2411.11619v1 Announce Type: cross 
Abstract: This study proposes a novel approach for real-time facial expression recognition utilizing short-range Frequency-Modulated Continuous-Wave (FMCW) radar equipped with one transmit (Tx), and three receive (Rx) antennas. The system leverages four distinct modalities simultaneously: Range-Doppler images (RDIs), micro range-Doppler Images (micro-RDIs), range azimuth images (RAIs), and range elevation images (REIs). Our innovative architecture integrates feature extractor blocks, intermediate feature extractor blocks, and a ResNet block to accurately classify facial expressions into smile, anger, neutral, and no-face classes. Our model achieves an average classification accuracy of 98.91% on the dataset collected using a 60 GHz short-range FMCW radar. The proposed solution operates in real-time in a person-independent manner, which shows the potential use of low-cost FMCW radars for effective facial expression recognition in various applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11619v1</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sabri Mustafa Kahya, Muhammet Sami Yavuz, Eckehard Steinbach</dc:creator>
    </item>
    <item>
      <title>Wideband Ultrasonic Acoustic Underwater Channels: Measurements and Characterization</title>
      <link>https://arxiv.org/abs/2411.11726</link>
      <description>arXiv:2411.11726v1 Announce Type: cross 
Abstract: In this work we present the results of a measurement campaign carried out in the Mediterranean sea aimed at characterizing the underwater acoustic channel in a wideband at ultrasonic frequencies centered at 80 kHz with a width of 96 kHz, covering two octaves from 32 to 128 kHz. So far, these type of wideband measurements are not found in the literature. Periodic orthogonal frequency division multiplexing (OFMD) sounding signals using Zadoff-Chu sequences have been specially designed for this purpose. The collected data has been post-processed to estimate the time-variant impulse and frequency responses and relevant parameters for system design like the time coherence, bandwidth coherence, delay spread and Doppler bandwidth. The statistical behavior of the channel gain random fluctuation has also been analyzed. This information has been extracted for both the global channel and each path separately. The wide bandwidth of the measurements have allowed the characterization of the channel in a scarcely explored ultrasonic band with an accuracy that is far beyond what is reported in previous works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11726v1</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TVT.2020.2973495</arxiv:DOI>
      <arxiv:journal_reference>IEEE TRANSACTIONS ON VEHICULAR TECHNOLOGY, vo. 69, no. 4, pp. 4019 - 4032 , April 2020</arxiv:journal_reference>
      <dc:creator>Jes\'us L\'opez-Fern\'andez, Unai Fern\'andez-Plazaola, Jos\'e F. Par\'is, Luis D\'iez, Eduardo Martos-Naya</dc:creator>
    </item>
    <item>
      <title>Freezing of Gait Detection Using Gramian Angular Fields and Federated Learning from Wearable Sensors</title>
      <link>https://arxiv.org/abs/2411.11764</link>
      <description>arXiv:2411.11764v1 Announce Type: cross 
Abstract: Freezing of gait (FOG) is a debilitating symptom of Parkinson's disease (PD) that impairs mobility and safety. Traditional detection methods face challenges due to intra and inter-patient variability, and most systems are tested in controlled settings, limiting their real-world applicability. Addressing these gaps, we present FOGSense, a novel FOG detection system designed for uncontrolled, free-living conditions. It uses Gramian Angular Field (GAF) transformations and federated deep learning to capture temporal and spatial gait patterns missed by traditional methods. We evaluated our FOGSense system using a public PD dataset, 'tdcsfog'. FOGSense improves accuracy by 10.4% over a single-axis accelerometer, reduces failure points compared to multi-sensor systems, and demonstrates robustness to missing values. The federated architecture allows personalized model adaptation and efficient smartphone synchronization during off-peak hours, making it effective for long-term monitoring as symptoms evolve. Overall, FOGSense achieves a 22.2% improvement in F1-score compared to state-of-the-art methods, along with enhanced sensitivity for FOG episode detection. Code is available: https://github.com/shovito66/FOGSense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11764v1</guid>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Shovito Barua Soumma, S M Raihanul Alam, Rudmila Rahman, Umme Niraj Mahi, Sayyed Mostafa Mostafavi, Hassan Ghasemzadeh</dc:creator>
    </item>
    <item>
      <title>COST CA20120 INTERACT Framework of Artificial Intelligence Based Channel Modeling</title>
      <link>https://arxiv.org/abs/2411.11798</link>
      <description>arXiv:2411.11798v1 Announce Type: cross 
Abstract: Accurate channel models are the prerequisite for communication-theoretic investigations as well as system design. Channel modeling generally relies on statistical and deterministic approaches. However, there are still significant limits for the traditional modeling methods in terms of accuracy, generalization ability, and computational complexity. The fundamental reason is that establishing a quantified and accurate mapping between physical environment and channel characteristics becomes increasing challenging for modern communication systems. Here, in the context of COST CA20120 Action, we evaluate and discuss the feasibility and implementation of using artificial intelligence (AI) for channel modeling, and explore where the future of this field lies. Firstly, we present a framework of AI-based channel modeling to characterize complex wireless channels. Then, we highlight in detail some major challenges and present the possible solutions: i) estimating the uncertainty of AI-based channel predictions, ii) integrating prior knowledge of propagation to improve generalization capabilities, and iii) interpretable AI for channel modeling. We present and discuss illustrative numerical results to showcase the capabilities of AI-based channel modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.11798v1</guid>
      <category>cs.IT</category>
      <category>cs.AI</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruisi He, Nicola D. Cicco, Bo Ai, Mi Yang, Yang Miao, Mate Boban</dc:creator>
    </item>
    <item>
      <title>Asymptotics of Proximity Operator for Squared Loss and Performance Prediction of Nonconvex Sparse Signal Recovery</title>
      <link>https://arxiv.org/abs/2103.10300</link>
      <description>arXiv:2103.10300v3 Announce Type: replace 
Abstract: Proximal splitting-based convex optimization is a promising approach to linear inverse problems because we can use some prior knowledge of the unknown variables explicitly. An understanding of the behavior of the optimization algorithms would be important for the tuning of the parameters and the development of new algorithms. In this paper, we first analyze the asymptotic property of the proximity operator for the squared loss function, which appears in the update equations of some proximal splitting methods for linear inverse problems. Our analysis shows that the output of the proximity operator can be characterized with a scalar random variable in the large system limit. Moreover, we apply the asymptotic result to the prediction of optimization algorithms for compressed sensing. Simulation results demonstrate that the MSE performance of the Douglas-Rachford algorithm can be well predicted in compressed sensing with the $\ell_{1}$ optimization. We also examine the behavior of the prediction for the case with nonconvex smoothly clipped absolute deviation (SCAD) regularization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.10300v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ryo Hayakawa</dc:creator>
    </item>
    <item>
      <title>6G Positioning and Sensing Through the Lens of Sustainability, Inclusiveness, and Trustworthiness</title>
      <link>https://arxiv.org/abs/2309.13602</link>
      <description>arXiv:2309.13602v3 Announce Type: replace 
Abstract: 6G promises a paradigm shift by integrating positioning and sensing, enhancing not only the communication performance but also enabling location- and context-aware services. Historically, positioning and sensing were focused on cost and performance tradeoffs, implying an escalated demand for resources, such as radio, physical, and computational resources, for improved performance. However, 6G expands this perspective, embracing a set of broader values, namely sustainability, inclusiveness, and trustworthiness. From a joint industrial/academic perspective, this paper aims to shed light on these important value indicators and their relationship with the conventional key performance indicators in the context of positioning and sensing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13602v3</guid>
      <category>eess.SP</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henk Wymeersch, Hui Chen, Hao Guo, Musa Furkan Keskin, Bahare M. Khorsandi, Mohammad H. Moghaddam, Alejandro Ramirez, Kim Schindhelm, Athanasios Stavridis, Tommy Svensson, Vijaya Yajnanarayana</dc:creator>
    </item>
    <item>
      <title>ARNN: Attentive Recurrent Neural Network for Multi-channel EEG Signals to Identify Epileptic Seizures</title>
      <link>https://arxiv.org/abs/2403.03276</link>
      <description>arXiv:2403.03276v2 Announce Type: replace 
Abstract: Electroencephalography (EEG) is a widely used tool for diagnosing brain disorders due to its high temporal resolution, non-invasive nature, and affordability. Manual analysis of EEG is labor-intensive and requires expertise, making automatic EEG interpretation crucial for reducing workload and accurately assessing seizures. In epilepsy diagnosis, prolonged EEG monitoring generates extensive data, often spanning hours, days, or even weeks. While machine learning techniques for automatic EEG interpretation have advanced significantly in recent decades, there remains a gap in its ability to efficiently analyze large datasets with a balance of accuracy and computational efficiency. To address the challenges mentioned above, an Attention Recurrent Neural Network (ARNN) is proposed that can process a large amount of data efficiently and accurately. This ARNN cell recurrently applies attention layers along a sequence and has linear complexity with the sequence length and leverages parallel computation by processing multi-channel EEG signals rather than single-channel signals. In this architecture, the attention layer is a computational unit that efficiently applies self-attention and cross-attention mechanisms to compute a recurrent function over a wide number of state vectors and input signals. This framework is inspired in part by the attention layer and long short-term memory (LSTM) cells, but it scales this typical cell up by several orders to parallelize for multi-channel EEG signals. It inherits the advantages of attention layers and LSTM gate while avoiding their respective drawbacks. The model's effectiveness is evaluated through extensive experiments with heterogeneous datasets, including the CHB-MIT and UPenn and Mayo's Clinic datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03276v2</guid>
      <category>eess.SP</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Salim Rukhsar, Anil Kumar Tiwari</dc:creator>
    </item>
    <item>
      <title>Enhancing RSS-Based Visible Light Positioning by Optimal Calibrating the LED Tilt and Gain</title>
      <link>https://arxiv.org/abs/2404.18650</link>
      <description>arXiv:2404.18650v2 Announce Type: replace 
Abstract: This paper presents an optimal calibration scheme and a weighted least squares (LS) localization algorithm for received signal strength (RSS) based visible light positioning (VLP) systems, focusing on the often overlooked impact of light emitting diode (LED) tilt. By optimally calibrating LED tilt and gain, we significantly enhance VLP localization accuracy. Our algorithm outperforms both machine learning Gaussian processes (GPs) and traditional multilateration techniques. Against GPs, it achieves improvements of 58% and 74% in the 50th and 99th percentiles, respectively. When compared to multilateration, it reduces the 50th percentile error from 7.4 cm to 3.2 cm and the 99th percentile error from 25.7 cm to 11 cm. We introduce a low-complexity estimator for tilt and gain that meets the Cramer-Rao lower bound (CRLB) for the mean squared error (MSE), emphasizing its precision and efficiency. Further, we elaborate on optimal calibration measurement placement and refine the observation model to include residual calibration errors, thereby improving localization performance. The weighted LS algorithm's effectiveness is validated through simulations and real-world data, consistently outperforming GPs and multilateration, across various training set sizes and reducing outlier errors. Our findings underscore the critical role of LED tilt calibration in advancing VLP system accuracy and contribute to a more precise model for indoor positioning technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18650v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu, Nobby Stevens, Lieven De Strycker, Fran\c{c}ois Rottenberg</dc:creator>
    </item>
    <item>
      <title>LUT-boosted CDR and Equalization for Burst-mode 50/100 Gbit/s Bandwidth-limited Flexible PON</title>
      <link>https://arxiv.org/abs/2406.19856</link>
      <description>arXiv:2406.19856v2 Announce Type: replace 
Abstract: We proposed and experimentally demonstrated a look-up table boosted fast CDR and equalization scheme for the burst-mode 50/100 Gbps bandwidth-limited flexible PON, requiring no preamble for convergence and achieved the same bit error rate performance as in the case of long preambles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19856v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanlu Huang, Liyan Wu, Shangya Han, Kai Jin, Kun Xu, Yanni Ou</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Intelligent Surfaces for 6G Mobile Networks: An Industry R&amp;D Perspective</title>
      <link>https://arxiv.org/abs/2406.19868</link>
      <description>arXiv:2406.19868v4 Announce Type: replace 
Abstract: The reconfigurable intelligent surface (RIS) technology is a potential solution to enhance network capacity and coverage without significant investment in additional infrastructure in 6G networks. This work highlights the interest of the mobile communication industry in RIS, and discusses the development of liquid crystal-based RIS for improved energy efficiency and coverage in the millimeter-wave band. Furthermore, the paper discusses perspectives and insights from an industry R&amp;D point of view, addressing relevant use cases, technical requirements, implementation challenges, and practical considerations for RIS deployment optimization in the context of 6G networks. A hardware design of an RIS with liquid crystal at 28 GHz is presented. A propagation model for RIS as a new part of the system architecture is discussed, with approaches of semi-empirical models, geometric models, and their combination through the application of artificial intelligence/machine learning. Finally, a channel model for deployment optimization and dimensioning is presented, with the findings that a rather large RIS is favorable for coverage improvement, as well as greater attenuation at higher frequencies combined with a smaller RIS size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.19868v4</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ACCESS.2024.3485227</arxiv:DOI>
      <arxiv:journal_reference>IEEE Access, Volume: 12, Pages: 163155-163171, 2024</arxiv:journal_reference>
      <dc:creator>Maik Sode (Ericsson Antenna Technology Germany GmbH, Rosenheim, Germany), Michael Ponschab (Ericsson Antenna Technology Germany GmbH, Rosenheim, Germany), Lucas N. Ribeiro (Ericsson Antenna Technology Germany GmbH, Rosenheim, Germany), Sven Haesloop (Fraunhofer Heinrich-Hertz-Institut, Berlin, Germany), Ehsan Tohidi (Fraunhofer Heinrich-Hertz-Institut, Berlin, Germany, Network Information Theory, Technische Universit\"at Berlin, Berlin, Germany), Michael Peter (Fraunhofer Heinrich-Hertz-Institut, Berlin, Germany), S{\l}awomir Sta\'nczak (Fraunhofer Heinrich-Hertz-Institut, Berlin, Germany, Network Information Theory, Technische Universit\"at Berlin, Berlin, Germany), Bilal H. Mohamed (Department of High Frequency Systems, Technische Universit\"at Berlin, Berlin, Germany), Wilhelm Keusgen (Department of High Frequency Systems, Technische Universit\"at Berlin, Berlin, Germany), Heinz Mellein (Rohde &amp; Schwarz GmbH &amp; Co. KG, Munich, Germany), Eslam Yassin (brown-iposs GmbH, Bonn, Germany), Bernd Schroeder (brown-iposs GmbH, Bonn, Germany)</dc:creator>
    </item>
    <item>
      <title>The D-Subspace Algorithm for Online Learning over Distributed Networks</title>
      <link>https://arxiv.org/abs/2410.21320</link>
      <description>arXiv:2410.21320v2 Announce Type: replace 
Abstract: This material introduces the D-Subspace algorithm derived on the basis of the centralized algorithm [1], which originally addresses parameter estimation problems under a subspace constraint.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21320v2</guid>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yitong Chen, Danqi Jin, Jie Chen, Cedric Richard</dc:creator>
    </item>
    <item>
      <title>Splitting Messages in the Dark- Rate-Splitting Multiple Access for FDD Massive MIMO Without CSI Feedback</title>
      <link>https://arxiv.org/abs/2405.00979</link>
      <description>arXiv:2405.00979v2 Announce Type: replace-cross 
Abstract: A critical hindrance in realizing frequency division duplex (FDD) massive multi-input multi-output (MIMO) systems is the overhead associated with the downlink (DL) channel state information at the transmitter (CSIT) acquisition. To address this, we propose a novel framework that eliminates the need for CSI feedback, while achieving robust sum spectral efficiency (SE). Specifically, by leveraging partial frequency invariance of channel parameters, we reconstruct the DL CSIT using uplink (UL) pilots with the 2D-Newtonized orthogonal matching pursuit (2D-NOMP) algorithm. Due to discrepancies between the two disjoint bands, however, perfect DL CSIT acquisition is infeasible; resulting in multi-user interference (MUI). To account for this, we reformulate the sum SE maximization problem using the reconstructed channel and its error covariance matrix (ECM). Then, we propose an ECM estimation method based on the observed Fisher information matrix and introduce a precoder optimization technique with rate-splitting multiple access (RSMA). Our simulation results verify the validity of the proposed framework in the practical FDD massive MIMO scenarios, highlighting the essential role of ECM estimation in mitigating MUI to attain RSMA gains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00979v2</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Namhyun Kim, Ian P. Roberts, Jeonghun Park</dc:creator>
    </item>
    <item>
      <title>An Optimized Binning and Probabilistic Slice Sharing Algorithm for Motion Correction in Abdominal DW-MRI</title>
      <link>https://arxiv.org/abs/2409.00798</link>
      <description>arXiv:2409.00798v2 Announce Type: replace-cross 
Abstract: Diffusion-weighted magnetic resonance imaging (DW-MRI) is a powerful, non-invasive tool for detecting and characterizing abdominal lesions to facilitate early diagnosis, but respiratory motion during a scan reduces image quality and accuracy of quantitative biomarkers. Respiratory binning, which groups image slices into motion phase bins based on a navigator signal, can help mitigate motion artifacts. However, in DW-MRI, the standard binning technique often generates volumes with missing slices along the superior-inferior axis. Thus, longer scans are required to obtain volumes without gaps. In this study, we proposed a new binning technique to minimize missing slices without increasing scan time. We first designed an algorithm using dynamic programming and prefix sum approaches to optimize the initial binning of MR images. Then, we developed a probabilistic refinement phase, selecting some slices to belong in two neighboring bins to further reduce missing slices. We tested our two-phase technique on free-breathing abdominal DW-MRI scans from eight subjects, including one with tumors. The proposed technique significantly reduced missing slices compared to standard binning (p&lt;1.0*10-15), yielding an average reduction of 81.74+/-7.58%. Our technique also reduced motion artifacts, improving the conspicuity of malignant lesions. Apparent Diffusion Coefficient (ADC) maps generated from free-breathing scans corrected using the proposed technique had lower intra-subject variability compared to ADC maps from uncorrected free-breathing and shallow-breathing scans (p&lt;0.001). Additionally, ADC maps from shallow-breathing scans were more consistent with corrected free-breathing maps rather than uncorrected free-breathing maps (p&lt;0.01). The proposed technique corrects for motion while simultaneously reducing missing slices, allowing for shorter acquisition times compared to standard binning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.00798v2</guid>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michelle Su, Cemre Ariyurek, Serge Vasylechko, Onur Afacan, Sila Kurugol</dc:creator>
    </item>
    <item>
      <title>Self-supervised Multimodal Speech Representations for the Assessment of Schizophrenia Symptoms</title>
      <link>https://arxiv.org/abs/2409.09733</link>
      <description>arXiv:2409.09733v5 Announce Type: replace-cross 
Abstract: Multimodal schizophrenia assessment systems have gained traction over the last few years. This work introduces a schizophrenia assessment system to discern between prominent symptom classes of schizophrenia and predict an overall schizophrenia severity score. We develop a Vector Quantized Variational Auto-Encoder (VQ-VAE) based Multimodal Representation Learning (MRL) model to produce task-agnostic speech representations from vocal Tract Variables (TVs) and Facial Action Units (FAUs). These representations are then used in a Multi-Task Learning (MTL) based downstream prediction model to obtain class labels and an overall severity score. The proposed framework outperforms the previous works on the multi-class classification task across all evaluation metrics (Weighted F1 score, AUC-ROC score, and Weighted Accuracy). Additionally, it estimates the schizophrenia severity score, a task not addressed by earlier approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09733v5</guid>
      <category>eess.AS</category>
      <category>cs.SD</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gowtham Premananth, Carol Espy-Wilson</dc:creator>
    </item>
    <item>
      <title>Pre-Chirp-Domain Index Modulation for Full-Diversity Affine Frequency Division Multiplexing towards 6G</title>
      <link>https://arxiv.org/abs/2410.00313</link>
      <description>arXiv:2410.00313v3 Announce Type: replace-cross 
Abstract: Affine frequency division multiplexing (AFDM), tailored as a superior multicarrier technique utilizing chirp signals for high-mobility communications, is envisioned as a promising candidate for the sixth-generation (6G) wireless network. AFDM is based on the discrete affine Fourier transform (DAFT) with two adjustable parameters of the chirp signals, termed as the pre-chirp and post-chirp parameters, respectively. We show that the pre-chirp counterpart can be flexibly manipulated for additional degree-of-freedom (DoF). Therefore, this paper proposes a novel AFDM scheme with the pre-chirp index modulation (PIM) philosophy (AFDM-PIM), which can implicitly convey extra information bits through dynamic pre-chirp parameter assignment, thus enhancing both spectral and energy efficiency. Specifically, we first demonstrate that the subcarrier orthogonality is still maintained by applying distinct pre-chirp parameters to various subcarriers in the AFDM modulation process. Inspired by this property, each AFDM subcarrier is constituted with a unique pre-chirp signal according to the incoming bits. By such arrangement, extra binary bits can be embedded into the index patterns of pre-chirp parameter assignment without additional energy consumption. For performance analysis, we derive the asymptotically tight upper bounds on the average bit error rates (BERs) of the proposed schemes with maximum-likelihood (ML) detection, and validate that the proposed AFDM-PIM can achieve the optimal diversity order under doubly dispersive channels. Based on the derivations, we further propose an optimal pre-chirp alphabet design to enhance the BER performance via intelligent optimization algorithms. Simulations demonstrate that the proposed AFDM-PIM outperforms the classical benchmarks under doubly dispersive channel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00313v3</guid>
      <category>cs.IT</category>
      <category>eess.SP</category>
      <category>math.IT</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guangyao Liu, Tianqi Mao, Zhenyu Xiao, Miaowen Wen, Ruiqi Liu, Jingjing Zhao, Ertugrul Basar, Zhaocheng Wang, Sheng Chen</dc:creator>
    </item>
    <item>
      <title>Understanding Generalizability of Diffusion Models Requires Rethinking the Hidden Gaussian Structure</title>
      <link>https://arxiv.org/abs/2410.24060</link>
      <description>arXiv:2410.24060v3 Announce Type: replace-cross 
Abstract: In this work, we study the generalizability of diffusion models by looking into the hidden properties of the learned score functions, which are essentially a series of deep denoisers trained on various noise levels. We observe that as diffusion models transition from memorization to generalization, their corresponding nonlinear diffusion denoisers exhibit increasing linearity. This discovery leads us to investigate the linear counterparts of the nonlinear diffusion models, which are a series of linear models trained to match the function mappings of the nonlinear diffusion denoisers. Surprisingly, these linear denoisers are approximately the optimal denoisers for a multivariate Gaussian distribution characterized by the empirical mean and covariance of the training dataset. This finding implies that diffusion models have the inductive bias towards capturing and utilizing the Gaussian structure (covariance information) of the training dataset for data generation. We empirically demonstrate that this inductive bias is a unique property of diffusion models in the generalization regime, which becomes increasingly evident when the model's capacity is relatively small compared to the training dataset size. In the case that the model is highly overparameterized, this inductive bias emerges during the initial training phases before the model fully memorizes its training data. Our study provides crucial insights into understanding the notable strong generalization phenomenon recently observed in real-world diffusion models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.24060v3</guid>
      <category>cs.LG</category>
      <category>cs.CV</category>
      <category>eess.IV</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Xiang Li, Yixiang Dai, Qing Qu</dc:creator>
    </item>
    <item>
      <title>Enhancing Predictive Maintenance in Mining Mobile Machinery through a TinyML-enabled Hierarchical Inference Network</title>
      <link>https://arxiv.org/abs/2411.07168</link>
      <description>arXiv:2411.07168v2 Announce Type: replace-cross 
Abstract: Mining machinery operating in variable environments faces high wear and unpredictable stress, challenging Predictive Maintenance (PdM). This paper introduces the Edge Sensor Network for Predictive Maintenance (ESN-PdM), a hierarchical inference framework across edge devices, gateways, and cloud services for real-time condition monitoring. The system dynamically adjusts inference locations--on-device, on-gateway, or on-cloud--based on trade-offs among accuracy, latency, and battery life, leveraging Tiny Machine Learning (TinyML) techniques for model optimization on resource-constrained devices. Performance evaluations showed that on-sensor and on-gateway inference modes achieved over 90\% classification accuracy, while cloud-based inference reached 99\%. On-sensor inference reduced power consumption by approximately 44\%, enabling up to 104 hours of operation. Latency was lowest for on-device inference (3.33 ms), increasing when offloading to the gateway (146.67 ms) or cloud (641.71 ms). The ESN-PdM framework provides a scalable, adaptive solution for reliable anomaly detection and PdM, crucial for maintaining machinery uptime in remote environments. By balancing accuracy, latency, and energy consumption, this approach advances PdM frameworks for industrial applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07168v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <category>cs.MA</category>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Tue, 19 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ra\'ul de la Fuente, Luciano Radrigan, Anibal S Morales</dc:creator>
    </item>
  </channel>
</rss>
