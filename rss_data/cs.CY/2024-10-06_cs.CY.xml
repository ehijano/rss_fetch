<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CY updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CY</link>
    <description>cs.CY updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CY" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 07 Oct 2024 04:00:07 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Fundamentals of legislation for autonomous artificial intelligence systems</title>
      <link>https://arxiv.org/abs/2410.02769</link>
      <description>arXiv:2410.02769v1 Announce Type: new 
Abstract: The article proposes a method for forming a dedicated operational context in course of development and implementation of autonomous corporate management systems based on example of autonomous systems for a board of directors. The significant part of the operational context for autonomous company management systems is the regulatory and legal environment within which corporations operate. In order to create a special operational context for autonomous artificial intelligence systems, the wording of local regulatory documents can be simultaneously presented in two versions: for use by people and for use by autonomous systems. In this case, the artificial intelligence system will get a well-defined operational context that allows such a system to perform functions within the required standards. Local regulations that provide for the specifics of the joint work of individuals and autonomous artificial intelligence systems can create the basis of the relevant legislation governing the development and implementation of autonomous systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02769v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.21683/1729-2646-2024-24-3-10-17</arxiv:DOI>
      <arxiv:journal_reference>Dependability 2024;3:10-17</arxiv:journal_reference>
      <dc:creator>Anna Romanova</dc:creator>
    </item>
    <item>
      <title>OATH: Efficient and Flexible Zero-Knowledge Proofs of End-to-End ML Fairness</title>
      <link>https://arxiv.org/abs/2410.02777</link>
      <description>arXiv:2410.02777v1 Announce Type: new 
Abstract: Though there is much interest in fair AI systems, the problem of fairness noncompliance -- which concerns whether fair models are used in practice -- has received lesser attention. Zero-Knowledge Proofs of Fairness (ZKPoF) address fairness noncompliance by allowing a service provider to verify to external parties that their model serves diverse demographics equitably, with guaranteed confidentiality over proprietary model parameters and data. They have great potential for building public trust and effective AI regulation, but no previous techniques for ZKPoF are fit for real-world deployment. We present OATH, the first ZKPoF framework that is (i) deployably efficient with client-facing communication comparable to in-the-clear ML as a Service query answering, and an offline audit phase that verifies an asymptotically constant quantity of answered queries, (ii) deployably flexible with modularity for any score-based classifier given a zero-knowledge proof of correct inference, (iii) deployably secure with an end-to-end security model that guarantees confidentiality and fairness across training, inference, and audits. We show that OATH obtains strong robustness against malicious adversaries at concretely efficient parameter settings. Notably, OATH provides a 1343x improvement to runtime over previous work for neural network ZKPoF, and scales up to much larger models -- even DNNs with tens of millions of parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02777v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Olive Franzese, Ali Shahin Shamsabadi, Hamed Haddadi</dc:creator>
    </item>
    <item>
      <title>Enhancing ICT Literacy and Sustainable Practices in the Hospitality Industry: Insights from Mnquma Municipality</title>
      <link>https://arxiv.org/abs/2410.02781</link>
      <description>arXiv:2410.02781v1 Announce Type: new 
Abstract: The leisure and hospitality industry is a significant driver of the global economy, with the adoption of new technologies transforming service delivery and customer experience. Despite the transformative potential and benefits associated with adopting technology, there remains a low level of adoption in rural areas, particularly among small-scale players. This study explores the role of ICT literacy and sustainable practices in influencing ICT adoption among small-scale players in the hospitality industry in rural Eastern Cape Province, South Africa, specifically focusing on Mnquma Municipality. The study employs a non-probability sampling and purposive technique, utilising a case study research design within a positivist paradigm. A random sample of 21 small-scale players (BnBs, guest houses, and non-serviced accommodations) was selected, and data were collected through a face-to-face interview and questionnaire featuring closed-ended questions. The data were analysed using descriptive statistics and the Kruskal-Wallis H Test to examine differences in ICT usage levels. The test yielded a Kruskal-Wallis H of 2.57 with a p-value of 0.277. The findings reveal that businesses with more educated workforces demonstrate higher ICT adoption levels. Moreover, key factors such as ICT literacy, awareness of sustainable practices, access to ICT resources, and contextual challenges significantly impact ICT adoption. Recommendations include integrating ICT literacy and sustainability education into training programs and developing targeted policies and support mechanisms to enhance ICT integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02781v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jose Lukose, Abayomi Agbeyangi</dc:creator>
    </item>
    <item>
      <title>High School Summer Camps Help Democratize Coding, Data Science, and Deep Learning</title>
      <link>https://arxiv.org/abs/2410.02782</link>
      <description>arXiv:2410.02782v1 Announce Type: new 
Abstract: This study documents the impact of a summer camp series that introduces high school students to coding, data science, and deep learning. Hosted on-campus, the camps provide an immersive university experience, fostering technical skills, collaboration, and inspiration through interactions with mentors and faculty. Campers' experiences are documented through interviews and pre- and post-camp surveys. Key lessons include the importance of personalized feedback, diverse mentorship, and structured collaboration. Survey data reveals increased confidence in coding, with 68.6\% expressing interest in AI and data science careers. The camps also play a crucial role in addressing disparities in STEM education for underrepresented minorities. These findings underscore the value of such initiatives in shaping future technology education and promoting diversity in STEM fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02782v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rosemarie Santa Gonzalez, Tsion Fitsum, Michael Butros</dc:creator>
    </item>
    <item>
      <title>Enhancing Mental Health Support through Human-AI Collaboration: Toward Secure and Empathetic AI-enabled chatbots</title>
      <link>https://arxiv.org/abs/2410.02783</link>
      <description>arXiv:2410.02783v1 Announce Type: new 
Abstract: Access to mental health support remains limited, particularly in marginalized communities where structural and cultural barriers hinder timely care. This paper explores the potential of AI-enabled chatbots as a scalable solution, focusing on advanced large language models (LLMs)-GPT v4, Mistral Large, and LLama V3.1-and assessing their ability to deliver empathetic, meaningful responses in mental health contexts. While these models show promise in generating structured responses, they fall short in replicating the emotional depth and adaptability of human therapists. Additionally, trustworthiness, bias, and privacy challenges persist due to unreliable datasets and limited collaboration with mental health professionals. To address these limitations, we propose a federated learning framework that ensures data privacy, reduces bias, and integrates continuous validation from clinicians to enhance response quality. This approach aims to develop a secure, evidence-based AI chatbot capable of offering trustworthy, empathetic, and bias-reduced mental health support, advancing AI's role in digital mental health care.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02783v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rawan AlMakinah, Andrea Norcini-Pala, Lindsey Disney, M. Abdullah Canbaz</dc:creator>
    </item>
    <item>
      <title>TaCIE: Enhancing Instruction Comprehension in Large Language Models through Task-Centred Instruction Evolution</title>
      <link>https://arxiv.org/abs/2410.02795</link>
      <description>arXiv:2410.02795v1 Announce Type: new 
Abstract: Large Language Models (LLMs) require precise alignment with complex instructions to optimize their performance in real-world applications. As the demand for refined instruction tuning data increases, traditional methods that evolve simple seed instructions often struggle to effectively enhance complexity or manage difficulty scaling across various domains. Our innovative approach, Task-Centered Instruction Evolution (TaCIE), addresses these shortcomings by redefining instruction evolution from merely evolving seed instructions to a more dynamic and comprehensive combination of elements. TaCIE starts by deconstructing complex instructions into their fundamental components. It then generates and integrates new elements with the original ones, reassembling them into more sophisticated instructions that progressively increase in difficulty, diversity, and complexity. Applied across multiple domains, LLMs fine-tuned with these evolved instructions have substantially outperformed those tuned with conventional methods, marking a significant advancement in instruction-based model fine-tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02795v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiuding Yang, Shengyao Lu, Weidong Guo, Xiangyang Li, Kaitong Yang, Yu Xu, Di Niu</dc:creator>
    </item>
    <item>
      <title>A Data Envelopment Analysis Approach for Assessing Fairness in Resource Allocation: Application to Kidney Exchange Programs</title>
      <link>https://arxiv.org/abs/2410.02799</link>
      <description>arXiv:2410.02799v1 Announce Type: new 
Abstract: Kidney exchange programs have significantly increased transplantation rates but raise pressing questions about fairness in organ allocation. We present a novel framework leveraging Data Envelopment Analysis (DEA) to evaluate multiple fairness criteria--Priority, Access, and Outcome--within a single model, capturing complexities that may be overlooked in single-metric analyses. Using data from the United Network for Organ Sharing, we analyze these criteria individually, measuring Priority fairness through waitlist durations, Access fairness through Kidney Donor Profile Index scores, and Outcome fairness through graft lifespan. We then apply our DEA model to demonstrate significant disparities in kidney allocation efficiency across ethnic groups. To quantify uncertainty, we employ conformal prediction within the DEA framework, yielding group-conditional prediction intervals with finite sample coverage guarantees. Our findings show notable differences in efficiency distributions between ethnic groups. Our study provides a rigorous framework for evaluating fairness in complex resource allocation systems, where resource scarcity and mutual compatibility constraints exist. All code for using the proposed method and reproducing results is available on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02799v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Kaazempur-Mofrad, Xiaowu Dai</dc:creator>
    </item>
    <item>
      <title>Bushfire Severity Modelling and Future Trend Prediction Across Australia: Integrating Remote Sensing and Machine Learning</title>
      <link>https://arxiv.org/abs/2410.02963</link>
      <description>arXiv:2410.02963v1 Announce Type: new 
Abstract: Bushfire is one of the major natural disasters that cause huge losses to livelihoods and the environment. Understanding and analyzing the severity of bushfires is crucial for effective management and mitigation strategies, helping to prevent the extensive damage and loss caused by these natural disasters. This study presents an in-depth analysis of bushfire severity in Australia over the last twelve years, combining remote sensing data and machine learning techniques to predict future fire trends. By utilizing Landsat imagery and integrating spectral indices like NDVI, NBR, and Burn Index, along with topographical and climatic factors, we developed a robust predictive model using XGBoost. The model achieved high accuracy, 86.13%, demonstrating its effectiveness in predicting fire severity across diverse Australian ecosystems. By analyzing historical trends and integrating factors such as population density and vegetation cover, we identify areas at high risk of future severe bushfires. Additionally, this research identifies key regions at risk, providing data-driven recommendations for targeted firefighting efforts. The findings contribute valuable insights into fire management strategies, enhancing resilience to future fire events in Australia. Also, we propose future work on developing a UAV-based swarm coordination model to enhance fire prediction in real-time and firefighting capabilities in the most vulnerable regions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02963v1</guid>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shouthiri Partheepan, Farzad Sanati, Jahan Hassan</dc:creator>
    </item>
    <item>
      <title>Transforming Teachers' Roles and Agencies in the Era of Generative AI: Perceptions, Acceptance, Knowledge, and Practices</title>
      <link>https://arxiv.org/abs/2410.03018</link>
      <description>arXiv:2410.03018v1 Announce Type: new 
Abstract: This paper explores the transformative impact of Generative Artificial Intelligence (GenAI) on teachers' roles and agencies in education, presenting a comprehensive framework that addresses teachers' perceptions, knowledge, acceptance, and practices of GenAI. As GenAI technologies, such as ChatGPT, become increasingly integrated into educational settings, teachers are required to adapt to evolving classroom dynamics, where AI plays a significant role in content creation, personalized learning, and student engagement. However, existing literature often treats these factors in isolation, overlooking how they collectively influence teachers' ability to effectively integrate GenAI into their pedagogical practices. This paper fills this gap by proposing a framework that categorizes teachers into four roles -- Observer, Adopter, Collaborator, and Innovator -- each representing different levels of GenAI engagement, outlining teachers' agencies in GenAI classrooms. By highlighting the need for continuous professional development and institutional support, we demonstrate how teachers can evolve from basic GenAI users to co-creators of knowledge alongside GenAI systems. The findings emphasize that for GenAI to reach its full educational potential, teachers must not only accept and understand its capabilities but also integrate it deeply into their teaching strategies. This study contributes to the growing literature on GenAI in education, offering practical implications for supporting teachers in navigating the complexities of GenAI adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03018v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoming Zhai</dc:creator>
    </item>
    <item>
      <title>Integrating Natural Language Prompting Tasks in Introductory Programming Courses</title>
      <link>https://arxiv.org/abs/2410.03063</link>
      <description>arXiv:2410.03063v1 Announce Type: new 
Abstract: Introductory programming courses often emphasize mastering syntax and basic constructs before progressing to more complex and interesting programs. This bottom-up approach can be frustrating for novices, shifting the focus away from problem solving and potentially making computing less appealing to a broad range of students. The rise of generative AI for code production could partially address these issues by fostering new skills via interaction with AI models, including constructing high-level prompts and evaluating code that is automatically generated. In this experience report, we explore the inclusion of two prompt-focused activities in an introductory course, implemented across four labs in a six-week module. The first requires students to solve computational problems by writing natural language prompts, emphasizing problem-solving over syntax. The second involves students crafting prompts to generate code equivalent to provided fragments, to foster an understanding of the relationship between prompts and code. Most of the students in the course had reported finding programming difficult to learn, often citing frustrations with syntax and debugging. We found that self-reported difficulty with learning programming had a strong inverse relationship with performance on traditional programming assessments such as tests and projects, as expected. However, performance on the natural language tasks was less strongly related to self-reported difficulty, suggesting they may target different skills. Learning how to communicate with AI coding models is becoming an important skill, and natural language prompting tasks may appeal to a broad range of students.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03063v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chris Kerslake, Paul Denny, David H Smith IV, James Prather, Juho Leinonen, Andrew Luxton-Reilly, Stephen MacNeil</dc:creator>
    </item>
    <item>
      <title>Strategic Insights from Simulation Gaming of AI Race Dynamics</title>
      <link>https://arxiv.org/abs/2410.03092</link>
      <description>arXiv:2410.03092v1 Announce Type: new 
Abstract: We present insights from "Intelligence Rising", a scenario exploration exercise about possible AI futures. Drawing on the experiences of facilitators who have overseen 43 games over a four-year period, we illuminate recurring patterns, strategies, and decision-making processes observed during gameplay. Our analysis reveals key strategic considerations about AI development trajectories in this simulated environment, including: the destabilising effects of AI races, the crucial role of international cooperation in mitigating catastrophic risks, the challenges of aligning corporate and national interests, and the potential for rapid, transformative change in AI capabilities. We highlight places where we believe the game has been effective in exposing participants to the complexities and uncertainties inherent in AI governance. Key recurring gameplay themes include the emergence of international agreements, challenges to the robustness of such agreements, the critical role of cybersecurity in AI development, and the potential for unexpected crises to dramatically alter AI trajectories. By documenting these insights, we aim to provide valuable foresight for policymakers, industry leaders, and researchers navigating the complex landscape of AI development and governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03092v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ross Gruetzemacher, Shahar Avin, James Fox, Alexander K Saeri</dc:creator>
    </item>
    <item>
      <title>Examining Racial Stereotypes in YouTube Autocomplete Suggestions</title>
      <link>https://arxiv.org/abs/2410.03102</link>
      <description>arXiv:2410.03102v1 Announce Type: new 
Abstract: Autocomplete is a popular search feature that predicts queries based on user input and guides users to a set of potentially relevant suggestions. In this study, we examine how YouTube autocompletes serve as an information source for users exploring information about race. We perform an algorithm output audit of autocomplete suggestions for input queries about four racial groups and examine the stereotypes they embody. Using critical discourse analysis, we identify five major sociocultural contexts in which racial biases manifest -- Appearance, Ability, Culture, Social Equity, and Manner. Our results show evidence of aggregated discrimination and interracial tensions in the autocompletes we collected and highlight their potential risks in othering racial minorities. We call for urgent innovations in content moderation policy design and enforcement to address these biases in search outputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03102v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eunbin Ha, Haein Kong, Shagun Jhaver</dc:creator>
    </item>
    <item>
      <title>Computational Diplomacy: How "hackathons for good" feed a participatory future for multilateralism in the digital age</title>
      <link>https://arxiv.org/abs/2410.03286</link>
      <description>arXiv:2410.03286v1 Announce Type: new 
Abstract: This article explores the role of hackathons for good in building a community of software and hardware developers focused on addressing global SDG challenges. We theorise this movement as computational diplomacy: a decentralised, participatory process for digital governance that leverages collective intelligence to tackle major global issues. Analysing Devpost and GitHub data reveals that 30% of hackathons since 2010 have addressed SDG topics, employing diverse technologies to create innovative solutions. Hackathons serve as crucial kairos moments, sparking innovation bursts that drive both immediate project outcomes and long-term production. We propose that these events harness the neurobiological basis of human cooperation and empathy, fostering a collective sense of purpose and reducing interpersonal prejudice. This bottom-up approach to digital governance integrates software development, human collective intelligence, and collective action, creating a dynamic model for transformative change. By leveraging kairos moments, computational diplomacy promotes a more inclusive and effective model for digital multilateral governance of the future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03286v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Thomas Maillart, Lucia Gomez, Ewa Lombard, Alexander Nolte, Francesco Pisano</dc:creator>
    </item>
    <item>
      <title>Evaluation of Study Plans using Partial Orders</title>
      <link>https://arxiv.org/abs/2410.03314</link>
      <description>arXiv:2410.03314v1 Announce Type: new 
Abstract: In higher education, data is collected that indicate the term(s) that a course is taken and when it is passed. Often, study plans propose a suggested course order to students. Study planners can adjust these based on detected deviations between the proposed and actual order of the courses being taken. In this work, we detect deviations by combining (1) the deviation between the proposed and actual course order with (2) the temporal difference between the expected and actual course-taking term(s). Partially ordered alignments identify the deviations between the proposed and actual order. We compute a partial order alignment by modeling a study plan as a process model and a student's course-taking behavior as a partial order. Using partial orders in such use cases allows one to relax the constraints of strictly ordered traces. This makes our approach less prone to the order in which courses are offered. Further, when modeling course-taking behavior as partial orders, we propose distinguishing intended course-taking behavior from actual course-passing behavior of students by including either all terms in which a course is attempted or only the term that a course is passed, respectively. This provides more perspectives when comparing the proposed and actual course-taking behavior. The proposed deviation measuring approach is evaluated on real-life data from RWTH Aachen University.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03314v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Christian Rennert, Mahsa Pourbafrani, Wil van der Aalst</dc:creator>
    </item>
    <item>
      <title>Chronic Disease Diagnoses Using Behavioral Data</title>
      <link>https://arxiv.org/abs/2410.03386</link>
      <description>arXiv:2410.03386v1 Announce Type: new 
Abstract: Early detection of chronic diseases is beneficial to healthcare by providing a golden opportunity for timely interventions. Although numerous prior studies have successfully used machine learning (ML) models for disease diagnoses, they highly rely on medical data, which are scarce for most patients in the early stage of the chronic diseases. In this paper, we aim to diagnose hyperglycemia (diabetes), hyperlipidemia, and hypertension (collectively known as 3H) using own collected behavioral data, thus, enable the early detection of 3H without using medical data collected in clinical settings. Specifically, we collected daily behavioral data from 629 participants over a 3-month study period, and trained various ML models after data preprocessing. Experimental results show that only using the participants' uploaded behavioral data, we can achieve accurate 3H diagnoses: 80.2\%, 71.3\%, and 81.2\% for diabetes, hyperlipidemia, and hypertension, respectively. Furthermore, we conduct Shapley analysis on the trained models to identify the most influential features for each type of diseases. The identified influential features are consistent with those reported in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03386v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Di Wang, Yidan Hu, Eng Sing Lee, Hui Hwang Teong, Ray Tian Rui Lai, Wai Han Hoi, Chunyan Miao</dc:creator>
    </item>
    <item>
      <title>Promoting the Culture of Qinhuai River Lantern Shadow Puppetry with a Digital Archive and Immersive Experience</title>
      <link>https://arxiv.org/abs/2410.03532</link>
      <description>arXiv:2410.03532v1 Announce Type: new 
Abstract: As an intangible cultural heritage, Chinese shadow puppetry is facing challenges in terms of its appeal and comprehension, especially among audiences from different cultural backgrounds. Additionally, the fragile materials of the puppets and obstacles to preservation pose further challenges. This study creates a digital archive of the Qinhuai River Lantern Festival shadow puppetry, utilizing digital technology to recreate scenes depicted in traditional Chinese poetry and painting. Moreover, this study employs a mixed-method approach, combining qualitative and quantitative methods, to evaluate the acceptance and audience experience of immersive shadow puppetry. An in-depth exploration was conducted from sensory, emotional, cultural dimensions and research hypotheses were tested using structural equation modeling and other methods. The results indicate that enhancing ease of use and cultural experience can improve audience appeal and comprehension, while enhancing emotional experience can increase audience participation intention. Our research holds profound significance for the preservation and transmission of shadow puppetry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03532v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuanfang Liu</dc:creator>
    </item>
    <item>
      <title>Management of high-tech companies in conditions of import substitution</title>
      <link>https://arxiv.org/abs/2410.03610</link>
      <description>arXiv:2410.03610v1 Announce Type: new 
Abstract: The article analyzes the development of high-tech sectors of the Russian economy in the context of import substitution. Features of managing priority project portfolios are considered. Issues of creating a unified information space for aviation industry enterprises are studied in the context of introduction of a modified OLAP technology of management decision support. Investment attractiveness of high-tech sectors of the Russian economy is estimated based on the coefficient of gross value added of project products. Investment-overheated industries are identified, and recommendations on market correction and returning project assets to a balanced state are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03610v1</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>S. E. Pyatovsky, N. S. Efimova, E. V. Surkova</dc:creator>
    </item>
    <item>
      <title>Overcoming Representation Bias in Fairness-Aware data Repair using Optimal Transport</title>
      <link>https://arxiv.org/abs/2410.02840</link>
      <description>arXiv:2410.02840v1 Announce Type: cross 
Abstract: Optimal transport (OT) has an important role in transforming data distributions in a manner which engenders fairness. Typically, the OT operators are learnt from the unfair attribute-labelled data, and then used for their repair. Two significant limitations of this approach are as follows: (i) the OT operators for underrepresented subgroups are poorly learnt (i.e. they are susceptible to representation bias); and (ii) these OT repairs cannot be effected on identically distributed but out-of-sample (i.e.\ archival) data. In this paper, we address both of these problems by adopting a Bayesian nonparametric stopping rule for learning each attribute-labelled component of the data distribution. The induced OT-optimal quantization operators can then be used to repair the archival data. We formulate a novel definition of the fair distributional target, along with quantifiers that allow us to trade fairness against damage in the transformed data. These are used to reveal excellent performance of our representation-bias-tolerant scheme in simulated and benchmark data sets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02840v1</guid>
      <category>cs.LG</category>
      <category>cs.CY</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abigail Langbridge, Anthony Quinn, Robert Shorten</dc:creator>
    </item>
    <item>
      <title>Pseudo-Automation: How Labor-Offsetting Technologies Reconfigure Roles and Relationships in Frontline Retail Work</title>
      <link>https://arxiv.org/abs/2410.02888</link>
      <description>arXiv:2410.02888v1 Announce Type: cross 
Abstract: Self-service machines are a form of pseudo-automation; rather than actually automate tasks, they offset them to unpaid customers. Typically implemented for customer convenience and to reduce labor costs, self-service is often criticized for worsening customer service and increasing loss and theft for retailers. Though millions of frontline service workers continue to interact with these technologies on a day-to-day basis, little is known about how these machines change the nature of frontline labor. Through interviews with current and former cashiers who work with self-checkout technologies, we investigate how technology that offsets labor from an employee to a customer can reconfigure frontline work. We find three changes to cashiering tasks as a result of self-checkout: (1) Working at self-checkout involved parallel demands from multiple customers, (2) self-checkout work was more problem-oriented (including monitoring and policing customers), and (3) traditional checkout began to become more demanding as easier transactions were filtered to self-checkout. As their interactions with customers became more focused on problem solving and rule enforcement, cashiers were often positioned as adversaries to customers at self-checkout. To cope with perceived adversarialism, cashiers engaged in a form of relational patchwork, using techniques like scapegoating the self-checkout machine and providing excessive customer service in order to maintain positive customer interactions in the face of potential conflict. Our findings highlight how even under pseudo-automation, workers must engage in relational work to manage and mend negative human-to-human interactions so that machines can be properly implemented in context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02888v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pegah Moradi, Karen Levy, Cristobal Cheyre</dc:creator>
    </item>
    <item>
      <title>LLMCO2: Advancing Accurate Carbon Footprint Prediction for LLM Inferences</title>
      <link>https://arxiv.org/abs/2410.02950</link>
      <description>arXiv:2410.02950v1 Announce Type: cross 
Abstract: Throughout its lifecycle, a large language model (LLM) generates a substantially larger carbon footprint during inference than training. LLM inference requests vary in batch size, prompt length, and token generation number, while cloud providers employ different GPU types and quantities to meet diverse service-level objectives for accuracy and latency. It is crucial for both users and cloud providers to have a tool that quickly and accurately estimates the carbon impact of LLM inferences based on a combination of inference request and hardware configurations before execution. Estimating the carbon footprint of LLM inferences is more complex than training due to lower and highly variable model FLOPS utilization, rendering previous equation-based models inaccurate. Additionally, existing machine learning (ML) prediction methods either lack accuracy or demand extensive training data, as they inadequately handle the distinct prefill and decode phases, overlook hardware-specific features, and inefficiently sample uncommon inference configurations. We introduce \coo, a graph neural network (GNN)-based model that greatly improves the accuracy of LLM inference carbon footprint predictions compared to previous methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.02950v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhenxiao Fu, Fan Chen, Shan Zhou, Haitong Li, Lei Jiang</dc:creator>
    </item>
    <item>
      <title>CounterQuill: Investigating the Potential of Human-AI Collaboration in Online Counterspeech Writing</title>
      <link>https://arxiv.org/abs/2410.03032</link>
      <description>arXiv:2410.03032v1 Announce Type: cross 
Abstract: Online hate speech has become increasingly prevalent on social media platforms, causing harm to individuals and society. While efforts have been made to combat this issue through content moderation, the potential of user-driven counterspeech as an alternative solution remains underexplored. Existing counterspeech methods often face challenges such as fear of retaliation and skill-related barriers. To address these challenges, we introduce CounterQuill, an AI-mediated system that assists users in composing effective and empathetic counterspeech. CounterQuill provides a three-step process: (1) a learning session to help users understand hate speech and counterspeech; (2) a brainstorming session that guides users in identifying key elements of hate speech and exploring counterspeech strategies; and (3) a co-writing session that enables users to draft and refine their counterspeech with CounterQuill. We conducted a within-subjects user study with 20 participants to evaluate CounterQuill in comparison to ChatGPT. Results show that CounterQuill's guidance and collaborative writing process provided users a stronger sense of ownership over their co-authored counterspeech. Users perceived CounterQuill as a writing partner and thus were more willing to post the co-written counterspeech online compared to the one written with ChatGPT.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03032v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaohan Ding, Kaike Ping, Uma Sushmitha Gunturi, Buse Carik, Sophia Stil, Lance T Wilhelm, Taufiq Daryanto, James Hawdon, Sang Won Lee, Eugenia H Rho</dc:creator>
    </item>
    <item>
      <title>The Potential of Citizen Platforms for Requirements Engineering of Large Socio-Technical Software Systems</title>
      <link>https://arxiv.org/abs/2410.03195</link>
      <description>arXiv:2410.03195v1 Announce Type: cross 
Abstract: Participatory citizen platforms are innovative solutions to digitally better engage citizens in policy-making and deliberative democracy in general. Although these platforms have been used also in an engineering context, thus far, there is no existing work for connecting the platforms to requirements engineering. The present paper fills this notable gap. In addition to discussing the platforms in conjunction with requirements engineering, the paper elaborates potential advantages and disadvantages, thus paving the way for a future pilot study in a software engineering context. With these engineering tenets, the paper also contributes to the research of large socio-technical software systems in a public sector context, including their implementation and governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03195v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jukka Ruohonen, Kalle Hjerppe</dc:creator>
    </item>
    <item>
      <title>Five Years of COVID-19 Discourse on Instagram: A Labeled Instagram Dataset of Over Half a Million Posts for Multilingual Sentiment Analysis</title>
      <link>https://arxiv.org/abs/2410.03293</link>
      <description>arXiv:2410.03293v1 Announce Type: cross 
Abstract: The work presented in this paper makes three scientific contributions with a specific focus on mining and analysis of COVID-19-related posts on Instagram. First, it presents a multilingual dataset of 500,153 Instagram posts about COVID-19 published between January 2020 and September 2024. This dataset, available at https://dx.doi.org/10.21227/d46p-v480, contains Instagram posts in 161 different languages as well as 535,021 distinct hashtags. After the development of this dataset, multilingual sentiment analysis was performed, which involved classifying each post as positive, negative, or neutral. The results of sentiment analysis are presented as a separate attribute in this dataset. Second, it presents the results of performing sentiment analysis per year from 2020 to 2024. The findings revealed the trends in sentiment related to COVID-19 on Instagram since the beginning of the pandemic. For instance, between 2020 and 2024, the sentiment trends show a notable shift, with positive sentiment decreasing from 38.35% to 28.69%, while neutral sentiment rising from 44.19% to 58.34%. Finally, the paper also presents findings of language-specific sentiment analysis. This analysis highlighted similar and contrasting trends of sentiment across posts published in different languages on Instagram. For instance, out of all English posts, 49.68% were positive, 14.84% were negative, and 35.48% were neutral. In contrast, among Hindi posts, 4.40% were positive, 57.04% were negative, and 38.56% were neutral, reflecting distinct differences in the sentiment distribution between these two languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03293v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nirmalya Thakur</dc:creator>
    </item>
    <item>
      <title>Multidimensional Human Activity Recognition With Large Language Model: A Conceptual Framework</title>
      <link>https://arxiv.org/abs/2410.03546</link>
      <description>arXiv:2410.03546v1 Announce Type: cross 
Abstract: In high-stake environments like emergency response or elder care, the integration of large language model (LLM), revolutionize risk assessment, resource allocation, and emergency responses in Human Activity Recognition (HAR) systems by leveraging data from various wearable sensors. We propose a conceptual framework that utilizes various wearable devices, each considered as a single dimension, to support a multidimensional learning approach within HAR systems. By integrating and processing data from these diverse sources, LLMs can process and translate complex sensor inputs into actionable insights. This integration mitigates the inherent uncertainties and complexities associated with them, and thus enhancing the responsiveness and effectiveness of emergency services. This paper sets the stage for exploring the transformative potential of LLMs within HAR systems in empowering emergency workers to navigate the unpredictable and risky environments they encounter in their critical roles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.03546v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Syed Mhamudul Hasan</dc:creator>
    </item>
    <item>
      <title>Tool-Assisted Learning of Computational Reductions</title>
      <link>https://arxiv.org/abs/2407.18215</link>
      <description>arXiv:2407.18215v2 Announce Type: replace 
Abstract: Computational reductions are an important and powerful concept in computer science. However, they are difficult for many students to grasp. In this paper, we outline a concept for how the learning of reductions can be supported by educational support systems. We present an implementation of the concept within such a system, concrete web-based and interactive learning material for reductions, and report on our experiences using the material in a large introductory course on theoretical computer science.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.18215v2</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tristan Kneisel, Elias Radtke, Marko Schmellenkamp, Fabian Vehlken, Thomas Zeume</dc:creator>
    </item>
    <item>
      <title>Cyber Food Swamps: Investigating the Impacts of Online-to-Offline Food Delivery Platforms on Healthy Food Choices</title>
      <link>https://arxiv.org/abs/2409.16601</link>
      <description>arXiv:2409.16601v2 Announce Type: replace 
Abstract: Online-to-offline (O2O) food delivery platforms have substantially enriched the food choices of urban residents by allowing them to conveniently access farther food outlets. However, concerns about the healthiness of delivered food persist, especially because the impact of O2O food delivery platforms on users' healthy food choices remains unclear. This study leverages large-scale empirical data from a leading O2O delivery platform to comprehensively analyze online food choice behaviors and how they are influenced by the online exposure to fast food restaurants, i.e., online food environment. Our analyses reveal significant discrepancy in food preferences across demographic groups and city sizes, where male, low-income, and younger users and those located in larger cities more likely to order fast food via O2O platforms. Besides, we also perform a comparative analysis on the food exposure differences in online and offline environments, confirming that the extended service ranges of O2O platforms can create larger "cyber food swamps". Furthermore, regression analysis highlights that a higher ratio of fast food orders is associated with "cyber food swamps", areas characterized by a higher share of accessible fast food restaurants. A 10% increase in this share raises the probability of ordering fast food by 22.0%. Moreover, a quasi-natural experiment substantiates the long-term causal effect of online food environment changes on healthy food choices. Our findings underscore the need for O2O food delivery platforms to address the health implications of online food choice exposure, thereby informing efforts by various stakeholders to improve residents' dietary health.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.16601v2</guid>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yunke Zhang, Yiran Fan, Peijie Liu, Fengli Xu, Yong Li</dc:creator>
    </item>
    <item>
      <title>Private Blotto: Viewpoint Competition with Polarized Agents</title>
      <link>https://arxiv.org/abs/2302.14123</link>
      <description>arXiv:2302.14123v3 Announce Type: replace-cross 
Abstract: Social media platforms are responsible for collecting and disseminating vast quantities of content. Recently, however, they have also begun enlisting users in helping annotate this content - for example, to provide context or label disinformation. However, users may act strategically, sometimes reflecting biases (e.g. political) about the "right" label. How can social media platforms design their systems to use human time most efficiently? Historically, competition over multiple items has been explored in the Colonel Blotto game setting (Borel, 1921). However, they were originally designed to model two centrally-controlled armies competing over zero-sum "items", a specific scenario with limited modern-day application. In this work, we propose and study the Private Blotto game, a variant with the key difference that individual agents act independently, without being coordinated by a central "Colonel". We completely characterize the Nash stability of this game and how this impacts the amount of "misallocated effort" of users on unimportant items. We show that the outcome function (aggregating multiple labels on a single item) has a critical impact, and specifically contrast a majority rule outcome (the median) as compared to a smoother outcome function (mean). In general, for median outcomes we show that instances without stable arrangements only occur for relatively few numbers of agents, but stable arrangements may have very high levels of misallocated effort. For mean outcome functions, we show that unstable arrangements can occur even for arbitrarily large numbers of agents, but when stable arrangements exist, they always have low misallocated effort. We conclude by discussing implications our results have for motivating examples in social media platforms and political competition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.14123v3</guid>
      <category>cs.GT</category>
      <category>cs.CY</category>
      <category>cs.SI</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kate Donahue, Jon Kleinberg</dc:creator>
    </item>
    <item>
      <title>SMILE: Single-turn to Multi-turn Inclusive Language Expansion via ChatGPT for Mental Health Support</title>
      <link>https://arxiv.org/abs/2305.00450</link>
      <description>arXiv:2305.00450v3 Announce Type: replace-cross 
Abstract: Developing specialized dialogue systems for mental health support requires multi-turn conversation data, which has recently garnered increasing attention. However, gathering and releasing large-scale, real-life multi-turn conversations that could facilitate advancements in mental health support presents challenges in data privacy protection and the time and cost involved in crowdsourcing. To address these challenges, we introduce SMILE, a single-turn to multi-turn inclusive language expansion technique that prompts ChatGPT to rewrite public single-turn dialogues into multi-turn ones. Our work begins by analyzing language transformation and validating the feasibility of our proposed method. We conduct a study on dialogue diversity, including lexical features, semantic features, and dialogue topics, demonstrating the effectiveness of our method. Further, we employ our method to generate a large-scale, lifelike, and diverse dialogue dataset named SMILECHAT, consisting of 55k dialogues. Finally, we utilize the collected corpus to develop a mental health chatbot, MeChat. To better assess the quality of SMILECHAT, we collect a small-scale real-life counseling dataset conducted by data anonymization. Both automatic and human evaluations demonstrate significant improvements in our dialogue system and confirm that SMILECHAT is high-quality. Code, data, and model are publicly available at https://github.com/qiuhuachuan/smile.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.00450v3</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huachuan Qiu, Hongliang He, Shuai Zhang, Anqi Li, Zhenzhong Lan</dc:creator>
    </item>
    <item>
      <title>The influence of coordinated behavior on toxicity</title>
      <link>https://arxiv.org/abs/2310.01283</link>
      <description>arXiv:2310.01283v2 Announce Type: replace-cross 
Abstract: In the intricate landscape of social media, genuine content dissemination may be altered by a number of threats. Coordinated Behavior (CB), defined as orchestrated efforts by entities to deceive or mislead users about their identity and intentions, emerges as a tactic to exploit or manipulate online discourse. This study delves into the relationship between CB and toxic conversation on X (formerly known as Twitter). Using a dataset of 11 million tweets from 1 million users preceding the 2019 UK general election, we show that users displaying CB typically disseminate less harmful content, irrespective of political affiliation. However, distinct toxicity patterns emerge among different coordinated cohorts. Compared to their non-CB counterparts, CB participants show marginally higher toxicity levels only when considering their original posts. We further show the effects of CB-driven toxic content on non-CB users, gauging its impact based on political leanings. Our findings suggest that CB only has a limited impact on the toxicity of digital discourse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01283v2</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.osnem.2024.100289</arxiv:DOI>
      <arxiv:journal_reference>Online Social Networks and Media, Volumes 43-44, 2024, 100289, ISSN 2468-6964</arxiv:journal_reference>
      <dc:creator>Edoardo Loru, Matteo Cinelli, Maurizio Tesconi, Walter Quattrociocchi</dc:creator>
    </item>
    <item>
      <title>MiTTenS: A Dataset for Evaluating Gender Mistranslation</title>
      <link>https://arxiv.org/abs/2401.06935</link>
      <description>arXiv:2401.06935v3 Announce Type: replace-cross 
Abstract: Translation systems, including foundation models capable of translation, can produce errors that result in gender mistranslation, and such errors can be especially harmful. To measure the extent of such potential harms when translating into and out of English, we introduce a dataset, MiTTenS, covering 26 languages from a variety of language families and scripts, including several traditionally under-represented in digital resources. The dataset is constructed with handcrafted passages that target known failure patterns, longer synthetically generated passages, and natural passages sourced from multiple domains. We demonstrate the usefulness of the dataset by evaluating both neural machine translation systems and foundation models, and show that all systems exhibit gender mistranslation and potential harm, even in high resource languages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.06935v3</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kevin Robinson, Sneha Kudugunta, Romina Stella, Sunipa Dev, Jasmijn Bastings</dc:creator>
    </item>
    <item>
      <title>DetoxLLM: A Framework for Detoxification with Explanations</title>
      <link>https://arxiv.org/abs/2402.15951</link>
      <description>arXiv:2402.15951v2 Announce Type: replace-cross 
Abstract: Prior works on detoxification are scattered in the sense that they do not cover all aspects of detoxification needed in a real-world scenario. Notably, prior works restrict the task of developing detoxification models to only a seen subset of platforms, leaving the question of how the models would perform on unseen platforms unexplored. Additionally, these works do not address non-detoxifiability, a phenomenon whereby the toxic text cannot be detoxified without altering the meaning. We propose DetoxLLM, the first comprehensive end-to-end detoxification framework, which attempts to alleviate the aforementioned limitations. We first introduce a cross-platform pseudo-parallel corpus applying multi-step data processing and generation strategies leveraging ChatGPT. We then train a suite of detoxification models with our cross-platform corpus. We show that our detoxification models outperform the SoTA model trained with human-annotated parallel corpus. We further introduce explanation to promote transparency and trustworthiness. DetoxLLM additionally offers a unique paraphrase detector especially dedicated for the detoxification task to tackle the non-detoxifiable cases. Through experimental analysis, we demonstrate the effectiveness of our cross-platform corpus and the robustness of DetoxLLM against adversarial toxicity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15951v2</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Tawkat Islam Khondaker, Muhammad Abdul-Mageed, Laks V. S. Lakshmanan</dc:creator>
    </item>
    <item>
      <title>Can Language Models Recognize Convincing Arguments?</title>
      <link>https://arxiv.org/abs/2404.00750</link>
      <description>arXiv:2404.00750v2 Announce Type: replace-cross 
Abstract: The capabilities of large language models (LLMs) have raised concerns about their potential to create and propagate convincing narratives. Here, we study their performance in detecting convincing arguments to gain insights into LLMs' persuasive capabilities without directly engaging in experimentation with humans. We extend a dataset by Durmus and Cardie (2018) with debates, votes, and user traits and propose tasks measuring LLMs' ability to (1) distinguish between strong and weak arguments, (2) predict stances based on beliefs and demographic characteristics, and (3) determine the appeal of an argument to an individual based on their traits. We show that LLMs perform on par with humans in these tasks and that combining predictions from different LLMs yields significant performance gains, surpassing human performance. The data and code released with this paper contribute to the crucial effort of continuously evaluating and monitoring LLMs' capabilities and potential impact. (https://go.epfl.ch/persuasion-llm)</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00750v2</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Paula Rescala, Manoel Horta Ribeiro, Tiancheng Hu, Robert West</dc:creator>
    </item>
    <item>
      <title>Extrinsic Evaluation of Cultural Competence in Large Language Models</title>
      <link>https://arxiv.org/abs/2406.11565</link>
      <description>arXiv:2406.11565v3 Announce Type: replace-cross 
Abstract: Productive interactions between diverse users and language technologies require outputs from the latter to be culturally relevant and sensitive. Prior works have evaluated models' knowledge of cultural norms, values, and artifacts, without considering how this knowledge manifests in downstream applications. In this work, we focus on extrinsic evaluation of cultural competence in two text generation tasks, open-ended question answering and story generation. We quantitatively and qualitatively evaluate model outputs when an explicit cue of culture, specifically nationality, is perturbed in the prompts. Although we find that model outputs do vary when varying nationalities and feature culturally relevant words, we also find weak correlations between text similarity of outputs for different countries and the cultural values of these countries. Finally, we discuss important considerations in designing comprehensive evaluation of cultural competence in user-facing tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11565v3</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shaily Bhatt, Fernando Diaz</dc:creator>
    </item>
    <item>
      <title>Suicide Phenotyping from Clinical Notes in Safety-Net Psychiatric Hospital Using Multi-Label Classification with Pre-Trained Language Models</title>
      <link>https://arxiv.org/abs/2409.18878</link>
      <description>arXiv:2409.18878v2 Announce Type: replace-cross 
Abstract: Accurate identification and categorization of suicidal events can yield better suicide precautions, reducing operational burden, and improving care quality in high-acuity psychiatric settings. Pre-trained language models offer promise for identifying suicidality from unstructured clinical narratives. We evaluated the performance of four BERT-based models using two fine-tuning strategies (multiple single-label and single multi-label) for detecting coexisting suicidal events from 500 annotated psychiatric evaluation notes. The notes were labeled for suicidal ideation (SI), suicide attempts (SA), exposure to suicide (ES), and non-suicidal self-injury (NSSI). RoBERTa outperformed other models using multiple single-label classification strategy (acc=0.86, F1=0.78). MentalBERT (acc=0.83, F1=0.74) also exceeded BioClinicalBERT (acc=0.82, F1=0.72) which outperformed BERT (acc=0.80, F1=0.70). RoBERTa fine-tuned with single multi-label classification further improved the model performance (acc=0.88, F1=0.81). The findings highlight that the model optimization, pretraining with domain-relevant data, and the single multi-label classification strategy enhance the model performance of suicide phenotyping. Keywords: EHR-based Phenotyping; Natural Language Processing; Secondary Use of EHR Data; Suicide Classification; BERT-based Model; Psychiatry; Mental Health</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.18878v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.IR</category>
      <pubDate>Mon, 07 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Zehan Li, Yan Hu, Scott Lane, Salih Selek, Lokesh Shahani, Rodrigo Machado-Vieira, Jair Soares, Hua Xu, Hongfang Liu, Ming Huang</dc:creator>
    </item>
  </channel>
</rss>
