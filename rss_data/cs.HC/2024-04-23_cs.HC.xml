<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Apr 2024 04:00:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Holding the Line: A Study of Writers' Attitudes on Co-creativity with AI</title>
      <link>https://arxiv.org/abs/2404.13165</link>
      <description>arXiv:2404.13165v1 Announce Type: new 
Abstract: Generative AI has put many professional writers on the defensive; a major negotiation point of the recent Writers Guild of America's strike concerned use of AI. However, must AI threaten writers, their livelihoods or their creativity? And under what conditions, if any, might AI assistance be invited by different types of writers (from the amateur to the professional, from the screenwriter to the novelist)? To explore these questions, we conducted a qualitative study with 37 writers. We found that most writing occurs across five stages and within one of three modes; we additionally map openness to AI assistance to each intersecting stage-mode. We found that most writers were interested in AI assistance to some degree, but some writers felt drawing firm boundaries with an AI was key to their comfort using such systems. Designers can leverage these insights to build agency-respecting AI products for writers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13165v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Morteza Behrooz, Yuandong Tian, William Ngan, Yael Yungster, Justin Wong, David Zax</dc:creator>
    </item>
    <item>
      <title>Improving User Mental Models of XAI Systems with Inclusive Design Approaches</title>
      <link>https://arxiv.org/abs/2404.13217</link>
      <description>arXiv:2404.13217v1 Announce Type: new 
Abstract: Explainable Artificial Intelligence (XAI) systems aim to improve users' understanding of AI but rarely consider the inclusivity aspects of XAI. Without inclusive approaches, improving explanations might not work well for everyone. This study investigates leveraging users' diverse problem-solving styles as an inclusive strategy to fix an XAI prototype, with the ultimate goal of improving users' mental models of AI. We ran a between-subject study with 69 participants. Our results show that the inclusivity fixes increased participants' engagement with explanations and produced significantly improved mental models. Analyzing differences in mental model scores further highlighted specific inclusivity fixes that contributed to the significant improvement in the mental model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13217v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md Montaser Hamid, Fatima Moussaoui, Jimena Noa Guevara, Andrew Anderson, Margaret Burnett</dc:creator>
    </item>
    <item>
      <title>Preserving History through Augmented Reality</title>
      <link>https://arxiv.org/abs/2404.13229</link>
      <description>arXiv:2404.13229v1 Announce Type: new 
Abstract: Extended reality can weave together the fabric of the past, present, and future. A two-day design hackathon was held to bring the community together through a love for history and a common goal to use technology for good. Through interviewing an influential community elder, Emile Pitre, and referencing his book Revolution to Evolution, my team developed an augmented reality artifact to tell his story and preserve on revolutionary's legacy that impacted the University of Washington's history forever.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13229v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Annie Yang</dc:creator>
    </item>
    <item>
      <title>DinAR: Augmenting Reality for Sustainable Dining</title>
      <link>https://arxiv.org/abs/2404.13272</link>
      <description>arXiv:2404.13272v1 Announce Type: new 
Abstract: Sustainable food is among the many challenges associated with climate change. The resources required to grow or gather the food and the distance it travels to reach the consumer are two key factors of an ingredient's sustainability. Food that is grown locally and is currently "in-season" will have a lower carbon footprint, but when dining out these details unfortunately may not affect one's ordering preferences. We introduce DinAR as an immersive experience to make this information more accessible and to encourage better dining choices through friendly competition with a leaderboard of sustainability scores. Our study measures the effectiveness of immersive AR experiences on impacting consumer preferences towards sustainability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13272v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>MJ Johns, Eunsol Sol Choi, Derusha Baskaran</dc:creator>
    </item>
    <item>
      <title>Augmented Object Intelligence: Making the Analog World Interactable with XR-Objects</title>
      <link>https://arxiv.org/abs/2404.13274</link>
      <description>arXiv:2404.13274v1 Announce Type: new 
Abstract: Seamless integration of physical objects as interactive digital entities remains a challenge for spatial computing. This paper introduces Augmented Object Intelligence (AOI), a novel XR interaction paradigm designed to blur the lines between digital and physical by endowing real-world objects with the ability to interact as if they were digital, where every object has the potential to serve as a portal to vast digital functionalities. Our approach utilizes object segmentation and classification, combined with the power of Multimodal Large Language Models (MLLMs), to facilitate these interactions. We implement the AOI concept in the form of XR-Objects, an open-source prototype system that provides a platform for users to engage with their physical environment in rich and contextually relevant ways. This system enables analog objects to not only convey information but also to initiate digital actions, such as querying for details or executing tasks. Our contributions are threefold: (1) we define the AOI concept and detail its advantages over traditional AI assistants, (2) detail the XR-Objects system's open-source design and implementation, and (3) show its versatility through a variety of use cases and a user study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13274v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mustafa Doga Dogan, Eric J. Gonzalez, Andrea Colaco, Karan Ahuja, Ruofei Du, Johnny Lee, Mar Gonzalez-Franco, David Kim</dc:creator>
    </item>
    <item>
      <title>ARtivism: AR-Enabled Accessible Public Art and Advocacy</title>
      <link>https://arxiv.org/abs/2404.13285</link>
      <description>arXiv:2404.13285v1 Announce Type: new 
Abstract: Activism can take a multitude of forms, including protests, social media campaigns, and even public art. The uniqueness of public art lies in that both the act of creation and the artifacts created can serve as activism. Furthermore, public art is often site-specific and can be created with (e.g., commissioned murals) or without permission (e.g., graffiti art) of the site's owner. However, the majority of public art is inaccessible to blind and low vision people, excluding them from political and social action. In this position paper, we build on a prior crowdsourced mural description project and describe the design of one potential process artifact, ARtivism, for making public art more accessible via augmented reality. We then discuss tensions that may occur at the intersection of public art, activism, and technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13285v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Lucy Jiang</dc:creator>
    </item>
    <item>
      <title>Empirical research methods for human-computer interaction</title>
      <link>https://arxiv.org/abs/2404.13319</link>
      <description>arXiv:2404.13319v1 Announce Type: new 
Abstract: Most attendees at CHI conferences will agree that an experiment (user study) is the hallmark of good research in human-computer interaction. But what constitutes an experiment? And how does one go from an experiment to a CHI paper? This course will teach how to pose testable research questions, how to make and measure observations, and how to design and conduct an experiment. Specifically, attendees will participate in a real experiment to gain experience as both an investigator and as a participant. The second session covers the statistical tools typically used to analyze data. Most notably, attendees will learn how to organize experiment results and write a CHI paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13319v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3544549.3574165</arxiv:DOI>
      <dc:creator>I. Scott MacKenzie, Janet C. Read, Matthew Horton</dc:creator>
    </item>
    <item>
      <title>"I Wish There Were an AI": Challenges and AI Potential in Cancer Patient-Provider Communication</title>
      <link>https://arxiv.org/abs/2404.13409</link>
      <description>arXiv:2404.13409v1 Announce Type: new 
Abstract: Patient-provider communication has been crucial to cancer patients' survival after their cancer treatments. However, the research community and patients themselves often overlook the communication challenges after cancer treatments as they are overshadowed by the severity of the patient's illness and the variety and rarity of the cancer disease itself. Meanwhile, the recent technical advances in AI, especially in Large Language Models (LLMs) with versatile natural language interpretation and generation ability, demonstrate great potential to support communication in complex real-world medical situations. By interviewing six healthcare providers and eight cancer patients, our goal is to explore the providers' and patients' communication barriers in the post-cancer treatment recovery period, their expectations for future communication technologies, and the potential of AI technologies in this context. Our findings reveal several challenges in current patient-provider communication, including the knowledge and timing gaps between cancer patients and providers, their collaboration obstacles, and resource limitations. Moreover, based on providers' and patients' needs and expectations, we summarize a set of design implications for intelligent communication systems, especially with the power of LLMs. Our work sheds light on the design of future AI-powered systems for patient-provider communication under high-stake and high-uncertainty situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13409v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziqi Yang, Xuhai Xu, Bingsheng Yao, Jiachen Li, Jennifer Bagdasarian, Guodong Gao, Dakuo Wang</dc:creator>
    </item>
    <item>
      <title>Evaluating the Effectiveness of LLMs in Introductory Computer Science Education: A Semester-Long Field Study</title>
      <link>https://arxiv.org/abs/2404.13414</link>
      <description>arXiv:2404.13414v1 Announce Type: new 
Abstract: The integration of AI assistants, especially through the development of Large Language Models (LLMs), into computer science education has sparked significant debate. An emerging body of work has looked into using LLMs in education, but few have examined the impacts of LLMs on students in entry-level programming courses, particularly in real-world contexts and over extended periods. To address this research gap, we conducted a semester-long, between-subjects study with 50 students using CodeTutor, an LLM-powered assistant developed by our research team. Our study results show that students who used CodeTutor (the experimental group) achieved statistically significant improvements in their final scores compared to peers who did not use the tool (the control group). Within the experimental group, those without prior experience with LLM-powered tools demonstrated significantly greater performance gain than their counterparts. We also found that students expressed positive feedback regarding CodeTutor's capability, though they also had concerns about CodeTutor's limited role in developing critical thinking skills. Over the semester, students' agreement with CodeTutor's suggestions decreased, with a growing preference for support from traditional human teaching assistants. Our analysis further reveals that the quality of user prompts was significantly correlated with CodeTutor's response effectiveness. Building upon our results, we discuss the implications of our findings for integrating Generative AI literacy into curricula to foster critical thinking skills and turn to examining the temporal dynamics of user engagement with LLM-powered tools. We further discuss the discrepancy between the anticipated functions of tools and students' actual capabilities, which sheds light on the need for tailored strategies to improve educational outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13414v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wenhan Lyu, Yimeng Wang, Tingting Rachel Chung, Yifan Sun, Yixuan Zhang</dc:creator>
    </item>
    <item>
      <title>Interactive tools for making temporally variable, multiple-attributes, and multiple-instances morphing accessible: Flexible manipulation of divergent speech instances for explorational research and education</title>
      <link>https://arxiv.org/abs/2404.13418</link>
      <description>arXiv:2404.13418v1 Announce Type: new 
Abstract: We generalized a voice morphing algorithm capable of handling temporally variable, multiple-attributes, and multiple instances. The generalized morphing provides a new strategy for investigating speech diversity. However, excessive complexity and the difficulty of preparation have prevented researchers and students from enjoying its benefits. To address this issue, we introduced a set of interactive tools to make preparation and tests less cumbersome. These tools are integrated into our previously reported interactive tools as extensions. The introduction of the extended tools in lessons in graduate education was successful. Finally, we outline further extensions to explore excessively complex morphing parameter settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13418v1</guid>
      <category>cs.HC</category>
      <category>eess.AS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hideki Kawahara, Masanori Morise</dc:creator>
    </item>
    <item>
      <title>Exploring Bi-Manual Teleportation in Virtual Reality</title>
      <link>https://arxiv.org/abs/2404.13431</link>
      <description>arXiv:2404.13431v1 Announce Type: new 
Abstract: Teleportation, a widely-used locomotion technique in Virtual Reality (VR), allows instantaneous movement within VR environments. Enhanced hand tracking in modern VR headsets has popularized hands-only teleportation methods, which eliminate the need for physical controllers. However, these techniques have not fully explored the potential of bi-manual input, where each hand plays a distinct role in teleportation: one controls the teleportation point and the other confirms selections. Additionally, the influence of users' posture, whether sitting or standing, on these techniques remains unexplored. Furthermore, previous teleportation evaluations lacked assessments based on established human motor models such as Fitts' Law. To address these gaps, we conducted a user study (N=20) to evaluate bi-manual pointing performance in VR teleportation tasks, considering both sitting and standing postures. We proposed a variation of the Fitts' Law model to accurately assess users' teleportation performance. We designed and evaluated various bi-manual teleportation techniques, comparing them to uni-manual and dwell-based techniques. Results showed that bi-manual techniques, particularly when the dominant hand is used for pointing and the non-dominant hand for selection, enable faster teleportation compared to other methods. Furthermore, bi-manual and dwell techniques proved significantly more accurate than uni-manual teleportation. Moreover, our proposed Fitts' Law variation more accurately predicted users' teleportation performance compared to existing models. Finally, we developed a set of guidelines for designers to enhance VR teleportation experiences and optimize user interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13431v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/VR58804.2024.00095</arxiv:DOI>
      <arxiv:journal_reference>in 2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR), Orlando, FL, USA, 2024 pp. 754-764. video: https://youtu.be/j9AkmCa8YA8</arxiv:journal_reference>
      <dc:creator>Siddhanth Raja Sindhupathiraja, A K M Amanat Ullah, William Delamare, Khalad Hasan</dc:creator>
    </item>
    <item>
      <title>Graph4GUI: Graph Neural Networks for Representing Graphical User Interfaces</title>
      <link>https://arxiv.org/abs/2404.13521</link>
      <description>arXiv:2404.13521v1 Announce Type: new 
Abstract: Present-day graphical user interfaces (GUIs) exhibit diverse arrangements of text, graphics, and interactive elements such as buttons and menus, but representations of GUIs have not kept up. They do not encapsulate both semantic and visuo-spatial relationships among elements. To seize machine learning's potential for GUIs more efficiently, Graph4GUI exploits graph neural networks to capture individual elements' properties and their semantic-visuo-spatial constraints in a layout. The learned representation demonstrated its effectiveness in multiple tasks, especially generating designs in a challenging GUI autocompletion task, which involved predicting the positions of remaining unplaced elements in a partially completed GUI. The new model's suggestions showed alignment and visual appeal superior to the baseline method and received higher subjective ratings for preference. Furthermore, we demonstrate the practical benefits and efficiency advantages designers perceive when utilizing our model as an autocompletion plug-in.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13521v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642822</arxiv:DOI>
      <dc:creator>Yue Jiang, Changkong Zhou, Vikas Garg, Antti Oulasvirta</dc:creator>
    </item>
    <item>
      <title>Preliminary Investigation of SSL for Complex Work Activity Recognition in Industrial Domain via MoIL</title>
      <link>https://arxiv.org/abs/2404.13581</link>
      <description>arXiv:2404.13581v1 Announce Type: new 
Abstract: In this study, we investigate a new self-supervised learning (SSL) approach for complex work activity recognition using wearable sensors. Owing to the cost of labeled sensor data collection, SSL methods for human activity recognition (HAR) that effectively use unlabeled data for pretraining have attracted attention. However, applying prior SSL to complex work activities such as packaging works is challenging because the observed data vary considerably depending on situations such as the number of items to pack and the size of the items in the case of packaging works. In this study, we focus on sensor data corresponding to characteristic and necessary actions (sensor data motifs) in a specific activity such as a stretching packing tape action in an assembling a box activity, and \textcolor{black}{try} to train a neural network in self-supervised learning so that it identifies occurrences of the characteristic actions, i.e., Motif Identification Learning (MoIL). The feature extractor in the network is used in the downstream task, i.e., work activity recognition, enabling precise activity recognition containing characteristic actions with limited labeled training data. The MoIL approach was evaluated on real-world work activity data and it achieved state-of-the-art performance under limited training labels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13581v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qingxin Xia, Takuya Maekawa, Jaime Morales, Takahiro Hara, Hirotomo Oshima, Masamitsu Fukuda, Yasuo Namioka</dc:creator>
    </item>
    <item>
      <title>Incorporating Different Verbal Cues to Improve Text-Based Computer-Delivered Health Messaging</title>
      <link>https://arxiv.org/abs/2404.13633</link>
      <description>arXiv:2404.13633v1 Announce Type: new 
Abstract: The ubiquity of smartphones has led to an increase in on demand healthcare being supplied. For example, people can share their illness-related experiences with others similar to themselves, and healthcare experts can offer advice for better treatment and care for remediable, terminal and mental illnesses. As well as this human-to-human communication, there has been an increased use of human-to-computer digital health messaging, such as chatbots. These can prove advantageous as they offer synchronous and anonymous feedback without the need for a human conversational partner. However, there are many subtleties involved in human conversation that a computer agent may not properly exhibit. For example, there are various conversational styles, etiquettes, politeness strategies or empathic responses that need to be chosen appropriately for the conversation. Encouragingly, computers are social actors (CASA) posits that people apply the same social norms to computers as they would do to people. On from this, previous studies have focused on applying conversational strategies to computer agents to make them embody more favourable human characteristics. However, if a computer agent fails in this regard it can lead to negative reactions from users. Therefore, in this dissertation we describe a series of studies we carried out to lead to more effective human-to-computer digital health messaging.
  In our first study, we use the crowd [...]
  Our second study investigates the effect of a health chatbot's conversational style [...]
  In our final study, we investigate the format used by a chatbot when [...]
  In summary, we have researched how to create more effective digital health interventions starting from generating health messages, to choosing an appropriate formality of messaging, and finally to formatting messages which reference a user's previous utterances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13633v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Rhys Cox</dc:creator>
    </item>
    <item>
      <title>SciDaSynth: Interactive Structured Knowledge Extraction and Synthesis from Scientific Literature with Large Language Model</title>
      <link>https://arxiv.org/abs/2404.13765</link>
      <description>arXiv:2404.13765v1 Announce Type: new 
Abstract: Extraction and synthesis of structured knowledge from extensive scientific literature are crucial for advancing and disseminating scientific progress. Although many existing systems facilitate literature review and digest, they struggle to process multimodal, varied, and inconsistent information within and across the literature into structured data. We introduce SciDaSynth, a novel interactive system powered by large language models (LLMs) that enables researchers to efficiently build structured knowledge bases from scientific literature at scale. The system automatically creates data tables to organize and summarize users' interested knowledge in literature via question-answering. Furthermore, it provides multi-level and multi-faceted exploration of the generated data tables, facilitating iterative validation, correction, and refinement. Our within-subjects study with researchers demonstrates the effectiveness and efficiency of SciDaSynth in constructing quality scientific knowledge bases. We further discuss the design implications for human-AI interaction tools for data extraction and structuring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13765v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingbo Wang, Samantha L. Huey, Rui Sheng, Saurabh Mehta, Fei Wang</dc:creator>
    </item>
    <item>
      <title>Explainable Interfaces for Rapid Gaze-Based Interactions in Mixed Reality</title>
      <link>https://arxiv.org/abs/2404.13777</link>
      <description>arXiv:2404.13777v1 Announce Type: new 
Abstract: Gaze-based interactions offer a potential way for users to naturally engage with mixed reality (XR) interfaces. Black-box machine learning models enabled higher accuracy for gaze-based interactions. However, due to the black-box nature of the model, users might not be able to understand and effectively adapt their gaze behaviour to achieve high quality interaction. We posit that explainable AI (XAI) techniques can facilitate understanding of and interaction with gaze-based model-driven system in XR. To study this, we built a real-time, multi-level XAI interface for gaze-based interaction using a deep learning model, and evaluated it during a visual search task in XR. A between-subjects study revealed that participants who interacted with XAI made more accurate selections compared to those who did not use the XAI system (i.e., F1 score increase of 10.8%). Additionally, participants who used the XAI system adapted their gaze behavior over time to make more effective selections. These findings suggest that XAI can potentially be used to assist users in more effective collaboration with model-driven interactions in XR.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13777v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengjie Yu, Dustin Harris, Ian Jones, Ting Zhang, Yue Liu, Naveen Sendhilnathan, Narine Kokhlikyan, Fulton Wang, Co Tran, Jordan L. Livingston, Krista E. Taylor, Zhenhong Hu, Mary A. Hood, Hrvoje Benko, Tanya R. Jonker</dc:creator>
    </item>
    <item>
      <title>The Fall of an Algorithm: Characterizing the Dynamics Toward Abandonment</title>
      <link>https://arxiv.org/abs/2404.13802</link>
      <description>arXiv:2404.13802v1 Announce Type: new 
Abstract: As more algorithmic systems have come under scrutiny for their potential to inflict societal harms, an increasing number of organizations that hold power over harmful algorithms have chosen (or were required under the law) to abandon them. While social movements and calls to abandon harmful algorithms have emerged across application domains, little academic attention has been paid to studying abandonment as a means to mitigate algorithmic harms. In this paper, we take a first step towards conceptualizing "algorithm abandonment" as an organization's decision to stop designing, developing, or using an algorithmic system due to its (potential) harms. We conduct a thematic analysis of real-world cases of algorithm abandonment to characterize the dynamics leading to this outcome. Our analysis of 40 cases reveals that campaigns to abandon an algorithm follow a common process of six iterative phases: discovery, diagnosis, dissemination, dialogue, decision, and death, which we term the "6 D's of abandonment". In addition, we highlight key factors that facilitate (or prohibit) abandonment, which include characteristics of both the technical and social systems that the algorithm is embedded within. We discuss implications for several stakeholders, including proprietors and technologists who have the power to influence an algorithm's (dis)continued use, FAccT researchers, and policymakers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13802v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658910</arxiv:DOI>
      <dc:creator>Nari Johnson, Sanika Moharana, Christina N. Harrington, Nazanin Andalibi, Hoda Heidari, Motahhare Eslami</dc:creator>
    </item>
    <item>
      <title>Robotic Blended Sonification: Consequential Robot Sound as Creative Material for Human-Robot Interaction</title>
      <link>https://arxiv.org/abs/2404.13821</link>
      <description>arXiv:2404.13821v1 Announce Type: new 
Abstract: Current research in robotic sounds generally focuses on either masking the consequential sound produced by the robot or on sonifying data about the robot to create a synthetic robot sound. We propose to capture, modify, and utilise rather than mask the sounds that robots are already producing. In short, this approach relies on capturing a robot's sounds, processing them according to contextual information (e.g., collaborators' proximity or particular work sequences), and playing back the modified sound. Previous research indicates the usefulness of non-semantic, and even mechanical, sounds as a communication tool for conveying robotic affect and function. Adding to this, this paper presents a novel approach which makes two key contributions: (1) a technique for real-time capture and processing of consequential robot sounds, and (2) an approach to explore these sounds through direct human-robot interaction. Drawing on methodologies from design, human-robot interaction, and creative practice, the resulting 'Robotic Blended Sonification' is a concept which transforms the consequential robot sounds into a creative material that can be explored artistically and within application-based studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13821v1</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stine S. Johansen, Yanto Browning, Anthony Brumpton, Jared Donovan, Markus Rittenbruch</dc:creator>
    </item>
    <item>
      <title>GazeIntent: Adapting dwell-time selection in VR interaction with real-time intent modeling</title>
      <link>https://arxiv.org/abs/2404.13829</link>
      <description>arXiv:2404.13829v1 Announce Type: new 
Abstract: The use of ML models to predict a user's cognitive state from behavioral data has been studied for various applications which includes predicting the intent to perform selections in VR. We developed a novel technique that uses gaze-based intent models to adapt dwell-time thresholds to aid gaze-only selection. A dataset of users performing selection in arithmetic tasks was used to develop intent prediction models (F1 = 0.94). We developed GazeIntent to adapt selection dwell times based on intent model outputs and conducted an end-user study with returning and new users performing additional tasks with varied selection frequencies. Personalized models for returning users effectively accounted for prior experience and were preferred by 63% of users. Our work provides the field with methods to adapt dwell-based selection to users, account for experience over time, and consider tasks that vary by selection frequency</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13829v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anish S. Narkar, Jan J. Michalak, Candace E. Peacock, Brendan David-John</dc:creator>
    </item>
    <item>
      <title>ActSonic: Everyday Activity Recognition on Smart Glasses using Active Acoustic Sensing</title>
      <link>https://arxiv.org/abs/2404.13924</link>
      <description>arXiv:2404.13924v1 Announce Type: new 
Abstract: In this paper, we introduce ActSonic, an intelligent, low-power active acoustic sensing system integrated into eyeglasses. ActSonic is designed to recognize 27 different everyday activities (e.g., eating, drinking, toothbrushing). It only needs a pair of miniature speakers and microphones mounted on each hinge of eyeglasses to emit ultrasonic waves to create an acoustic aura around the body. Based on the position and motion of various body parts, the acoustic signals are reflected with unique patterns captured by the microphone and analyzed by a customized self-supervised deep learning framework to infer the performed activities. ActSonic was deployed in a user study with 19 participants across 19 households to evaluate its efficacy. Without requiring any training data from a new user (leave-one-participant-out evaluation), ActSonic was able to detect 27 activities with an inference resolution of 1 second, achieving an average F1-score of 86.6% in an unconstrained setting and 93.4% in a prompted setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13924v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Saif Mahmud, Vineet Parikh, Qikang Liang, Ke Li, Ruidong Zhang, Ashwin Ajit, Vipin Gunda, Devansh Agarwal, Fran\c{c}ois Guimbreti\`ere, Cheng Zhang</dc:creator>
    </item>
    <item>
      <title>Comparison of On-Orbit Manual Attitude Control Methods for Non-Docking Spacecraft Through Virtual Reality Simulation</title>
      <link>https://arxiv.org/abs/2404.13933</link>
      <description>arXiv:2404.13933v1 Announce Type: new 
Abstract: On-orbit manual attitude control of manned spacecraft is accomplished using external visual references and some method of three axis attitude control. All past, present, and developmental spacecraft feature the capability to manually control attitude for deorbit. National Aeronautics and Space Administration (NASA) spacecraft permit an aircraft windshield type front view, wherein an arc of the Earths horizon is visible to the crew in deorbit attitude. Russian and Chinese spacecraft permit the crew a bottom view wherein the entire circular Earth horizon disk is visible to the crew in deorbit attitude. Our study compared these two types of external views for efficiency in achievement of deorbit attitude. We used a Unity Virtual Reality (VR) spacecraft simulator that we built in house. The task was to accurately achieve deorbit attitude while in a 400 km circular orbit. Six military test pilots and six civilians with gaming experience flew the task using two methods of visual reference. Comparison was based on time taken, fuel consumed, cognitive workload assessment and user preference. We used ocular parameters, EEG, NASA TLX and IBM SUS to quantify our results. Our study found that the bottom view was easier to operate for manual deorbit task. Additionally, we realized that a VR based system can work as a training simulator for manual on-orbit flight path control tasks by pilots and non pilots. Results from our study can be used for design of manual on orbit attitude control of present and future spacecrafts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13933v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajit Krishnan, Himanshu Vishwakarma, Maharudra Kharsade, Pradipta Biswas</dc:creator>
    </item>
    <item>
      <title>No General Code of Ethics for All: Ethical Considerations in Human-bot Psycho-counseling</title>
      <link>https://arxiv.org/abs/2404.14070</link>
      <description>arXiv:2404.14070v1 Announce Type: new 
Abstract: The pervasive use of AI applications is increasingly influencing our everyday decisions. However, the ethical challenges associated with AI transcend conventional ethics and single-discipline approaches. In this paper, we propose aspirational ethical principles specifically tailored for human-bot psycho-counseling during an era when AI-powered mental health services are continually emerging. We examined the responses generated by EVA2.0, GPT-3.5, and GPT-4.0 in the context of psycho-counseling and mental health inquiries. Our analysis focused on standard psycho-counseling ethical codes (respect for autonomy, non-maleficence, beneficence, justice, and responsibility) as well as crisis intervention strategies (risk assessment, involvement of emergency services, and referral to human professionals). The results indicate that although there has been progress in adhering to regular ethical codes as large language models (LLMs) evolve, the models' capabilities in handling crisis situations need further improvement. Additionally, we assessed the linguistic quality of the generated responses and found that misleading responses are still produced by the models. Furthermore, the ability of LLMs to encourage individuals to introspect in the psycho-counseling setting remains underdeveloped.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14070v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lizhi Ma, Tong Zhao, Huachuan Qiu, Zhenzhong Lan</dc:creator>
    </item>
    <item>
      <title>A participatory design approach to using social robots for elderly care</title>
      <link>https://arxiv.org/abs/2404.14134</link>
      <description>arXiv:2404.14134v1 Announce Type: new 
Abstract: We present our ongoing research on applying a participatory design approach to using social robots for elderly care. Our approach involves four different groups of stakeholders: the elderly, (non-professional) caregivers, medical professionals, and psychologists. We focus on card sorting and storyboarding techniques to elicit the concerns of the stakeholders towards deploying social robots for elderly care. This is followed by semi-structured interviews to assess their attitudes towards social robots individually. Then we are conducting two-stage workshops with different elderly groups to understand how to engage them with the technology and to identify the challenges in this task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14134v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Barbara Sienkiewicz, Zuzanna Radosz-Knawa, Bipin Indurkhya</dc:creator>
    </item>
    <item>
      <title>Designing Safe and Engaging AI Experiences for Children: Towards the Definition of Best Practices in UI/UX Design</title>
      <link>https://arxiv.org/abs/2404.14218</link>
      <description>arXiv:2404.14218v1 Announce Type: new 
Abstract: This workshop proposal focuses on best practices in UI/UX design for AI applications aimed at children, emphasising safety, engagement, and ethics. It aims to address the challenge of measuring the safety, trustworthiness, and reliability of interactions between children and AI systems. Through collaborative discussions, participants will explore effective design strategies and ethical guidelines while developing methodologies for assessing the safety and reliability of AI interactions with children. This proposal seeks to foster responsible and child-centered AI design practices within the CHI community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14218v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Grazia Ragone, Paolo Buono, Rosa Lanzilotti</dc:creator>
    </item>
    <item>
      <title>An Artificial Neuron for Enhanced Problem Solving in Large Language Models</title>
      <link>https://arxiv.org/abs/2404.14222</link>
      <description>arXiv:2404.14222v1 Announce Type: new 
Abstract: Recent advancements in artificial intelligence have propelled the capabilities of Large Language Models, yet their ability to mimic nuanced human reasoning remains limited. This paper introduces a novel conceptual enhancement to LLMs, termed the Artificial Neuron, designed to significantly bolster cognitive processing by integrating external memory systems. This enhancement mimics neurobiological processes, facilitating advanced reasoning and learning through a dynamic feedback loop mechanism. We propose a unique framework wherein each LLM interaction specifically in solving complex math word problems and common sense reasoning tasks is recorded and analyzed. Incorrect responses are refined using a higher capacity LLM or human in the loop corrections, and both the query and the enhanced response are stored in a vector database, structured much like neuronal synaptic connections. This Artificial Neuron thus serves as an external memory aid, allowing the LLM to reference past interactions and apply learned reasoning strategies to new problems. Our experimental setup involves training with the GSM8K dataset for initial model response generation, followed by systematic refinements through feedback loops. Subsequent testing demonstrated a significant improvement in accuracy and efficiency, underscoring the potential of external memory systems to advance LLMs beyond current limitations. This approach not only enhances the LLM's problem solving precision but also reduces computational redundancy, paving the way for more sophisticated applications of artificial intelligence in cognitive tasks. This paper details the methodology, implementation, and implications of the Artificial Neuron model, offering a transformative perspective on enhancing machine intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14222v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sumedh Rasal</dc:creator>
    </item>
    <item>
      <title>Resistance Against Manipulative AI: key factors and possible actions</title>
      <link>https://arxiv.org/abs/2404.14230</link>
      <description>arXiv:2404.14230v1 Announce Type: new 
Abstract: If AI is the new electricity, what should we do to keep ourselves from getting electrocuted? In this work, we explore factors related to the potential of large language models (LLMs) to manipulate human decisions. We describe the results of two experiments designed to determine what characteristics of humans are associated with their susceptibility to LLM manipulation, and what characteristics of LLMs are associated with their manipulativeness potential. We explore human factors by conducting user studies in which participants answer general knowledge questions using LLM-generated hints, whereas LLM factors by provoking language models to create manipulative statements. Then, we analyze their obedience, the persuasion strategies used, and the choice of vocabulary. Based on these experiments, we discuss two actions that can protect us from LLM manipulation. In the long term, we put AI literacy at the forefront, arguing that educating society would minimize the risk of manipulation and its consequences. We also propose an ad hoc solution, a classifier that detects manipulation of LLMs - a Manipulation Fuse.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14230v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Piotr Wilczy\'nski, Wiktoria Mieleszczenko-Kowszewicz, Przemys{\l}aw Biecek</dc:creator>
    </item>
    <item>
      <title>Shifting Focus with HCEye: Exploring the Dynamics of Visual Highlighting and Cognitive Load on User Attention and Saliency Prediction</title>
      <link>https://arxiv.org/abs/2404.14232</link>
      <description>arXiv:2404.14232v1 Announce Type: new 
Abstract: Visual highlighting can guide user attention in complex interfaces. However, its effectiveness under limited attentional capacities is underexplored. This paper examines the joint impact of visual highlighting (permanent and dynamic) and dual-task-induced cognitive load on gaze behaviour. Our analysis, using eye-movement data from 27 participants viewing 150 unique webpages reveals that while participants' ability to attend to UI elements decreases with increasing cognitive load, dynamic adaptations (i.e., highlighting) remain attention-grabbing. The presence of these factors significantly alters what people attend to and thus what is salient. Accordingly, we show that state-of-the-art saliency models increase their performance when accounting for different cognitive loads. Our empirical insights, along with our openly available dataset, enhance our understanding of attentional processes in UIs under varying cognitive (and perceptual) loads and open the door for new models that can predict user attention while multitasking.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14232v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3655610</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Hum.-Comput. Interact., Vol. 8, No. ETRA, Article 236. Publication date: May 2024</arxiv:journal_reference>
      <dc:creator>Anwesha Das, Zekun Wu, Iza \v{S}krjanec, Anna Maria Feit</dc:creator>
    </item>
    <item>
      <title>"I Upload...All Types of Different Things to Say, the World of Blindness Is More Than What They Think It Is": A Study of Blind TikTokers' Identity Work from a Flourishing Perspective</title>
      <link>https://arxiv.org/abs/2404.14305</link>
      <description>arXiv:2404.14305v1 Announce Type: new 
Abstract: Identity work in Human-Computer Interaction (HCI) has focused on the marginalized group to explore designs to support their asset (what they have). However, little has been explored specifically on the identity work of people with disabilities, specifically, visual impairments. In this study, we interviewed 45 BlindTokers (blind users on TikTok) from various backgrounds to understand their identity work from a positive design perspective. We found that BlindTokers leverage the affordance of the platform to create positive content, share their identities, and build the community with the desire to flourish. We proposed flourishing labor to present the work conducted by BlindTokers for their community's flourishing with implications to support the flourishing labor. This work contributes to understanding blind users' experience in short video platforms and highlights that flourishing is not just an activity for any single Blind user but also a job that needs all stakeholders, including all user groups and the TikTok platform, serious and committed contribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14305v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yao Lyu, Jie Cai, Bryan Dosono, Davis Yadav, John M. Carroll</dc:creator>
    </item>
    <item>
      <title>Penn &amp; Slavery Project's Augmented Reality Tour: Augmenting a Campus to Reveal a Hidden History</title>
      <link>https://arxiv.org/abs/2404.14379</link>
      <description>arXiv:2404.14379v1 Announce Type: new 
Abstract: In 2006 and 2016, the University of Pennsylvania denied any ties to slavery. In 2017, a group of undergraduate researchers, led by Professor Kathleen Brown, investigated this claim. Initial research, focused on 18th century faculty and trustees who owned slaves, revealed deep connections between the university's history and the institution of slavery. These findings, and discussions amongst the researchers shaped the Penn and Slavery Project's goal of redefining complicity beyond ownership. Breanna Moore's contributions in PSP's second semester expanded the project's focus to include generational wealth gaps. In 2018, VanJessica Gladney served as the PSP's Public History Fellow and spread the project outreach in the greater Philadelphia area. That year, the PSP team began to design an augmented reality app as a Digital Interruption and an attempt to display the truth about Penn's history on its campus. Unfortunately, PSP faced delays due to COVID 19. Despite setbacks, the project persisted, engaging with activists and the wider community to confront historical injustices and modern inequalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14379v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>VanJessica Gladney, Breanna Moore, Kathleen Brown</dc:creator>
    </item>
    <item>
      <title>Insights from an experiment crowdsourcing data from thousands of US Amazon users: The importance of transparency, money, and data use</title>
      <link>https://arxiv.org/abs/2404.13172</link>
      <description>arXiv:2404.13172v1 Announce Type: cross 
Abstract: Data generated by users on digital platforms are a crucial resource for advocates and researchers interested in uncovering digital inequities, auditing algorithms, and understanding human behavior. Yet data access is often restricted. How can researchers both effectively and ethically collect user data? This paper shares an innovative approach to crowdsourcing user data to collect otherwise inaccessible Amazon purchase histories, spanning 5 years, from more than 5000 US users. We developed a data collection tool that prioritizes participant consent and includes an experimental study design. The design allows us to study multiple aspects of privacy perception and data sharing behavior. Experiment results (N=6325) reveal both monetary incentives and transparency can significantly increase data sharing. Age, race, education, and gender also played a role, where female and less-educated participants were more likely to share. Our study design enables a unique empirical evaluation of the "privacy paradox", where users claim to value their privacy more than they do in practice. We set up both real and hypothetical data sharing scenarios and find measurable similarities and differences in share rates across these contexts. For example, increasing monetary incentives had a 6 times higher impact on share rates in real scenarios. In addition, we study participants' opinions on how data should be used by various third parties, again finding demographics have a significant impact. Notably, the majority of participants disapproved of government agencies using purchase data yet the majority approved of use by researchers. Overall, our findings highlight the critical role that transparency, incentive design, and user demographics play in ethical data collection practices, and provide guidance for future researchers seeking to crowdsource user generated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13172v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alex Berke, Robert Mahari, Sandy Pentland, Kent Larson, D. Calacci</dc:creator>
    </item>
    <item>
      <title>Should Teleoperation Be like Driving in a Car? Comparison of Teleoperation HMIs</title>
      <link>https://arxiv.org/abs/2404.13697</link>
      <description>arXiv:2404.13697v1 Announce Type: cross 
Abstract: Since Automated Driving Systems are not expected to operate flawlessly, Automated Vehicles will require human assistance in certain situations. For this reason, teleoperation offers the opportunity for a human to be remotely connected to the vehicle and assist it. The Remote Operator can provide extensive support by directly controlling the vehicle, eliminating the need for Automated Driving functions. However, due to the physical disconnection to the vehicle, monitoring and controlling is challenging compared to driving in the vehicle. Therefore, this work follows the approach of simplifying the task for the Remote Operator by separating the path and velocity input. In a study using a miniature vehicle, different operator-vehicle interactions and input devices were compared based on collisions, task completion time, usability and workload. The evaluation revealed significant differences between the three implemented prototypes using a steering wheel, mouse and keyboard or a touchscreen. The separate input of path and velocity via mouse and keyboard or touchscreen is preferred but is slower compared to parallel input via steering wheel.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13697v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria-Magdalena Wolf, Richard Taupitz, Frank Diermeyer</dc:creator>
    </item>
    <item>
      <title>Counterfactual Reasoning Using Predicted Latent Personality Dimensions for Optimizing Persuasion Outcome</title>
      <link>https://arxiv.org/abs/2404.13792</link>
      <description>arXiv:2404.13792v1 Announce Type: cross 
Abstract: Customizing persuasive conversations related to the outcome of interest for specific users achieves better persuasion results. However, existing persuasive conversation systems rely on persuasive strategies and encounter challenges in dynamically adjusting dialogues to suit the evolving states of individual users during interactions. This limitation restricts the system's ability to deliver flexible or dynamic conversations and achieve suboptimal persuasion outcomes. In this paper, we present a novel approach that tracks a user's latent personality dimensions (LPDs) during ongoing persuasion conversation and generates tailored counterfactual utterances based on these LPDs to optimize the overall persuasion outcome. In particular, our proposed method leverages a Bi-directional Generative Adversarial Network (BiCoGAN) in tandem with a Dialogue-based Personality Prediction Regression (DPPR) model to generate counterfactual data. This enables the system to formulate alternative persuasive utterances that are more suited to the user. Subsequently, we utilize the D3QN model to learn policies for optimized selection of system utterances on counterfactual data. Experimental results we obtained from using the PersuasionForGood dataset demonstrate the superiority of our approach over the existing method, BiCoGAN. The cumulative rewards and Q-values produced by our method surpass ground truth benchmarks, showcasing the efficacy of employing counterfactual reasoning and LPDs to optimize reinforcement learning policy in online interactions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13792v1</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-58226-4_22</arxiv:DOI>
      <dc:creator>Donghuo Zeng, Roberto S. Legaspi, Yuewen Sun, Xinshuai Dong, Kazushi Ikeda, Peter Spirtes, kun Zhang</dc:creator>
    </item>
    <item>
      <title>Navigating the Path of Writing: Outline-guided Text Generation with Large Language Models</title>
      <link>https://arxiv.org/abs/2404.13919</link>
      <description>arXiv:2404.13919v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have significantly impacted the writing process, enabling collaborative content creation and enhancing productivity. However, generating high-quality, user-aligned text remains challenging. In this paper, we propose Writing Path, a framework that uses explicit outlines to guide LLMs in generating goal-oriented, high-quality pieces of writing. Our approach draws inspiration from structured writing planning and reasoning paths, focusing on capturing and reflecting user intentions throughout the writing process. We construct a diverse dataset from unstructured blog posts to benchmark writing performance and introduce a comprehensive evaluation framework assessing the quality of outlines and generated texts. Our evaluations with GPT-3.5-turbo, GPT-4, and HyperCLOVA X demonstrate that the Writing Path approach significantly enhances text quality according to both LLMs and human evaluations. This study highlights the potential of integrating writing-specific techniques into LLMs to enhance their ability to meet the diverse writing needs of users.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.13919v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yukyung Lee, Soonwon Ka, Bokyung Son, Pilsung Kang, Jaewook Kang</dc:creator>
    </item>
    <item>
      <title>Competition and Collaboration in Crowdsourcing Communities: What happens when peers evaluate each other?</title>
      <link>https://arxiv.org/abs/2404.14141</link>
      <description>arXiv:2404.14141v1 Announce Type: cross 
Abstract: Crowdsourcing has evolved as an organizational approach to distributed problem solving and innovation. As contests are embedded in online communities and evaluation rights are assigned to the crowd, community members face a tension: they find themselves exposed to both competitive motives to win the contest prize and collaborative participation motives in the community. The competitive motive suggests they may evaluate rivals strategically according to their self-interest, the collaborative motive suggests they may evaluate their peers truthfully according to mutual interest. Using field data from Threadless on 38 million peer evaluations of more than 150,000 submissions across 75,000 individuals over 10 years and two natural experiments to rule out alternative explanations, we answer the question of how community members resolve this tension. We show that as their skill level increases, they become increasingly competitive and shift from using self-promotion to sabotaging their closest competitors. However, we also find signs of collaborative behavior when high-skilled members show leniency toward those community members who do not directly threaten their chance of winning. We explain how the individual-level use of strategic evaluations translates into important organizational-level outcomes by affecting the community structure through individuals' long-term participation. While low-skill targets of sabotage are less likely to participate in future contests, high-skill targets are more likely. This suggests a feedback loop between competitive evaluation behavior and future participation. These findings have important implications for the literature on crowdsourcing design, and the evolution and sustainability of crowdsourcing communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.14141v1</guid>
      <category>econ.GN</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1287/orsc.2021.15163</arxiv:DOI>
      <arxiv:journal_reference>Organization Science, 2024</arxiv:journal_reference>
      <dc:creator>Christoph Riedl, Tom Grad, Christopher Lettl</dc:creator>
    </item>
    <item>
      <title>Two-In-One: A Design Space for Mapping Unimanual Input into Bimanual Interactions in VR for Users with Limited Movement</title>
      <link>https://arxiv.org/abs/2108.12390</link>
      <description>arXiv:2108.12390v3 Announce Type: replace 
Abstract: Virtual Reality (VR) applications often require users to perform actions with two hands when performing tasks and interacting with objects in virtual environments. Although bimanual interactions in VR can resemble real-world interactions -- thus increasing realism and improving immersion -- they can also pose significant accessibility challenges to people with limited mobility, such as for people who have full use of only one hand. An opportunity exists to create accessible techniques that take advantage of users' abilities, but designers currently lack structured tools to consider alternative approaches. To begin filling this gap, we propose Two-in-One, a design space that facilitates the creation of accessible methods for bimanual interactions in VR from unimanual input. Our design space comprises two dimensions, bimanual interactions and computer assistance, and we provide a detailed examination of issues to consider when creating new unimanual input techniques that map to bimanual interactions in VR. We used our design space to create three interaction techniques that we subsequently implemented for a subset of bimanual interactions and received user feedback through a video elicitation study with 17 people with limited mobility. Our findings explore complex tradeoffs associated with autonomy and agency and highlight the need for additional settings and methods to make VR accessible to people with limited mobility.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.12390v3</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3510463</arxiv:DOI>
      <dc:creator>Momona Yamagami, Sasa Junuzovic, Mar Gonzalez-Franco, Eyal Ofek, Edward Cutrell, John R. Porter, Andrew D. Wilson, Martez E. Mott</dc:creator>
    </item>
    <item>
      <title>When to Show a Suggestion? Integrating Human Feedback in AI-Assisted Programming</title>
      <link>https://arxiv.org/abs/2306.04930</link>
      <description>arXiv:2306.04930v3 Announce Type: replace 
Abstract: AI powered code-recommendation systems, such as Copilot and CodeWhisperer, provide code suggestions inside a programmer's environment (e.g., an IDE) with the aim of improving productivity. We pursue mechanisms for leveraging signals about programmers' acceptance and rejection of code suggestions to guide recommendations. We harness data drawn from interactions with GitHub Copilot, a system used by millions of programmers, to develop interventions that can save time for programmers. We introduce a utility-theoretic framework to drive decisions about suggestions to display versus withhold. The approach, conditional suggestion display from human feedback (CDHF), relies on a cascade of models that provide the likelihood that recommended code will be accepted. These likelihoods are used to selectively hide suggestions, reducing both latency and programmer verification time. Using data from 535 programmers, we perform a retrospective evaluation of CDHF and show that we can avoid displaying a significant fraction of suggestions that would have been rejected. We further demonstrate the importance of incorporating the programmer's latent unobserved state in decisions about when to display suggestions through an ablation study. Finally, we showcase how using suggestion acceptance as a reward signal for guiding the display of suggestions can lead to suggestions of reduced quality, indicating an unexpected pitfall.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.04930v3</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz</dc:creator>
    </item>
    <item>
      <title>(Social) Trouble on the Road: Understanding and Addressing Social Discomfort in Shared Car Trips</title>
      <link>https://arxiv.org/abs/2311.04456</link>
      <description>arXiv:2311.04456v2 Announce Type: replace 
Abstract: Unpleasant social interactions on the road can negatively affect driving safety. Could voice assistants reduce social discomfort in a car? We recorded nine families going on drives and performed interaction analysis on this data. We define three strategies to address social discomfort: contextual mediation, social mediation, and social support. We discuss impacts for engineering and design, and explore the limitations of current large language models in addressing social discomfort on the road.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04456v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexandra Bremers, Natalie Friedman, Sam Lee, Tong Wu, Eric Laurier, Malte Jung, Jorge Ortiz, Wendy Ju</dc:creator>
    </item>
    <item>
      <title>MERBench: A Unified Evaluation Benchmark for Multimodal Emotion Recognition</title>
      <link>https://arxiv.org/abs/2401.03429</link>
      <description>arXiv:2401.03429v3 Announce Type: replace 
Abstract: Multimodal emotion recognition plays a crucial role in enhancing user experience in human-computer interaction. Over the past few decades, researchers have proposed a series of algorithms and achieved impressive progress. Although each method shows its superior performance, different methods lack a fair comparison due to inconsistencies in feature extractors, evaluation manners, and experimental settings. These inconsistencies severely hinder the development of this field. Therefore, we build MERBench, a unified evaluation benchmark for multimodal emotion recognition. We aim to reveal the contribution of some important techniques employed in previous works, such as feature selection, multimodal fusion, robustness analysis, fine-tuning, pre-training, etc. We hope this benchmark can provide clear and comprehensive guidance for follow-up researchers. Based on the evaluation results of MERBench, we further point out some promising research directions. Additionally, we introduce a new emotion dataset MER2023, focusing on the Chinese language environment. This dataset can serve as a benchmark dataset for research on multi-label learning, noise robustness, and semi-supervised learning. We encourage the follow-up researchers to evaluate their algorithms under the same experimental setup as MERBench for fair comparisons. Our code is available at: https://github.com/zeroQiaoba/MERTools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03429v3</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zheng Lian, Licai Sun, Yong Ren, Hao Gu, Haiyang Sun, Lan Chen, Bin Liu, Jianhua Tao</dc:creator>
    </item>
    <item>
      <title>Effects of Multimodal Explanations for Autonomous Driving on Driving Performance, Cognitive Load, Expertise, Confidence, and Trust</title>
      <link>https://arxiv.org/abs/2401.04206</link>
      <description>arXiv:2401.04206v3 Announce Type: replace 
Abstract: Advances in autonomous driving provide an opportunity for AI-assisted driving instruction that directly addresses the critical need for human driving improvement. How should an AI instructor convey information to promote learning? In a pre-post experiment (n = 41), we tested the impact of an AI Coach's explanatory communications modeled after performance driving expert instructions. Participants were divided into four (4) groups to assess two (2) dimensions of the AI coach's explanations: information type ('what' and 'why'-type explanations) and presentation modality (auditory and visual). We compare how different explanatory techniques impact driving performance, cognitive load, confidence, expertise, and trust via observational learning. Through interview, we delineate participant learning processes. Results show AI coaching can effectively teach performance driving skills to novices. We find the type and modality of information influences performance outcomes. Differences in how successfully participants learned are attributed to how information directs attention, mitigates uncertainty, and influences overload experienced by participants. Results suggest efficient, modality-appropriate explanations should be opted for when designing effective HMI communications that can instruct without overwhelming. Further, results support the need to align communications with human learning and cognitive processes. We provide eight design implications for future autonomous vehicle HMI and AI coach design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.04206v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Kaufman, Jean Costa, Everlyne Kimani</dc:creator>
    </item>
    <item>
      <title>DrawTalking: Building Interactive Worlds by Sketching and Speaking</title>
      <link>https://arxiv.org/abs/2401.05631</link>
      <description>arXiv:2401.05631v3 Announce Type: replace 
Abstract: We introduce DrawTalking, an approach to building and controlling interactive worlds by sketching and speaking. It emphasizes user control and flexibility, and gives programming-like capability without requiring code. We built a prototype to demonstrate it. An early open-ended study shows the mechanics resonate and are applicable to many creative-exploratory use cases, with the potential to inspire and inform research in future natural interfaces for creative exploration and authoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05631v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karl Toby Rosenberg, Rubaiat Habib Kazi, Li-Yi Wei, Haijun Xia, Ken Perlin</dc:creator>
    </item>
    <item>
      <title>Exploring the Impact of AI Value Alignment in Collaborative Ideation: Effects on Perception, Ownership, and Output</title>
      <link>https://arxiv.org/abs/2402.12814</link>
      <description>arXiv:2402.12814v3 Announce Type: replace 
Abstract: AI-based virtual assistants are increasingly used to support daily ideation tasks. The values or bias present in these agents can influence output in hidden ways. They may also affect how people perceive the ideas produced with these AI agents and lead to implications for the design of AI-based tools. We explored the effects of AI agents with different values on the ideation process and user perception of idea quality, ownership, agent competence, and values present in the output. Our study tasked 180 participants with brainstorming practical solutions to a set of problems with AI agents of different values. Results show no significant difference in self-evaluation of idea quality and perception of the agent based on value alignment; however, ideas generated reflected the AI's values and feeling of ownership is affected. This highlights an intricate interplay between AI values and human ideation, suggesting careful design considerations for future AI-supported brainstorming tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12814v3</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alicia Guo, Pat Pataranutaporn, Pattie Maes</dc:creator>
    </item>
    <item>
      <title>Doing AI: Algorithmic decision support as a human activity</title>
      <link>https://arxiv.org/abs/2402.14674</link>
      <description>arXiv:2402.14674v2 Announce Type: replace 
Abstract: Algorithmic decision support (ADS), using Machine-Learning-based AI, is becoming a major part of many processes. Organizations introduce ADS to improve decision-making and use available data, thereby possibly limiting deviations from the normative "homo economicus" and the biases that characterize human decision-making. However, a closer look at the development and use of ADS systems in organizational settings reveals that they necessarily involve a series of largely unspecified human decisions. They begin with deliberations for which decisions to use ADS, continue with choices while developing and deploying the ADS, and end with decisions on how to use the ADS output in an organization's operations. The paper presents an overview of these decisions and some relevant behavioral phenomena. It points out directions for further research, which is essential for correctly assessing the processes and their vulnerabilities. Understanding these behavioral aspects is important for successfully implementing ADS in organizations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.14674v2</guid>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joachim Meyer</dc:creator>
    </item>
    <item>
      <title>Recourse for reclamation: Chatting with generative language models</title>
      <link>https://arxiv.org/abs/2403.14467</link>
      <description>arXiv:2403.14467v2 Announce Type: replace 
Abstract: Researchers and developers increasingly rely on toxicity scoring to moderate generative language model outputs, in settings such as customer service, information retrieval, and content generation. However, toxicity scoring may render pertinent information inaccessible, rigidify or "value-lock" cultural norms, and prevent language reclamation processes, particularly for marginalized people. In this work, we extend the concept of algorithmic recourse to generative language models: we provide users a novel mechanism to achieve their desired prediction by dynamically setting thresholds for toxicity filtering. Users thereby exercise increased agency relative to interactions with the baseline system. A pilot study ($n = 30$) supports the potential of our proposed recourse mechanism, indicating improvements in usability compared to fixed-threshold toxicity-filtering of model outputs. Future work should explore the intersection of toxicity scoring, model controllability, user agency, and language reclamation processes -- particularly with regard to the bias that many communities encounter when interacting with generative language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.14467v2</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613905.3650999</arxiv:DOI>
      <dc:creator>Jennifer Chien, Kevin R. McKee, Jackie Kay, William Isaac</dc:creator>
    </item>
    <item>
      <title>Negotiating the Shared Agency between Humans &amp; AI in the Recommender System</title>
      <link>https://arxiv.org/abs/2403.15919</link>
      <description>arXiv:2403.15919v3 Announce Type: replace 
Abstract: Smart recommendation algorithms have revolutionized information dissemination, enhancing efficiency and reshaping content delivery across various domains. However, concerns about user agency have arisen due to the inherent opacity (information asymmetry) and the nature of one-way output (power asymmetry) on algorithms. While both issues have been criticized by scholars via advocating explainable AI (XAI) and human-AI collaborative decision-making (HACD), few research evaluates their integrated effects on users, and few HACD discussions in recommender systems beyond improving and filtering the results. This study proposes an incubating idea as a missing step in HACD that allows users to control the degrees of AI-recommended content. Then, we integrate it with existing XAI to a flow prototype aimed at assessing the enhancement of user agency. We seek to understand how types of agency impact user perception and experience, and bring empirical evidence to refine the guidelines and designs for human-AI interactive systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.15919v3</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mengke Wu, Weizi Liu, Yanyun Wang, Mike Yao</dc:creator>
    </item>
    <item>
      <title>Ink and Individuality: Crafting a Personalised Narrative in the Age of LLMs</title>
      <link>https://arxiv.org/abs/2404.00026</link>
      <description>arXiv:2404.00026v3 Announce Type: replace 
Abstract: Individuality and personalization comprise the distinctive characteristics that make each writer unique and influence their words in order to effectively engage readers while conveying authenticity. However, our growing reliance on LLM-based writing assistants risks compromising our creativity and individuality over time. We often overlook the negative impacts of this trend on our creativity and uniqueness, despite the possible consequences. This study investigates these concerns by performing a brief survey to explore different perspectives and concepts, as well as trying to understand people's viewpoints, in conjunction with past studies in the area. Addressing these issues is essential for improving human-computer interaction systems and enhancing writing assistants for personalization and individuality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00026v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Azmine Toushik Wasi, Raima Islam, Mst Rafia Islam</dc:creator>
    </item>
    <item>
      <title>LLMs as Writing Assistants: Exploring Perspectives on Sense of Ownership and Reasoning</title>
      <link>https://arxiv.org/abs/2404.00027</link>
      <description>arXiv:2404.00027v3 Announce Type: replace 
Abstract: Sense of ownership in writing confines our investment of thoughts, time, and contribution, leading to attachment to the output. However, using writing assistants introduces a mental dilemma, as some content isn't directly our creation. For instance, we tend to credit Large Language Models (LLMs) more in creative tasks, even though all tasks are equal for them. Additionally, while we may not claim complete ownership of LLM-generated content, we freely claim authorship. We conduct a short survey to examine these issues and understand underlying cognitive processes in order to gain a better knowledge of human-computer interaction in writing and improve writing aid systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00027v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Azmine Toushik Wasi, Mst Rafia Islam, Raima Islam</dc:creator>
    </item>
    <item>
      <title>A Typology of Decision-Making Tasks for Visualization</title>
      <link>https://arxiv.org/abs/2404.08812</link>
      <description>arXiv:2404.08812v2 Announce Type: replace 
Abstract: Despite decision-making being a vital goal of data visualization, little work has been done to differentiate the decision-making tasks within our field. While visualization task taxonomies and typologies exist, they are often too granular for describing complex decision goals and decision-making processes, thus limiting their potential use in designing decision-support tools. In this paper, we contribute a typology of decision-making tasks that were iteratively refined from a list of design goals distilled from a literature review. Our typology is concise and consists of only three tasks: choose, activate, and create. Originally proposed by the scientific community, we extend and provide definitions for these tasks that are suitable for the visualization community. Our proposed typology offers two benefits. First, it facilitates the composition of decisions using these three tasks, allowing for flexible and clear descriptions across varying complexities and domains. Second, diagrams created using this typology encourage productive discourse between visualization designers and domain experts by abstracting the intricacies of data, thereby promoting clarity and rigorous analysis of decision-making processes. We motivate the use of our typology through four case studies and demonstrate the benefits of our approach through semi-structured interviews conducted with experienced members of the visualization community, comprising academic and industry experts, who have contributed to developing or publishing decision support systems for domain experts. Our interviewees composed diagrams using our typology to delineate the decision-making processes that drive their decision-support tools, demonstrating its descriptive capacity and effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08812v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Camelia D. Brumar, Sam Molnar, Gabriel Appleby, Kristi Potter, Remco Chang</dc:creator>
    </item>
    <item>
      <title>A Longitudinal Study of Child Wellbeing Assessment via Online Interactions with a Social Robots</title>
      <link>https://arxiv.org/abs/2404.10593</link>
      <description>arXiv:2404.10593v2 Announce Type: replace 
Abstract: Socially Assistive Robots are studied in different Child-Robot Interaction settings. However, logistical constraints limit accessibility, particularly affecting timely support for mental wellbeing. In this work, we have investigated whether online interactions with a robot can be used for the assessment of mental wellbeing in children. The children (N=40, 20 girls and 20 boys; 8-13 years) interacted with the Nao robot (30-45 mins) over three sessions, at least a week apart. Audio-visual recordings were collected throughout the sessions that concluded with the children answering user perception questionnaires pertaining to their anxiety towards the robot, and the robot's abilities. We divided the participants into three wellbeing clusters (low, med and high tertiles) using their responses to the Short Moods and Feelings Questionnaire (SMFQ) and further analysed how their wellbeing and their perceptions of the robot changed over the wellbeing tertiles, across sessions and across participants' gender. Our primary findings suggest that (I) online mediated-interactions with robots can be effective in assessing children's mental wellbeing over time, and (II) children's overall perception of the robot either improved or remained consistent across time. Supplementary exploratory analyses have also revealed that gender affected the children's wellbeing assessments as well as their perceptions of the robot.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10593v2</guid>
      <category>cs.HC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nida Itrat Abbasi, Guy Laban, Tamsin Ford, Peter B. Jones, Hatice Gunes</dc:creator>
    </item>
    <item>
      <title>Characterizing and modeling harms from interactions with design patterns in AI interfaces</title>
      <link>https://arxiv.org/abs/2404.11370</link>
      <description>arXiv:2404.11370v2 Announce Type: replace 
Abstract: The proliferation of applications using artificial intelligence (AI) systems has led to a growing number of users interacting with these systems through sophisticated interfaces. Human-computer interaction research has long shown that interfaces shape both user behavior and user perception of technical capabilities and risks. Yet, practitioners and researchers evaluating the social and ethical risks of AI systems tend to overlook the impact of anthropomorphic, deceptive, and immersive interfaces on human-AI interactions. Here, we argue that design features of interfaces with adaptive AI systems can have cascading impacts, driven by feedback loops, which extend beyond those previously considered. We first conduct a scoping review of AI interface designs and their negative impact to extract salient themes of potentially harmful design patterns in AI interfaces. Then, we propose Design-Enhanced Control of AI systems (DECAI), a conceptual model to structure and facilitate impact assessments of AI interface designs. DECAI draws on principles from control systems theory -- a theory for the analysis and design of dynamic physical systems -- to dissect the role of the interface in human-AI systems. Through two case studies on recommendation systems and conversational language model systems, we show how DECAI can be used to evaluate AI interface designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11370v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lujain Ibrahim, Luc Rocher, Ana Valdivia</dc:creator>
    </item>
    <item>
      <title>Reading Between the Lines: Modeling User Behavior and Costs in AI-Assisted Programming</title>
      <link>https://arxiv.org/abs/2210.14306</link>
      <description>arXiv:2210.14306v5 Announce Type: replace-cross 
Abstract: Code-recommendation systems, such as Copilot and CodeWhisperer, have the potential to improve programmer productivity by suggesting and auto-completing code. However, to fully realize their potential, we must understand how programmers interact with these systems and identify ways to improve that interaction. To seek insights about human-AI collaboration with code recommendations systems, we studied GitHub Copilot, a code-recommendation system used by millions of programmers daily. We developed CUPS, a taxonomy of common programmer activities when interacting with Copilot. Our study of 21 programmers, who completed coding tasks and retrospectively labeled their sessions with CUPS, showed that CUPS can help us understand how programmers interact with code-recommendation systems, revealing inefficiencies and time costs. Our insights reveal how programmers interact with Copilot and motivate new interface designs and metrics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.14306v5</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussein Mozannar, Gagan Bansal, Adam Fourney, Eric Horvitz</dc:creator>
    </item>
    <item>
      <title>Closing the Gap in High-Risk Pregnancy Care Using Machine Learning and Human-AI Collaboration</title>
      <link>https://arxiv.org/abs/2305.17261</link>
      <description>arXiv:2305.17261v3 Announce Type: replace-cross 
Abstract: A high-risk pregnancy is a pregnancy complicated by factors that can adversely affect the outcomes of the mother or the infant. Health insurers use algorithms to identify members who would benefit from additional clinical support. This work presents the implementation of a real-world ML-based system to assist care managers in identifying pregnant patients at risk of complications. In this retrospective evaluation study, we developed a novel hybrid-ML classifier to predict whether patients are pregnant and trained a standard classifier using claims data from a health insurance company in the US to predict whether a patient will develop pregnancy complications. These models were developed in cooperation with the care management team and integrated into a user interface with explanations for the nurses. The proposed models outperformed commonly used claim codes for the identification of pregnant patients at the expense of a manageable false positive rate. Our risk complication classifier shows that we can accurately triage patients by risk of complication. Our approach and evaluation are guided by human-centric design. In user studies with the nurses, they preferred the proposed models over existing approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.17261v3</guid>
      <category>cs.LG</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hussein Mozannar, Yuria Utsumi, Irene Y. Chen, Stephanie S. Gervasi, Michele Ewing, Aaron Smith-McLallen, David Sontag</dc:creator>
    </item>
    <item>
      <title>PCNN: Probable-Class Nearest-Neighbor Explanations Improve Fine-Grained Image Classification Accuracy for AIs and Humans</title>
      <link>https://arxiv.org/abs/2308.13651</link>
      <description>arXiv:2308.13651v2 Announce Type: replace-cross 
Abstract: Nearest neighbors (NN) are traditionally used to compute final decisions, e.g., in Support Vector Machines or k-NN classifiers, and to provide users with explanations for the model's decision. In this paper, we show a novel utility of nearest neighbors: To improve predictions of a frozen, pretrained classifier C. We leverage an image comparator S that (1) compares the input image with NN images from the top-K most probable classes; and (2) uses S's output scores to weight the confidence scores of C. Our method consistently improves fine-grained image classification accuracy on CUB-200, Cars-196, and Dogs-120. Also, a human study finds that showing lay users our probable-class nearest neighbors (PCNN) improves their decision accuracy over prior work which only shows only the top-1 class examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.13651v2</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giang Nguyen, Valerie Chen, Mohammad Reza Taesiri, Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>Domain-Specific Fine-Tuning of Large Language Models for Interactive Robot Programming</title>
      <link>https://arxiv.org/abs/2312.13905</link>
      <description>arXiv:2312.13905v2 Announce Type: replace-cross 
Abstract: Industrial robots are applied in a widening range of industries, but robot programming mostly remains a task limited to programming experts. We propose a natural language-based assistant for programming of advanced, industrial robotic applications and investigate strategies for domain-specific fine-tuning of foundation models with limited data and compute.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.13905v2</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Benjamin Alt, Urs Ke{\ss}ner, Aleksandar Taranovic, Darko Katic, Andreas Hermann, Rainer J\"akel, Gerhard Neumann</dc:creator>
    </item>
    <item>
      <title>Harnessing Smartwatch Microphone Sensors for Cough Detection and Classification</title>
      <link>https://arxiv.org/abs/2401.17738</link>
      <description>arXiv:2401.17738v2 Announce Type: replace-cross 
Abstract: This study investigates the potential of using smartwatches with built-in microphone sensors for monitoring coughs and detecting various cough types. We conducted a study involving 32 participants and collected 9 hours of audio data in a controlled manner. Afterward, we processed this data using a structured approach, resulting in 223 positive cough samples. We further improved the dataset through augmentation techniques and employed a specialized 1D CNN model. This model achieved an impressive accuracy rate of 98.49% while non-walking and 98.2% while walking, showing smartwatches can detect cough. Moreover, our research successfully identified four distinct types of coughs using clustering techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.17738v2</guid>
      <category>cs.SD</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>eess.AS</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pranay Jaiswal, Haroon R. Lone</dc:creator>
    </item>
    <item>
      <title>What AIs are not Learning (and Why): Bio-Inspired Foundation Models for Robots</title>
      <link>https://arxiv.org/abs/2404.04267</link>
      <description>arXiv:2404.04267v5 Announce Type: replace-cross 
Abstract: It is hard to build robots (including telerobots) that are useful, and harder to build autonomous robots that are robust and general. Current robots are built using manual programming, mathematical models, planning frameworks, and reinforcement learning. These methods do not lead to the leaps in performance and generality seen with deep learning, generative AI, and foundation models (FMs). Today's robots do not learn to provide home care, to be nursing assistants, or to do household chores and other services reliably. Addressing the aspirational opportunities of robot service applications requires improving the path to get there. The high cost of bipedal multi-sensory robots ("bodies") is a significant obstacle for both research and deployment. A deeper issue is that mainstream FMs ("minds") do not support sensing and acting in the world. They do not lead to robots that experiment, communicate, or collaborate. They do not lead to robots that learn from and with others. They do not lead to robots that know enough to be deployed in service applications. This paper focuses on what service robots need to know. It recommends developing experiential FMs for bootstrapping service robots.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04267v5</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mark Stefik</dc:creator>
    </item>
    <item>
      <title>Allowing humans to interactively guide machines where to look does not always improve human-AI team's classification accuracy</title>
      <link>https://arxiv.org/abs/2404.05238</link>
      <description>arXiv:2404.05238v3 Announce Type: replace-cross 
Abstract: Via thousands of papers in Explainable AI (XAI), attention maps \cite{vaswani2017attention} and feature importance maps \cite{bansal2020sam} have been established as a common means for finding how important each input feature is to an AI's decisions. It is an interesting, unexplored question whether allowing users to edit the feature importance at test time would improve a human-AI team's accuracy on downstream tasks. In this paper, we address this question by leveraging CHM-Corr, a state-of-the-art, ante-hoc explainable classifier \cite{taesiri2022visual} that first predicts patch-wise correspondences between the input and training-set images, and then bases on them to make classification decisions. We build CHM-Corr++, an interactive interface for CHM-Corr, enabling users to edit the feature importance map provided by CHM-Corr and observe updated model decisions. Via CHM-Corr++, users can gain insights into if, when, and how the model changes its outputs, improving their understanding beyond static explanations. However, our study with 18 expert users who performed 1,400 decisions finds no statistical significance that our interactive approach improves user accuracy on CUB-200 bird image classification over static explanations. This challenges the hypothesis that interactivity can boost human-AI team accuracy and raises needs for future research. We open-source CHM-Corr++, an interactive tool for editing image classifier attention (see an interactive demo here: http://137.184.82.109:7080/). We release code and data on github: https://github.com/anguyen8/chm-corr-interactive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05238v3</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Giang Nguyen, Mohammad Reza Taesiri, Sunnie S. Y. Kim, Anh Nguyen</dc:creator>
    </item>
    <item>
      <title>EyeFormer: Predicting Personalized Scanpaths with Transformer-Guided Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2404.10163</link>
      <description>arXiv:2404.10163v2 Announce Type: replace-cross 
Abstract: From a visual perception perspective, modern graphical user interfaces (GUIs) comprise a complex graphics-rich two-dimensional visuospatial arrangement of text, images, and interactive objects such as buttons and menus. While existing models can accurately predict regions and objects that are likely to attract attention ``on average'', so far there is no scanpath model capable of predicting scanpaths for an individual. To close this gap, we introduce EyeFormer, which leverages a Transformer architecture as a policy network to guide a deep reinforcement learning algorithm that controls gaze locations. Our model has the unique capability of producing personalized predictions when given a few user scanpath samples. It can predict full scanpath information, including fixation positions and duration, across individuals and various stimulus types. Additionally, we demonstrate applications in GUI layout optimization driven by our model. Our software and models will be publicly available.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10163v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Jiang, Zixin Guo, Hamed Rezazadegan Tavakoli, Luis A. Leiva, Antti Oulasvirta</dc:creator>
    </item>
    <item>
      <title>Large Language Models for Synthetic Participatory Planning of Shared Automated Electric Mobility Systems</title>
      <link>https://arxiv.org/abs/2404.12317</link>
      <description>arXiv:2404.12317v2 Announce Type: replace-cross 
Abstract: Unleashing the synergies of rapidly evolving mobility technologies in a multi-stakeholder landscape presents unique challenges and opportunities for addressing urban transportation problems. This paper introduces a novel synthetic participatory method, critically leveraging large language models (LLMs) to create digital avatars representing diverse stakeholders to plan shared automated electric mobility systems (SAEMS). These calibratable agents collaboratively identify objectives, envision and evaluate SAEMS alternatives, and strategize implementation under risks and constraints. The results of a Montreal case study indicate that a structured and parameterized workflow provides outputs with high controllability and comprehensiveness on an SAEMS plan than generated using a single LLM-enabled expert agent. Consequently, the approach provides a promising avenue for cost-efficiently improving the inclusivity and interpretability of multi-objective transportation planning, suggesting a paradigm shift in how we envision and strategize for sustainable and equitable transportation systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12317v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiangbo Yu</dc:creator>
    </item>
  </channel>
</rss>
