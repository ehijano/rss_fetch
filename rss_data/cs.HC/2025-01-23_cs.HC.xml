<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 24 Jan 2025 02:37:53 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Understanding the LLM-ification of CHI: Unpacking the Impact of LLMs at CHI through a Systematic Literature Review</title>
      <link>https://arxiv.org/abs/2501.12557</link>
      <description>arXiv:2501.12557v1 Announce Type: new 
Abstract: Large language models (LLMs) have been positioned to revolutionize HCI, by reshaping not only the interfaces, design patterns, and sociotechnical systems that we study, but also the research practices we use. To-date, however, there has been little understanding of LLMs' uptake in HCI. We address this gap via a systematic literature review of 153 CHI papers from 2020-24 that engage with LLMs. We taxonomize: (1) domains where LLMs are applied; (2) roles of LLMs in HCI projects; (3) contribution types; and (4) acknowledged limitations and risks. We find LLM work in 10 diverse domains, primarily via empirical and artifact contributions. Authors use LLMs in five distinct roles, including as research tools or simulated users. Still, authors often raise validity and reproducibility concerns, and overwhelmingly study closed models. We outline opportunities to improve HCI research with and on LLMs, and provide guiding questions for researchers to consider the validity and appropriateness of LLM-related work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12557v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rock Yuren Pang, Hope Schroeder, Kynnedy Simone Smith, Solon Barocas, Ziang Xiao, Emily Tseng, Danielle Bragg</dc:creator>
    </item>
    <item>
      <title>Bridging the Digital Divide: Approach to Documenting Early Computing Artifacts Using Established Standards for Cross-Collection Knowledge Integration Ontology</title>
      <link>https://arxiv.org/abs/2501.12603</link>
      <description>arXiv:2501.12603v1 Announce Type: new 
Abstract: In this paper we address the challenges of documenting early digital artifacts in collections built to offer historical context for future generations. Through insights from active community members (N=20), we examine current archival needs and obstacles. We assess the potential of the CIDOC Conceptual Reference Model (CRM) for categorizing fragmented digital data. Despite its complexity, CIDOC-CRM proves logical, human-readable, and adaptable, enabling archivists to select minimal yet effective building blocks set to empower community-led heritage projects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12603v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maciej Grzeszczuk, Kinga Skorupska, Grzegorz Marcin Wojcik</dc:creator>
    </item>
    <item>
      <title>As Confidence Aligns: Exploring the Effect of AI Confidence on Human Self-confidence in Human-AI Decision Making</title>
      <link>https://arxiv.org/abs/2501.12868</link>
      <description>arXiv:2501.12868v1 Announce Type: new 
Abstract: Complementary collaboration between humans and AI is essential for human-AI decision making. One feasible approach to achieving it involves accounting for the calibrated confidence levels of both AI and users. However, this process would likely be made more difficult by the fact that AI confidence may influence users' self-confidence and its calibration. To explore these dynamics, we conducted a randomized behavioral experiment. Our results indicate that in human-AI decision-making, users' self-confidence aligns with AI confidence and such alignment can persist even after AI ceases to be involved. This alignment then affects users' self-confidence calibration. We also found the presence of real-time correctness feedback of decisions reduced the degree of alignment. These findings suggest that users' self-confidence is not independent of AI confidence, which practitioners aiming to achieve better human-AI collaboration need to be aware of. We call for research focusing on the alignment of human cognition and behavior with AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12868v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingshu Li, Yitian Yang, Q. Vera Liao, Junti Zhang, Yi-Chieh Lee</dc:creator>
    </item>
    <item>
      <title>Not Just a Number: A Multidimensional Approach to Ageing in HCI</title>
      <link>https://arxiv.org/abs/2501.12924</link>
      <description>arXiv:2501.12924v1 Announce Type: new 
Abstract: The focus on managing problems that can arise for older adults has meant that extant HCI and Ageing research has not given the concepts of 'age' and 'ageing' the explicit theoretical attention they deserve. Attending to this gap, we critically examine a ten-year corpus of CHI publications through the lens of an existing typology which we have further developed to analyse how age is understood, interpreted and constructed in the field of HCI. Our resulting multidimensional typology of age in HCI elucidates the distinctive characteristics of older adults considered when designing with and for this user group, but also highlights the need for a more critical, reflexive, social constructivist approach to age in HCI. Applying this approach, we explore age as a multidimensional system of stratification to better understand the phenomenon of the age-based digital divide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12924v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bran Knowles, Jasmine Fledderjohann, Aneesha Singh, Richard Harper, Julia McDowell, Judith Tsouvalis, Alice Ashcroft, Yvonne Rogers, Ewan Soubutts, Andrew Steptoe, Caroline Swarbrick</dc:creator>
    </item>
    <item>
      <title>Characterizing Collective Efforts in Content Sharing and Quality Control for ADHD-relevant Content on Video-sharing Platforms</title>
      <link>https://arxiv.org/abs/2501.13020</link>
      <description>arXiv:2501.13020v1 Announce Type: new 
Abstract: Video-sharing platforms (VSPs) have become increasingly important for individuals with ADHD to recognize symptoms, acquire knowledge, and receive support. While videos offer rich information and high engagement, they also present unique challenges, such as information quality and accessibility issues to users with ADHD. However, little work has thoroughly examined the video content quality and accessibility issues, the impact, and the control strategies in the ADHD community. We fill this gap by systematically collecting 373 ADHD-relevant videos with comments from YouTube and TikTok and analyzing the data with a mixed method. Our study identified the characteristics of ADHD-relevant videos on VSPs (e.g., creator types, video presentation forms, quality issues) and revealed the collective efforts of creators and viewers in video quality control, such as authority building, collective quality checking, and accessibility improvement. We further derive actionable design implications for VSPs to offer more reliable and ADHD-friendly contents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13020v1</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanxiu 'Hazel' Zhu, Avanthika Senthil Kumar, Sihang Zhao, Ru Wang, Xin Tong, Yuhang Zhao</dc:creator>
    </item>
    <item>
      <title>ELEGNT: Expressive and Functional Movement Design for Non-anthropomorphic Robot</title>
      <link>https://arxiv.org/abs/2501.12493</link>
      <description>arXiv:2501.12493v1 Announce Type: cross 
Abstract: Nonverbal behaviors such as posture, gestures, and gaze are essential for conveying internal states, both consciously and unconsciously, in human interaction. For robots to interact more naturally with humans, robot movement design should likewise integrate expressive qualities, such as intention, attention, and emotions, alongside traditional functional considerations like task fulfillment and time efficiency. In this paper, we present the design and prototyping of a lamp-like robot that explores the interplay between functional and expressive objectives in movement design. Using a research-through-design methodology, we document the hardware design process, define expressive movement primitives, and outline a set of interaction scenario storyboards. We propose a framework that incorporates both functional and expressive utilities during movement generation, and implement the robot behavior sequences in different function- and social- oriented tasks. Through a user study comparing expression-driven versus function-driven movements across six task scenarios, our findings indicate that expression-driven movements significantly enhance user engagement and perceived robot qualities. This effect is especially pronounced in social-oriented tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12493v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhan Hu, Peide Huang, Mouli Sivapurapu, Jian Zhang</dc:creator>
    </item>
    <item>
      <title>A Basis for Human Responsibility in Artificial Intelligence Computation</title>
      <link>https://arxiv.org/abs/2501.12498</link>
      <description>arXiv:2501.12498v1 Announce Type: cross 
Abstract: Recent advancements in artificial intelligence have reopened the question about the boundaries of AI autonomy, particularly in discussions around artificial general intelligence (AGI) and its potential to act independently across varied purposes. This paper explores these boundaries through the analysis of the Alignment Research Center experiment on GPT-4 and introduces the Start Button Problem, a thought experiment that examines the origins and limits of AI autonomy. By examining the thought experiment and its counterarguments will be enlightened how in the need for human activation and purpose definition lies the AI's inherent dependency on human-initiated actions, challenging the assumption of AI as an agent. Finally, the paper addresses the implications of this dependency on human responsibility, questioning the measure of the extension of human responsibility when using AI systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12498v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vincenzo Calderonio</dc:creator>
    </item>
    <item>
      <title>Leveraging LLMs to Create a Haptic Devices' Recommendation System</title>
      <link>https://arxiv.org/abs/2501.12573</link>
      <description>arXiv:2501.12573v1 Announce Type: cross 
Abstract: Haptic technology has seen significant growth, yet a lack of awareness of existing haptic device design knowledge hinders development. This paper addresses these limitations by leveraging advancements in Large Language Models (LLMs) to develop a haptic agent, focusing specifically on Grounded Force Feedback (GFF) devices recommendation. Our approach involves automating the creation of a structured haptic device database using information from research papers and product specifications. This database enables the recommendation of relevant GFF devices based on user queries. To ensure precise and contextually relevant recommendations, the system employs a dynamic retrieval method that combines both conditional and semantic searches. Benchmarking against the established UEQ and existing haptic device searching tools, the proposed haptic recommendation agent ranks in the top 10\% across all UEQ categories with mean differences favoring the agent in nearly all subscales, and maintains no significant performance bias across different user groups, showcasing superior usability and user satisfaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12573v1</guid>
      <category>cs.MM</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yang Liu, Haiwei Dong, Abdulmotaleb El Saddik</dc:creator>
    </item>
    <item>
      <title>Mechanism Design for Blockchain Order Books against Selfish Miners</title>
      <link>https://arxiv.org/abs/2501.12576</link>
      <description>arXiv:2501.12576v1 Announce Type: cross 
Abstract: In blockchain-based order book systems, buyers and sellers trade assets, while it is miners to match them and include their transactions in the blockchain. It is found that many miners behave selfishly and myopically, prioritizing transactions with high fees and ignoring many desirable matches that could enhance social welfare. Existing blockchain mechanisms fail to address this issue by overlooking miners' selfish behaviors. To our best knowledge, this work presents the first analytical study to quantify and understand buyer and seller transaction fee choices and selfish miners' transaction matching strategies, proving an infinitely large price of anarchy (PoA) for social welfare loss. To mitigate this, we propose an adjustable block size mechanism that is easy to implement without altering the existing decentralized protocols and still allows buyers and sellers to freely decide transaction fees and miners to selfishly match. The analysis is challenging, as pure strategy Nash equilibria do not always exist, requiring the analysis of many buyers' or sellers' interactive mixed-strategy distributions. Moreover, the system designer may even lack information about each buyer's or seller's bid/ask prices and trading quantities. Nevertheless, our mechanism achieves a well-bounded PoA, and under the homogeneous-quantity trading for non-fungible tokens (NFT), it attains a PoA of 1 with no social welfare loss. We implement our mechanism on a local instance of Ethereum to demonstrate the feasibility of our approach. Experiments based on the realistic dataset demonstrate that our mechanism achieves social optimum for homogeneous-quantity trading like NFT. It can enhance social welfare up to 3.7 times compared to the existing order book benchmarks for heterogeneous-quantity trading of Bitcoin tokens. It exhibits robustness against random variations in buyers and sellers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12576v1</guid>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Yunshu Liu, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Designing and Evaluating an Educational Recommender System with Different Levels of User Control</title>
      <link>https://arxiv.org/abs/2501.12894</link>
      <description>arXiv:2501.12894v1 Announce Type: cross 
Abstract: Educational recommender systems (ERSs) play a crucial role in personalizing learning experiences and enhancing educational outcomes by providing recommendations of personalized resources and activities to learners, tailored to their individual learning needs. However, their effectiveness is often diminished by insufficient user control and limited transparency. To address these challenges, in this paper, we present the systematic design and evaluation of an interactive ERS, in which we introduce different levels of user control. Concretely, we introduce user control around the input (i.e., user profile), process (i.e., recommendation algorithm), and output (i.e., recommendations) of the ERS. To evaluate our system, we conducted an online user study (N=30) to explore the impact of user control on users' perceptions of the ERS in terms of several important user-centric aspects. Moreover, we investigated the effects of user control on multiple recommendation goals, namely transparency, trust, and satisfaction, as well as the interactions between these goals. Our results demonstrate the positive impact of user control on user perceived benefits of the ERS. Moreover, our study shows that user control strongly correlates with transparency and moderately correlates with trust and satisfaction. In terms of interaction between these goals, our results reveal that transparency moderately correlates and trust strongly correlates with satisfaction. Whereas, transparency and trust stand out as less correlated with each other.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12894v1</guid>
      <category>cs.IR</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qurat Ul Ain, Mohamed Amine Chatti, William Kana Tsoplefack, Rawaa Alatrash, Shoeb Joarder</dc:creator>
    </item>
    <item>
      <title>Development of the Critical Reflection and Agency in Computing Index</title>
      <link>https://arxiv.org/abs/2501.13060</link>
      <description>arXiv:2501.13060v1 Announce Type: cross 
Abstract: As computing's societal impact grows, so does the need for computing students to recognize and address the ethical and sociotechnical implications of their work. While there are efforts to integrate ethics into computing curricula, we lack a standardized tool to measure those efforts, specifically, students' attitudes towards ethical reflection and their ability to effect change. This paper introduces the novel framework of Critically Conscious Computing and reports on the development and content validation of the Critical Reflection and Agency in Computing Index, a novel instrument designed to assess undergraduate computing students' attitudes towards practicing critically conscious computing. The resulting index is a theoretically grounded, expert-reviewed tool to support research and practice in computing ethics education. This enables researchers and educators to gain insights into students' perspectives, inform the design of targeted ethics interventions, and measure the effectiveness of computing ethics education initiatives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13060v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3706598.3713189</arxiv:DOI>
      <dc:creator>Aadarsh Padiyath, Mark Guzdial, Barbara Ericson</dc:creator>
    </item>
    <item>
      <title>ChoiceMates: Supporting Unfamiliar Online Decision-Making with Multi-Agent Conversational Interactions</title>
      <link>https://arxiv.org/abs/2310.01331</link>
      <description>arXiv:2310.01331v3 Announce Type: replace 
Abstract: From deciding on a PhD program to buying a new camera, unfamiliar decisions--decisions without domain knowledge--are frequent and significant. The complexity and uncertainty of such decisions demand unique approaches to information seeking, understanding, and decision-making. Our formative study highlights that users want to start by discovering broad and relevant domain information evenly and simultaneously, quickly address emerging inquiries, and gain personalized standards to assess information found. We present ChoiceMates, an interactive multi-agent system designed to address these needs by enabling users to engage with a dynamic set of LLM agents each presenting a unique experience in the domain. Unlike existing multi-agent systems that automate tasks with agents, the user orchestrates agents to assist their decision-making process. Our user evaluation (n=12) shows that ChoiceMates enables a more confident, satisfactory decision-making with better situation understanding than web search, and higher decision quality and confidence than a commercial multi-agent framework. This work provides insights into designing a more controllable and collaborative multi-agent system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.01331v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jeongeon Park, Bryan Min, Kihoon Son, Jean Y. Song, Xiaojuan Ma, Juho Kim</dc:creator>
    </item>
    <item>
      <title>Can AI Prompt Humans? Multimodal Agents Prompt Players' Game Actions and Show Consequences to Raise Sustainability Awareness</title>
      <link>https://arxiv.org/abs/2409.08486</link>
      <description>arXiv:2409.08486v4 Announce Type: replace 
Abstract: Unsustainable behaviors are challenging to prevent due to their long-term, often unclear consequences. Games offer a promising solution by creating artificial environments where players can immediately experience the outcomes of their actions. To explore this potential, we developed EcoEcho, a GenAI-powered game leveraging multimodal agents to raise sustainability awareness. These agents engage players in natural conversations, prompting them to take in-game actions that lead to visible environmental impacts. We evaluated EcoEcho using a mixed-methods approach with 23 participants. Results show a significant increase in intended sustainable behaviors post-game, although attitudes towards sustainability only slightly improved. This finding highlights the potential of multimodal agents and action-consequence mechanics to effectively motivate real-world behavioral changes such as raising environmental sustainability awareness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08486v4</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qinshi Zhang, Ruoyu Wen, Latisha Besariani Hendra, Zijian Ding, Ray LC</dc:creator>
    </item>
    <item>
      <title>PaperWave: Listening to Research Papers as Conversational Podcasts Scripted by LLM</title>
      <link>https://arxiv.org/abs/2410.15023</link>
      <description>arXiv:2410.15023v2 Announce Type: replace 
Abstract: Listening to audio content, such as podcasts and audiobooks, is one way for people to engage with knowledge. Listening affords people more mobility than reading by seeing, thereby broadening their learning opportunities. This study explores the potential applications of large language models (LLMs) to adapt text documents to audio content and addresses the lack of listening-friendly materials for niche content, such as research papers. LLMs can generate scripts of audio content in various styles tailored to specific needs, such as full-content duration or speech types (monologue or dialogue). To explore this potential, we developed PaperWave as a prototype that transforms academic paper PDFs into conversational podcasts. Our two-month investigation, involving 11 participants (including the authors), employed an autobiographical design, a field study, and a design workshop. The findings highlight the importance of considering listener interaction with their environment when designing document-to-audio systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.15023v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3706599.3706664</arxiv:DOI>
      <dc:creator>Yuchi Yahagi, Rintaro Chujo, Yuga Harada, Changyo Han, Kohei Sugiyama, Takeshi Naemura</dc:creator>
    </item>
    <item>
      <title>"We do use it, but not how hearing people think": How the Deaf and Hard of Hearing Community Uses Large Language Model Tools</title>
      <link>https://arxiv.org/abs/2410.21358</link>
      <description>arXiv:2410.21358v3 Announce Type: replace 
Abstract: Generative AI tools, particularly those utilizing large language models (LLMs), are increasingly used in everyday contexts. While these tools enhance productivity and accessibility, little is known about how Deaf and Hard of Hearing (DHH) individuals engage with them or the challenges they face when using them. This paper presents a mixed-method study exploring how the DHH community uses Text AI tools like ChatGPT to reduce communication barriers and enhance information access. We surveyed 80 DHH participants and conducted interviews with 11 participants. Our findings reveal important benefits, such as eased communication and bridging Deaf and hearing cultures, alongside challenges like lack of American Sign Language (ASL) support and Deaf cultural understanding. We highlight unique usage patterns, propose inclusive design recommendations, and outline future research directions to improve Text AI accessibility for the DHH community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21358v3</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuxu Huffman, Si Chen, Kelly Avery Mack, Haotian Su, Qi Wang, Raja Kushalnagar</dc:creator>
    </item>
    <item>
      <title>A Tale of Two Models: Understanding Data Workers' Internal and External Representations of Complex Data</title>
      <link>https://arxiv.org/abs/2501.09862</link>
      <description>arXiv:2501.09862v2 Announce Type: replace 
Abstract: Data workers may have a a different mental model of their data that the one reified in code. Understanding the organization of their data is necessary for analyzing data, be it through scripting, visualization or abstract thought. More complicated organizations, such as tables with attached hierarchies, may tax people's ability to think about and interact with data. To better understand and ultimately design for these situations, we conduct a study across a team of ten people working with the same reified data model. Through interviews and sketching, we probed their conception of the data model and developed themes through reflexive data analysis. Participants had diverse data models that differed from the reified data model, even among team members who had designed the model, resulting in parallel hazards limiting their ability to reason about the data. From these observations, we suggest potential design interventions for data analysis processes and tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.09862v2</guid>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor Scully-Allison, Katy Williams, Stephanie Brink, Olga Pearce, Katherine E. Isaacs</dc:creator>
    </item>
    <item>
      <title>Web vs. LLMs: An Empirical Study of Learning Behaviors of CS2 Students</title>
      <link>https://arxiv.org/abs/2501.11935</link>
      <description>arXiv:2501.11935v2 Announce Type: replace 
Abstract: LLMs such as ChatGPT have been widely adopted by students in higher education as tools for learning programming and related concepts. However, it remains unclear how effective students are and what strategies students use while learning with LLMs. Since the majority of students' experiences in online self-learning have come through using search engines such as Google, evaluating AI tools in this context can help us address these gaps. In this mixed methods research, we conducted an exploratory within-subjects study to understand how CS2 students learn programming concepts using both LLMs as well as traditional online methods such as educational websites and videos to examine how students approach learning within and across both scenarios. We discovered that students found it easier to learn a more difficult concept using traditional methods than using ChatGPT. We also found that students ask fewer follow-ups and use more keyword-based queries for search engines while their prompts to LLMs tend to explicitly ask for information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.11935v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Aayush Kumar, Daniel Prol, Amin Alipour, Sruti Srinivasa Ragavan</dc:creator>
    </item>
    <item>
      <title>Panza: Design and Analysis of a Fully-Local Personalized Text Writing Assistant</title>
      <link>https://arxiv.org/abs/2407.10994</link>
      <description>arXiv:2407.10994v2 Announce Type: replace-cross 
Abstract: The availability of powerful open-source large language models (LLMs) opens exciting use cases, such as automated personal assistants that adapt to the user's unique data and demands. Two key requirements for such assistants are personalization - in the sense that the assistant should reflect the user's own writing style - and privacy - users may prefer to always store their personal data locally, on their own computing device. In this application paper, we present a new design and evaluation for such an automated assistant, for the specific use case of email generation, which we call Panza. Specifically, Panza can be trained and deployed locally on commodity hardware, and is personalized to the user's writing style. Panza's personalization features are based on a combination of fine-tuning using a variant of the Reverse Instructions technique together with Retrieval-Augmented Generation (RAG). We demonstrate that this combination allows us to fine-tune an LLM to better reflect a user's writing style using limited data, while executing on extremely limited resources, e.g. on a free Google Colab instance. Our key methodological contribution is what we believe to be the first detailed study of evaluation metrics for this personalized writing task, and of how different choices of system components - e.g. the use of RAG and of different fine-tuning approaches - impact the system's performance. We are releasing the full Panza code as well as a new "David" personalized email dataset licensed for research use, both available on https://github.com/IST-DASLab/PanzaMail.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10994v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Armand Nicolicioiu, Eugenia Iofinova, Eldar Kurtic, Mahdi Nikdan, Andrei Panferov, Ilia Markov, Nir Shavit, Dan Alistarh</dc:creator>
    </item>
    <item>
      <title>TelePreview: A User-Friendly Teleoperation System with Virtual Arm Assistance for Enhanced Effectiveness</title>
      <link>https://arxiv.org/abs/2412.13548</link>
      <description>arXiv:2412.13548v3 Announce Type: replace-cross 
Abstract: Teleoperation provides an effective way to collect robot data, which is crucial for learning from demonstrations. In this field, teleoperation faces several key challenges: user-friendliness for new users, safety assurance, and transferability across different platforms. While collecting real robot dexterous manipulation data by teleoperation to train robots has shown impressive results on diverse tasks, due to the morphological differences between human and robot hands, it is not only hard for new users to understand the action mapping but also raises potential safety concerns during operation. To address these limitations, we introduce TelePreview. This teleoperation system offers real-time visual feedback on robot actions based on human user inputs, with a total hardware cost of less than $1,000. TelePreview allows the user to see a virtual robot that represents the outcome of the user's next movement. By enabling flexible switching between command visualization and actual execution, this system helps new users learn how to demonstrate quickly and safely. We demonstrate that it outperforms other teleoperation systems across five tasks, emphasize its ease of use, and highlight its straightforward deployment across diverse robotic platforms. We release our code and a deployment document on our website https://telepreview.github.io.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13548v3</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <pubDate>Thu, 23 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingxiang Guo, Jiayu Luo, Zhenyu Wei, Yiwen Hou, Zhixuan Xu, Xiaoyi Lin, Chongkai Gao, Lin Shao</dc:creator>
    </item>
  </channel>
</rss>
