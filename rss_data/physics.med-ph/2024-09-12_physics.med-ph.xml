<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 13 Sep 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Does time to retreatment matter? An NTCP model to predict radionecrosis after repeat SRS for recurrent brain metastases incorporating time-dependent discounted dose</title>
      <link>https://arxiv.org/abs/2409.07647</link>
      <description>arXiv:2409.07647v1 Announce Type: new 
Abstract: Purpose: To develop and compare normal tissue complication probability (NTCP) models for recurrent brain metastases (BMs) treated with repeat single-fraction stereotactic radiosurgery (SRS), considering time-dependent discounted prior dose. Methods: We developed three NTCP models of BMs treated with GammaKnife-based SRS. The maximum dose to 0.2cc (D0.2cc) of each lesion-specific brain and one-year radionecrosis was fitted using a logistic model with equivalent-dose conversions in 2 Gy (EQD2). The M0 and M1-retreat modeled radionecrosis risk following SRS to 1029 non-recurrent lesions (patients=262) and 2nd SRS to 149 recurrent lesions (patients=87). The M1-combo model accounted for 2nd SRS and time-dependent discounted 1st SRS dose for recurrent lesions estimated by a modified Gompertzian function. Results: All three models fitted the data well (Chi-2 = 0.039-0.089 and p = 0.999-1.000). The fitted EQD250 was ~103 Gy for M0, ~88 Gy for M1-retreat, and ~165 Gy for M1-combo. The fitted EQD2_50 exhibited a progressively flatter dose-response curve across the three models, with values of 1.2 Gy for M0, 0.6 Gy for M1-retreat, and 0.4 Gy for M1-combo. For the brain D0.2cc of 29Gy and 19Gy, the steepest to shallowest dose-response or largest change in NTCP, i.e., NTCP29Gy - NTCP19Gy was observed in M1-retreat (0.16), M0 (0.14) and M1-combo (0.06). Conclusions: The model-fitted parameters predict that recurrent BMs have a lower threshold dose tolerance and a more gradual dose response for the 2nd SRS than non-recurrent BMs. This gradual dose-response becomes even more apparent when considering the time-dependent discounted 1st SRS as a cumulative 2nd SRS. Tailoring SRS retreatment protocols based on NTCP modeling can potentially enhance therapeutic efficacy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07647v1</guid>
      <category>physics.med-ph</category>
      <category>physics.bio-ph</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Manju Sharma, Issam El Naqa, Penny K Sneed</dc:creator>
    </item>
    <item>
      <title>CTLESS: A scatter-window projection and deep learning-based transmission-less attenuation compensation method for myocardial perfusion SPECT</title>
      <link>https://arxiv.org/abs/2409.07761</link>
      <description>arXiv:2409.07761v1 Announce Type: new 
Abstract: Attenuation compensation (AC), while being beneficial for visual-interpretation tasks in myocardial perfusion imaging (MPI) by SPECT, typically requires the availability of a separate X-ray CT component, leading to additional radiation dose, higher costs, and potentially inaccurate diagnosis due to SPECT/CT misalignment. To address these issues, we developed a method for cardiac SPECT AC using deep learning and emission scatter-window photons without a separate transmission scan (CTLESS). In this method, an estimated attenuation map reconstructed from scatter-energy window projections is segmented into different regions using a multi-channel input multi-decoder network trained on CT scans. Pre-defined attenuation coefficients are assigned to these regions, yielding the attenuation map used for AC. We objectively evaluated this method in a retrospective study with anonymized clinical SPECT/CT stress MPI images on the clinical task of detecting defects with an anthropomorphic model observer. CTLESS yielded statistically non-inferior performance compared to a CT-based AC (CTAC) method and significantly outperformed a non-AC (NAC) method on this clinical task. Similar results were observed in stratified analyses with different sexes, defect extents and severities. The method was observed to generalize across two SPECT scanners, each with a different camera. In addition, CTLESS yielded similar performance as CTAC and outperformed NAC method on the metrics of root mean squared error and structural similarity index measure. Moreover, as we reduced the training dataset size, CTLESS yielded relatively stable AUC values and generally outperformed another DL-based AC method that directly estimated the attenuation coefficient within each voxel. These results demonstrate the capability of the CTLESS method for transmission-less AC in SPECT and motivate further clinical evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07761v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zitong Yu, Md Ashequr Rahman, Craig K. Abbey, Richard Laforest, Nancy A. Obuchowski, Barry A. Siegel, Abhinav K. Jha</dc:creator>
    </item>
    <item>
      <title>AutoPET Challenge: Tumour Synthesis for Data Augmentation</title>
      <link>https://arxiv.org/abs/2409.08068</link>
      <description>arXiv:2409.08068v1 Announce Type: cross 
Abstract: Accurate lesion segmentation in whole-body PET/CT scans is crucial for cancer diagnosis and treatment planning, but limited datasets often hinder the performance of automated segmentation models. In this paper, we explore the potential of leveraging the deep prior from a generative model to serve as a data augmenter for automated lesion segmentation in PET/CT scans. We adapt the DiffTumor method, originally designed for CT images, to generate synthetic PET-CT images with lesions. Our approach trains the generative model on the AutoPET dataset and uses it to expand the training data. We then compare the performance of segmentation models trained on the original and augmented datasets. Our findings show that the model trained on the augmented dataset achieves a higher Dice score, demonstrating the potential of our data augmentation approach. In a nutshell, this work presents a promising direction for improving lesion segmentation in whole-body PET/CT scans with limited datasets, potentially enhancing the accuracy and reliability of cancer diagnostics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.08068v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lap Yan Lennon Chan, Chenxin Li, Yixuan Yuan</dc:creator>
    </item>
    <item>
      <title>Iterative CT Reconstruction via Latent Variable Optimization of Shallow Diffusion Models</title>
      <link>https://arxiv.org/abs/2408.03156</link>
      <description>arXiv:2408.03156v2 Announce Type: replace-cross 
Abstract: Image-generative artificial intelligence (AI) has garnered significant attention in recent years. In particular, the diffusion model, a core component of generative AI, produces high-quality images with rich diversity. In this study, we proposed a novel computed tomography (CT) reconstruction method by combining the denoising diffusion probabilistic model with iterative CT reconstruction. In sharp contrast to previous studies, we optimized the fidelity loss of CT reconstruction with respect to the latent variable of the diffusion model, instead of the image and model parameters. To suppress the changes in anatomical structures produced by the diffusion model, we shallowed the diffusion and reverse processes and fixed a set of added noises in the reverse process to make it deterministic during the inference. We demonstrated the effectiveness of the proposed method through the sparse-projection CT reconstruction of 1/10 projection data. Despite the simplicity of the implementation, the proposed method has the potential to reconstruct high-quality images while preserving the patient's anatomical structures and was found to outperform existing methods, including iterative reconstruction, iterative reconstruction with total variation, and the diffusion model alone in terms of quantitative indices such as the structural similarity index and peak signal-to-noise ratio. We also explored further sparse-projection CT reconstruction using 1/20 projection data with the same trained diffusion model. As the number of iterations increased, the image quality improved comparable to that of 1/10 sparse-projection CT reconstruction. In principle, this method can be widely applied not only to CT but also to other imaging modalities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03156v2</guid>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>physics.med-ph</category>
      <pubDate>Fri, 13 Sep 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sho Ozaki, Shizuo Kaji, Toshikazu Imae, Kanabu Nawa, Hideomi Yamashita, Keiichi Nakagawa</dc:creator>
    </item>
  </channel>
</rss>
