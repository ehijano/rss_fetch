<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 25 Dec 2024 02:30:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Approximation Algorithms for Clustering with Minimum Sum of Radii, Diameters, and Squared Radii</title>
      <link>https://arxiv.org/abs/2412.16327</link>
      <description>arXiv:2412.16327v1 Announce Type: new 
Abstract: In this paper, we present an improved approximation algorithm for three related problems. In the Minimum Sum of Radii clustering problem (MSR), we aim to select $k$ balls in a metric space to cover all points while minimizing the sum of the radii. In the Minimum Sum of Diameters clustering problem (MSD), we are to pick $k$ clusters to cover all the points such that sum of diameters of all the clusters is minimized. At last, in the Minimum Sum of Squared Radii problem (MSSR), the goal is to choose $k$ balls, similar to MSR. However in MSSR, the goal is to minimize the sum of squares of radii of the balls. We present a 3.389-approximation for MSR and a 6.546-approximation for MSD, improving over respective 3.504 and 7.008 developed by Charikar and Panigrahy (2001). In particular, our guarantee for MSD is better than twice our guarantee for MSR. In the case of MSSR, the best known approximation guarantee is $4\cdot(540)^{2}$ based on the work of Bhowmick, Inamdar, and Varadarajan in their general analysis of the $t$-Metric Multicover Problem. At last with our analysis, we get a 11.078-approximation algorithm for Minimum Sum of Squared Radii.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16327v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.ESA.2022.56</arxiv:DOI>
      <dc:creator>Zachary Friggstad, Mahya Jamshidian</dc:creator>
    </item>
    <item>
      <title>Faster Positional-Population Counts for AVX2, AVX-512, and ASIMD</title>
      <link>https://arxiv.org/abs/2412.16370</link>
      <description>arXiv:2412.16370v1 Announce Type: new 
Abstract: The positional population count operation pospopcnt() counts for an array of w-bit words how often each of the w bits was set. Various applications in bioinformatics, database engineering, and digital processing exist. Building on earlier work by Klarqvist et al., we show how positional population counts can be rapidly computed using SIMD techniques with good performance from the first byte, approaching memory-bound speeds for input arrays of as little as 4 KiB. Improvements include an improved algorithm structure, better handling of unaligned and very short arrays, as well as faster bit-parallel accumulation of intermediate results. We provide a generic algorithm description as well as implementations for various SIMD instruction set extensions, including Intel AVX2, AVX-512, and ARM ASIMD, and discuss the adaption of our algorithm to other platforms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16370v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Robert Clausecker, Daniel Lemire, Florian Schintke</dc:creator>
    </item>
    <item>
      <title>Chorba: A novel CRC32 implementation</title>
      <link>https://arxiv.org/abs/2412.16398</link>
      <description>arXiv:2412.16398v1 Announce Type: new 
Abstract: This paper describes a novel method for efficiently calculating CRC checksums without lookup tables or hardware support for polynomial multiplication. Throughput of CRC32 is increased by 100% across different platforms compared with the current state of the art. Performance is on par with or exceeds hardware-accelerated solutions on x86_64 and ARMv8 processors, and these hardware-accelerated solutions see a performance increase of 5-20% depending on message length. The small number of operations required with this approach could simplify hardware CRC32 implementations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16398v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sam Russell</dc:creator>
    </item>
    <item>
      <title>Fast Biclique Counting on Bipartite Graphs: A Node Pivot-based Approach</title>
      <link>https://arxiv.org/abs/2412.16485</link>
      <description>arXiv:2412.16485v1 Announce Type: new 
Abstract: Counting the number of $(p, q)$-bicliques (complete bipartite subgraphs) in a bipartite graph is a fundamental problem which plays a crucial role in numerous bipartite graph analysis applications. However, existing algorithms for counting $(p, q)$-bicliques often face significant computational challenges, particularly on large real-world networks. In this paper, we propose a general biclique counting framework, called \npivot, based on a novel concept of node-pivot. We show that previous methods can be viewed as specific implementations of this general framework. More importantly, we propose a novel implementation of \npivot based on a carefully-designed minimum non-neighbor candidate partition strategy. We prove that our new implementation of \npivot has lower worst-case time complexity than the state-of-the-art methods. Beyond basic biclique counting, a nice feature of \npivot is that it also supports local counting (computing bicliques per node) and range counting (simultaneously counting bicliques within a size range). Extensive experiments on 12 real-world large datasets demonstrate that our proposed \npivot substantially outperforms state-of-the-art algorithms by up to two orders of magnitude.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16485v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaowei Ye, Rong-Hua Li, Longlong Lin, Shaojie Qiao, Guoren Wang</dc:creator>
    </item>
    <item>
      <title>Carbonyl4: A Sketch for Set-Increment Mixed Updates</title>
      <link>https://arxiv.org/abs/2412.16566</link>
      <description>arXiv:2412.16566v1 Announce Type: new 
Abstract: In the realm of data stream processing, the advent of SET-INCREMENT Mixed (SIM) data streams necessitates algorithms that efficiently handle both SET and INCREMENT operations. We present Carbonyl4, an innovative algorithm designed specifically for SIM data streams, ensuring accuracy, unbiasedness, and adaptability. Carbonyl4 introduces two pioneering techniques: the Balance Bucket for refined variance optimization, and the Cascading Overflow for maintaining precision amidst overflow scenarios. Our experiments across four diverse datasets establish Carbonyl4's supremacy over existing algorithms, particularly in terms of accuracy for item-level information retrieval and adaptability to fluctuating memory requirements. The versatility of Carbonyl4 is further demonstrated through its dynamic memory shrinking capability, achieved via a re-sampling and a heuristic approach. The source codes of Carbonyl4 are available at GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16566v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yikai Zhao, Yuhan Wu, Tong Yang</dc:creator>
    </item>
    <item>
      <title>Sparsest cut and eigenvalue multiplicities on low degree Abelian Cayley graphs</title>
      <link>https://arxiv.org/abs/2412.17115</link>
      <description>arXiv:2412.17115v1 Announce Type: new 
Abstract: Whether or not the Sparsest Cut problem admits an efficient $O(1)$-approximation algorithm is a fundamental algorithmic question with connections to geometry and the Unique Games Conjecture. We design an $O(1)$-approximation algorithm to Sparsest Cut for the class of Cayley graphs over Abelian groups, running in time $n^{O(1)}\cdot \exp\{d^{O(d)}\}$ where $d$ is the degree of the graph.
  Previous work has centered on solving cut problems on graphs which are ``expander-like'' in various senses, such as being a small-set expander or having low threshold rank.
  In contrast, low-degree Abelian Cayley graphs are natural examples of non-expanding graphs far from these assumptions (e.g. the cycle). We demonstrate that spectral and semidefinite programming-based methods can still succeed in these graphs by analyzing an eigenspace enumeration algorithm which searches for a sparse cut among the low eigenspace of the Laplacian matrix. We dually interpret this algorithm as searching for a hyperplane cut in a low-dimensional embedding of the graph.
  In order to analyze the algorithm, we prove a bound of $d^{O(d)}$ on the number of eigenvalues ``near'' $\lambda_2$ for connected degree-$d$ Abelian Cayley graphs. We obtain a tight bound of $2^{\Theta(d)}$ on the multiplicity of $\lambda_2$ itself which improves on a previous bound of $2^{O(d^2)}$ by Lee and Makarychev.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17115v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tommaso d'Orsi, Chris Jones, Jake Ruotolo, Salil Vadhan, Jiyu Zhang</dc:creator>
    </item>
    <item>
      <title>Online coloring of short interval graphs and two-count interval graphs</title>
      <link>https://arxiv.org/abs/2412.17193</link>
      <description>arXiv:2412.17193v1 Announce Type: new 
Abstract: We study the online coloring of $\sigma$-interval graphs which are interval graphs where the interval lengths are between 1 and $\sigma$ and 2-count interval graphs which are interval graphs that require at most $2$ distinct interval lengths.
  For online $\sigma$-interval graph coloring, we focus on online algorithms that do not have knowledge of the interval representation. The Kierstead-Trotter algorithm has competitive ratio 3 for all $\sigma$ and no online algorithm has competitive ratio better than 2, even for $\sigma=1$. In this paper, we show that for every $\epsilon&gt;0$, there is a $\sigma&gt;1$ such that there is no online algorithm for $\sigma$-interval coloring with competitive ratio less than $3-\epsilon$. Our strategy also improves the best known lower bounds for the greedy algorithm First-Fit for many values of $\sigma$.
  For online 2-count interval graph coloring, we analyze the performance of First-Fit and algorithms under various scenarios. We consider algorithms that receive the interval representation as input and algorithms that do not. We also consider algorithms that have prior knowledge of the interval lengths and algorithms that do not. We provide non-trivial lower bounds for each of the four cases. In particular, we show that there is no online algorithm with competitive ratio less than $2.5$ when the interval lengths are known, there is no online algorithm with competitive ratio less than $2$ when the interval representation is known, and there is no online algorithm with competitive ratio less than $1.75$ when both the interval lengths and interval representation are known.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17193v1</guid>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Israel R. Curbelo</dc:creator>
    </item>
    <item>
      <title>On the complexity of finding a spanning even tree in a graph</title>
      <link>https://arxiv.org/abs/2412.17307</link>
      <description>arXiv:2412.17307v1 Announce Type: new 
Abstract: A tree is said to be even if for every pair of distinct leaves, the length of the unique path between them is even. In this paper we discuss the problem of determining whether an input graph has a spanning even tree. Hofmann and Walsh [Australas. J Comb. 35, 2006] proved that this problem can be solved in polynomial time on bipartite graphs. In contrast to this, we show that this problem is NP-complete even on planar graphs. We also give polynomial-time algorithms for several restricted classes of graphs, such as split graphs, cographs, cobipartite graphs, unit interval graphs, and block graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17307v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tesshu Hanaka, Yasuaki Kobayashi, Kazuhiro Kurita, Yasuko Matsui, Atsuki Nagao, Hirotaka Ono, Kazuhisa Seto</dc:creator>
    </item>
    <item>
      <title>On the number of $k$-mers admitting a given lexicographical minimizer</title>
      <link>https://arxiv.org/abs/2412.17492</link>
      <description>arXiv:2412.17492v2 Announce Type: new 
Abstract: The minimizer of a word of size $k$ (a $k$-mer) is defined as its smallest substring of size $m$ (with $m\leq k$), according to some ordering on $m$-mers. minimizers have been used in bioinformatics -- notably -- to partition sequencing datasets, binning together $k$-mers that share the same minimizer. It is folklore that using the lexicographical order lead to very unbalanced partitions, resulting in an abundant literature devoted to devising alternative orders for achieving better balanced partitions. To the best of our knowledge, the unbalanced-ness of lexicographical-based minimizer partitions has never been investigated from a theoretical point of view. In this article, we aim to fill this gap and determine, for a given minimizer, how many $k$-mers would admit the chosen minimizer -- i.e. what would be the size of the bucket associated to the chosen minimizer in the worst case, where all $k$-mers would be seen in the data. We show that this number can be computed in $O(km)$ space and $O(km^2)$ time. We further introduce approximations that can be computed in $O(k)$ space and $O(km)$ time. We also show on genomic datasets that the practical number of $k$-mers associated to a minimizer are closely correlated to the theoretical expected number. We introduce two conjectures that could help closely approximating the total number of $k$-mers sharing a minimizer. We believe that characterising the distribution of the number of $k$-mers per minimizer will help devise efficient lexicographic-based minimizer bucketting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17492v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Florian Ingels, Camille Marchet, Mika\"el Salson</dc:creator>
    </item>
    <item>
      <title>Efficient Fault-Tolerant Search by Fast Indexing of Subnetworks</title>
      <link>https://arxiv.org/abs/2412.17776</link>
      <description>arXiv:2412.17776v1 Announce Type: new 
Abstract: We design sensitivity oracles for error-prone networks. For a network problem $\Pi$, the data structure preprocesses a network $G=(V,E)$ and sensitivity parameter $f$ such that, for any set $F\subseteq V\cup E$ of up to $f$ link or node failures, it report a solution for $\Pi$ in $G{-}F$. We study three exemplary problems $\Pi$. $L$-Hop Shortest Path: Given $s,t \in V$, is there a shortest $s$-$t$-path in $G-F$ with at most $L$ links? $k$-Path: Does $G-F$ contain a simple path with $k$ links? $k$-Clique: Does $G-F$ contain a clique of $k$ nodes? Our main technical contribution is a new construction of $(L,f)$-replacement path coverings ($(L,f)$-RPC) in the parameter realm where $f = o(\log L)$. An $(L,f)$-RPC is a family $\mathcal{G}$ of subnetworks of $G$ which, for every $F \subseteq E$ with $|F| \le f$, contain a subfamily $\mathcal{G}_F \subseteq \mathcal{G}$ such that (i) every subnetwork in $\mathcal{G}_F$ contains no link of $F$ and (ii) for each $s,t \in V$, if $G-F$ contains a shortest $s$-$t$ path with at most $L$ links, then some subnetwork in $\mathcal{G}_F$ retains at least one of such path. Our $(L, f)$-RPC has almost the same size as the one by Weimann and Yuster [ACM TALG 2013] but it improves the query time to access $\mathcal{G}_F$ from $\widetilde{O}(f^2L^f)$ to $\widetilde{O}(f^{\frac{5}{2}} L^{o(1)})$. It also improves both the size and query time of the $(L,f)$-RPC by Karthik and Parter [SODA 2021] by nearly a factor of $L$. We then derive oracles for $L$-Hop Shortest Path, $k$-Path, and $k$-Clique from this. Notably, our solution for $k$-Path improves the query time of the one by Bil\`o, et al. [ITCS 2022] for $f=o(\log k)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17776v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Davide Bil\`o, Keerti Choudhary, Sarel Cohen, Tobias Friedrich, Martin Schirneck</dc:creator>
    </item>
    <item>
      <title>Minimum Weighted Feedback Arc Sets for Ranking from Pairwise Comparisons</title>
      <link>https://arxiv.org/abs/2412.16181</link>
      <description>arXiv:2412.16181v1 Announce Type: cross 
Abstract: The Minimum Weighted Feedback Arc Set (MWFAS) problem is fundamentally connected to the Ranking Problem -- the task of deriving global rankings from pairwise comparisons. Recent work [He et al. ICML2022] has advanced the state-of-the-art for the Ranking Problem using learning-based methods, improving upon multiple previous approaches. However, the connection to MWFAS remains underexplored. This paper investigates this relationship and presents efficient combinatorial algorithms for solving MWFAS, thus addressing the Ranking Problem. Our experimental results demonstrate that these simple, learning-free algorithms not only significantly outperform learning-based methods in terms of speed but also generally achieve superior ranking accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16181v1</guid>
      <category>cs.IR</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Soroush Vahidi, Ioannis Koutis</dc:creator>
    </item>
    <item>
      <title>HashEvict: A Pre-Attention KV Cache Eviction Strategy using Locality-Sensitive Hashing</title>
      <link>https://arxiv.org/abs/2412.16187</link>
      <description>arXiv:2412.16187v2 Announce Type: cross 
Abstract: Transformer-based large language models (LLMs) use the key-value (KV) cache to significantly accelerate inference by storing the key and value embeddings of past tokens. However, this cache consumes significant GPU memory. In this work, we introduce HashEvict, an algorithm that uses locality-sensitive hashing (LSH) to compress the KV cache. HashEvict quickly locates tokens in the cache that are cosine dissimilar to the current query token. This is achieved by computing the Hamming distance between binarized Gaussian projections of the current token query and cached token keys, with a projection length much smaller than the embedding dimension. We maintain a lightweight binary structure in GPU memory to facilitate these calculations. Unlike existing compression strategies that compute attention to determine token retention, HashEvict makes these decisions pre-attention, thereby reducing computational costs. Additionally, HashEvict is dynamic - at every decoding step, the key and value of the current token replace the embeddings of a token expected to produce the lowest attention score. We demonstrate that HashEvict can compress the KV cache by 30%-70% while maintaining high performance across reasoning, multiple-choice, long-context retrieval and summarization tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16187v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minghui Liu, Tahseen Rabbani, Tony O'Halloran, Ananth Sankaralingam, Mary-Anne Hartley, Brian Gravelle, Furong Huang, Cornelia Ferm\"uller, Yiannis Aloimonos</dc:creator>
    </item>
    <item>
      <title>Lower bounds for the universal TSP on the plane</title>
      <link>https://arxiv.org/abs/2412.16448</link>
      <description>arXiv:2412.16448v1 Announce Type: cross 
Abstract: We show a lower bound for the universal traveling salesman heuristic on the plane: for any linear order on the unit square $[0,1]^2$, there are finite subsets $S \subset [0,1]^2$ of arbitrarily large size such that the path visiting each element of $S$ according to the linear order has length $\geq C \sqrt{\log |S| / \log \log |S|}$ times the length of the shortest path visiting each element in $S$. ($C&gt;0$ is a constant that depends only on the linear order.) This improves the previous lower bound $\geq C \sqrt[6]{\log |S| / \log \log |S|}$ of [HKL06]. The proof establishes a dichotomy about any long walk on a cycle: the walk either zig-zags between two far away points, or else for a large amount of time it stays inside a set of small diameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16448v1</guid>
      <category>math.MG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Cosmas Kravaris</dc:creator>
    </item>
    <item>
      <title>Robust random graph matching in dense graphs via vector approximate message passing</title>
      <link>https://arxiv.org/abs/2412.16457</link>
      <description>arXiv:2412.16457v1 Announce Type: cross 
Abstract: In this paper, we focus on the matching recovery problem between a pair of correlated Gaussian Wigner matrices with a latent vertex correspondence. We are particularly interested in a robust version of this problem such that our observation is a perturbed input $(A+E,B+F)$ where $(A,B)$ is a pair of correlated Gaussian Wigner matrices and $E,F$ are adversarially chosen matrices supported on an unknown $\epsilon n * \epsilon n$ principle minor of $A,B$, respectively. We propose a vector-approximate message passing (vector-AMP) algorithm that succeeds in polynomial time as long as the correlation $\rho$ between $(A,B)$ is a non-vanishing constant and $\epsilon = o\big( \tfrac{1}{(\log n)^{20}} \big)$.
  The main methodological inputs for our result are the iterative random graph matching algorithm proposed in \cite{DL22+, DL23+} and the spectral cleaning procedure proposed in \cite{IS24+}. To the best of our knowledge, our algorithm is the first efficient random graph matching type algorithm that is robust under any adversarial perturbations of $n^{1-o(1)}$ size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16457v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhangsong Li</dc:creator>
    </item>
    <item>
      <title>Balls-and-Bins Sampling for DP-SGD</title>
      <link>https://arxiv.org/abs/2412.16802</link>
      <description>arXiv:2412.16802v1 Announce Type: cross 
Abstract: We introduce the Balls-and-Bins sampling for differentially private (DP) optimization methods such as DP-SGD. While it has been common practice to use some form of shuffling in DP-SGD implementations, privacy accounting algorithms have typically assumed that Poisson subsampling is used instead. Recent work by Chua et al. (ICML 2024) however pointed out that shuffling based DP-SGD can have a much larger privacy cost in practical regimes of parameters. We show that the Balls-and-Bins sampling achieves the "best-of-both" samplers, namely, the implementation of Balls-and-Bins sampling is similar to that of Shuffling and models trained using DP-SGD with Balls-and-Bins sampling achieve utility comparable to those trained using DP-SGD with Shuffling at the same noise multiplier, and yet, Balls-and-Bins sampling enjoys similar-or-better privacy amplification as compared to Poisson subsampling in practical regimes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16802v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lynn Chua, Badih Ghazi, Charlie Harrison, Ethan Leeman, Pritish Kamath, Ravi Kumar, Pasin Manurangsi, Amer Sinha, Chiyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Algorithm Design for Continual Learning in IoT Networks</title>
      <link>https://arxiv.org/abs/2412.16830</link>
      <description>arXiv:2412.16830v2 Announce Type: cross 
Abstract: Continual learning (CL) is a new online learning technique over sequentially generated streaming data from different tasks, aiming to maintain a small forgetting loss on previously-learned tasks. Existing work focuses on reducing the forgetting loss under a given task sequence. However, if similar tasks continuously appear to the end time, the forgetting loss is still huge on prior distinct tasks. In practical IoT networks, an autonomous vehicle to sample data and learn different tasks can route and alter the order of task pattern at increased travelling cost. To our best knowledge, we are the first to study how to opportunistically route the testing object and alter the task sequence in CL. We formulate a new optimization problem and prove it NP-hard. We propose a polynomial-time algorithm to achieve approximation ratios of $\frac{3}{2}$ for underparameterized case and $\frac{3}{2} + r^{1-T}$ for overparameterized case, respectively, where $r:=1-\frac{n}{m}$ is a parameter of feature number $m$ and sample number $n$ and $T$ is the task number. Simulation results verify our algorithm's close-to-optimum performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16830v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>cs.NI</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shugang Hao, Lingjie Duan</dc:creator>
    </item>
    <item>
      <title>Efficiently Solving Turn-Taking Stochastic Games with Extensive-Form Correlation</title>
      <link>https://arxiv.org/abs/2412.16934</link>
      <description>arXiv:2412.16934v1 Announce Type: cross 
Abstract: We study equilibrium computation with extensive-form correlation in two-player turn-taking stochastic games. Our main results are two-fold: (1) We give an algorithm for computing a Stackelberg extensive-form correlated equilibrium (SEFCE), which runs in time polynomial in the size of the game, as well as the number of bits required to encode each input number. (2) We give an efficient algorithm for approximately computing an optimal extensive-form correlated equilibrium (EFCE) up to machine precision, i.e., the algorithm achieves approximation error $\varepsilon$ in time polynomial in the size of the game, as well as $\log(1 / \varepsilon)$.
  Our algorithm for SEFCE is the first polynomial-time algorithm for equilibrium computation with commitment in such a general class of stochastic games. Existing algorithms for SEFCE typically make stronger assumptions such as no chance moves, and are designed for extensive-form games in the less succinct tree form. Our algorithm for approximately optimal EFCE is, to our knowledge, the first algorithm that achieves 3 desiderata simultaneously: approximate optimality, polylogarithmic dependency on the approximation error, and compatibility with stochastic games in the more succinct graph form. Existing algorithms achieve at most 2 of these desiderata, often also relying on additional technical assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.16934v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanrui Zhang, Yu Cheng, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>Grams: Gradient Descent with Adaptive Momentum Scaling</title>
      <link>https://arxiv.org/abs/2412.17107</link>
      <description>arXiv:2412.17107v1 Announce Type: cross 
Abstract: We introduce \textbf{Gr}adient Descent with \textbf{A}daptive \textbf{M}omentum \textbf{S}caling (\textbf{Grams}), a novel optimization algorithm that decouples the direction and magnitude of parameter updates in deep learning. Unlike traditional optimizers that directly integrate momentum into updates, Grams separates the update direction, derived from current gradients, from momentum, which is used solely for adaptive magnitude scaling. This approach enables Grams to achieve improved loss descent compared to state-of-the-art cautious and momentum-based optimizers. We establish a global convergence guarantee for Grams and validate its effectiveness through extensive empirical evaluations. The results demonstrate Grams' superior performance, including faster convergence and better generalization, compared to widely-used optimizers such as Adam, Lion, and their cautious variants. Our results highlight Grams' potential as a transformative approach for efficient optimization in large-scale machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17107v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Cao, Xiaoyu Li, Zhao Song</dc:creator>
    </item>
    <item>
      <title>Hiding, Shuffling, and Triangle Finding: Quantum Algorithms on Edge Lists</title>
      <link>https://arxiv.org/abs/2412.17786</link>
      <description>arXiv:2412.17786v1 Announce Type: cross 
Abstract: The edge list model is arguably the simplest input model for graphs, where the graph is specified by a list of its edges. In this model, we study the quantum query complexity of three variants of the triangle finding problem. The first asks whether there exists a triangle containing a target edge and raises general questions about the hiding of a problem's input among irrelevant data. The second asks whether there exists a triangle containing a target vertex and raises general questions about the shuffling of a problem's input. The third asks for finding a triangle in the input edge list; this problem bridges the $3$-distinctness and $3$-sum problems, which have been extensively studied by both cryptographers and complexity theorists. We provide tight or nearly tight results for all of our problems as well as some first answers to the general questions they raise. In particular, given a graph with low maximum degree, such as a random sparse graph, we prove that the quantum query complexity of triangle finding in its length-$m$ edge list is $m^{5/7 \pm o(1)}$. We prove the lower bound in Zhandry's recording query framework [CRYPTO '19] and the upper bound by adapting Belovs's learning graph algorithm for $3$-distinctness [FOCS '12].</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17786v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Shiraz Gilani, Daochen Wang, Pei Wu, Xingyu Zhou</dc:creator>
    </item>
    <item>
      <title>Distributed Subgraph Finding: Progress and Challenges</title>
      <link>https://arxiv.org/abs/2203.06597</link>
      <description>arXiv:2203.06597v4 Announce Type: replace 
Abstract: This is a survey of the exciting recent progress made in understanding the complexity of distributed subgraph finding problems. It overviews the results and techniques for assorted variants of subgraph finding problems in various models of distributed computing, and states intriguing open questions. This version contains some updates over the ICALP 2021 version, and I will try to keep updating it as additional progress is made.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.06597v4</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keren Censor-Hillel</dc:creator>
    </item>
    <item>
      <title>Parameterizing Path Partitions</title>
      <link>https://arxiv.org/abs/2212.11653</link>
      <description>arXiv:2212.11653v3 Announce Type: replace 
Abstract: We study the algorithmic complexity of partitioning the vertex set of a given (di)graph into a small number of paths. The Path Partition problem (PP) has been studied extensively, as it includes Hamiltonian Path as a special case. The natural variants where the paths are required to be either \emph{induced} (Induced Path Partition, IPP) or \emph{shortest} (Shortest Path Partition, SPP), have received much less attention. Both problems are known to be NP-complete on undirected graphs; we strengthen this by showing that they remain so even on planar bipartite directed acyclic graphs (DAGs), and that SPP remains NP-hard on undirected bipartite graphs. When parameterized by the natural parameter ``number of paths'', both SPP and IPP are shown to be W[1]-hard on DAGs. We also show that SPP is in XP both for DAGs and undirected graphs for the same parameter, as well as for other special subclasses of directed graphs (IPP is known to be NP-hard on undirected graphs, even for two paths). On the positive side, we show that for undirected graphs, both problems are in FPT, parameterized by neighborhood diversity. We also give an explicit algorithm for the vertex cover parameterization of PP. When considering the dual parameterization (graph order minus number of paths), all three variants, IPP, SPP and PP, are shown to be in FPT for undirected graphs. We also lift the mentioned neighborhood diversity and dual parameterization results to directed graphs; here, we need to define a proper novel notion of directed neighborhood diversity. As we also show, most of our results transfer to the case of covering by edge-disjoint paths, and purely covering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.11653v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.tcs.2024.115029</arxiv:DOI>
      <arxiv:journal_reference>Theoretical Computer Science 1028:115029, 2025</arxiv:journal_reference>
      <dc:creator>Henning Fernau, Florent Foucaud, Kevin Mann, Utkarsh Padariya, Rajath Rao K. N</dc:creator>
    </item>
    <item>
      <title>Revising Apetrei's bounding volume hierarchy construction algorithm to allow stackless traversal</title>
      <link>https://arxiv.org/abs/2402.00665</link>
      <description>arXiv:2402.00665v2 Announce Type: replace 
Abstract: Stackless traversal is a technique to speed up range queries by avoiding usage of a stack during the tree traversal. One way to achieve that is to transform a given binary tree to store a left child and a skip-connection (also called an escape index). In general, this operation requires an additional tree traversal during the tree construction. For some tree structures, however, it is possible achieve the same result at a reduced cost. We propose one such algorithm for a GPU hierarchy construction algorithm proposed by Karras in [Karras, 2012]. Furthermore, we show that our algorithm also works with the improved algorithm proposed by Apetrei in [Apetrei, 2014], despite a different ordering of the internal nodes. We achieve that by modifying the Apetrei's algorithm to restore the original Karras' ordering of the internal nodes. Using the modified algorithm, we show how to construct a hierarchy suitable for a stackless traversal in a single bottom-up pass.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00665v2</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrey Prokopenko, Damien Lebrun-Grandi\'e</dc:creator>
    </item>
    <item>
      <title>Noisy Computing of the Threshold Function</title>
      <link>https://arxiv.org/abs/2403.07227</link>
      <description>arXiv:2403.07227v3 Announce Type: replace 
Abstract: Let $\mathsf{TH}_k$ denote the $k$-out-of-$n$ threshold function: given $n$ input Boolean variables, the output is $1$ if and only if at least $k$ of the inputs are $1$. We consider the problem of computing the $\mathsf{TH}_k$ function using noisy readings of the Boolean variables, where each reading is incorrect with some fixed and known probability $p \in (0,1/2)$. As our main result, we show that it is sufficient to use $(1+o(1)) \frac{n\log \frac{m}{\delta}}{D_{\mathsf{KL}}(p \| 1-p)}$ queries in expectation to compute the $\mathsf{TH}_k$ function with a vanishing error probability $\delta = o(1)$, where $m\triangleq \min\{k,n-k+1\}$ and $D_{\mathsf{KL}}(p \| 1-p)$ denotes the Kullback-Leibler divergence between $\mathsf{Bern}(p)$ and $\mathsf{Bern}(1-p)$ distributions. Conversely, we show that any algorithm achieving an error probability of $\delta = o(1)$ necessitates at least $(1-o(1))\frac{(n-m)\log\frac{m}{\delta}}{D_{\mathsf{KL}}(p \| 1-p)}$ queries in expectation. The upper and lower bounds are tight when $m=o(n)$, and are within a multiplicative factor of $\frac{n}{n-m}$ when $m=\Theta(n)$. In particular, when $k=n/2$, the $\mathsf{TH}_k$ function corresponds to the $\mathsf{MAJORITY}$ function, in which case the upper and lower bounds are tight up to a multiplicative factor of two. Compared to previous work, our result tightens the dependence on $p$ in both the upper and lower bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07227v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziao Wang, Nadim Ghaddar, Banghua Zhu, Lele Wang</dc:creator>
    </item>
    <item>
      <title>Safe Paths and Sequences for Scalable ILPs in RNA Transcript Assembly Problems</title>
      <link>https://arxiv.org/abs/2411.03871</link>
      <description>arXiv:2411.03871v2 Announce Type: replace 
Abstract: A common step at the core of many RNA transcript assembly tools is to find a set of weighted paths that best explain the weights of a DAG. While such problems easily become NP-hard, scalable solvers exist only for a basic error-free version of this problem, namely minimally decomposing a network flow into weighted paths.
  The main result of this paper is to show that we can achieve speedups of two orders of magnitude also for path-finding problems in the realistic setting (i.e., the weights do not induce a flow). We obtain these by employing the safety information that is encoded in the graph structure inside Integer Linear Programming (ILP) solvers for these problems. We first characterize the paths that appear in all path covers of the DAG, generalizing a graph reduction commonly used in the error-free setting (e.g. by Kloster et al. [ALENEX~2018]). Secondly, following the work of Ma, Zheng and Kingsford [RECOMB 2021], we characterize the \emph{sequences} of arcs that appear in all path covers of the DAG.
  We experiment with a path-finding ILP model (least squares) and with a more recent and accurate one. We use a variety of datasets originally created by Shao and Kingsford [TCBB, 2017], as well as graphs built from sequencing reads by the state-of-the-art tool for long-read transcript discovery, IsoQuant [Prjibelski et al., Nat.~Biotechnology~2023]. The ILPs armed with safe paths or sequences exhibit significant speed-ups over the original ones. On graphs with a large width, average speed-ups are in the range $50-160\times$ in the latter ILP model and in the range $100-1000\times$ in the least squares model.
  Our scaling techniques apply to any ILP whose solution paths are a path cover of the arcs of the DAG. As such, they can become a scalable building block of practical RNA transcript assembly tools, avoiding heuristic trade-offs currently needed on complex graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03871v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.GN</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Sena, Alexandru I. Tomescu</dc:creator>
    </item>
    <item>
      <title>The Online Submodular Assignment Problem</title>
      <link>https://arxiv.org/abs/2412.03826</link>
      <description>arXiv:2412.03826v2 Announce Type: replace 
Abstract: Online resource allocation is a rich and varied field. One of the most well-known problems in this area is online bipartite matching, introduced in 1990 by Karp, Vazirani, and Vazirani [KVV90]. Since then, many variants have been studied, including AdWords, the generalized assignment problem (GAP), and online submodular welfare maximization.
  In this paper, we introduce a generalization of GAP which we call the submodular assignment problem (SAP). This generalization captures many online assignment problems, including all classical online bipartite matching problems as well as broader online combinatorial optimization problems such as online arboricity, flow scheduling, and laminar restricted allocations. We present a fractional algorithm for online SAP that is (1-1/e)-competitive.
  Additionally, we study several integral special cases of the problem. In particular, we provide a (1-1/e-epsilon)-competitive integral algorithm under a small-bids assumption, and a (1-1/e)-competitive integral algorithm for online submodular welfare maximization where the utility functions are given by rank functions of matroids.
  The key new ingredient for our results is the construction and structural analysis of a "water level" vector for polymatroids, which allows us to generalize the classic water-filling paradigm used in online matching problems. This construction reveals connections to submodular utility allocation markets and principal partition sequences of matroids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03826v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Hathcock, Billy Jin, Kalen Patton, Sherry Sarkar, Michael Zlatin</dc:creator>
    </item>
    <item>
      <title>On the tractability of sampling from the Potts model at low temperatures via random-cluster dynamics</title>
      <link>https://arxiv.org/abs/2304.03182</link>
      <description>arXiv:2304.03182v2 Announce Type: replace-cross 
Abstract: Sampling from the $q$-state ferromagnetic Potts model is a fundamental question in statistical physics, probability theory, and theoretical computer science. On general graphs, this problem may be computationally hard, and this hardness holds at arbitrarily low temperatures. At the same time, in recent years, there has been significant progress showing the existence of low-temperature sampling algorithms in various specific families of graphs. Our aim in this paper is to understand the minimal structural properties of general graphs that enable polynomial-time sampling from the $q$-state ferromagnetic Potts model at low temperatures. We study this problem from the perspective of random-cluster dynamics. These are non-local Markov chains that have long been believed to converge rapidly to equilibrium at low temperatures in many graphs. However, the hardness of the sampling problem likely indicates that this is not even the case for all bounded degree graphs.
  Our results demonstrate that a key graph property behind fast or slow convergence time for these dynamics is whether the independent edge-percolation on the graph admits a strongly supercritical phase. By this, we mean that at large $p&lt;1$, it has a large linear-sized component, and the graph complement of that component is comprised of only small components. Specifically, we prove that such a condition implies fast mixing of the random-cluster Glauber and Swendsen--Wang dynamics on two general families of bounded-degree graphs: (a) graphs of at most stretched-exponential volume growth and (b) locally treelike graphs. In the other direction, we show that, even among graphs in those families, these Markov chains can converge exponentially slowly at arbitrarily low temperatures if the edge-percolation condition does not hold.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.03182v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Antonio Blanca, Reza Gheissari</dc:creator>
    </item>
    <item>
      <title>Reducing Leximin Fairness to Utilitarian Optimization</title>
      <link>https://arxiv.org/abs/2409.10395</link>
      <description>arXiv:2409.10395v3 Announce Type: replace-cross 
Abstract: Two prominent objectives in social choice are utilitarian - maximizing the sum of agents' utilities, and leximin - maximizing the smallest agent's utility, then the second-smallest, etc. Utilitarianism is typically computationally easier to attain but is generally viewed as less fair. This paper presents a general reduction scheme that, given a utilitarian solver, produces a distribution over states (deterministic outcomes) that is leximin in expectation. Importantly, the scheme is robust in the sense that, given an approximate utilitarian solver, it produces a lottery that is approximately-leximin (in expectation) - with the same approximation factor. We apply our scheme to several social choice problems: stochastic allocations of indivisible goods, giveaway lotteries, and fair lotteries for participatory budgeting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.10395v3</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eden Hartman, Yonatan Aumann, Avinatan Hassidim, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Assessing fault-tolerant quantum advantage for $k$-SAT with structure</title>
      <link>https://arxiv.org/abs/2412.13274</link>
      <description>arXiv:2412.13274v2 Announce Type: replace-cross 
Abstract: For many problems, quantum algorithms promise speedups over their classical counterparts. However, these results predominantly rely on asymptotic worst-case analysis, which overlooks significant overheads due to error correction and the fact that real-world instances often contain exploitable structure. In this work, we employ the hybrid benchmarking method to evaluate the potential of quantum Backtracking and Grover's algorithm against the 2023 SAT competition main track winner in solving random $k$-SAT instances with tunable structure, designed to represent industry-like scenarios, using both $T$-depth and $T$-count as cost metrics to estimate quantum run times. Our findings reproduce the results of Campbell, Khurana, and Montanaro (Quantum '19) in the unstructured case using hybrid benchmarking. However, we offer a more sobering perspective in practically relevant regimes: almost all quantum speedups vanish, even asymptotically, when minimal structure is introduced or when $T$-count is considered instead of $T$-depth. Moreover, when the requirement is for the algorithm to find a solution within a single day, we find that only Grover's algorithm has the potential to outperform classical algorithms, but only in a very limited regime and only when using $T$-depth. We also discuss how more sophisticated heuristics could restore the asymptotic scaling advantage for quantum backtracking, but our findings suggest that the potential for practical quantum speedups in more structured $k$-SAT solving will remain limited.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.13274v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 24 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martijn Brehm, Jordi Weggemans</dc:creator>
    </item>
  </channel>
</rss>
