<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 23 Feb 2026 05:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Physics-informed graph neural networks for flow field estimation in carotid arteries</title>
      <link>https://arxiv.org/abs/2408.07110</link>
      <description>arXiv:2408.07110v2 Announce Type: replace 
Abstract: Hemodynamic quantities are valuable biomedical risk factors for cardiovascular pathology such as atherosclerosis. Non-invasive, in-vivo measurement of these quantities can only be performed using a select number of modalities that are not widely available, such as 4D flow magnetic resonance imaging (MRI). In this work, we create a surrogate model for hemodynamic flow field estimation, powered by machine learning. We train graph neural networks that include priors about the underlying symmetries and physics, limiting the amount of data required for training. This allows us to train the model using moderately-sized, in-vivo 4D flow MRI datasets, instead of large in-silico datasets obtained by computational fluid dynamics (CFD), as is the current standard. We create an efficient, equivariant neural network by combining the popular PointNet++ architecture with group-steerable layers. To incorporate the physics-informed priors, we derive an efficient discretisation scheme for the involved differential operators. We perform extensive experiments in carotid arteries and show that our model can accurately estimate low-noise hemodynamic flow fields in the carotid artery. Moreover, we show how the learned relation between geometry and hemodynamic quantities transfers to 3D vascular models obtained using a different imaging modality than the training data. This shows that physics-informed graph neural networks can be trained using 4D flow MRI data to estimate blood flow in unseen carotid artery geometries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.07110v2</guid>
      <category>q-bio.QM</category>
      <category>cs.LG</category>
      <category>physics.flu-dyn</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.media.2026.103974</arxiv:DOI>
      <dc:creator>Julian Suk, Dieuwertje Alblas, Barbara A. Hutten, Albert Wiegman, Christoph Brune, Pim van Ooij, Jelmer M. Wolterink</dc:creator>
    </item>
    <item>
      <title>A measurement noise scaling law for cellular representation learning</title>
      <link>https://arxiv.org/abs/2503.02726</link>
      <description>arXiv:2503.02726v2 Announce Type: replace 
Abstract: Large genomic and imaging datasets can be used to train models that learn meaningful representations of cellular systems. Across domains, model performance improves predictably with dataset size and compute budget, providing a basis for allocating data and computation. Scientific data, however, is also limited by noise arising from factors such as molecular undersampling, sequencing errors, and image resolution. By fitting 1,670 representation learning models across three data modalities (gene expression, sequence, and image data), we show that noise defines a distinct axis along which performance improves. Noise scaling follows a logarithmic law. We derive the law from a model of noise propagation, and use it to define noise sensitivity and model capacity as benchmarking metrics. We show that protein sequence representations are noise-robust while single cell transcriptomics models are not, with a Transformer-based model showing greater noise robustness but lower saturating performance than a variational autoencoder model. Noise scaling metrics may support future model evaluation and experimental design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.02726v2</guid>
      <category>q-bio.QM</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gokul Gowri, Igor Sadalski, Dan Raviv, Peng Yin, Jonathan Rosenfeld, Allon M. Klein</dc:creator>
    </item>
    <item>
      <title>An Entropy-initiated Coupled-Trait ODE Framework for Modeling Longitudinal Cohort Dynamics</title>
      <link>https://arxiv.org/abs/2506.20622</link>
      <description>arXiv:2506.20622v3 Announce Type: replace 
Abstract: This work introduces a minimal, information-theoretic dynamical framework for modeling longitudinal cohort data using an entropy-initiated system of coupled-trait ordinary differential equations (ECTO). For each survey wave, item-level Likert responses are compressed into a normalized Shannon entropy index that summarizes cross-sectional dispersion; this index is used to initialize the low-dimensional state variables of the autonomous ODE system. ECTO then tracks the interactions among a primary trait-like state, a secondary coupled state, and a latent environmental-stress component through phenomenological terms representing generic self-limitation, trade-offs, and feedback. Using data from the Swedish Adoption/Twin Study on Aging (SATSA), the framework reproduces broad cohort-level trajectories and is evaluated with leave-one-wave-out forecasting and comparisons against simple statistical baselines. A second longitudinal dataset of U.S. dental student data provides an external validation test, demonstrating that low-dimensional dynamics initialized from entropy measures can generalize across cohorts with different measurement instruments, demographic compositions, and timescales. Across both datasets, ECTO achieves stable out-of-sample performance, indicating that major cohort-level trends can be captured without assuming complex latent-variable models or time-varying causal inputs. Entropy here functions as a compact summary of population heterogeneity rather than a dynamical driver, and the coupled ODEs supply an interpretable alternative to high-dimensional or black box machine-learning approaches. This framework establishes a concise, transparent method for linking information-theoretic preprocessing with cohort-level dynamical modeling and provides a foundation for future multivariate or multi-cohort extensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20622v3</guid>
      <category>q-bio.QM</category>
      <category>physics.bio-ph</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1371/journal.pone.0344090</arxiv:DOI>
      <dc:creator>Anderson M. Rodriguez</dc:creator>
    </item>
    <item>
      <title>Co-Evolution-Based Metal-Binding Residue Prediction with Graph Neural Networks</title>
      <link>https://arxiv.org/abs/2502.16189</link>
      <description>arXiv:2502.16189v2 Announce Type: replace-cross 
Abstract: Understanding protein-metal interactions is central to structural biology, with metal ions being vital for catalysis, stability, and signal transduction. Predicting metal-binding residues and metal types remains challenging due to the structural and evolutionary complexity of proteins. Conventional sequence- and structure-based methods often fail to capture co-evolutionary constraints that reflect how residues evolve together to maintain metal-binding functionality. Recent co-evolution-based methods capture part of this information, but still underutilize the complete co-evolved residue network. To address this limitation, we introduce the Metal-Binding Graph Neural Network (MBGNN), which leverages the complete co-evolved residue network to better capture complex dependencies within protein structures. Experimental results show that MBGNN substantially outperforms the state-of-the-art co-evolution-based method MetalNet2, achieving F1 score improvements of 2.5% for binding residue identification and 3.3% for metal type classification on the MetalNet2 dataset. Its superiority is further demonstrated on both the MetalNet2 and MIonSite datasets, where it outperforms two co-evolution-based and two sequence-based methods, achieving the highest mean F1 scores across both prediction tasks. These findings highlight how integrating co-evolutionary residue networks with graph-based learning advances our ability to decode protein-metal interactions, thereby facilitating functional annotation and rational metalloprotein design. The code and data are released at https://github.com/SRastegari/MBGNN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16189v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.mtrl-sci</category>
      <category>q-bio.BM</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayedmohammadreza Rastegari, Sina Tabakhi, Xianyuan Liu, Tianyi Jiang, Wei Sang, Haiping Lu</dc:creator>
    </item>
    <item>
      <title>Generative Distribution Embeddings: Lifting autoencoders to the space of distributions for multiscale representation learning</title>
      <link>https://arxiv.org/abs/2505.18150</link>
      <description>arXiv:2505.18150v2 Announce Type: replace-cross 
Abstract: Many real-world problems require reasoning across multiple scales, demanding models which operate not on single data points, but on entire distributions. We introduce generative distribution embeddings (GDE), a framework that lifts autoencoders to the space of distributions. In GDEs, an encoder acts on sets of samples, and the decoder is replaced by a generator which aims to match the input distribution. This framework enables learning representations of distributions by coupling conditional generative models with encoder networks which satisfy a criterion we call distributional invariance. We show that GDEs learn predictive sufficient statistics embedded in the Wasserstein space, such that latent GDE distances approximately recover the $W_2$ distance, and latent interpolation approximately recovers optimal transport trajectories for Gaussian and Gaussian mixture distributions. We systematically benchmark GDEs against existing approaches on synthetic datasets, demonstrating consistently stronger performance. We then apply GDEs to six key problems in computational biology: learning donor-level representations from single-nuclei RNA sequencing data (6M cells), capturing clonal dynamics in lineage-traced RNA sequencing data (150K cells), predicting perturbation effects on transcriptomes (1M cells), predicting perturbation effects on cellular phenotypes (20M single-cell images), designing synthetic yeast promoters (34M sequences), and spatiotemporal modeling of viral protein sequences (1M sequences).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.18150v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <category>stat.ML</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nic Fishman, Gokul Gowri, Peng Yin, Jonathan Gootenberg, Omar Abudayyeh</dc:creator>
    </item>
    <item>
      <title>Reversible Deep Learning for 13C NMR in Chemoinformatics: On Structures and Spectra</title>
      <link>https://arxiv.org/abs/2602.03875</link>
      <description>arXiv:2602.03875v3 Announce Type: replace-cross 
Abstract: We introduce a reversible deep learning model for 13C NMR that uses a single conditional invertible neural network for both directions between molecular structures and spectra. The network is built from i-RevNet style bijective blocks, so the forward map and its inverse are available by construction. We train the model to predict a 128-bit binned spectrum code from a graph-based structure encoding, while the remaining latent dimensions capture residual variability. At inference time, we invert the same trained network to generate structure candidates from a spectrum code, which explicitly represents the one-to-many nature of spectrum-to-structure inference. On a filtered subset, the model is numerically invertible on trained examples, achieves spectrum-code prediction above chance, and produces coarse but meaningful structural signals when inverted on validation spectra. These results demonstrate that invertible architectures can unify spectrum prediction and uncertainty-aware candidate generation within one end-to-end model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.03875v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Mon, 23 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Stefan Kuhn, Vandana Dwarka, Przemyslaw Karol Grenda, Eero Vainikko</dc:creator>
    </item>
  </channel>
</rss>
