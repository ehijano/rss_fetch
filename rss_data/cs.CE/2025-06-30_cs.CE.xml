<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 30 Jun 2025 04:00:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Storm Surge in Color: RGB-Encoded Physics-Aware Deep Learning for Storm Surge Forecasting</title>
      <link>https://arxiv.org/abs/2506.21743</link>
      <description>arXiv:2506.21743v1 Announce Type: new 
Abstract: Storm surge forecasting plays a crucial role in coastal disaster preparedness, yet existing machine learning approaches often suffer from limited spatial resolution, reliance on coastal station data, and poor generalization. Moreover, many prior models operate directly on unstructured spatial data, making them incompatible with modern deep learning architectures. In this work, we introduce a novel approach that projects unstructured water elevation fields onto structured Red Green Blue (RGB)-encoded image representations, enabling the application of Convolutional Long Short Term Memory (ConvLSTM) networks for end-to-end spatiotemporal surge forecasting. Our model further integrates ground-truth wind fields as dynamic conditioning signals and topo-bathymetry as a static input, capturing physically meaningful drivers of surge evolution. Evaluated on a large-scale dataset of synthetic storms in the Gulf of Mexico, our method demonstrates robust 48-hour forecasting performance across multiple regions along the Texas coast and exhibits strong spatial extensibility to other coastal areas. By combining structured representation, physically grounded forcings, and scalable deep learning, this study advances the frontier of storm surge forecasting in usability, adaptability, and interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21743v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jinpai Zhao, Albert Cerrone, Eirik Valseth, Leendert Westerink, Clint Dawson</dc:creator>
    </item>
    <item>
      <title>Laser Scan Path Design for Controlled Microstructure in Additive Manufacturing with Integrated Reduced-Order Phase-Field Modeling and Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2506.21815</link>
      <description>arXiv:2506.21815v1 Announce Type: new 
Abstract: Laser powder bed fusion (L-PBF) is a widely recognized additive manufacturing technology for producing intricate metal components with exceptional accuracy. A key challenge in L-PBF is the formation of complex microstructures affecting product quality. We propose a physics-guided, machine-learning approach to optimize scan paths for desired microstructure outcomes, such as equiaxed grains. We utilized a phase-field method (PFM) to model crystalline grain structure evolution. To reduce computational costs, we trained a surrogate machine learning model, a 3D U-Net convolutional neural network, using single-track phase-field simulations with various laser powers to predict crystalline grain orientations based on initial microstructure and thermal history. We investigated three scanning strategies across various hatch spacings within a square domain, achieving a two-orders-of-magnitude speedup using the surrogate model. To reduce trial and error in designing laser scan toolpaths, we used deep reinforcement learning (DRL) to generate optimized scan paths for target microstructure. Results from three cases demonstrate the DRL approach's effectiveness. We integrated the surrogate 3D U-Net model into our DRL environment to accelerate the reinforcement learning training process. The reward function minimizes both aspect ratio and grain volume of the predicted microstructure from the agent's scan path. The reinforcement learning algorithm was benchmarked against conventional zigzag approach for smaller and larger domains, showing machine learning methods' potential to enhance microstructure control and computational efficiency in L-PBF optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21815v1</guid>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Augustine Twumasi, Prokash Chandra Roy, Zixun Li, Soumya Shouvik Bhattacharjee, Zhengtao Gan</dc:creator>
    </item>
    <item>
      <title>Model-free Forecasting of Rogue Waves using Reservoir Computing</title>
      <link>https://arxiv.org/abs/2506.21918</link>
      <description>arXiv:2506.21918v1 Announce Type: new 
Abstract: Recent research has demonstrated Reservoir Computing's capability to model various chaotic dynamical systems, yet its application to Hamiltonian systems remains relatively unexplored. This paper investigates the effectiveness of Reservoir Computing in capturing rogue wave dynamics from the nonlinear Schr\"{o}dinger equation, a challenging Hamiltonian system with modulation instability. The model-free approach learns from breather simulations with five unstable modes. A properly tuned parallel Echo State Network can predict dynamics from two distinct testing datasets. The first set is a continuation of the training data, whereas the second set involves a higher-order breather. An investigation of the one-step prediction capability shows remarkable agreement between the testing data and the models. Furthermore, we show that the trained reservoir can predict the propagation of rogue waves over a relatively long prediction horizon, despite facing unseen dynamics. Finally, we introduce a method to significantly improve the Reservoir Computing prediction in autonomous mode, enhancing its long-term forecasting ability. These results advance the application of Reservoir Computing to spatio-temporal Hamiltonian systems and highlight the critical importance of phase space coverage in the design of training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21918v1</guid>
      <category>cs.CE</category>
      <category>nlin.PS</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Abrari Noor Hasmi, Hadi Susanto</dc:creator>
    </item>
    <item>
      <title>A Deep Learning Algorithm Based on CNN-LSTM Framework for Predicting Cancer Drug Sales Volume</title>
      <link>https://arxiv.org/abs/2506.21927</link>
      <description>arXiv:2506.21927v1 Announce Type: new 
Abstract: This study explores the application potential of a deep learning model based on the CNN-LSTM framework in forecasting the sales volume of cancer drugs, with a focus on modeling complex time series data. As advancements in medical technology and cancer treatment continue, the demand for oncology medications is steadily increasing. Accurate forecasting of cancer drug sales plays a critical role in optimizing production planning, supply chain management, and healthcare policy formulation. The dataset used in this research comprises quarterly sales records of a specific cancer drug in Egypt from 2015 to 2024, including multidimensional information such as date, drug type, pharmaceutical company, price, sales volume, effectiveness, and drug classification. To improve prediction accuracy, a hybrid deep learning model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks is employed. The CNN component is responsible for extracting local temporal features from the sales data, while the LSTM component captures long-term dependencies and trends. Model performance is evaluated using two widely adopted metrics: Mean Squared Error (MSE) and Root Mean Squared Error (RMSE). The results demonstrate that the CNN-LSTM model performs well on the test set, achieving an MSE of 1.150 and an RMSE of 1.072, indicating its effectiveness in handling nonlinear and volatile sales data. This research provides theoretical and technical support for data-driven decision-making in pharmaceutical marketing and healthcare resource planning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21927v1</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yinghan Li, Yilin Yao, Junghua Lin, Nanxi Wang</dc:creator>
    </item>
    <item>
      <title>PEACE: Empowering Geologic Map Holistic Understanding with MLLMs</title>
      <link>https://arxiv.org/abs/2501.06184</link>
      <description>arXiv:2501.06184v1 Announce Type: cross 
Abstract: Geologic map, as a fundamental diagram in geology science, provides critical insights into the structure and composition of Earth's subsurface and surface. These maps are indispensable in various fields, including disaster detection, resource exploration, and civil engineering. Despite their significance, current Multimodal Large Language Models (MLLMs) often fall short in geologic map understanding. This gap is primarily due to the challenging nature of cartographic generalization, which involves handling high-resolution map, managing multiple associated components, and requiring domain-specific knowledge. To quantify this gap, we construct GeoMap-Bench, the first-ever benchmark for evaluating MLLMs in geologic map understanding, which assesses the full-scale abilities in extracting, referring, grounding, reasoning, and analyzing. To bridge this gap, we introduce GeoMap-Agent, the inaugural agent designed for geologic map understanding, which features three modules: Hierarchical Information Extraction (HIE), Domain Knowledge Injection (DKI), and Prompt-enhanced Question Answering (PEQA). Inspired by the interdisciplinary collaboration among human scientists, an AI expert group acts as consultants, utilizing a diverse tool pool to comprehensively analyze questions. Through comprehensive experiments, GeoMap-Agent achieves an overall score of 0.811 on GeoMap-Bench, significantly outperforming 0.369 of GPT-4o. Our work, emPowering gEologic mAp holistiC undErstanding (PEACE) with MLLMs, paves the way for advanced AI applications in geology, enhancing the efficiency and accuracy of geological investigations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.06184v1</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.HC</category>
      <category>cs.MA</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yangyu Huang, Tianyi Gao, Haoran Xu, Qihao Zhao, Yang Song, Zhipeng Gui, Tengchao Lv, Hao Chen, Lei Cui, Scarlett Li, Furu Wei</dc:creator>
    </item>
    <item>
      <title>Large-Scale Simulations of Turbulent Flows using Lattice Boltzmann Methods on Heterogeneous High Performance Computers</title>
      <link>https://arxiv.org/abs/2506.21804</link>
      <description>arXiv:2506.21804v1 Announce Type: cross 
Abstract: Current GPU-accelerated supercomputers promise to enable large-scale simulations of turbulent flows. Lattice Boltzmann Methods (LBM) are particularly well-suited to fulfilling this promise due to their intrinsic compatibility with highly parallel execution on both SIMD CPUs and GPUs. A novel LBM scheme for wall-modeled LES in complex geometries is described with a special focus on the efficient implementation in the open source LBM framework OpenLB. Detailed scalability results are provided for all HoreKa partitions, utilizing up to 128 nodes and covering problem sizes up to 18 billion cells.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21804v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.CE</category>
      <category>cs.MS</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Adrian Kummerl\"ander, Fedor Bukreev, Yuji Shimojima, Shota Ito, Mathias J. Krause</dc:creator>
    </item>
    <item>
      <title>StructMG: A Fast and Scalable Structured Algebraic Multigrid</title>
      <link>https://arxiv.org/abs/2506.21932</link>
      <description>arXiv:2506.21932v1 Announce Type: cross 
Abstract: Parallel multigrid is widely used as preconditioners in solving large-scale sparse linear systems. However, the current multigrid library still needs more satisfactory performance for structured grid problems regarding speed and scalability. Based on the classical 'multigrid seesaw', we derive three necessary principles for an efficient structured multigrid, which instructs our design and implementation of StructMG, a fast and scalable algebraic multigrid that constructs hierarchical grids automatically. As a preconditioner, StructMG can achieve both low cost per iteration and good convergence when solving large-scale linear systems with iterative methods in parallel. A stencil-based triple-matrix product via symbolic derivation and code generation is proposed for multi-dimensional Galerkin coarsening to reduce grid complexity, operator complexity, and implementation effort. A unified parallel framework of sparse triangular solver is presented to achieve fast convergence and high parallel efficiency for smoothers, including dependence-preserving Gauss-Seidel and incomplete LU methods. Idealized and real-world problems from radiation hydrodynamics, petroleum reservoir simulation, numerical weather prediction, and solid mechanics, are evaluated on ARM and X86 platforms to show StructMG's effectiveness. In comparison to \textit{hypre}'s structured and general multigrid preconditioners, StructMG achieves the fastest time-to-solutions in all cases with average speedups of 15.5x, 5.5x, 6.7x, 7.3x over SMG, PFMG, SysPFMG, and BoomerAMG, respectively. StructMG also significantly improves strong and weak scaling efficiencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21932v1</guid>
      <category>math.NA</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>cs.PF</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yi Zong, Peinan Yu, Haopeng Huang, Zhengding Hu, Xinliang Wang, Qin Wang, Chensong Zhang, Xiaowen Xu, Jian Sun, Yongxiao Zhou, Wei Xue</dc:creator>
    </item>
    <item>
      <title>EUR/USD Exchange Rate Forecasting incorporating Text Mining Based on Pre-trained Language Models and Deep Learning Methods</title>
      <link>https://arxiv.org/abs/2411.07560</link>
      <description>arXiv:2411.07560v2 Announce Type: replace 
Abstract: This study introduces a novel approach for EUR/USD exchange rate forecasting that integrates deep learning, textual analysis, and particle swarm optimization (PSO). By incorporating online news and analysis texts as qualitative data, the proposed PSO-LSTM model demonstrates superior performance compared to traditional econometric and machine learning models. The research employs advanced text mining techniques, including sentiment analysis using the RoBERTa-Large model and topic modeling with LDA. Empirical findings underscore the significant advantage of incorporating textual data, with the PSO-LSTM model outperforming benchmark models such as SVM, SVR, ARIMA, and GARCH. Ablation experiments reveal the contribution of each textual data category to the overall forecasting performance. The study highlights the transformative potential of artificial intelligence in finance and paves the way for future research in real-time forecasting and the integration of alternative data sources.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.07560v2</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongcheng Ding, Xiangyu Shi, Ruiting Deng, Salaar Faroog, Deshinta Arrova Dewi, Shamsul Nahar Abdullah, Bahiah A Malek</dc:creator>
    </item>
    <item>
      <title>V2T-CoT: From Vision to Text Chain-of-Thought for Medical Reasoning and Diagnosis</title>
      <link>https://arxiv.org/abs/2506.19610</link>
      <description>arXiv:2506.19610v2 Announce Type: replace 
Abstract: Recent advances in multimodal techniques have led to significant progress in Medical Visual Question Answering (Med-VQA). However, most existing models focus on global image features rather than localizing disease-specific regions crucial for diagnosis. Additionally, current research tends to emphasize answer accuracy at the expense of the reasoning pathway, yet both are crucial for clinical decision-making. To address these challenges, we propose From Vision to Text Chain-of-Thought (V2T-CoT), a novel approach that automates the localization of preference areas within biomedical images and incorporates this localization into region-level pixel attention as knowledge for Vision CoT. By fine-tuning the vision language model on constructed R-Med 39K dataset, V2T-CoT provides definitive medical reasoning paths. V2T-CoT integrates visual grounding with textual rationale generation to establish precise and explainable diagnostic results. Experimental results across four Med-VQA benchmarks demonstrate state-of-the-art performance, achieving substantial improvements in both performance and interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.19610v2</guid>
      <category>cs.CE</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Wang, Jiaxiang Liu, Shujian Gao, Bin Feng, Zhihang Tang, Xiaotang Gai, Jian Wu, Zuozhu Liu</dc:creator>
    </item>
    <item>
      <title>From Data Quality for AI to AI for Data Quality: A Systematic Review of Tools for AI-Augmented Data Quality Management in Data Warehouses</title>
      <link>https://arxiv.org/abs/2406.10940</link>
      <description>arXiv:2406.10940v3 Announce Type: replace-cross 
Abstract: While high data quality (DQ) is critical for analytics, compliance, and AI performance, data quality management (DQM) remains a complex, resource-intensive, and often manual process. This study investigates the extent to which existing tools support AI-augmented data quality management (DQM) in data warehouse environments. To this end, we conduct a systematic review of 151 DQ tools to evaluate their automation capabilities, particularly in detecting and recommending DQ rules in data warehouses -- a key component of modern data ecosystems. Using a multi-phase screening process based on functionality, trialability, regulatory compliance (e.g., GDPR), and architectural compatibility with data warehouses, only 10 tools met the criteria for AI-augmented DQM. The analysis reveals that most tools emphasize data cleansing and preparation for AI, rather than leveraging AI to improve DQ itself. Although metadata- and ML-based rule detection techniques are present, features such as SQL-based rule specification, reconciliation logic, and explainability of AI-driven recommendations remain scarce. This study offers practical guidance for tool selection and outlines critical design requirements for next-generation AI-driven DQ solutions -- advocating a paradigm shift from ``data quality for AI'' to ``AI for data quality management''.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.10940v3</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.ET</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Heidi Carolina Tamm, Anastasija Nikiforova</dc:creator>
    </item>
    <item>
      <title>EUR-USD Exchange Rate Forecasting Based on Information Fusion with Large Language Models and Deep Learning Methods</title>
      <link>https://arxiv.org/abs/2408.13214</link>
      <description>arXiv:2408.13214v2 Announce Type: replace-cross 
Abstract: Accurate forecasting of the EUR/USD exchange rate is crucial for investors, businesses, and policymakers. This paper proposes a novel framework, IUS, that integrates unstructured textual data from news and analysis with structured data on exchange rates and financial indicators to enhance exchange rate prediction. The IUS framework employs large language models for sentiment polarity scoring and exchange rate movement classification of texts. These textual features are combined with quantitative features and input into a Causality-Driven Feature Generator. An Optuna-optimized Bi-LSTM model is then used to forecast the EUR/USD exchange rate. Experiments demonstrate that the proposed method outperforms benchmark models, reducing MAE by 10.69% and RMSE by 9.56% compared to the best performing baseline. Results also show the benefits of data fusion, with the combination of unstructured and structured data yielding higher accuracy than structured data alone. Furthermore, feature selection using the top 12 important quantitative features combined with the textual features proves most effective. The proposed IUS framework and Optuna-Bi-LSTM model provide a powerful new approach for exchange rate forecasting through multi-source data integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13214v2</guid>
      <category>q-fin.CP</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.CL</category>
      <pubDate>Mon, 30 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongcheng Ding, Xuanze Zhao, Ruiting Deng, Shamsul Nahar Abdullah, Deshinta Arrova Dewi</dc:creator>
    </item>
  </channel>
</rss>
