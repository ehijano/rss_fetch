<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 08 Aug 2025 06:31:10 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Subset Sum in Near-Linear Pseudopolynomial Time and Polynomial Space</title>
      <link>https://arxiv.org/abs/2508.04726</link>
      <description>arXiv:2508.04726v1 Announce Type: new 
Abstract: Given a multiset $A = \{a_1, \dots, a_n\}$ of positive integers and a target integer $t$, the Subset Sum problem asks if there is a subset of $A$ that sums to $t$. Bellman's [1957] classical dynamic programming algorithm runs in $O(nt)$ time and $O(t)$ space. Since then, there have been multiple improvements in both time and space complexity.
  Notably, Bringmann [SODA 2017] uses a two-step color-coding technique to obtain a randomized algorithm that runs in $\tilde{O}(n+t)$ time and $\tilde{O}(t)$ space. On the other hand, there are polynomial space algorithms -- for example, Jin, Vyas and Williams [SODA 2021] build upon the algorithm given by Bringmann, using a clever algebraic trick first seen in Kane's Logspace algorithm, to obtain an $\tilde{O}(nt)$ time and $\tilde{O}(\log(nt))$ space algorithm. A natural question, asked by Jin et al. is if there is an $\tilde{O}(n+t)$ time algorithm running in poly$(n, \log t)$ space. Another natural question is whether it is possible to construct a deterministic polynomial space algorithm with time complexity comparable to that of Bellman's.
  In this paper, we answer both questions affirmatively. We build on the framework given by Jin et al., using a multipoint evaluation-based approach to speed up a bottleneck step in their algorithm. We construct a deterministic algorithm that runs in $\tilde{O}(nt)$ time and $\tilde{O}(n \log^2 t)$ space and a randomized algorithm that runs in $\tilde{O}(n+t)$ time and $\tilde{O}(n^2 + n \log^2 t)$ space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04726v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thejas Radhika Sajith</dc:creator>
    </item>
    <item>
      <title>A Refutation of Elmasry's $\tilde{O}(m \sqrt{n})$-Time Algorithm for Single-Source Shortest Paths</title>
      <link>https://arxiv.org/abs/2508.04872</link>
      <description>arXiv:2508.04872v1 Announce Type: new 
Abstract: In this note we examine the recent paper "Breaking the Bellman-Ford Shortest-Path Bound" by Amr Elmasry, where he presents an algorithm for the single-source shortest path problem and claims that its running time complexity is $\tilde{O}(m\sqrt{n})$, where $n$ is the number of vertices and $m$ is the number of edges. We show that his analysis is incorrect, by providing an example of a weighted graph on which the running time of his algorithm is $\Omega(mn)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04872v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sunny Atalig, Marek Chrobak</dc:creator>
    </item>
    <item>
      <title>Text Indexing and Pattern Matching with Ephemeral Edits</title>
      <link>https://arxiv.org/abs/2508.05124</link>
      <description>arXiv:2508.05124v1 Announce Type: new 
Abstract: A sequence $e_0,e_1,\ldots$ of edit operations in a string $T$ is called ephemeral if operation $e_i$ constructing string $T^i$, for all $i=2k$ with $k\in\mathbb{N}$, is reverted by operation $e_{i+1}$ that reconstructs $T$. Such a sequence arises when processing a stream of independent edits or testing hypothetical edits.
  We introduce text indexing with ephemeral substring edits, a new version of text indexing. Our goal is to design a data structure over a given text that supports subsequent pattern matching queries with ephemeral substring insertions, deletions, or substitutions in the text; we require insertions and substitutions to be of constant length. In particular, we preprocess a text $T=T[0\mathinner{.\,.} n)$ over an integer alphabet $\Sigma=[0,\sigma)$ with $\sigma=n^{\mathcal{O}(1)}$ in $\mathcal{O}(n)$ time. Then, we can preprocess any arbitrary pattern $P=P[0\mathinner{.\,.} m)$ given online in $\mathcal{O}(m\log\log m)$ time and $\mathcal{O}(m)$ space and allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in $\mathcal{O}(\log\log n + \text{Occ})$ time.
  We also introduce pattern matching with ephemeral edits. In particular, we preprocess two strings $T$ and $P$, each of length at most $n$, over an integer alphabet $\Sigma=[0,\sigma)$ with $\sigma=n^{\mathcal{O}(1)}$ in $\mathcal{O}(n)$ time. Then, we allow any ephemeral sequence of edit operations in $T$. Before reverting the $i$th operation, we report all Occ occurrences of $P$ in $T^i$ in the optimal $\mathcal{O}(\text{Occ})$ time. Along our way to this result, we also give an optimal solution for pattern matching with ephemeral block deletions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05124v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Solon P. Pissis</dc:creator>
    </item>
    <item>
      <title>Space-Efficient Hierholzer: Eulerian Cycles in O(m) Time and O(n) Space</title>
      <link>https://arxiv.org/abs/2508.05251</link>
      <description>arXiv:2508.05251v1 Announce Type: new 
Abstract: We describe a simple variant of Hierholzer's algorithm that finds an Eulerian cycle in a (multi)graph with $n$ vertices and $m$ edges using $\mathrm{O}(n \lg m)$ bits of working memory. This substantially improves the working space compared to standard implementations of Hierholzer's algorithm, which use $\mathrm{O}(m \lg n)$ bits of space. Our algorithm runs in linear time, like the classical versions, but avoids an $\mathrm{O}(m)$-size stack of vertices or storing information for each edge. To our knowledge, this is the first linear-time algorithm to achieve this space bound, and the method is very easy to implement. The correctness argument, by contrast, is surprisingly subtle; we give a detailed formal proof. The space savings are particularly relevant for dense graphs or multigraphs with large edge multiplicities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05251v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziad Ismaili Alaoui, Detlef Plump, Sebastian Wild</dc:creator>
    </item>
    <item>
      <title>Parameterized Algorithms for Spanning Tree Isomorphism by Redundant Set Size</title>
      <link>https://arxiv.org/abs/2508.05351</link>
      <description>arXiv:2508.05351v1 Announce Type: new 
Abstract: In this paper, we present fixed-parameter tractability algorithms for both the undirected and directed versions of the Spanning Tree Isomorphism Problem, parameterized by the size $k$ of a redundant set. A redundant set is a collection of edges whose removal transforms the graph into a spanning tree. For the undirected version, our algorithm achieves a time complexity of $O(n^2 \log n \cdot 2^{k \log k})$. For the directed version, we propose a more efficient algorithm with a time complexity of $O(n^2 \cdot 2^{4k-3})$, where $n$ is the number of vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05351v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangjian Shen, Yicheng Zheng, Wushao Wen, Hankz Hankui Zhuo</dc:creator>
    </item>
    <item>
      <title>Online Sparsification of Bipartite-Like Clusters in Graphs</title>
      <link>https://arxiv.org/abs/2508.05437</link>
      <description>arXiv:2508.05437v1 Announce Type: new 
Abstract: Graph clustering is an important algorithmic technique for analysing massive graphs, and has been widely applied in many research fields of data science. While the objective of most graph clustering algorithms is to find a vertex set of low conductance, a sequence of recent studies highlights the importance of the inter-connection between vertex sets when analysing real-world datasets. Following this line of research, in this work we study bipartite-like clusters and present efficient and online sparsification algorithms that find such clusters in both undirected graphs and directed ones. We conduct experimental studies on both synthetic and real-world datasets, and show that our algorithms significantly speedup the running time of existing clustering algorithms while preserving their effectiveness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05437v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joyentanuj Das, Suranjan De, He Sun</dc:creator>
    </item>
    <item>
      <title>Parameterized complexity of isometric path partition: treewidth and diameter</title>
      <link>https://arxiv.org/abs/2508.05448</link>
      <description>arXiv:2508.05448v1 Announce Type: new 
Abstract: We investigate the parameterized complexity of the Isometric Path Partition problem when parameterized by the treewidth ($\mathrm{tw}$) of the input graph, arguably one of the most widely studied parameters. Courcelle's theorem shows that graph problems that are expressible as MSO formulas of constant size admit FPT algorithms parameterized by the treewidth of the input graph. This encompasses many natural graph problems. However, many metric-based graph problems, where the solution is defined using some metric-based property of the graph (often the distance) are not expressible as MSO formulas of constant size. These types of problems, Isometric Path Partition being one of them, require individual attention and often draw the boundary for the success story of parameterization by treewidth.
  In this paper, we prove that Isometric Path Partition is $W[1]$-hard when parameterized by treewidth (in fact, even pathwidth), answering the question by Dumas et al. [SIDMA, 2024], Fernau et al. [CIAC, 2023], and confirming the aforementioned tendency. We complement this hardness result by designing a tailored dynamic programming algorithm running in $n^{O(\mathrm{tw})}$ time. This dynamic programming approach also results in an algorithm running in time $\textrm{diam}^{O(\mathrm{tw}^2)} \cdot n^{O(1)}$, where $\textrm{diam}$ is the diameter of the graph. Note that the dependency on treewidth is unusually high, as most problems admit algorithms running in time $2^{O(\mathrm{tw})}\cdot n^{O(1)}$ or $2^{O(\mathrm{tw} \log (\mathrm{tw}))}\cdot n^{O(1)}$. However, we rule out the possibility of a significantly faster algorithm by proving that Isometric Path Partition does not admit an algorithm running in time $\textrm{diam}^{o(\mathrm{tw}^2/(\log^3(\mathrm{tw})))} \cdot n^{O(1)}$, unless the Randomized-ETH fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05448v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dibyayan Chakraborty, Oscar Defrain, Florent Foucaud, Mathieu Mari, Prafullkumar Tale</dc:creator>
    </item>
    <item>
      <title>An Improved Approximation Algorithm for the Capacitated Arc Routing Problem</title>
      <link>https://arxiv.org/abs/2508.05471</link>
      <description>arXiv:2508.05471v1 Announce Type: new 
Abstract: The Capacitated Arc Routing Problem (CARP), introduced by Golden and Wong in 1981, is an important arc routing problem in Operations Research, which generalizes the famous Capacitated Vehicle Routing Problem (CVRP). When every customer has a unit demand, the best known approximation ratio for CARP, given by Jansen in 1993, remains $\frac{5}{2}-\frac{1.5}{k}$, where $k$ denotes the vehicle capacity. Based on recent progress in approximating CVRP, we improve this result by proposing a $(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$-approximation algorithm, which to the best of our knowledge constitutes the first improvement over Jansen's bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05471v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Zhao, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Minimum-Weight Parity Factor Decoder for Quantum Error Correction</title>
      <link>https://arxiv.org/abs/2508.04969</link>
      <description>arXiv:2508.04969v1 Announce Type: cross 
Abstract: Fast and accurate quantum error correction (QEC) decoding is crucial for scalable fault-tolerant quantum computation. Most-Likely-Error (MLE) decoding, while being near-optimal, is intractable on general quantum Low-Density Parity-Check (qLDPC) codes and typically relies on approximation and heuristics. We propose HyperBlossom, a unified framework that formulates MLE decoding as a Minimum-Weight Parity Factor (MWPF) problem and generalizes the blossom algorithm to hypergraphs via a similar primal-dual linear programming model with certifiable proximity bounds. HyperBlossom unifies all the existing graph-based decoders like (Hypergraph) Union-Find decoders and Minimum-Weight Perfect Matching (MWPM) decoder, thus bridging the gap between heuristic and certifying decoders.
  We implement HyperBlossom in software, namely Hyperion. Hyperion achieves a 4.8x lower logical error rate compared to the MWPM decoder on the distance-11 surface code and 1.6x lower logical error rate compared to a fine-tuned BPOSD decoder on the $[[90, 8, 10]]$ bivariate bicycle code under code-capacity noise. It also achieves an almost-linear average runtime scaling on both the surface code and the color code, with numerical results up to sufficiently large code distances of 99 and 31 for code-capacity noise and circuit-level noise, respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04969v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Wu, Binghong Li, Kathleen Chang, Shruti Puri, Lin Zhong</dc:creator>
    </item>
    <item>
      <title>Necessity of Block Designs for Optimal Locally Private Distribution Estimation</title>
      <link>https://arxiv.org/abs/2508.05110</link>
      <description>arXiv:2508.05110v1 Announce Type: cross 
Abstract: Local differential privacy represents the gold standard for preserving the privacy of data before it leaves the device, and distribution estimation under this model has been well studied. Recently, protocols built upon balanced incomplete block designs were shown to achieve optimal error for this problem. However, it remained unknown whether other constructions could also be optimal. We resolve this question by proving that any protocol achieving optimal error must correspond to some balanced incomplete block design. This result, combined with prior work, completely characterises the set of optimal protocols for this problem. As a consequence, the protocols that achieve optimal error and optimal communication are only those based on symmetrical balanced incomplete block designs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05110v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>math.IT</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abigail Gentle</dc:creator>
    </item>
    <item>
      <title>NP-Hardness and ETH-Based Inapproximability of Communication Complexity via Relaxed Interlacing</title>
      <link>https://arxiv.org/abs/2508.05597</link>
      <description>arXiv:2508.05597v1 Announce Type: cross 
Abstract: We prove that computing the deterministic communication complexity D(f) of a Boolean function is NP-hard, even when protocols are limited to a constant number of alternations, resolving a question first posed by Yao (1979). Our reduction builds and expands on a suite of structural "interlacing" lemmas introduced by Mackenzie and Saffidine (arXiv:2505.12345); these lemmas can be reused as black boxes in future lower-bound constructions.
  The instances produced by our reduction admit optimal protocols that use only constant alternations, so NP-hardness holds under stronger restrictions than those considered in concurrent and independent work by Hirahara, Ilango, and Loff (arXiv:2507.06789), whose proof requires unbounded alternations.
  Because the gadgets in our construction are self-similar, they can be recursively embedded. We sketch how this yields, under the Exponential-Time Hypothesis, an additive inapproximability gap that grows without bound, and we outline a route toward NP-hardness of approximating D(f) within a fixed constant additive error. Full details of the ETH-based inapproximability results will appear in a future version.
  Beyond settling the complexity of deterministic communication complexity itself, the modular framework we develop opens the door to a wider class of reductions and, we believe, will prove useful in tackling other long-standing questions in communication complexity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.05597v1</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Serge Gaspers, Zixu He, Simon Mackenzie</dc:creator>
    </item>
    <item>
      <title>Computing the probability of intersection</title>
      <link>https://arxiv.org/abs/2507.10329</link>
      <description>arXiv:2507.10329v2 Announce Type: replace-cross 
Abstract: Let $\Omega_1, \ldots, \Omega_m$ be probability spaces, let $\Omega=\Omega_1 \times \cdots \times \Omega_m$ be their product and let $A_1, \ldots, A_n \subset \Omega$ be events. Suppose that each event $A_i$ depends on $r_i$ coordinates of a point $x \in \Omega$, $x=\left(\xi_1, \ldots, \xi_m\right)$, and that for each event $A_i$ there are $\Delta_i$ of other events $A_j$ that depend on some of the coordinates that $A_i$ depends on. Let $\Delta=\max\{5,\ \Delta_i: i=1, \ldots, n\}$ and let $\mu_i=\min\{r_i,\ \Delta_i+1\}$ for $i=1, \ldots, n$. We prove that if $P(A_i) &lt; (3\Delta)^{-3\mu_i}$ for all $i$, then for any $0 &lt; \epsilon &lt; 1$, the probability $P\left( \bigcap_{i=1}^n \overline{A}_i\right)$ of the intersection of the complements of all $A_i$ can be computed within relative error $\epsilon$ in polynomial time from the probabilities $P\left(A_{i_1} \cap \ldots \cap A_{i_k}\right)$ of $k$-wise intersections of the events $A_i$ for $k = e^{O(\Delta)} \ln (n/\epsilon)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10329v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Fri, 08 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Barvinok</dc:creator>
    </item>
  </channel>
</rss>
