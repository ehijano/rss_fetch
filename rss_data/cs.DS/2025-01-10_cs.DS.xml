<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 10 Jan 2025 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Improved Approximation Algorithms for (1,2)-TSP and Max-TSP Using Path Covers in the Semi-Streaming Model</title>
      <link>https://arxiv.org/abs/2501.04813</link>
      <description>arXiv:2501.04813v1 Announce Type: new 
Abstract: We investigate semi-streaming algorithms for the Traveling Salesman Problem (TSP). Specifically, we focus on a variant known as the $(1,2)$-TSP, where the distances between any two vertices are either one or two. Our primary emphasis is on the closely related Maximum Path Cover Problem, which aims to find a collection of vertex-disjoint paths that covers the maximum number of edges in a graph. We propose an algorithm that, for any $\epsilon &gt; 0$, achieves a $(\frac{2}{3}-\epsilon)$-approximation of the maximum path cover size for an $n$-vertex graph, using $\text{poly}(\frac{1}{\epsilon})$ passes. This result improves upon the previous $\frac{1}{2}$-approximation by Behnezhad and et al. [ICALP 2024] in the semi-streaming model. Building on this result, we design a semi-streaming algorithm that constructs a tour for an instance of \tsp with an approximation factor of $(\frac{4}{3} + \epsilon)$, improving upon the previous $\frac{3}{2}$-approximation actor algorithm by Behnezhad and et al. [ICALP 2024] (Although it is not explicitly stated in this paper that their algorithm works in the semi-streaming model, it is easy to verify). Furthermore, we extend our approach to develop an approximation algorithm for the Maximum TSP (Max-TSP), where the goal is to find a Hamiltonian cycle with the maximum possible weight in a given weighted graph $G$. Our algorithm provides a $(\frac{7}{12} - \epsilon)$-approximation for Max-TSP in $\text{poly}(\frac{1}{\epsilon})$ passes, improving on the previously known $(\frac{1}{2}-\epsilon)$-approximation obtained via maximum weight matching in the semi-streaming model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04813v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharareh Alipour, Ermiya Farokhnejad, Tobias M\"omke</dc:creator>
    </item>
    <item>
      <title>ETH-Tight FPT Algorithm for Makespan Minimization on Uniform Machines</title>
      <link>https://arxiv.org/abs/2501.04859</link>
      <description>arXiv:2501.04859v1 Announce Type: new 
Abstract: Given $n$ jobs with processing times $p_1,\dotsc,p_n\in\mathbb N$ and $m\le n$ machines with speeds $s_1,\dotsc,s_m\in\mathbb N$ our goal is to allocate the jobs to machines minimizing the makespan. We present an algorithm that solves the problem in time $p_{\max}^{O(d)} n^{O(1)}$, where $p_{\max}$ is the maximum processing time and $d\le p_{\max}$ is the number of distinct processing times. This is essentially the best possible due to a lower bound based on the exponential time hypothesis (ETH).
  Our result improves over prior works that had a quadratic term in $d$ in the exponent and answers an open question by Kouteck\'y and Zink. The algorithm is based on integer programming techniques combined with novel ideas based on modular arithmetic. They can also be implemented efficiently for the more compact high-multiplicity instance encoding.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04859v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Lars Rohwedder</dc:creator>
    </item>
    <item>
      <title>Sampling Unlabeled Chordal Graphs in Expected Polynomial Time</title>
      <link>https://arxiv.org/abs/2501.05024</link>
      <description>arXiv:2501.05024v1 Announce Type: new 
Abstract: We design an algorithm that generates an $n$-vertex unlabeled chordal graph uniformly at random in expected polynomial time. Along the way, we develop the following two results: (1) an $\mathsf{FPT}$ algorithm for counting and sampling labeled chordal graphs with a given automorphism $\pi$, parameterized by the number of moved points of $\pi$, and (2) a proof that the probability that a random $n$-vertex labeled chordal graph has a given automorphism $\pi\in S_n$ is at most $1/2^{c\max\{\mu^2,n\}}$, where $\mu$ is the number of moved points of $\pi$ and $c$ is a constant. Our algorithm for sampling unlabeled chordal graphs calls the aforementioned $\mathsf{FPT}$ algorithm as a black box with potentially large values of the parameter $\mu$, but the probability of calling this algorithm with a large value of $\mu$ is exponentially small.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05024v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Ursula H\'ebert-Johnson, Daniel Lokshtanov</dc:creator>
    </item>
    <item>
      <title>Approximate Minimum Tree Cover in All Symmetric Monotone Norms Simultaneously</title>
      <link>https://arxiv.org/abs/2501.05048</link>
      <description>arXiv:2501.05048v1 Announce Type: new 
Abstract: We study the problem of partitioning a set of $n$ objects in a metric space into $k$ clusters $V_1,\dots,V_k$. The quality of the clustering is measured by considering the vector of cluster costs and then minimizing some monotone symmetric norm of that vector (in particular, this includes the $\ell_p$-norms). For the costs of the clusters we take the weight of a minimum-weight spanning tree on the objects in~$V_i$, which may serve as a proxy for the cost of traversing all objects in the cluster, but also as a shape-invariant measure of cluster density similar to Single-Linkage Clustering.
  This setting has been studied by Even, Garg, K\"onemann, Ravi, Sinha (Oper. Res. Lett.}, 2004) for the setting of minimizing the weight of the largest cluster (i.e., using $\ell_\infty$) as Min-Max Tree Cover, for which they gave a constant-factor approximation. We provide a careful adaptation of their algorithm to compute solutions which are approximately optimal with respect to all monotone symmetric norms simultaneously, and show how to find them in polynomial time. In fact, our algorithm is purely combinatorial and can process metric spaces with 10,000 points in less than a second.
  As an extension, we also consider the case where instead of a target number of clusters we are provided with a set of depots in the space such that every cluster should contain at least one such depot. For this setting also we are able to give a polynomial time algorithm computing a constant factor approximation with respect to all monotone symmetric norms simultaneously.
  To show that the algorithmic results are tight up to the precise constant of approximation attainable, we also prove that such clustering problems are already APX-hard when considering only one single $\ell_p$ norm for the objective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05048v1</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matthias Kaul, Kelin Luo, Matthias Mnich, Heiko R\"oglin</dc:creator>
    </item>
    <item>
      <title>Entangled Mean Estimation in High-Dimensions</title>
      <link>https://arxiv.org/abs/2501.05425</link>
      <description>arXiv:2501.05425v1 Announce Type: new 
Abstract: We study the task of high-dimensional entangled mean estimation in the subset-of-signals model. Specifically, given $N$ independent random points $x_1,\ldots,x_N$ in $\mathbb{R}^D$ and a parameter $\alpha \in (0, 1)$ such that each $x_i$ is drawn from a Gaussian with mean $\mu$ and unknown covariance, and an unknown $\alpha$-fraction of the points have identity-bounded covariances, the goal is to estimate the common mean $\mu$. The one-dimensional version of this task has received significant attention in theoretical computer science and statistics over the past decades. Recent work [LY20; CV24] has given near-optimal upper and lower bounds for the one-dimensional setting. On the other hand, our understanding of even the information-theoretic aspects of the multivariate setting has remained limited.
  In this work, we design a computationally efficient algorithm achieving an information-theoretically near-optimal error. Specifically, we show that the optimal error (up to polylogarithmic factors) is $f(\alpha,N) + \sqrt{D/(\alpha N)}$, where the term $f(\alpha,N)$ is the error of the one-dimensional problem and the second term is the sub-Gaussian error rate. Our algorithmic approach employs an iterative refinement strategy, whereby we progressively learn more accurate approximations $\hat \mu$ to $\mu$. This is achieved via a novel rejection sampling procedure that removes points significantly deviating from $\hat \mu$, as an attempt to filter out unusually noisy samples. A complication that arises is that rejection sampling introduces bias in the distribution of the remaining points. To address this issue, we perform a careful analysis of the bias, develop an iterative dimension-reduction strategy, and employ a novel subroutine inspired by list-decodable learning that leverages the one-dimensional result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05425v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ilias Diakonikolas, Daniel M. Kane, Sihan Liu, Thanasis Pittas</dc:creator>
    </item>
    <item>
      <title>Distributed Graph Algorithms with Predictions</title>
      <link>https://arxiv.org/abs/2501.05267</link>
      <description>arXiv:2501.05267v1 Announce Type: cross 
Abstract: We initiate the study of deterministic distributed graph algorithms with predictions in synchronous message passing systems. The process at each node in the graph is given a prediction, which is some extra information about the problem instance that may be incorrect. The processes may use the predictions to help them solve the problem. The overall goal is to develop algorithms that both work faster when predictions are good and do not work much worse than algorithms without predictions when predictions are bad. Concepts from the more general area of algorithms with predictions, such as error measures, consistency, robustness, and smoothness, are adapted to distributed graph algorithms with predictions.
  We consider algorithms with predictions for four distributed graph problems, Maximal Independent Set, Maximal Matching, $(\Delta+1)$-Vertex Coloring, and $(2\Delta-1)$-Edge Coloring, where $\Delta$ denotes the degree of the graph. For each, we define an appropriate error measure. We present generic templates that can be used to design deterministic distributed graph algorithms with predictions from existing algorithms without predictions. Using these templates, we develop algorithms with predictions for Maximal Independent Set. Alternative error measures for the Maximal Independent Set problem are also considered. We obtain algorithms with predictions for general graphs and for rooted trees and analyze them using two of these error measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05267v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joan Boyar, Faith Ellen, Kim S. Larsen</dc:creator>
    </item>
    <item>
      <title>Private Selection with Heterogeneous Sensitivities</title>
      <link>https://arxiv.org/abs/2501.05309</link>
      <description>arXiv:2501.05309v1 Announce Type: cross 
Abstract: Differentially private (DP) selection involves choosing a high-scoring candidate from a finite candidate pool, where each score depends on a sensitive dataset. This problem arises naturally in a variety of contexts including model selection, hypothesis testing, and within many DP algorithms. Classical methods, such as Report Noisy Max (RNM), assume all candidates' scores are equally sensitive to changes in a single individual's data, but this often isn't the case. To address this, algorithms like the Generalised Exponential Mechanism (GEM) leverage variability in candidate sensitivities. However, we observe that while these algorithms can outperform RNM in some situations, they may underperform in others - they can even perform worse than random selection. In this work, we explore how the distribution of scores and sensitivities impacts DP selection mechanisms. In all settings we study, we find that there exists a mechanism that utilises heterogeneity in the candidate sensitivities that outperforms standard mechanisms like RNM. However, no single mechanism uniformly outperforms RNM. We propose using the correlation between the scores and sensitivities as the basis for deciding which DP selection mechanism to use. Further, we design a slight variant of GEM, modified GEM that generally performs well whenever GEM performs poorly. Relying on the correlation heuristic we propose combined GEM, which adaptively chooses between GEM and modified GEM and outperforms both in polarised settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05309v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniela Antonova, Allegra Laro, Audra McMillan, Lorenz Wolf</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Hopsets and Spanners</title>
      <link>https://arxiv.org/abs/2108.09673</link>
      <description>arXiv:2108.09673v3 Announce Type: replace 
Abstract: Given an undirected graph $G=(V,E)$, an {\em $(\alpha,\beta)$-spanner} $H=(V,E')$ is a subgraph that approximately preserves distances; for every $u,v\in V$, $d_H(u,v)\le \alpha\cdot d_G(u,v)+\beta$. An $(\alpha,\beta)$-hopset is a graph $H=(V,E")$, so that adding its edges to $G$ guarantees every pair has an $\alpha$-approximate shortest path that has at most $\beta$ edges (hops), that is, $d_G(u,v)\le d_{G\cup H}^{(\beta)}(u,v)\le \alpha\cdot d_G(u,v)$. Given the usefulness of spanners and hopsets for fundamental algorithmic tasks, several different algorithms and techniques were developed for their construction, for various regimes of the stretch parameter $\alpha$.
  In this work we develop a single algorithm that can attain all state-of-the-art spanners and hopsets for general graphs, by choosing the appropriate input parameters. In fact, in some cases it also improves upon the previous best results. We also show a lower bound on our algorithm.
  In \cite{BP20}, given a parameter $k$, a $(O(k^{\epsilon}),O(k^{1-\epsilon}))$-hopset of size $\tilde{O}(n^{1+1/k})$ was shown for any $n$-vertex graph and parameter $0&lt;\epsilon&lt;1$, and they asked whether this result is best possible. We resolve this open problem, showing that any $(\alpha,\beta)$-hopset of size $O(n^{1+1/k})$ must have $\alpha\cdot \beta\ge\Omega(k)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2108.09673v3</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ofer Neiman, Idan Shabat</dc:creator>
    </item>
    <item>
      <title>Fair Set Cover</title>
      <link>https://arxiv.org/abs/2405.11639</link>
      <description>arXiv:2405.11639v2 Announce Type: replace 
Abstract: The potential harms of algorithmic decisions have ignited algorithmic fairness as a central topic in computer science. One of the fundamental problems in computer science is Set Cover, which has numerous applications with societal impacts, such as assembling a small team of individuals that collectively satisfy a range of expertise requirements. However, despite its broad application spectrum and significant potential impact, set cover has yet to be studied through the lens of fairness. Therefore, in this paper, we introduce Fair Set Cover, which aims not only to cover with a minimum-size set but also to satisfy demographic parity in its selection of sets. To this end, we develop multiple versions of fair set cover, study their hardness, and devise efficient approximation algorithms for each variant. Notably, under certain assumptions, our algorithms always guarantees zero-unfairness, with only a small increase in the approximation ratio compared to regular set cover. Furthermore, our experiments on various data sets and across different settings confirm the negligible price of fairness, as (a) the output size increases only slightly (if any) and (b) the time to compute the output does not significantly increase.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.11639v2</guid>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3690624.3709184</arxiv:DOI>
      <dc:creator>Mohsen Dehghankar, Rahul Raychaudhury, Stavros Sintos, Abolfazl Asudeh</dc:creator>
    </item>
    <item>
      <title>Paired-domination Problem on Circle and $k$-polygon Graphs</title>
      <link>https://arxiv.org/abs/2411.19473</link>
      <description>arXiv:2411.19473v4 Announce Type: replace 
Abstract: A vertex set $D \subseteq V$ is considered a dominating set of $G$ if every vertex in $V - D$ is adjacent to at least one vertex in $D$. We called a dominating set $D$ as a paired-dominating set if the subgraph of $G$ induced by $D$ contains a perfect matching. In this paper, we show that determining the minimum paired-dominating set on circle graphs is NP-complete. We further propose an $O(n(\frac{n}{k^2-k})^{2k^2-2k})$-time algorithm for $k$-polygon graphs, a subclass of circle graphs, for finding the minimum paired-dominating set. Moreover, we extend our method to improve the algorithm for finding the minimum dominating set on $k$-polygon graphs in~[\emph{E.S.~Elmallah and L.K.~Stewart, Independence and domination in polygon graphs, Discrete Appl. Math., 1993}] and reduce their time-complexity from $O(n^{4k^2+3})$ to $O(n^{3k-5})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.19473v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>math.CO</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ta-Yu Mu, Ching-Chi Lin</dc:creator>
    </item>
    <item>
      <title>Adversary Resilient Learned Bloom Filters</title>
      <link>https://arxiv.org/abs/2409.06556</link>
      <description>arXiv:2409.06556v4 Announce Type: replace-cross 
Abstract: The Learned Bloom Filter is a recently proposed data structure that combines the Bloom Filter with a Learning Model while preserving the Bloom Filter's one-sided error guarantees. Creating an adversary-resilient construction of the Learned Bloom Filter with provable guarantees is an open problem. We define a strong adversarial model for the Learned Bloom Filter. Our adversarial model extends an existing adversarial model designed for the Classical (i.e. not "Learned") Bloom Filter by prior work and considers computationally bounded adversaries that run in probabilistic polynomial time (PPT). Using our model, we construct an adversary-resilient variant of the Learned Bloom Filter called the Downtown Bodega Filter. We show that: if pseudo-random permutations exist, then an Adversary Resilient Learned Bloom Filter may be constructed with $2\lambda$ extra bits of memory and at most one extra pseudo-random permutation in the critical path. We construct a hybrid adversarial model for the case where a fraction of the query workload is chosen by an adversary. We show realistic scenarios where using the Downtown Bodega Filter gives better performance guarantees compared to alternative approaches in this hybrid model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06556v4</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Allison Bishop, Hayder Tirmazi</dc:creator>
    </item>
    <item>
      <title>An Algorithmic Approach to Finding Degree-Doubling Nodes in Oriented Graphs</title>
      <link>https://arxiv.org/abs/2501.00614</link>
      <description>arXiv:2501.00614v4 Announce Type: replace-cross 
Abstract: Seymour's Second Neighborhood Conjecture asserts that in the square of any oriented graph, there exists a node whose out-degree at least doubles. This paper presents a definitive proof of the conjecture by introducing the GLOVER (Graph Level Order) data structure, which facilitates a systematic partitioning of neighborhoods and an analysis of degree-doubling conditions. By leveraging this structure, we construct a decreasing sequence of subsets that establish a well-ordering of nodes, ensuring that no counterexample can exist. This approach not only confirms the conjecture for all oriented graphs but also provides a novel framework for analyzing degrees and arcs in complex networks. The findings have implications for theoretical graph studies and practical applications in network optimization and algorithm design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00614v4</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Fri, 10 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Charles Glover</dc:creator>
    </item>
  </channel>
</rss>
