<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 24 Apr 2025 04:00:43 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Maximum Information Extraction From Noisy Data Via Shannon Entropy Minimization</title>
      <link>https://arxiv.org/abs/2504.12990</link>
      <description>arXiv:2504.12990v4 Announce Type: replace 
Abstract: Granting maximum information extraction in the analysis of noisy data is non-trivial. We introduce a general, data-driven approach that employs Shannon entropy as a transferable metric to quantify the maximum information extractable from noisy data via their clustering into statistically-relevant micro-domains. We demonstrate the method's efficiency by analyzing, as a first example, time-series data extracted from molecular dynamics simulations of water and ice coexisting at the solid/liquid transition temperature. The method allows quantifying the information contained in the data distributions (time-independent component) and the additional information gain attainable by analyzing data as time-series (i.e., accounting for the information contained in data time-correlations). A second test case shows how the MInE approach is also highly effective for high-dimensional datasets, providing clear demonstrations of how, e.g., considering components/data that are little informative, but noisy, may be not only useless but even detrimental to maximum information extraction. This provides a general and robust parameter-free approach and quantitative metrics for data-analysis, and for the study of any type of system from its data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12990v4</guid>
      <category>physics.data-an</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matteo Becchi (Politecnico di Torino, Dipartimento di Scienze Applicate e Tecnologia), Giovanni Maria Pavan (Politecnico di Torino, Dipartimento di Scienze Applicate e Tecnologia)</dc:creator>
    </item>
    <item>
      <title>Constrained composite Bayesian optimization for rational synthesis of polymeric particles</title>
      <link>https://arxiv.org/abs/2411.10471</link>
      <description>arXiv:2411.10471v2 Announce Type: replace-cross 
Abstract: Polymeric nano- and micro-scale particles have critical roles in tackling critical healthcare and energy challenges with their miniature characteristics. However, tailoring their synthesis process to meet specific design targets has traditionally depended on domain expertise and costly trial-and-errors. Recently, modeling strategies, particularly Bayesian optimization (BO), have been proposed to aid materials discovery for maximized/minimized properties. Coming from practical demands, this study for the first time integrates constrained and composite Bayesian optimization (CCBO) to perform efficient target value optimization under black-box feasibility constraints and limited data for laboratory experimentation. Using a synthetic problem that simulates electrospraying, a model nanomanufacturing process, CCBO strategically avoided infeasible conditions and efficiently optimized particle production towards predefined size targets, surpassing standard BO pipelines and providing decisions comparable to human experts. Further laboratory experiments validated CCBO capability to guide the rational synthesis of poly(lactic-co-glycolic acid) (PLGA) particles with diameters of 300 nm and 3.0 $\mu$m via electrospraying. With minimal initial data and unknown experiment constraints, CCBO reached the design targets within 4 iterations. Overall, the CCBO approach presents a versatile and holistic optimization paradigm for next-generation target-driven particle synthesis empowered by artificial intelligence (AI).</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10471v2</guid>
      <category>cs.LG</category>
      <category>cond-mat.soft</category>
      <category>physics.data-an</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fanjin Wang, Maryam Parhizkar, Anthony Harker, Mohan Edirisinghe</dc:creator>
    </item>
  </channel>
</rss>
