<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 17 Jul 2024 01:51:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 16 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>UQE: A Query Engine for Unstructured Databases</title>
      <link>https://arxiv.org/abs/2407.09522</link>
      <description>arXiv:2407.09522v1 Announce Type: new 
Abstract: Analytics on structured data is a mature field with many successful methods. However, most real world data exists in unstructured form, such as images and conversations. We investigate the potential of Large Language Models (LLMs) to enable unstructured data analytics. In particular, we propose a new Universal Query Engine (UQE) that directly interrogates and draws insights from unstructured data collections. This engine accepts queries in a Universal Query Language (UQL), a dialect of SQL that provides full natural language flexibility in specifying conditions and operators. The new engine leverages the ability of LLMs to conduct analysis of unstructured data, while also allowing us to exploit advances in sampling and optimization techniques to achieve efficient and accurate query execution. In addition, we borrow techniques from classical compiler theory to better orchestrate the workflow between sampling methods and foundation model calls. We demonstrate the efficiency of UQE on data analytics across different modalities, including images, dialogs and reviews, across a range of useful query types, including conditional aggregation, semantic retrieval and abstraction aggregation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09522v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hanjun Dai, Bethany Yixin Wang, Xingchen Wan, Bo Dai, Sherry Yang, Azade Nova, Pengcheng Yin, Phitchaya Mangpo Phothilimthana, Charles Sutton, Dale Schuurmans</dc:creator>
    </item>
    <item>
      <title>Implementing the draft Graph Query Language Standard</title>
      <link>https://arxiv.org/abs/2407.09566</link>
      <description>arXiv:2407.09566v1 Announce Type: new 
Abstract: The International Standards Organization (ISO) is developing a new standard for Graph Query Language, with a particular focus on graph patterns with repeating paths. The Linked Database Benchmark Council (LDBC) has developed benchmarks to test proposed implementations. Their Financial Benchmark includes a novel requirement for truncation of results. This paper presents an open-source implementation of the benchmark workloads and truncation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09566v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:journal_reference>IARIA, 2024. ISBN: 978-1-68558-138-1</arxiv:journal_reference>
      <dc:creator>Malcolm Crowe, Fritz Laux</dc:creator>
    </item>
    <item>
      <title>Statistical Validation of Column Matching in the Database Schema Evolution of the Brazilian Public School Census</title>
      <link>https://arxiv.org/abs/2407.09885</link>
      <description>arXiv:2407.09885v1 Announce Type: new 
Abstract: Publicly available datasets are subject to new versions, with each new version potentially reflecting changes to the data. These changes may involve adding or removing attributes, changing data types, and modifying values or their semantics. Integrating these datasets into a database poses a significant challenge: how to keep track of the evolving database schema while incorporating different versions of the data sources? This paper presents a statistical methodology to validate the integration of 12 years of open-access datasets from Brazil's School Census, with a new version of the datasets released annually by the Brazilian Ministry of Education (MEC). We employ various statistical tests to find matching attributes between datasets from a specific year and their potential equivalents in datasets from later years. The results show that by using the Kolmogorov-Smirnov test we can successfully match columns from different dataset versions in about 90% of cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09885v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muriki G. Yamanaka, Diogo H. de Almeida, Paulo R. Lisboa de Almeida, Simone Dominico, Leticia M. Peres, Marcos S. Sunye, Eduardo C. de Almeida</dc:creator>
    </item>
    <item>
      <title>A novel multi-threaded web crawling model</title>
      <link>https://arxiv.org/abs/2407.10440</link>
      <description>arXiv:2407.10440v1 Announce Type: new 
Abstract: This paper proposes a novel model for web crawling suitable for large-scale web data acquisition. This model first divides web data into several sub-data, with each sub-data corresponding to a thread task. In each thread task, web crawling tasks are concurrently executed, and the crawled data are stored in a buffer queue, awaiting further parsing. The parsing process is also divided into several threads. By establishing the model and continuously conducting crawler tests, it is found that this model is significantly optimized compared to single-threaded approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10440v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weijie. Jiang</dc:creator>
    </item>
    <item>
      <title>Intelligent Urban Traffic Management via Semantic Interoperability across Multiple Heterogeneous Mobility Data Sources</title>
      <link>https://arxiv.org/abs/2407.10539</link>
      <description>arXiv:2407.10539v1 Announce Type: new 
Abstract: The integrated exploitation of data sources in the mobility domain is key to providing added-value services to passengers, transport companies and authorities. Indeed, multiple stakeholders operate and maintain different kinds of data but several interoperability issues limit their effective usage. In this paper, we present an architecture enabled by Semantic Web technologies to overcome such issues and facilitate the development of an integrated solution for mobility stakeholders. The proposed solution is composed of different components that address challenges for enabling data interoperability, from the findability of data sources to their integrated consumption adopting standardised data formats. We report on the implementation and validation in four European cities of the TANGENT solution enabling data-driven tools for the dynamic management of multimodal traffic. Finally, we discuss the feedback received by users testing the solution and the lessons learnt during its development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10539v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mario Scrocca, Marco Grassi, Marco Comerio, Valentina Anita Carriero, Tiago Delgado Dias, Ana Vieira Da Silva, Irene Celino</dc:creator>
    </item>
    <item>
      <title>Semantic Units: Increasing Expressivity and Simplicity of Formal Representations of Data and Knowledge in Knowledge Graphs</title>
      <link>https://arxiv.org/abs/2407.10720</link>
      <description>arXiv:2407.10720v1 Announce Type: new 
Abstract: Knowledge graphs and ontologies are becoming increasingly vital as they align with the FAIR Guiding Principles (Findable, Accessible, Interoperable, Reusable). We address eleven challenges that may impede the full realization of the potential of FAIR knowledge graphs, as conventional solutions are perceived to be overly complex and lacking in cognitive interoperability. We extend the concept of "semantic units" as a conceptual solution by adding further subcategories. Semantic units structure a knowledge graph into identifiable and semantically meaningful subgraphs, with each subgraph being represented by a resource that instantiates a semantic unit class. We introduce some-instance, most-instances, every-instance, and all-instances resources as new types of representational entities in addition to named-individual, class, and property resources. We combine these new resource types with the concept of semantic units and introduce new subcategories of statement units and semantically meaningful collections of statement units (i.e., compound units) that provide solutions to the eleven challenges. These include, for instance, schemes for modelling assertional, contingent, prototypical, and universal statements, including class axioms, as well as absence statements, negations, and cardinality restrictions. The schemes are alternatives to existing OWL-based modelling schemes, and we provide corresponding representations for them that do not involve blank nodes. With question units we also introduce a way of representing questions in a knowledge graph that can be made readily executable as graph queries. We also provide schemes for directive statements, directive conditional statements, and logical arguments. We argue that semantic units provide a framework that increases the overall expressivity and cognitive interoperability of knowledge graphs compared to conventional OWL-based solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10720v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lars Vogt</dc:creator>
    </item>
    <item>
      <title>Application of cloud computing platform in industrial big data processing</title>
      <link>https://arxiv.org/abs/2407.09491</link>
      <description>arXiv:2407.09491v1 Announce Type: cross 
Abstract: With the rapid growth and increasing complexity of industrial big data, traditional data processing methods are facing many challenges. This article takes an in-depth look at the application of cloud computing technology in industrial big data processing and explores its potential impact on improving data processing efficiency, security, and cost-effectiveness. The article first reviews the basic principles and key characteristics of cloud computing technology, and then analyzes the characteristics and processing requirements of industrial big data. In particular, this study focuses on the application of cloud computing in real-time data processing, predictive maintenance, and optimization, and demonstrates its practical effects through case studies. At the same time, this article also discusses the main challenges encountered during the implementation process, such as data security, privacy protection, performance and scalability issues, and proposes corresponding solution strategies. Finally, this article looks forward to the future trends of the integration of cloud computing and industrial big data, as well as the application prospects of emerging technologies such as artificial intelligence and machine learning in this field. The results of this study not only provide practical guidance for cloud computing applications in the industry, but also provide a basis for further research in academia.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09491v1</guid>
      <category>cs.DC</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziyan Yao</dc:creator>
    </item>
    <item>
      <title>Protecting Data Buyer Privacy in Data Markets</title>
      <link>https://arxiv.org/abs/2407.09771</link>
      <description>arXiv:2407.09771v1 Announce Type: cross 
Abstract: Data markets serve as crucial platforms facilitating data discovery, exchange, sharing, and integration among data users and providers. However, the paramount concern of privacy has predominantly centered on protecting privacy of data owners and third parties, neglecting the challenges associated with protecting the privacy of data buyers. In this article, we address this gap by modeling the intricacies of data buyer privacy protection and investigating the delicate balance between privacy and purchase cost. Through comprehensive experimentation, our results yield valuable insights, shedding light on the efficacy and efficiency of our proposed approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09771v1</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Minxing Zhang, Jian Pei</dc:creator>
    </item>
    <item>
      <title>General algorithm of assigning raster features to vector maps at any resolution or scale</title>
      <link>https://arxiv.org/abs/2407.10599</link>
      <description>arXiv:2407.10599v1 Announce Type: cross 
Abstract: The fusion of multi-source data is essential for a comprehensive analysis of geographic applications. Due to distinct data structures, the fusion process tends to encounter technical difficulties in terms of preservation of the intactness of each source data. Furthermore, a lack of generalized methods is a problem when the method is expected to be applicable in multiple resolutions, sizes, or scales of raster and vector data, to what is being processed. In this study, we propose a general algorithm of assigning features from raster data (concentrations of air pollutants) to vector components (roads represented by edges) in city maps through the iterative construction of virtual layers to expand geolocation from a city centre to boundaries in a 2D projected map. The construction follows the rule of perfect squares with a slight difference depending on the oddness or evenness of the ratio of city size to raster resolution. We demonstrate the algorithm by applying it to assign accurate PM$_{2.5}$ and NO$_{2}$ concentrations to roads in 1692 cities globally for a potential graph-based pollution analysis. This method could pave the way for agile studies on urgent climate issues by providing a generic and efficient method to accurately fuse multiple datasets of varying scales and compositions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10599v1</guid>
      <category>cs.IR</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan Xu, Mark Stevenson, Kerry A. Nice, Sachith Seneviratne</dc:creator>
    </item>
    <item>
      <title>Innovation Resistance Theory in Action: Unveiling Barriers to Open Government Data Adoption by Public Organizations to Unlock Open Data Innovation</title>
      <link>https://arxiv.org/abs/2407.10883</link>
      <description>arXiv:2407.10883v1 Announce Type: cross 
Abstract: Open Government Data (OGD) plays a pivotal role in fostering data-driven innovation and sustainability across various sectors. Despite its potential, many public organizations are reluctant to share their data openly. While existing research has explored factors impacting the public organizations intention to share OGD, there is a paucity of research applying theoretical models to investigate the resistance by public organizations to making government data publicly available. This study addresses the gap by developing an Innovation Resistance Theory (IRT) model tailored to OGD that allows identifying predictors of resistance among public agencies. We develop an initial model based on literature and refine it through interviews with 21 public agencies across six countries. The final model describes 39 barriers related to usage, value, risks, tradition, and image. The findings contribute to the literature by adapting IRT to the context of OGD, an area where its application has been notably limited. As such, this study addresses the growing demand for novel theoretical frameworks to examine OGD adoption barriers. Practical insights are provided to support policymakers in creating data ecosystems that encourage data openness and address challenges in OGD adoption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.10883v1</guid>
      <category>cs.CY</category>
      <category>cs.DB</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anastasija Nikiforova, Antoine Clarinval, Anneke Zuiderwijk, Daniel Rudmark, Petar Milic, Katrin Rajam\"ae-Soosaar</dc:creator>
    </item>
    <item>
      <title>Spatialyze: A Geospatial Video Analytics System with Spatial-Aware Optimizations</title>
      <link>https://arxiv.org/abs/2308.03276</link>
      <description>arXiv:2308.03276v5 Announce Type: replace 
Abstract: Videos that are shot using commodity hardware such as phones and surveillance cameras record various metadata such as time and location. We encounter such geospatial videos on a daily basis and such videos have been growing in volume significantly. Yet, we do not have data management systems that allow users to interact with such data effectively.
  In this paper, we describe Spatialyze, a new framework for end-to-end querying of geospatial videos. Spatialyze comes with a domain-specific language where users can construct geospatial video analytic workflows using a 3-step, declarative, build-filter-observe paradigm. Internally, Spatialyze leverages the declarative nature of such workflows, the temporal-spatial metadata stored with videos, and physical behavior of real-world objects to optimize the execution of workflows. Our results using real-world videos and workflows show that Spatialyze can reduce execution time by up to 5.3x, while maintaining up to 97.1% accuracy compared to unoptimized execution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03276v5</guid>
      <category>cs.DB</category>
      <category>cs.CV</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.14778/3665844.3665846</arxiv:DOI>
      <arxiv:journal_reference>Proc. VLDB Endow. 17 (2024) 2136-2148</arxiv:journal_reference>
      <dc:creator>Chanwut Kittivorawong, Yongming Ge, Yousef Helal, Alvin Cheung</dc:creator>
    </item>
    <item>
      <title>Differentially Private Stream Processing at Scale</title>
      <link>https://arxiv.org/abs/2303.18086</link>
      <description>arXiv:2303.18086v3 Announce Type: replace-cross 
Abstract: We design, to the best of our knowledge, the first differentially private (DP) stream aggregation processing system at scale. Our system -- Differential Privacy SQL Pipelines (DP-SQLP) -- is built using a streaming framework similar to Spark streaming, and is built on top of the Spanner database and the F1 query engine from Google.
  Towards designing DP-SQLP we make both algorithmic and systemic advances, namely, we (i) design a novel (user-level) DP key selection algorithm that can operate on an unbounded set of possible keys, and can scale to one billion keys that users have contributed, (ii) design a preemptive execution scheme for DP key selection that avoids enumerating all the keys at each triggering time, and (iii) use algorithmic techniques from DP continual observation to release a continual DP histogram of user contributions to different keys over the stream length. We empirically demonstrate the efficacy by obtaining at least $16\times$ reduction in error over meaningful baselines we consider. We implemented a streaming differentially private user impressions for Google Shopping with DP-SQLP. The streaming DP algorithms are further applied to Google Trends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.18086v3</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bing Zhang, Vadym Doroshenko, Peter Kairouz, Thomas Steinke, Abhradeep Thakurta, Ziyin Ma, Eidan Cohen, Himani Apte, Jodi Spacek</dc:creator>
    </item>
  </channel>
</rss>
