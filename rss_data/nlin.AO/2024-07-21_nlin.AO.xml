<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>nlin.AO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/nlin.AO</link>
    <description>nlin.AO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/nlin.AO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 22 Jul 2024 04:07:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 22 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Higher-order triadic percolation on random hypergraphs</title>
      <link>https://arxiv.org/abs/2407.14213</link>
      <description>arXiv:2407.14213v1 Announce Type: new 
Abstract: In this work, we propose a comprehensive theoretical framework combining percolation theory with nonlinear dynamics in order to study hypergraphs with a time-varying giant component. We consider in particular hypergraphs with higher-order triadic interactions that can upregulate or downregulate the hyperedges. Triadic interactions are a general type of signed regulatory interaction that occurs when a third node regulates the interaction between two other nodes. For example, in brain networks, the glia can facilitate or inhibit synaptic interactions between neurons. However, the regulatory interactions may not only occur between regulator nodes and pairwise interactions but also between regulator nodes and higher-order interactions (hyperedges), leading to higher-order triadic interactions. For instance, in biochemical reaction networks, the enzymes regulate the reactions involving multiple reactants. Here we propose and investigate higher-order triadic percolation on hypergraphs showing that the giant component can have a non-trivial dynamics. Specifically, we demonstrate that, under suitable conditions, the order parameter of this percolation problem, i.e., the fraction of nodes in the giant component, undergoes a route to chaos in the universality class of the logistic map. In hierarchical higher-order triadic percolation, we extend this paradigm in order to treat hierarchically nested triadic interactions demonstrating the non-trivial effect of their increased combinatorial complexity on the critical phenomena and the dynamical properties of the process. Finally, we consider other generalizations of the model studying the effect of considering interdependencies and node regulation instead of hyperedge regulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14213v1</guid>
      <category>nlin.AO</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanlin Sun, Ginestra Bianconi</dc:creator>
    </item>
    <item>
      <title>Coprime networks of the composite numbers: pseudo-randomness and synchronizability</title>
      <link>https://arxiv.org/abs/2407.14149</link>
      <description>arXiv:2407.14149v1 Announce Type: cross 
Abstract: In this paper, we propose a network whose nodes are labeled by the composite numbers and two nodes are connected by an undirected link if they are relatively prime to each other. As the size of the network increases, the network will be connected whenever the largest possible node index $n\geq 49$. To investigate how the nodes are connected, we analytically describe that the link density saturates to $6/\pi^2$, whereas the average degree increases linearly with slope $6/\pi^2$ with the size of the network. To investigate how the neighbors of the nodes are connected to each other, we find the shortest path length will be at most 3 for $49\leq n\leq 288$ and it is at most 2 for $n\geq 289$. We also derive an analytic expression for the local clustering coefficients of the nodes, which quantifies how close the neighbors of a node to form a triangle. We also provide an expression for the number of $r$-length labeled cycles, which indicates the existence of a cycle of length at most $O(\log n)$. Finally, we show that this graph sequence is actually a sequence of weakly pseudo-random graphs. We numerically verify our observed analytical results. As a possible application, we have observed less synchronizability (the ratio of the largest and smallest positive eigenvalue of the Laplacian matrix is high) as compared to Erd\H{o}s-R\'{e}nyi random network and Barab\'{a}si-Albert network. This unusual observation is consistent with the prolonged transient behaviors of ecological and predator-prey networks which can easily avoid the global synchronization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.14149v1</guid>
      <category>math.CO</category>
      <category>cs.DM</category>
      <category>cs.SI</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.dam.2024.04.024</arxiv:DOI>
      <arxiv:journal_reference>Discrete Applied Mathematics, 355(2024)96</arxiv:journal_reference>
      <dc:creator>Md Rahil Miraj, Dibakar Ghosh, Chittaranjan Hens</dc:creator>
    </item>
    <item>
      <title>Temporal Complexity of a Hopfield-Type Neural Model in Random and Scale-Free Graphs</title>
      <link>https://arxiv.org/abs/2406.12895</link>
      <description>arXiv:2406.12895v2 Announce Type: replace-cross 
Abstract: The Hopfield network model and its generalizations were introduced as a model of associative, or content-addressable, memory. They were widely investigated both as a unsupervised learning method in artificial intelligence and as a model of biological neural dynamics in computational neuroscience. The complexity features of biological neural networks are attracting the interest of scientific community since the last two decades. More recently, concepts and tools borrowed from complex network theory were applied to artificial neural networks and learning, thus focusing on the topological aspects. However, the temporal structure is also a crucial property displayed by biological neural networks and investigated in the framework of systems displaying complex intermittency. The Intermittency-Driven Complexity (IDC) approach indeed focuses on the metastability of self-organized states, whose signature is a power-decay in the inter-event time distribution or a scaling behavior in the related event-driven diffusion processes. The investigation of IDC in neural dynamics and its relationship with network topology is still in its early stages. In this work we present the preliminary results of a IDC analysis carried out on a bio-inspired Hopfield-type neural network comparing two different connectivities, i.e., scale-free vs. random network topology. We found that random networks can trigger complexity features similar to that of scale-free networks, even if with some differences and for different parameter values, in particular for different noise levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12895v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.NA</category>
      <category>nlin.AO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Marco Cafiso, Paolo Paradisi</dc:creator>
    </item>
  </channel>
</rss>
