<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 May 2024 04:00:20 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Game theory in the case of a geopolitical operation between two persons</title>
      <link>https://arxiv.org/abs/2405.10381</link>
      <description>arXiv:2405.10381v1 Announce Type: new 
Abstract: This article explores the interaction of two agents during a geopolitical operation. Collaborative work is considered, rather than being done alone. However, each agent has the goal of maximizing personal net profit. We will have 3 different situations depending on the order of the players moves, in each of which we will present the game in both expanded and normal form. In each of them we find optimal strategies for both players and possible Nash equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10381v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>O. A. Malafeyev, V. Vekovtsev</dc:creator>
    </item>
    <item>
      <title>A Reliability Theory of Compromise Decisions for Large-Scale Stochastic Programs</title>
      <link>https://arxiv.org/abs/2405.10414</link>
      <description>arXiv:2405.10414v1 Announce Type: new 
Abstract: Stochastic programming models can lead to very large-scale optimization problems for which it may be impossible to enumerate all possible scenarios. In such cases, one adopts a sampling-based solution methodology in which case the reliability of the resulting decisions may be suspect. For such instances, it is advisable to adopt methodologies that promote variance reduction. One such approach goes under a framework known as "compromise decision", which requires multiple replications of the solution procedure. This paper studies the reliability of stochastic programming solutions resulting from the "compromise decision" process. This process is characterized by minimizing an aggregation of objective function approximations across replications, presumably conducted in parallel. We refer to the post-parallel-processing problem as the problem of "compromise decision". We quantify the reliability of compromise decisions by estimating the expectation and variance of the "pessimistic distance" of sampled instances from the set of true optimal decisions. Such pessimistic distance is defined as an estimate of the largest possible distance of the solution of the sampled instance from the "true" optimal solution set. The Rademacher average of instances is used to bound the sample complexity of the compromise decision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10414v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shuotao Diao, Suvrajeet Sen</dc:creator>
    </item>
    <item>
      <title>Optimization-Aided Construction of Multivariate Chebyshev Polynomials</title>
      <link>https://arxiv.org/abs/2405.10438</link>
      <description>arXiv:2405.10438v1 Announce Type: new 
Abstract: This article is concerned with an extension of univariate Chebyshev polynomials of the first kind to the multivariate setting, where one chases best approximants to specific monomials by polynomials of lower degree relative to the uniform norm. Exploiting the Moment-SOS hierarchy, we devise a versatile semidefinite-programming-based procedure to compute such best approximants, as well as associated signatures. Applying this procedure in three variables leads to the values of best approximation errors for all mononials up to degree six on the euclidean ball, the simplex, and the cross-polytope. Furthermore, inspired by numerical experiments, we obtain explicit expressions for Chebyshev polynomials in two cases unresolved before, namely for the monomial $x_1^2 x_2^2 x_3$ on the euclidean ball and for the monomial $x_1^2 x_2 x_3$ on the simplex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10438v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mareike Dressler, Simon Foucart, Etienne de Klerk, Mioara Joldes, Jean Bernard Lasserre, Yuan Xu</dc:creator>
    </item>
    <item>
      <title>A Branch and Bound Algorithm for Multiobjective Optimization Problems Using General Ordering Cones</title>
      <link>https://arxiv.org/abs/2405.10500</link>
      <description>arXiv:2405.10500v1 Announce Type: new 
Abstract: Many existing branch and bound algorithms for multiobjective optimization problems require a significant computational cost to approximate the entire Pareto optimal solution set. In this paper, we propose a new branch and bound algorithm that approximates a part of the Pareto optimal solution set by introducing the additional preference information in the form of ordering cones. The basic idea is to replace the Pareto dominance induced by the nonnegative orthant with the cone dominance induced by a larger ordering cone in the discarding test. In particular, we consider both polyhedral and non-polyhedral cones, and propose the corresponding cone dominance-based discarding tests, respectively. In this way, the subboxes that do not contain efficient solutions with respect to the ordering cone will be removed, even though they may contain Pareto optimal solutions. We prove the global convergence of the proposed algorithm. Finally, the proposed algorithm is applied to a number of test instances as well as to 2- to 5-objective real-world constrained problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10500v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Weitian Wu, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Optimal Control of Two-Phase Membrane Problem</title>
      <link>https://arxiv.org/abs/2405.10704</link>
      <description>arXiv:2405.10704v1 Announce Type: new 
Abstract: We consider an optimal control problem where the state is governed by a free boundary problem called the two-phase membrane problem and the control appears in the coefficients of the characteristic function of the positivity and negativity parts of the solution. Our investigation focuses on various properties associated with the control-to-state map. Due to the non-differentiability of this map, we regularize the state equation. The existence, uniqueness, and characterization of the optimal pairs are established.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10704v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Farid Bozorgnia, Vyacheslav Kungurtsev</dc:creator>
    </item>
    <item>
      <title>Variance-reduction for Variational Inequality Problems with Bregman Distance Function</title>
      <link>https://arxiv.org/abs/2405.10735</link>
      <description>arXiv:2405.10735v1 Announce Type: new 
Abstract: In this paper, we address variational inequalities (VI) with a finite-sum structure. We introduce a novel single-loop stochastic variance-reduced algorithm, incorporating the Bregman distance function, and establish an optimal convergence guarantee under a monotone setting. Additionally, we explore a structured class of non-monotone problems that exhibit weak Minty solutions, and analyze the complexity of our proposed method, highlighting a significant improvement over existing approaches. Numerical experiments are presented to demonstrate the performance of our algorithm compared to state-of-the-art methods</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10735v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeinab Alizadeh, Erfan Yazdandoost Hamedani, Afrooz Jalilzadeh</dc:creator>
    </item>
    <item>
      <title>Stable Phase Retrieval with Mirror Descent</title>
      <link>https://arxiv.org/abs/2405.10754</link>
      <description>arXiv:2405.10754v1 Announce Type: new 
Abstract: In this paper, we aim to reconstruct an n-dimensional real vector from m phaseless measurements corrupted by an additive noise. We extend the noiseless framework developed in [15], based on mirror descent (or Bregman gradient descent), to deal with noisy measurements and prove that the procedure is stable to (small enough) additive noise. In the deterministic case, we show that mirror descent converges to a critical point of the phase retrieval problem, and if the algorithm is well initialized and the noise is small enough, the critical point is near the true vector up to a global sign change. When the measurements are i.i.d Gaussian and the signal-to-noise ratio is large enough, we provide global convergence guarantees that ensure that with high probability, mirror descent converges to a global minimizer near the true vector (up to a global sign change), as soon as the number of measurements m is large enough. The sample complexity bound can be improved if a spectral method is used to provide a good initial guess. We complement our theoretical study with several numerical results showing that mirror descent is both a computationally and statistically efficient scheme to solve the phase retrieval problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10754v1</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jean-Jacques Godeme, Jalal Fadili, Claude Amra, Myriam Zerrad</dc:creator>
    </item>
    <item>
      <title>A Functional Model Method for Nonconvex Nonsmooth Conditional Stochastic Optimization</title>
      <link>https://arxiv.org/abs/2405.10815</link>
      <description>arXiv:2405.10815v1 Announce Type: new 
Abstract: We consider stochastic optimization problems involving an expected value of a nonlinear function of a base random vector and a conditional expectation of another function depending on the base random vector, a dependent random vector, and the decision variables. We call such problems conditional stochastic optimization problems. They arise in many applications, such as uplift modeling, reinforcement learning, and contextual optimization. We propose a specialized single time-scale stochastic method for nonconvex constrained conditional stochastic optimization problems with a Lipschitz smooth outer function and a generalized differentiable inner function. In the method, we approximate the inner conditional expectation with a rich parametric model whose mean squared error satisfies a stochastic version of a {\L}ojasiewicz condition. The model is used by an inner learning algorithm. The main feature of our approach is that unbiased stochastic estimates of the directions used by the method can be generated with one observation from the joint distribution per iteration, which makes it applicable to real-time learning. The directions, however, are not gradients or subgradients of any overall objective function. We prove the convergence of the method with probability one, using the method of differential inclusions and a specially designed Lyapunov function, involving a stochastic generalization of the Bregman distance. Finally, a numerical illustration demonstrates the viability of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10815v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrzej Ruszczy\'nski, Shangzhe Yang</dc:creator>
    </item>
    <item>
      <title>Diagnosing and Decoupling the Degradation Mechanisms in Lithium Ion Cells: An Estimation Approach</title>
      <link>https://arxiv.org/abs/2405.10857</link>
      <description>arXiv:2405.10857v1 Announce Type: new 
Abstract: Understanding battery degradation in electric vehicles (EVs) under real-world conditions remains a critical yet under-explored area of research. Central to this investigation is the challenge of estimating the specific degradation modes in aged cells with no available information on usage history, bypassing the conventional yet invasive method of tear-down tests. Using an electrochemical model, this study pioneers a methodology to decouple and isolate the aging mechanisms in batteries sourced from EVs with varying mileages. A robust correlation is established between the model parameters and distinct degradation processes, enabling the diagnosis and estimation of each mechanism's impact on the battery's parameters. This paper sheds light on battery degradation in real-world scenarios and demonstrates the feasibility of their identification, isolation, and approximate quantification of their effects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10857v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raja Abhishek Appana, Faissal El Idrissi, Prashanth Ramesh, Marcello Canova, Chun Yong Kang, Kimoon Um</dc:creator>
    </item>
    <item>
      <title>Efficient Line Search Method Based on Regression and Uncertainty Quantification</title>
      <link>https://arxiv.org/abs/2405.10897</link>
      <description>arXiv:2405.10897v1 Announce Type: new 
Abstract: Unconstrained optimization problems are typically solved using iterative methods, which often depend on line search techniques to determine optimal step lengths in each iteration. This paper introduces a novel line search approach. Traditional line search methods, aimed at determining optimal step lengths, often discard valuable data from the search process and focus on refining step length intervals. This paper proposes a more efficient method using Bayesian optimization, which utilizes all available data points, i.e., function values and gradients, to guide the search towards a potential global minimum. This new approach more effectively explores the search space, leading to better solution quality. It is also easy to implement and integrate into existing frameworks. Tested on the challenging CUTEst test set, it demonstrates superior performance compared to existing state-of-the-art methods, solving more problems to optimality with equivalent resource usage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10897v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>S\"oren Laue, Tomislav Prusina</dc:creator>
    </item>
    <item>
      <title>Kernel Expansions for High-Dimensional Mean-Field Control with Non-local Interactions</title>
      <link>https://arxiv.org/abs/2405.10922</link>
      <description>arXiv:2405.10922v1 Announce Type: new 
Abstract: Mean-field control (MFC) problems aim to find the optimal policy to control massive populations of interacting agents. These problems are crucial in areas such as economics, physics, and biology. We consider the non-local setting, where the interactions between agents are governed by a suitable kernel. For $N$ agents, the interaction cost has $\mathcal{O}(N^2)$ complexity, which can be prohibitively slow to evaluate and differentiate when $N$ is large. To this end, we propose an efficient primal-dual algorithm that utilizes basis expansions of the kernels. The basis expansions reduce the cost of computing the interactions, while the primal-dual methodology decouples the agents at the expense of solving for a moderate number of dual variables. We also demonstrate that our approach can further be structured in a multi-resolution manner, where we estimate optimal dual variables using a moderate $N$ and solve decoupled trajectory optimization problems for large $N$. We illustrate the effectiveness of our method on an optimal control of 5000 interacting quadrotors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10922v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Vidal, Samy Wu Fung, Stanley Osher, Luis Tenorio, Levon Nurbekyan</dc:creator>
    </item>
    <item>
      <title>Efficient model predictive control for nonlinear systems modelled by deep neural networks</title>
      <link>https://arxiv.org/abs/2405.10372</link>
      <description>arXiv:2405.10372v1 Announce Type: cross 
Abstract: This paper presents a model predictive control (MPC) for dynamic systems whose nonlinearity and uncertainty are modelled by deep neural networks (NNs), under input and state constraints. Since the NN output contains a high-order complex nonlinearity of the system state and control input, the MPC problem is nonlinear and challenging to solve for real-time control. This paper proposes two types of methods for solving the MPC problem: the mixed integer programming (MIP) method which produces an exact solution to the nonlinear MPC, and linear relaxation (LR) methods which generally give suboptimal solutions but are much computationally cheaper. Extensive numerical simulation for an inverted pendulum system modelled by ReLU NNs of various sizes is used to demonstrate and compare performance of the MIP and LR methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10372v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jianglin Lan</dc:creator>
    </item>
    <item>
      <title>A note on continuous-time online learning</title>
      <link>https://arxiv.org/abs/2405.10399</link>
      <description>arXiv:2405.10399v1 Announce Type: cross 
Abstract: In online learning, the data is provided in a sequential order, and the goal of the learner is to make online decisions to minimize overall regrets. This note is concerned with continuous-time models and algorithms for several online learning problems: online linear optimization, adversarial bandit, and adversarial linear bandit. For each problem, we extend the discrete-time algorithm to the continuous-time setting and provide a concise proof of the optimal regret bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10399v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lexing Ying</dc:creator>
    </item>
    <item>
      <title>Neural Optimization with Adaptive Heuristics for Intelligent Marketing System</title>
      <link>https://arxiv.org/abs/2405.10490</link>
      <description>arXiv:2405.10490v1 Announce Type: cross 
Abstract: Computational marketing has become increasingly important in today's digital world, facing challenges such as massive heterogeneous data, multi-channel customer journeys, and limited marketing budgets. In this paper, we propose a general framework for marketing AI systems, the Neural Optimization with Adaptive Heuristics (NOAH) framework. NOAH is the first general framework for marketing optimization that considers both to-business (2B) and to-consumer (2C) products, as well as both owned and paid channels. We describe key modules of the NOAH framework, including prediction, optimization, and adaptive heuristics, providing examples for bidding and content optimization. We then detail the successful application of NOAH to LinkedIn's email marketing system, showcasing significant wins over the legacy ranking system. Additionally, we share details and insights that are broadly useful, particularly on: (i) addressing delayed feedback with lifetime value, (ii) performing large-scale linear programming with randomization, (iii) improving retrieval with audience expansion, (iv) reducing signal dilution in targeting tests, and (v) handling zero-inflated heavy-tail metrics in statistical testing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10490v1</guid>
      <category>stat.ME</category>
      <category>cs.AI</category>
      <category>cs.IR</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Changshuai Wei, Benjamin Zelditch, Joyce Chen, Andre Assuncao Silva T Ribeiro, Jingyi Kenneth Tay, Borja Ocejo Elizondo, Keerthi Selvaraj, Aman Gupta, Licurgo Benemann De Almeida</dc:creator>
    </item>
    <item>
      <title>Future Aware Safe Active Learning of Time Varying Systems using Gaussian Processes</title>
      <link>https://arxiv.org/abs/2405.10581</link>
      <description>arXiv:2405.10581v1 Announce Type: cross 
Abstract: Experimental exploration of high-cost systems with safety constraints, common in engineering applications, is a challenging endeavor. Data-driven models offer a promising solution, but acquiring the requisite data remains expensive and is potentially unsafe. Safe active learning techniques prove essential, enabling the learning of high-quality models with minimal expensive data points and high safety. This paper introduces a safe active learning framework tailored for time-varying systems, addressing drift, seasonal changes, and complexities due to dynamic behavior. The proposed Time-aware Integrated Mean Squared Prediction Error (T-IMSPE) method minimizes posterior variance over current and future states, optimizing information gathering also in the time domain. Empirical results highlight T-IMSPE's advantages in model quality through toy and real-world examples. State of the art Gaussian processes are compatible with T-IMSPE. Our theoretical contributions include a clear delineation which Gaussian process kernels, domains, and weighting measures are suitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10581v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Markus Lange-Hegermann, Christoph Zimmer</dc:creator>
    </item>
    <item>
      <title>Distributed Event-Based Learning via ADMM</title>
      <link>https://arxiv.org/abs/2405.10618</link>
      <description>arXiv:2405.10618v1 Announce Type: cross 
Abstract: We consider a distributed learning problem, where agents minimize a global objective function by exchanging information over a network. Our approach has two distinct features: (i) It substantially reduces communication by triggering communication only when necessary, and (ii) it is agnostic to the data-distribution among the different agents. We can therefore guarantee convergence even if the local data-distributions of the agents are arbitrarily distinct. We analyze the convergence rate of the algorithm and derive accelerated convergence rates in a convex setting. We also characterize the effect of communication drops and demonstrate that our algorithm is robust to communication failures. The article concludes by presenting numerical results from a distributed LASSO problem, and distributed learning tasks on MNIST and CIFAR-10 datasets. The experiments underline communication savings of 50% or more due to the event-based communication strategy, show resilience towards heterogeneous data-distributions, and highlight that our approach outperforms common baselines such as FedAvg, FedProx, and FedADMM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10618v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Guner Dilsad Er, Sebastian Trimpe, Michael Muehlebach</dc:creator>
    </item>
    <item>
      <title>Recovery of Sparse Graph Signals</title>
      <link>https://arxiv.org/abs/2405.10649</link>
      <description>arXiv:2405.10649v1 Announce Type: cross 
Abstract: This paper investigates the recovery of a node-domain sparse graph signal from the output of a graph filter. This problem, often referred to as the identification of the source of a diffused sparse graph signal, is seminal in the field of graph signal processing (GSP). Sparse graph signals can be used in the modeling of a variety of real-world applications in networks, such as social, biological, and power systems, and enable various GSP tasks, such as graph signal reconstruction, blind deconvolution, and sampling. In this paper, we assume double sparsity of both the graph signal and the graph topology, as well as a low-order graph filter. We propose three algorithms to reconstruct the support set of the input sparse graph signal from the graph filter output samples, leveraging these assumptions and the generalized information criterion (GIC). First, we describe the graph multiple GIC (GM-GIC) method, which is based on partitioning the dictionary elements (graph filter matrix columns) that capture information on the signal into smaller subsets. Then, the local GICs are computed for each subset and aggregated to make a global decision. Second, inspired by the well-known branch and bound (BNB) approach, we develop the graph-based branch and bound GIC (graph-BNB-GIC), and incorporate a new tractable heuristic bound tailored to the graph and graph filter characteristics. Finally, we propose the graph-based first order correction (GFOC) method, which improves existing sparse recovery methods by iteratively examining potential improvements to the GIC cost function through replacing elements from the estimated support set with elements from their one-hop neighborhood. We conduct simulations that demonstrate that the proposed sparse recovery methods outperform existing methods in terms of support set recovery accuracy, and without a significant computational overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10649v1</guid>
      <category>eess.SP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gal Morgenstern, Tirza Routtenberg</dc:creator>
    </item>
    <item>
      <title>Integer Traffic Assignment Problem: Algorithms and Insights on Random Graphs</title>
      <link>https://arxiv.org/abs/2405.10763</link>
      <description>arXiv:2405.10763v1 Announce Type: cross 
Abstract: Path optimization is a fundamental concern across various real-world scenarios, ranging from traffic congestion issues to efficient data routing over the internet. The Traffic Assignment Problem (TAP) is a classic continuous optimization problem in this field. This study considers the Integer Traffic Assignment Problem (ITAP), a discrete variant of TAP. ITAP involves determining optimal routes for commuters in a city represented by a graph, aiming to minimize congestion while adhering to integer flow constraints on paths. This restriction makes ITAP an NP-hard problem. While conventional TAP prioritizes repulsive interactions to minimize congestion, this work also explores the case of attractive interactions, related to minimizing the number of occupied edges. We present and evaluate multiple algorithms to address ITAP, including a message passing algorithm, a greedy approach, simulated annealing, and relaxation of ITAP to TAP. Inspired by studies of random ensembles in the large-size limit in statistical physics, comparisons between these algorithms are conducted on large sparse random regular graphs with a random set of origin-destination pairs. Our results indicate that while the simplest greedy algorithm performs competitively in the repulsive scenario, in the attractive case the message-passing-based algorithm and simulated annealing demonstrate superiority. We then investigate the relationship between TAP and ITAP in the repulsive case. We find that, as the number of paths increases, the solution of TAP converges toward that of ITAP, and we investigate the speed of this convergence. Depending on the number of paths, our analysis leads us to identify two scaling regimes: in one the average flow per edge is of order one, and in another the number of paths scales quadratically with the size of the graph, in which case the continuous relaxation solves the integer problem closely.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10763v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.DM</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rayan Harfouche, Giovanni Piccioli, Lenka Zdeborov\'a</dc:creator>
    </item>
    <item>
      <title>Submodular Information Selection for Hypothesis Testing with Misclassification Penalties</title>
      <link>https://arxiv.org/abs/2405.10930</link>
      <description>arXiv:2405.10930v1 Announce Type: cross 
Abstract: We consider the problem of selecting an optimal subset of information sources for a hypothesis testing/classification task where the goal is to identify the true state of the world from a finite set of hypotheses, based on finite observation samples from the sources. In order to characterize the learning performance, we propose a misclassification penalty framework, which enables non-uniform treatment of different misclassification errors. In a centralized Bayesian learning setting, we study two variants of the subset selection problem: (i) selecting a minimum cost information set to ensure that the maximum penalty of misclassifying the true hypothesis remains bounded and (ii) selecting an optimal information set under a limited budget to minimize the maximum penalty of misclassifying the true hypothesis. Under mild assumptions, we prove that the objective (or constraints) of these combinatorial optimization problems are weak (or approximate) submodular, and establish high-probability performance guarantees for greedy algorithms. Further, we propose an alternate metric for information set selection which is based on the total penalty of misclassification. We prove that this metric is submodular and establish near-optimal guarantees for the greedy algorithms for both the information set selection problems. Finally, we present numerical simulations to validate our theoretical results over several randomly generated instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10930v1</guid>
      <category>stat.ML</category>
      <category>cs.CC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayanth Bhargav, Mahsa Ghasemi, Shreyas Sundaram</dc:creator>
    </item>
    <item>
      <title>A multigrid solver for PDE-constrained optimization with uncertain inputs</title>
      <link>https://arxiv.org/abs/2302.13680</link>
      <description>arXiv:2302.13680v4 Announce Type: replace 
Abstract: In this manuscript, we present a collective multigrid algorithm to solve efficiently the large saddle-point systems of equations that typically arise in PDE-constrained optimization under uncertainty, and develop a novel convergence analysis of collective smoothers and collective two-level methods. The multigrid algorithm is based on a collective smoother that at each iteration sweeps over the nodes of the computational mesh, and solves a reduced saddle-point system whose size is proportional to the number $N$ of samples used to discretized the probability space. We show that this reduced system can be solved with optimal $O(N)$ complexity.
  The multigrid method is tested both as a stationary method and as a preconditioner for GMRES on three problems: a linear-quadratic problem, possibly with a local or a boundary control, for which the multigrid method is used to solve directly the linear optimality system; a nonsmooth problem with box constraints and $L^1$-norm penalization on the control, in which the multigrid scheme is used as an inner solver within a semismooth Newton iteration; a risk-averse problem with the smoothed CVaR risk measure where the multigrid method is called within a preconditioned Newton iteration. In all cases, the multigrid algorithm exhibits excellent performances and robustness with respect to the parameters of interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.13680v4</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Gabriele Ciaramella, Fabio Nobile, Tommaso Vanzan</dc:creator>
    </item>
    <item>
      <title>Stochastic Reachability of Uncontrolled Systems via Probability Measures: Approximation via Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2304.00598</link>
      <description>arXiv:2304.00598v2 Announce Type: replace 
Abstract: This paper poses a theoretical characterization of the stochastic reachability problem in terms of probability measures, capturing the probability measure of the state of the system that satisfies the reachability specification for all probabilities over a finite horizon. We achieve this by constructing the level sets of the probability measure for all probability values and, since our approach is only for autonomous systems, we can determine the level sets via forward simulations of the system from a point in the state space at some time step in the finite horizon to estimate the reach probability. We devise a training procedure which exploits this forward simulation and employ it to design a deep neural network (DNN) to predict the reach probability provided the current state and time step. We validate the effectiveness of our approach through three examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.00598v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Karthik Sivaramakrishnan, Vignesh Sivaramakrishnan, Rosalyn Alex Devonport, Meeko M. K. Oishi</dc:creator>
    </item>
    <item>
      <title>Stochastic optimal control problems with delays in the state and in the control via viscosity solutions and applications to optimal advertising and optimal investment problems</title>
      <link>https://arxiv.org/abs/2308.14506</link>
      <description>arXiv:2308.14506v2 Announce Type: replace 
Abstract: In this manuscript we consider optimal control problems of stochastic differential equations with delays in the state and in the control. First, we prove an equivalent Markovian reformulation on Hilbert spaces of the state equation. Then, using the dynamic programming approach for infinite-dimensional systems, we prove that the value function is the unique viscosity solution of the infinite-dimensional Hamilton-Jacobi-Bellman equation. We apply these results to problems coming from economics: stochastic optimal advertising problems and stochastic optimal investment problems with time-to-build.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14506v2</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo de Feo</dc:creator>
    </item>
    <item>
      <title>Robust Online Learning over Networks</title>
      <link>https://arxiv.org/abs/2309.00520</link>
      <description>arXiv:2309.00520v2 Announce Type: replace 
Abstract: The recent deployment of multi-agent networks has enabled the distributed solution of learning problems, where agents cooperate to train a global model without sharing their local, private data. This work specifically targets some prevalent challenges inherent to distributed learning: (i) online training, i.e., the local data change over time; (ii) asynchronous agent computations; (iii) unreliable and limited communications; and (iv) inexact local computations. To tackle these challenges, we apply the Distributed Operator Theoretical (DOT) version of the Alternating Direction Method of Multipliers (ADMM), which we call "DOT-ADMM". We prove that if the DOT-ADMM operator is metric subregular, then it converges with a linear rate for a large class of (not necessarily strongly) convex learning problems toward a bounded neighborhood of the optimal time-varying solution, and characterize how such neighborhood depends on (i)-(iv). We first derive an easy-to-verify condition for ensuring the metric subregularity of an operator, followed by tutorial examples on linear and logistic regression problems. We corroborate the theoretical analysis with numerical simulations comparing DOT-ADMM with other state-of-the-art algorithms, showing that only the proposed algorithm exhibits robustness to (i)-(iv).</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.00520v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicola Bastianello, Diego Deplano, Mauro Franceschelli, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Locational Marginal Pricing of Energy in Pipeline Transport of Natural Gas and Hydrogen with Carbon Offset Incentives</title>
      <link>https://arxiv.org/abs/2310.13181</link>
      <description>arXiv:2310.13181v2 Announce Type: replace 
Abstract: We propose an optimization formulation for locational pricing of energy transported through a pipeline network that carries mixtures of natural gas and hydrogen from distributed sources to consumers. The objective includes the economic value provided by the pipeline to consumers of energy and suppliers of natural gas and green hydrogen, as well as incentives to lower carbon emissions by consuming the latter instead of the former. The optimization is subject to the physics of gas flow and mixing in the pipeline network as well as engineering limits. In addition to formulating this mathematical program, we synthesize the Lagrangian and derive analytical expressions for the dual variables. We propose that the dual solution can be used to derive locational marginal prices of natural gas, hydrogen, and energy, as well as the decarbonization premium paid by consumers that receive hydrogen. We derive several properties of solutions obtained using the proposed market mechanism, and demonstrate them using case studies for standard 8-node and 40-node pipeline test networks. Finally, we show that optimization-based analysis of the type proposed here is critical for making sound decisions about economic policy and infrastructure expansion for blending green hydrogen into existing natural gas pipelines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13181v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mo Sodwatana, Saif R. Kazi, Kaarthik Sundar, Adam Brandt, Anatoly Zlotnik</dc:creator>
    </item>
    <item>
      <title>A Sparse Smoothing Newton Method for Solving Discrete Optimal Transport Problems</title>
      <link>https://arxiv.org/abs/2311.06448</link>
      <description>arXiv:2311.06448v2 Announce Type: replace 
Abstract: The discrete optimal transport (OT) problem, which offers an effective computational tool for comparing two discrete probability distributions, has recently attracted much attention and played essential roles in many modern applications. This paper proposes to solve the discrete OT problem by applying a squared smoothing Newton method via the Huber smoothing function for solving the corresponding KKT system directly. The proposed algorithm admits appealing convergence properties and is able to take advantage of the solution sparsity to greatly reduce computational costs. Moreover, the algorithm can be extended to solve problems with similar structures including the Wasserstein barycenter (WB) problem with fixed supports. To verify the practical performance of the proposed method, we conduct extensive numerical experiments to solve a large set of discrete OT and WB benchmark problems. Our numerical results show that the proposed method is efficient compared to state-of-the-art linear programming (LP) solvers. Moreover, the proposed method consumes less memory than existing LP solvers, which demonstrates the potential usage of our algorithm for solving large-scale OT and WB problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.06448v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Di Hou, Ling Liang, Kim-Chuan Toh</dc:creator>
    </item>
    <item>
      <title>Distributed Constrained Combinatorial Optimization leveraging Hypergraph Neural Networks</title>
      <link>https://arxiv.org/abs/2311.09375</link>
      <description>arXiv:2311.09375v2 Announce Type: replace 
Abstract: Scalable addressing of high dimensional constrained combinatorial optimization problems is a challenge that arises in several science and engineering disciplines. Recent work introduced novel application of graph neural networks for solving quadratic-cost combinatorial optimization problems. However, effective utilization of models such as graph neural networks to address general problems with higher order constraints is an unresolved challenge. This paper presents a framework, HypOp, which advances the state of the art for solving combinatorial optimization problems in several aspects: (i) it generalizes the prior results to higher order constrained problems with arbitrary cost functions by leveraging hypergraph neural networks; (ii) enables scalability to larger problems by introducing a new distributed and parallel training architecture; (iii) demonstrates generalizability across different problem formulations by transferring knowledge within the same hypergraph; (iv) substantially boosts the solution accuracy compared with the prior art by suggesting a fine-tuning step using simulated annealing; (v) shows a remarkable progress on numerous benchmark examples, including hypergraph MaxCut, satisfiability, and resource allocation problems, with notable run time improvements using a combination of fine-tuning and distributed training techniques. We showcase the application of HypOp in scientific discovery by solving a hypergraph MaxCut problem on NDC drug-substance hypergraph. Through extensive experimentation on various optimization problems, HypOp demonstrates superiority over existing unsupervised learning-based solvers and generic optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09375v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nasimeh Heydaribeni, Xinrui Zhan, Ruisi Zhang, Tina Eliassi-Rad, Farinaz Koushanfar</dc:creator>
    </item>
    <item>
      <title>Input-to-State Stability of Newton Methods for Generalized Equations in Nonlinear Optimization</title>
      <link>https://arxiv.org/abs/2403.16165</link>
      <description>arXiv:2403.16165v2 Announce Type: replace 
Abstract: We show that Newton methods for generalized equations are input-to-state stable with respect to disturbances such as due to inexact computations. We then use this result to obtain convergence and robustness of a multistep Newton-type method for multivariate generalized equations. We demonstrate the usefulness of the results with other applications to nonlinear optimization. In particular, we provide a new proof for (robust) local convergence of the augmented Lagrangian method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16165v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Torbj{\o}rn Cunis, Ilya Kolmanovsky</dc:creator>
    </item>
    <item>
      <title>Measurized Discounted Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2405.03888</link>
      <description>arXiv:2405.03888v2 Announce Type: replace 
Abstract: In this paper, we build a framework that facilitates the analysis of discounted infinite horizon Markov Decision Processes (MDPs) by visualizing them as deterministic processes where the states are probability measures on the original state space and the actions are stochastic kernels on the original action space. We provide a simple general algebraic approach to lifting any MDP to this space of measures; we call this to measurize the original stochastic MDP. We show that measurized MDPs are in fact a generalization of stochastic MDPs, thus the measurized framework can be deployed without loss of fidelity. Lifting an MDP can be convenient because the measurized framework enables constraints and value function approximations that are not easily available from the standard MDP setting. For instance, one can add restrictions or build approximations based on moments, quantiles, risk measures, etc. Moreover, since the measurized counterpart to any MDP is deterministic, the measurized optimality equations trade the complexity of dealing with the expected value function that appears in the stochastic optimality equations with a more complex state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03888v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Adelman, Alba V. Olivares-Nadal</dc:creator>
    </item>
    <item>
      <title>Secure Set-Based State Estimation for Linear Systems under Adversarial Attacks on Sensors</title>
      <link>https://arxiv.org/abs/2309.05075</link>
      <description>arXiv:2309.05075v2 Announce Type: replace-cross 
Abstract: Set-based state estimation plays a vital role in the safety verification of dynamical systems, which becomes significantly challenging when the system's sensors are susceptible to cyber-attacks. Existing methods often impose limitations on the attacker's capabilities, restricting the number of attacked sensors to be strictly less than half of the total number of sensors. This paper proposes a Secure Set-Based State Estimation (S3E) algorithm that addresses this limitation. The S3E algorithm guarantees that the true system state is contained within the estimated set, provided the initialization set encompasses the true initial state and the system is redundantly observable from the set of uncompromised sensors. The algorithm gives the estimated set as a collection of constrained zonotopes, which can be employed as robust certificates for verifying whether the system adheres to safety constraints. Furthermore, we demonstrate that the estimated set remains unaffected by attack signals of sufficiently large and also establish sufficient conditions for attack detection, identification, and filtering. This compels the attacker to inject only stealthy signals of small magnitude to evade detection, thus preserving the accuracy of the estimated set. When a few number of sensors (less than half) can be compromised, we prove that the estimated set remains bounded by a contracting set that converges to a ball whose radius is solely determined by the noise magnitude and is independent of the attack signals. To address the computational complexity of the algorithm, we offer several strategies for complexity-performance trade-offs. The efficacy of the proposed algorithm is illustrated through its application to a three-story building model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05075v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Umar B. Niazi, Michelle S. Chong, Amr Alanwar, Karl H. Johansson</dc:creator>
    </item>
    <item>
      <title>Convergence of flow-based generative models via proximal gradient descent in Wasserstein space</title>
      <link>https://arxiv.org/abs/2310.17582</link>
      <description>arXiv:2310.17582v2 Announce Type: replace-cross 
Abstract: Flow-based generative models enjoy certain advantages in computing the data generation and the likelihood, and have recently shown competitive empirical performance. Compared to the accumulating theoretical studies on related score-based diffusion models, analysis of flow-based models, which are deterministic in both forward (data-to-noise) and reverse (noise-to-data) directions, remain sparse. In this paper, we provide a theoretical guarantee of generating data distribution by a progressive flow model, the so-called JKO flow model, which implements the Jordan-Kinderleherer-Otto (JKO) scheme in a normalizing flow network. Leveraging the exponential convergence of the proximal gradient descent (GD) in Wasserstein space, we prove the Kullback-Leibler (KL) guarantee of data generation by a JKO flow model to be $O(\varepsilon^2)$ when using $N \lesssim \log (1/\varepsilon)$ many JKO steps ($N$ Residual Blocks in the flow) where $\varepsilon $ is the error in the per-step first-order condition. The assumption on data density is merely a finite second moment, and the theory extends to data distributions without density and when there are inversion errors in the reverse process where we obtain KL-$W_2$ mixed error guarantees. The non-asymptotic convergence rate of the JKO-type $W_2$-proximal GD is proved for a general class of convex objective functionals that includes the KL divergence as a special case, which can be of independent interest. The analysis framework can extend to other first-order Wasserstein optimization schemes applied to flow-based generative models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.17582v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiuyuan Cheng, Jianfeng Lu, Yixin Tan, Yao Xie</dc:creator>
    </item>
    <item>
      <title>Abstract dissipative Hamiltonian differential-algebraic equations are everywhere</title>
      <link>https://arxiv.org/abs/2311.03091</link>
      <description>arXiv:2311.03091v4 Announce Type: replace-cross 
Abstract: In this paper we study the representation of partial differential equations (PDEs) as abstract differential-algebraic equations (DAEs) with dissipative Hamiltonian structure (adHDAEs). We show that these systems not only arise when there are constraints coming from the underlying physics, but many standard PDE models can be seen as an adHDAE on an extended state space. This reflects the fact that models often include closure relations and structural properties. We present a unifying operator theoretic approach to analyze the properties of such operator equations and illustrate this by several applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03091v4</guid>
      <category>math.FA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volker Mehrmann, Hans Zwart</dc:creator>
    </item>
    <item>
      <title>Incentive Design for Eco-driving in Urban Transportation Networks</title>
      <link>https://arxiv.org/abs/2311.03682</link>
      <description>arXiv:2311.03682v2 Announce Type: replace-cross 
Abstract: Eco-driving emerges as a cost-effective and efficient strategy to mitigate greenhouse gas emissions in urban transportation networks. Acknowledging the persuasive influence of incentives in shaping driver behavior, this paper presents the `eco-planner,' a digital platform devised to promote eco-driving practices in urban transportation. At the outset of their trips, users provide the platform with their trip details and travel time preferences, enabling the eco-planner to formulate personalized eco-driving recommendations and corresponding incentives, while adhering to its budgetary constraints. Upon trip completion, incentives are transferred to users who comply with the recommendations and effectively reduce their emissions. By comparing our proposed incentive mechanism with a baseline scheme that offers uniform incentives to all users, we demonstrate that our approach achieves superior emission reductions and increased user compliance with a smaller budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03682v2</guid>
      <category>eess.SY</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Umar B. Niazi, Jung-Hoon Cho, Munther A. Dahleh, Roy Dong, Cathy Wu</dc:creator>
    </item>
    <item>
      <title>Boundary Control for Suppressing Chaotic Response to Dynamic Hydrogen Blending in a Gas Pipeline</title>
      <link>https://arxiv.org/abs/2311.04407</link>
      <description>arXiv:2311.04407v2 Announce Type: replace-cross 
Abstract: It is known that periodic forcing of nonlinear flows can result in a chaotic response under certain conditions. Such non-periodic and chaotic solutions have been observed in simulations of heterogeneous gas flow in a pipeline with periodic, time-varying boundary conditions. In this paper, we examine a proportional feedback law for boundary control of a parabolic partial differential equation system that represents the flow of two gases through a pipe. We demonstrate that periodic variation of the mass fraction of the lighter gas at the pipe inlet can result in the chaotic propagation of gas pressure waves, and show that appropriate flow control can suppress this response. We examine phase space solutions for the single pipe system subject to boundary control, and use numerical experiments to characterize conditions for the controller gain to suppress chaos.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04407v2</guid>
      <category>math.DS</category>
      <category>math.OC</category>
      <category>nlin.CD</category>
      <category>physics.flu-dyn</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luke S. Baker, Anatoly Zlotnik</dc:creator>
    </item>
    <item>
      <title>Learning Soft Constrained MPC Value Functions: Efficient MPC Design and Implementation providing Stability and Safety Guarantees</title>
      <link>https://arxiv.org/abs/2401.07780</link>
      <description>arXiv:2401.07780v2 Announce Type: replace-cross 
Abstract: Model Predictive Control (MPC) can be applied to safety-critical control problems, providing closed-loop safety and performance guarantees. Implementation of MPC controllers requires solving an optimization problem at every sampling instant, which is challenging to execute on embedded hardware. To address this challenge, we propose a framework that combines a tightened soft constrained MPC formulation with supervised learning to approximate the MPC value function. This combination enables us to obtain a corresponding optimal control law, which can be implemented efficiently on embedded platforms. The framework ensures stability and constraint satisfaction for various nonlinear systems. While the design effort is similar to that of nominal MPC, the proposed formulation provides input-to-state stability (ISS) with respect to the approximation error of the value function. Furthermore, we prove that the value function corresponding to the soft constrained MPC problem is Lipschitz continuous for Lipschitz continuous systems, even if the optimal control law may be discontinuous. This serves two purposes: First, it allows to relate approximation errors to a sufficiently large constraint tightening to obtain constraint satisfaction guarantees. Second, it paves the way for an efficient supervised learning procedure to obtain a continuous value function approximation. We demonstrate the effectiveness of the method using a nonlinear numerical example.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.07780v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Chatzikiriakos, Kim P. Wabersich, Felix Berkel, Patricia Pauli, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>SafEDMD: A certified learning architecture tailored to data-driven control of nonlinear dynamical systems</title>
      <link>https://arxiv.org/abs/2402.03145</link>
      <description>arXiv:2402.03145v2 Announce Type: replace-cross 
Abstract: The Koopman operator serves as the theoretical backbone for machine learning of dynamical control systems, where the operator is heuristically approximated by extended dynamic mode decomposition (EDMD). In this paper, we propose Stability- and certificate-oriented EDMD (SafEDMD): a novel EDMD-based learning architecture which comes along with rigorous certificates, resulting in a reliable surrogate model generated in a data-driven fashion. To ensure the trustworthiness of SafEDMD, we derive proportional error bounds, which vanish at the origin and are tailored to control tasks, leading to certified controller design based on semi-definite programming. We illustrate the developed method by means of several benchmark examples and highlight the advantages over state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.03145v2</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robin Str\"asser, Manuel Schaller, Karl Worthmann, Julian Berberich, Frank Allg\"ower</dc:creator>
    </item>
    <item>
      <title>Bilinear optimal control for the Stokes-Brinkman equations: a priori and a posteriori error analyses</title>
      <link>https://arxiv.org/abs/2404.18348</link>
      <description>arXiv:2404.18348v2 Announce Type: replace-cross 
Abstract: We analyze a bilinear optimal control problem for the Stokes--Brinkman equations: the control variable enters the state equations as a coefficient. In two- and three-dimensional Lipschitz domains, we perform a complete continuous analysis that includes the existence of solutions and first- and second-order optimality conditions. We also develop two finite element methods that differ fundamentally in whether the admissible control set is discretized or not. For each of the proposed methods, we perform a convergence analysis and derive a priori error estimates; the latter under the assumption that the domain is convex. Finally, assuming that the domain is Lipschitz, we develop an a posteriori error estimator for each discretization scheme and obtain a global reliability bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18348v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alejandro Allendes, Gilberto Campa\~na, Enrique Otarola</dc:creator>
    </item>
    <item>
      <title>Thompson Sampling for Infinite-Horizon Discounted Decision Processes</title>
      <link>https://arxiv.org/abs/2405.08253</link>
      <description>arXiv:2405.08253v2 Announce Type: replace-cross 
Abstract: We model a Markov decision process, parametrized by an unknown parameter, and study the asymptotic behavior of a sampling-based algorithm, called Thompson sampling. The standard definition of regret is not always suitable to evaluate a policy, especially when the underlying chain structure is general. We show that the standard (expected) regret can grow (super-)linearly and fails to capture the notion of learning in realistic settings with non-trivial state evolution. By decomposing the standard (expected) regret, we develop a new metric, called the expected residual regret, which forgets the immutable consequences of past actions. Instead, it measures regret against the optimal reward moving forward from the current period. We show that the expected residual regret of the Thompson sampling algorithm is upper bounded by a term which converges exponentially fast to 0. We present conditions under which the posterior sampling error of Thompson sampling converges to 0 almost surely. We then introduce the probabilistic version of the expected residual regret and present conditions under which it converges to 0 almost surely. Thus, we provide a viable concept of learning for sampling algorithms which will serve useful in broader settings than had been considered previously.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.08253v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Adelman, Cagla Keceli, Alba V. Olivares-Nadal</dc:creator>
    </item>
    <item>
      <title>Dynamical behavior and optimal control of a stochastic SAIRS epidemic model with two saturated incidences</title>
      <link>https://arxiv.org/abs/2405.09982</link>
      <description>arXiv:2405.09982v2 Announce Type: replace-cross 
Abstract: Stochastic models are widely used to investigate the spread of epidemics in a complex environment. This paper extends a deterministic SAIRS epidemic model to a stochastic case with limited patient capacity and exposure. We first study the dynamical properties of the model under certain conditions, including persistence, extinction, and ergodic. Then, we introduce vaccination and isolation into the model as control variables. The optimal control strategies are obtained based on the Pontryagin minimum principle. Finally, numerical simulations are given to illustrate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09982v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xiaohui Zhang, Zhiming Li, Shenglong Chen, Jikai Yang</dc:creator>
    </item>
  </channel>
</rss>
