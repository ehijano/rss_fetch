<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.soc-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.soc-ph</link>
    <description>physics.soc-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.soc-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Feb 2026 03:07:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Fragmentation of a longitudinal population-scale social network: Decreasing network closure in the Netherlands</title>
      <link>https://arxiv.org/abs/2602.00234</link>
      <description>arXiv:2602.00234v1 Announce Type: new 
Abstract: Population-level dynamics of social cohesion and its underlying mechanisms remain difficult to study. In this paper, we propose a network approach to measure the evolution of social cohesion at the population scale and identify mechanisms driving the change. We use twelve annual snapshots (2010-2021) of a population-scale social network from the Netherlands linking all residents through family, household, work, school, and neighbor relations. Results show that over this period, social cohesion, quantified as average closure in the network, declines by more than 15%. We demonstrate that the decline is not due to changes in demographic composition, but to rewiring in individual ego networks. Statistical models confirm a decreasing overlap of social contexts and greater geographical mobility as drivers. Residential relocation, however, temporarily increases closure, suggesting that local cohesion-seeking behavior can yield global network fragmentation, with implications for policies related to housing, urban planning, and social integration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00234v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eszter Bok\'anyi, Yuliia Kazmina, Eelke M. Heemskerk, Frank W. Takes</dc:creator>
    </item>
    <item>
      <title>Testing the validity of multiple opinion dynamics models</title>
      <link>https://arxiv.org/abs/2602.00876</link>
      <description>arXiv:2602.00876v1 Announce Type: new 
Abstract: While opinion dynamics models have been extensively studied as stylized models, there has been growing attention to the possibility of combining these models with empirical data. This attention seems to be driven by the many social issues that strongly depend on people's opinions (such as climate change and vaccination) and the need for empirically valid models to design related policy interventions. While different models have been combined in various ways with empirical data, standardised comparison of models against empirical data is still lacking. In this article, we test the validity of multiple opinion dynamics models--including both stylized and more realistic models. Our approach follows a "data science-like" validation procedure, where we first calibrate the model's free parameters using an initial range of years (e.g. 2010-2015), and then use data from one wave (e.g. 2016) to predict data in the following wave (e.g. 2017). We initially tested such a procedure using simulated data and then tested different models on various topics from the European Social Survey. Both toy models and empirical models perform well on the simulated data, but fail to predict future years in the empirical data. Furthermore, during the calibration phase on the empirical data, most models learned to "freeze"--meaning that their predictions for the following year are just a copy of the data from the previous year. This work advances the literature by offering a benchmark for comparing different opinion dynamics models. Furthermore, our tests show that real-world dynamics appear to be completely incompatible with the dynamics of the tested models. This calls for more effort in exploring what are the features that would improve validity and applications for opinion dynamics models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00876v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel Moor-Smith, Dino Carpentras</dc:creator>
    </item>
    <item>
      <title>FinEvo: From Isolated Backtests to Ecological Market Games for Multi-Agent Financial Strategy Evolution</title>
      <link>https://arxiv.org/abs/2602.00948</link>
      <description>arXiv:2602.00948v1 Announce Type: new 
Abstract: Conventional financial strategy evaluation relies on isolated backtests in static environments. Such evaluations assess each policy independently, overlook correlations and interactions, and fail to explain why strategies ultimately persist or vanish in evolving markets. We shift to an ecological perspective, where trading strategies are modeled as adaptive agents that interact and learn within a shared market. Instead of proposing a new strategy, we present FinEvo, an ecological game formalism for studying the evolutionary dynamics of multi-agent financial strategies. At the individual level, heterogeneous ML-based traders-rule-based, deep learning, reinforcement learning, and large language model (LLM) agents-adapt using signals such as historical prices and external news. At the population level, strategy distributions evolve through three designed mechanisms-selection, innovation, and environmental perturbation-capturing the dynamic forces of real markets. Together, these two layers of adaptation link evolutionary game theory with modern learning dynamics, providing a principled environment for studying strategic behavior. Experiments with external shocks and real-world news streams show that FinEvo is both stable for reproducibility and expressive in revealing context-dependent outcomes. Strategies may dominate, collapse, or form coalitions depending on their competitors-patterns invisible to static backtests. By reframing strategy evaluation as an ecological game formalism, FinEvo provides a unified, mechanism-level protocol for analyzing robustness, adaptation, and emergent dynamics in multi-agent financial markets, and may offer a means to explore the potential impact of macroeconomic policies and financial regulations on price evolution and equilibrium.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00948v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingxi Zou, Jiaxiang Chen, Aotian Luo, Jingyi Dai, Chi Zhang, Dongning Sun, Zenglin Xu</dc:creator>
    </item>
    <item>
      <title>Was Benoit Mandelbrot a hedgehog or a fox?</title>
      <link>https://arxiv.org/abs/2602.01122</link>
      <description>arXiv:2602.01122v1 Announce Type: new 
Abstract: Benoit Mandelbrot's scientific legacy spans an extraordinary range of disciplines, from linguistics and fluid turbulence to cosmology and finance, suggesting the intellectual temperament of a "fox" in Isaiah Berlin's famous dichotomy of thinkers. This essay argues, however, that Mandelbrot was, at heart, a "hedgehog": a thinker unified by a single guiding principle. Across his diverse pursuits, the concept of scaling -- manifested in self-similarity, power laws, fractals, and multifractals -- served as the central idea that structured his work. By tracing the continuity of this scaling paradigm through his contributions to mathematics, physics, and economics, the paper reveals a coherent intellectual trajectory masked by apparent eclecticism. Mandelbrot's enduring insight in the modeling of natural and social phenomena can be understood through the lens of the geometry and statistics of scale invariance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01122v1</guid>
      <category>physics.soc-ph</category>
      <category>q-fin.ST</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rosario N. Mantegna</dc:creator>
    </item>
    <item>
      <title>Coordinated planning of European charging infrastructure and energy system for optimal V1G and V2G deployment</title>
      <link>https://arxiv.org/abs/2602.01862</link>
      <description>arXiv:2602.01862v1 Announce Type: new 
Abstract: Vehicle charging infrastructure targets in Europe currently rely on uniform benchmarks and overlook the flexibility that could be provided by future smart charging (V1G) and vehicle to grid operation (V2G). To address this gap, we explicitly represent charging infrastructure and its costs in a cost minimizing European energy system model, allowing uncontrolled charging, V1G, and V2G to compete. We find that V1G captures the majority of system cost savings, amounting to 19 to 42 billion euros per year, or 2.2 to 4.5 percent, and substantially reduces infrastructure requirements. V2G provides more limited system cost savings of up to 2.5 billion euros per year, but generates substantial balancing market revenues of around 6.4 billion euros per year. V2G deployment is most cost effective in photovoltaic dominated systems and in scenarios with limited grid expansion, where combined solar and wind generation is relatively scarce. Charging infrastructure requirements vary across countries, reflecting either utilization maximization or flexibility maximization. This indicates that uniform EU targets risk overestimating infrastructure needs in some regions while constraining the benefits of smart charging in others.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01862v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesco Sanvito, Francesco Lombardi, Stefan Pfenninger-Lee</dc:creator>
    </item>
    <item>
      <title>Effect of higher-order interactions on noisy majority-rule dynamics with random group sizes</title>
      <link>https://arxiv.org/abs/2602.01902</link>
      <description>arXiv:2602.01902v1 Announce Type: new 
Abstract: We study noisy majority-rule dynamics on annealed hypergraphs to clarify how variability in group interaction sizes reshapes collective ordering. At each update, a group is sampled from a prescribed size distribution and either follows the strict within-group majority or, with probability $q$, updates independently under an external bias $p$. At the symmetric point $p=1/2$, we obtain an explicit analytical expression for the critical independence threshold $q_c$, which separates macroscopic ordering from a fluctuating mixed state and can be interpreted as the largest fraction of independent behavior that can be sustained without destroying order. Because $q_c$ is governed by group-size statistics through an effective majority leverage, broad and heavy-tailed size distributions enhance robustness by enabling rare large-group events to realign a substantial fraction of the population. We further derive analytical predictions, benchmarked against Monte Carlo simulations, for the leading finite-size behavior of relaxation: for narrow distributions the characteristic relaxation time typically grows logarithmically with system size, whereas sufficiently heavy-tailed power laws produce strong crossovers and make the large-system dynamics sensitive to how $q$ approaches the transition. In the pure majority-rule limit, we find a crossover from conventional logarithmic consensus times to rapid ordering driven by occasional macroscopic groups, and the exit probability near coexistence collapses onto a universal error-function form controlled by a single structural parameter.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01902v1</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roni Muslim, Jong-Min Park, Jihye Kim, Rinto Anugraha NQZ</dc:creator>
    </item>
    <item>
      <title>Patterns in Conflict Dynamics in Yemen and Syria</title>
      <link>https://arxiv.org/abs/2602.02337</link>
      <description>arXiv:2602.02337v1 Announce Type: new 
Abstract: Conflict fatalities tend to follow heavy-tailed statistical distributions. A 2005 fusion-fission theory predicts mathematically that for armed groups operating in dynamically evolving clusters within a given conflict, the number of fatalities per conflict event will follow an approximate power-law distribution with exponent near 2.5, with the specific exponent value offering insight into the relative robustness of larger versus smaller clusters of fighters in that armed group. Since Yemen and Syria are current hotspots for future conflict, yet their most recent conflicts (2023-2025) have not been studied at the event level, we use ACLED data to determine their best-fit exponent value as each conflict evolved. We find that the exponent lies between 2.5 and 3.5 predominantly throughout each conflict, which suggests that the fighters in each of these conflicts continued to operate in smaller clusters as the conflict evolved. Moreover, temporary reductions in the exponent value -- which suggests a temporary increase in the robustness and involvement of larger clusters of fighters -- appear to arise during major crises ahead of the largest battles. Though the lack higher-quality data for these conflicts prevents us from establishing this more firmly, such a temporary reduction in the exponent value hints at its potential use as an early-warning signature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.02337v1</guid>
      <category>physics.soc-ph</category>
      <category>nlin.AO</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moussa Abdou, Neil F. Johnson</dc:creator>
    </item>
    <item>
      <title>Social Learning with Endogenous Information and the Countervailing Effects of Homophily</title>
      <link>https://arxiv.org/abs/2602.00934</link>
      <description>arXiv:2602.00934v1 Announce Type: cross 
Abstract: People learn about opportunities and actions by observing the experiences of their friends. We model how homophily -- the tendency to associate with similar others -- affects both the endogenous quality and diversity of the information accessible to decision makers. Homophily provides higher-quality information, since observing the payoffs of another person is more informative the more similar that person is to the decision maker. However, homophily can lead people to take actions that generate less information. We show how network connectivity influences the tradeoff between the endogenous quantity and quality of information. Although homophily hampers learning in sparse networks, it enhances learning in sufficiently dense networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.00934v1</guid>
      <category>econ.TH</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunus C. Aybas, Matthew O. Jackson</dc:creator>
    </item>
    <item>
      <title>Leaves of preferential attachment trees</title>
      <link>https://arxiv.org/abs/2602.01021</link>
      <description>arXiv:2602.01021v1 Announce Type: cross 
Abstract: We provide a local probabilistic description of the limiting statistics of large preferential attachment trees in terms of the ordinary degree (number of neighbors) but augmented with information on leafdegree (number of neighbors that are leaves). The full description is the joint degree-leafdegree distribution $n_{k,\ell}$, which we derive from its associated multivariate generating function. From $n_{k,\ell}$ we obtain the leafdegree distribution, $m_{\ell}$, as well as the fraction of vertices that are protected (nonleaves with leafdegree zero) as a function of degree, $n_{k,0}$, among numerous other results. We also examine fluctuations and concentration of joint degree-leafdegree empirical counts $N_{k,\ell}$. Although our main findings pertain to the preferential attachment tree, the approach we present is highly generalizable and can characterize numerous existing models, in addition to facilitating the development of tractable new models. We further demonstrate the approach by analyzing $n_{k,\ell}$ in two other models: the random recursive tree, and a redirection-based model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2602.01021v1</guid>
      <category>cond-mat.stat-mech</category>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harrison Hartle, P. L. Krapivsky</dc:creator>
    </item>
    <item>
      <title>A Blue Start: A large-scale pairwise and higher-order social network dataset</title>
      <link>https://arxiv.org/abs/2505.11608</link>
      <description>arXiv:2505.11608v2 Announce Type: replace 
Abstract: Large-scale networks have been instrumental in shaping how we think about social systems, and have undergirded many foundational results in mathematical epidemiology, computational social science, and biology. However, many of the social systems through which diseases spread, information disseminates, and individuals interact are inherently mediated through groups, known as higher-order interactions. A gap exists between higher-order models of group formation and spreading processes and the data necessary to validate these mechanisms. Similarly, few datasets bridge the gap between pairwise and higher-order network data. The Bluesky social media platform is an ideal laboratory for observing social ties at scale through its open API. Not only does Bluesky contain pairwise following relationships, but it also contains higher-order social ties known as "starter packs" which are user-curated lists designed to promote social network growth. We introduce "A Blue Start", a large-scale network dataset comprising 39.7M user accounts, 2.4B pairwise following relationships, and 365.8K groups representing starter packs. This dataset will be an essential resource for the study of higher-order networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11608v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alyssa Smith, Ilya Amburg, Sagar Kumar, Brooke Foucault Welles, Nicholas W. Landry</dc:creator>
    </item>
    <item>
      <title>Screening, sorting, and the feedback cycles that imperil peer review</title>
      <link>https://arxiv.org/abs/2507.10734</link>
      <description>arXiv:2507.10734v3 Announce Type: replace 
Abstract: Scholarly journals rely on peer review to identify the science most worthy of publication. Yet finding willing and qualified reviewers to evaluate manuscripts has become an increasingly challenging task, possibly even threatening the long-term viability of peer review as an institution. What can or should be done to salvage it? Here, we develop mathematical models to reveal the intricate interactions among incentives faced by authors, reviewers, and readers in their endeavors to identify the best science. Two facets are particularly salient. First, peer review partially reveals authors' private sense of their work's quality through their decisions of where to send their manuscripts. Second, journals' reliance on traditionally unpaid and largely unrewarded review labor deprives them of a standard market mechanism -- wages -- to recruit additional reviewers when review labor is in short supply. We highlight a resulting feedback loop that threatens to overwhelm the peer review system: (1) an increase in submissions overtaxes the pool of suitable peer reviewers; (2) the accuracy of review drops because journals either must either solicit assistance from less qualified reviewers or ask current reviewers to do more; (3) as review accuracy drops, submissions further increase as more authors try their luck at venues that might otherwise be a stretch. We illustrate how this cycle is propelled by the increasing emphasis on high-impact publications, the proliferation of journals, and competition among these journals for peer reviews. Finally, we suggest interventions that could slow or even reverse this cycle of peer-review meltdown.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.10734v3</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Carl T. Bergstrom, Kevin Gross</dc:creator>
    </item>
    <item>
      <title>HIF: The hypergraph interchange format for higher-order networks</title>
      <link>https://arxiv.org/abs/2507.11520</link>
      <description>arXiv:2507.11520v2 Announce Type: replace 
Abstract: Many empirical systems contain complex interactions of arbitrary size, representing, for example, chemical reactions, social groups, co-authorship relationships, and ecological dependencies. These interactions are known as higher-order interactions and the collection of these interactions comprise a higher-order network, or hypergraph. Hypergraphs have established themselves as a popular and versatile mathematical representation of such systems and a number of software packages written in various programming languages have been designed to analyze these networks. However, the ecosystem of higher-order network analysis software is fragmented due to specialization of each software's programming interface and compatible data representations. To enable seamless data exchange between higher-order network analysis software packages, we introduce the Hypergraph Interchange Format (HIF), a standardized format for storing higher-order network data. HIF supports multiple types of higher-order networks, including undirected hypergraphs, directed hypergraphs, and abstract simplicial complexes, while actively exploring extensions to represent multiplex hypergraphs, temporal hypergraphs, and ordered hypergraphs. To accommodate the wide variety of metadata used in different contexts, HIF also includes support for attributes associated with nodes, edges, and incidences. This initiative is a collaborative effort involving authors, maintainers, and contributors from prominent hypergraph software packages. This project introduces a JSON schema with corresponding documentation and unit tests, example HIF-compliant datasets, and tutorials demonstrating the use of HIF with several popular higher-order network analysis software packages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.11520v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SI</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1017/nws.2025.10018</arxiv:DOI>
      <arxiv:journal_reference>Net Sci 13 (2025) e21</arxiv:journal_reference>
      <dc:creator>Mart\'in Coll, Cliff A. Joslyn, Nicholas W. Landry, Quintino Francesco Lotito, Audun Myers, Joshua Pickard, Brenda Praggastis, Przemys{\l}aw Szufel</dc:creator>
    </item>
    <item>
      <title>Trade-offs between structural richness and communication efficiency in music network representations</title>
      <link>https://arxiv.org/abs/2509.14053</link>
      <description>arXiv:2509.14053v2 Announce Type: replace 
Abstract: Music is a structured and perceptually rich sequence of sounds in time with well-defined symbolic features, whose perception is shaped by the interplay of expectation and uncertainty. Network science offers a powerful framework for studying its structural organization and communication efficiency. However, it remains unclear how feature selection affects the properties of reconstructed networks and perceptual alignment. Here, we systematically compare eight encodings of musical sequences, ranging from single-feature descriptions to richer multi-feature combinations. We show that representational choices fundamentally shape network topology, the distribution of uncertainty, and the estimated communication efficiency under perceptual constraints. Single-feature representations compress sequences into dense transition structures that support efficient communication, yielding high entropy rates with low modeled perceptual error, but they discard structural richness. By contrast, multi-feature representations preserve descriptive detail and structural specificity, expanding the state space and producing sharper transition profiles and lower entropy rates, which leads to higher modeled perceptual error. Across representations, we found that uncertainty increasingly concentrates in nodes with higher diffusion-based centrality while their perceptual error remains low, unveiling an interplay between predictable structure and localized surprise. Together, these results show that feature choice directly shapes music network representation, describing trade-offs between descriptive richness and communication efficiency and suggesting structural conditions that may support efficient learning and prediction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14053v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lluc Bono Rossell\'o, Robert Jankowski, Hugues Bersini, Mari\'an Bogu\~n\'a, M. \'Angeles Serrano</dc:creator>
    </item>
    <item>
      <title>Detectability threshold in weighted modular networks</title>
      <link>https://arxiv.org/abs/2511.00214</link>
      <description>arXiv:2511.00214v2 Announce Type: replace 
Abstract: We study the necessary condition to detect, by means of spectral modularity optimization, the ground-truth partition in networks generated according to the weighted planted-partition model with two equally sized communities. We analytically derive a general expression for the maximum level of mixing tolerated by the algorithm to retrieve community structure, showing that the value of this detectability threshold depends on the first two moments of the distributions of node degree and edge weight. We focus on the standard case of Poisson-distributed node degrees and compare the detectability thresholds of five edge-weight distributions: Dirac, Poisson, exponential, geometric, and signed Bernoulli. We show that Dirac distributed weights yield the smallest detectability threshold, while exponentially distributed weights increase the threshold by a factor $\sqrt{2}$, with other distributions exhibiting distinct behaviors that depend, either or both, on the average values of the degree and weight distributions. Our results indicate that larger variability in edge weights can make communities less detectable. In cases where edge weights carry no information about community structure, incorporating weights in community detection is detrimental.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.00214v2</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/bt2h-b7kb</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 113, 014318 (2026)</arxiv:journal_reference>
      <dc:creator>Filippo Radicchi, Filipi N. Silva, Alessandro Flammini, Santo Fortunato, Sadamori Kojaku</dc:creator>
    </item>
    <item>
      <title>Forsaking your own: unveiling the delayed recognition of Garfield's work on the "delayed recognition" phenomenon</title>
      <link>https://arxiv.org/abs/2512.16943</link>
      <description>arXiv:2512.16943v3 Announce Type: replace 
Abstract: Delayed recognition (DR) implies that the full scholarly potential of certain scientific papers is recognized belatedly many years after their publication. Such papers are initially barely cited (sleep), and then suddenly, sometime in the future, their citation numbers burst (are awakened). After van Raan (2004a) called them "Sleeping Beauties" the DR phenomenon has drawn considerable attention. However, long before van Raan (2004a) Garfield studied the phenomenon in a series of articles from 1970 up to year 2004. In the present study we ask the pertinent question; Has the phenomenon of DR itself suffered the delayed recognition? In search of an answer we study the citation history of the Garfield (1980a) paper in which Garfield addressed DR directly for the first time. We find that the paper hardly received the attention befitting the Garfield's stature as an information scientist. Specifically, the paper received a meager of 10 citations up to the publication year of van Raan (2004a) and was then, in 2007, feebly awakened from its deep sleep of twenty-eight years receiving 20 citations in next four years; up to 2010. Being the undisputed giant of information science that even Garfield's paper on DR can suffer DR is hardly anticipated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.16943v3</guid>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tariq Ahmad Mir, Marcel Ausloos</dc:creator>
    </item>
    <item>
      <title>On (Newcomb-)Benford's law: a tale of two papers and of their disproportionate citations. How citation counts can become biased</title>
      <link>https://arxiv.org/abs/2601.02395</link>
      <description>arXiv:2601.02395v2 Announce Type: replace 
Abstract: The first digit (FD) phenomenon i.e., the significant digits of numbers in large data are often distributed according to a logarithmically decreasing function was first reported by S. Newcomb and then many decades later independently by F. Benford. After its century long neglect the last three decades have seen huge growth in the number of relevant publications. However, notwithstanding the rising popularity the two independent proponents of the phenomenon are not equally acknowledged an indication of which is disproportionate number of citations accumulated by Newcomb (1881) and Benford (1938). In the present study we use citation analysis to show that the formalization of the eponym Benford's law, a name questionable itself for overlooking Newcomb's contribution, by Raimi (1976) had a strong adverse effect on the future citations of Newcomb (1881). Furthermore, we identify the papers published over various decades of the developmental history of the FD phenomenon, which latter turned out to be amongst the most cited ones in the field. We find that lack of its consideration, intentional or occasionally out of ignorance for referencing by the prominent papers, is responsible for a far lesser number of citations of Newcomb (1881) in comparison to Benford (1938).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.02395v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.DL</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tariq Ahmad Mir, Marcel Ausloos</dc:creator>
    </item>
    <item>
      <title>A costing framework for fusion power plants</title>
      <link>https://arxiv.org/abs/2601.21724</link>
      <description>arXiv:2601.21724v2 Announce Type: replace 
Abstract: This paper summarizes and consolidates fusion power-plant costing work performed in support of ARPA-E from 2017 through 2024, and documents the evolution of the associated analysis framework from early capital-cost-focused studies to a standards-aligned, auditable costing capability. Early efforts applied ARIES-style cost-scaling relations to generate Nth-of-a-kind (NOAK) estimates and were calibrated through a pilot study with Bechtel and Decysive Systems to benchmark balance-of-plant (BOP) costs and validate plant-level reasonableness from an engineering, procurement, and construction (EPC) perspective. Subsequent work, informed by Lucid Catalyst studies of nuclear cost drivers, expanded the methodology to treat indirect costs explicitly and to evaluate cost-reduction pathways for non-fusion-island systems through design-for-cost practices, modularization, centralized manufacturing, and learning. As ARPA-E's fusion portfolio expanded, these methods were applied across BETHE and GAMOW concepts (and select ALPHA revisits), including enhanced treatment of tritium handling and plant integration supported by Princeton/PPPL expertise. In 2023 the capability was refactored to align with the IAEA-GEN-IV EMWG-EPRI code-of-accounts lineage, while key ARIES-derived scaling relations were replaced by bottom-up subsystem models for dominant fusion cost drivers (e.g., magnets, lasers, power supplies, and power-core components) coupled to physics-informed power balances and engineering-constrained radial builds. These developments were implemented in the spreadsheet-based Fusion Economics code (FECONs) and released as an open-source Python framework (pyFECONs), providing a transparent mapping from subsystem estimates to standardized accounts and a consistent computation of LCOE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.21724v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.SE</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Simon Woodruff</dc:creator>
    </item>
    <item>
      <title>Convergent Discovery of Critical Phenomena Mathematics Across Disciplines: A Cross-Domain Analysis</title>
      <link>https://arxiv.org/abs/2601.22389</link>
      <description>arXiv:2601.22389v2 Announce Type: replace 
Abstract: Techniques for detecting critical phenomena -- phase transitions where correlation length diverges and small perturbations have large effects -- have been developed across at least eight fields of application over nine decades. We document this convergence pattern. The physicist's correlation length $\xi$, the cardiologist's DFA scaling exponent $\alpha$, the financial analyst's Hurst exponent $H$, and the machine learning engineer's spectral radius $\chi$ all measure correlation decay rate, detecting the same critical signatures under different notation. Citation analysis reveals minimal cross-domain awareness during the formative period (1987--2010): researchers in biomedicine, finance, machine learning, power systems, and traffic flow developed equivalent techniques independently, each with distinct notation and terminology. We present Metatron Dynamics, a framework derived from distributed systems engineering, as a candidate ninth independent discovery -- strengthening the convergence pattern while acknowledging that as authors of both the framework and this analysis, external validation would strengthen this claim. Correspondence testing on the 2D Ising model confirms that measures from multiple frameworks correctly identify the critical regime at $T_c = 2.269$. We argue that repeated independent discovery establishes criticality mathematics as fundamental public knowledge, with implications for cross-disciplinary education and research accessibility. Because these findings affect fields beyond mathematics and physics, we include a plain-language summary in Appendix B for non-specialist readers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.22389v2</guid>
      <category>physics.soc-ph</category>
      <category>cond-mat.stat-mech</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bruce Stephenson, Robin Macomber</dc:creator>
    </item>
    <item>
      <title>Multilayer Horizontal Visibility Graphs for Multivariate Time Series Analysis</title>
      <link>https://arxiv.org/abs/2301.02333</link>
      <description>arXiv:2301.02333v2 Announce Type: replace-cross 
Abstract: Multivariate time series analysis is a vital but challenging task, with multidisciplinary applicability, tackling the characterization of multiple interconnected variables over time and their dependencies. Traditional methodologies often adapt univariate approaches or rely on assumptions specific to certain domains or problems, presenting limitations. A recent promising alternative is to map multivariate time series into high-level network structures such as multiplex networks, with past work relying on connecting successive time series components with interconnections between contemporary timestamps.
  In this work, we first define a novel cross-horizontal visibility mapping between lagged timestamps of different time series and then introduce the concept of multilayer horizontal visibility graphs. This allows describing cross-dimension dependencies via inter-layer edges, leveraging the entire structure of multilayer networks. To this end, a novel parameter-free topological measure is proposed and common measures are extended for the multilayer setting. Our approach is general and applicable to any kind of multivariate time series data.
  We provide an extensive experimental evaluation with both synthetic and real-world datasets. We first explore the proposed methodology and the data properties highlighted by each measure, showing that inter-layer edges based on cross-horizontal visibility preserve more information than previous mappings, while also complementing the information captured by commonly used intra-layer edges. We then illustrate the applicability and validity of our approach in multivariate time series mining tasks, showcasing its potential for enhanced data analysis and insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.02333v2</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vanessa Freitas Silva, Maria Eduarda Silva, Pedro Ribeiro, Fernando Silva</dc:creator>
    </item>
    <item>
      <title>Limited Improvement of Connectivity in Scale-Free Networks by Increasing the Power-Law Exponent</title>
      <link>https://arxiv.org/abs/2509.17652</link>
      <description>arXiv:2509.17652v3 Announce Type: replace-cross 
Abstract: It has been well-known that many real networks are scale-free (SF) but extremely vulnerable against attacks. We investigate the robustness of connectivity and the lengths of the shortest loops in randomized SF networks with realistic exponents $2.0 &lt; \gamma \leq 4.0$. We show that smaller variance of degree distributions leads to stronger robustness and longer average length of the shortest loops, which means the existing of large holes. These results will provide important insights toward enhancing the robustness by changing degree distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.17652v3</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yingzhou Mou, Yukio Hayashi</dc:creator>
    </item>
    <item>
      <title>Triadic percolation on multilayer networks</title>
      <link>https://arxiv.org/abs/2510.09341</link>
      <description>arXiv:2510.09341v2 Announce Type: replace-cross 
Abstract: Triadic interactions are special types of higher-order interactions that occur when regulator nodes modulate the interactions between other two or more nodes. In presence of triadic interactions, a percolation process occurring on a single-layer network becomes a fully-fledged dynamical system, characterized by period-doubling and a route to chaos. Here, we generalize the model to multilayer networks and name it as the multilayer triadic percolation (MTP) model. We find a much richer dynamical behavior of the MTP model than its single-layer counterpart. MTP displays a Neimark-Sacker bifurcation, leading to oscillations of arbitrarily large period or pseudo-periodic oscillations. Moreover, MTP admits period-two oscillations without negative regulatory interactions, whereas single-layer systems only display discontinuous hybrid transitions. This comprehensive model offers new insights on the importance of regulatory interactions in real-world systems such as brain networks, climate, and ecological systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.09341v2</guid>
      <category>nlin.AO</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>nlin.CD</category>
      <category>physics.soc-ph</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/yvtg-wnn4</arxiv:DOI>
      <arxiv:journal_reference>Physical Review E 113.1 (2026): 014313</arxiv:journal_reference>
      <dc:creator>Hanlin Sun, Filippo Radicchi, Ginestra Bianconi</dc:creator>
    </item>
    <item>
      <title>Are penalty shootouts better than a coin toss? Evidence from international club football in Europe</title>
      <link>https://arxiv.org/abs/2510.17641</link>
      <description>arXiv:2510.17641v4 Announce Type: replace-cross 
Abstract: Penalty shootouts play a crucial role in the knockout stage of major football tournaments. Their importance has been substantially increased from the 2021/22 season, when the Union of European Football Associations (UEFA) scrapped the away goals rule. Our paper examines whether the outcome of a penalty shootout can be predicted in UEFA club competitions. Based on all shootouts between 2000 and 2025, we find no evidence for the effect of the kicking order, the field of the match, or psychological momentum. In contrast to previous results, we do not detect any (positive) relationship between relative team strength and shootout success using differences in Elo ratings. Consequently, penalty shootouts seem to be close to a coin toss in top European club football.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.17641v4</guid>
      <category>econ.GN</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <pubDate>Tue, 03 Feb 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>L\'aszl\'o Csat\'o, D\'ora Gr\'eta Petr\'oczy</dc:creator>
    </item>
  </channel>
</rss>
