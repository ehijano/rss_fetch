<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.geo-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.geo-ph</link>
    <description>physics.geo-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.geo-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 21 Oct 2025 02:40:27 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Evaluating Multi-station Phase Picking Algorithm Phase Neural Operator (PhaseNO) on Local Seismic Networks</title>
      <link>https://arxiv.org/abs/2510.15281</link>
      <description>arXiv:2510.15281v1 Announce Type: new 
Abstract: Reliable automatic phase picking is important for many seismic applications. With the development of machine learning approaches, many algorithms are proposed, evaluated and applied to different areas. Many of these algorithms are single station based, while recent proposed methods start to combine surrounding stations into consideration in the problem of phase picking. Among these algorithms, the Phase Neural Operator (PhaseNO) shows promising results on regional datasets comparing to existing algorithms. But there are many use cases for the local seismic networks in our community, therefore in this paper we evaluate the performance of PhaseNO on 4 different local datasets and compared the results to PhaseNet and EQTransformer. We used both individual phase picking metrics as well as association metrics to illustrate the performance of PhaseNO. With manually reviewing the newly detected events, we find the PhaseNO model outperformed the single station-based approaches in the local-scale use cases due to its consideration of coherent signals from multiple stations. We also explored PhaseNO's behaviors when only using one station, as well as gradually increase the number of stations in the seismic network to understand it better. Overall, using the off-the-shelf machine learning based phase pickers, PhaseNO demonstrated its good performance on local-scale seismic networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15281v1</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingkai Kong, Avigyan Chatterjee, Chengping Chai, Alex Dzubay, Kayla A. Kroll, Josh C. Stachnik, Scott Fertig, Jeffrey Liefer, Paul Friberg</dc:creator>
    </item>
    <item>
      <title>Experimental and numerical study on the influence of extra-depth on cut blasting post-blast damage</title>
      <link>https://arxiv.org/abs/2510.15443</link>
      <description>arXiv:2510.15443v1 Announce Type: new 
Abstract: Cutting is a key factor affecting the speed of blasting excavation. With the continuous advancement of deep-hole blasting technology, determining the optimal extra-depth of the cut relative to the non-cut blast hole is of paramount importance. By combining model experiments and numerical simulations, this study systematically investigates the effect of extra-depth on post-blast damage morphology, damage width, depth, area, and fractal damage. Furthermore, numerical simulations were employed to validate the experimental results from the perspectives of damage evolution and peak pressure at monitoring points. The main findings are as follows: The extra-depth of the cut has a significant nonlinear effect on the blasting outcome. As the extra-depth increases, blasting damage initially increases but decreases beyond a critical depth due to marginal effects, leading to the appearance of residual blast hole features. Under experimental conditions, when the extra-depth was 15 mm, the damage depth, width, and area reached their maximum values of 43.5 mm, 109.9 mm, and 6055.2 mm, respectively, indicating optimal blasting performance. The fractal damage of the specimen also exhibited a significant trend of initially increasing and then decreasing. The maximum fractal damage, obtained by deriving the fitting curve, was 0.75, corresponding to an extra-depth of 13.7 mm. The numerical simulation results are in good agreement with the experimental findings, showing a significant downward shift in the peak pressure points in the damage zone with increasing extra-depth. In summary, an appropriate extra-depth can achieve optimal borehole utilization, while an excessive extra-depth can lead to residual blast hole formation at the bottom of the cut, reducing effectiveness. This study provides theoretical guidance for optimizing the design parameters of extra-depth in deep-hole blasting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15443v1</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Changda Zheng, Renshu Yang, Chenxi Ding, Songlin He, Bo Wang, Yongzhong Yuan</dc:creator>
    </item>
    <item>
      <title>Multiphysics inversion with variable complexity of receiver-function, surface-wave dispersion and magnetotelluric data reduces uncertainty for lithosphere structure</title>
      <link>https://arxiv.org/abs/2510.15779</link>
      <description>arXiv:2510.15779v1 Announce Type: new 
Abstract: We present a probabilistic multiphysics inversion based on Bayesian inference with trans-dimensional models. We jointly consider magnetotelluric, receiver function, and Rayleigh-wave dispersion data to infer one-dimensional lithospheric structure in the vicinity of Athabasca, Canada. The location is on the North American Craton with a cover of sediments from the Western Canada Sedimentary Basin. The trans-dimensional model uses layer nodes that include parameters that are activated or deactivated based on data information. Furthermore, the number of nodes is based on data information. Hence, the parameterization uncertainty is included in the uncertainty estimates. Furthermore, the layer nodes permit trans-dimensional decoupling such that some discontinuities may be represented by only some of the parameters. In probabilistic multiphysics inversion, it is important that the various data types are weighed objectively. Here, the weights are the data covariance matrices of the various data types. We apply empirical estimation of data covariance matrices and employ hierarchical scaling parameters to reduce the dependence on some assumptions required by the empirical approach. Hence, we account for noise variances and covariances, which is crucial for successful probabilistic multiphysics inversion. The parameter estimates and data covariance matrices are obtained with the reversible-jump Markov chain Monte Carlo algorithm with parallel tempering to enhance the efficiency. Since covariance matrix estimation changes data weights, the estimation process is carried out while samples are not recorded for inference. The results at the Athabasca site fit the data and produce plausible data covariance matrices for the data weights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15779v1</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. Shahsavari, J. Dettmer, M. J. Unsworth, A. Schaeffer</dc:creator>
    </item>
    <item>
      <title>Eruption column modelling of explosive volcanism on Venus</title>
      <link>https://arxiv.org/abs/2510.15492</link>
      <description>arXiv:2510.15492v1 Announce Type: cross 
Abstract: Volcanism on Venus has never been directly observed, but several measurements indicate present-day activity. Volcanism could potentially play a role in climatic processes on Venus, especially in the sulfur cycle like on Earth. Observation of volcanic activity is the primary objective of future Venus spacecraft. However, there are many unknowns regarding its Venusian characteristics, like the condition at the vent, the volatile content and composition. Past modelling efforts have only studied explosive volcanic plume propagation over a limited range of flow parameters at the vent and in an idealised Venus atmospheric configuration. We propose to use the 1D FPLUME volcanic plume model in a realistic Venusian environment. In similar Venusian conditions, the height of the plume is consistent with past modelling. The present study shows that explosive volcanism would preferably reach 15 km of altitude. Under certain conditions, plumes are able to reach the VenSpec-H tropospheric altitude range of observations and even the 45 km cloud floor. For the first time, the impact of wind was quantified, and the super-rotating winds have a substantial impact by plume-bending of reducing the height of plumes. Contrary to the Earth, the atmospheric heat capacity depends greatly on temperature, and will disadvantage lower plumes and allow larger plumes to propagate at higher altitudes. The high latitude atmospheric environment, due to the thermal profile and weaker winds, is favorable to plumes reaching higher altitudes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15492v1</guid>
      <category>astro-ph.EP</category>
      <category>physics.ao-ph</category>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1029/2025JE009320</arxiv:DOI>
      <arxiv:journal_reference>Journal of Geophysical Research: Planets, 130, e2025JE009320</arxiv:journal_reference>
      <dc:creator>Maxence Lef\`evre, Matteo Cerminara, Antonio Costa</dc:creator>
    </item>
    <item>
      <title>Residual Kriging for Regional-Scale Canopy Height Mapping: Insights into GEDI-Induced Anisotropies and Sparse Sampling</title>
      <link>https://arxiv.org/abs/2510.15572</link>
      <description>arXiv:2510.15572v1 Announce Type: cross 
Abstract: Quantifying aboveground biomass (AGB) is essential in the context of global climate change. Canopy height, which is related to AGB, can be mapped using machine learning models trained with multi-source spatial data and GEDI measurements. In this study, a comparative analysis of canopy height estimates derived from two models is presented: a U-Net deep learning model (CHNET) and a Random Forest algorithm (RFH). Both models were trained using GEDI lidar data and utilized multi-source inputs, including optical, radar, and environmental data. While CHNET can leverage its convolutional architecture to account for spatial correlations, we observed that it does not fully incorporate all the spatial autocorrelation present in GEDI canopy height measurements. By conducting a spatial analysis of the models' residuals, we also identified that GEDI data acquisition parameters, particularly the variability in laser beam energy combined with the azimuthal directions of the observation tracks, introduce spatial inconsistencies in the measurements in the form of periodic patterns. To address these anisotropies, we considered exclusively GEDI power beams, and we conducted our spatial autocorrelation analysis in the GEDI track azimuthal direction. Next, we employed the residual kriging (RK) spatial interpolation technique to account for the spatial autocorrelation of canopy heights and improve the accuracies of CHNET and RFH estimates. Adding RK corrections improved the performance of both CHNET and RFH, with more substantial gains observed for RFH. The corrections appeared to be localized around the GEDI sample points and the density of usable GEDI information is therefore an important factor in the effectiveness of spatial interpolation. Furthermore, our findings reveal that a Random Forest model combined with spatial interpolation can deliver performance comparable to that of a U-Net model alone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.15572v1</guid>
      <category>stat.AP</category>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Kamel Lahssini, Guerric le Maire, Nicolas Baghdadi, Ibrahim Fayad</dc:creator>
    </item>
    <item>
      <title>Cluster analysis of earthquake hypocenters in Azerbaijan and surrounding territories</title>
      <link>https://arxiv.org/abs/2506.22829</link>
      <description>arXiv:2506.22829v2 Announce Type: replace 
Abstract: The research focuses on seismic events that occurred in Azerbaijan and adjacent territories, regions known for strong seismic activity. We analyze a catalog of recorded earthquakes between 2010 and 2023, extracting the locations of the earthquake hypocenters for study purposes. Using statistical methods and cluster analysis tools, we developed a procedure for partitioning hypocenter clusters. The procedure begins with estimates of the Morisita Index, which is suitable for preliminary assessments of the statistical properties of hypocenter sets. Analysis of the Morisita Index indicates that the spatial distribution of hypocenters is heterogeneous, containing denser domains referred to as clusters. The next stage involves identifying spatial clusters using the DBSCAN and HDBSCAN algorithms. Due to the strong dependence of results on the algorithm's parameters, we selected several partitions with 5-8 clusters that provided maximal or near-maximal Silhouette Index values. The final stage assesses the similarity of the resulting partitions, using the Adjusted Rand Index to identify partitions with a specified degree of similarity. The final set of partitions was compared to the fault network of the region. Based on the selected partition, the earthquake depth distributions were studied. Specifically, approximate probability density functions were constructed in the form of mixtures of normal distributions, leading to the identification of several bimodal distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22829v2</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergii Skurativskyi, Sergiy Mykulyak, Yuliya Semenova, Kateryna Skurativska</dc:creator>
    </item>
    <item>
      <title>From Local Earthquake Nowcasting to Natural Time Forecasting: A Simple Do-It-Yourself (DIY) Method</title>
      <link>https://arxiv.org/abs/2510.02467</link>
      <description>arXiv:2510.02467v2 Announce Type: replace 
Abstract: Previous papers have outlined nowcasting methods to track the current state of earthquake hazard using only observed seismic catalogs. The basis for one of these methods, the "counting method", is the Gutenberg-Richter (GR) magnitude-frequency relation. The GR relation states that for every large earthquake of magnitude greater than MT , there are on average NGR small earthquakes of magnitude MS. In this paper we use this basic relation, combined with the Receiver Operating Characteristic (ROC) formalism from machine learning, to compute the probability of a large earthquake. The probability is conditioned on the number of small earthquakes n(t) that have occurred since the last large earthquake. We work in natural time, which is defined as the count of small earthquakes between large earthquakes. We do not need to assume a probability model, which is a major advantage. Instead, the probability is computed as the Positive Predictive Value (PPV) associated with the ROC curve. We find that the PPV following the last large earthquake initially decreases as more small earthquakes occur, indicating the property of temporal clustering of large earthquakes as is observed. As the number of small earthquakes continues to accumulate, the PPV subsequently begins to increase. Eventually a point is reached beyond which the rate of increase becomes much larger and more dramatic. Here we describe and illustrate the method by applying it to a local region around Los Angeles, California, following the January 17, 1994 magnitude M6.7 Northridge earthquake.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02467v2</guid>
      <category>physics.geo-ph</category>
      <pubDate>Mon, 20 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John B Rundle, Ian Baughman, Andrea Donnellan, Lisa Grant, Geoffrey Fox</dc:creator>
    </item>
  </channel>
</rss>
