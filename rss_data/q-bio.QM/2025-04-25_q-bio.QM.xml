<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 04:01:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Last-layer committee machines for uncertainty estimations of benthic imagery</title>
      <link>https://arxiv.org/abs/2504.16952</link>
      <description>arXiv:2504.16952v1 Announce Type: new 
Abstract: Automating the annotation of benthic imagery (i.e., images of the seafloor and its associated organisms, habitats, and geological features) is critical for monitoring rapidly changing ocean ecosystems. Deep learning approaches have succeeded in this purpose; however, consistent annotation remains challenging due to ambiguous seafloor images, potential inter-user annotation disagreements, and out-of-distribution samples. Marine scientists implementing deep learning models often obtain predictions based on one-hot representations trained using a cross-entropy loss objective with softmax normalization, resulting with a single set of model parameters. While efficient, this approach may lead to overconfident predictions for context-challenging datasets, raising reliability concerns that present risks for downstream tasks such as benthic habitat mapping and marine spatial planning. In this study, we investigated classification uncertainty as a tool to improve the labeling of benthic habitat imagery. We developed a framework for two challenging sub-datasets of the recently publicly available BenthicNet dataset using Bayesian neural networks, Monte Carlo dropout inference sampling, and a proposed single last-layer committee machine. This approach resulted with a &gt; 95% reduction of network parameters to obtain per-sample uncertainties while obtaining near-identical performance compared to computationally more expensive strategies such as Bayesian neural networks, Monte Carlo dropout, and deep ensembles. The method proposed in this research provides a strategy for obtaining prioritized lists of uncertain samples for human-in-the-loop interventions to identify ambiguous, mislabeled, out-of-distribution, and/or difficult images for enhancing existing annotation tools for benthic mapping and other applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16952v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>H. Martin Gillis, Isaac Xu, Benjamin Misiuk, Craig J. Brown, Thomas Trappenberg</dc:creator>
    </item>
    <item>
      <title>Deep Multi-modal Breast Cancer Detection Network</title>
      <link>https://arxiv.org/abs/2504.16954</link>
      <description>arXiv:2504.16954v1 Announce Type: new 
Abstract: Automated breast cancer detection via computer vision techniques is challenging due to the complex nature of breast tissue, the subtle appearance of cancerous lesions, and variations in breast density. Mainstream techniques primarily focus on visual cues, overlooking complementary patient-specific textual features that are equally important and can enhance diagnostic accuracy. To address this gap, we introduce Multi-modal Cancer Detection Network (MMDCNet) that integrates visual cues with clinical data to improve breast cancer detection. Our approach processes medical images using computer vision techniques while structured patient metadata patterns are learned through a custom fully connected network. The extracted features are fused to form a comprehensive representation, allowing the model to leverage both visual and clinical information. The final classifier is trained based on the joint features embedding space of visual and clinical cues and experiments prove enhanced performance, improving accuracy from 79.38\% to 90.87\% on a Mini-DDSM dataset. Additionally, our approach achieves 97.05\% accuracy on an image-only dataset, highlighting the robustness and effectiveness of visual feature extraction. These findings emphasise the potential of multi-modal learning in medical diagnostics, paving the way for future research on optimising data integration strategies and refining AI-driven clinical decision support systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16954v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noor Ul Huda Shah, Tanveer Hussain, Amr Ahmed, Yonghuai Liu, Usman Ali, Ardhendu Behera</dc:creator>
    </item>
    <item>
      <title>Automating tumor-infiltrating lymphocyte assessment in breast cancer histopathology images using QuPath: a transparent and accessible machine learning pipeline</title>
      <link>https://arxiv.org/abs/2504.16979</link>
      <description>arXiv:2504.16979v1 Announce Type: new 
Abstract: In this study, we built an end-to-end tumor-infiltrating lymphocytes (TILs) assessment pipeline within QuPath, demonstrating the potential of easily accessible tools to perform complex tasks in a fully automatic fashion. First, we trained a pixel classifier to segment tumor, tumor-associated stroma, and other tissue compartments in breast cancer H&amp;E-stained whole-slide images (WSI) to isolate tumor-associated stroma for subsequent analysis. Next, we applied a pre-trained StarDist deep learning model in QuPath for cell detection and used the extracted cell features to train a binary classifier distinguishing TILs from other cells. To evaluate our TILs assessment pipeline, we calculated the TIL density in each WSI and categorized them as low, medium, or high TIL levels. Our pipeline was evaluated against pathologist-assigned TIL scores, achieving a Cohen's kappa of 0.71 on the external test set, corroborating previous research findings. These results confirm that existing software can offer a practical solution for the assessment of TILs in H&amp;E-stained WSIs of breast cancer.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16979v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masoud Tafavvoghi, Lars Ailo Bongo, Andr\'e Berli Delgado, Nikita Shvetsov, Anders Sildnes, Line Moi, Lill-Tove Rasmussen Busund, Kajsa M{\o}llersen</dc:creator>
    </item>
    <item>
      <title>Moving mountains: grazing agents drive terracette formation on steep hillslopes</title>
      <link>https://arxiv.org/abs/2504.17496</link>
      <description>arXiv:2504.17496v1 Announce Type: new 
Abstract: Terracettes, striking, step-like landforms that stripe steep, vegetated hillslopes, have puzzled scientists for more than a century. Competing hypotheses invoke either slow mass-wasting or the relentless trampling of grazing animals, yet no mechanistic model has linked hoof-scale behavior to landscape-scale form. Here we bridge that gap with an active-walker model in which ungulates are represented as stochastic foragers moving on an erodible slope. Each agent weighs the energetic cost of climbing against the benefit of fresh forage; every hoof-fall compacts soil and lowers local biomass, subtly reshaping the energy landscape that guides subsequent steps. Over time, these stigmergic feedbacks concentrate traffic along cross-slope paths that coalesce into periodic tread-and-riser bands, morphologically analogous to natural terracettes. Our model illustrates how local foraging rules governing movement and substrate feedback can self-organize into large-scale topographic patterns, highlighting the wider role of decentralized biological processes in sculpting terrestrial landscapes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17496v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Benjamin Seleb, Atanu Chatterjee, Saad Bhamla</dc:creator>
    </item>
    <item>
      <title>A Novel Graph Transformer Framework for Gene Regulatory Network Inference</title>
      <link>https://arxiv.org/abs/2504.16961</link>
      <description>arXiv:2504.16961v1 Announce Type: cross 
Abstract: The inference of gene regulatory networks (GRNs) is a foundational stride towards deciphering the fundamentals of complex biological systems. Inferring a possible regulatory link between two genes can be formulated as a link prediction problem. Inference of GRNs via gene coexpression profiling data may not always reflect true biological interactions, as its susceptibility to noise and misrepresenting true biological regulatory relationships. Most GRN inference methods face several challenges in the network reconstruction phase. Therefore, it is important to encode gene expression values, leverege the prior knowledge gained from the available inferred network structures and positional informations of the input network nodes towards inferring a better and more confident GRN network reconstruction. In this paper, we explore the integration of multiple inferred networks to enhance the inference of Gene Regulatory Networks (GRNs). Primarily, we employ autoencoder embeddings to capture gene expression patterns directly from raw data, preserving intricate biological signals. Then, we embed the prior knowledge from GRN structures transforming them into a text-like representation using random walks, which are then encoded with a masked language model, BERT, to generate global embeddings for each gene across all networks. Additionally, we embed the positional encodings of the input gene networks to better identify the position of each unique gene within the graph. These embeddings are integrated into graph transformer-based model, termed GT-GRN, for GRN inference. The GT-GRN model effectively utilizes the topological structure of the ground truth network while incorporating the enriched encoded information. Experimental results demonstrate that GT-GRN significantly outperforms existing GRN inference methods, achieving superior accuracy and highlighting the robustness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16961v1</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>q-bio.GN</category>
      <category>q-bio.MN</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Binon Teji, Swarup Roy</dc:creator>
    </item>
    <item>
      <title>Transferring Spatial Filters via Tangent Space Alignment in Motor Imagery BCIs</title>
      <link>https://arxiv.org/abs/2504.17111</link>
      <description>arXiv:2504.17111v1 Announce Type: cross 
Abstract: We propose a method to improve subject transfer in motor imagery BCIs by aligning covariance matrices on a Riemannian manifold, followed by computing a new common spatial patterns (CSP) based spatial filter. We explore various ways to integrate information from multiple subjects and show improved performance compared to standard CSP. Across three datasets, our method shows marginal improvements over standard CSP; however, when training data are limited, the improvements become more significant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17111v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tekin Gunasar, Virginia de Sa</dc:creator>
    </item>
    <item>
      <title>Probing molecular concentration in cell nuclei with Brillouin microscopy</title>
      <link>https://arxiv.org/abs/2504.17362</link>
      <description>arXiv:2504.17362v1 Announce Type: cross 
Abstract: Cell volume is controlled by osmotic regulation of the fluid content, via water efflux through the cell membrane. The rate of this process is controlled by the ability of the liquid to move through the meshwork of solid elements within the cell. While such dynamics have been interpreted in the frame of the poroelastic theory in the cytoplasm, the behavior of the nucleus remains unknown due to a lack of technique to probe it. Brillouin light scattering (BLS) allows to interrogate the sound velocity and attenuation of a sample in a non-contact manner, thus revealing the dynamic response of the material. In cells, such data were initially interpreted as the viscoelastic response of the actin meshwork, but later studies pointed out the importance of water content. To resolve this lack of consensus in the interpretation of the hypersonic data obtained from BLS spectra, and investigate the possible poroelastic nature of the nucleus, we vary the relative volume fraction of intracellular water and solid network by applying osmotic compressions to single cells. In the nucleus, we observe a non-linear increase in the sound velocity and attenuation with increasing osmotic pressure that we fit to a poroelastic model, providing an estimate of the friction coefficient between the water phase and the network. By comparing BLS data to volume measurements, our approach demonstrates clearly that Brillouin microscopy actually provides a measure of molecular concentration in living cells</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17362v1</guid>
      <category>physics.bio-ph</category>
      <category>cond-mat.soft</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucie Vovard, Alexis Viel, Estelle Bastien, Lou-Anne Goutier, Gaetan Jardine, Jeremie Margueritat, Sylvain Monnier, Thomas Dehoux</dc:creator>
    </item>
    <item>
      <title>Beyond Cox Models: Assessing the Performance of Machine-Learning Methods in Non-Proportional Hazards and Non-Linear Survival Analysis</title>
      <link>https://arxiv.org/abs/2504.17568</link>
      <description>arXiv:2504.17568v1 Announce Type: cross 
Abstract: Survival analysis often relies on Cox models, assuming both linearity and proportional hazards (PH). This study evaluates machine and deep learning methods that relax these constraints, comparing their performance with penalized Cox models on a benchmark of three synthetic and three real datasets. In total, eight different models were tested, including six non-linear models of which four were also non-PH. Although Cox regression often yielded satisfactory performance, we showed the conditions under which machine and deep learning models can perform better. Indeed, the performance of these methods has often been underestimated due to the improper use of Harrell's concordance index (C-index) instead of more appropriate scores such as Antolini's concordance index, which generalizes C-index in cases where the PH assumption does not hold. In addition, since occasionally high C-index models happen to be badly calibrated, combining Antolini's C-index with Brier's score is useful to assess the overall performance of a survival method. Results on our benchmark data showed that survival prediction should be approached by testing different methods to select the most appropriate one according to sample size, non-linearity and non-PH conditions. To allow an easy reproducibility of these tests on our benchmark data, code and documentation are freely available at https://github.com/compbiomed-unito/survhive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17568v1</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Rossi, Flavio Sartori, Cesare Rollo, Giovanni Birolo, Piero Fariselli, Tiziana Sanavia</dc:creator>
    </item>
    <item>
      <title>Fast Directed $q$-Analysis for Brain Graphs</title>
      <link>https://arxiv.org/abs/2501.04596</link>
      <description>arXiv:2501.04596v3 Announce Type: replace 
Abstract: Recent innovations in reconstructing large scale, full-precision, neuron-synapse-scale connectomes demand subsequent improvements to graph analysis methods to keep up with the growing complexity and size of the data. One such tool is the recently introduced directed $q$-analysis. We present numerous improvements, theoretical and applied, to this technique: on the theoretical side, we introduce modified definitions for key elements of directed $q$-analysis, which remedy a well-hidden and previously undetected bias. This also leads to new, beneficial perspectives to the associated computational challenges. Most importantly, we present a high-speed, publicly available, low-level implementation that provides speed-ups of several orders of magnitude on C. Elegans. Furthermore, the speed gains grow with the size of the considered graph. This is made possible due to the mathematical and algorithmic improvements as well as a carefully crafted implementation. These speed-ups enable, for the first time, the analysis of full-sized connectomes such as those obtained by recent reconstructive methods. Additionally, the speed-ups allow comparative analysis to corresponding null models, appropriately designed randomly structured artificial graphs that do not correspond to actual brains. This, in turn, allows for assessing the efficacy and usefulness of directed $q$-analysis for studying the brain. We report on the results in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04596v3</guid>
      <category>q-bio.QM</category>
      <category>math.AT</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Felix Windisch, Florian Unger</dc:creator>
    </item>
    <item>
      <title>MAGE: Model-Level Graph Neural Networks Explanations via Motif-based Graph Generation</title>
      <link>https://arxiv.org/abs/2405.12519</link>
      <description>arXiv:2405.12519v2 Announce Type: replace-cross 
Abstract: Graph Neural Networks (GNNs) have shown remarkable success in molecular tasks, yet their interpretability remains challenging. Traditional model-level explanation methods like XGNN and GNNInterpreter often fail to identify valid substructures like rings, leading to questionable interpretability. This limitation stems from XGNN's atom-by-atom approach and GNNInterpreter's reliance on average graph embeddings, which overlook the essential structural elements crucial for molecules. To address these gaps, we introduce an innovative \textbf{M}otif-b\textbf{A}sed \textbf{G}NN \textbf{E}xplainer (MAGE) that uses motifs as fundamental units for generating explanations. Our approach begins with extracting potential motifs through a motif decomposition technique. Then, we utilize an attention-based learning method to identify class-specific motifs. Finally, we employ a motif-based graph generator for each class to create molecular graph explanations based on these class-specific motifs. This novel method not only incorporates critical substructures into the explanations but also guarantees their validity, yielding results that are human-understandable. Our proposed method's effectiveness is demonstrated through quantitative and qualitative assessments conducted on six real-world molecular datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.12519v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 25 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhaoning Yu, Hongyang Gao</dc:creator>
    </item>
  </channel>
</rss>
