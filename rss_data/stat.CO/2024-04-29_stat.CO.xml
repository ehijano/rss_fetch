<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Apr 2024 04:00:59 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Doubly Adaptive Importance Sampling</title>
      <link>https://arxiv.org/abs/2404.18556</link>
      <description>arXiv:2404.18556v1 Announce Type: new 
Abstract: We propose an adaptive importance sampling scheme for Gaussian approximations of intractable posteriors. Optimization-based approximations like variational inference can be too inaccurate while existing Monte Carlo methods can be too slow. Therefore, we propose a hybrid where, at each iteration, the Monte Carlo effective sample size can be guaranteed at a fixed computational cost by interpolating between natural-gradient variational inference and importance sampling. The amount of damping in the updates adapts to the posterior and guarantees the effective sample size. Gaussianity enables the use of Stein's lemma to obtain gradient-based optimization in the highly damped variational inference regime and a reduction of Monte Carlo error for undamped adaptive importance sampling. The result is a generic, embarrassingly parallel and adaptive posterior approximation method. Numerical studies on simulated and real data show its competitiveness with other, less general methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18556v1</guid>
      <category>stat.CO</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Willem van den Boom, Andrea Cremaschi, Alexandre H. Thiery</dc:creator>
    </item>
    <item>
      <title>DeepVARMA: A Hybrid Deep Learning and VARMA Model for Chemical Industry Index Forecasting</title>
      <link>https://arxiv.org/abs/2404.17615</link>
      <description>arXiv:2404.17615v1 Announce Type: cross 
Abstract: Since the chemical industry index is one of the important indicators to measure the development of the chemical industry, forecasting it is critical for understanding the economic situation and trends of the industry. Taking the multivariable nonstationary series-synthetic material index as the main research object, this paper proposes a new prediction model: DeepVARMA, and its variants Deep-VARMA-re and DeepVARMA-en, which combine LSTM and VARMAX models. The new model firstly uses the deep learning model such as the LSTM remove the trends of the target time series and also learn the representation of endogenous variables, and then uses the VARMAX model to predict the detrended target time series with the embeddings of endogenous variables, and finally combines the trend learned by the LSTM and dependency learned by the VARMAX model to obtain the final predictive values. The experimental results show that (1) the new model achieves the best prediction accuracy by combining the LSTM encoding of the exogenous variables and the VARMAX model. (2) In multivariate non-stationary series prediction, DeepVARMA uses a phased processing strategy to show higher adaptability and accuracy compared to the traditional VARMA model as well as the machine learning models LSTM, RF and XGBoost. (3) Compared with smooth sequence prediction, the traditional VARMA and VARMAX models fluctuate more in predicting non-smooth sequences, while DeepVARMA shows more flexibility and robustness. This study provides more accurate tools and methods for future development and scientific decision-making in the chemical industry.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17615v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiang Li, Hu Yang</dc:creator>
    </item>
    <item>
      <title>Using Pre-training and Interaction Modeling for ancestry-specific disease prediction in UK Biobank</title>
      <link>https://arxiv.org/abs/2404.17626</link>
      <description>arXiv:2404.17626v1 Announce Type: cross 
Abstract: Recent genome-wide association studies (GWAS) have uncovered the genetic basis of complex traits, but show an under-representation of non-European descent individuals, underscoring a critical gap in genetic research. Here, we assess whether we can improve disease prediction across diverse ancestries using multiomic data. We evaluate the performance of Group-LASSO INTERaction-NET (glinternet) and pretrained lasso in disease prediction focusing on diverse ancestries in the UK Biobank. Models were trained on data from White British and other ancestries and validated across a cohort of over 96,000 individuals for 8 diseases. Out of 96 models trained, we report 16 with statistically significant incremental predictive performance in terms of ROC-AUC scores. These findings suggest that advanced statistical methods that borrow information across multiple ancestries may improve disease risk prediction, but with limited benefit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17626v1</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Le Menestrel, Erin Craig, Robert Tibshirani, Trevor Hastie, Manuel Rivas</dc:creator>
    </item>
    <item>
      <title>Likelihood Based Inference in Fully and Partially Observed Exponential Family Graphical Models with Intractable Normalizing Constants</title>
      <link>https://arxiv.org/abs/2404.17763</link>
      <description>arXiv:2404.17763v1 Announce Type: cross 
Abstract: Probabilistic graphical models that encode an underlying Markov random field are fundamental building blocks of generative modeling to learn latent representations in modern multivariate data sets with complex dependency structures. Among these, the exponential family graphical models are especially popular, given their fairly well-understood statistical properties and computational scalability to high-dimensional data based on pseudo-likelihood methods. These models have been successfully applied in many fields, such as the Ising model in statistical physics and count graphical models in genomics. Another strand of models allows some nodes to be latent, so as to allow the marginal distribution of the observable nodes to depart from exponential family to capture more complex dependence. These approaches form the basis of generative models in artificial intelligence, such as the Boltzmann machines and their restricted versions. A fundamental barrier to likelihood-based (i.e., both maximum likelihood and fully Bayesian) inference in both fully and partially observed cases is the intractability of the likelihood. The usual workaround is via adopting pseudo-likelihood based approaches, following the pioneering work of Besag (1974). The goal of this paper is to demonstrate that full likelihood based analysis of these models is feasible in a computationally efficient manner. The chief innovation lies in using a technique of Geyer (1991) to estimate the intractable normalizing constant, as well as its gradient, for intractable graphical models. Extensive numerical results, supporting theory and comparisons with pseudo-likelihood based approaches demonstrate the applicability of the proposed method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17763v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yujie Chen, Anindya Bhadra, Antik Chakraborty</dc:creator>
    </item>
    <item>
      <title>PWEXP: An R Package Using Piecewise Exponential Model for Study Design and Event/Timeline Prediction</title>
      <link>https://arxiv.org/abs/2404.17772</link>
      <description>arXiv:2404.17772v1 Announce Type: cross 
Abstract: Parametric assumptions such as exponential distribution are commonly used in clinical trial design and analysis. However, violation of distribution assumptions can introduce biases in sample size and power calculations. Piecewise exponential (PWE) hazard model partitions the hazard function into segments each with constant hazards and is easy for interpretation and computation. Due to its piecewise property, PWE can fit a wide range of survival curves and accurately predict the future number of events and analysis time in event-driven clinical trials, thus enabling more flexible and reliable study designs. Compared with other existing approaches, the PWE model provides a superior balance of flexibility and robustness in model fitting and prediction. The proposed PWEXP package is designed for estimating and predicting PWE hazard models for right-censored data. By utilizing well-established criteria such as AIC, BIC, and cross-validation log-likelihood, the PWEXP package chooses the optimal number of change-points and determines the optimal position of change-points. With its particular goodness-of-fit, the PWEXP provides accurate and robust hazard estimation, which can be used for reliable power calculation at study design and timeline prediction at study conduct. The package also offers visualization functions to facilitate the interpretation of survival curve fitting results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17772v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianchen Xu, Rachael Wen</dc:creator>
    </item>
    <item>
      <title>Uncertainty quantification for iterative algorithms in linear models with application to early stopping</title>
      <link>https://arxiv.org/abs/2404.17856</link>
      <description>arXiv:2404.17856v1 Announce Type: cross 
Abstract: This paper investigates the iterates $\hbb^1,\dots,\hbb^T$ obtained from iterative algorithms in high-dimensional linear regression problems, in the regime where the feature dimension $p$ is comparable with the sample size $n$, i.e., $p \asymp n$. The analysis and proposed estimators are applicable to Gradient Descent (GD), proximal GD and their accelerated variants such as Fast Iterative Soft-Thresholding (FISTA). The paper proposes novel estimators for the generalization error of the iterate $\hbb^t$ for any fixed iteration $t$ along the trajectory. These estimators are proved to be $\sqrt n$-consistent under Gaussian designs. Applications to early-stopping are provided: when the generalization error of the iterates is a U-shape function of the iteration $t$, the estimates allow to select from the data an iteration $\hat t$ that achieves the smallest generalization error along the trajectory. Additionally, we provide a technique for developing debiasing corrections and valid confidence intervals for the components of the true coefficient vector from the iterate $\hbb^t$ at any finite iteration $t$. Extensive simulations on synthetic data illustrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17856v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre C. Bellec, Kai Tan</dc:creator>
    </item>
    <item>
      <title>Estimation of uncertainties in the density driven flow in fractured porous media using MLMC</title>
      <link>https://arxiv.org/abs/2404.18003</link>
      <description>arXiv:2404.18003v1 Announce Type: cross 
Abstract: We use the Multi Level Monte Carlo method to estimate uncertainties in a Henry-like salt water intrusion problem with a fracture. The flow is induced by the variation of the density of the fluid phase, which depends on the mass fraction of salt. We assume that the fracture has a known fixed location but an uncertain aperture. Other input uncertainties are the porosity and permeability fields and the recharge. In our setting, porosity and permeability vary spatially and recharge is time-dependent. For each realisation of these uncertain parameters, the evolution of the mass fraction and pressure fields is modelled by a system of non-linear and time-dependent PDEs with a jump of the solution at the fracture. The uncertainties propagate into the distribution of the salt concentration, which is an important characteristic of the quality of water resources. We show that the multilevel Monte Carlo (MLMC) method is able to reduce the overall computational cost compared to classical Monte Carlo methods. This is achieved by balancing discretisation and statistical errors. Multiple scenarios are evaluated at different spatial and temporal mesh levels. The deterministic solver ug4 is run in parallel to calculate all stochastic scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18003v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitry Logashenko, Alexander Litvinenko, Raul Tempone, Gabriel Wittum</dc:creator>
    </item>
    <item>
      <title>Using Exponential Histograms to Approximate the Quantiles of Heavy- and Light-Tailed Data</title>
      <link>https://arxiv.org/abs/2404.18024</link>
      <description>arXiv:2404.18024v1 Announce Type: cross 
Abstract: Exponential histograms, with bins of the form $\left\{ \left(\rho^{k-1},\rho^{k}\right]\right\} _{k\in\mathbb{Z}}$, for $\rho&gt;1$, straightforwardly summarize the quantiles of streaming data sets (Masson et al. 2019). While they guarantee the relative accuracy of their estimates, they appear to use only $\log n$ values to summarize $n$ inputs. We study four aspects of exponential histograms -- size, accuracy, occupancy, and largest gap size -- when inputs are i.i.d. $\mathrm{Exp}\left(\lambda\right)$ or i.i.d. $\mathrm{Pareto}\left(\nu,\beta\right)$, taking $\mathrm{Exp}\left(\lambda\right)$ (or, $\mathrm{Pareto}\left(\nu,\beta\right)$) to represent all light- (or, heavy-) tailed distributions. We show that, in these settings, size grows like $\log n$ and takes on a Gumbel distribution as $n$ grows large. We bound the missing mass to the right of the histogram and the mass of its final bin and show that occupancy grows apace with size. Finally, we approximate the size of the largest number of consecutive, empty bins. Our study gives a deeper and broader view of this low-memory approach to quantile estimation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18024v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philip T. Labo</dc:creator>
    </item>
    <item>
      <title>Semiparametric fiducial inference</title>
      <link>https://arxiv.org/abs/2404.18779</link>
      <description>arXiv:2404.18779v1 Announce Type: cross 
Abstract: R. A. Fisher introduced the concept of fiducial as a potential replacement for the Bayesian posterior distribution in the 1930s. During the past century, fiducial approaches have been explored in various parametric and nonparametric settings. However, to the best of our knowledge, no fiducial inference has been developed in the realm of semiparametric statistics. In this paper, we propose a novel fiducial approach for semiparametric models. To streamline our presentation, we use the Cox proportional hazards model, which is the most popular model for the analysis of survival data, as a running example. Other models and extensions are also discussed. In our experiments, we find our method to perform well especially in situations when the maximum likelihood estimator fails.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18779v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Cui, Jan Hannig, Paul Edlefsen</dc:creator>
    </item>
    <item>
      <title>Accurate adaptive deep learning method for solving elliptic problems</title>
      <link>https://arxiv.org/abs/2404.18838</link>
      <description>arXiv:2404.18838v1 Announce Type: cross 
Abstract: Deep learning method is of great importance in solving partial differential equations. In this paper, inspired by the failure-informed idea proposed by Gao et.al. (SIAM Journal on Scientific Computing 45(4)(2023)) and as an improvement, a new accurate adaptive deep learning method is proposed for solving elliptic problems, including the interface problems and the convection-dominated problems. Based on the failure probability framework, the piece-wise uniform distribution is used to approximate the optimal proposal distribution and an kernel-based method is proposed for efficient sampling. Together with the improved Levenberg-Marquardt optimization method, the proposed adaptive deep learning method shows great potential in improving solution accuracy. Numerical tests on the elliptic problems without interface conditions, on the elliptic interface problem, and on the convection-dominated problems demonstrate the effectiveness of the proposed method, as it reduces the relative errors by a factor varying from $10^2$ to $10^4$ for different cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18838v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jingyong Ying, Yaqi Xie, Jiao Li, Hongqiao Wang</dc:creator>
    </item>
    <item>
      <title>VT-MRF-SPF: Variable Target Markov Random Field Scalable Particle Filter</title>
      <link>https://arxiv.org/abs/2404.18857</link>
      <description>arXiv:2404.18857v1 Announce Type: cross 
Abstract: Markov random fields (MRFs) are invaluable tools across diverse fields, and spatiotemporal MRFs (STMRFs) amplify their effectiveness by integrating spatial and temporal dimensions. However, modeling spatiotemporal data introduces additional hurdles, including dynamic spatial dimensions and partial observations, prevalent in scenarios like disease spread analysis and environmental monitoring. Tracking high-dimensional targets with complex spatiotemporal interactions over extended periods poses significant challenges in accuracy, efficiency, and computational feasibility. To tackle these obstacles, we introduce the variable target MRF scalable particle filter (VT-MRF-SPF), a fully online learning algorithm designed for high-dimensional target tracking over STMRFs with varying dimensions under partial observation. We rigorously guarantee algorithm performance, explicitly indicating overcoming the curse of dimensionality. Additionally, we provide practical guidelines for tuning graphical parameters, leading to superior performance in extensive examinations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.18857v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ning Ning</dc:creator>
    </item>
    <item>
      <title>AI-driven non-intrusive uncertainty quantification of advanced nuclear fuels for digital twin-enabling technology</title>
      <link>https://arxiv.org/abs/2211.13687</link>
      <description>arXiv:2211.13687v3 Announce Type: replace 
Abstract: In response to the urgent need to establish AI/ML-integrated Digital Twin (DT) technology within next-generation nuclear systems, advancements in modeling methods and simulation codes are necessary. The increased complexity of models demands significant computational resources to quantify their uncertainties. To address this challenge, a data-driven non-intrusive uncertainty quantification method via polynomial chaos expansion is introduced as an efficient strategy within the finite element analysis-based fuel performance code BISON. Models of and fuels, alongside SiC/SiC cladding material, were prepared to demonstrate the proposed method. The impact of four independent uncertain input variables on the system output was quantified, requiring fewer than 100 BISON simulations for each model. This approach not only accelerates the modeling and simulation task but also enhances the reliability in the development of DT-enabling technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.13687v3</guid>
      <category>stat.CO</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.pnucene.2024.105177</arxiv:DOI>
      <arxiv:journal_reference>Progress in Nuclear Energy 172 (2024): 105177</arxiv:journal_reference>
      <dc:creator>Kazuma Kobayashi, Dinesh Kumar, Syed Bahauddin Alam</dc:creator>
    </item>
    <item>
      <title>Calibrar: an R package for fitting complex ecological models</title>
      <link>https://arxiv.org/abs/1603.03141</link>
      <description>arXiv:1603.03141v2 Announce Type: replace-cross 
Abstract: The fitting or parameter estimation of complex ecological models is a challenging optimisation task, with a notable lack of tools for fitting complex, long runtime or stochastic models. calibrar is an R package that is dedicated to the fitting of complex models to data. It is a generic tool that can be used for any type of model, especially those with non-differentiable objective functions and long runtime, including Individual Based Models. calibrar supports multiple phases and constrained optimisation, includes 18 optimisation algorithms, including derivative-based and heuristic ones. It supports any type of parallelization, the restart of interrupted optimisations for long runtime models and the combination of different optimisation methods during the multiple phases of the calibration. User-level expertise in R is necessary to handle calibration experiments with calibrar, but there is no need to modify the model's code, which can be programmed in any language. It implements maximum likelihood estimation methods and automated construction of the objective function from simulated model outputs. For more experienced users, calibrar allows the implementation of user-defined objective functions. The package source code is fully accessible and can be installed directly from CRAN.</description>
      <guid isPermaLink="false">oai:arXiv.org:1603.03141v2</guid>
      <category>q-bio.QM</category>
      <category>math.OC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ricardo Oliveros-Ramos, Yunne-Jai Shin</dc:creator>
    </item>
    <item>
      <title>Explainable, Interpretable &amp; Trustworthy AI for Intelligent Digital Twin: Case Study on Remaining Useful Life</title>
      <link>https://arxiv.org/abs/2301.06676</link>
      <description>arXiv:2301.06676v2 Announce Type: replace-cross 
Abstract: Artificial intelligence (AI) and Machine learning (ML) are increasingly used in energy and engineering systems, but these models must be fair, unbiased, and explainable. It is critical to have confidence in AI's trustworthiness. ML techniques have been useful in predicting important parameters and in improving model performance. However, for these AI techniques to be useful for making decisions, they need to be audited, accounted for, and easy to understand. Therefore, the use of explainable AI (XAI) and interpretable machine learning (IML) is crucial for the accurate prediction of prognostics, such as remaining useful life (RUL), in a digital twin system, to make it intelligent while ensuring that the AI model is transparent in its decision-making processes and that the predictions it generates can be understood and trusted by users. By using AI that is explainable, interpretable, and trustworthy, intelligent digital twin systems can make more accurate predictions of RUL, leading to better maintenance and repair planning, and ultimately, improved system performance. The objective of this paper is to explain the ideas of XAI and IML and to justify the important role of AI/ML in the digital twin framework and components, which requires XAI to understand the prediction better. This paper explains the importance of XAI and IML in both local and global aspects to ensure the use of trustworthy AI/ML applications for RUL prediction. We used the RUL prediction for the XAI and IML studies and leveraged the integrated Python toolbox for interpretable machine learning~(PiML).</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06676v2</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2023.107620</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence 129 (2024): 107620</arxiv:journal_reference>
      <dc:creator>Kazuma Kobayashi, Syed Bahauddin Alam</dc:creator>
    </item>
    <item>
      <title>Improved generalization with deep neural operators for engineering systems: Path towards digital twin</title>
      <link>https://arxiv.org/abs/2301.06701</link>
      <description>arXiv:2301.06701v3 Announce Type: replace-cross 
Abstract: Neural Operator Networks (ONets) represent a novel advancement in machine learning algorithms, offering a robust and generalizable alternative for approximating partial differential equations (PDEs) solutions. Unlike traditional Neural Networks (NN), which directly approximate functions, ONets specialize in approximating mathematical operators, enhancing their efficacy in addressing complex PDEs. In this work, we evaluate the capabilities of Deep Operator Networks (DeepONets), an ONets implementation using a branch/trunk architecture. Three test cases are studied: a system of ODEs, a general diffusion system, and the convection/diffusion Burgers equation. It is demonstrated that DeepONets can accurately learn the solution operators, achieving prediction accuracy scores above 0.96 for the ODE and diffusion problems over the observed domain while achieving zero shot (without retraining) capability. More importantly, when evaluated on unseen scenarios (zero shot feature), the trained models exhibit excellent generalization ability. This underscores ONets vital niche for surrogate modeling and digital twin development across physical systems. While convection-diffusion poses a greater challenge, the results confirm the promise of ONets and motivate further enhancements to the DeepONet algorithm. This work represents an important step towards unlocking the potential of digital twins through robust and generalizable surrogates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.06701v3</guid>
      <category>cs.LG</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.engappai.2024.107844</arxiv:DOI>
      <arxiv:journal_reference>Engineering Applications of Artificial Intelligence 131 (2024): 107844</arxiv:journal_reference>
      <dc:creator>Kazuma Kobayashi, James Daniell, Syed Bahauddin Alam</dc:creator>
    </item>
    <item>
      <title>Subsampling Error in Stochastic Gradient Langevin Diffusions</title>
      <link>https://arxiv.org/abs/2305.13882</link>
      <description>arXiv:2305.13882v2 Announce Type: replace-cross 
Abstract: The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to approximate Bayesian posterior distributions in statistical learning procedures with large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC) algorithms, SGLD is not stationary with respect to the posterior distribution; two sources of error appear: The first error is introduced by an Euler--Maruyama discretisation of a Langevin diffusion process, the second error comes from the data subsampling that enables its use in large-scale data settings. In this work, we consider an idealised version of SGLD to analyse the method's pure subsampling error that we then see as a best-case error for diffusion-based subsampling MCMC methods. Indeed, we introduce and study the Stochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov process that follows the Langevin diffusion corresponding to a data subset and switches this data subset after exponential waiting times. There, we show the exponential ergodicity of SLGDiff and that the Wasserstein distance between the posterior and the limiting distribution of SGLDiff is bounded above by a fractional power of the mean waiting time. We bring our results into context with other analyses of SGLD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.13882v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kexin Jin, Chenguang Liu, Jonas Latz</dc:creator>
    </item>
    <item>
      <title>Deep Neural Operator Driven Real Time Inference for Nuclear Systems to Enable Digital Twin Solutions</title>
      <link>https://arxiv.org/abs/2308.07523</link>
      <description>arXiv:2308.07523v2 Announce Type: replace-cross 
Abstract: This paper focuses on the feasibility of Deep Neural Operator (DeepONet) as a robust surrogate modeling method within the context of digital twin (DT) for nuclear energy systems. Through benchmarking and evaluation, this study showcases the generalizability and computational efficiency of DeepONet in solving a challenging particle transport problem. DeepONet also exhibits remarkable prediction accuracy and speed, outperforming traditional ML methods, making it a suitable algorithm for real-time DT inference. However, the application of DeepONet also reveals challenges related to optimal sensor placement and model evaluation, critical aspects of real-world implementation. Addressing these challenges will further enhance the method's practicality and reliability. Overall, DeepONet presents a promising and transformative nuclear engineering research and applications tool. Its accurate prediction and computational efficiency capabilities can revolutionize DT systems, advancing nuclear engineering research. This study marks an important step towards harnessing the power of surrogate modeling techniques in critical engineering domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.07523v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1038/s41598-024-51984-x</arxiv:DOI>
      <arxiv:journal_reference>Sci Rep 14, 2101 (2024)</arxiv:journal_reference>
      <dc:creator>Kazuma Kobayashi, Syed Bahauddin Alam</dc:creator>
    </item>
  </channel>
</rss>
