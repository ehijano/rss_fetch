<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Oct 2025 01:41:29 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Near Optimal Hardness of Approximating $k$-CSP</title>
      <link>https://arxiv.org/abs/2510.23991</link>
      <description>arXiv:2510.23991v1 Announce Type: new 
Abstract: We show that for every $k\in\mathbb{N}$ and $\varepsilon&gt;0$, for large enough alphabet $R$, given a $k$-CSP with alphabet size $R$, it is NP-hard to distinguish between the case that there is an assignment satisfying at least $1-\varepsilon$ fraction of the constraints, and the case no assignment satisfies more than $1/R^{k-1-\varepsilon}$ of the constraints. This result improves upon prior work of [Chan, Journal of the ACM 2016], who showed the same result with weaker soundness of $O(k/R^{k-2})$, and nearly matches the trivial approximation algorithm that finds an assignment satisfying at least $1/R^{k-1}$ fraction of the constraints.
  Our proof follows the approach of a recent work by the authors, wherein the above result is proved for $k=2$. Our main new ingredient is a counting lemma for hyperedges between pseudo-random sets in the Grassmann graphs, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.23991v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dor Minzer, Kai Zhe Zheng</dc:creator>
    </item>
    <item>
      <title>Reachability of Independent Sets and Vertex Covers Under Extended Reconfiguration Rules</title>
      <link>https://arxiv.org/abs/2510.24226</link>
      <description>arXiv:2510.24226v1 Announce Type: new 
Abstract: In reconfiguration problems, we are given two feasible solutions to a graph problem and asked whether one can be transformed into the other via a sequence of feasible intermediate solutions under a given reconfiguration rule. While earlier work focused on modifying a single element at a time, recent studies have started examining how different rules impact computational complexity. Motivated by recent progress, we study Independent Set Reconfiguration (ISR) and Vertex Cover Reconfiguration (VCR) under the $k$-Token Jumping ($k$-TJ) and $k$-Token Sliding ($k$-TS) models. In $k$-TJ, up to $k$ vertices may be replaced, while $k$-TS additionally requires a perfect matching between removed and added vertices. It is known that the complexity of ISR crucially depends on $k$, ranging from PSPACE-complete and NP-complete to polynomial-time solvable. In this paper, we further explore the gradient of computational complexity of the problems. We first show that ISR under $k$-TJ with $k = |I| - \mu$ remains NP-hard when $\mu$ is any fixed positive integer and the input graph is restricted to graphs of maximum degree 3 or planar graphs of maximum degree 4, where $|I|$ is the size of feasible solutions. In addition, we prove that the problem belongs to NP not only for $\mu=O(1)$ but also for $\mu = O(\log |I|)$. In contrast, we show that VCR under $k$-TJ is in XP when parameterized by $\mu = |S| - k$, where $|S|$ is the size of feasible solutions. Furthermore, we establish the PSPACE-completeness of ISR and VCR under both $k$-TJ and $k$-TS on several graph classes, for fixed $k$ as well as superconstant $k$ relative to the size of feasible solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.24226v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuichi Hirahara, Naoto Ohsaka, Tatsuhiro Suga, Akira Suzuki, Yuma Tamura, Xiao Zhou</dc:creator>
    </item>
    <item>
      <title>On bounded depth proofs for Tseitin formulas on the grid; revisited</title>
      <link>https://arxiv.org/abs/2209.05839</link>
      <description>arXiv:2209.05839v3 Announce Type: replace 
Abstract: We study Frege proofs using depth-$d$ Boolean formulas for the Tseitin contradiction on $n \times n$ grids. We prove that if each line in the proof is of size $M$ then the number of lines is exponential in $n/(\log M)^{O(d)}$. This strengthens a recent result of Pitassi et al. [PRT22]. The key technical step is a multi-switching lemma extending the switching lemma of H\r{a}stad [H\r{a}s20] for a space of restrictions related to the Tseitin contradiction. The strengthened lemma also allows us to improve the lower bound for standard proof size of bounded depth Frege refutations from exponential in $\tilde \Omega (n^{1/59d})$ to exponential in $\tilde \Omega (n^{1/d})$. This strengthens the bounds given in the preliminary version of this paper [HR22].</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.05839v3</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1137/22M153851X</arxiv:DOI>
      <dc:creator>Johan H\r{a}stad, Kilian Risse</dc:creator>
    </item>
    <item>
      <title>Computational Complexity in Property Testing</title>
      <link>https://arxiv.org/abs/2510.05927</link>
      <description>arXiv:2510.05927v2 Announce Type: replace 
Abstract: We initiate a systematic study of the computational complexity of property testing, focusing on the relationship between query and time complexity. While traditional work in property testing has emphasized query complexity, relatively little is known about the computational hardness of property testers. Our goal is to chart the landscape of time-query interplay and develop tools for proving time complexity lower bounds. Our first contribution is a pair of time-query hierarchy theorems for property testing. For all suitable nondecreasing functions $q(n)$ and $t(n)$ with $t(n)\geq q(n)$, we construct properties with query complexity $\tilde{\Theta}(q(n))$ and time complexity $\tilde\Omega(t(n))$. Our weak hierarchy holds unconditionally, whereas the strong version-assuming the Strong Exponential Time Hypothesis-provides better control over the time complexity of the constructed properties.
  We then turn to halfspaces in $\mathbb{R}^d$, a fundamental class in property testing and learning theory. We study the problem of approximating the distance from the input function to the nearest halfspace within additive error $\epsilon$. For the distribution-free distance approximation problem, known algorithms achieve query complexity $O(d/\epsilon^2)$, but take time $\tilde{\Theta}(1/\epsilon^d)$. We provide a fine-grained justification for this gap: assuming the $k$-SUM conjecture, any algorithm must have running time ${\Omega}(1/\epsilon^{d/2})$. This fine-grained lower bound yields a provable separation between query and time complexity for a natural and well-studied (tolerant) testing problem. We also prove that any Statistical Query (SQ) algorithm under the standard Gaussian distribution requires $(1/\epsilon)^{\Omega(d)}$ queries if the queries are answered with additive error up to $\epsilon^{\Omega(d)}$, revealing a fundamental barrier even in the distribution-specific setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.05927v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Renato Ferreira Pinto Jr., Diptaksho Palit, Sofya Raskhodnikova</dc:creator>
    </item>
    <item>
      <title>Characterizing the Distinguishability of Product Distributions through Multicalibration</title>
      <link>https://arxiv.org/abs/2412.03562</link>
      <description>arXiv:2412.03562v5 Announce Type: replace-cross 
Abstract: Given a sequence of samples $x_1, \dots , x_k$ promised to be drawn from one of two distributions $X_0, X_1$, a well-studied problem in statistics is to decide $\textit{which}$ distribution the samples are from. Information theoretically, the maximum advantage in distinguishing the two distributions given $k$ samples is captured by the total variation distance between $X_0^{\otimes k}$ and $X_1^{\otimes k}$. However, when we restrict our attention to $\textit{efficient distinguishers}$ (i.e., small circuits) of these two distributions, exactly characterizing the ability to distinguish $X_0^{\otimes k}$ and $X_1^{\otimes k}$ is more involved and less understood.
  In this work, we give a general way to reduce bounds on the computational indistinguishability of $X_0$ and $X_1$ to bounds on the $\textit{information-theoretic}$ indistinguishability of some specific, related variables $\widetilde{X}_0$ and $\widetilde{X}_1$. As a consequence, we prove a new, tight characterization of the number of samples $k$ needed to efficiently distinguish $X_0^{\otimes k}$ and $X_1^{\otimes k}$ with constant advantage as
  \[
  k = \Theta\left(d_H^{-2}\left(\widetilde{X}_0, \widetilde{X}_1\right)\right),
  \] which is the inverse of the squared Hellinger distance $d_H$ between two distributions $\widetilde{X}_0$ and $\widetilde{X}_1$ that are computationally indistinguishable from $X_0$ and $X_1$. Likewise, our framework can be used to re-derive a result of Halevi and Rabin (TCC 2008) and Geier (TCC 2022), proving nearly-tight bounds on how computational indistinguishability scales with the number of samples for arbitrary product distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03562v5</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Cassandra Marcussen, Aaron Putterman, Salil Vadhan</dc:creator>
    </item>
    <item>
      <title>Induced Minor Models. II. Sufficient conditions for polynomial-time detection of induced minors</title>
      <link>https://arxiv.org/abs/2501.00161</link>
      <description>arXiv:2501.00161v4 Announce Type: replace-cross 
Abstract: The $H$-Induced Minor Containment problem ($H$-IMC) consists in deciding if a fixed graph $H$ is an induced minor of a graph $G$ given as input, that is, whether $H$ can be obtained from $G$ by deleting vertices and contracting edges. Equivalently, the problem asks if there exists an induced minor model of $H$ in $G$, that is, a collection of disjoint subsets of vertices of $G$, each inducing a connected subgraph, such that contracting each subgraph into a single vertex results in $H$.
  It is known that $H$-IMC is NP-complete for several graphs $H$, even when $H$ is a tree. In this work, we investigate which properties of $H$ guarantee the existence of an induced minor model whose structure can be leveraged to solve the problem in polynomial time. This allows us to identify four infinite families of graphs $H$ that enjoy such properties. Moreover, we show that if the input graph $G$ excludes long induced paths, then $H$-IMC is polynomial-time solvable for any fixed graph $H$. As a byproduct of our results, this implies that $H$-IMC is polynomial-time solvable for all graphs $H$ with at most $5$ vertices, except for three open cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00161v4</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Wed, 29 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Dallard, Ma\"el Dumas, Claire Hilaire, Anthony Perez</dc:creator>
    </item>
  </channel>
</rss>
