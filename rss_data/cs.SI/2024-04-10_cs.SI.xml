<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SI</link>
    <description>cs.SI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>The increasing fragmentation of global science limits the diffusion of ideas</title>
      <link>https://arxiv.org/abs/2404.05861</link>
      <description>arXiv:2404.05861v1 Announce Type: new 
Abstract: The global scientific landscape emerges from a complex interplay of collaboration and competition, where nations vie for dominance while simultaneously fostering the diffusion of knowledge on a global scale. This raises crucial questions: What underlying patterns govern international scientific recognition and influence? How does this structure impact knowledge dissemination? Traditional models view the global scientific ecosystem through a core-periphery lens, with Western nations dominating knowledge production. Here, we investigate the dynamics of international scientific recognition through the lens of national preferences, introducing a novel signed measure to characterize national citation preferences and enabling a network analysis of international scientific recognition. We find that scientific recognition is related to cultural and political factors in addition to economic strength and scientific quality. Our analysis challenges the conventional core-periphery narrative, uncovering instead several communities of international knowledge production that are rapidly fragmenting the scientific recognition ecosystem. Moreover, we provide compelling evidence that this network significantly constrains the diffusion of ideas across international borders. The resulting network framework for global scientific recognition sheds light on the barriers and opportunities for collaboration, innovation, and the equitable recognition of scientific advancements, with significant consequences for policymakers seeking to foster inclusive and impactful international scientific endeavors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05861v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander J. Gates, Indraneel Mane, Jianjian Gao</dc:creator>
    </item>
    <item>
      <title>Design of Transit-Centric Multimodal Urban Mobility System with Autonomous Mobility-on-Demand</title>
      <link>https://arxiv.org/abs/2404.05885</link>
      <description>arXiv:2404.05885v1 Announce Type: new 
Abstract: This paper addresses the pressing challenge of urban mobility in the context of growing urban populations, changing demand patterns for urban mobility, and emerging technologies like Mobility-on-Demand (MoD) platforms and Autonomous Vehicle (AV). As urban areas swell and demand pattern changes, the integration of Autonomous Mobility-on-Demand (AMoD) systems with existing public transit (PT) networks presents great opportunities to enhancing urban mobility. We propose a novel optimization framework for solving the Transit-Centric Multimodal Urban Mobility with Autonomous Mobility-on-Demand (TCMUM-AMoD) at scale. The system operator (public transit agency) determines the network design and frequency settings of the PT network, fleet sizing and allocations of AMoD system, and the pricing for using the multimodal system with the goal of minimizing passenger disutility. Passengers' mode and route choice behaviors are modeled explicitly using discrete choice models. A first-order approximation algorithm is introduced to solve the problem at scale. Using a case study in Chicago, we showcase the potential to optimize urban mobility across different demand scenarios. To our knowledge, ours is the first paper to jointly optimize transit network design, fleet sizing, and pricing for the multimodal mobility system while considering passengers' mode and route choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05885v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaotong Guo, Jinhua Zhao</dc:creator>
    </item>
    <item>
      <title>Commute with Community: Enhancing Shared Travel through Social Networks</title>
      <link>https://arxiv.org/abs/2404.05987</link>
      <description>arXiv:2404.05987v1 Announce Type: new 
Abstract: Shared mobility redefines urban transportation, offering economic and environmental benefits by reducing pollution and urban congestion. However, in the post-pandemic era, the shared mobility sector is grappling with a crisis of trust, particularly concerning passenger hesistancy towards shared transportation options. To address these problems, in this paper we take social network into consideration and propose a novel carpooling matching framework based on graph neural network and reinforcement learning,increasing the carpooling rate to 48% and reducing the average delay time to 6.1 minutes and average detour distance to 2.8km. Furthermore, we introduce an innovative metric, termed 'tolerance' for mobility scheduling models to effectively quantify users' sensitivity to social distancing. We conduct a sensitivity analysis to demonstrate that our model offers a viable approach to amplify the benefits, delivering resilient strategies for the advancement and proliferation of shared mobility incentives.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05987v1</guid>
      <category>cs.SI</category>
      <category>physics.soc-ph</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Tian Siyuan, Dai Renjie, Wang Junhao, He Zhengxiao</dc:creator>
    </item>
    <item>
      <title>Echo Chambers in the Age of Algorithms: An Audit of Twitter's Friend Recommender System</title>
      <link>https://arxiv.org/abs/2404.06422</link>
      <description>arXiv:2404.06422v1 Announce Type: new 
Abstract: The presence of political misinformation and ideological echo chambers on social media platforms is concerning given the important role that these sites play in the public's exposure to news and current events. Algorithmic systems employed on these platforms are presumed to play a role in these phenomena, but little is known about their mechanisms and effects. In this work, we conduct an algorithmic audit of Twitter's Who-To-Follow friend recommendation system, the first empirical audit that investigates the impact of this algorithm in-situ. We create automated Twitter accounts that initially follow left and right affiliated U.S. politicians during the 2022 U.S. midterm elections and then grow their information networks using the platform's recommender system. We pair the experiment with an observational study of Twitter users who already follow the same politicians. Broadly, we find that while following the recommendation algorithm leads accounts into dense and reciprocal neighborhoods that structurally resemble echo chambers, the recommender also results in less political homogeneity of a user's network compared to accounts growing their networks through social endorsement. Furthermore, accounts that exclusively followed users recommended by the algorithm had fewer opportunities to encounter content centered on false or misleading election narratives compared to choosing friends based on social endorsement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06422v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kayla Duskin, Joseph S. Schafer, Jevin D. West, Emma S. Spiro</dc:creator>
    </item>
    <item>
      <title>On Early-stage Debunking Rumors on Twitter: Leveraging the Wisdom of Weak Learners</title>
      <link>https://arxiv.org/abs/1709.04402</link>
      <description>arXiv:1709.04402v2 Announce Type: replace 
Abstract: Recently a lot of progress has been made in rumor modeling and rumor detection for micro-blogging streams. However, existing automated methods do not perform very well for early rumor detection, which is crucial in many settings, e.g., in crisis situations. One reason for this is that aggregated rumor features such as propagation features, which work well on the long run, are - due to their accumulating characteristic - not very helpful in the early phase of a rumor. In this work, we present an approach for early rumor detection, which leverages Convolutional Neural Networks for learning the hidden representations of individual rumor-related tweets to gain insights on the credibility of each tweets. We then aggregate the predictions from the very beginning of a rumor to obtain the overall event credits (so-called wisdom), and finally combine it with a time series based rumor classification model. Our extensive experiments show a clearly improved classification performance within the critical very first hours of a rumor. For a better understanding, we also conduct an extensive feature evaluation that emphasized on the early stage and shows that the low-level credibility has best predictability at all phases of the rumor lifetime.</description>
      <guid isPermaLink="false">oai:arXiv.org:1709.04402v2</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tu Nguyen, Cheng Li, Claudia Nieder\'ee</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Low and High-level Feature Analysis for Early Rumor Detection on Twitter</title>
      <link>https://arxiv.org/abs/1711.00726</link>
      <description>arXiv:1711.00726v3 Announce Type: replace 
Abstract: Recent work have done a good job in modeling rumors and detecting them over microblog streams. However, the performance of their automatic approaches are not relatively high when looking early in the diffusion. A first intuition is that, at early stage, most of the aggregated rumor features (e.g., propagation features) are not mature and distinctive enough. The objective of rumor debunking in microblogs, however, are to detect these misinformation as early as possible. In this work, we leverage neural models in learning the hidden representations of individual rumor-related tweets at the very beginning of a rumor. Our extensive experiments show that the resulting signal improves our classification performance over time, significantly within the first 10 hours. To deepen the understanding of these low and high-level features in contributing to the model performance over time, we conduct an extensive study on a wide range of high impact rumor features for the 48 hours range. The end model that engages these features are shown to be competitive, reaches over 90% accuracy and out-performs strong baselines in our carefully cured dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:1711.00726v3</guid>
      <category>cs.SI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tu Nguyen</dc:creator>
    </item>
    <item>
      <title>Mathematical Model of Dating Apps' Influence on Sexually Transmitted Diseases Spread</title>
      <link>https://arxiv.org/abs/2310.00341</link>
      <description>arXiv:2310.00341v3 Announce Type: replace 
Abstract: Sexually transmitted diseases (STDs) are a group of pathogens infecting new hosts through sexual interactions. Due to its social and economic burden, multiple models have been proposed to study the spreading of pathogens. In parallel, in the ever-evolving landscape of digital social interactions, the pervasive utilization of dating apps has become a prominent facet of modern society. Despite the surge in popularity and the profound impact on relationship formation, a crucial gap in the literature persists regarding the potential ramifications of dating apps usage on the dynamics of STDs. In this paper, we address this gap by presenting a novel mathematical framework - an extended Susceptible-Infected-Susceptible (SIS) epidemiological model to elucidate the intricate interplay between dating apps engagement and the propagation of STDs. Namely, as dating apps are designed to make users revisit them and have mainly casual sexual interactions with other users, they increase the number of causal partners, which increases the overall spread of STDS. Using extensive simulation, based on real-world data, explore the effect of dating apps adoption and control on the STD spread. We show that an increased adoption of dating apps can result in an STD outbreak if not handled appropriately.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00341v3</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Teddy Lazebnik</dc:creator>
    </item>
    <item>
      <title>Quantifying metadata-block structure relationships in networks using description length</title>
      <link>https://arxiv.org/abs/2311.18705</link>
      <description>arXiv:2311.18705v2 Announce Type: replace 
Abstract: Network analysis is often enriched by including an examination of node metadata. In the context of understanding the mesoscale of networks it is often assumed that node groups based on metadata and node groups based on connectivity patterns are intrinsically linked. Recently, this assumption has been challenged and it has been demonstrated that metadata might be entirely unrelated to structure or, similarly, multiple sets of metadata might be relevant to the structure of a network in different ways. We propose the metablox tool to quantify the relationship between a network's node metadata and its mesoscale structure, measuring the strength of the relationship and the type of structural arrangement exhibited by the metadata. Our tool incorporates a way to distinguish significantly relevant relationships and can be used as part of systematic meta analyses comparing large numbers of networks, which we demonstrate on a number of synthetic and empirical networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.18705v2</guid>
      <category>cs.SI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lena Mangold, Camille Roth</dc:creator>
    </item>
    <item>
      <title>Deep learning for dynamic graphs: models and benchmarks</title>
      <link>https://arxiv.org/abs/2307.06104</link>
      <description>arXiv:2307.06104v4 Announce Type: replace-cross 
Abstract: Recent progress in research on Deep Graph Networks (DGNs) has led to a maturation of the domain of learning on graphs. Despite the growth of this research field, there are still important challenges that are yet unsolved. Specifically, there is an urge of making DGNs suitable for predictive tasks on realworld systems of interconnected entities, which evolve over time. With the aim of fostering research in the domain of dynamic graphs, at first, we survey recent advantages in learning both temporal and spatial information, providing a comprehensive overview of the current state-of-the-art in the domain of representation learning for dynamic graphs. Secondly, we conduct a fair performance comparison among the most popular proposed approaches on node and edge-level tasks, leveraging rigorous model selection and assessment for all the methods, thus establishing a sound baseline for evaluating new architectures and approaches</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.06104v4</guid>
      <category>cs.LG</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/TNNLS.2024.3379735</arxiv:DOI>
      <dc:creator>Alessio Gravina, Davide Bacciu</dc:creator>
    </item>
    <item>
      <title>Exploring the Deceptive Power of LLM-Generated Fake News: A Study of Real-World Detection Challenges</title>
      <link>https://arxiv.org/abs/2403.18249</link>
      <description>arXiv:2403.18249v2 Announce Type: replace-cross 
Abstract: Recent advancements in Large Language Models (LLMs) have enabled the creation of fake news, particularly in complex fields like healthcare. Studies highlight the gap in the deceptive power of LLM-generated fake news with and without human assistance, yet the potential of prompting techniques has not been fully explored. Thus, this work aims to determine whether prompting strategies can effectively narrow this gap. Current LLM-based fake news attacks require human intervention for information gathering and often miss details and fail to maintain context consistency. Therefore, to better understand threat tactics, we propose a strong fake news attack method called conditional Variational-autoencoder-Like Prompt (VLPrompt). Unlike current methods, VLPrompt eliminates the need for additional data collection while maintaining contextual coherence and preserving the intricacies of the original text. To propel future research on detecting VLPrompt attacks, we created a new dataset named VLPrompt fake news (VLPFN) containing real and fake texts. Our experiments, including various detection methods and novel human study metrics, were conducted to assess their performance on our dataset, yielding numerous findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.18249v2</guid>
      <category>cs.CL</category>
      <category>cs.SI</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanshen Sun, Jianfeng He, Limeng Cui, Shuo Lei, Chang-Tien Lu</dc:creator>
    </item>
  </channel>
</rss>
