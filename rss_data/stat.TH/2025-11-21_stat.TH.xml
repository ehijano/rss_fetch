<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Nov 2025 05:02:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>New Empirical Process Tools and Their Applications to Robust Deep ReLU Networks and Phase Transitions for Nonparametric Regression</title>
      <link>https://arxiv.org/abs/2511.15841</link>
      <description>arXiv:2511.15841v1 Announce Type: new 
Abstract: This paper introduces new empirical process tools for analyzing a broad class of statistical learning models under heavy-tailed noise and complex function classes. Our primary contribution is the derivation of two Dudley-type maximal inequalities for expected empirical processes that remove restrictive assumptions such as light tails and uniform boundedness of the function class. These inequalities enlarge the scope of empirical process theory available for statistical learning and nonparametric estimation. Exploiting the new bounds, we establish robustness guarantees for deep ReLU network estimators in Huber and quantile regression. In particular, we prove a unified non-asymptotic sub-Gaussian concentration bound that remains valid even under infinite-variance noise and provide a comprehensive analysis of non-asymptotic robustness for deep Huber estimators across all noise regimes. For deep quantile regression, we provide the first non-asymptotic sub-Gaussian bounds without requiring moment assumptions. As an additional application, our framework yields estimation error bounds for nonparametric least-squares estimators that simultaneously accommodate infinite-variance noise, non-Donsker function classes, and approximation error. Moreover, unlike prior approaches based on specialized multiplier processes, our framework extends to broader empirical risk minimization problems, including the nonparametric generalized linear models and the ``set-structured'' models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15841v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yizhe Ding, Runze Li, Lingzhou Xue</dc:creator>
    </item>
    <item>
      <title>Bias Reduction for nonparametric Estimators applied to functional Data Analysis</title>
      <link>https://arxiv.org/abs/2511.16389</link>
      <description>arXiv:2511.16389v1 Announce Type: new 
Abstract: Compared to nonparametric estimators in the multivariate setting, kernel estimators for functional data models have a larger order of bias. This is problematic for constructing confidence regions or statistical tests since the bias might not be negligible. It stems from the fact that one sided kernels are used where already the first moment of the kernel is different from 0. It cannot be cured by assuming the existence of higher order derivatives. In the following, we propose bias corrected estimators based on the idea in \cite{Cheng2018} which still have an appealing structure, but have a bias of smaller order as in multiple regression settings while the variance is of the same order of magnitude as before. In addition we show asymptotic normality of such estimators and derive uniform rates. The performance of the estimator in finite samples is in addition checked in a simulation study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16389v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Melanie Birke, Tim Greger</dc:creator>
    </item>
    <item>
      <title>How many outbreaks before an epidemic?</title>
      <link>https://arxiv.org/abs/2511.15736</link>
      <description>arXiv:2511.15736v1 Announce Type: cross 
Abstract: In this work, we study the finite-population behaviour of the Reed-Frost epidemic model. Our analysis relies on the exact expression for the final epidemic size, replaced by Monte Carlo simulations in cases where the exact formula becomes numerically unstable. When the initial reproduction number is greater than a critical threshold, the distribution of the final size becomes bimodal. We therefore define the probabilities of small and large outbreaks, providing an intuitive answer to the question posed in the title through simple arguments based on the geometric distribution. Finally, an agent-based simulation confirms that the Reed-Frost model offers a good approximation in the case of the COVID-19 outbreak.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15736v1</guid>
      <category>q-bio.PE</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fabio Rapallo, Enrico Scalas, Pietro Terna</dc:creator>
    </item>
    <item>
      <title>Models with Accelerated Failure Conditionals</title>
      <link>https://arxiv.org/abs/2511.15769</link>
      <description>arXiv:2511.15769v1 Announce Type: cross 
Abstract: Arnold and Arvanitis (2020) introduced a novel bivariate conditionally specified distribution, a distribution in which dependence between two random variables is established by defining the distribution of one variable conditional on the other. This novel conditioning regime was achieved through the use of survival functions, and the approach was termed the accelerated failure conditionals model. In their work, the conditioning framework was constructed using the exponential distribution. Although further generalization was proposed, challenges emerged in deriving the necessary and sufficient conditions for valid joint survival functions. The present study achieves such generalization, extending the conditioning framework to encompass distributional families whose marginal densities may exhibit unimodality and skewness, moving beyond distributional families whose marginal densities are non-increasing. The resulting models are fully specified through closed-form expressions for their moments, with simulations implemented using either a copula-based procedure or the Metropolis-Hastings algorithm. Empirical applications to two datasets, each featuring variables which are unimodal and skewed, demonstrate that the models with flexible, non-monotonic marginal densities yield a superior fit relative to those models with marginal densities restricted to monotonically decaying forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15769v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jared N. Lakhani</dc:creator>
    </item>
    <item>
      <title>Cross-Balancing for Data-Informed Design and Efficient Analysis of Observational Studies</title>
      <link>https://arxiv.org/abs/2511.15896</link>
      <description>arXiv:2511.15896v1 Announce Type: cross 
Abstract: Causal inference starts with a simple idea: compare groups that differ by treatment, not much else. Traditionally, similar groups are constructed using only observed covariates; however, it remains a long-standing challenge to incorporate available outcome data into the study design while preserving valid inference. In this paper, we study the general problem of covariate adjustment, effect estimation, and statistical inference when balancing features are constructed or selected with the aid of outcome information from the data. We propose cross-balancing, a method that uses sample splitting to separate the error in feature construction from the error in weight estimation. Our framework addresses two cases: one where the features are learned functions and one where they are selected from a potentially high-dimensional dictionary. In both cases, we establish mild and general conditions under which cross-balancing produces consistent, asymptotically normal, and efficient estimators. In the learned-function case, cross-balancing achieves finite-sample bias reduction relative to plug-in-type estimators, and is multiply robust when the learned features converge at slow rates. In the variable-selection case, cross-balancing only requires a product condition on how well the selected variables approximate true functions. We illustrate cross-balancing in extensive simulations and an observational study, showing that careful use of outcome information can substantially improve both estimation and inference while maintaining interpretability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15896v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ying Jin, Jos\'e Zubizarreta</dc:creator>
    </item>
    <item>
      <title>Bayesian Semiparametric Causal Inference: Targeted Doubly Robust Estimation of Treatment Effects</title>
      <link>https://arxiv.org/abs/2511.15904</link>
      <description>arXiv:2511.15904v1 Announce Type: cross 
Abstract: We propose a semiparametric Bayesian methodology for estimating the average treatment effect (ATE) within the potential outcomes framework using observational data with high-dimensional nuisance parameters. Our method introduces a Bayesian debiasing procedure that corrects for bias arising from nuisance estimation and employs a targeted modeling strategy based on summary statistics rather than the full data. These summary statistics are identified in a debiased manner, enabling the estimation of nuisance bias via weighted observables and facilitating hierarchical learning of the ATE. By combining debiasing with sample splitting, our approach separates nuisance estimation from inference on the target parameter, reducing sensitivity to nuisance model specification. We establish that, under mild conditions, the marginal posterior for the ATE satisfies a Bernstein-von Mises theorem when both nuisance models are correctly specified and remains consistent and robust when only one is correct, achieving Bayesian double robustness. This ensures asymptotic efficiency and frequentist validity. Extensive simulations confirm the theoretical results, demonstrating accurate point estimation and credible intervals with nominal coverage, even in high-dimensional settings. The proposed framework can also be extended to other causal estimands, and its key principles offer a general foundation for advancing Bayesian semiparametric inference more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.15904v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G\"ozde Sert, Abhishek Chakrabortty, Anirban Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Possibilistic Instrumental Variable Regression</title>
      <link>https://arxiv.org/abs/2511.16029</link>
      <description>arXiv:2511.16029v1 Announce Type: cross 
Abstract: Instrumental variable regression is a common approach for causal inference in the presence of unobserved confounding. However, identifying valid instruments is often difficult in practice. In this paper, we propose a novel method based on possibility theory that performs posterior inference on the treatment effect, conditional on a user-specified set of potential violations of the exogeneity assumption. Our method can provide informative results even when only a single, potentially invalid, instrument is available, offering a natural and principled framework for sensitivity analysis. Simulation experiments and a real-data application indicate strong performance of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16029v1</guid>
      <category>stat.ME</category>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Gregor Steiner, Jeremie Houssineau, Mark F. J. Steel</dc:creator>
    </item>
    <item>
      <title>Estimation of the Coefficient of Variation of Weibull Distribution under Type-I Progressively Interval Censoring: A Simulation-based Approach</title>
      <link>https://arxiv.org/abs/2511.16102</link>
      <description>arXiv:2511.16102v1 Announce Type: cross 
Abstract: Measures of relative variability, such as the Pearson's coefficient of variation (CV$_p$), give much insight into the spread of lifetime distributions, like the Weibull distribution. The estimation of the Weibull CV$_p$ in modern statistics has traditionally been prioritized only when complete data is available. In this article, we estimate the Weibull CV$_p$ and its second-order alternative, denoted as CV$_k$, under type-I progressively interval censoring, which is a typical scenario in survival analysis and reliability theory. Point estimates are obtained using the methods of maximum likelihood, least squares, and the Bayesian approach with MCMC simulation. A nonlinear least squares method is proposed for estimating the CV$_p$ and CV$_k$. We also perform interval estimation of the CV$_p$ and CV$_k$ using the asymptotic confidence intervals, bootstrap intervals through the least squares estimates, and the highest posterior density intervals. A comprehensive Monte Carlo simulation study is carried out to understand and compare the performance of the estimators. The proposed least squares and the Bayesian methods produce better point estimates for the CV$_p$. The highest posterior density intervals outperform other interval estimates in many cases. The methodologies are also applied to a real dataset to demonstrate the performance of the estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16102v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bankitdor M Nongrum, Adarsha Kumar Jena</dc:creator>
    </item>
    <item>
      <title>Failure of uniform laws of large numbers for subdifferentials and beyond</title>
      <link>https://arxiv.org/abs/2511.16568</link>
      <description>arXiv:2511.16568v1 Announce Type: cross 
Abstract: We provide counterexamples showing that uniform laws of large numbers do not hold for subdifferentials under natural assumptions. Our results apply to random Lipschitz functions and random convex functions with a finite number of smooth pieces. Consequently, they resolve the questions posed by Shapiro and Xu [J. Math. Anal. Appl., 325(2), 2007] in the negative and highlight the obstacles nonsmoothness poses to uniform results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.16568v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lai Tian, Johannes O. Royset</dc:creator>
    </item>
    <item>
      <title>Asymptotic theory for extreme value generalized additive models</title>
      <link>https://arxiv.org/abs/2303.02402</link>
      <description>arXiv:2303.02402v4 Announce Type: replace 
Abstract: The classical approach to analyzing extreme value data is the generalized Pareto distribution (GPD). When the GPD is used to explain a target variable with the large dimension of covariates, the shape and scale function of covariates included in GPD are sometimes modeled using the generalized additive models (GAM). In contrast to many results of application, there are no theoretical results on the hybrid technique of GAM and GPD, which motivates us to develop its asymptotic theory. We provide the rate of convergence of the estimator of shape and scale functions, as well as its local asymptotic normality.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.02402v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Takuma Yoshida</dc:creator>
    </item>
    <item>
      <title>A Generalized Back-Door Criterion for Linear Regression</title>
      <link>https://arxiv.org/abs/2511.04060</link>
      <description>arXiv:2511.04060v3 Announce Type: replace 
Abstract: What assumptions about the data-generating process are required to permit a causal interpretation of partial regression coefficients? To answer this question, this paper generalizes Pearl's single-door and back-door criteria and proposes a new criterion that enables the identification of total or partial causal effects. In addition, this paper elucidates the mechanism of post-treatment bias, showing that a repeated sequence of nodes can be a potential source of this bias. The results apply to linear data-generating processes represented by directed acyclic graphs with distribution-free error terms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.04060v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Masato Shimokawa</dc:creator>
    </item>
    <item>
      <title>Gamma-Based Statistical Modeling for Extended Target Detection in mmWave Automotive Radar</title>
      <link>https://arxiv.org/abs/2509.26573</link>
      <description>arXiv:2509.26573v3 Announce Type: replace-cross 
Abstract: Millimeter-wave (mmWave) radar systems, owing to their large bandwidth, provide fine range resolution that enables the observation of multiple scatterers originating from a single automotive target, commonly referred to as an extended target. Conventional CFAR-based detection algorithms typically treat these scatterers as independent detections, thereby discarding the spatial scattering structure intrinsic to the target. To preserve this scattering spread, this paper proposes a Range-Doppler (RD) segment framework designed to encapsulate the typical scattering profile of an automobile. The statistical characterization of the segment is performed using Maximum Likelihood Estimation (MLE) and posterior density modeling based on the Gamma distribution, facilitated through Gibbs Markov Chain Monte Carlo (MCMC) sampling. A skewness-based test statistic, derived from the estimated statistical model, is introduced for binary hypothesis classification of extended targets. Additionally, the paper presents a detection pipeline that incorporates Intersection over Union (IoU) and segment centering based on peak response, optimized to work within a single dwell. Extensive evaluations using both simulated and real-world datasets demonstrate the effectiveness of the proposed approach, underscoring its suitability for automotive radar applications through improved detection accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.26573v3</guid>
      <category>eess.SP</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vinay Kulkarni, V. V. Reddy</dc:creator>
    </item>
    <item>
      <title>Non-Asymptotic Analysis of Data Augmentation for Precision Matrix Estimation</title>
      <link>https://arxiv.org/abs/2510.02119</link>
      <description>arXiv:2510.02119v2 Announce Type: replace-cross 
Abstract: This paper addresses the problem of inverse covariance (also known as precision matrix) estimation in high-dimensional settings. Specifically, we focus on two classes of estimators: linear shrinkage estimators with a target proportional to the identity matrix, and estimators derived from data augmentation (DA). Here, DA refers to the common practice of enriching a dataset with artificial samples--typically generated via a generative model or through random transformations of the original data--prior to model fitting. For both classes of estimators, we derive estimators and provide concentration bounds for their quadratic error. This allows for both method comparison and hyperparameter tuning, such as selecting the optimal proportion of artificial samples. On the technical side, our analysis relies on tools from random matrix theory. We introduce a novel deterministic equivalent for generalized resolvent matrices, accommodating dependent samples with specific structure. We support our theoretical results with numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02119v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Fri, 21 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lucas Morisset, Adrien Hardy, Alain Durmus</dc:creator>
    </item>
  </channel>
</rss>
