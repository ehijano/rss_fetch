<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.SE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.SE</link>
    <description>cs.SE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.SE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Sep 2025 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Aspect-Oriented Programming in Secure Software Development: A Case Study of Security Aspects in Web Applications</title>
      <link>https://arxiv.org/abs/2509.07449</link>
      <description>arXiv:2509.07449v1 Announce Type: new 
Abstract: Security remains a critical challenge in modern web applications, where threats such as unauthorized access, data breaches, and injection attacks continue to undermine trust and reliability. Traditional Object-Oriented Programming (OOP) often intertwines security logic with business functionality, leading to code tangling, scattering, and reduced maintainability. This study investigates the role of Aspect-Oriented Programming (AOP) in enhancing secure software development by modularizing cross-cutting security concerns. Using a case study approach, we compare AOP-based implementations of security features including authentication, authorization, input validation, encryption, logging, and session management with conventional OOP or middleware-based approaches. Data collection involves analyzing code quality metrics (e.g., lines of code, coupling, cohesion, modularity index, reusability), performance metrics (response time, throughput, memory usage), and maintainability indicators. Developer feedback is also incorporated to assess integration and debugging experiences. Statistical methods, guided by the ISO/IEC 25010 software quality model, are applied to evaluate differences across implementations. The findings demonstrate that AOP enhances modularity, reusability, and maintainability of security mechanisms, while introducing only minimal performance overhead. The study contributes practical insights for software engineers and researchers seeking to balance security with software quality in web application development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07449v1</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mterorga Ukor</dc:creator>
    </item>
    <item>
      <title>CRACI: A Cloud-Native Reference Architecture for the Industrial Compute Continuum</title>
      <link>https://arxiv.org/abs/2509.07498</link>
      <description>arXiv:2509.07498v1 Announce Type: new 
Abstract: The convergence of Information Technology (IT) and Operational Technology (OT) in Industry 4.0 exposes the limitations of traditional, hierarchical architectures like ISA-95 and RAMI 4.0. Their inherent rigidity, data silos, and lack of support for cloud-native technologies impair the development of scalable and interoperable industrial systems. This paper addresses this issue by introducing CRACI, a Cloud-native Reference Architecture for the Industrial Compute Continuum. Among other features, CRACI promotes a decoupled and event-driven model to enable flexible, non-hierarchical data flows across the continuum. It embeds cross-cutting concerns as foundational pillars: Trust, Governance &amp; Policy, Observability, and Lifecycle Management, ensuring quality attributes are core to the design. The proposed architecture is validated through a two-fold approach: (1) a comparative theoretical analysis against established standards, operational models, and academic proposals; and (2) a quantitative evaluation based on performance data from previously published real-world smart manufacturing implementations. The results demonstrate that CRACI provides a viable, state-of-the-art architecture that utilizes the compute continuum to overcome the structural limitations of legacy models and enable scalable, modern industrial systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07498v1</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hai Dinh-Tuan</dc:creator>
    </item>
    <item>
      <title>PatchSeeker: Mapping NVD Records to their Vulnerability-fixing Commits with LLM Generated Commits and Embeddings</title>
      <link>https://arxiv.org/abs/2509.07540</link>
      <description>arXiv:2509.07540v1 Announce Type: new 
Abstract: Software vulnerabilities pose serious risks to modern software ecosystems. While the National Vulnerability Database (NVD) is the authoritative source for cataloging these vulnerabilities, it often lacks explicit links to the corresponding Vulnerability-Fixing Commits (VFCs). VFCs encode precise code changes, enabling vulnerability localization, patch analysis, and dataset construction. Automatically mapping NVD records to their true VFCs is therefore critical. Existing approaches have limitations as they rely on sparse, often noisy commit messages and fail to capture the deep semantics in the vulnerability descriptions. To address this gap, we introduce PatchSeeker, a novel method that leverages large language models to create rich semantic links between vulnerability descriptions and their VFCs. PatchSeeker generates embeddings from NVD descriptions and enhances commit messages by synthesizing detailed summaries for those that are short or uninformative. These generated messages act as a semantic bridge, effectively closing the information gap between natural language reports and low-level code changes. Our approach PatchSeeker achieves 59.3% higher MRR and 27.9% higher Recall@10 than the best-performing baseline, Prospector, on the benchmark dataset. The extended evaluation on recent CVEs further confirms PatchSeeker's effectiveness. Ablation study shows that both the commit message generation method and the selection of backbone LLMs make a positive contribution to PatchSeeker. We also discuss limitations and open challenges to guide future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07540v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huu Hung Nguyen, Anh Tuan Nguyen, Thanh Le-Cong, Yikun Li, Han Wei Ang, Yide Yin, Frank Liauw, Shar Lwin Khin, Ouh Eng Lieh, Ting Zhang, David Lo</dc:creator>
    </item>
    <item>
      <title>Bridging the Gap Between Binary and Source Based Package Management in Spack</title>
      <link>https://arxiv.org/abs/2509.07728</link>
      <description>arXiv:2509.07728v1 Announce Type: new 
Abstract: Binary package managers install software quickly but they limit configurability due to rigid ABI requirements that ensure compatibility between binaries. Source package managers provide flexibility in building software, but compilation can be slow. For example, installing an HPC code with a new MPI implementation may result in a full rebuild. Spack, a widely deployed, HPC-focused package manager, can use source and pre-compiled binaries, but lacks a binary compatibility model, so it cannot mix binaries not built together. We present splicing, an extension to Spack that models binary compatibility between packages and allows seamless mixing of source and binary distributions. Splicing augments Spack's packaging language and dependency resolution engine to reuse compatible binaries but maintains the flexibility of source builds. It incurs minimal installation-time overhead and allows rapid installation from binaries, even for ABI-sensitive dependencies like MPI that would otherwise require many rebuilds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07728v1</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Gouwar, Gregory Becker, Tamara Dahlgren, Nathan Hanford, Arjun Guha, Todd Gamblin</dc:creator>
    </item>
    <item>
      <title>What's Coming Next? Short-Term Simulation of Business Processes from Current State</title>
      <link>https://arxiv.org/abs/2509.07747</link>
      <description>arXiv:2509.07747v1 Announce Type: new 
Abstract: Business process simulation is an approach to evaluate business process changes prior to implementation. Existing methods in this field primarily support tactical decision-making, where simulations start from an empty state and aim to estimate the long-term effects of process changes. A complementary use-case is operational decision-making, where the goal is to forecast short-term performance based on ongoing cases and to analyze the impact of temporary disruptions, such as demand spikes and shortfalls in available resources. An approach to tackle this use-case is to run a long-term simulation up to a point where the workload is similar to the current one (warm-up), and measure performance thereon. However, this approach does not consider the current state of ongoing cases and resources in the process. This paper studies an alternative approach that initializes the simulation from a representation of the current state derived from an event log of ongoing cases. The paper addresses two challenges in operationalizing this approach: (1) Given a simulation model, what information is needed so that a simulation run can start from the current state of cases and resources? (2) How can the current state of a process be derived from an event log? The resulting short-term simulation approach is embodied in a simulation engine that takes as input a simulation model and a log of ongoing cases, and simulates cases for a given time horizon. An experimental evaluation shows that this approach yields more accurate short-term performance forecasts than long-term simulations with warm-up period, particularly in the presence of concept drift or bursty performance patterns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07747v1</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maksym Avramenko, David Chapela-Campa, Marlon Dumas, Fredrik Milani</dc:creator>
    </item>
    <item>
      <title>What Were You Thinking? An LLM-Driven Large-Scale Study of Refactoring Motivations in Open-Source Projects</title>
      <link>https://arxiv.org/abs/2509.07763</link>
      <description>arXiv:2509.07763v1 Announce Type: new 
Abstract: Context. Code refactoring improves software quality without changing external behavior. Despite its advantages, its benefits are hindered by the considerable cost of time, resources, and continuous effort it demands. Aim. Understanding why developers refactor, and which metrics capture these motivations, may support wider and more effective use of refactoring in practice. Method. We performed a large-scale empirical study to analyze developers refactoring activity, leveraging Large Language Models (LLMs) to identify underlying motivations from version control data, comparing our findings with previous motivations reported in the literature. Results. LLMs matched human judgment in 80% of cases, but aligned with literature-based motivations in only 47%. They enriched 22% of motivations with more detailed rationale, often highlighting readability, clarity, and structural improvements. Most motivations were pragmatic, focused on simplification and maintainability. While metrics related to developer experience and code readability ranked highest, their correlation with motivation categories was weak. Conclusions. We conclude that LLMs effectively capture surface-level motivations but struggle with architectural reasoning. Their value lies in providing localized explanations, which, when combined with software metrics, can form hybrid approaches. Such integration offers a promising path toward prioritizing refactoring more systematically and balancing short-term improvements with long-term architectural goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07763v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mikel Robredo, Matteo Esposito, Fabio Palomba, Rafael Pe\~naloza, Valentina Lenarduzzi</dc:creator>
    </item>
    <item>
      <title>"We provide our resources in a dedicated repository": Surveying the Transparency of HICSS publications</title>
      <link>https://arxiv.org/abs/2509.07851</link>
      <description>arXiv:2509.07851v1 Announce Type: new 
Abstract: Every day, new discoveries are made by researchers from all across the globe and fields. HICSS is a flagship venue to present and discuss such scientific advances. Yet, the activities carried out for any given research can hardly be fully contained in a single document of a few pages-the "paper." Indeed, any given study entails data, artifacts, or other material that is crucial to truly appreciate the contributions claimed in the corresponding paper. External repositories (e.g., GitHub) are a convenient tool to store all such resources so that future work can freely observe and build upon them -- thereby improving transparency and promoting reproducibility of research as a whole. In this work, we scrutinize the extent to which papers recently accepted to HICSS leverage such repositories to provide supplementary material. To this end, we collect all the 5579 papers included in HICSS proceedings from 2017-2024. Then, we identify those entailing either human subject research (850) or technical implementations (737), or both (147). Finally, we review their text, examining how many include a link to an external repository-and, inspect its contents. Overall, out of 2028 papers, only 3\% have a functional and publicly available repository that is usable by downstream research. We release all our tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07851v1</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.24251/HICSS.2025.881</arxiv:DOI>
      <dc:creator>Irdin Pekaric, Giovanni Apruzzese</dc:creator>
    </item>
    <item>
      <title>Breaking Android with AI: A Deep Dive into LLM-Powered Exploitation</title>
      <link>https://arxiv.org/abs/2509.07933</link>
      <description>arXiv:2509.07933v1 Announce Type: new 
Abstract: The rapid evolution of Artificial Intelligence (AI) and Large Language Models (LLMs) has opened up new opportunities in the area of cybersecurity, especially in the exploitation automation landscape and penetration testing. This study explores Android penetration testing automation using LLM-based tools, especially PentestGPT, to identify and execute rooting techniques. Through a comparison of the traditional manual rooting process and exploitation methods produced using AI, this study evaluates the efficacy, reliability, and scalability of automated penetration testing in achieving high-level privilege access on Android devices. With the use of an Android emulator (Genymotion) as the testbed, we fully execute both traditional and exploit-based rooting methods, automating the process using AI-generated scripts. Secondly, we create a web application by integrating OpenAI's API to facilitate automated script generation from LLM-processed responses. The research focuses on the effectiveness of AI-enabled exploitation by comparing automated and manual penetration testing protocols, by determining LLM weaknesses and strengths along the way. We also provide security suggestions of AI-enabled exploitation, including ethical factors and potential misuse. The findings exhibit that while LLMs can significantly streamline the workflow of exploitation, they need to be controlled by humans to ensure accuracy and ethical application. This study adds to the increasing body of literature on AI-powered cybersecurity and its effect on ethical hacking, security research, and mobile device security.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07933v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wanni Vidulige Ishan Perera, Xing Liu, Fan liang, Junyi Zhang</dc:creator>
    </item>
    <item>
      <title>From Passive to Participatory: How Liberating Structures Can Revolutionize Our Conferences</title>
      <link>https://arxiv.org/abs/2509.07046</link>
      <description>arXiv:2509.07046v1 Announce Type: cross 
Abstract: Our conferences face a growing crisis: an overwhelming flood of submissions, increased reviewing burdens, and diminished opportunities for meaningful engagement. With AI making paper generation easier than ever, we must ask whether the current model fosters real innovation or simply incentivizes more publications. This article advocates for a shift from passive paper presentations to interactive, participatory formats. We propose Liberating Structures, facilitation techniques that promote collaboration and deeper intellectual exchange. By restructuring conferences into two tracks, one for generating new ideas and another for discussing established work, we can prioritize quality over quantity and reinvigorate academic gatherings. Embracing this change will ensure conferences remain spaces for real insight, creativity, and impactful collaboration in the AI era.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07046v1</guid>
      <category>cs.CY</category>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3765705</arxiv:DOI>
      <arxiv:journal_reference>Communications of the ACM, 2025</arxiv:journal_reference>
      <dc:creator>Daniel Russo, Margaret-Anne Storey</dc:creator>
    </item>
    <item>
      <title>Lookup multivariate Kolmogorov-Arnold Networks</title>
      <link>https://arxiv.org/abs/2509.07103</link>
      <description>arXiv:2509.07103v1 Announce Type: cross 
Abstract: High-dimensional linear mappings, or linear layers, dominate both the parameter count and the computational cost of most modern deep-learning models. We introduce a general drop-in replacement, lookup multivariate Kolmogorov-Arnold Networks (lmKANs), which deliver a substantially better trade-off between capacity and inference cost. Our construction expresses a general high-dimensional mapping through trainable low-dimensional multivariate functions. These functions can carry dozens or hundreds of trainable parameters each, and yet it takes only a few multiplications to compute them because they are implemented as spline lookup tables. Empirically, lmKANs reduce inference FLOPs by up to 6.0x while matching the flexibility of MLPs in general high-dimensional function approximation. In another feedforward fully connected benchmark, on the tabular-like dataset of randomly displaced methane configurations, lmKANs enable more than 10x higher H100 throughput at equal accuracy. Within frameworks of Convolutional Neural Networks, lmKAN-based CNNs cut inference FLOPs at matched accuracy by 1.6-2.1x and by 1.7x on the CIFAR-10 and ImageNet-1k datasets, respectively. Our code, including dedicated CUDA kernels, is available online at https://github.com/schwallergroup/lmkan.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07103v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PF</category>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Pozdnyakov, Philippe Schwaller</dc:creator>
    </item>
    <item>
      <title>SafeToolBench: Pioneering a Prospective Benchmark to Evaluating Tool Utilization Safety in LLMs</title>
      <link>https://arxiv.org/abs/2509.07315</link>
      <description>arXiv:2509.07315v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have exhibited great performance in autonomously calling various tools in external environments, leading to better problem solving and task automation capabilities. However, these external tools also amplify potential risks such as financial loss or privacy leakage with ambiguous or malicious user instructions. Compared to previous studies, which mainly assess the safety awareness of LLMs after obtaining the tool execution results (i.e., retrospective evaluation), this paper focuses on prospective ways to assess the safety of LLM tool utilization, aiming to avoid irreversible harm caused by directly executing tools. To this end, we propose SafeToolBench, the first benchmark to comprehensively assess tool utilization security in a prospective manner, covering malicious user instructions and diverse practical toolsets. Additionally, we propose a novel framework, SafeInstructTool, which aims to enhance LLMs' awareness of tool utilization security from three perspectives (i.e., \textit{User Instruction, Tool Itself, and Joint Instruction-Tool}), leading to nine detailed dimensions in total. We experiment with four LLMs using different methods, revealing that existing approaches fail to capture all risks in tool utilization. In contrast, our framework significantly enhances LLMs' self-awareness, enabling a more safe and trustworthy tool utilization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07315v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongfei Xia, Hongru Wang, Zeming Liu, Qian Yu, Yuhang Guo, Haifeng Wang</dc:creator>
    </item>
    <item>
      <title>A smart fridge with AI-enabled food computing</title>
      <link>https://arxiv.org/abs/2509.07400</link>
      <description>arXiv:2509.07400v1 Announce Type: cross 
Abstract: The Internet of Things (IoT) plays a crucial role in enabling seamless connectivity and intelligent home automation, particularly in food management. By integrating IoT with computer vision, the smart fridge employs an ESP32-CAM to establish a monitoring subsystem that enhances food management efficiency through real-time food detection, inventory tracking, and temperature monitoring. This benefits waste reduction, grocery planning improvement, and household consumption optimization. In high-density inventory conditions, capturing partial or layered images complicates object detection, as overlapping items and occluded views hinder accurate identification and counting. Besides, varied angles and obscured details in multi-layered setups reduce algorithm reliability, often resulting in miscounts or misclassifications. Our proposed system is structured into three core modules: data pre-processing, object detection and management, and a web-based visualization. To address the challenge of poor model calibration caused by overconfident predictions, we implement a variant of focal loss that mitigates over-confidence and under-confidence in multi-category classification. This approach incorporates adaptive, class-wise error calibration via temperature scaling and evaluates the distribution of predicted probabilities across methods. Our results demonstrate that robust functional calibration significantly improves detection reliability under varying lighting conditions and scalability challenges. Further analysis demonstrates a practical, user-focused approach to modern food management, advancing sustainable living goals through reduced waste and more informed consumption.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07400v1</guid>
      <category>eess.SY</category>
      <category>cs.CV</category>
      <category>cs.SE</category>
      <category>cs.SY</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>The 9th OISP Science and Technology Symposium for Students Ho Chi Minh City University of Technology (HCMUT), VNU-HCM, 2025</arxiv:journal_reference>
      <dc:creator>Khue Nong Thuc, Khoa Tran Nguyen Anh, Tai Nguyen Huy, Du Nguyen Hao Hong, Khanh Dinh Ba</dc:creator>
    </item>
    <item>
      <title>Astra: A Multi-Agent System for GPU Kernel Performance Optimization</title>
      <link>https://arxiv.org/abs/2509.07506</link>
      <description>arXiv:2509.07506v1 Announce Type: cross 
Abstract: GPU kernel optimization has long been a central challenge at the intersection of high-performance computing and machine learning. Efficient kernels are crucial for accelerating large language model (LLM) training and serving, yet attaining high performance typically requires extensive manual tuning. Compiler-based systems reduce some of this burden, but still demand substantial manual design and engineering effort. Recently, researchers have explored using LLMs for GPU kernel generation, though prior work has largely focused on translating high-level PyTorch modules into CUDA code. In this work, we introduce Astra, the first LLM-based multi-agent system for GPU kernel optimization. Unlike previous approaches, Astra starts from existing CUDA implementations extracted from SGLang, a widely deployed framework for serving LLMs, rather than treating PyTorch modules as the specification. Within Astra, specialized LLM agents collaborate through iterative code generation, testing, profiling, and planning to produce kernels that are both correct and high-performance. On kernels from SGLang, Astra achieves an average speedup of 1.32x using zero-shot prompting with OpenAI o4-mini. A detailed case study further demonstrates that LLMs can autonomously apply loop transformations, optimize memory access patterns, exploit CUDA intrinsics, and leverage fast math operations to yield substantial performance gains. Our work highlights multi-agent LLM systems as a promising new paradigm for GPU kernel optimization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.07506v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjiang Wei, Tianran Sun, Yogesh Seenichamy, Hang Song, Anne Ouyang, Azalia Mirhoseini, Ke Wang, Alex Aiken</dc:creator>
    </item>
    <item>
      <title>Challenging Bug Prediction and Repair Models with Synthetic Bugs</title>
      <link>https://arxiv.org/abs/2310.02407</link>
      <description>arXiv:2310.02407v3 Announce Type: replace 
Abstract: Bugs are essential in software engineering; many research studies in the past decades have been proposed to detect, localize, and repair bugs in software systems. Effectiveness evaluation of such techniques requires complex bugs, i.e., those that are hard to detect through testing and hard to repair through debugging. From the classic software engineering point of view, a hard-to-repair bug differs from the correct code in multiple locations, making it hard to localize and repair. Hard-to-detect bugs, on the other hand, manifest themselves under specific test inputs and reachability conditions. These two objectives, i.e., generating hard-to-detect and hard-to-repair bugs, are mostly aligned; a bug generation technique can change multiple statements to be covered only under a specific set of inputs. However, these two objectives are conflicting for learning-based techniques: A bug should have a similar code representation to the correct code in the training data to challenge a bug prediction model to distinguish them. The hard-to-repair bug definition remains the same but with a caveat: the more a bug differs from the original code, the more distant their representations are and easier to be detected. We propose BugFarm, to transform arbitrary code into multiple complex bugs. BugFarm leverages LLMs to mutate code in multiple locations (hard-to-repair). To ensure that multiple modifications do not notably change the code representation, BugFarm analyzes the attention of the underlying model and instructs LLMs to only change the least attended locations (hard-to-detect). Our comprehensive evaluation of 435k+ bugs from over 1.9M mutants generated by BUGFARM and two alternative approaches demonstrates our superiority in generating bugs that are hard to detect by learning-based bug prediction approaches and hard-to-repair by state-of-the-art learning-based program repair technique.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.02407v3</guid>
      <category>cs.SE</category>
      <category>cs.LG</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Reza Ibrahimzada, Yang Chen, Ryan Rong, Reyhaneh Jabbarvand</dc:creator>
    </item>
    <item>
      <title>Are "Solved Issues" in SWE-bench Really Solved Correctly? An Empirical Study</title>
      <link>https://arxiv.org/abs/2503.15223</link>
      <description>arXiv:2503.15223v2 Announce Type: replace 
Abstract: Automated issue solving aims to resolve real-world issues in software repositories. The most popular benchmarks for automated issue solving are SWE-bench and its human-filtered subset SWE-bench Verified. These benchmarks leverage testing to validate generated patches. However, because testing is rarely exhaustive, a patch may pass the tests but nevertheless fail to match the developers' expectations. Unfortunately, it is currently unclear to what extent evaluations performed with SWE-bench suffer from such plausible but incorrect patches. This paper presents an in-depth empirical study of the correctness of plausible patches generated by three state-of-the-art issue-solving tools evaluated on SWE-bench Verified. We extensively test and inspect generated patches, and compare them against human-written ground truth patches. The core of our methodology is a novel technique PatchDiff for differential patch testing, which automatically exposes behavioral discrepancies between two patches. Our findings reveal critical weaknesses in SWE-bench's patch validation mechanism, which causes 7.8% of all patches to count as correct while failing the developer-written test suite. Moreover, our novel automated technique reveals that even more (29.6%) plausible patches induce different behavior than the ground truth patches. These behavioral differences are often due to similar, but divergent implementations (46.8%) and due to generated patches that adapt more behavior than the ground truth patches (27.3%). Our manual inspection shows that 28.6% of behaviorally divergent patches are certainly incorrect. Combined, the different weaknesses lead to an inflation of reported resolution rates by 6.2 absolute percent points. Our findings are a call to arms for more robust and reliable evaluation of issue-solving tools. We envision our automated differential patch testing technique to be useful for this purpose.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15223v2</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3744916.3764576</arxiv:DOI>
      <dc:creator>You Wang, Michael Pradel, Zhongxin Liu</dc:creator>
    </item>
    <item>
      <title>Specification-Guided Repair of Arithmetic Errors in Dafny Programs using LLMs</title>
      <link>https://arxiv.org/abs/2507.03659</link>
      <description>arXiv:2507.03659v3 Announce Type: replace 
Abstract: Debugging and repairing faults when programs fail to formally verify can be complex and time-consuming. Automated Program Repair (APR) can ease this burden by automatically identifying and fixing faults. However, traditional APR techniques often rely on test suites for validation, but these may not capture all possible scenarios. In contrast, formal specifications provide strong correctness criteria, enabling more effective automated repair.
  In this paper, we present an APR tool for Dafny, a verification-aware programming language that uses formal specifications - including pre-conditions, post-conditions, and invariants - as oracles for fault localization and repair. Assuming the correctness of the specifications and focusing on arithmetic bugs, we localize faults through a series of steps, which include using Hoare logic to determine the state of each statement within the program, and applying Large Language Models (LLMs) to synthesize candidate fixes. The models considered are GPT-4o mini, Llama 3, Mistral 7B, and Llemma 7B.
  We evaluate our approach using DafnyBench, a benchmark of real-world Dafny programs. Our tool achieves 89.6% fault localization coverage and GPT-4o mini yields the highest repair success rate of 74.18%. These results highlight the potential of combining formal reasoning with LLM-based program synthesis for automated program repair.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03659v3</guid>
      <category>cs.SE</category>
      <category>cs.PL</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Valentina Wu, Alexandra Mendes, Alexandre Abreu</dc:creator>
    </item>
    <item>
      <title>Vulnerability-Affected Versions Identification: How Far Are We?</title>
      <link>https://arxiv.org/abs/2509.03876</link>
      <description>arXiv:2509.03876v2 Announce Type: replace 
Abstract: Identifying which software versions are affected by a vulnerability is critical for patching, risk mitigation. Despite a growing body of tools, their real-world effectiveness remains unclear due to narrow evaluation scopes often limited to early SZZ variants, outdated techniques, and small or coarse-grained datasets. In this paper, we present the first comprehensive empirical study of vulnerability affected versions identification. We curate a high quality benchmark of 1,128 real-world C/C++ vulnerabilities and systematically evaluate 12 representative tools from both tracing and matching paradigms across four dimensions: effectiveness at both vulnerability and version levels, root causes of false positives and negatives, sensitivity to patch characteristics, and ensemble potential. Our findings reveal fundamental limitations: no tool exceeds 45.0% accuracy, with key challenges stemming from heuristic dependence, limited semantic reasoning, and rigid matching logic. Patch structures such as add-only and cross-file changes further hinder performance. Although ensemble strategies can improve results by up to 10.1%, overall accuracy remains below 60.0%, highlighting the need for fundamentally new approaches. Moreover, our study offers actionable insights to guide tool development, combination strategies, and future research in this critical area. Finally, we release the replicated code and benchmark on our website to encourage future contributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03876v2</guid>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xingchu Chen, Chengwei Liu, Jialun Cao, Yang Xiao, Xinyue Cai, Yeting Li, Jingyi Shi, Tianqi Sun, Haiming Chen ang Wei Huo</dc:creator>
    </item>
    <item>
      <title>Software Model Checking via Summary-Guided Search (Extended Version)</title>
      <link>https://arxiv.org/abs/2508.15137</link>
      <description>arXiv:2508.15137v3 Announce Type: replace-cross 
Abstract: In this work, we describe a new software model-checking algorithm called GPS. GPS treats the task of model checking a program as a directed search of the program states, guided by a compositional, summary-based static analysis. The summaries produced by static analysis are used both to prune away infeasible paths and to drive test generation to reach new, unexplored program states. GPS can find both proofs of safety and counter-examples to safety (i.e., inputs that trigger bugs), and features a novel two-layered search strategy that renders it particularly efficient at finding bugs in programs featuring long, input-dependent error paths. To make GPS refutationally complete (in the sense that it will find an error if one exists, if it is allotted enough time), we introduce an instrumentation technique and show that it helps GPS achieve refutation-completeness without sacrificing overall performance. We benchmarked GPS on a diverse suite of benchmarks including programs from the Software Verification Competition (SV-COMP), from prior literature, as well as synthetic programs based on examples in this paper. We found that our implementation of GPS outperforms state-of-the-art software model checkers (including the top performers in SV-COMP ReachSafety-Loops category), both in terms of the number of benchmarks solved and in terms of running time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15137v3</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 10 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3763142</arxiv:DOI>
      <arxiv:journal_reference>Proc. ACM Program. Lang. 9, OOPSLA2, Article 364 (October 2025)</arxiv:journal_reference>
      <dc:creator>Ruijie Fang, Zachary Kincaid, Thomas Reps</dc:creator>
    </item>
  </channel>
</rss>
