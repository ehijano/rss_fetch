<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.NI updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.NI</link>
    <description>cs.NI updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.NI" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 Oct 2025 04:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Toward Hyper-Dimensional Connectivity in Beyond 6G: A Conceptual Framework</title>
      <link>https://arxiv.org/abs/2510.12896</link>
      <description>arXiv:2510.12896v1 Announce Type: new 
Abstract: Cellular wireless networks enable mobile broadband connectivity for Internet-based applications through their radio access and core network infrastructure. While Fifth-Generation (5G) cellular systems are currently being deployed, ongoing research on cellular technologies primarily focuses on Sixth-Generation (6G) networks to set the stage for developing standards for these systems. Therefore, the time has come to articulate the visions for beyond 6G (B6G) systems. In this article, we present a visionary framework toward hyper-dimensional connectivity in B6G that enables wireless access to hyper-immersive Internet technologies. Our contributions include a conceptual framework for B6G cellular systems with jointly integrated communication, cognition, computing, and cyber-physical capabilities as core connectivity dimensions, a set of technical definitions outlining potential use cases and system-level requirements, a mapping of prospective technology enablers, and a forward-looking research agenda for B6G systems. The conceptual discussions in this article would be helpful for identifying innovation drivers, shaping long-term technical goals, and defining research agendas for the future of mobile broadband technologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12896v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ekram Hossain, Angelo Vera-Rivera</dc:creator>
    </item>
    <item>
      <title>Towards xApp Conflict Evaluation with Explainable Machine Learning and Causal Inference in O-RAN</title>
      <link>https://arxiv.org/abs/2510.13031</link>
      <description>arXiv:2510.13031v1 Announce Type: new 
Abstract: The Open Radio Access Network (O-RAN) architecture enables a flexible, vendor-neutral deployment of 5G networks by disaggregating base station components and supporting third-party xApps for near real-time RAN control. However, the concurrent operation of multiple xApps can lead to conflicting control actions, which may cause network performance degradation. In this work, we propose a framework for xApp conflict management that combines explainable machine learning and causal inference to evaluate the causal relationships between RAN Control Parameters (RCPs) and Key Performance Indicators (KPIs). We use model explainability tools such as SHAP to identify RCPs that jointly affect the same KPI, signaling potential conflicts, and represent these interactions as a causal Directed Acyclic Graph (DAG). We then estimate the causal impact of each of these RCPs on their associated KPIs using metrics such as Average Treatment Effect (ATE) and Conditional Average Treatment Effect (CATE). This approach offers network operators guided insights into identifying conflicts and quantifying their impacts, enabling more informed and effective conflict resolution strategies across diverse xApp deployments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13031v1</guid>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pragya Sharma, Shihua Sun, Shachi Deshpande, Angelos Stavrou, Haining Wang</dc:creator>
    </item>
    <item>
      <title>Automated Network Protocol Testing with LLM Agents</title>
      <link>https://arxiv.org/abs/2510.13248</link>
      <description>arXiv:2510.13248v1 Announce Type: new 
Abstract: Network protocol testing is fundamental for modern network infrastructure. However, traditional network protocol testing methods are labor-intensive and error-prone, requiring manual interpretation of specifications, test case design, and translation into executable artifacts, typically demanding one person-day of effort per test case. Existing model-based approaches provide partial automation but still involve substantial manual modeling and expert intervention, leading to high costs and limited adaptability to diverse and evolving protocols. In this paper, we propose a first-of-its-kind system called NeTestLLM that takes advantage of multi-agent Large Language Models (LLMs) for end-to-end automated network protocol testing. NeTestLLM employs hierarchical protocol understanding to capture complex specifications, iterative test case generation to improve coverage, a task-specific workflow for executable artifact generation, and runtime feedback analysis for debugging and refinement. NeTestLLM has been deployed in a production environment for several months, receiving positive feedback from domain experts. In experiments, NeTestLLM generated 4,632 test cases for OSPF, RIP, and BGP, covering 41 historical FRRouting bugs compared to 11 by current national standards. The process of generating executable artifacts also improves testing efficiency by a factor of 8.65x compared to manual methods. NeTestLLM provides the first practical LLM-powered solution for automated end-to-end testing of heterogeneous network protocols.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13248v1</guid>
      <category>cs.NI</category>
      <category>cs.LG</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yunze Wei, Kaiwen Wei, Shibo Du, Jianyu Wang, Zhangzhong Liu, Yawen Wang, Zhanyou Li, Congcong Miao, Xiaohui Xie, Yong Cui</dc:creator>
    </item>
    <item>
      <title>NetMCP: Network-Aware Model Context Protocol Platform for LLM Capability Extension</title>
      <link>https://arxiv.org/abs/2510.13467</link>
      <description>arXiv:2510.13467v1 Announce Type: new 
Abstract: Large Language Models (LLMs) remain static in functionality after training, and extending their capabilities requires integration with external data, computation, and services. The Model Context Protocol (MCP) has emerged as a standard interface for such extensions, but current implementations rely solely on semantic matching between users' requests and server function descriptions, which makes current deployments and simulation testbeds fragile under latency fluctuations or server failures. We address this gap by enhancing MCP tool routing algorithms with real-time awareness of network and server status. To provide a controlled test environment for development and evaluation, we construct a heterogeneous experimental platform, namely Network-aware MCP (NetMCP), which offers five representative network states and build a benchmark for latency sequence generation and MCP server datasets. On top of NetMCP platform, we analyze latency sequences and propose a Semantic-Oriented and Network-Aware Routing (SONAR) algorithm, which jointly optimizes semantic similarity and network Quality of Service (QoS) metrics for adaptive tool routing. Results show that SONAR consistently improves task success rate and reduces completion time and failure number compared with semantic-only, LLM-based baselines, demonstrating the value of network-aware design for production-scale LLM systems. The code for NetMCP is available at https://github.com/NICE-HKU/NetMCP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13467v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Enhan Li, Hongyang Du, Kaibin Huang</dc:creator>
    </item>
    <item>
      <title>Fair Ordering</title>
      <link>https://arxiv.org/abs/2510.13664</link>
      <description>arXiv:2510.13664v1 Announce Type: new 
Abstract: A growing class of applications demands \emph{fair ordering/sequencing} of events which ensures that events generated earlier by one client are processed before later events from other clients. However, achieving such sequencing is fundamentally challenging due to the inherent limitations of clock synchronization. We advocate for an approach that embraces, rather than eliminates, clock variability. Instead of attempting to remove error from a timestamp, Tommy, our proposed system, leverages a statistical model to compare two noisy timestamps probabilistically by learning per-clock offset distributions. Our preliminary statistical model computes the probability that one event precedes another w.r.t. the wall-clock time without access to the wall-clock. This serves as a foundation for a new relation: \emph{likely-happened-before} denoted by $\xrightarrow{p}$ where $p$ represents the probability of an event to have happened before another. The $\xrightarrow{p}$ relation provides a basis for ordering multiple events which are otherwise considered \emph{concurrent} by the typical \emph{happened-before} ($\rightarrow$) relation. We highlight various related challenges including intransitivity of $\xrightarrow{p}$ relation as opposed to the transitive $\rightarrow$ relation. We also outline several research directions: online fair sequencing, stochastically fair total ordering, host-level support for fairness and more.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13664v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Haseeb, Jinkun Geng, Radhika Mittal, Aurojit Panda, Srinivas Narayana, Anirudh Sivaraman</dc:creator>
    </item>
    <item>
      <title>Optimize Replica Server Placement in a Satellite Network</title>
      <link>https://arxiv.org/abs/2510.13689</link>
      <description>arXiv:2510.13689v1 Announce Type: new 
Abstract: Satellite communication offers Internet connectivity to remote locations, such as villages, deserts, mountains, and at sea. However, transmitting content over satellite networks is significantly more expensive than traditional Internet. To address this issue, we propose placing content replica servers within satellite networks and optimizing replica placement for important performance metrics, such as latency, transmission, and storage cost. Our approach can support different types of satellite networks, including Low Earth Orbit (LEO), Medium Earth Orbit (MEO), Geostationary Orbit (GEO), and their combinations. An important challenge for supporting content replicas in such networks is that LEO and MEO satellites are constantly moving. We address this challenge by explicitly considering their moving trajectories and strategically optimizing not only client performance, but also the cost of transferring content from one satellite to another as needed. We demonstrate the effectiveness of our approach using both simulated traffic traces and a prototype system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13689v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhiyuan He, Yi Xu, Cheng Luo, Lili Qiu, Yuqing Yang</dc:creator>
    </item>
    <item>
      <title>Investigating Web Content Delivery Performance over Starlink</title>
      <link>https://arxiv.org/abs/2510.13710</link>
      <description>arXiv:2510.13710v1 Announce Type: new 
Abstract: Low Earth Orbit (LEO) satellite ISPs promise universal Internet connectivity, yet their interaction with content delivery remains poorly understood. We present the first comprehensive measurement study decomposing Starlink's web content delivery performance decomposed across Point of Presence (PoP), DNS, and CDN layers. Through two years of measurements combining 225K Cloudflare AIM tests, M-Lab data, and active probing from 99 RIPE Atlas and controlled Starlink probes, we collect 6.1M traceroutes and 10.8M DNS queries to quantify how satellite architecture disrupts terrestrial CDN assumptions. We identify three distinct performance regimes based on infrastructure density. Regions with local content-rich PoPs achieve near-terrestrial latencies with the satellite segment dominating 80-90% of RTT. Infrastructure-sparse regions suffer cascading penalties: remote PoPs force distant resolver selection, which triggers CDN mis-localization, pushing latencies beyond 200 ms. Dense-infrastructure regions show minimal sensitivity to PoP changes. Leveraging Starlink's infrastructure expansion in early 2025 as a natural experiment, we demonstrate that relocating PoPs closer to user location reduces median page-fetch times by 60%. Our findings reveal that infrastructure proximity, not satellite coverage, influences web performance, requiring fundamental changes to CDN mapping and DNS resolution for satellite ISPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13710v1</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rohan Bose, Jinwei Zhao, Tanya Shreedhar, Jianping Pan, Nitinder Mohan</dc:creator>
    </item>
    <item>
      <title>Scalable Pilot Assignment for Distributed Massive MIMO using Channel Estimation Error</title>
      <link>https://arxiv.org/abs/2510.13732</link>
      <description>arXiv:2510.13732v1 Announce Type: new 
Abstract: Pilot contamination remains a major bottleneck in realizing the full potential of distributed massive MIMO systems. We propose two dynamic and scalable pilot assignment strategies designed for practical deployment in such networks. First, we present a low complexity centralized algorithm that sequentially assigns pilots to user equipments (UEs) to minimize the global channel estimation errors across serving access points (APs). This improves the channel estimation quality and reduces interference among UEs, enhancing the spectral efficiency. Second, we develop a fully distributed algorithm that uses a priority-based pilot selection approach. In this algorithm, each selected AP minimizes estimation error using only local information and offers candidate pilots to the UEs. Every UE then selects a suitable pilot based on AP priority. This approach ensures consistency and minimizes interference while significantly reducing pilot contamination. The method requires no global coordination, maintains low signaling overhead, and adapts dynamically to the UE deployment. Numerical simulations demonstrate the superiority of our proposed schemes in terms of network throughput when compared to other state-of-the-art benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13732v1</guid>
      <category>cs.NI</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohd Saif Ali Khan, Karthik RM, Samar Agnihotri</dc:creator>
    </item>
    <item>
      <title>Towards Trusted Service Monitoring: Verifiable Service Level Agreements</title>
      <link>https://arxiv.org/abs/2510.13370</link>
      <description>arXiv:2510.13370v1 Announce Type: cross 
Abstract: Service Level Agreement (SLA) monitoring in service-oriented environments suffers from inherent trust conflicts when providers self-report metrics, creating incentives to underreport violations. We introduce a framework for generating verifiable SLA violation claims through trusted hardware monitors and zero-knowledge proofs, establishing cryptographic foundations for genuine trustworthiness in service ecosystems. Our approach starts with machine-readable SLA clauses converted into verifiable predicates and monitored within Trusted Execution Environments. These monitors collect timestamped telemetry, organize measurements into Merkle trees, and produce signed attestations. Zero-knowledge proofs aggregate Service-Level Indicators to evaluate compliance, generating cryptographic proofs verifiable by stakeholders, arbitrators, or insurers in disputes, without accessing underlying data. This ensures three security properties: integrity, authenticity, and validity. Our prototype demonstrates linear scaling up to over 1 million events per hour for measurements with near constant-time proof generation and verification for single violation claims, enabling trustless SLA enforcement through cryptographic guarantees for automated compliance verification in service monitoring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13370v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fernando Castillo, Eduardo Brito, Sebastian Werner, Pille Pullonen-Raudvere, Jonathan Heiss</dc:creator>
    </item>
    <item>
      <title>Optimizing Storage Overhead of User Behavior Log for ML-embedded Mobile Apps</title>
      <link>https://arxiv.org/abs/2510.13405</link>
      <description>arXiv:2510.13405v1 Announce Type: cross 
Abstract: Machine learning (ML) models are increasingly integrated into modern mobile apps to enable personalized and intelligent services. These models typically rely on rich input features derived from historical user behaviors to capture user intents. However, as ML-driven services become more prevalent, recording necessary user behavior data imposes substantial storage cost on mobile apps, leading to lower system responsiveness and more app uninstalls. To address this storage bottleneck, we present AdaLog, a lightweight and adaptive system designed to improve the storage efficiency of user behavior log in ML-embedded mobile apps, without compromising model inference accuracy or latency. We identify two key inefficiencies in current industrial practices of user behavior log: (i) redundant logging of overlapping behavior data across different features and models, and (ii) sparse storage caused by storing behaviors with heterogeneous attribute descriptions in a single log file. To solve these issues, AdaLog first formulates the elimination of feature-level redundant data as a maximum weighted matching problem in hypergraphs, and proposes a hierarchical algorithm for efficient on-device deployment. Then, AdaLog employs a virtually hashed attribute design to distribute heterogeneous behaviors into a few log files with physically dense storage. Finally, to ensure scalability to dynamic user behavior patterns, AdaLog designs an incremental update mechanism to minimize the I/O operations needed for adapting outdated behavior log. We implement a prototype of AdaLog and deploy it into popular mobile apps in collaboration with our industry partner. Evaluations on real-world user data show that AdaLog reduces behavior log size by 19% to 44% with minimal system overhead (only 2 seconds latency and 15 MB memory usage), providing a more efficient data foundation for broader adoption of on-device ML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13405v1</guid>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3771575</arxiv:DOI>
      <dc:creator>Chen Gong, Yan Zhuang, Zhenzhe Zheng, Yiliu Chen, Sheng Wang, Fan Wu, Guihai Chen</dc:creator>
    </item>
    <item>
      <title>Mobile Coverage Analysis using Crowdsourced Data</title>
      <link>https://arxiv.org/abs/2510.13459</link>
      <description>arXiv:2510.13459v1 Announce Type: cross 
Abstract: Effective assessment of mobile network coverage and the precise identification of service weak spots are paramount for network operators striving to enhance user Quality of Experience (QoE). This paper presents a novel framework for mobile coverage and weak spot analysis utilising crowdsourced QoE data. The core of our methodology involves coverage analysis at the individual cell (antenna) level, subsequently aggregated to the site level, using empirical geolocation data. A key contribution of this research is the application of One-Class Support Vector Machine (OC-SVM) algorithm for calculating mobile network coverage. This approach models the decision hyperplane as the effective coverage contour, facilitating robust calculation of coverage areas for individual cells and entire sites. The same methodology is extended to analyse crowdsourced service loss reports, thereby identifying and quantifying geographically localised weak spots. Our findings demonstrate the efficacy of this novel framework in accurately mapping mobile coverage and, crucially, in highlighting granular areas of signal deficiency, particularly within complex urban environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13459v1</guid>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.NI</category>
      <category>stat.AP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Timothy Wong, Tom Freeman, Joseph Feehily</dc:creator>
    </item>
    <item>
      <title>Load-Balancing versus Anycast: A First Look at Operational Challenges</title>
      <link>https://arxiv.org/abs/2503.14351</link>
      <description>arXiv:2503.14351v2 Announce Type: replace 
Abstract: Load Balancing (LB) is a routing strategy that increases performance by distributing traffic over multiple outgoing paths. In this work, we introduce a novel methodology to detect the influence of LB on anycast routing, which can be used by operators to detect networks that experience anycast site flipping, where traffic from a single client reaches multiple anycast sites. We use our methodology to measure the effects of LB-behavior on anycast routing at a global scale, covering both IPv4 and IPv6. Our results show that LB-induced anycast site flipping is widespread. The results also show our method can detect LB implementations on the global Internet, including detection and classification of Points-of-Presence (PoP) and egress selection techniques deployed by hypergiants, cloud providers, and network operators. We observe LB-induced site flipping directs distinct flows to different anycast sites with significant latency inflation. In cases with two paths between an anycast instance and a load-balanced destination, we observe an average RTT difference of 30 ms with 8% of load-balanced destinations seeing RTT differences of over 100 ms. Being able to detect these cases can help anycast operators significantly improve their service for affected clients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.14351v2</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Remi Hendriks, Mattijs Jonker, Roland van Rijswijk-Deij, Raffaele Sommese</dc:creator>
    </item>
    <item>
      <title>LACeS: An Open, Fast, Responsible, and Efficient Longitudinal Anycast Census System</title>
      <link>https://arxiv.org/abs/2503.20554</link>
      <description>arXiv:2503.20554v3 Announce Type: replace 
Abstract: IP anycast replicates an address at multiple locations to reduce latency and enhance resilience. Due to anycast's crucial role in the modern Internet, earlier research introduced tools to perform anycast censuses. The first, iGreedy, uses latency measurements from geographically dispersed locations to map anycast deployments. The second, MAnycast2, uses anycast to perform a census of other anycast networks. MAnycast2's advantage is speed and coverage but suffers from problems with accuracy, while iGreedy is highly accurate but slower using author-defined probing rates and costlier. In this paper we address the shortcomings of both systems and present LACeS (Longitudinal Anycast Census System). Taking MAnycast2 as a basis, we completely redesign its measurement pipeline, and add support for distributed probing, additional protocols (DNS over UDP, TCP SYN/ACK, and IPv6) and latency measurements similar to iGreedy. We validate LACeS on an anycast testbed with 32 globally distributed nodes, compare against an external anycast production deployment, extensive latency measurements with RIPE Atlas and cross-check over 60% of detected anycast using operator ground truth that shows LACeS achieves high accuracy. Finally, we provide a longitudinal analysis of anycast, covering 17+ months, showing LACeS achieves high precision. We make continual daily LACeS censuses available to the community and release the source code of the tool under a permissive open source license.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.20554v3</guid>
      <category>cs.NI</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Remi Hendriks, Matthew Luckie, Mattijs Jonker, Raffaele Sommese, Roland van Rijswijk-Deij</dc:creator>
    </item>
    <item>
      <title>Evolution of AI Agent Registry Solutions: Centralized, Enterprise, and Distributed Approaches</title>
      <link>https://arxiv.org/abs/2508.03095</link>
      <description>arXiv:2508.03095v2 Announce Type: replace 
Abstract: Autonomous AI agents now operate across cloud, enterprise, and decentralized domains, creating demand for registry infrastructures that enable trustworthy discovery, capability negotiation, and identity assurance. We analyze five prominent approaches: (1) MCP Registry (centralized publication of mcp.json descriptors), (2) A2A Agent Cards (decentralized self-describing JSON capability manifests), (3) AGNTCY Agent Directory Service (IPFS Kademlia DHT content routing extended for semantic taxonomy-based content discovery, OCI artifact storage, and Sigstore-backed integrity), (4) Microsoft Entra Agent ID (enterprise SaaS directory with policy and zero-trust integration), and (5) NANDA Index AgentFacts (cryptographically verifiable, privacy-preserving fact model with credentialed assertions). Using four evaluation dimensions: security, authentication, scalability, and maintainability, we surface architectural trade-offs between centralized control, enterprise governance, and distributed resilience. We conclude with design recommendations for an emerging Internet of AI Agents requiring verifiable identity, adaptive discovery flows, and interoperable capability semantics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.03095v2</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditi Singh, Abul Ehtesham, Mahesh Lambe, Jared James Grogan, Abhishek Singh, Saket Kumar, Luca Muscariello, Vijoy Pandey, Guillaume Sauvage De Saint Marc, Pradyumna Chari, Ramesh Raskar</dc:creator>
    </item>
    <item>
      <title>Toward Sustainable Subterranean mMTC: Space-Air-Ground-Underground Networks Powered by LoRaWAN and Wireless Energy Transfer</title>
      <link>https://arxiv.org/abs/2508.15058</link>
      <description>arXiv:2508.15058v2 Announce Type: replace 
Abstract: Wireless underground sensor networks (WUSNs), which enable real-time sensing and monitoring of underground resources by underground devices (UDs), hold great promise for delivering substantial social and economic benefits across various verticals. However, due to the harsh subterranean environment, scarce network resources, and restricted communication coverage, WUSNs face significant challenges in supporting sustainable massive machine-type communications (mMTC), particularly in remote, disaster-stricken, and hard-to-reach areas. To complement this, we conceptualize in this study a novel space-air-ground-underground integrated network (SAGUIN) architecture that seamlessly incorporates satellite systems, aerial platforms, terrestrial networks, and underground communications. On this basis, we integrate LoRaWAN and wireless energy transfer (WET) technologies into SAGUIN to enable sustainable subterranean mMTC. We begin by reviewing the relevant technical background and presenting the architecture and implementation challenges of SAGUIN. Then, we employ simulations to model a remote underground pipeline monitoring scenario to evaluate the feasibility and performance of SAGUIN based on LoRaWAN and WET technologies, focusing on the effects of parameters such as underground conditions, time allocation, LoRaWAN spread factor (SF) configurations, reporting periods, and harvested energy levels. Our results evidence that the proposed SAGUIN system, when combined with the derived time allocation strategy and an appropriate SF, can effectively extend the operational lifetime of UDs, thereby facilitating sustainable subterranean mMTC. Finally, we pinpoint key challenges and future research directions for SAGUIN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.15058v2</guid>
      <category>cs.NI</category>
      <category>eess.SP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaiqiang Lin, Mohamed-Slim Alouini</dc:creator>
    </item>
    <item>
      <title>ASE: Practical Acoustic Speed Estimation Beyond Doppler via Sound Diffusion Field</title>
      <link>https://arxiv.org/abs/2412.20142</link>
      <description>arXiv:2412.20142v2 Announce Type: replace-cross 
Abstract: Passive human speed estimation plays a critical role in acoustic sensing. Despite extensive study, existing systems, however, suffer from various limitations: First, the channel measurement rate proves inadequate to estimate high moving speeds. Second, previous acoustic speed estimation exploits Doppler Frequency Shifts (DFS) created by moving targets and relies on microphone arrays, making them only capable of sensing the radial speed within a constrained distance. To overcome these issues, we present ASE, an accurate and robust Acoustic Speed Estimation system on a single commodity microphone. We propose a novel Orthogonal Time-Delayed Multiplexing (OTDM) scheme for acoustic channel estimation at a high rate that was previously infeasible, making it possible to estimate high speeds. We then model the sound propagation from a unique perspective of the acoustic diffusion field, and infer the speed from the acoustic spatial distribution, a completely different way of thinking about speed estimation beyond prior DFS-based approaches. We further develop novel techniques for motion detection and signal enhancement to deliver a robust and practical system. We implement and evaluate ASE through extensive real-world experiments. Our results show that ASE reliably tracks walking speed, independently of target location and direction, with a mean error of 0.13 m/s, a reduction of 2.5x from DFS, and a detection rate of 97.4% for large coverage, e.g., free walking in a 4m x 4m room. We believe ASE pushes acoustic speed estimation beyond the conventional DFS-based paradigm and inspires exciting research in acoustic sensing. Code is available at https://github.com/aiot-lab/ASE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.20142v2</guid>
      <category>cs.HC</category>
      <category>cs.NI</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>eess.SP</category>
      <pubDate>Thu, 16 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3749475</arxiv:DOI>
      <arxiv:journal_reference>Sheng Lyu and Chenshu Wu. 2025. ASE: Practical Acoustic Speed Estimation Beyond Doppler via Sound Diffusion Field. Proc. ACM Interact. Mob. Wearable Ubiquitous Technol. 9, 3, Article 115 (September 2025), 26 pages</arxiv:journal_reference>
      <dc:creator>Sheng Lyu, Chenshu Wu</dc:creator>
    </item>
  </channel>
</rss>
