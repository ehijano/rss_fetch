<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Jul 2025 01:40:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hemispheric-Specific Coupling Improves Modeling of Functional Connectivity Using Wilson-Cowan Dynamics</title>
      <link>https://arxiv.org/abs/2506.22951</link>
      <description>arXiv:2506.22951v1 Announce Type: new 
Abstract: Large-scale neural mass models have been widely used to simulate resting-state brain activity from structural connectivity. In this work, we extend a well-established Wilson--Cowan framework by introducing a novel hemispheric-specific coupling scheme that differentiates between intra-hemispheric and inter-hemispheric structural interactions. We apply this model to empirical cortical connectomes and resting-state fMRI data from matched control and schizophrenia groups. Simulated functional connectivity is computed from the band-limited envelope correlations of regional excitatory activity and compared against empirical functional connectivity matrices. Our results show that incorporating hemispheric asymmetries enhances the correlation between simulated and empirical functional connectivity, highlighting the importance of anatomically-informed coupling strategies in improving the biological realism of large-scale brain network models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22951v1</guid>
      <category>q-bio.NC</category>
      <category>nlin.CD</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ramiro Pl\"uss, Hern\'an Villota, Patricio Orio</dc:creator>
    </item>
    <item>
      <title>Distinct Modes of Functional Neural Organization in Autism: Insights from Dynamical Systems Analysis of Resting-State EEG</title>
      <link>https://arxiv.org/abs/2506.23013</link>
      <description>arXiv:2506.23013v1 Announce Type: new 
Abstract: While differences in patterns of functional connectivity and neural synchronization have been reported between individuals on the autism spectrum and neurotypical peers at various age stages, these differences appear to be subtle and may not be captured by typical quantitative measures of EEG. We used the dynamical systems approach to analyze resting-state EEG to investigate fine-grained spatiotemporal organization of brain networks in autistic and neurotypical young adults. While power spectra showed minimal group differences, autistic participants exhibited higher Lyapunov exponents (indicating less stable neural dynamics), weaker phase synchronization, and lower clustering/efficiency of functional networks during eyes-open resting state, suggesting more random and less stably connected neural dynamics in comparison to those of neurotypical peers. Closing the eyes regularized neural dynamics in autistic but not neurotypical participants, with increases in synchrony strength, transient desynchronization patterning, and functional connectivity observed in the autistic group. The results point to the distinct modes of neural dynamics organization that could reflect life-long adaptations to sensory inputs that shape both resting-state neural activity and cognitive processing strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23013v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.biopsycho.2025.109077</arxiv:DOI>
      <arxiv:journal_reference>Biological Psychology (2025)</arxiv:journal_reference>
      <dc:creator>Sungwoo Ahn, Leonid L Rubchinsky, Evie A Malaia</dc:creator>
    </item>
    <item>
      <title>Neural Langevin Machine: a local asymmetric learning rule can be creative</title>
      <link>https://arxiv.org/abs/2506.23546</link>
      <description>arXiv:2506.23546v1 Announce Type: new 
Abstract: Fixed points of recurrent neural networks can be leveraged to store and generate information. These fixed points can be captured by the Boltzmann-Gibbs measure, which leads to neural Langevin dynamics that can be used for sampling and learning a real dataset. We call this type of generative model neural Langevin machine, which is interpretable due to its analytic form of distribution and is simple to train. Moreover, the learning process is derived as a local asymmetric plasticity rule, bearing biological relevance. Therefore, one can realize a continuous sampling of creative dynamics in a neural network, mimicking an imagination process in brain circuits. This neural Langevin machine may be another promising generative model, at least in its strength in circuit-based sampling and biologically plausible learning rule.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23546v1</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zhendong Yu, Weizhong Huang, Haiping Huang</dc:creator>
    </item>
    <item>
      <title>An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals</title>
      <link>https://arxiv.org/abs/2506.22476</link>
      <description>arXiv:2506.22476v1 Announce Type: cross 
Abstract: Objective skill assessment in high-stakes procedural environments requires models that not only decode underlying cognitive and motor processes but also generalize across tasks, individuals, and experimental contexts. While prior work has demonstrated the potential of functional near-infrared spectroscopy (fNIRS) for evaluating cognitive-motor performance, existing approaches are often task-specific, rely on extensive preprocessing, and lack robustness to new procedures or conditions. Here, we introduce an interpretable transformer-based foundation model trained on minimally processed fNIRS signals for cross-procedural skill assessment. Pretrained using self-supervised learning on data from laparoscopic surgical tasks and endotracheal intubation (ETI), the model achieves greater than 88% classification accuracy on all tasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It generalizes to a novel emergency airway procedure--cricothyrotomy--using fewer than 30 labeled samples and a lightweight (less than 2k parameter) adapter module, attaining an AUC greater than 87%. Interpretability is achieved via a novel channel attention mechanism--developed specifically for fNIRS--that identifies functionally coherent prefrontal sub-networks validated through ablation studies. Temporal attention patterns align with task-critical phases and capture stress-induced changes in neural variability, offering insight into dynamic cognitive states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22476v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Subedi, S. De, L. Cavuoto, S. Schwaitzberg, M. Hackett, J. Norfleet</dc:creator>
    </item>
    <item>
      <title>Can "consciousness" be observed from large language model (LLM) internal states? Dissecting LLM representations obtained from Theory of Mind test with Integrated Information Theory and Span Representation analysis</title>
      <link>https://arxiv.org/abs/2506.22516</link>
      <description>arXiv:2506.22516v1 Announce Type: cross 
Abstract: Integrated Information Theory (IIT) provides a quantitative framework for explaining consciousness phenomenon, positing that conscious systems comprise elements integrated through causal properties. We apply IIT 3.0 and 4.0 -- the latest iterations of this framework -- to sequences of Large Language Model (LLM) representations, analyzing data derived from existing Theory of Mind (ToM) test results. Our study systematically investigates whether the differences of ToM test performances, when presented in the LLM representations, can be revealed by IIT estimates, i.e., $\Phi^{\max}$ (IIT 3.0), $\Phi$ (IIT 4.0), Conceptual Information (IIT 3.0), and $\Phi$-structure (IIT 4.0). Furthermore, we compare these metrics with the Span Representations independent of any estimate for consciousness. This additional effort aims to differentiate between potential "consciousness" phenomena and inherent separations within LLM representational space. We conduct comprehensive experiments examining variations across LLM transformer layers and linguistic spans from stimuli. Our results suggest that sequences of contemporary Transformer-based LLM representations lack statistically significant indicators of observed "consciousness" phenomena but exhibit intriguing patterns under $\textit{spatio}$-permutational analyses. The Appendix and code are available as Supplementary Materials at: https://doi.org/10.1016/j.nlp.2025.100163.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22516v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.NE</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.nlp.2025.100163</arxiv:DOI>
      <arxiv:journal_reference>Natural Language Processing Journal 12C (2025) 100163</arxiv:journal_reference>
      <dc:creator>Jingkai Li</dc:creator>
    </item>
    <item>
      <title>Hierarchical Characterization of Brain Dynamics via State Space-based Vector Quantization</title>
      <link>https://arxiv.org/abs/2506.22952</link>
      <description>arXiv:2506.22952v1 Announce Type: cross 
Abstract: Understanding brain dynamics through functional Magnetic Resonance Imaging (fMRI) remains a fundamental challenge in neuroscience, particularly in capturing how the brain transitions between various functional states. Recently, metastability, which refers to temporarily stable brain states, has offered a promising paradigm to quantify complex brain signals into interpretable, discretized representations. In particular, compared to cluster-based machine learning approaches, tokenization approaches leveraging vector quantization have shown promise in representation learning with powerful reconstruction and predictive capabilities. However, most existing methods ignore brain transition dependencies and lack a quantification of brain dynamics into representative and stable embeddings. In this study, we propose a Hierarchical State space-based Tokenization network, termed HST, which quantizes brain states and transitions in a hierarchical structure based on a state space-based model. We introduce a refined clustered Vector-Quantization Variational AutoEncoder (VQ-VAE) that incorporates quantization error feedback and clustering to improve quantization performance while facilitating metastability with representative and stable token representations. We validate our HST on two public fMRI datasets, demonstrating its effectiveness in quantifying the hierarchical dynamics of the brain and its potential in disease diagnosis and reconstruction performance. Our method offers a promising framework for the characterization of brain dynamics, facilitating the analysis of metastability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22952v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yanwu Yang, Thomas Wolfers</dc:creator>
    </item>
    <item>
      <title>CSBrain: A Cross-scale Spatiotemporal Brain Foundation Model for EEG Decoding</title>
      <link>https://arxiv.org/abs/2506.23075</link>
      <description>arXiv:2506.23075v1 Announce Type: cross 
Abstract: Understanding and decoding brain activity from electroencephalography (EEG) signals is a fundamental challenge in neuroscience and AI, with applications in cognition, emotion recognition, diagnosis, and brain-computer interfaces. While recent EEG foundation models advance generalized decoding via unified architectures and large-scale pretraining, they adopt a scale-agnostic dense modeling paradigm inherited from NLP and vision. This design neglects a core property of neural activity: cross-scale spatiotemporal structure. EEG task patterns span a wide range of temporal and spatial scales, from short bursts to slow rhythms, and from localized cortical responses to distributed interactions. Ignoring this diversity leads to suboptimal representations and weak generalization. We propose CSBrain, a Cross-scale Spatiotemporal Brain foundation model for generalized EEG decoding. CSBrain introduces: (i) Cross-scale Spatiotemporal Tokenization (CST), which aggregates multi-scale features from localized temporal windows and anatomical brain regions into compact scale-aware tokens; and (ii) Structured Sparse Attention (SSA), which captures cross-window and cross-region dependencies, enhancing scale diversity while removing spurious correlations. CST and SSA are alternately stacked to progressively integrate multi-scale dependencies. Experiments on 11 EEG tasks across 16 datasets show that CSBrain consistently outperforms task-specific and foundation model baselines. These results establish cross-scale modeling as a key inductive bias and position CSBrain as a robust backbone for future brain-AI research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23075v1</guid>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>eess.SP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen Zhou, Jiamin Wu, Zichen Ren, Zhouheng Yao, Weiheng Lu, Kunyu Peng, Qihao Zheng, Chunfeng Song, Wanli Ouyang, Chao Gou</dc:creator>
    </item>
    <item>
      <title>Objective-Free Local Learning and Emergent Language Structure in Thinking Machines</title>
      <link>https://arxiv.org/abs/2506.23293</link>
      <description>arXiv:2506.23293v1 Announce Type: cross 
Abstract: We present a neuro-symbolic framework for generative language modeling based on local, event-driven emergent learning. At its core is a hierarchical Hopfield memory chain acting as a compositional short-term memory and dynamic tokenizer (retokenizer). Rather than relying on predefined tokens or supervision, the model builds structure from scratch, learning symbol sequences as multi-scale representations. It constructs projection tensors that bind co-occurring features into hierarchical tokens, introducing redundancy (i.e an emergent gauge structure) and enabling compression of local activations into long-range dependencies. Curiously, we find that the retokenizer can filter natural language patterns from noise, generating synthetic languages with coherent internal morphology -- quantifiably the same as human language. Language is learned in a local (Hebbian) fashion, where model constraints dictate allowed emergent structure, and new information is retained in alignment with this structure. The absence of a global objective enables a form of plasticity not found in conventional language models, allowing the system to generalize beyond its initial inference class -- even without explicit data. We demonstrate that briefly activating a new neuron during inference binds distributed multi-scale token features into a symbolic embedding. These emergent embedding neurons act as long-term memory and support a key-value mechanism for compositional inference and generalization. This architecture provides a methodological foundation for studying how symbolic structure can emerge from local neural learning. It offers a new pathway for building scalable, interpretable neuro-symbolic systems -- where tokens, grammar, and reasoning arise as compressed memory traces within a Hopfield hierarchy. This approach advances the development of neuromorphic architectures for generative language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23293v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. Myles Eugenio</dc:creator>
    </item>
    <item>
      <title>Peripheral brain interfacing: Reading high-frequency brain signals from the output of the nervous system</title>
      <link>https://arxiv.org/abs/2410.20872</link>
      <description>arXiv:2410.20872v2 Announce Type: replace 
Abstract: Accurate and robust recording and decoding from the central nervous system (CNS) is essential for advances in human-machine interfacing. However, technologies used to directly measure CNS activity are limited by their resolution, sensitivity to interferences, and invasiveness. Advances in muscle recordings and deep learning allow us to decode the spiking activity of spinal motor neurons (MNs) in real time and with high accuracy. MNs represent the motor output layer of the CNS, receiving and sampling signals originating in different regions in the nervous system, and generating the neural commands that control muscles. The input signals to MNs can be estimated from the MN outputs. Here we argue that peripheral neural interfaces using muscle sensors represent a promising, non-invasive approach to estimate some neural activity from the CNS that reaches the MNs but does not directly modulate force production. We also discuss the evidence supporting this concept, and the necessary advances to consolidate and test MN-based CNS interfaces in controlled and real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20872v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Jaime Ib\'a\~nez, Blanka Zicher, Etienne Burdet, Stuart N. Baker, Carsten Mehring, Dario Farina</dc:creator>
    </item>
    <item>
      <title>Functional Correspondences in the Human and Marmoset Visual Cortex During Movie Watching: Insights from Correlation, Redundancy, and Synergy</title>
      <link>https://arxiv.org/abs/2503.15218</link>
      <description>arXiv:2503.15218v3 Announce Type: replace 
Abstract: The world of beauty is deeply connected to the visual cortex, as perception often begins with vision in both humans and marmosets. In this study, to investigate their functional correspondences, we used 13 healthy human volunteers (9 males and 4 females, aged 22-56 years) and 8 common marmosets (6 males and 2 females, aged 20-42 months). We then measured pairwise and beyond-pairwise correlations, redundancy, and synergy in movie-driven fMRI data across species. First, we consistently observed a high degree of functional similarity in visual processing within and between species, suggesting that integrative processing mechanisms are preserved in both humans and marmosets, despite potential differences in their specific activity patterns. Second, we found that the strongest functional correspondences during movie watching occurred between the human peri-entorhinal and entorhinal cortex (PeEc) and the occipitotemporal high-level visual regions in the marmoset, reflecting a synergistic functional relationship. This suggests that these regions share complementary and integrated patterns of information processing across species. Third, redundancy measures maintained stable high-order hubs, indicating a steady core of shared information processing, while synergy measures revealed a dynamic shift from low- to high-level visual regions as interaction increased, reflecting adaptive integration. This highlights distinct patterns of information processing across the visual hierarchy. Ultimately, our results reveal the marmoset as a compelling model for investigating visual perception, distinguished by its remarkable functional parallels to the human visual cortex.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15218v3</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Ting Xu, Vince D. Calhoun</dc:creator>
    </item>
    <item>
      <title>The Relationship between Cognition and Computation: "Global-first" Cognition versus Local-first Computation</title>
      <link>https://arxiv.org/abs/2506.17970</link>
      <description>arXiv:2506.17970v3 Announce Type: replace 
Abstract: What fundamental research questions are essential for advancing toward brain-inspired AI or AGI capable of performing any intellectual task a human can? We believe the key question today is the relationship between cognition and computation (RCC). For example, the widely discussed question "Will artificial intelligence replace the human mind?" is, in essence and in scientific terms, an issue concerning RCC.
  We have chosen to classify RCC into four categories:
  1. The relationship between the primitives of cognition and the primitives of computation.
  2. The relationship between the anatomical structure of neural representation of cognition and the computational architecture of artificial intelligence.
  3. The relationship between emergents in cognition and emergents in computation.
  4. The relationship between the mathematical foundations of cognition and computation.
  The cumulative empirical evidence and theoretical analyses led us to formulate the "Global-first" principle, which highlights the contrast between "Global-first" cognition and local-first computation in RCC, offering a specific and well-defined starting point for understanding RCC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.17970v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lin Chen</dc:creator>
    </item>
    <item>
      <title>Automatic Depression Assessment using Machine Learning: A Comprehensive Survey</title>
      <link>https://arxiv.org/abs/2506.18915</link>
      <description>arXiv:2506.18915v2 Announce Type: replace 
Abstract: Depression is a common mental illness across current human society. Traditional depression assessment relying on inventories and interviews with psychologists frequently suffer from subjective diagnosis results, slow and expensive diagnosis process as well as lack of human resources. Since there is a solid evidence that depression is reflected by various human internal brain activities and external expressive behaviours, early traditional machine learning (ML) and advanced deep learning (DL) models have been widely explored for human behaviour-based automatic depression assessment (ADA) since 2012. However, recent ADA surveys typically only focus on a limited number of human behaviour modalities. Despite being used as a theoretical basis for developing ADA approaches, existing ADA surveys lack a comprehensive review and summary of multi-modal depression-related human behaviours. To bridge this gap, this paper specifically summarises depression-related human behaviours across a range of modalities (e.g. the human brain, verbal language and non-verbal audio/facial/body behaviours). We focus on conducting an up-to-date and comprehensive survey of ML-based ADA approaches for learning depression cues from these behaviours as well as discussing and comparing their distinctive features and limitations. In addition, we also review existing ADA competitions and datasets, identify and discuss the main challenges and opportunities to provide further research directions for future ADA researchers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.18915v2</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyang Song, Yupeng Huo, Shiqing Tang, Jiaee Cheong, Rui Gao, Michel Valstar, Hatice Gunes</dc:creator>
    </item>
    <item>
      <title>Brain-inspired and Self-based Artificial Intelligence</title>
      <link>https://arxiv.org/abs/2402.18784</link>
      <description>arXiv:2402.18784v2 Announce Type: replace-cross 
Abstract: The question "Can machines think?" and the Turing Test to assess whether machines could achieve human-level intelligence is one of the roots of AI. With the philosophical argument "I think, therefore I am", this paper challenge the idea of a "thinking machine" supported by current AIs since there is no sense of self in them. Current artificial intelligence is only seemingly intelligent information processing and does not truly understand or be subjectively aware of oneself and perceive the world with the self as human intelligence does. In this paper, we introduce a Brain-inspired and Self-based Artificial Intelligence (BriSe AI) paradigm. This BriSe AI paradigm is dedicated to coordinating various cognitive functions and learning strategies in a self-organized manner to build human-level AI models and robotic applications. Specifically, BriSe AI emphasizes the crucial role of the Self in shaping the future AI, rooted with a practical hierarchical Self framework, including Perception and Learning, Bodily Self, Autonomous Self, Social Self, and Conceptual Self. The hierarchical framework of the Self highlights self-based environment perception, self-bodily modeling, autonomous interaction with the environment, social interaction and collaboration with others, and even more abstract understanding of the Self. Furthermore, the positive mutual promotion and support among multiple levels of Self, as well as between Self and learning, enhance the BriSe AI's conscious understanding of information and flexible adaptation to complex environments, serving as a driving force propelling BriSe AI towards real Artificial General Intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18784v2</guid>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yi Zeng, Feifei Zhao, Yuxuan Zhao, Dongcheng Zhao, Enmeng Lu, Qian Zhang, Yuwei Wang, Hui Feng, Zhuoya Zhao, Jihang Wang, Qingqun Kong, Yinqian Sun, Yang Li, Guobin Shen, Bing Han, Yiting Dong, Wenxuan Pan, Xiang He, Aorigele Bao, Jin Wang</dc:creator>
    </item>
    <item>
      <title>Statistical Mechanics of Support Vector Regression</title>
      <link>https://arxiv.org/abs/2412.05439</link>
      <description>arXiv:2412.05439v2 Announce Type: replace-cross 
Abstract: A key problem in deep learning and computational neuroscience is relating the geometrical properties of neural representations to task performance. Here, we consider this problem for continuous decoding tasks where neural variability may affect task precision. Using methods from statistical mechanics, we study the average-case learning curves for $\varepsilon$-insensitive Support Vector Regression ($\varepsilon$-SVR) and discuss its capacity as a measure of linear decodability. Our analysis reveals a phase transition in training error at a critical load, capturing the interplay between the tolerance parameter $\varepsilon$ and neural variability. We uncover a double-descent phenomenon in the generalization error, showing that $\varepsilon$ acts as a regularizer, both suppressing and shifting these peaks. Theoretical predictions are validated both with toy models and deep neural networks, extending the theory of Support Vector Machines to continuous tasks with inherent neural variability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.05439v2</guid>
      <category>cond-mat.dis-nn</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/78dr-c4xd</arxiv:DOI>
      <dc:creator>Abdulkadir Canatar, SueYeon Chung</dc:creator>
    </item>
  </channel>
</rss>
