<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 30 Sep 2025 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Grouped Satisficing Paths in Pure Strategy Games: a Topological Perspective</title>
      <link>https://arxiv.org/abs/2509.23157</link>
      <description>arXiv:2509.23157v1 Announce Type: new 
Abstract: In game theory and multi-agent reinforcement learning (MARL), each agent selects a strategy, interacts with the environment and other agents, and subsequently updates its strategy based on the received payoff. This process generates a sequence of joint strategies $(s^t)_{t \geq 0}$, where $s^t$ represents the strategy profile of all agents at time step $t$. A widely adopted principle in MARL algorithms is "win-stay, lose-shift", which dictates that an agent retains its current strategy if it achieves the best response. This principle exhibits a fixed-point property when the joint strategy has become an equilibrium. The sequence of joint strategies under this principle is referred to as a satisficing path, a concept first introduced in [40] and explored in the context of $N$-player games in [39]. A fundamental question arises regarding this principle: Under what conditions does every initial joint strategy $s$ admit a finite-length satisficing path $(s^t)_{0 \leq t \leq T}$ where $s^0=s$ and $s^T$ is an equilibrium? This paper establishes a sufficient condition for such a property, and demonstrates that any finite-state Markov game, as well as any $N$-player game, guarantees the existence of a finite-length satisficing path from an arbitrary initial strategy to some equilibrium. These results provide a stronger theoretical foundation for the design of MARL algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23157v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yanqing Fu, Chao Huang, Chenrun Wang, Zhuping Wang</dc:creator>
    </item>
    <item>
      <title>Beyond Game Theory Optimal: Profit-Maximizing Poker Agents for No-Limit Holdem</title>
      <link>https://arxiv.org/abs/2509.23747</link>
      <description>arXiv:2509.23747v1 Announce Type: new 
Abstract: Game theory has grown into a major field over the past few decades, and poker has long served as one of its key case studies. Game-Theory-Optimal (GTO) provides strategies to avoid loss in poker, but pure GTO does not guarantee maximum profit. To this end, we aim to develop a model that outperforms GTO strategies to maximize profit in No Limit Holdem, in heads-up (two-player) and multi-way (more than two-player) situations. Our model finds the GTO foundation and goes further to exploit opponents. The model first navigates toward many simulated poker hands against itself and keeps adjusting its decisions until no action can reliably beat it, creating a strong baseline that is close to the theoretical best strategy. Then, it adapts by observing opponent behavior and adjusting its strategy to capture extra value accordingly. Our results indicate that Monte-Carlo Counterfactual Regret Minimization (CFR) performs best in heads-up situations and CFR remains the strongest method in most multi-way situations. By combining the defensive strength of GTO with real-time exploitation, our approach aims to show how poker agents can move from merely not losing to consistently winning against diverse opponents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23747v1</guid>
      <category>cs.GT</category>
      <category>cs.CL</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>SeungHyun Yi, Seungjun Yi</dc:creator>
    </item>
    <item>
      <title>Evolutionary hypergame dynamics: Introspection reasoning and social learning</title>
      <link>https://arxiv.org/abs/2509.24398</link>
      <description>arXiv:2509.24398v1 Announce Type: new 
Abstract: In the realm of evolutionary game theory, standard frameworks typically presuppose that every player possesses comprehensive knowledge and unrestricted access to the entire strategy space. However, real-world human society inherently harbors diverse levels of knowledge, experience, and background among individuals. Hypergames incorporate this heterogeneity by permitting individuals to differ in their access to the full strategy set, reflecting cognitive or informational constraints and giving rise to asymmetric strategic interactions. Yet, their evolutionary consequences remain underexplored. Our inquiry employs prototype models featuring three available strategies, focusing on social dilemmas involving cooperation, defection, and loner. These strategies manifest cyclic dominance, akin to the well-studied rock-paper-scissors dynamics, a foundational model in game theory. Our study spans both well-mixed and spatial lattice populations, delving into the intricacies of learning and evolution of the strategy set within the evolutionary hypergame dynamics. In stark contrast to traditional evolutionary game dynamics, our findings unveil nuanced and intricate phases, encompassing scenarios of loner dominance, coexistence of multiple strategy sets, combinations of cooperation and loner dominance, and more. Remarkably, we discern that heightened rationality significantly promotes cooperative behaviors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24398v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feipeng Zhang, Te Wu, Guofeng Zhang, Long Wang</dc:creator>
    </item>
    <item>
      <title>Dynamic Pricing of an Expiring Item under Strategic Buyers with Stochastic Arrival</title>
      <link>https://arxiv.org/abs/2509.24720</link>
      <description>arXiv:2509.24720v1 Announce Type: new 
Abstract: We study the optimal dynamic pricing of an expiring ticket or voucher, sold by a time-sensitive seller to strategic buyers who arrive stochastically with private values. The expiring nature creates a conflict: the seller's urgency to sell before expiration drives price reductions, which in turn incentivize buyers to wait. We seek the seller's optimal pricing policy that resolves this tension. The main analytical challenge is that buyer type is two-dimensional (valuation and arrival time), which makes equilibrium intractable under general strategies. To address this, we introduce the Value-Based Threshold (VBT) strategy, a tractable framework that decouples these two dimensions. Using this framework, we prove equilibrium existence via an ordinary differential equation and provide a constructive procedure for its characterization. We then derive near-optimal pricing policies for two stylized regimes: a constant price in thin markets and a linear discount in thick markets. Numerical frontier analysis confirms these benchmarks and shows how optimal policy adapts as the seller's time sensitivity changes. Our findings clarify the conflict between quick sales and strategic waiting. Sellers facing thick markets or high time sensitivity benefit from linear discounts, while in thin markets a constant price neutralizes buyers' incentive to wait. We also show this simple policy remains robust across broad conditions. For patient sellers, a quasi-auction schedule that maintains a high price until a sharp final drop is most effective in aggregating demand.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24720v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Suyeon Choi, Changhyun Kwon, Seungki Min</dc:creator>
    </item>
    <item>
      <title>A Bilevel Approach to Integrated Surgeon Scheduling and Surgery Planning solved via Branch-and-Price</title>
      <link>https://arxiv.org/abs/2509.24806</link>
      <description>arXiv:2509.24806v1 Announce Type: new 
Abstract: In this paper, we study a multi-agent scheduling problem for organising the operations within the operating room department. The head of the surgeon group and individual surgeons are together responsible for the surgeon schedule and surgical case planning. The surgeon head allocates time blocks to individual surgeons, whereas individual surgeons determine the planning of surgical cases independently, which might degrade the schedule quality envisaged by the surgeon head. The bilevel optimisation under study seeks an optimal Nash equilibrium solution -- a surgeon schedule and surgical case plan that optimise the objectives of the surgeon head, while ensuring that no individual surgeon can improve their own objective within the allocated time blocks. We propose a dedicated branch-and-price that adds lazy constraints to the formulation of surgeon-specific pricing problems to ensure an optimal bilevel feasible solution is retrieved. In this way, the surgeon head respects the objective requirements of the individual surgeons and the solution space can be searched efficiently. In the computational experiments, we validate the performance of the proposed algorithm and its dedicated components and provide insights into the benefits of attaining an equilibrium solution under different scenarios by calculating the price of stability and the price of decentralisation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24806v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.omega.2025.103424</arxiv:DOI>
      <dc:creator>Broos Maenhout, P\v{r}emysl \v{S}\r{u}cha, Viktorie Valdmanov\'a, Ond\v{r}ej Tkadlec, Jana Thao Rozlivkov\'a</dc:creator>
    </item>
    <item>
      <title>The Free Option Problem of ePBS</title>
      <link>https://arxiv.org/abs/2509.24849</link>
      <description>arXiv:2509.24849v1 Announce Type: new 
Abstract: Ethereum's upcoming Glamsterdam upgrade introduces EIP-7732 enshrined Proposer--Builder Separation (ePBS), which improves the block production pipeline by addressing trust and scalability challenges. Yet it also creates a new liveness risk: builders gain a short-dated ``free'' option to prevent the execution payload they committed to from becoming canonical, without incurring an additional penalty. Exercising this option renders an empty block for the slot in question, thereby degrading network liveness.
  We present the first systematic study of the free option problem. Our theoretical results predict that option value and exercise probability grow with market volatility, the length of the option window, and the share of block value derived from external signals such as external market prices. The availability of a free option will lead to mispricing and LP losses. The problem would be exacerbated if Ethereum further scales and attracts more liquidity. Empirical estimates of values and exercise probabilities on historical blocks largely confirm our theoretical predictions. While the option is rarely profitable to exercise on average (0.82\% of blocks assuming an 8-second option time window), it becomes significant in volatile periods, reaching up to 6\% of blocks on high-volatility days -- precisely when users most require timely execution.
  Moreover, builders whose block value relies heavily on CEX-DEX arbitrage are more likely to exercise the option. We demonstrate that mitigation strategies -- shortening the option window or penalizing exercised options -- effectively reduce liveness risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24849v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bruno Mazorra, Burak \"Oz, Christoph Schlegel, Fei Wu</dc:creator>
    </item>
    <item>
      <title>A Management Framework for Vehicular Cloudtoward Economic and Environmental Efficiency</title>
      <link>https://arxiv.org/abs/2509.24946</link>
      <description>arXiv:2509.24946v1 Announce Type: new 
Abstract: Vehicular Cloud Computing (VCC) leverages the idle computing capacity of vehicles to execute end-users' offloaded tasks without requiring new computation infrastructure. Despite its conceptual appeal, VCC adoption is hindered by the lack of quantitative evidence demonstrating its profitability and environmental advantages in real-world scenarios. This paper tackles the fundamental question: Can VCC be both profitable and sustainable? We address this problem by proposing a management scheme for VCC that combines energy-aware task allocation with a game-theoretic revenue-sharing mechanism. Our framework is the first to jointly model latency, energy consumption, monetary incentives, and carbon emissions within urban mobility and 5G communication settings. The task allocation strategy maximizes the aggregate stakeholder utility while satisfying deadlines and minimizing energy costs. The payoffs are distributed via a coalitional game theory adapted to dynamic vehicular environments, to prevent disincentivizing participants with potentially negative contributions. Extensive simulations demonstrate that our approach supports low-latency task execution, enables effective monetization of vehicular resources, and reduces CO2 emissions by more than 99% compared to conventional edge infrastructures, making VCC a practical and sustainable alternative to edge computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24946v1</guid>
      <category>cs.GT</category>
      <category>cs.DC</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rosario Patan\`e, Andrea Araldo, Nadjib Achir, Lila Boukhatem</dc:creator>
    </item>
    <item>
      <title>The Popular Dimension of Matchings</title>
      <link>https://arxiv.org/abs/2509.25150</link>
      <description>arXiv:2509.25150v1 Announce Type: new 
Abstract: We study popular matchings in three classical settings: the house allocation problem, the marriage problem, and the roommates problem. In the popular matching problem, (a subset of) the vertices in a graph have preference orderings over their potential matches. A matching is popular if it gets a plurality of votes in a pairwise election against any other matching. Unfortunately, popular matchings typically do not exist. So we study a natural relaxation, namely popular winning sets which are a set of matchings that collectively get a plurality of votes in a pairwise election against any other matching. The $\textit{popular dimension}$ is the minimum cardinality of a popular winning set, in the worst case over the problem class.
  We prove that the popular dimension is exactly $2$ in the house allocation problem, even if the voters are weighted and ties are allowed in their preference lists. For the marriage problem and the roommates problem, we prove that the popular dimension is between $2$ and $3$, when the agents are weighted and/or their preferences orderings allow ties. In the special case where the agents are unweighted and have strict preference orderings, the popular dimension of the marriage problem is known to be exactly $1$ and we prove the popular dimension of the roommates problem is exactly $2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25150v1</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Frank Connor, Louis-Roy Langevin, Ndiam\'e Ndiaye, Agn\`es Totschnig, Rohit Vasishta, Adrian Vetta</dc:creator>
    </item>
    <item>
      <title>Towards Strategic Persuasion with Language Models</title>
      <link>https://arxiv.org/abs/2509.22989</link>
      <description>arXiv:2509.22989v1 Announce Type: cross 
Abstract: Large language models (LLMs) have demonstrated strong persuasive capabilities comparable to those of humans, offering promising benefits while raising societal concerns about their deployment. However, systematically evaluating the persuasive capabilities of LLMs is inherently challenging, as the effectiveness of persuasion among humans varies significantly across different domains. In this paper, we take a theory-driven approach to provide a scalable and principled framework for measuring the persuasive capabilities of LLMs. Grounded in the Bayesian Persuasion (BP) framework, we repurpose existing human-human persuasion datasets to construct environments for evaluating and training LLMs in strategic persuasion. Our results reveal that frontier models can consistently achieve high persuasion gains and exhibit sophisticated persuasion strategies that align with theoretical predictions. Building on this, we use reinforcement learning to train LLMs for strategic persuasion in our environments. Our results also demonstrate that even small LLMs can obtain significantly higher persuasion gains through reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22989v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zirui Cheng, Jiaxuan You</dc:creator>
    </item>
    <item>
      <title>T-TAMER: Provably Taming Trade-offs in ML Serving</title>
      <link>https://arxiv.org/abs/2509.22992</link>
      <description>arXiv:2509.22992v1 Announce Type: cross 
Abstract: As machine learning models continue to grow in size and complexity, efficient serving faces increasingly broad trade-offs spanning accuracy, latency, resource usage, and other objectives. Multi-model serving further complicates these trade-offs; for example, in cascaded models, each early-exit decision balances latency reduction against potential accuracy loss. Despite the pervasiveness and importance of such trade-offs, current strategies remain largely heuristic and case-specific, limiting both their theoretical guarantees and general applicability.
  We present a general framework, T-Tamer, which formalizes this setting as a multi-stage decision process, where the objective is to determine both when to exit and which model to consult. Our main result shows that recall (i.e., the ability to revisit earlier models) is both necessary and sufficient for achieving provable performance guarantees. In particular, we prove that strategies without recall cannot obtain any constant-factor approximation to the optimal trade-off, whereas recall-based strategies provably attain the optimal trade-off in polynomial time.
  We validate our analysis through experiments on synthetic datasets and early-exit workloads for vision and NLP benchmarks. The results show that recall-based strategies consistently yield efficient accuracy-latency trade-offs. We hope this work provides a principled foundation for bridging heuristic practice with theoretical guarantees in the design of early-exit and cascaded models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.22992v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuanyuan Yang, Ruimin Zhang, Jamie Morgenstern, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>Game-Theoretic Understandings of Multi-Agent Systems with Multiple Objectives</title>
      <link>https://arxiv.org/abs/2509.23026</link>
      <description>arXiv:2509.23026v1 Announce Type: cross 
Abstract: In practical multi-agent systems, agents often have diverse objectives, which makes the system more complex, as each agent's performance across multiple criteria depends on the joint actions of all agents, creating intricate strategic trade-offs. To address this, we introduce the Multi-Objective Markov Game (MOMG), a framework for multi-agent reinforcement learning with multiple objectives. We propose the Pareto-Nash Equilibrium (PNE) as the primary solution concept, where no agent can unilaterally improve one objective without sacrificing performance on another. We prove existence of PNE, and establish an equivalence between the PNE and the set of Nash Equilibria of MOMG's corresponding linearly scalarized games, enabling solutions of MOMG by transferring to a standard single-objective Markov game. However, we note that computing a PNE is theoretically and computationally challenging, thus we propose and study weaker but more tractable solution concepts. Building on these foundations, we develop online learning algorithm that identify a single solution to MOMGs. Furthermore, we propose a two-phase, preference-free algorithm that decouples exploration from planning. Our algorithm enables computation of a PNE for any given preference profile without collecting new samples, providing an efficient methodological characterization of the entire Pareto-Nash front.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23026v1</guid>
      <category>cs.MA</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Wang</dc:creator>
    </item>
    <item>
      <title>Two-Sided Fairness in Many-to-One Matching</title>
      <link>https://arxiv.org/abs/2509.24111</link>
      <description>arXiv:2509.24111v1 Announce Type: cross 
Abstract: We consider a classic many-to-one matching setting, where participants need to be assigned to teams based on the preferences of both sides. Unlike most of the matching literature, we aim to provide fairness not only to participants, but also to teams using concepts from the literature of fair division. We present a polynomial-time algorithm that computes an allocation satisfying team-justified envy-freeness up to one participant, participant-justified envy-freeness, balancedness, Pareto optimality, and group-strategyproofness for participants, even in the possible presence of ties. Our algorithm generalizes both the Gale-Shapley algorithm from two-sided matching as well as the round-robin algorithm from fair division. We also discuss how our algorithm can be extended to accommodate quotas and incomplete preferences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.24111v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayumi Igarashi, Naoyuki Kamiyama, Yasushi Kawase, Warut Suksompong, Hanna Sumita, Yu Yokoi</dc:creator>
    </item>
    <item>
      <title>Incentive-Aligned Multi-Source LLM Summaries</title>
      <link>https://arxiv.org/abs/2509.25184</link>
      <description>arXiv:2509.25184v1 Announce Type: cross 
Abstract: Large language models (LLMs) are increasingly used in modern search and answer systems to synthesize multiple, sometimes conflicting, texts into a single response, yet current pipelines offer weak incentives for sources to be accurate and are vulnerable to adversarial content. We introduce Truthful Text Summarization (TTS), an incentive-aligned framework that improves factual robustness without ground-truth labels. TTS (i) decomposes a draft synthesis into atomic claims, (ii) elicits each source's stance on every claim, (iii) scores sources with an adapted multi-task peer-prediction mechanism that rewards informative agreement, and (iv) filters unreliable sources before re-summarizing. We establish formal guarantees that align a source's incentives with informative honesty, making truthful reporting the utility-maximizing strategy. Experiments show that TTS improves factual accuracy and robustness while preserving fluency, aligning exposure with informative corroboration and disincentivizing manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25184v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanchen Jiang, Zhe Feng, Aranyak Mehta</dc:creator>
    </item>
    <item>
      <title>A System-Level Analysis of Conference Peer Review</title>
      <link>https://arxiv.org/abs/2303.09020</link>
      <description>arXiv:2303.09020v2 Announce Type: replace 
Abstract: The conference peer review process involves three constituencies with different objectives: authors want their papers accepted at prestigious venues (and quickly), conferences want to present a program with many high-quality and few low-quality papers, and reviewers want to avoid being overburdened by reviews. These objectives are far from aligned, primarily because the evaluation of a submission is inherently noisy. Over the years, conferences have experimented with numerous policies to navigate the tradeoffs. These experiments include setting various bars for acceptance, varying the number of reviews per submission, requiring prior reviews to be included with resubmissions, and others. In this work, we investigate, both analytically and empirically, how well various policies work, and more importantly, why they do or do not work.
  We model the conference-author interactions as a Stackelberg game in which a prestigious conference commits to an acceptance policy; the authors best-respond by (re)submitting or not (re)submitting to the conference in each round of review, the alternative being a "sure accept" (such as a lightly refereed venue). Our main results include the following observations: 1) the conference should typically set a higher acceptance threshold than the actual desired quality; we call this the "resubmission gap". 2) the reviewing load is heavily driven by resubmissions of borderline papers - therefore, a judicious choice of acceptance threshold may lead to fewer reviews while incurring an acceptable loss in conference quality. 3) conference prestige, reviewer inaccuracy, and author patience increase the resubmission gap, and thus increase the review load for a fixed level of conference quality. For robustness, we further consider different models of paper quality and compare our theoretical results to simulations based on plausible parameters estimated from real data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.09020v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3490486.3538235</arxiv:DOI>
      <dc:creator>Yichi Zhang, Fang-Yi Yu, Grant Schoenebeck, David Kempe</dc:creator>
    </item>
    <item>
      <title>Is Thompson Sampling Susceptible to Algorithmic Collusion?</title>
      <link>https://arxiv.org/abs/2405.17463</link>
      <description>arXiv:2405.17463v2 Announce Type: replace 
Abstract: When two players are engaged in a repeated game with unknown payoff matrices, they may use single-agent multi-armed bandit algorithms to choose the actions independent of each other. We show that when the players use Thompson sampling, the game dynamics converges to the Nash equilibrium under a mild assumption on the payoff matrices. Therefore, algorithmic collusion doesn't arise in this case despite the fact that the players do not intentionally deploy competitive strategies. To prove the convergence result, we find that the framework developed in stochastic approximation doesn't apply, because of the sporadic and infrequent updates of the inferior actions and the lack of Lipschitz continuity. We develop a novel sample-path-wise approach to show the convergence. However, when the payoff matrices do not satisfy the assumption, the game may converge to collusive outcomes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17463v2</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yi Xiong, Ningyuan Chen, Xuefeng Gao</dc:creator>
    </item>
    <item>
      <title>Second-Order Algorithms for Finding Local Nash Equilibria in Zero-Sum Games</title>
      <link>https://arxiv.org/abs/2406.03565</link>
      <description>arXiv:2406.03565v3 Announce Type: replace 
Abstract: Zero-sum games arise in a wide variety of problems, including robust optimization and adversarial learning. However, algorithms deployed for finding a local Nash equilibrium in these games often converge to non-Nash stationary points. This highlights a key challenge: for any algorithm, the stability properties of its underlying dynamical system can cause non-Nash points to be potential attractors. To overcome this challenge, algorithms must account for subtleties involving the curvatures of players' costs. To this end, we leverage dynamical system theory and develop a second-order algorithm for finding a local Nash equilibrium in the smooth, possibly nonconvex-nonconcave, zero-sum game setting. First, we prove that this novel method guarantees convergence to only local Nash equilibria with an asymptotic local \textit{linear} convergence rate. We then interpret a version of this method as a modified Gauss-Newton algorithm with local \textit{superlinear} convergence to the neighborhood of a point that satisfies first-order local Nash equilibrium conditions. In comparison, current related state-of-the-art methods with similar guarantees do not offer convergence rates in the nonconvex-nonconcave setting. Furthermore, we show that this approach naturally generalizes to settings with convex and potentially coupled constraints while retaining earlier guarantees of convergence to only local (generalized) Nash equilibria. Code for our experiments can be found at https://github.com/CLeARoboticsLab/ZeroSumGameSolve.jl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.03565v3</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kushagra Gupta, Xinjie Liu, Ross Allen, Ufuk Topcu, David Fridovich-Keil</dc:creator>
    </item>
    <item>
      <title>Mixing Any Cocktail with Limited Ingredients: On the Structure of Payoff Sets in Multi-Objective POMDPs and its Impact on Randomised Strategies</title>
      <link>https://arxiv.org/abs/2502.18296</link>
      <description>arXiv:2502.18296v2 Announce Type: replace 
Abstract: We consider multi-dimensional payoff functions in partially observable Markov decision processes. We study the structure of the set of expected payoff vectors of all strategies (policies) and study what kind are needed to achieve a given expected payoff vector. In general, pure strategies (i.e., not resorting to randomisation) do not suffice for this problem.
  We prove that for any payoff for which the expectation is well-defined under all strategies, it is sufficient to mix (i.e., randomly select a pure strategy at the start of a play and committing to it for the rest of the play) finitely many pure strategies to approximate any expected payoff vector up to any precision. Furthermore, for any payoff for which the expected payoff is finite under all strategies, any expected payoff can be obtained exactly by mixing finitely many strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.18296v2</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.FL</category>
      <category>cs.LO</category>
      <category>math.PR</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>James C. A. Main, Mickael Randour</dc:creator>
    </item>
    <item>
      <title>Last-Iterate Convergence: Zero-Sum Games and Constrained Min-Max Optimization</title>
      <link>https://arxiv.org/abs/1807.04252</link>
      <description>arXiv:1807.04252v5 Announce Type: replace-cross 
Abstract: Motivated by applications in Game Theory, Optimization, and Generative Adversarial Networks, recent work of Daskalakis et al \cite{DISZ17} and follow-up work of Liang and Stokes \cite{LiangS18} have established that a variant of the widely used Gradient Descent/Ascent procedure, called "Optimistic Gradient Descent/Ascent (OGDA)", exhibits last-iterate convergence to saddle points in {\em unconstrained} convex-concave min-max optimization problems. We show that the same holds true in the more general problem of {\em constrained} min-max optimization under a variant of the no-regret Multiplicative-Weights-Update method called "Optimistic Multiplicative-Weights Update (OMWU)". This answers an open question of Syrgkanis et al \cite{SALS15}.
  The proof of our result requires fundamentally different techniques from those that exist in no-regret learning literature and the aforementioned papers. We show that OMWU monotonically improves the Kullback-Leibler divergence of the current iterate to the (appropriately normalized) min-max solution until it enters a neighborhood of the solution. Inside that neighborhood we show that OMWU is locally (asymptotically) stable converging to the exact solution. We believe that our techniques will be useful in the analysis of the last iterate of other learning algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:1807.04252v5</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Constantinos Daskalakis, Ioannis Panageas</dc:creator>
    </item>
    <item>
      <title>Last iterate convergence in no-regret learning: constrained min-max optimization for convex-concave landscapes</title>
      <link>https://arxiv.org/abs/2002.06768</link>
      <description>arXiv:2002.06768v3 Announce Type: replace-cross 
Abstract: In a recent series of papers it has been established that variants of Gradient Descent/Ascent and Mirror Descent exhibit last iterate convergence in convex-concave zero-sum games. Specifically, \cite{DISZ17, LiangS18} show last iterate convergence of the so called "Optimistic Gradient Descent/Ascent" for the case of \textit{unconstrained} min-max optimization. Moreover, in \cite{Metal} the authors show that Mirror Descent with an extra gradient step displays last iterate convergence for convex-concave problems (both constrained and unconstrained), though their algorithm does not follow the online learning framework; it uses extra information rather than \textit{only} the history to compute the next iteration. In this work, we show that "Optimistic Multiplicative-Weights Update (OMWU)" which follows the no-regret online learning framework, exhibits last iterate convergence locally for convex-concave games, generalizing the results of \cite{DP19} where last iterate convergence of OMWU was shown only for the \textit{bilinear case}. We complement our results with experiments that indicate fast convergence of the method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.06768v3</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qi Lei, Sai Ganesh Nagarajan, Ioannis Panageas, Xiao Wang</dc:creator>
    </item>
    <item>
      <title>Joint Value Estimation and Bidding in Repeated First-Price Auctions</title>
      <link>https://arxiv.org/abs/2502.17292</link>
      <description>arXiv:2502.17292v2 Announce Type: replace-cross 
Abstract: We study regret minimization in repeated first-price auctions (FPAs), where a bidder observes only the realized outcome after each auction -- win or loss. This setup reflects practical scenarios in online display advertising where the actual value of an impression depends on the difference between two potential outcomes, such as clicks or conversion rates, when the auction is won versus lost. We analyze three outcome models: (1) adversarial outcomes without features, (2) linear potential outcomes with features, and (3) linear treatment effects in features. For each setting, we propose algorithms that jointly estimate private values and optimize bidding strategies, achieving near-optimal regret bounds. Notably, our framework enjoys a unique feature that the treatments are also actively chosen, and hence eliminates the need for the overlap condition commonly required in causal inference.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.17292v2</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuxiao Wen, Yanjun Han, Zhengyuan Zhou</dc:creator>
    </item>
    <item>
      <title>Steering the Herd: A Framework for LLM-based Control of Social Learning</title>
      <link>https://arxiv.org/abs/2504.02648</link>
      <description>arXiv:2504.02648v3 Announce Type: replace-cross 
Abstract: Algorithms increasingly serve as information mediators--from social media feeds and targeted advertising to the increasing ubiquity of LLMs. This engenders a joint process where agents combine private, algorithmically-mediated signals with learning from peers to arrive at decisions. To study such settings, we introduce a model of controlled sequential social learning in which an information-mediating planner (e.g. an LLM) controls the information structure of agents while they also learn from the decisions of earlier agents. The planner may seek to improve social welfare (altruistic planner) or to induce a specific action the planner prefers (biased planner). Our framework presents a new optimization problem for social learning that combines dynamic programming with decentralized action choices and Bayesian belief updates.
  We prove the convexity of the value function and characterize the optimal policies of altruistic and biased planners, which attain desired tradeoffs between the costs they incur and the payoffs they earn from induced agent choices. Notably, in some regimes the biased planner intentionally obfuscates the agents' signals. Even under stringent transparency constraints--information parity with individuals, no lying or cherry-picking, and full observability--we show that information mediation can substantially shift social welfare in either direction. We complement our theory with simulations in which LLMs act as both planner and agents. Notably, the LLM planner in our simulations exhibits emergent strategic behavior in steering public opinion that broadly mirrors the trends predicted, though key deviations suggest the influence of non-Bayesian reasoning consistent with the cognitive patterns of both humans and LLMs trained on human-like data. Together, we establish our framework as a tractable basis for studying the impact and regulation of LLM information mediators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.02648v3</guid>
      <category>eess.SY</category>
      <category>cs.GT</category>
      <category>cs.SI</category>
      <category>cs.SY</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Raghu Arghal, Kevin He, Shirin Saeedi Bidokhti, Saswati Sarkar</dc:creator>
    </item>
    <item>
      <title>The Second-Order T\^atonnement: Decentralized Interior-Point Methods for Market Equilibrium</title>
      <link>https://arxiv.org/abs/2508.04822</link>
      <description>arXiv:2508.04822v3 Announce Type: replace-cross 
Abstract: The t\^atonnement process and Smale's process are two classical approaches to compute market equilibrium in exchange economies. While the t\^atonnement process can be seen as a first-order method, Smale's process, being second-order, is less popular due to its reliance on additional information from the players and expensive Newton steps. In this paper, we study Fisher exchange market for a broad class of utility functions, where we show that all high-order information required by Smale's process is readily available from players' best responses. Motivated by this observation, we develop two second-order t\^atonnement processes, constructed as decentralized interior-point methods, which are traditionally known to work in a centralized manner. The methods here bear the name "t\^atonnement", since, in spirit, they demand no more information than the classical t\^atonnement process. To address the Newton systems involved, we introduce an explicitly invertible approximation with high-probability guarantees and a scaling matrix that optimally minimizes the condition number, both of which rely solely on best responses as the methods themselves. Using these tools, the first second-order t\^atonnement process has O(log(1/$\epsilon$))complexity rate. Under mild conditions, the other method achieves a non-asymptotic superlinear convergence rate. Preliminary experiments are presented to justify the capability of the proposed methods for large-scale problems. Extensions of our approach are also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.04822v3</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 30 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chuwen Zhang, Chang He, Bo Jiang, Yinyu Ye</dc:creator>
    </item>
  </channel>
</rss>
