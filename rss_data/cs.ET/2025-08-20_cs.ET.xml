<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 21 Aug 2025 01:30:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Quantum-Inspired Artificial Bee Colony for Latency-Aware Task Offloading in IoV</title>
      <link>https://arxiv.org/abs/2508.13637</link>
      <description>arXiv:2508.13637v1 Announce Type: new 
Abstract: Efficient task offloading is crucial for reducing latency and ensuring timely decision-making in intelligent transportation systems within the rapidly evolving Internet of Vehicles (IoV) landscape. This paper introduces a novel Quantum-Inspired Artificial Bee Colony (QABC) algorithm specifically designed for latency-sensitive task offloading involving cloud servers, Roadside Units (RSUs), and vehicular nodes. By incorporating principles from quantum computing, such as quantum state evolution and probabilistic encoding, QABC enhances the classical Artificial Bee Colony (ABC) algorithm's ability to avoid local optima and explore high-dimensional solution spaces. This research highlights the potential of quantum-inspired heuristics to optimize real-time offloading strategies in future vehicular networks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13637v1</guid>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mamta Kumari, Mayukh Sarkar, Rohit Kumar Nonia</dc:creator>
    </item>
    <item>
      <title>Fine Grain 3D Integration for Microarchitecture Design Through Cube Packing Exploration</title>
      <link>https://arxiv.org/abs/2508.13158</link>
      <description>arXiv:2508.13158v1 Announce Type: cross 
Abstract: Most previous 3D IC research focused on stacking traditional 2D silicon layers, so the interconnect reduction is limited to inter-block delays. In this paper, we propose techniques that enable efficient exploration of the 3D design space where each logical block can span more than one silicon layers. Although further power and performance improvement is achievable through fine grain 3D integration, the necessary modeling and tool infrastructure has been mostly missing. We develop a cube packing engine which can simultaneously optimize physical and architectural design for effective utilization of 3D in terms of performance, area and temperature. Our experimental results using a design driver show 36% performance improvement (in BIPS) over 2D and 14% over 3D with single layer blocks. Additionally multi-layer blocks can provide up to 30% reduction in power dissipation compared to the single-layer alternatives. Peak temperature of the design is kept within limits as a result of thermal-aware floorplanning and thermal via insertion techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13158v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>25th IEEE International Conference on Computer Design, pp. 259-266, 2007</arxiv:journal_reference>
      <dc:creator>Yongxiang Liu, Yuchun Ma, Eren Kurshan, Glenn Reinman, Jason Cong</dc:creator>
    </item>
    <item>
      <title>Through Silicon Via Aware Design Planning for Thermally Efficient 3-D Integrated Circuits</title>
      <link>https://arxiv.org/abs/2508.13160</link>
      <description>arXiv:2508.13160v1 Announce Type: cross 
Abstract: 3-D integrated circuits (3-D ICs) offer performance advantages due to their increased bandwidth and reduced wire-length enabled by through-silicon-via structures (TSVs). Traditionally TSVs have been considered to improve the thermal conductivity in the vertical direction. However, the lateral thermal blockage effect becomes increasingly important for TSV via farms (a cluster of TSV vias used for signal bus connections between layers) because the TSV size and pitch continue to scale in {\mu}m range and the metal to insulator ratio becomes smaller. Consequently, dense TSV farms can create lateral thermal blockages in thinned silicon substrate and exacerbate the local hotspots. In this paper, we propose a thermal-aware via farm placement technique for 3-D ICs to minimize lateral heat blockages caused by dense signal bus TSV structures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13160v1</guid>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems, 1335-1346, 2013</arxiv:journal_reference>
      <dc:creator>Yibo Chen, Eren Kurshan, Dave Motschman, Charles Johnson, Yuan Xie</dc:creator>
    </item>
    <item>
      <title>Harnessing the Full Potential of RRAMs through Scalable and Distributed In-Memory Computing with Integrated Error Correction</title>
      <link>https://arxiv.org/abs/2508.13298</link>
      <description>arXiv:2508.13298v1 Announce Type: cross 
Abstract: Exponential growth in global computing demand is exacerbated due to the higher-energy requirements of conventional architectures, primarily due to energy-intensive data movement. In-memory computing with Resistive Random Access Memory (RRAM) addresses this by co-integrating memory and processing, but faces significant hurdles related to device-level non-idealities and poor scalability for large computing tasks. Here, we introduce \textbf{MELISO+} (In-\textbf{Me}mory \textbf{Li}near \textbf{So}lver), a full-stack, distributed framework for energy-efficient in-memory computing. MELISO+ proposes a novel two-tier error correction mechanism to mitigate device non-idealities and develops a distributed RRAM computing framework to enable matrix computations exceeding dimensions of $65,000 \times 65,000$. This approach reduces first- and second-order arithmetic errors due to device non-idealities by over 90\%, enhances energy efficiency by three to five orders of magnitude, and decreases latency 100-fold. Hence, MELISO+ allows lower-precision RRAM devices to outperform high-precision device alternatives in accuracy, energy and latency metrics. By unifying algorithm-hardware co-design with scalable architecture, MELISO+ significantly advances sustainable, high-dimensional computing suitable for applications like large language models and generative AI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13298v1</guid>
      <category>cs.DC</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huynh Q. N. Vo, Md Tawsif Rahman Chowdhury, Paritosh Ramanan, Murat Yildirim, Gozde Tutuncuoglu</dc:creator>
    </item>
    <item>
      <title>OrbitChain: Orchestrating In-orbit Real-time Analytics of Earth Observation Data</title>
      <link>https://arxiv.org/abs/2508.13374</link>
      <description>arXiv:2508.13374v1 Announce Type: cross 
Abstract: Earth observation analytics have the potential to serve many time-sensitive applications. However, due to limited bandwidth and duration of ground-satellite connections, it takes hours or even days to download and analyze data from existing Earth observation satellites, making real-time demands like timely disaster response impossible. Toward real-time analytics, we introduce OrbitChain, a collaborative analytics framework that orchestrates computational resources across multiple satellites in an Earth observation constellation. OrbitChain decomposes analytics applications into microservices and allocates computational resources for time-constrained analysis. A traffic routing algorithm is devised to minimize the inter-satellite communication overhead. OrbitChain adopts a pipeline workflow that completes Earth observation tasks in real-time, facilitates time-sensitive applications and inter-constellation collaborations such as tip-and-cue. To evaluate OrbitChain, we implement a hardware-in-the-loop orbital computing testbed. Experiments show that our system can complete up to 60% analytics workload than existing Earth observation analytics framework while reducing the communication overhead by up to 72%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13374v1</guid>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhouyu Li, Zhijing Yang, Huayue Gu, Xiaojian Wang, Yuchen Liu, Ruozhou Yu</dc:creator>
    </item>
    <item>
      <title>Virtuous Machines: Towards Artificial General Science</title>
      <link>https://arxiv.org/abs/2508.13421</link>
      <description>arXiv:2508.13421v1 Announce Type: cross 
Abstract: Artificial intelligence systems are transforming scientific discovery by accelerating specific research tasks, from protein structure prediction to materials design, yet remain confined to narrow domains requiring substantial human oversight. The exponential growth of scientific literature and increasing domain specialisation constrain researchers' capacity to synthesise knowledge across disciplines and develop unifying theories, motivating exploration of more general-purpose AI systems for science. Here we show that a domain-agnostic, agentic AI system can independently navigate the scientific workflow - from hypothesis generation through data collection to manuscript preparation. The system autonomously designed and executed three psychological studies on visual working memory, mental rotation, and imagery vividness, executed one new online data collection with 288 participants, developed analysis pipelines through 8-hour+ continuous coding sessions, and produced completed manuscripts. The results demonstrate the capability of AI scientific discovery pipelines to conduct non-trivial research with theoretical reasoning and methodological rigour comparable to experienced researchers, though with limitations in conceptual nuance and theoretical interpretation. This is a step toward embodied AI that can test hypotheses through real-world experiments, accelerating discovery by autonomously exploring regions of scientific space that human cognitive and resource constraints might otherwise leave unexplored. It raises important questions about the nature of scientific understanding and the attribution of scientific credit.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13421v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gabrielle Wehr, Reuben Rideaux, Amaya J. Fox, David R. Lightfoot, Jason Tangen, Jason B. Mattingley, Shane E. Ehrhardt</dc:creator>
    </item>
    <item>
      <title>A fully-programmable integrated photonic processor for both domain-specific and general-purpose computing</title>
      <link>https://arxiv.org/abs/2508.13551</link>
      <description>arXiv:2508.13551v1 Announce Type: cross 
Abstract: A variety of complicated computational scenarios have made unprecedented demands on the computing power and energy efficiency of electronic computing systems, including solving intractable nondeterministic polynomial-time (NP)-complete problems and dealing with large-scale artificial intelligence models. Optical computing emerges as a promising paradigm to meet these challenges, whereas current optical computing architectures have limited versatility. Their applications are usually either constrained to a specialized domain or restricted to general-purpose matrix computation. Here, we implement a fully-programmable integrated photonic processor that can be configured to tackle both specific computational problems and general-purpose matrix computation. We achieve complete end-to-end control of the photonic processor by utilizing a self-developed integrated programmable optoelectronic computing platform. For domain-specific computing, our photonic processor can efficiently solve two kinds of NP-complete problems: subset sum problem (far more than 2^N different instances) and exact cover problem. For general-purpose computation, we experimentally demonstrate high-precision optical dot product and further realize accurate image edge detection and MNIST handwritten image classification task with an accuracy of 97%. Our work enhances the versatility and capability of optical computing architecture, paving the way for its practical application in future high-performance and complex computing scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13551v1</guid>
      <category>physics.optics</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Feng-Kai Han, Xiao-Yun Xu, Tian-Yu Zhang, Lei Feng, Chu-Han Wang, Jie Ma, Ze-Feng Lan, Chao-Qian Li, Yi Xie, Hai Yan, Yu-Fei Liu, Yu-Quan Peng, Xian-Min Jin</dc:creator>
    </item>
    <item>
      <title>Portfolio construction using a sampling-based variational quantum scheme</title>
      <link>https://arxiv.org/abs/2508.13557</link>
      <description>arXiv:2508.13557v1 Announce Type: cross 
Abstract: The efficient and effective construction of portfolios that adhere to real-world constraints is a challenging optimization task in finance. We investigate a concrete representation of the problem with a focus on design proposals of an Exchange Traded Fund. We evaluate the sampling-based CVaR Variational Quantum Algorithm (VQA), combined with a local-search post-processing, for solving problem instances that beyond a certain size become classically hard. We also propose a problem formulation that is suited for sampling-based VQA. Our utility-scale experiments on IBM Heron processors involve 109 qubits and up to 4200 gates, achieving a relative solution error of 0.49%. Results indicate that a combined quantum-classical workflow achieves better accuracy compared to purely classical local search, and that hard-to-simulate quantum circuits may lead to better convergence than simpler circuits. Our work paves the path to further explore portfolio construction with quantum computers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13557v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>q-fin.CP</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele Agliardi, Dimitris Alevras, Vaibhaw Kumar, Roberto Lo Nardo, Gabriele Compostella, Sumit Kumar, Manuel Proissl, Bimal Mehta</dc:creator>
    </item>
    <item>
      <title>Security-as-a-Function for IDS/IPS in Softwarized Network and Applications to 5G Network Systems</title>
      <link>https://arxiv.org/abs/2508.13581</link>
      <description>arXiv:2508.13581v1 Announce Type: cross 
Abstract: The service-based architecture of 5G network allows network operators to place virtualized network functions on commodity hardware, unlike the traditional vendor-specific hardware-based functionalities. However, it expands the security vulnerabilities and threats to the 5G network. While there exist several theoretical studies on network function placement and service routing, a few focused on the security aspects of the 5G network systems.
  This paper focuses on safeguarding the 5G core network systems from DoS and DDoS attacks by placing intrusion detection and prevention systems (IDS-IPS) as virtualized network functions following the 5G standalone architecture. To ensure the virtualized placement of IDS-IPS, first, we provide thorough virtual machine (VM)-based and containerized implementation details and evaluate the network performance with two scenarios, IDS and IPS, in the presence of TCP and UDP applications. Second, we apply the VM-based implementation of IDS-IPS on a softwarized 5G core network and study the network performances. The experiment results on network throughput, latency, and packet drop reveal that the softwarized IDS-IPS can meet the QoS requirements of 5G applications, while safeguarding the network from DoS and DDoS attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.13581v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shivank Malik, Samaresh Bera</dc:creator>
    </item>
    <item>
      <title>Analog computation with transcriptional networks</title>
      <link>https://arxiv.org/abs/2508.14017</link>
      <description>arXiv:2508.14017v1 Announce Type: cross 
Abstract: Transcriptional networks represent one of the most extensively studied types of systems in synthetic biology. Although the completeness of transcriptional networks for digital logic is well-established, *analog* computation plays a crucial role in biological systems and offers significant potential for synthetic biology applications. While transcriptional circuits typically rely on cooperativity and highly non-linear behavior of transcription factors to regulate *production* of proteins, they are often modeled with simple linear *degradation* terms. In contrast, general analog dynamics require both non-linear positive as well as negative terms, seemingly necessitating control over not just transcriptional (i.e., production) regulation but also the degradation rates of transcription factors.
  Surprisingly, we prove that controlling transcription factor production (i.e., transcription rate) without explicitly controlling degradation is mathematically complete for analog computation, achieving equivalent capabilities to systems where both production and degradation are programmable. We demonstrate our approach on several examples including oscillatory and chaotic dynamics, analog sorting, memory, PID controller, and analog extremum seeking. Our result provides a systematic methodology for engineering novel analog dynamics using synthetic transcriptional networks without the added complexity of degradation control and informs our understanding of the capabilities of natural transcriptional circuits.
  We provide a compiler, in the form of a Python package that can take any system of polynomial ODEs and convert it to an equivalent transcriptional network implementing the system *exactly*, under appropriate conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14017v1</guid>
      <category>cs.CC</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Doty, Mina Latifi, David Soloveichick</dc:creator>
    </item>
    <item>
      <title>Scaling Intelligence: Designing Data Centers for Next-Gen Language Models</title>
      <link>https://arxiv.org/abs/2506.15006</link>
      <description>arXiv:2506.15006v2 Announce Type: replace-cross 
Abstract: The explosive growth of Large Language Models (LLMs), such as GPT-4 with 1.8 trillion parameters, demands a fundamental rethinking of data center architecture to ensure scalability, efficiency, and cost-effectiveness. Our work provides a comprehensive co-design framework that jointly explores FLOPS, HBM bandwidth and capacity, multiple network topologies (two-tier vs. FullFlat optical), the size of the scale-out domain, and popular parallelism/optimization strategies used in LLMs. We introduce and evaluate FullFlat network architectures, which provide uniform high-bandwidth, low-latency connectivity between all nodes, and demonstrate their transformative impact on performance and scalability. Through detailed sensitivity analyses, we quantify the benefits of overlapping compute and communication, leveraging hardware-accelerated collectives, widening the scale-out domain, and increasing memory capacity. Our study spans both sparse (mixture of experts) and dense transformer-based LLMs, revealing how system design choices affect Model FLOPS Utilization (MFU = Model FLOPS per token * Observed tokens per second / Peak FLOPS of the hardware) and overall throughput. For the co-design study, we utilized an analytical performance modeling tool capable of predicting LLM runtime within 10% of real-world measurements. Our findings offer actionable insights and a practical roadmap for designing AI data centers that can efficiently support trillion-parameter models, reduce optimization complexity, and sustain the rapid evolution of AI capabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15006v2</guid>
      <category>cs.AR</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.PF</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jesmin Jahan Tithi, Hanjiang Wu, Avishaii Abuhatzera, Fabrizio Petrini</dc:creator>
    </item>
    <item>
      <title>LLM4VV: Evaluating Cutting-Edge LLMs for Generation and Evaluation of Directive-Based Parallel Programming Model Compiler Tests</title>
      <link>https://arxiv.org/abs/2507.21447</link>
      <description>arXiv:2507.21447v2 Announce Type: replace-cross 
Abstract: The usage of Large Language Models (LLMs) for software and test development has continued to increase since LLMs were first introduced, but only recently have the expectations of LLMs become more realistic. Verifying the correctness of code generated by LLMs is key to improving their usefulness, but there have been no comprehensive and fully autonomous solutions developed yet. Hallucinations are a major concern when LLMs are applied blindly to problems without taking the time and effort to verify their outputs, and an inability to explain the logical reasoning of LLMs leads to issues with trusting their results. To address these challenges while also aiming to effectively apply LLMs, this paper proposes a dual-LLM system (i.e. a generative LLM and a discriminative LLM) and experiments with the usage of LLMs for the generation of a large volume of compiler tests. We experimented with a number of LLMs possessing varying parameter counts and presented results using ten carefully-chosen metrics that we describe in detail in our narrative. Through our findings, it is evident that LLMs possess the promising potential to generate quality compiler tests and verify them automatically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21447v2</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zachariah Sollenberger, Rahul Patel, Saieda Ali Zada, Sunita Chandrasekaran</dc:creator>
    </item>
    <item>
      <title>Fortifying the Agentic Web: A Unified Zero-Trust Architecture Against Logic-layer Threats</title>
      <link>https://arxiv.org/abs/2508.12259</link>
      <description>arXiv:2508.12259v2 Announce Type: replace-cross 
Abstract: This paper presents a Unified Security Architecture that fortifies the Agentic Web through a Zero-Trust IAM framework. This architecture is built on a foundation of rich, verifiable agent identities using Decentralized Identifiers (DIDs) and Verifiable Credentials (VCs), with discovery managed by a protocol-agnostic Agent Name Service (ANS). Security is operationalized through a multi-layered Trust Fabric which introduces significant innovations, including Trust-Adaptive Runtime Environments (TARE), Causal Chain Auditing, and Dynamic Identity with Behavioral Attestation. By explicitly linking the LPCI threat to these enhanced architectural countermeasures within a formal security model, we propose a comprehensive and forward-looking blueprint for a secure, resilient, and trustworthy agentic ecosystem. Our formal analysis demonstrates that the proposed architecture provides provable security guarantees against LPCI attacks with bounded probability of success.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.12259v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Wed, 20 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Ken Huang, Yasir Mehmood, Hammad Atta, Jerry Huang, Muhammad Zeeshan Baig, Sree Bhargavi Balija</dc:creator>
    </item>
  </channel>
</rss>
