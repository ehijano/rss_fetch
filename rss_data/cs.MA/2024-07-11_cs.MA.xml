<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.MA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.MA</link>
    <description>cs.MA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.MA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Jul 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Field Deployment of Multi-Agent Reinforcement Learning Based Variable Speed Limit Controllers</title>
      <link>https://arxiv.org/abs/2407.08021</link>
      <description>arXiv:2407.08021v1 Announce Type: new 
Abstract: This article presents the first field deployment of a multi-agent reinforcement-learning (MARL) based variable speed limit (VSL) control system on the I-24 freeway near Nashville, Tennessee. We describe how we train MARL agents in a traffic simulator and directly deploy the simulation-based policy on a 17-mile stretch of Interstate 24 with 67 VSL controllers. We use invalid action masking and several safety guards to ensure the posted speed limits satisfy the real-world constraints from the traffic management center and the Tennessee Department of Transportation. Since the time of launch of the system through April, 2024, the system has made approximately 10,000,000 decisions on 8,000,000 trips. The analysis of the controller shows that the MARL policy takes control for up to 98% of the time without intervention from safety guards. The time-space diagrams of traffic speed and control commands illustrate how the algorithm behaves during rush hour. Finally, we quantify the domain mismatch between the simulation and real-world data and demonstrate the robustness of the MARL policy to this mismatch.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08021v1</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhang Zhang, Zhiyao Zhang, Marcos Qui\~nones-Grueiro, William Barbour, Clay Weston, Gautam Biswas, Daniel Work</dc:creator>
    </item>
    <item>
      <title>United We Stand: Decentralized Multi-Agent Planning With Attrition</title>
      <link>https://arxiv.org/abs/2407.08254</link>
      <description>arXiv:2407.08254v1 Announce Type: new 
Abstract: Decentralized planning is a key element of cooperative multi-agent systems for information gathering tasks. However, despite the high frequency of agent failures in realistic large deployment scenarios, current approaches perform poorly in the presence of failures, by not converging at all, and/or by making very inefficient use of resources (e.g. energy). In this work, we propose Attritable MCTS (A-MCTS), a decentralized MCTS algorithm capable of timely and efficient adaptation to changes in the set of active agents. It is based on the use of a global reward function for the estimation of each agent's local contribution, and regret matching for coordination. We evaluate its effectiveness in realistic data-harvesting problems under different scenarios. We show both theoretically and experimentally that A-MCTS enables efficient adaptation even under high failure rates. Results suggest that, in the presence of frequent failures, our solution improves substantially over the best existing approaches in terms of global utility and scalability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08254v1</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nhat Nguyen, Duong Nguyen, Gianluca Rizzo, Hung Nguyen</dc:creator>
    </item>
    <item>
      <title>Hierarchical Consensus-Based Multi-Agent Reinforcement Learning for Multi-Robot Cooperation Tasks</title>
      <link>https://arxiv.org/abs/2407.08164</link>
      <description>arXiv:2407.08164v1 Announce Type: cross 
Abstract: In multi-agent reinforcement learning (MARL), the Centralized Training with Decentralized Execution (CTDE) framework is pivotal but struggles due to a gap: global state guidance in training versus reliance on local observations in execution, lacking global signals. Inspired by human societal consensus mechanisms, we introduce the Hierarchical Consensus-based Multi-Agent Reinforcement Learning (HC-MARL) framework to address this limitation. HC-MARL employs contrastive learning to foster a global consensus among agents, enabling cooperative behavior without direct communication. This approach enables agents to form a global consensus from local observations, using it as an additional piece of information to guide collaborative actions during execution. To cater to the dynamic requirements of various tasks, consensus is divided into multiple layers, encompassing both short-term and long-term considerations. Short-term observations prompt the creation of an immediate, low-layer consensus, while long-term observations contribute to the formation of a strategic, high-layer consensus. This process is further refined through an adaptive attention mechanism that dynamically adjusts the influence of each consensus layer. This mechanism optimizes the balance between immediate reactions and strategic planning, tailoring it to the specific demands of the task at hand. Extensive experiments and real-world applications in multi-robot systems showcase our framework's superior performance, marking significant advancements over baselines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08164v1</guid>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pu Feng, Junkang Liang, Size Wang, Xin Yu, Rongye Shi, Wenjun Wu</dc:creator>
    </item>
    <item>
      <title>A Text-to-Game Engine for UGC-Based Role-Playing Games</title>
      <link>https://arxiv.org/abs/2407.08195</link>
      <description>arXiv:2407.08195v1 Announce Type: cross 
Abstract: The shift from professionally generated content (PGC) to user-generated content (UGC) has revolutionized various media formats, from text to video. With the rapid advancements in generative AI, a similar shift is set to transform the game industry, particularly in the realm of role-playing games (RPGs). This paper introduces a new framework for a text-to-game engine that utilizes foundation models to convert simple textual inputs into complex, interactive RPG experiences. The engine dynamically renders the game story in a multi-modal format and adjusts the game character, environment, and mechanics in real-time in response to player actions. Using this framework, we developed the "Zagii" game engine, which has successfully supported hundreds of RPG games across a diverse range of genres and facilitated tens of thousands of online user gameplay instances. This validates the effectiveness of our frame-work. Our work showcases the potential for a more open and democratized gaming paradigm, highlighting the transformative impact of generative AI on the game life cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08195v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lei Zhang, Xuezheng Peng, Shuyi Yang, Feiyang Wang</dc:creator>
    </item>
    <item>
      <title>Incorporating Large Language Models into Production Systems for Enhanced Task Automation and Flexibility</title>
      <link>https://arxiv.org/abs/2407.08550</link>
      <description>arXiv:2407.08550v1 Announce Type: cross 
Abstract: This paper introduces a novel approach to integrating large language model (LLM) agents into automated production systems, aimed at enhancing task automation and flexibility. We organize production operations within a hierarchical framework based on the automation pyramid. Atomic operation functionalities are modeled as microservices, which are executed through interface invocation within a dedicated digital twin system. This allows for a scalable and flexible foundation for orchestrating production processes. In this digital twin system, low-level, hardware-specific data is semantically enriched and made interpretable for LLMs for production planning and control tasks. Large language model agents are systematically prompted to interpret these production-specific data and knowledge. Upon receiving a user request or identifying a triggering event, the LLM agents generate a process plan. This plan is then decomposed into a series of atomic operations, executed as microservices within the real-world automation system. We implement this overall approach on an automated modular production facility at our laboratory, demonstrating how the LLMs can handle production planning and control tasks through a concrete case study. This results in an intuitive production facility with higher levels of task automation and flexibility. Finally, we reveal the several limitations in realizing the full potential of the large language models in autonomous systems and point out promising benefits. Demos of this series of ongoing research series can be accessed at: https://github.com/YuchenXia/GPT4IndustrialAutomation</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08550v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.51202/9783181024379</arxiv:DOI>
      <dc:creator>Yuchen Xia, Jize Zhang, Nasser Jazdi, Michael Weyrich</dc:creator>
    </item>
    <item>
      <title>A Review of Nine Physics Engines for Reinforcement Learning Research</title>
      <link>https://arxiv.org/abs/2407.08590</link>
      <description>arXiv:2407.08590v1 Announce Type: cross 
Abstract: We present a review of popular simulation engines and frameworks used in reinforcement learning (RL) research, aiming to guide researchers in selecting tools for creating simulated physical environments for RL and training setups. It evaluates nine frameworks (Brax, Chrono, Gazebo, MuJoCo, ODE, PhysX, PyBullet, Webots, and Unity) based on their popularity, feature range, quality, usability, and RL capabilities. We highlight the challenges in selecting and utilizing physics engines for RL research, including the need for detailed comparisons and an understanding of each framework's capabilities. Key findings indicate MuJoCo as the leading framework due to its performance and flexibility, despite usability challenges. Unity is noted for its ease of use but lacks scalability and simulation fidelity. The study calls for further development to improve simulation engines' usability and performance and stresses the importance of transparency and reproducibility in RL research. This review contributes to the RL community by offering insights into the selection process for simulation engines, facilitating informed decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.08590v1</guid>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Kaup, Cornelius Wolff, Hyerim Hwang, Julius Mayer, Elia Bruni</dc:creator>
    </item>
    <item>
      <title>Network Preference Dynamics using Lattice Theory</title>
      <link>https://arxiv.org/abs/2310.00179</link>
      <description>arXiv:2310.00179v2 Announce Type: replace 
Abstract: Preferences, fundamental in all forms of strategic behavior and collective decision-making, in their raw form, are an abstract ordering on a set of alternatives. Agents, we assume, revise their preferences as they gain more information about other agents. Exploiting the ordered algebraic structure of preferences, we introduce a message-passing algorithm for heterogeneous agents distributed over a network to update their preferences based on aggregations of the preferences of their neighbors in a graph. We demonstrate the existence of equilibrium points of the resulting global dynamical system of local preference updates and provide a sufficient condition for trajectories to converge to equilibria: stable preferences. Finally, we present numerical simulations demonstrating our preliminary results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00179v2</guid>
      <category>cs.MA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans Riess, Gregory Henselman-Petrusek, Michael C. Munger, Robert Ghrist, Zachary I. Bell, Michael M. Zavlanos</dc:creator>
    </item>
    <item>
      <title>Analysis of Robotic System Models Through Property Inheritance from Petri Net Meta-models</title>
      <link>https://arxiv.org/abs/2407.06454</link>
      <description>arXiv:2407.06454v2 Announce Type: replace-cross 
Abstract: This article investigates the analysis of robotic system models using the Robotic System Hierarchic Petri Net (RSHPN) meta-model, proposing streamlined methods by focusing on significant system fragments and inheriting properties from the meta-model. Our research demonstrates that it is feasible to: 1) effectively analyze complex robotic systems expressed using RSHPN, and 2) enable models to inherit properties from the meta-model. This approach significantly simplifies the analysis process, reduces design time, and ensures the safety and reliability of the systems. These aspects are crucial for robots operating in human environments. Our results suggest that Petri nets could be further explored as a useful tool for the formal description and in-depth analysis of the properties of robotic systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.06454v2</guid>
      <category>cs.RO</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maksym Figat, Cezary Zieli\'nski</dc:creator>
    </item>
  </channel>
</rss>
