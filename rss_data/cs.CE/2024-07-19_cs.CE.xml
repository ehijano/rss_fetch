<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CE updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CE</link>
    <description>cs.CE updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CE" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:13 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Patient-specific coronary angioplasty simulations -- a mixed-dimensional finite element modeling approach</title>
      <link>https://arxiv.org/abs/2407.13276</link>
      <description>arXiv:2407.13276v1 Announce Type: new 
Abstract: Coronary angioplasty with stent implantation is the most frequently used interventional treatment for coronary artery disease. However, reocclusion within the stent, referred to as in-stent restenosis, occurs in up to 10% of lesions. It is widely accepted that mechanical loads on the vessel wall strongly affect adaptive and maladaptive mechanisms. Yet, the role of procedural and lesion-specific influence on restenosis risk remains understudied. Computational modeling of the stenting procedure can provide new mechanistic insights, such as local stresses, that play a significant role in tissue growth and remodeling. Previous simulation studies often featured simplified artery and stent geometries and cannot be applied to real-world examples. Realistic simulations were computationally expensive since they featured fully resolved stenting device models. The aim of this work is to develop and present a mixed-dimensional formulation to simulate the patient-specific stenting procedure with a reduced-dimensional beam model for the stent and 3D models for the artery. In addition to presenting the numerical approach, we apply it to realistic cases to study the intervention's mechanical effect on the artery and correlate the findings with potential high-risk locations for in-stent restenosis. We found that high artery wall stresses develop during the coronary intervention in severely stenosed areas and at the stent boundaries. Herewith, we lay the groundwork for further studies towards preventing in-stent restenosis after coronary angioplasty.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13276v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Janina C. Datz, Ivo Steinbrecher, Christoph Meier, Nora Hagmeyer, Leif-Christopher Engel, Alexander Popp, Martin R. Pfaller, Heribert Schunkert, Wolfgang A. Wall</dc:creator>
    </item>
    <item>
      <title>DeepClair: Utilizing Market Forecasts for Effective Portfolio Selection</title>
      <link>https://arxiv.org/abs/2407.13427</link>
      <description>arXiv:2407.13427v1 Announce Type: new 
Abstract: Utilizing market forecasts is pivotal in optimizing portfolio selection strategies. We introduce DeepClair, a novel framework for portfolio selection. DeepClair leverages a transformer-based time-series forecasting model to predict market trends, facilitating more informed and adaptable portfolio decisions. To integrate the forecasting model into a deep reinforcement learning-driven portfolio selection framework, we introduced a two-step strategy: first, pre-training the time-series model on market data, followed by fine-tuning the portfolio selection architecture using this model. Additionally, we investigated the optimization technique, Low-Rank Adaptation (LoRA), to enhance the pre-trained forecasting model for fine-tuning in investment scenarios. This work bridges market forecasting and portfolio selection, facilitating the advancement of investment strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13427v1</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Donghee Choi, Jinkyu Kim, Mogan Gim, Jinho Lee, Jaewoo Kang</dc:creator>
    </item>
    <item>
      <title>Projection-based model-order reduction for unstructured meshes with graph autoencoders</title>
      <link>https://arxiv.org/abs/2407.13669</link>
      <description>arXiv:2407.13669v1 Announce Type: new 
Abstract: This paper presents a graph autoencoder architecture capable of performing projection-based model-order reduction (PMOR) on advection-dominated flows modeled by unstructured meshes. The autoencoder is coupled with the time integration scheme from a traditional deep least-squares Petrov-Galerkin projection and provides the first deployment of a graph autoencoder into a PMOR framework. The presented graph autoencoder is constructed with a two-part process that consists of (1) generating a hierarchy of reduced graphs to emulate the compressive abilities of convolutional neural networks (CNNs) and (2) training a message passing operation at each step in the hierarchy of reduced graphs to emulate the filtering process of a CNN. The resulting framework provides improved flexibility over traditional CNN-based autoencoders because it is extendable to unstructured meshes. To highlight the capabilities of the proposed framework, which is named geometric deep least-squares Petrov-Galerkin (GD-LSPG), we benchmark the method on a one-dimensional Burgers' equation problem with a structured mesh and demonstrate the flexibility of GD-LSPG by deploying it to a two-dimensional Euler equations model that uses an unstructured mesh. The proposed framework provides considerable improvement in accuracy for very low-dimensional latent spaces in comparison with traditional affine projections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13669v1</guid>
      <category>cs.CE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liam K. Magargal (Department of Mechanical Engineering and Mechanics, Lehigh University, Bethlehem, PA, United States), Parisa Khodabakhshi (Department of Mechanical Engineering and Mechanics, Lehigh University, Bethlehem, PA, United States), Steven N. Rodriguez (Computational Multiphysics Systems Laboratory, United States Naval Research Laboratory, Washington, DC, United States), Justin W. Jaworski (Kevin T. Crofton Department of Aerospace and Ocean Engineering, Virginia Tech, Blacksburg, VA, United States), John G. Michopoulos (Computational Multiphysics Systems Laboratory, United States Naval Research Laboratory, Washington, DC, United States)</dc:creator>
    </item>
    <item>
      <title>Maintenance Strategies for Sewer Pipes with Multi-State Degradation and Deep Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2407.12894</link>
      <description>arXiv:2407.12894v1 Announce Type: cross 
Abstract: Large-scale infrastructure systems are crucial for societal welfare, and their effective management requires strategic forecasting and intervention methods that account for various complexities. Our study addresses two challenges within the Prognostics and Health Management (PHM) framework applied to sewer assets: modeling pipe degradation across severity levels and developing effective maintenance policies. We employ Multi-State Degradation Models (MSDM) to represent the stochastic degradation process in sewer pipes and use Deep Reinforcement Learning (DRL) to devise maintenance strategies. A case study of a Dutch sewer network exemplifies our methodology. Our findings demonstrate the model's effectiveness in generating intelligent, cost-saving maintenance strategies that surpass heuristics. It adapts its management strategy based on the pipe's age, opting for a passive approach for newer pipes and transitioning to active strategies for older ones to prevent failures and reduce costs. This research highlights DRL's potential in optimizing maintenance policies. Future research will aim improve the model by incorporating partial observability, exploring various reinforcement learning algorithms, and extending this methodology to comprehensive infrastructure management.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12894v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.36001/phme.2024.v8i1.4091</arxiv:DOI>
      <arxiv:journal_reference>Proceedings of the 8th European Conference of The Prognostics and Health Management Society 2024</arxiv:journal_reference>
      <dc:creator>Lisandro A. Jimenez-Roa, Thiago D. Sim\~ao, Zaharah Bukhsh, Tiedo Tinga, Hajo Molegraaf, Nils Jansen, Marielle Stoelinga</dc:creator>
    </item>
    <item>
      <title>A Resolution Independent Neural Operator</title>
      <link>https://arxiv.org/abs/2407.13010</link>
      <description>arXiv:2407.13010v1 Announce Type: cross 
Abstract: The Deep operator network (DeepONet) is a powerful yet simple neural operator architecture that utilizes two deep neural networks to learn mappings between infinite-dimensional function spaces. This architecture is highly flexible, allowing the evaluation of the solution field at any location within the desired domain. However, it imposes a strict constraint on the input space, requiring all input functions to be discretized at the same locations; this limits its practical applications. In this work, we introduce a Resolution Independent Neural Operator (RINO) that provides a framework to make DeepONet resolution-independent, enabling it to handle input functions that are arbitrarily, but sufficiently finely, discretized. To this end, we propose a dictionary learning algorithm to adaptively learn a set of appropriate continuous basis functions, parameterized as implicit neural representations (INRs), from the input data. These basis functions are then used to project arbitrary input function data as a point cloud onto an embedding space (i.e., a vector space of finite dimensions) with dimensionality equal to the dictionary size, which can be directly used by DeepONet without any architectural changes. In particular, we utilize sinusoidal representation networks (SIRENs) as our trainable INR basis functions. We demonstrate the robustness and applicability of RINO in handling arbitrarily (but sufficiently richly) sampled input functions during both training and inference through several numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13010v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>physics.comp-ph</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bahador Bahmani, Somdatta Goswami, Ioannis G. Kevrekidis, Michael D. Shields</dc:creator>
    </item>
    <item>
      <title>A Gentle Approach to Multi-Sensor Fusion Data Using Linear Kalman Filter</title>
      <link>https://arxiv.org/abs/2407.13062</link>
      <description>arXiv:2407.13062v1 Announce Type: cross 
Abstract: This research paper delves into the Linear Kalman Filter (LKF), highlighting its importance in merging data from multiple sensors. The Kalman Filter is known for its recursive solution to the linear filtering problem in discrete data, making it ideal for estimating states in dynamic systems by reducing noise in measurements and processes. Our focus is on linear dynamic systems due to the LKF's assumptions about system dynamics, measurement noise, and initial conditions. We thoroughly explain the principles, assumptions, and mechanisms of the LKF, emphasizing its practical application in multi-sensor data fusion. This fusion is essential for integrating diverse sensory inputs, thereby improving the accuracy and reliability of state estimations. To illustrate the LKF's real-world applicability and versatility, the paper presents two physical examples where the LKF significantly enhances precision and stability in dynamic systems. These examples not only demonstrate the theoretical concepts but also provide practical insights into implementing the LKF in multi-sensor data fusion scenarios. Our discussion underscores the LKF's crucial role in fields such as robotics, navigation, and signal processing. By combining an in-depth exploration of the LKF's theoretical foundations with practical examples, this paper aims to provide a comprehensive and accessible understanding of multi-sensor data fusion. Our goal is to contribute to the growing body of knowledge in this important area of research, promoting further innovations and advancements in data fusion technologies and encouraging their wider adoption across various scientific and industrial fields.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13062v1</guid>
      <category>cs.CY</category>
      <category>cs.CE</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Parsa Veysi, Mohsen Adeli, Nayerosadat Peirov Naziri, Ehsan Adeli</dc:creator>
    </item>
    <item>
      <title>International Trade Flow Prediction with Bilateral Trade Provisions</title>
      <link>https://arxiv.org/abs/2407.13698</link>
      <description>arXiv:2407.13698v1 Announce Type: cross 
Abstract: This paper presents a novel methodology for predicting international bilateral trade flows, emphasizing the growing importance of Preferential Trade Agreements (PTAs) in the global trade landscape. Acknowledging the limitations of traditional models like the Gravity Model of Trade, this study introduces a two-stage approach combining explainable machine learning and factorization models. The first stage employs SHAP Explainer for effective variable selection, identifying key provisions in PTAs, while the second stage utilizes Factorization Machine models to analyze the pairwise interaction effects of these provisions on trade flows. By analyzing comprehensive datasets, the paper demonstrates the efficacy of this approach. The findings not only enhance the predictive accuracy of trade flow models but also offer deeper insights into the complex dynamics of international trade, influenced by specific bilateral trade provisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13698v1</guid>
      <category>q-fin.ST</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zijie Pan, Stepan Gordeev, Jiahui Zhao, Ziyi Meng, Caiwen Ding, Sandro Steinbach, Dongjin Song</dc:creator>
    </item>
    <item>
      <title>Fusion of Movement and Naive Predictions for Point Forecasting in Univariate Random Walks</title>
      <link>https://arxiv.org/abs/2406.14469</link>
      <description>arXiv:2406.14469v3 Announce Type: replace 
Abstract: Traditional methods for point forecasting in univariate random walks often fail to surpass naive benchmarks due to data unpredictability. This study introduces a novel forecasting method that fuses movement prediction (binary classification) with naive forecasts for accurate one-step-ahead point forecasting in univariate random walks. The method's efficacy is demonstrated through theoretical analysis, simulations, and real-world data experiments. It reliably outperforms naive forecasts with moderate movement prediction accuracies, such as 0.55, and is superior to baseline models such as the ARIMA, linear regression, MLP, and LSTM networks in forecasting the S&amp;P 500 index and Bitcoin prices. This method is particularly advantageous when accurate point predictions are challenging but accurate movement predictions are attainable, translating movement predictions into point forecasts in random walk contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14469v3</guid>
      <category>cs.CE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cheng Zhang</dc:creator>
    </item>
    <item>
      <title>Improving the Accuracy of Transaction-Based Ponzi Detection on Ethereum</title>
      <link>https://arxiv.org/abs/2308.16391</link>
      <description>arXiv:2308.16391v2 Announce Type: replace-cross 
Abstract: The Ponzi scheme, an old-fashioned fraud, is now popular on the Ethereum blockchain, causing considerable financial losses to many crypto investors. A few Ponzi detection methods have been proposed in the literature, most of which detect a Ponzi scheme based on its smart contract source code. This contract-code-based approach, while achieving very high accuracy, is not robust because a Ponzi developer can fool a detection model by obfuscating the opcode or inventing a new profit distribution logic that cannot be detected. On the contrary, a transaction-based approach could improve the robustness of detection because transactions, unlike smart contracts, are harder to be manipulated. However, the current transaction-based detection models achieve fairly low accuracy. In this paper, we aim to improve the accuracy of the transaction-based models by employing time-series features, which turn out to be crucial in capturing the life-time behaviour a Ponzi application but were completely overlooked in previous works. We propose a new set of 85 features (22 known account-based and 63 new time-series features), which allows off-the-shelf machine learning algorithms to achieve up to 30% higher F1-scores compared to existing works.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.16391v2</guid>
      <category>cs.CR</category>
      <category>cs.CE</category>
      <category>cs.LG</category>
      <category>q-fin.ST</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Phuong Duy Huynh, Son Hoang Dau, Xiaodong Li, Phuc Luong, Emanuele Viterbo</dc:creator>
    </item>
  </channel>
</rss>
