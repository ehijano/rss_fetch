<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DC</link>
    <description>cs.DC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Jul 2024 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Enabling an OpenStack-based cloud on top of RISC-V hardware</title>
      <link>https://arxiv.org/abs/2407.12008</link>
      <description>arXiv:2407.12008v1 Announce Type: new 
Abstract: The European Union's technological sovereignty strategy centers around the RISC-V Instruction Set Architecture, with the European Processor Initiative leading efforts to build production-ready processors. Focusing on realizing a functional RISC-V cloud ecosystem, the Vitamin-V European project developed an OpenStack cluster utilizing genuine hardware. In this poster, we detail the efforts done in porting and setting up the cluster and the many software services required by OpenStack to properly run on real hardware. In this poster, we detail our efforts on building an minimal viable prototype OpenStack cluster using real hardware. The cluster is almost functional, and we expect it to be complete in the next few months.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12008v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Diego Marr\'on, Aaron Call, Josep Ll. Berral, Ramon Nou</dc:creator>
    </item>
    <item>
      <title>Digital Twinning of a Pressurized Water Reactor Startup Operation and Partial Computational Offloading in In-network Computing-Assisted Multiaccess Edge Computing</title>
      <link>https://arxiv.org/abs/2407.12011</link>
      <description>arXiv:2407.12011v1 Announce Type: new 
Abstract: This paper addresses the challenge of representing complex human action (HA) in a nuclear power plant (NPP) digital twin (DT) and minimizing latency in partial computation offloading (PCO) in sixth-generation-enabled computing in the network (COIN) assisted multiaccess edge computing (MEC). Accurate HA representation in the DT-HA model is vital for modeling human interventions that are crucial for the safe and efficient operation of NPPs. In this context, DT-enabled COIN-assisted MEC harnesses DT (known as a cybertwin) capabilities to optimize resource allocation and reduce latency effectively. A two-stage approach is employed to address system complexity. First, a probabilistic graphical model (PGM) is introduced to capture HAs in the DT abstraction. In the PGM, HA and NPP asset-twin abstractions form coupled systems that evolve and interact through observable data and control input. Next, the underlying PCO problem is formulated as a multiuser game, where NPP assets can partially offload tasks to COIN and MEC. We propose a decentralized algorithm to optimize offloading decisions, offloading ratios, and resource allocation. The simulation results demonstrate the effectiveness of the proposed method in capturing complex HAs and optimal resource allocation in DT-enabled NPPs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12011v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ibrahim Aliyu, Awwal M. Arigi, Tai-Won Um, Jinsul Kim</dc:creator>
    </item>
    <item>
      <title>Mitigating Interference of Microservices with a Scoring Mechanism in Large-scale Clusters</title>
      <link>https://arxiv.org/abs/2407.12248</link>
      <description>arXiv:2407.12248v1 Announce Type: new 
Abstract: Co-locating latency-critical services (LCSs) and best-effort jobs (BEJs) constitute the principal approach for enhancing resource utilization in production. Nevertheless, the co-location practice hurts the performance of LCSs due to resource competition, even when employing isolation technology. Through an extensive analysis of voluminous real trace data derived from two production clusters, we observe that BEJs typically exhibit periodic execution patterns and serve as the primary sources of interference to LCSs. Furthermore, despite occupying the same level of resource consumption, the diverse compositions of BEJs can result in varying degrees of interference on LCSs. Subsequently, we propose PISM, a proactive Performance Interference Scoring and Mitigating framework for LCSs through the optimization of BEJ scheduling. Firstly, PISM adopts a data-driven approach to establish a characterization and classification methodology for BEJs. Secondly, PISM models the relationship between the composition of BEJs on servers and the response time (RT) of LCSs. Thirdly, PISM establishes an interference scoring mechanism in terms of RT, which serves as the foundation for BEJ scheduling. We assess the effectiveness of PISM on a small-scale cluster and through extensive data-driven simulations. The experiment results demonstrate that PISM can reduce cluster interference by up to 41.5%, and improve the throughput of long-tail LCSs by 76.4%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12248v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dingyu Yang, Kangpeng Zheng, Shiyou Qian, Jian Cao, Guangtao Xue</dc:creator>
    </item>
    <item>
      <title>LLM Inference Serving: Survey of Recent Advances and Opportunities</title>
      <link>https://arxiv.org/abs/2407.12391</link>
      <description>arXiv:2407.12391v1 Announce Type: new 
Abstract: This survey offers a comprehensive overview of recent advancements in Large Language Model (LLM) serving systems, focusing on research since the year 2023. We specifically examine system-level enhancements that improve performance and efficiency without altering the core LLM decoding mechanisms. By selecting and reviewing high-quality papers from prestigious ML and system venues, we highlight key innovations and practical considerations for deploying and scaling LLMs in real-world production environments. This survey serves as a valuable resource for LLM practitioners seeking to stay abreast of the latest developments in this rapidly evolving field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12391v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Baolin Li, Yankai Jiang, Vijay Gadepally, Devesh Tiwari</dc:creator>
    </item>
    <item>
      <title>Computing: Looking Back and Moving Forward</title>
      <link>https://arxiv.org/abs/2407.12558</link>
      <description>arXiv:2407.12558v1 Announce Type: new 
Abstract: The Internet and computer commercialization have transformed the computing systems area over the past sixty years, affecting society. Computer systems have evolved to meet diverse social needs thanks to technological advances. The Internet of Things (IoT), cloud computing, fog computing, edge computing, and other emerging paradigms provide new economic and creative potential. Therefore, this article explores and evaluates the elements impacting the advancement of computing platforms, including both long standing systems and frameworks and more recent innovations like cloud computing, quantum technology, and edge AI. In this article, we examine computing paradigms, domains, and next generation computing systems to better understand the past, present, and future of computing technologies. This paper provides readers with a comprehensive overview of developments in computing technologies and highlights promising research gaps for the advancement of future computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12558v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muhammed Golec, Sukhpal Singh Gill</dc:creator>
    </item>
    <item>
      <title>Continuous reasoning for adaptive container image distribution in the cloud-edge continuum</title>
      <link>https://arxiv.org/abs/2407.12605</link>
      <description>arXiv:2407.12605v1 Announce Type: new 
Abstract: Cloud-edge computing requires applications to operate across diverse infrastructures, often triggered by cyber-physical events. Containers offer a lightweight deployment option but pulling images from central repositories can cause delays. This article presents a novel declarative approach and open-source prototype for replicating container images across the cloud-edge continuum. Considering resource availability, network QoS, and storage costs, we leverage logic programming to (i) determine optimal initial placements via Answer Set Programming (ASP) and (ii) adapt placements using Prolog-based continuous reasoning. We evaluate our solution through simulations, showcasing how combining ASP and Prolog continuous reasoning can balance cost optimisation and prompt decision-making in placement adaptation at increasing infrastructure sizes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12605v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.LO</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Damiano Azzolini, Stefano Forti, Antonio Ielo</dc:creator>
    </item>
    <item>
      <title>LSKV: A Confidential Distributed Datastore to Protect Critical Data in the Cloud</title>
      <link>https://arxiv.org/abs/2407.12623</link>
      <description>arXiv:2407.12623v1 Announce Type: new 
Abstract: Software services are increasingly migrating to the cloud, requiring trust in actors with direct access to the hardware, software and data comprising the service. A distributed datastore storing critical data sits at the core of many services; a prime example being etcd in Kubernetes. Trusted execution environments can secure this data from cloud providers during execution, but it is complex to build trustworthy data storage systems using such mechanisms. We present the design and evaluation of the Ledger-backed Secure Key-Value datastore (LSKV), a distributed datastore that provides an etcd-like API but can use trusted execution mechanisms to keep cloud providers outside the trust boundary. LSKV provides a path to transition traditional systems towards confidential execution, provides competitive performance compared to etcd, and helps clients to gain trust in intermediary services. LSKV forms a foundational core, lowering the barriers to building more trustworthy systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12623v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrew Jeffery, Julien Maffre, Heidi Howard, Richard Mortier</dc:creator>
    </item>
    <item>
      <title>FlexFL: Heterogeneous Federated Learning via APoZ-Guided Flexible Pruning in Uncertain Scenarios</title>
      <link>https://arxiv.org/abs/2407.12729</link>
      <description>arXiv:2407.12729v1 Announce Type: new 
Abstract: Along with the increasing popularity of Deep Learning (DL) techniques, more and more Artificial Intelligence of Things (AIoT) systems are adopting federated learning (FL) to enable privacy-aware collaborative learning among AIoT devices. However, due to the inherent data and device heterogeneity issues, existing FL-based AIoT systems suffer from the model selection problem. Although various heterogeneous FL methods have been investigated to enable collaborative training among heterogeneous models, there is still a lack of i) wise heterogeneous model generation methods for devices, ii) consideration of uncertain factors, and iii) performance guarantee for large models, thus strongly limiting the overall FL performance. To address the above issues, this paper introduces a novel heterogeneous FL framework named FlexFL. By adopting our Average Percentage of Zeros (APoZ)-guided flexible pruning strategy, FlexFL can effectively derive best-fit models for heterogeneous devices to explore their greatest potential. Meanwhile, our proposed adaptive local pruning strategy allows AIoT devices to prune their received models according to their varying resources within uncertain scenarios. Moreover, based on self-knowledge distillation, FlexFL can enhance the inference performance of large models by learning knowledge from small models. Comprehensive experimental results show that, compared to state-of-the-art heterogeneous FL methods, FlexFL can significantly improve the overall inference accuracy by up to 14.24%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12729v1</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zekai Chen, Chentao Jia, Ming Hu, Xiaofei Xie, Anran Li, Mingsong Chen</dc:creator>
    </item>
    <item>
      <title>Efficiently Training 7B LLM with 1 Million Sequence Length on 8 GPUs</title>
      <link>https://arxiv.org/abs/2407.12117</link>
      <description>arXiv:2407.12117v1 Announce Type: cross 
Abstract: Nowadays, Large Language Models (LLMs) have been trained using extended context lengths to foster more creative applications. However, long context training poses great challenges considering the constraint of GPU memory. It not only leads to substantial activation memory consumption during training, but also incurs considerable memory fragmentation. To facilitate long context training, existing frameworks have adopted strategies such as recomputation and various forms of parallelisms. Nevertheless, these techniques rely on redundant computation or extensive communication, resulting in low Model FLOPS Utilization (MFU). In this paper, we propose MEMO, a novel LLM training framework designed for fine-grained activation memory management. Given the quadratic scaling of computation and linear scaling of memory with sequence lengths when using FlashAttention, we offload memory-consuming activations to CPU memory after each layer's forward pass and fetch them during the backward pass. To maximize the swapping of activations without hindering computation, and to avoid exhausting limited CPU memory, we implement a token-wise activation recomputation and swapping mechanism. Furthermore, we tackle the memory fragmentation issue by employing a bi-level Mixed Integer Programming (MIP) approach, optimizing the reuse of memory across transformer layers. Empirical results demonstrate that MEMO achieves an average of 2.42x and 2.26x MFU compared to Megatron-LM and DeepSpeed, respectively. This improvement is attributed to MEMO's ability to minimize memory fragmentation, reduce recomputation and intensive communication, and circumvent the delays associated with the memory reorganization process due to fragmentation. By leveraging fine-grained activation memory management, MEMO facilitates efficient training of 7B LLM with 1 million sequence length on just 8 A800 GPUs, achieving an MFU of 52.30%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12117v1</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pinxue Zhao, Hailin Zhang, Fangcheng Fu, Xiaonan Nie, Qibin Liu, Fang Yang, Yuanbo Peng, Dian Jiao, Shuaipeng Li, Jinbao Xue, Yangyu Tao, Bin Cui</dc:creator>
    </item>
    <item>
      <title>Gaming and Blockchain: Hype and Reality</title>
      <link>https://arxiv.org/abs/2407.12134</link>
      <description>arXiv:2407.12134v1 Announce Type: cross 
Abstract: This paper explores the adoption of blockchain technology in the gaming industry. While supporters affirm that distributed ledger technology has potential to revolutionize gaming economies and provide players with control over their virtual assets, there are practical challenges such as energy consumption and user adoption to be addressed, and detractors question whether blockchain integration is even necessary. This report characterises popular blockchain-based gaming projects like Enjin and Axie Infinity, then compares metrics such as transaction cost and player feedback to evaluate the longevity of blockchain-integrated gaming as a whole.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12134v1</guid>
      <category>cs.CY</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Max McGuinness</dc:creator>
    </item>
    <item>
      <title>To Trade Or Not To Trade: Cascading Waterfall Round Robin Rebalancing Mechanism for Cryptocurrencies</title>
      <link>https://arxiv.org/abs/2407.12150</link>
      <description>arXiv:2407.12150v1 Announce Type: cross 
Abstract: We have designed an innovative portfolio rebalancing mechanism termed the Cascading Waterfall Round Robin Mechanism. This algorithmic approach recommends an ideal size and number of trades for each asset during the periodic rebalancing process, factoring in the gas fee and slippage. The essence of the model we have created gives indications regarding whether trades should be made on individual assets depending on the uncertainty in the micro - asset level characteristics - and macro - aggregate market factors - environments. In the hyper-volatile crypto market, our approach to daily rebalancing will benefit from volatility. Price movements will cause our algorithm to buy assets that drop in prices and sell as they soar. In fact, the buying and selling happen only when certain boundaries are crossed in order to weed out any market noise and ensure sound trade execution. We have provided several numerical examples to illustrate the steps - including the calculation of several intermediate variables - of our rebalancing mechanism. The Algorithm we have developed can be easily applied outside blockchain to investment funds across all asset classes at any trading frequency and rebalancing duration.
  Shakespeare As A Crypto Trader:
  To Trade Or Not To Trade, that is the Question,
  Whether an Optimizer can Yield the Answer,
  Against the Spikes and Crashes of Markets Gone Wild,
  To Quench One's Thirst before Liquidity Runs Dry,
  Or Wait till the Tide of Momentum turns Mild.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12150v1</guid>
      <category>q-fin.PM</category>
      <category>cs.CE</category>
      <category>cs.DC</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ravi Kashyap</dc:creator>
    </item>
    <item>
      <title>Building AI Agents for Autonomous Clouds: Challenges and Design Principles</title>
      <link>https://arxiv.org/abs/2407.12165</link>
      <description>arXiv:2407.12165v1 Announce Type: cross 
Abstract: The rapid growth in the use of Large Language Models (LLMs) and AI Agents as part of software development and deployment is revolutionizing the information technology landscape. While code generation receives significant attention, a higher-impact application lies in using AI agents for operational resilience of cloud services, which currently require significant human effort and domain knowledge. There is a growing interest in AI for IT Operations (AIOps) which aims to automate complex operational tasks, like fault localization and root cause analysis, thereby reducing human intervention and customer impact. However, achieving the vision of autonomous and self-healing clouds though AIOps is hampered by the lack of standardized frameworks for building, evaluating, and improving AIOps agents. This vision paper lays the groundwork for such a framework by first framing the requirements and then discussing design decisions that satisfy them. We also propose AIOpsLab, a prototype implementation leveraging agent-cloud-interface that orchestrates an application, injects real-time faults using chaos engineering, and interfaces with an agent to localize and resolve the faults. We report promising results and lay the groundwork to build a modular and robust framework for building, evaluating, and improving agents for autonomous clouds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12165v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Manish Shetty, Yinfang Chen, Gagan Somashekar, Minghua Ma, Yogesh Simmhan, Xuchao Zhang, Jonathan Mace, Dax Vandevoorde, Pedro Las-Casas, Shachee Mishra Gupta, Suman Nath, Chetan Bansal, Saravan Rajmohan</dc:creator>
    </item>
    <item>
      <title>The Latency Price of Threshold Cryptosystem in Blockchains</title>
      <link>https://arxiv.org/abs/2407.12172</link>
      <description>arXiv:2407.12172v1 Announce Type: cross 
Abstract: Threshold cryptography is essential for many blockchain protocols. For example, many protocols rely on threshold common coin to implement asynchronous consensus, leader elections, and provide support for randomized applications. Similarly, threshold signature schemes are frequently used for protocol efficiency and state certification, and threshold decryption and threshold time-lock puzzles are often necessary for privacy.
  In this paper, we study the interplay between threshold cryptography and a class of blockchains that use Byzantine-fault tolerant (BFT) consensus protocols with a focus on latency. More specifically, we focus on blockchain-native threshold cryptosystem, where the blockchain validators seek to run a threshold cryptographic protocol once for every block with the block contents as an input to the threshold cryptographic protocol. All existing approaches for blockchain-native threshold cryptosystems introduce a latency overhead of at least one message delay for running the threshold cryptographic protocol. In this paper, we first propose a mechanism to eliminate this overhead for blockchain-native threshold cryptosystems with tight thresholds, i.e., in threshold cryptographic protocols where the secrecy and reconstruction thresholds are the same. However, many real-world proof-of-stake-based blockchain-native threshold cryptosystems rely on ramp thresholds, where reconstruction thresholds are strictly greater than secrecy thresholds. For these blockchains, we formally demonstrate that the additional delay is unavoidable. We then introduce a mechanism to minimize this delay in the optimistic case. We implement our optimistic protocol for the proof-of-stake distributed randomness scheme on the Aptos blockchain. Our measurements from the Aptos mainnet show that the optimistic approach reduces latency overhead by 71%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12172v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhuolun Xiang, Sourav Das, Zekun Li, Zhoujun Ma, Alexander Spiegelman</dc:creator>
    </item>
    <item>
      <title>More is Different: Prototyping and Analyzing a New Form of Edge Server with Massive Mobile SoCs</title>
      <link>https://arxiv.org/abs/2212.12842</link>
      <description>arXiv:2212.12842v2 Announce Type: replace 
Abstract: Huge energy consumption poses a significant challenge for edge clouds. In response to this, we introduce a new type of edge server, namely SoC Cluster, that orchestrates multiple low-power mobile system-on-chips (SoCs) through an on-chip network. For the first time, we have developed a concrete SoC Cluster consisting of 60 Qualcomm Snapdragon 865 SoCs housed in a 2U rack, which has been successfully commercialized and extensively deployed in edge clouds. Cloud gaming emerges as the principal workload on these deployed SoC Clusters, owing to the compatibility between mobile SoCs and native mobile games.
  In this study, we aim to demystify whether the SoC Cluster can efficiently serve more generalized, typical edge workloads. Therefore, we developed a benchmark suite that employs state-of-the-art libraries for two critical edge workloads, i.e., video transcoding and deep learning inference. This suite evaluates throughput, latency, power consumption, and other application-specific metrics like video quality. Following this, we conducted a thorough measurement study and directly compared the SoC Cluster with traditional edge servers, with regards to electricity usage and monetary cost. Our results quantitatively reveal when and for which applications mobile SoCs exhibit higher energy efficiency than traditional servers, as well as their ability to proportionally scale power consumption with fluctuating incoming loads. These outcomes provide insightful implications and offer valuable direction for further refinement of the SoC Cluster to facilitate its deployment across wider edge scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.12842v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Zhang, Zhe Fu, Boqing Shi, Xiang Li, Rujin Lai, Chenyang Yang, Ao Zhou, Xiao Ma, Shangguang Wang, Mengwei Xu</dc:creator>
    </item>
    <item>
      <title>CXL Shared Memory Programming: Barely Distributed and Almost Persistent</title>
      <link>https://arxiv.org/abs/2405.19626</link>
      <description>arXiv:2405.19626v2 Announce Type: replace 
Abstract: While Compute Express Link (CXL) enables support for cache-coherent shared memory among multiple nodes, it also introduces new types of failures--processes can fail before data does, or data might fail before a process does. The lack of a failure model for CXL-based shared memory makes it challenging to understand and mitigate these failures.
  To solve these challenges, in this paper, we describe a model categorizing and handling the CXL-based shared memory's failures: data and process failures. Data failures in CXL-based shared memory render data inaccessible or inconsistent for a currently running application. We argue that such failures are unlike data failures in distributed storage systems and require CXL-specific handling. To address this, we look into traditional data failure mitigation techniques like erasure coding and replication and propose new solutions to better handle data failures in CXL-based shared memory systems. Next, we look into process failures and compare the failures and potential solutions with PMEM's failure model and programming solutions. We argue that although PMEM shares some of CXL's characteristics, it does not fully address CXL's volatile nature and low access latencies. Finally, taking inspiration from PMEM programming solutions, we propose techniques to handle these new failures.
  Thus, this paper is the first work to define the CXL-based shared memory failure model and propose tailored solutions that address challenges specific to CXL-based systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.19626v2</guid>
      <category>cs.DC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yi Xu, Suyash Mahar, Ziheng Liu, Mingyao Shen, Steven Swanson</dc:creator>
    </item>
    <item>
      <title>CaBaFL: Asynchronous Federated Learning via Hierarchical Cache and Feature Balance</title>
      <link>https://arxiv.org/abs/2404.12850</link>
      <description>arXiv:2404.12850v2 Announce Type: replace-cross 
Abstract: Federated Learning (FL) as a promising distributed machine learning paradigm has been widely adopted in Artificial Intelligence of Things (AIoT) applications. However, the efficiency and inference capability of FL is seriously limited due to the presence of stragglers and data imbalance across massive AIoT devices, respectively. To address the above challenges, we present a novel asynchronous FL approach named CaBaFL, which includes a hierarchical Cache-based aggregation mechanism and a feature Balance-guided device selection strategy. CaBaFL maintains multiple intermediate models simultaneously for local training. The hierarchical cache-based aggregation mechanism enables each intermediate model to be trained on multiple devices to align the training time and mitigate the straggler issue. In specific, each intermediate model is stored in a low-level cache for local training and when it is trained by sufficient local devices, it will be stored in a high-level cache for aggregation. To address the problem of imbalanced data, the feature balance-guided device selection strategy in CaBaFL adopts the activation distribution as a metric, which enables each intermediate model to be trained across devices with totally balanced data distributions before aggregation. Experimental results show that compared with the state-of-the-art FL methods, CaBaFL achieves up to 9.26X training acceleration and 19.71\% accuracy improvements.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.12850v2</guid>
      <category>cs.LG</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeke Xia, Ming Hu, Dengke Yan, Xiaofei Xie, Tianlin Li, Anran Li, Junlong Zhou, Mingsong Chen</dc:creator>
    </item>
  </channel>
</rss>
