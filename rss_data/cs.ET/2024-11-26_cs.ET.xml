<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 06:04:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>MolMetaLM: a Physicochemical Knowledge-Guided Molecular Meta Language Model</title>
      <link>https://arxiv.org/abs/2411.15500</link>
      <description>arXiv:2411.15500v1 Announce Type: new 
Abstract: Most current molecular language models transfer the masked language model or image-text generation model from natural language processing to molecular field. However, molecules are not solely characterized by atom/bond symbols; they encapsulate important physical/chemical properties. Moreover, normal language models bring grammar rules that are irrelevant for understanding molecules. In this study, we propose a novel physicochemical knowledge-guided molecular meta language framework MolMetaLM. We design a molecule-specialized meta language paradigm, formatted as multiple &lt;S,P,O&gt; (subject, predicate, object) knowledge triples sharing the same S (i.e., molecule) to enhance learning the semantic relationships between physicochemical knowledge and molecules. By introducing different molecular knowledge and noises, the meta language paradigm generates tens of thousands of pretraining tasks. By recovering the token/sequence/order-level noises, MolMetaLM exhibits proficiency in large-scale benchmark evaluations involving property prediction, molecule generation, conformation inference, and molecular optimization. Through MolMetaLM, we offer a new insight for designing language models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15500v1</guid>
      <category>cs.ET</category>
      <category>cs.CL</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Wu, Min Zeng, Yang Li, Yang Zhang, Min Li</dc:creator>
    </item>
    <item>
      <title>Imperfect-Information Games on Quantum Computers: A Case Study in Skat</title>
      <link>https://arxiv.org/abs/2411.15294</link>
      <description>arXiv:2411.15294v1 Announce Type: cross 
Abstract: For decades it is known that Quantum Computers might serve as a tool to solve a very specific kind of problems that have long thought to be incalculable. Some of those problems are of a combinatorial nature, with the quantum advantage arising from the exploding size of a huge decision tree. Although this is of high interest as well, there are more opportunities to make use of the quantum advantage among non-perfect information games with a limited amount of steps within the game. Even though it is not possible to answer the question for the winning move in a specific situation, people are rather interested in what choice gives the best outcome in the long run. This leads us to the search for the highest number of paths within the game's decision tree despite the lack of information and, thus, to a maximum of the payoff-function. We want to illustrate on how Quantum Computers can play a significant role in solving these kind of games, using an example of the most popular German card game Skat. Therefore we use quantum registers to encode the game's information properly and construct the corresponding quantum gates in order to model the game progress and obey the rules. Finally, we use a score operator to project the quantum state onto the winning subspace and therefore evaluate the winning probability for each alternative decision by the player to be made by using quantum algorithms, such as quantum counting of the winning paths to gain a possible advantage in computation speed over classical approaches. Thus, we get a reasonable recommendation of how to act at the table due to the payoff-function maximization. This approach is clearly not doable on a classical computer due to the huge tree-search problem and we discuss peculiarities of the problem that may lead to a quantum advantage when exceeding a certain problem size.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15294v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Erik Schulze, Ulrich Armbr\"uster, Gabriel Maresch, Stefan Edelkamp</dc:creator>
    </item>
    <item>
      <title>Mera: Memory Reduction and Acceleration for Quantum Circuit Simulation via Redundancy Exploration</title>
      <link>https://arxiv.org/abs/2411.15332</link>
      <description>arXiv:2411.15332v1 Announce Type: cross 
Abstract: With the development of quantum computing, quantum processor demonstrates the potential supremacy in specific applications, such as Grovers database search and popular quantum neural networks (QNNs). For better calibrating the quantum algorithms and machines, quantum circuit simulation on classical computers becomes crucial. However, as the number of quantum bits (qubits) increases, the memory requirement grows exponentially. In order to reduce memory usage and accelerate simulation, we propose a multi-level optimization, namely Mera, by exploring memory and computation redundancy. First, for a large number of sparse quantum gates, we propose two compressed structures for low-level full-state simulation. The corresponding gate operations are designed for practical implementations, which are relieved from the longtime compression and decompression. Second, for the dense Hadamard gate, which is definitely used to construct the superposition, we design a customized structure for significant memory saving as a regularity-oriented simulation. Meanwhile, an ondemand amplitude updating process is optimized for execution acceleration. Experiments show that our compressed structures increase the number of qubits from 17 to 35, and achieve up to 6.9 times acceleration for QNN.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15332v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuhong Song, Edwin Hsing-Mean Sha, Longshan Xu, Qingfeng Zhuge, Zili Shao</dc:creator>
    </item>
    <item>
      <title>Reformulating Regression Test Suite Optimization using Quantum Annealing -- an Empirical Study</title>
      <link>https://arxiv.org/abs/2411.15963</link>
      <description>arXiv:2411.15963v1 Announce Type: cross 
Abstract: Maintaining software quality is crucial in the dynamic landscape of software development. Regression testing ensures that software works as expected after changes are implemented. However, re-executing all test cases for every modification is often impractical and costly, particularly for large systems. Although very effective, traditional test suite optimization techniques are often impractical in resource-constrained scenarios, as they are computationally expensive. Hence, quantum computing solutions have been developed to improve their efficiency but have shown drawbacks in terms of effectiveness. We propose reformulating the regression test case selection problem to use quantum computation techniques better. Our objectives are (i) to provide more efficient solutions than traditional methods and (ii) to improve the effectiveness of previously proposed quantum-based solutions. We propose SelectQA, a quantum annealing approach that can outperform the quantum-based approach BootQA in terms of effectiveness while obtaining results comparable to those of the classic Additional Greedy and DIV-GA approaches. Regarding efficiency, SelectQA outperforms DIV-GA and has similar results with the Additional Greedy algorithm but is exceeded by BootQA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15963v1</guid>
      <category>cs.SE</category>
      <category>cs.ET</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Antonio Trovato, Manuel De Stefano, Fabiano Pecorelli, Dario Di Nucci, Andrea De Lucia</dc:creator>
    </item>
    <item>
      <title>Data Processing Efficiency Aware User Association and Resource Allocation in Blockchain Enabled Metaverse over Wireless Communications</title>
      <link>https://arxiv.org/abs/2411.16083</link>
      <description>arXiv:2411.16083v1 Announce Type: cross 
Abstract: In the rapidly evolving landscape of the Metaverse, enhanced by blockchain technology, the efficient processing of data has emerged as a critical challenge, especially in wireless communication systems. Addressing this need, our paper introduces the innovative concept of data processing efficiency (DPE), aiming to maximize processed bits per unit of resource consumption in blockchain-empowered Metaverse environments. To achieve this, we propose the DPE-Aware User Association and Resource Allocation (DAUR) algorithm, a tailored solution for these complex systems. The DAUR algorithm transforms the challenging task of optimizing the sum of DPE ratios into a solvable convex optimization problem. It uniquely alternates the optimization of key variables like user association, work offloading ratios, task-specific computing resource distribution, bandwidth allocation, user power usage ratios, and server computing resource allocation ratios. Our extensive numerical results demonstrate the DAUR algorithm's effectiveness in DPE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16083v1</guid>
      <category>eess.SP</category>
      <category>cs.DC</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liangxin Qian, Jun Zhao</dc:creator>
    </item>
    <item>
      <title>Collaboration in Virtual Reality: Survey and Perspectives</title>
      <link>https://arxiv.org/abs/2411.16124</link>
      <description>arXiv:2411.16124v1 Announce Type: cross 
Abstract: The application of Virtual Reality Environments (VRE) has been gaining momentum as a relatively new tool to assist with mitigating various difficulties including abstractness of concepts, lack of user engagement, perception of disconnection from other users. A VRE may offer both synchronous and asynchronous experiences, in addition to an immersive environment which promotes users' engagement. Past research has shown that, in general, VRE do improve the experiences they try to enhance in many aspects of human activity. Terms like immersiveness and 3D representation of real life objects and environments are, as it appears, the two most obvious positive effects of Virtual Reality (VR) applications. However, despite these benefits it does not come without challenges. The main three concepts/challenges are the spatial design, the collaboration interaction between its members and the VRE, and the audio and video fidelity. Each of the three includes a number of other components that should be addressed for the total experience to be fine-tuned. These include mutual embodiment and shared perspectives, teleportation, gestural interaction, symmetric and asymmetric collaboration, physical and virtual co-location, inventory, and time and spatial synchronization. This paper comprises a survey of the literature, that identifies and explains the features introduced and the challenges involved with the VREs, and furthermore provides various interesting future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16124v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ourania Koutzampasopoulou Xanthidou, Nadine Aburumman, Han\^ene Ben-Abdallah</dc:creator>
    </item>
    <item>
      <title>A Survey of Blockchain-Based Privacy Applications: An Analysis of Consent Management and Self-Sovereign Identity Approaches</title>
      <link>https://arxiv.org/abs/2411.16404</link>
      <description>arXiv:2411.16404v1 Announce Type: cross 
Abstract: Modern distributed applications in healthcare, supply chain, and the Internet of Things handle a large amount of data in a diverse application setting with multiple stakeholders. Such applications leverage advanced artificial intelligence (AI) and machine learning algorithms to automate business processes. The proliferation of modern AI technologies increases the data demand. However, real-world networks often include private and sensitive information of businesses, users, and other organizations. Emerging data-protection regulations such as the General Data Protection Regulation (GDPR) and the California Consumer Privacy Act (CCPA) introduce policies around collecting, storing, and managing digital data. While Blockchain technology offers transparency, auditability, and immutability for multi-stakeholder applications, it lacks inherent support for privacy. Typically, privacy support is added to a blockchain-based application by incorporating cryptographic schemes, consent mechanisms, and self-sovereign identity. This article surveys the literature on blockchain-based privacy-preserving systems and identifies the tools for protecting privacy. Besides, consent mechanisms and identity management in the context of blockchain-based systems are also analyzed. The article concludes by highlighting the list of open challenges and further research opportunities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16404v1</guid>
      <category>cs.CR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rodrigo Dutra Garcia, Gowri Ramachandran, Kealan Dunnett, Raja Jurdak, Caetano Ranieri, Bhaskar Krishnamachari, Jo Ueyama</dc:creator>
    </item>
    <item>
      <title>Distributing Quantum Computations, Shot-wise</title>
      <link>https://arxiv.org/abs/2411.16530</link>
      <description>arXiv:2411.16530v1 Announce Type: cross 
Abstract: NISQ (Noisy Intermediate-Scale Quantum) era constraints, high sensitivity to noise and limited qubit count, impose significant barriers on the usability of QPUs (Quantum Process Units) capabilities. To overcome these challenges, researchers are exploring methods to maximize the utility of existing QPUs despite their limitations. Building upon the idea that the execution of a quantum circuit's shots needs not to be treated as a singular monolithic unit, we propose a methodological framework, termed shot-wise, which enables the distribution of shots for a single circuit across multiple QPUs. Our framework features customizable policies to adapt to various scenarios. Additionally, it introduces a calibration method to pre-evaluate the accuracy and reliability of each QPU's output before the actual distribution process and an incremental execution mechanism for dynamically managing the shot allocation and policy updates. Such an approach enables flexible and fine-grained management of the distribution process, taking into account various user-defined constraints and (contrasting) objectives. Experimental findings show that while these strategies generally do not exceed the best individual QPU results, they maintain robustness and align closely with average outcomes. Overall, the shot-wise methodology improves result stability and often outperforms single QPU runs, offering a flexible approach to managing variability in quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16530v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <category>cs.SE</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giuseppe Bisicchia, Giuseppe Clemente, Jose Garcia-Alonso, Juan Manuel Murillo Rodr\'iguez, Massimo D'Elia, Antonio Brogi</dc:creator>
    </item>
    <item>
      <title>Rate-independent continuous inhibitory chemical reaction networks are Turing-universal</title>
      <link>https://arxiv.org/abs/2403.07099</link>
      <description>arXiv:2403.07099v2 Announce Type: replace 
Abstract: We study the model of continuous chemical reaction networks (CRNs), consisting of reactions such as $A+B \to C+D$ that can transform some continuous, nonnegative real-valued quantity (called a *concentration*) of chemical species $A$ and $B$ into equal concentrations of $C$ and $D$. Such a reaction can occur from any state in which both reactants $A$ and $B$ are present, i.e., have positive concentration. We modify the model to allow *inhibitors*, for instance, reaction $A+B \to^{I} C+D$ can occur only if the reactants $A$ and $B$ are present and the inhibitor $I$ is absent. The computational power of non-inhibitory CRNs has been studied. For instance, the reaction $X_1+X_2 \to Y$ can be thought to compute the function $f(x_1,x_2) = \min(x_1,x_2)$. Under an "adversarial" model in which reaction rates can vary arbitrarily over time, it was found that exactly the continuous, piecewise linear functions can be computed, ruling out even simple functions such as $f(x) = x^2$. In contrast, in this paper we show that inhibitory CRNs can compute any computable function $f:\mathbb{N}\to\mathbb{N}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07099v2</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-63742-1_8</arxiv:DOI>
      <dc:creator>Kim Calabrese, David Doty</dc:creator>
    </item>
    <item>
      <title>Reasoning Abilities of Large Language Models: In-Depth Analysis on the Abstraction and Reasoning Corpus</title>
      <link>https://arxiv.org/abs/2403.11793</link>
      <description>arXiv:2403.11793v3 Announce Type: replace-cross 
Abstract: The existing methods for evaluating the inference abilities of Large Language Models (LLMs) have been predominantly results-centric, making it challenging to assess the inference process comprehensively. We introduce a novel approach using the Abstraction and Reasoning Corpus (ARC) benchmark to evaluate the inference and contextual understanding abilities of LLMs in a process-centric manner, focusing on three key components from the Language of Thought Hypothesis (LoTH): Logical Coherence, Compositionality, and Productivity. Our carefully designed experiments reveal that while LLMs demonstrate some inference capabilities, they still significantly lag behind human-level reasoning in these three aspects. The main contribution of this paper lies in introducing the LoTH perspective, which provides a method for evaluating the reasoning process that conventional results-oriented approaches fail to capture, thereby offering new insights into the development of human-level reasoning in artificial intelligence systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.11793v3</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.SC</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Seungpil Lee, Woochang Sim, Donghyeon Shin, Wongyu Seo, Jiwon Park, Seokki Lee, Sanha Hwang, Sejin Kim, Sundong Kim</dc:creator>
    </item>
    <item>
      <title>Unsupervised machine learning for data-driven rock mass classification: addressing limitations in existing systems using drilling data</title>
      <link>https://arxiv.org/abs/2405.02631</link>
      <description>arXiv:2405.02631v2 Announce Type: replace-cross 
Abstract: Rock mass classification systems are crucial for assessing stability and risk in underground construction globally and guiding support and excavation design. However, these systems, developed primarily in the 1970s, lack access to modern high-resolution data and advanced statistical techniques, limiting their effectiveness as decision-support systems. We outline these limitations and describe how a data-driven system, based on drilling data, can overcome them. Using statistical information extracted from thousands of MWD-data values in one-meter sections of a tunnel profile, acting as a signature of the rock mass, we demonstrate that well-defined clusters can form a foundational basis for various classification systems. Representation learning was used to reduce the dimensionality of 48-value vectors via a nonlinear manifold learning technique (UMAP) and linear principal component analysis (PCA) to enhance clustering. Unsupervised machine learning methods (HDBSCAN, Agglomerative Clustering, K-means) clustered the data, with hyperparameters optimised through multi-objective Bayesian optimisation. Domain knowledge improved clustering by adding extra features to core MWD-data clusters. We structured and correlated these clusters with physical rock properties, including rock type and quality, and analysed cumulative distributions of key MWD-parameters to determine if clusters meaningfully differentiate rock masses. The ability of MWD data to form distinct rock mass clusters suggests substantial potential for future classification systems using this objective, data-driven methodology, minimising human bias.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.02631v2</guid>
      <category>cs.LG</category>
      <category>cs.ET</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>T. F. Hansen, A. Aarset</dc:creator>
    </item>
    <item>
      <title>Analog In-Memory Computing Attention Mechanism for Fast and Energy-Efficient Large Language Models</title>
      <link>https://arxiv.org/abs/2409.19315</link>
      <description>arXiv:2409.19315v2 Announce Type: replace-cross 
Abstract: Transformer networks, driven by self-attention, are central to Large Language Models. In generative Transformers, self-attention uses cache memory to store token projections, avoiding recomputation at each time step. However, GPU-stored projections must be loaded into SRAM for each new generation step, causing latency and energy bottlenecks.
  We present a custom self-attention in-memory computing architecture based on emerging charge-based memories called gain cells, which can be efficiently written to store new tokens during sequence generation and enable parallel analog dot-product computation required for self-attention. However, the analog gain cell circuits introduce non-idealities and constraints preventing the direct mapping of pre-trained models. To circumvent this problem, we design an initialization algorithm achieving text processing performance comparable to GPT-2 without training from scratch. Our architecture respectively reduces attention latency and energy consumption by up to two and five orders of magnitude compared to GPUs, marking a significant step toward ultra-fast, low-power generative Transformers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.19315v2</guid>
      <category>cs.NE</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Leroux, Paul-Philipp Manea, Chirag Sudarshan, Jan Finkbeiner, Sebastian Siegel, John Paul Strachan, Emre Neftci</dc:creator>
    </item>
  </channel>
</rss>
