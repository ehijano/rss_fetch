<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 30 Jan 2025 05:00:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Hardness and Approximation Algorithms for Balanced Districting Problems</title>
      <link>https://arxiv.org/abs/2501.17277</link>
      <description>arXiv:2501.17277v1 Announce Type: new 
Abstract: We introduce and study the problem of balanced districting, where given an undirected graph with vertices carrying two types of weights (different population, resource types, etc) the goal is to maximize the total weights covered in vertex disjoint districts such that each district is a star or (in general) a connected induced subgraph with the two weights to be balanced. This problem is strongly motivated by political redistricting, where contiguity, population balance, and compactness are essential. We provide hardness and approximation algorithms for this problem. In particular, we show NP-hardness for an approximation better than $n^{1/2-\delta}$ for any constant $\delta&gt;0$ in general graphs even when the districts are star graphs, as well as NP-hardness on complete graphs, tree graphs, planar graphs and other restricted settings. On the other hand, we develop an algorithm for balanced star districting that gives an $O(\sqrt{n})$-approximation on any graph (which is basically tight considering matching hardness of approximation results), an $O(\log n)$ approximation on planar graphs with extensions to minor-free graphs. Our algorithm uses a modified Whack-a-Mole algorithm [Bhattacharya, Kiss, and Saranurak, SODA 2023] to find a sparse solution of a fractional packing linear program (despite exponentially many variables) and to get a good approximation ratio of the rounding procedure, a crucial element in the analysis is the \emph{balanced scattering separators} for planar graphs and minor-free graphs - separators that can be partitioned into a small number of $k$-hop independent sets for some constant $k$ - which may find independent interest in solving other packing style problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17277v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Prathamesh Dharangutte, Jie Gao, Shang-En Huang, Fang-Yi Yu</dc:creator>
    </item>
    <item>
      <title>Stable Tree Labelling for Accelerating Distance Queries on Dynamic Road Networks</title>
      <link>https://arxiv.org/abs/2501.17379</link>
      <description>arXiv:2501.17379v1 Announce Type: new 
Abstract: Finding the shortest-path distance between two arbitrary vertices is an important problem in road networks. Due to real-time traffic conditions, road networks undergo dynamic changes all the time. Current state-of-the-art methods incrementally maintain a distance labelling based on a hierarchy among vertices to support efficient distance computation. However, their labelling sizes are often large and cannot be efficiently maintained. To combat these issues, we present a simple yet efficient labelling method, namely \emph{Stable Tree Labelling} (STL), for answering distance queries on dynamic road networks. We observe that the properties of an underlying hierarchy play an important role in improving and balancing query and update performance. Thus, we introduce the notion of \emph{stable tree hierarchy} which lays the ground for developing efficient maintenance algorithms on dynamic road networks. Based on stable tree hierarchy, STL can be efficiently constructed as a 2-hop labelling. A crucial ingredient of STL is to only store distances within subgraphs in labels, rather than distances in the entire graph, which restricts the labels affected by dynamic changes. We further develop two efficient maintenance algorithms upon STL: \emph{Label Search algorithm} and \emph{Pareto Search algorithm}. Label Search algorithm identifies affected ancestors in a stable tree hierarchy and performs efficient searches to update labels from those ancestors. Pareto Search algorithm explores the interaction between search spaces of different ancestors, and combines searches from multiple ancestors into only two searches for each update, eliminating duplicate graph traversals. The experiments show that our algorithms significantly outperform state-of-the-art dynamic methods in maintaining the labelling and query processing, while requiring an order of magnitude less space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17379v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Henning Koehler, Muhammad Farhan, Qing Wang</dc:creator>
    </item>
    <item>
      <title>Search Trees on Trees via LP</title>
      <link>https://arxiv.org/abs/2501.17563</link>
      <description>arXiv:2501.17563v1 Announce Type: new 
Abstract: We consider the problem of computing optimal search trees on trees (STTs). STTs generalize binary search trees (BSTs) in which we search nodes in a path (linear order) to search trees that facilitate search over general tree topologies. Golinsky proposed a linear programming (LP) relaxation of the problem of computing an optimal static STT over a given tree topology. He used this LP formulation to compute an STT that is a $2$-approximation to an optimal STT, and conjectured that it is, in fact, an extended formulation of the convex-hull of all depths-vectors of STTs, and thus always gives an optimal solution. In this work we study this LP approach further. We show that the conjecture is false and that Golinsky's LP does not always give an optimal solution. To show this we use what we call the ``normals method''. We use this method to enumerate over vertices of Golinsky's polytope for all tree topologies of no more than 8 nodes. We give a lower bound on the integrality gap of the LP and on the approximation ratio of Golinsky's rounding method. We further enumerate several research directions that can lead to the resolution of the question whether one can compute an optimal STT in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17563v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yaniv Sadeh, Haim Kaplan, Uri Zwick</dc:creator>
    </item>
    <item>
      <title>Unifying Scheduling Algorithms for Group Completion Time</title>
      <link>https://arxiv.org/abs/2501.17682</link>
      <description>arXiv:2501.17682v1 Announce Type: new 
Abstract: We propose new abstract problems that unify a collection of scheduling and graph coloring problems with general min-sum objectives. Specifically, we consider the weighted sum of completion times over groups of entities (jobs, vertices, or edges), which generalizes two important objectives in scheduling: makespan and sum of weighted completion times.
  We study these problems in both online and offline settings. In the non-clairvoyant online setting, we give a novel $O(\log g)$-competitive algorithm, where $g$ is the size of the largest group. This is the first non-trivial competitive bound for many problems with group completion time objective, and it is an exponential improvement over previous results for non-clairvoyant coflow scheduling. Notably, this bound is asymptotically best-possible. For offline scheduling, we provide powerful meta-frameworks that lead to new or stronger approximation algorithms for our new abstract problems and for previously well-studied special cases. In particular, we improve the approximation ratio from $13.5$ to $10.874$ for non-preemptive related machine scheduling and from $4+\varepsilon$ to $2+\varepsilon$ for preemptive unrelated machine scheduling (MOR 2012), and we improve the approximation ratio for sum coloring problems from $10.874$ to $5.437$ for perfect graphs and from $11.273$ to $10.874$ for interval graphs (TALG 2008).</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17682v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alexander Lindermayr, Zhenwei Liu, Nicole Megow</dc:creator>
    </item>
    <item>
      <title>Decision-Theoretic Approaches in Learning-Augmented Algorithms</title>
      <link>https://arxiv.org/abs/2501.17701</link>
      <description>arXiv:2501.17701v1 Announce Type: new 
Abstract: In this work, we initiate the systemic study of decision-theoretic metrics in the design and analysis of algorithms with machine-learned predictions. We introduce approaches based on both deterministic measures such as distance-based evaluation, that help us quantify how close the algorithm is to an ideal solution, as well as stochastic measures that allow us to balance the trade-off between the algorithm's performance and the risk associated with the imperfect oracle. These approaches help us quantify the algorithmic performance across the entire spectrum of prediction error, unlike several previous works that focus on few, and often extreme values of the error. We apply these techniques to two well-known problems from resource allocation and online decision making, namely contract scheduling and 1-max search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17701v1</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spyros Angelopoulos, Christoph D\"urr, Georgii Melidi</dc:creator>
    </item>
    <item>
      <title>Improved fixed-parameter bounds for Min-Sum-Radii and Diameters $k$-clustering and their fair variants</title>
      <link>https://arxiv.org/abs/2501.17708</link>
      <description>arXiv:2501.17708v1 Announce Type: new 
Abstract: We provide improved upper and lower bounds for the Min-Sum-Radii (MSR) and Min-Sum-Diameters (MSD) clustering problems with a bounded number of clusters $k$. In particular, we propose an exact MSD algorithm with running-time $n^{O(k)}$. We also provide $(1+\epsilon)$ approximation algorithms for both MSR and MSD with running-times of $O(kn) +(1/\epsilon)^{O(dk)}$ in metrics spaces of doubling dimension $d$. Our algorithms extend to $k$-center, improving upon previous results, and to $\alpha$-MSR, where radii are raised to the $\alpha$ power for $\alpha&gt;1$. For $\alpha$-MSD we prove an exponential time ETH-based lower bound for $\alpha&gt;\log 3$. All algorithms can also be modified to handle outliers. Moreover, we can extend the results to variants that observe \emph{fairness} constraints, as well as to the general framework of \emph{mergeable} clustering, which includes many other popular clustering variants. We complement these upper bounds with ETH-based lower bounds for these problems, in particular proving that $n^{O(k)}$ time is tight for MSR and $\alpha$-MSR even in doubling spaces, and that $2^{o(k)}$ bounds are impossible for MSD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17708v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sandip Banerjee, Yair Bartal, Lee-Ad Gottlieb, Alon Hovav</dc:creator>
    </item>
    <item>
      <title>Matrix Product Sketching via Coordinated Sampling</title>
      <link>https://arxiv.org/abs/2501.17836</link>
      <description>arXiv:2501.17836v1 Announce Type: new 
Abstract: We revisit the well-studied problem of approximating a matrix product, $\mathbf{A}^T\mathbf{B}$, based on small space sketches $\mathcal{S}(\mathbf{A})$ and $\mathcal{S}(\mathbf{B})$ of $\mathbf{A} \in \R^{n \times d}$ and $\mathbf{B}\in \R^{n \times m}$. We are interested in the setting where the sketches must be computed independently of each other, except for the use of a shared random seed. We prove that, when $\mathbf{A}$ and $\mathbf{B}$ are sparse, methods based on \emph{coordinated random sampling} can outperform classical linear sketching approaches, like Johnson-Lindenstrauss Projection or CountSketch. For example, to obtain Frobenius norm error $\epsilon\|\mathbf{A}\|_F\|\mathbf{B}\|_F$, coordinated sampling requires sketches of size $O(s/\epsilon^2)$ when $\mathbf{A}$ and $\mathbf{B}$ have at most $s \leq d,m$ non-zeros per row. In contrast, linear sketching leads to sketches of size $O(d/\epsilon^2)$ and $O(m/\epsilon^2)$ for $\mathbf{A}$ and $\mathbf{B}$. We empirically evaluate our approach on two applications: 1) distributed linear regression in databases, a problem motivated by tasks like dataset discovery and augmentation, and 2) approximating attention matrices in transformer-based language models. In both cases, our sampling algorithms yield an order of magnitude improvement over linear sketching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17836v1</guid>
      <category>cs.DS</category>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Majid Daliri, Juliana Freire, Danrong Li, Christopher Musco</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Algorithms for Omniprediction</title>
      <link>https://arxiv.org/abs/2501.17205</link>
      <description>arXiv:2501.17205v1 Announce Type: cross 
Abstract: Omnipredictors are simple prediction functions that encode loss-minimizing predictions with respect to a hypothesis class $\H$, simultaneously for every loss function within a class of losses $\L$. In this work, we give near-optimal learning algorithms for omniprediction, in both the online and offline settings. To begin, we give an oracle-efficient online learning algorithm that acheives $(\L,\H)$-omniprediction with $\tilde{O}(\sqrt{T \log |\H|})$ regret for any class of Lipschitz loss functions $\L \subseteq \L_\mathrm{Lip}$. Quite surprisingly, this regret bound matches the optimal regret for \emph{minimization of a single loss function} (up to a $\sqrt{\log(T)}$ factor). Given this online algorithm, we develop an online-to-offline conversion that achieves near-optimal complexity across a number of measures. In particular, for all bounded loss functions within the class of Bounded Variation losses $\L_\mathrm{BV}$ (which include all convex, all Lipschitz, and all proper losses) and any (possibly-infinite) $\H$, we obtain an offline learning algorithm that, leveraging an (offline) ERM oracle and $m$ samples from $\D$, returns an efficient $(\L_{\mathrm{BV}},\H,\eps(m))$-omnipredictor for $\eps(m)$ scaling near-linearly in the Rademacher complexity of $\mathrm{Th} \circ \H$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17205v1</guid>
      <category>stat.ML</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Princewill Okoroafor, Robert Kleinberg, Michael P. Kim</dc:creator>
    </item>
    <item>
      <title>Better and Simpler Reducibility Bounds over the Integers</title>
      <link>https://arxiv.org/abs/2501.17638</link>
      <description>arXiv:2501.17638v1 Announce Type: cross 
Abstract: We study the settings where we are given a function of n variables defined in a given box of integers. We show that in many cases we can replace the given objective function by a new function with a much smaller domain. Our approach allows us to transform a family of weakly polynomial time algorithms into strongly polynomial time algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.17638v1</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Asaf Levin</dc:creator>
    </item>
    <item>
      <title>Finding a Minimum Spanning Tree with a Small Non-Terminal Set</title>
      <link>https://arxiv.org/abs/2310.05494</link>
      <description>arXiv:2310.05494v2 Announce Type: replace 
Abstract: In this paper, we study the problem of finding a minimum weight spanning tree that contains each vertex in a given subset $V_{\rm NT}$ of vertices as an internal vertex. This problem, called Minimum Weight Non-Terminal Spanning Tree, includes $s$-$t$ Hamiltonian Path as a special case, and hence it is NP-hard. In this paper, we first observe that Non-Terminal Spanning Tree, the unweighted counterpart of Minimum Weight Non-Terminal Spanning Tree, is already NP-hard on some special graph classes. Moreover, it is W[1]-hard when parameterized by clique-width. In contrast, we give a $3k$-vertex kernel and $O^*(2^k)$-time algorithm, where $k$ is the size of non-terminal set $V_{\rm NT}$. The latter algorithm can be extended to Minimum Weight Non-Terminal Spanning Tree with the restriction that each edge has a polynomially bounded integral weight. We also show that Minimum Weight Non-Terminal Spanning Tree is fixed-parameter tractable parameterized by the number of edges in the subgraph induced by the non-terminal set $V_{\rm NT}$, extending the fixed-parameter tractability of Minimum Weight Non-Terminal Spanning Tree to the general case. Finally, we give several results for structural parameterization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05494v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tesshu Hanaka, Yasuaki Kobayashi</dc:creator>
    </item>
    <item>
      <title>Counting on General Run-Length Grammars</title>
      <link>https://arxiv.org/abs/2406.00221</link>
      <description>arXiv:2406.00221v4 Announce Type: replace 
Abstract: We introduce a data structure for counting pattern occurrences in texts compressed with any run-length context-free grammar. Our structure uses space proportional to the grammar size and counts the occurrences of a pattern of length $m$ in a text of length $n$ in time \(O(m\log^{2+\epsilon} n)\), for any constant \(\epsilon &gt; 0\) chosen at indexing time. This is the first solution to an open problem posed by Christiansen et al.~[ACM TALG 2020] and enhances our abilities for computation over compressed data; we give an example application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.00221v4</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gonzalo Navarro, Alejandro Pacheco</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for (1,2)-TSP and Max-TSP Using Path Covers in the Semi-Streaming Model</title>
      <link>https://arxiv.org/abs/2501.04813</link>
      <description>arXiv:2501.04813v2 Announce Type: replace 
Abstract: We investigate semi-streaming algorithms for the Traveling Salesman Problem (TSP). Specifically, we focus on a variant known as the $(1,2)$-TSP, where the distances between any two vertices are either one or two. Our primary emphasis is on the closely related Maximum Path Cover Problem, which aims to find a collection of vertex-disjoint paths that cover the maximum number of edges in a graph. We propose an algorithm that, for any $\epsilon &gt; 0$, achieves a $(\frac{2}{3}-\epsilon)$-approximation of the maximum path cover size for an $n$-vertex graph, using $\text{poly}(\frac{1}{\epsilon})$ passes. This result improves upon the previous $\frac{1}{2}$-approximation by Behnezhad et al. [ICALP 2024] in the semi-streaming model. Building on this result, we design a semi-streaming algorithm that constructs a tour for an instance of $(1,2)$-TSP with an approximation factor of $(\frac{4}{3} + \epsilon)$, improving upon the previous $\frac{3}{2}$-approximation actor algorithm by Behnezhad et al. [ICALP 2024] (Although it is not explicitly stated in the paper that their algorithm works in the semi-streaming model, it is easy to verify). Furthermore, we extend our approach to develop an approximation algorithm for the Maximum TSP (Max-TSP), where the goal is to find a Hamiltonian cycle with the maximum possible weight in a given weighted graph $G$. Our algorithm provides a $(\frac{7}{12} - \epsilon)$-approximation for Max-TSP in $\text{poly}(\frac{1}{\epsilon})$ passes, improving on the previously known $(\frac{1}{2}-\epsilon)$-approximation obtained via maximum weight matching in the semi-streaming model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.04813v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sharareh Alipour, Ermiya Farokhnejad, Tobias M\"omke</dc:creator>
    </item>
    <item>
      <title>An Efficient Algorithm for Permutation Iteration Using a Singly Linked List</title>
      <link>https://arxiv.org/abs/2501.10102</link>
      <description>arXiv:2501.10102v5 Announce Type: replace 
Abstract: We present a new algorithm for iterating over all permutations of a sequence. The algorithm leverages elementary $O(1)$ operations on recursive lists. As a result, no new nodes are allocated during the computation. Instead, all elements are rearranged within the original nodes of the singly linked list throughout the process. While permutations are generated in an unusual order, the transitions between consecutive permutations remain smooth. A proof of concept written in the Lisp programming language is proposed and discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.10102v5</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Thomas Baruchel</dc:creator>
    </item>
    <item>
      <title>The 2020 United States Decennial Census Is More Private Than You (Might) Think</title>
      <link>https://arxiv.org/abs/2410.09296</link>
      <description>arXiv:2410.09296v2 Announce Type: replace-cross 
Abstract: The U.S. Decennial Census serves as the foundation for many high-profile policy decision-making processes, including federal funding allocation and redistricting. In 2020, the Census Bureau adopted differential privacy to protect the confidentiality of individual responses through a disclosure avoidance system that injects noise into census data tabulations. The Bureau subsequently posed an open question: Could stronger privacy guarantees be obtained for the 2020 U.S. Census compared to their published guarantees, or equivalently, had the privacy budgets been fully utilized?
  In this paper, we address this question affirmatively by demonstrating that the 2020 U.S. Census provides significantly stronger privacy protections than its nominal guarantees suggest at each of the eight geographical levels, from the national level down to the block level. This finding is enabled by our precise tracking of privacy losses using $f$-differential privacy, applied to the composition of private queries across these geographical levels. Our analysis reveals that the Census Bureau introduced unnecessarily high levels of noise to meet the specified privacy guarantees for the 2020 Census. Consequently, we show that noise variances could be reduced by $15.08\%$ to $24.82\%$ while maintaining nearly the same level of privacy protection for each geographical level, thereby improving the accuracy of privatized census statistics. We empirically demonstrate that reducing noise injection into census statistics mitigates distortion caused by privacy constraints in downstream applications of private census data, illustrated through a study examining the relationship between earnings and education.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.09296v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>stat.AP</category>
      <category>stat.ML</category>
      <pubDate>Thu, 30 Jan 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Buxin Su, Weijie J. Su, Chendi Wang</dc:creator>
    </item>
  </channel>
</rss>
