<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.OT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.OT</link>
    <description>stat.OT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.OT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 16 May 2024 10:10:02 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 16 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>What's So Hard about the Monty Hall Problem?</title>
      <link>https://arxiv.org/abs/2405.00884</link>
      <description>arXiv:2405.00884v2 Announce Type: replace 
Abstract: The Monty Hall problem is notorious for its deceptive simplicity. Although today it is widely used as a provocative thought experiment to introduce Bayesian thinking to students of probability, in the not so distant past it was rejected by established mathematicians. This essay provides some historical background to the problem and explains why it is considered so counter-intuitive to many. It is argued that the main barrier to understanding the problem is the back-grounding of the concept of dependence in probability theory as it is commonly taught. To demonstrate this, a Bayesian solution is provided and augmented with a probabilistic graphical model (PGM) inspired by the work of Pearl (1988, 1998). Although the Bayesian approach produces the correct answer, without a representation of the dependency structure of events implied by the problem, the salient fact that motivates the problem's solution remains hidden.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00884v2</guid>
      <category>stat.OT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rafael C. Alvarado</dc:creator>
    </item>
    <item>
      <title>A review of regularised estimation methods and cross-validation in spatiotemporal statistics</title>
      <link>https://arxiv.org/abs/2402.00183</link>
      <description>arXiv:2402.00183v2 Announce Type: replace-cross 
Abstract: This review article focuses on regularised estimation procedures applicable to geostatistical and spatial econometric models. These methods are particularly relevant in the case of big geospatial data for dimensionality reduction or model selection. To structure the review, we initially consider the most general case of multivariate spatiotemporal processes (i.e., $g &gt; 1$ dimensions of the spatial domain, a one-dimensional temporal domain, and $q \geq 1$ random variables). Then, the idea of regularised/penalised estimation procedures and different choices of shrinkage targets are discussed. Finally, guided by the elements of a mixed-effects model setup, which allows for a variety of spatiotemporal models, we show different regularisation procedures and how they can be used for the analysis of geo-referenced data, e.g. for selection of relevant regressors, dimensionality reduction of the covariance matrices, detection of conditionally independent locations, or the estimation of a full spatial interaction matrix.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.00183v2</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.OT</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Otto, Alessandro Fass\`o, Paolo Maranzano</dc:creator>
    </item>
  </channel>
</rss>
