<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 01 Aug 2024 01:39:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 31 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Anomaly Detection Based on Machine Learning for the CMS Electromagnetic Calorimeter Online Data Quality Monitoring</title>
      <link>https://arxiv.org/abs/2407.20278</link>
      <description>arXiv:2407.20278v1 Announce Type: cross 
Abstract: A real-time autoencoder-based anomaly detection system using semi-supervised machine learning has been developed for the online Data Quality Monitoring system of the electromagnetic calorimeter of the CMS detector at the CERN LHC. A novel method is introduced which maximizes the anomaly detection performance by exploiting the time-dependent evolution of anomalies as well as spatial variations in the detector response. The autoencoder-based system is able to efficiently detect anomalies, while maintaining a very low false discovery rate. The performance of the system is validated with anomalies found in 2018 and 2022 LHC collision data. Additionally, the first results from deploying the autoencoder-based system in the CMS online Data Quality Monitoring workflow during the beginning of Run 3 of the LHC are presented, showing its ability to detect issues missed by the existing system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20278v1</guid>
      <category>physics.ins-det</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abhirami Harilal (On behalf of the CMS Collaboration), Kyungmin Park (On behalf of the CMS Collaboration), Manfred Paulini (On behalf of the CMS Collaboration)</dc:creator>
    </item>
    <item>
      <title>An Assessment of Commonly Used Equivalent Circuit Models for Corrosion Analysis: A Bayesian Approach to Electrochemical Impedance Spectroscopy</title>
      <link>https://arxiv.org/abs/2407.20297</link>
      <description>arXiv:2407.20297v1 Announce Type: cross 
Abstract: Electrochemical Impedance Spectroscopy (EIS) is a crucial technique for assessing corrosion of a metallic materials. The analysis of EIS hinges on the selection of an appropriate equivalent circuit model (ECM) that accurately characterizes the system under study. In this work, we systematically examined the applicability of three commonly used ECMs across several typical material degradation scenarios. By applying Bayesian Inference to simulated corrosion EIS data, we assessed the suitability of these ECMs under different corrosion conditions and identified regions where the EIS data lacks sufficient information to statistically substantiate the ECM structure. Additionally, we posit that the traditional approach to EIS analysis, which often requires measurements to very low frequencies, might not be always necessary to correctly model the appropriate ECM. Our study assesses the impact of omitting data from low to medium-frequency ranges on inference results and reveals that a significant portion of low-frequency measurements can be excluded without substantially compromising the accuracy of extracting system parameters. Further, we propose simple checks to the posterior distributions of the ECM components and posterior predictions, which can be used to quantitatively evaluate the suitability of a particular ECM and the minimum frequency required to be measured. This framework points to a pathway for expediting EIS acquisition by intelligently reducing low-frequency data collection and permitting on-the-fly EIS measurements</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20297v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Runze Zhang, Debashish Sur, Kangming Li, Julia Witt, Robert Black, Alexander Whittingham, John R. Scully, Jason Hattrick-Simpers</dc:creator>
    </item>
    <item>
      <title>Universal New Physics Latent Space</title>
      <link>https://arxiv.org/abs/2407.20315</link>
      <description>arXiv:2407.20315v1 Announce Type: cross 
Abstract: We develop a machine learning method for mapping data originating from both Standard Model processes and various theories beyond the Standard Model into a unified representation (latent) space while conserving information about the relationship between the underlying theories. We apply our method to three examples of new physics at the LHC of increasing complexity, showing that models can be clustered according to their LHC phenomenology: different models are mapped to distinct regions in latent space, while indistinguishable models are mapped to the same region. This opens interesting new avenues on several fronts, such as model discrimination, selection of representative benchmark scenarios, and identifying gaps in the coverage of model space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20315v1</guid>
      <category>hep-ph</category>
      <category>cs.LG</category>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anna Hallin, Gregor Kasieczka, Sabine Kraml, Andr\'e Lessa, Louis Moureaux, Tore von Schwartz, David Shih</dc:creator>
    </item>
    <item>
      <title>Homomorphic data compression for real time photon correlation analysis</title>
      <link>https://arxiv.org/abs/2407.20356</link>
      <description>arXiv:2407.20356v1 Announce Type: cross 
Abstract: The construction of highly coherent x-ray sources has enabled new research opportunities across the scientific landscape. The maximum raw data rate per beamline now exceeds 40 GB/s, posing unprecedented challenges for the online processing and offline storage of the big data. Such challenge is particularly prominent for x-ray photon correlation spectroscopy (XPCS), where real time analyses require simultaneous calculation on all the previously acquired data in the time series. We present a homomorphic compression scheme to effectively reduce the computational time and memory space required for XPCS analysis. Leveraging similarities in the mathematical expression between a matrix-based compression algorithm and the correlation calculation, our approach allows direct operation on the compressed data without their decompression. The lossy compression reduces the computational time by a factor of 10,000, enabling real time calculation of the correlation functions at kHz framerate. Our demonstration of a homomorphic compression of scientific data provides an effective solution to the big data challenge at coherent light sources. Beyond the example shown in this work, the framework can be extended to facilitate real-time operations directly on a compressed data stream for other techniques.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20356v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sebastian Strempfer, Zichao Wendy Di, Kazutomo Yoshii, Yue Cao, Qingteng Zhang, Eric M. Dufresne, Mathew Cherukara, Suresh Narayanan, Martin V. Holt, Antonino Miceli, Tao Zhou</dc:creator>
    </item>
    <item>
      <title>GPU-based data processing for speeding-up correlation plenoptic imaging</title>
      <link>https://arxiv.org/abs/2407.20692</link>
      <description>arXiv:2407.20692v1 Announce Type: cross 
Abstract: Correlation Plenoptic Imaging (CPI) is a novel technological imaging modality enabling to overcome drawbacks of standard plenoptic devices, while preserving their advantages. However, a major challenge in view of real-time application of CPI is related with the relevant amount of required frames and the consequent computational-intensive processing algorithm. In this work, we describe the design and implementation of an optimized processing algorithm that is portable to an efficient computational environment and exploits the highly parallel algorithm offered by GPUs. Improvements by a factor ranging from 20x, for correlation measurement, to 500x, for refocusing, are demonstrated. Exploration of the relation between the improvement in performance achieved and actual GPU capabilities, also indicates the feasibility of near-real time processing capability, opening up to the potential use of CPI for practical real-time application.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20692v1</guid>
      <category>eess.IV</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francesca Santoro, Isabella Petrelli, Gianlorenzo Massaro, George Filios, Francesco V. Pepe, Leonardo Amoruso, Maria Ieronimaki, Samuel Burri, Edoardo Charbon, Paul Mos, Arin Ulku, Michael Wayne, Cristoforo Abbattista, Claudio Bruschini, Milena D'Angelo</dc:creator>
    </item>
    <item>
      <title>Detecting Causality in the Frequency Domain with Cross-Mapping Coherence</title>
      <link>https://arxiv.org/abs/2407.20694</link>
      <description>arXiv:2407.20694v1 Announce Type: cross 
Abstract: Understanding causal relationships within a system is crucial for uncovering its underlying mechanisms. Causal discovery methods, which facilitate the construction of such models from time-series data, hold the potential to significantly advance scientific and engineering fields.
  This study introduces the Cross-Mapping Coherence (CMC) method, designed to reveal causal connections in the frequency domain between time series. CMC builds upon nonlinear state-space reconstruction and extends the Convergent Cross-Mapping algorithm to the frequency domain by utilizing coherence metrics for evaluation. We tested the Cross-Mapping Coherence method using simulations of logistic maps, Lorenz systems, Kuramoto oscillators, and the Wilson-Cowan model of the visual cortex. CMC accurately identified the direction of causal connections in all simulated scenarios. When applied to the Wilson-Cowan model, CMC yielded consistent results similar to spectral Granger causality.
  Furthermore, CMC exhibits high sensitivity in detecting weak connections, demonstrates sample efficiency, and maintains robustness in the presence of noise.
  In conclusion, the capability to determine directed causal influences across different frequency bands allows CMC to provide valuable insights into the dynamics of complex, nonlinear systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20694v1</guid>
      <category>cs.LG</category>
      <category>nlin.CD</category>
      <category>physics.data-an</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zsigmond Benk\H{o}, B\'alint Varga, Marcell Stippinger, Zolt\'an Somogyv\'ari</dc:creator>
    </item>
    <item>
      <title>Integrating audiological datasets via federated merging of Auditory Profiles</title>
      <link>https://arxiv.org/abs/2407.20765</link>
      <description>arXiv:2407.20765v1 Announce Type: cross 
Abstract: Audiological datasets contain valuable knowledge about hearing loss in patients, which can be uncovered using data-driven, federated learning techniques. Our previous approach summarized patient information from one audiological dataset into distinct Auditory Profiles (APs). To cover the complete audiological patient population, however, patient patterns must be analyzed across multiple, separated datasets, and finally, be integrated into a combined set of APs. This study aimed at extending the existing profile generation pipeline with an AP merging step, enabling the combination of APs from different datasets based on their similarity across audiological measures. The 13 previously generated APs (NA=595) were merged with 31 newly generated APs from a second dataset (NB=1272) using a similarity score derived from the overlapping densities of common features across the two datasets. To ensure clinical applicability, random forest models were created for various scenarios, encompassing different combinations of audiological measures. A new set with 13 combined APs is proposed, providing well-separable profiles, which still capture detailed patient information from various test outcome combinations. The classification performance across these profiles is satisfactory. The best performance was achieved using a combination of loudness scaling, audiogram and speech test information, while single measures performed worst. The enhanced profile generation pipeline demonstrates the feasibility of combining APs across datasets, which should generalize to all datasets and could lead to an interpretable population-based profile set in the future. The classification models maintain clinical applicability. Hence, even if only smartphone-based measures are available, a given patient can be classified into an appropriate AP.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20765v1</guid>
      <category>physics.med-ph</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samira Saak, Dirk Oetting, Birger Kollmeier, Mareike Buhl</dc:creator>
    </item>
    <item>
      <title>Automated Review Generation Method Based on Large Language Models</title>
      <link>https://arxiv.org/abs/2407.20906</link>
      <description>arXiv:2407.20906v1 Announce Type: cross 
Abstract: Literature research, vital for scientific advancement, is overwhelmed by the vast ocean of available information. Addressing this, we propose an automated review generation method based on Large Language Models (LLMs) to streamline literature processing and reduce cognitive load. In case study on propane dehydrogenation (PDH) catalysts, our method swiftly generated comprehensive reviews from 343 articles, averaging seconds per article per LLM account. Extended analysis of 1041 articles provided deep insights into catalysts' composition, structure, and performance. Recognizing LLMs' hallucinations, we employed a multi-layered quality control strategy, ensuring our method's reliability and effective hallucination mitigation. Expert verification confirms the accuracy and citation integrity of generated reviews, demonstrating LLM hallucination risks reduced to below 0.5% with over 95% confidence. Released Windows application enables one-click review generation, aiding researchers in tracking advancements and recommending literature. This approach showcases LLMs' role in enhancing scientific research productivity and sets the stage for further exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.20906v1</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shican Wu, Xiao Ma, Dehui Luo, Lulu Li, Xiangcheng Shi, Xin Chang, Xiaoyun Lin, Ran Luo, Chunlei Pei, Zhi-Jian Zhao, Jinlong Gong</dc:creator>
    </item>
    <item>
      <title>Bayesian technique to combine independently-trained Machine-Learning models applied to direct dark matter detection</title>
      <link>https://arxiv.org/abs/2407.21008</link>
      <description>arXiv:2407.21008v1 Announce Type: cross 
Abstract: We carry out a Bayesian analysis of dark matter (DM) direct detection data to determine particle model parameters using the Truncated Marginal Neural Ratio Estimation (TMNRE) machine learning technique. TMNRE avoids an explicit calculation of the likelihood, which instead is estimated from simulated data, unlike in traditional Markov Chain Monte Carlo (MCMC) algorithms. This considerably speeds up, by several orders of magnitude, the computation of the posterior distributions, which allows to perform the Bayesian analysis of an otherwise computationally prohibitive number of benchmark points. In this article we demonstrate that, in the TMNRE framework, it is possible to include, combine, and remove different datasets in a modular fashion, which is fast and simple as there is no need to re-train the machine learning algorithm or to define a combined likelihood. In order to assess the performance of this method, we consider the case of WIMP DM with spin-dependent and independent interactions with protons and neutrons in a xenon experiment. After validating our results with MCMC, we employ the TMNRE procedure to determine the regions where the DM parameters can be reconstructed. Finally, we present CADDENA, a Python package that implements the modular Bayesian analysis of direct detection experiments described in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.21008v1</guid>
      <category>hep-ph</category>
      <category>astro-ph.CO</category>
      <category>physics.data-an</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Cerdeno, Martin de los Rios, Andres D. Perez</dc:creator>
    </item>
  </channel>
</rss>
