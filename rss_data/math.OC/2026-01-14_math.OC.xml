<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 14 Jan 2026 05:00:24 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Convergence of a Multi-Inertial-Iteration Scheme in Cone b, p-Normed Banach Spaces</title>
      <link>https://arxiv.org/abs/2601.07837</link>
      <description>arXiv:2601.07837v1 Announce Type: new 
Abstract: We propose and analyze a multi-inertial-iteration scheme in cone b, p-normed Banach spaces. This framework extends the classical Krasnoselskii-Mann and two-step inertial iterations by incorporating three independent inertial parameters and multiple error-control sequences. Under mild assumptions such as quasi-nonexpansiveness, weak contraction, and compatibility of mappings, we establish convergence theorems guaranteeing the existence and uniqueness of fixed points. Illustrative numerical examples demonstrate accelerated convergence compared with the classical Krasnoselskii-Mann method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07837v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Elvin Rada</dc:creator>
    </item>
    <item>
      <title>Dual characterizations of norm minimization problems</title>
      <link>https://arxiv.org/abs/2601.08153</link>
      <description>arXiv:2601.08153v1 Announce Type: new 
Abstract: The paper studies a general norm minimization problem on a product of normed vector spaces. We establish dual necessary and sufficient optimality conditions and derive explicit formulas for the corresponding solution sets. These formulas are obtained under the assumption that one optimal solution together with its associated dual vectors arising from the optimality conditions is known. Three important cases of product norms, namely the sum norm, maximum norm and $p$-norm, are also studied. Several examples in finite and infinite dimensional spaces equipped with various types of norms are presented to illustrate the established results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08153v1</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nguyen Duy Cuong</dc:creator>
    </item>
    <item>
      <title>Stratification for Nonlinear Semidefinite Programming</title>
      <link>https://arxiv.org/abs/2601.08362</link>
      <description>arXiv:2601.08362v1 Announce Type: new 
Abstract: This paper introduces a stratification framework for nonlinear semidefinite programming (NLSDP) that reveals and utilizes the geometry behind the nonsmooth KKT system. Based on the \emph{index stratification} of $\mathbb{S}^n$ and its lift to the primal--dual space, a stratified variational analysis is developed. Specifically, we define the stratum-restricted regularity property, characterize it by the verifiable weak second order condition (W-SOC) and weak strict Robinson constraint qualification (W-SRCQ), and interpret the W-SRCQ geometrically via transversality, which provides its genericity over ambient space and stability along strata. The interactions of these properties across neighboring strata are further examined, leading to the conclusion that classical strong-form regularity conditions correspond to the local uniform validity of stratum-restricted counterparts. On the algorithmic side, a stratified Gauss--Newton method with normal steps and a correction mechanism is proposed for globally solving the KKT equation through a least-squares merit function. We demonstrate that the algorithm converges globally to directional stationary points. Moreover, under the W-SOC and the strict Robinson constraint qualification (SRCQ), it achieves local quadratic convergence to KKT pairs and eventually identifies the active stratum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08362v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenglong Bao, Chao Ding, Fuxiaoyue Feng, Jingyu Li</dc:creator>
    </item>
    <item>
      <title>Kantorovich Distance via Spanning Trees: Properties and Algorithms</title>
      <link>https://arxiv.org/abs/2601.08396</link>
      <description>arXiv:2601.08396v1 Announce Type: new 
Abstract: We study optimal transport between probability measures supported on the same finite metric space, where the ground cost is a distance induced by a weighted connected graph. Building on recent work showing that the resulting Kantorovich distance can be expressed as a minimization problem over the set of spanning trees of this underlying graph, we investigate the implications of this reformulation on the construction of an optimal transport plan and a dual potential based on the solution of such an optimization problem. In this setting, we derive an explicit formula for the Kantorovich potential in terms of the imbalanced cumulative mass (a generalization of the cumulative distribution in R) along an optimal spanning tree solving such a minimization problem, under a weak non-degeneracy condition on the pair of measures that guarantees the uniqueness of a dual potential. Our second contribution establishes the existence of an optimal transport plan that can be computed efficiently by a dynamic programming procedure once an optimal spanning tree is known. Finally, we propose a stochastic algorithm based on simulated annealing on the space of spanning trees to compute such an optimal spanning tree. Numerical experiments illustrate the theoretical results and demonstrate the practical relevance of the proposed approach for optimal transport on finite metric spaces.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08396v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J\'er\'emie Bigot, Luis Fredes</dc:creator>
    </item>
    <item>
      <title>Two-Product Make-to-Stock System: Strategic Joining and Optimal Inventory Levels</title>
      <link>https://arxiv.org/abs/2601.08426</link>
      <description>arXiv:2601.08426v1 Announce Type: new 
Abstract: This paper analyzes a two-product make-to-stock queueing system where a single production facility serves two customer classes with independent Poisson arrivals. Customers make strategic join-or-balk decisions without observing current inventory levels. The analysis establishes the existence and uniqueness of Nash equilibria in customer joining strategies for various inventory scenarios. Optimal base-stock levels are characterized from both profit-maximizing and welfare-maximizing perspectives, with closed-form expressions for key performance measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08426v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Odysseas Kanavetas, Ekaterina Kosarevskaia</dc:creator>
    </item>
    <item>
      <title>Exploring an Alternative Line-Search Method for Lagrange-Newton Optimization</title>
      <link>https://arxiv.org/abs/2601.08431</link>
      <description>arXiv:2601.08431v1 Announce Type: new 
Abstract: In the Lagrange-Newton method, where Newton's method is applied to a Lagrangian function that includes equality constraints, all stationary points are saddle points. It is therefore not possible to use a line-search method based on the value of the objective function; instead, the line search can operate on merit functions. In this report, we explore an alternative line-search method which is applicable to this case; it particulary addresses the damping of the step length in tight valleys. We propose a line-search criterion based on the divergence of the field of Newton step vectors. The visualization of the criterion for two-dimensional test functions reveals a network of ravines with flat bottom at the zero points of the criterion. The ravines are typically connected to stationary points. To traverse this ravine network in order to approach a stationary point, a zigzag strategy is devised. Numerical experiments demonstrate that the novel line-search strategy succeeds from most starting points in all test functions, but only exhibits the desired damping of the step length in some situations. At the present stage it is therefore difficult to appraise the utility of this contribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08431v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ralf M\"oller</dc:creator>
    </item>
    <item>
      <title>An efficient mixed-integer linear programming formulation for solving influence diagrams</title>
      <link>https://arxiv.org/abs/2601.08460</link>
      <description>arXiv:2601.08460v1 Announce Type: new 
Abstract: Influence diagrams represent decision-making problems with interdependencies between random events, decisions, and consequences. Traditionally, they have been solved using algorithms that determine the expected utility-maximizing decision strategy. In contrast, state-of-the-art solution approaches convert influence diagrams into a mixed-integer linear programming (MILP) model, which can be solved with powerful off-the-shelf MILP solvers. From a computational standpoint, the existing MILP formulations can be efficiently solved when applied to influence diagrams that represent periodic (or sequential) decision processes, which can be cast as partially observable Markov Decision Processes. However, they are inefficient in problems that lack a periodic structure or if the nodes in the influence diagram have large state spaces, thus limiting their practical use. In this paper, we present an efficient MILP formulation that is specifically designed for influence diagrams that are challenging for the earlier MILP formulation-based methods. Additionally, we present how the proposed formulation can be adapted to maximize conditional value-at-risk and how chance and logical constraints can be incorporated into the formulation, thus retaining the modeling flexibility of the MILP-based methods. Finally, we perform computational experiments addressing problems from the literature and compare the computational efficiency of the proposed formulation against the available MILP formulations for the reported influence diagrams. We find that the MILP models based on the proposed formulations can be solved significantly more efficiently compared to the state-of-the-art when solving influence diagrams that cannot be cast as partially observable Markov decision processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08460v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Topias Terho, Fabricio Oliveira, Ahti Salo, Pedro Munari</dc:creator>
    </item>
    <item>
      <title>A New Duality-Free Framework for Convex Optimisation with Superlinear Convergence and Effective Warm-Starting</title>
      <link>https://arxiv.org/abs/2601.08494</link>
      <description>arXiv:2601.08494v1 Announce Type: new 
Abstract: Modern second order solvers for convex optimisation, such as interior point methods, rely on primal dual information and are difficult to warm start, limiting their applicability in real time control. We propose the PVM, a duality free framework that reformulates the constrained problem as the unconstrained minimisation of a value function. The resulting problem always has a solution, yields a certificate of infeasibility and is amenable to warm starting. We develop a second order algorithm for Quadratic Programming based on the PPA and semismooth Newton methods, and establish sufficient conditions for superlinear convergence to an arbitrarily small neighbourhood of the solution. Numerical experiments on a MPC problem demonstrate competitive performance with state of the art solvers from a cold start and up to 70\% reduction in Newton iterations when warm starting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08494v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Michael Cummins, Eric Kerrigan</dc:creator>
    </item>
    <item>
      <title>Convergence of gradient flow for learning convolutional neural networks</title>
      <link>https://arxiv.org/abs/2601.08547</link>
      <description>arXiv:2601.08547v1 Announce Type: new 
Abstract: Convolutional neural networks are widely used in imaging and image recognition. Learning such networks from training data leads to the minimization of a non-convex function. This makes the analysis of standard optimization methods such as variants of (stochastic) gradient descent challenging. In this article we study the simplified setting of linear convolutional networks. We show that the gradient flow (to be interpreted as an abstraction of gradient descent) applied to the empirical risk defined via certain loss functions including the square loss always converges to a critical point, under a mild condition on the training data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08547v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jona-Maria Diederen, Holger Rauhut, Ulrich Terstiege</dc:creator>
    </item>
    <item>
      <title>Truncated Multidimensional Trigonometric Moment Problem: A Choice of Bases and the Unique Solution</title>
      <link>https://arxiv.org/abs/2601.08551</link>
      <description>arXiv:2601.08551v1 Announce Type: new 
Abstract: In this prelinimary version of paper, we propose to give a complete solution to the Truncated Multidimensional Trigonometric Moment Problem (TMTMP) from a system and signal processing perspective. In mathematical TMTMPs, people care about whether a solution exists for a given sequence of multidimensional trigonometric moments. The solution can have the form of an atomic measure. However, for the TMTMPs in system and signal processing, a solution as an analytic rational function, of which the numerator and the denominator are positive polynomials, is desired for the ARMA modelling of a stochastic process, which is the so-called Multidimensional Rational Covariance Extension problem (RCEP) . In the literature, the feasible domain of the TMTMPs, where the spectral density is positive, is difficult to obtain given a specific choice of basis functions, which causes severe problems in the Multidimensional RCEP. In this paper, we propose a choice of basis functions, and a corresponding estimation scheme by convex optimization, for the TMTMPs, with which the trigonometric moments of the spectral estimate are exactly the sample moments. We propose an explicit condition for the convex optimization problem for guaranteeing the positiveness of the spectral estimation. The map from the parameters of the estimate to the trigonometric moments is proved to be a diffeomorphism, which ensures the existence and uniqueness of solution. The statistical properties of the proposed spectral density estimation scheme are comprehensively proved, including the consistency, (asymptotical) unbiasedness, convergence rate and efficiency under a mild assumption. This well-posed treatment is then applied to a system identification task, and the simulation results validate our proposed treatment for the TMTMP in system and signal processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08551v1</guid>
      <category>math.OC</category>
      <category>stat.ME</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Guangyu Wu, Anders Lindquist</dc:creator>
    </item>
    <item>
      <title>Accelerated Methods with Complexity Separation Under Data Similarity for Federated Learning Problems</title>
      <link>https://arxiv.org/abs/2601.08614</link>
      <description>arXiv:2601.08614v1 Announce Type: new 
Abstract: Heterogeneity within data distribution poses a challenge in many modern federated learning tasks. We formalize it as an optimization problem involving a computationally heavy composite under data similarity. By employing different sets of assumptions, we present several approaches to develop communication-efficient methods. An optimal algorithm is proposed for the convex case. The constructed theory is validated through a series of experiments across various problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08614v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dmitry Bylinkin, Sergey Skorik, Dmitriy Bystrov, Leonid Berezin, Aram Avetisyan, Aleksandr Beznosikov</dc:creator>
    </item>
    <item>
      <title>Optimal Dirac controls for time-periodic bistable ODEs, application to population replacement</title>
      <link>https://arxiv.org/abs/2601.08630</link>
      <description>arXiv:2601.08630v1 Announce Type: new 
Abstract: This work addresses an optimal control problem on a dynamics governed by a nonlinear differential equation with a bistable time-periodic nonlinearity. This problem, relevant in population dynamics, models the strategy of replacing a population of A-type individuals by a population of B-type individuals in a time-varying environment, focusing on the evolution of the proportion of B-type individuals among the whole population. The control term accounts for the instant release of B-type individuals. Our main goal, after noting some interesting properties on the differential equation, is to determine the optimal time at which this release should be operated to ensure population replacement while minimizing the release effort. The results establish that the optimal release time appears to be the minimizer of a function involving the carrying capacity of the environment and the threshold periodic solution of the dynamics; they also describe the convergence of the whole optimal release strategy. An application to the biocontrol of mosquito populations using Wolbachia-infected individuals illustrates the relevance of the theoretical results. Wolbachia is a bacterium that helps preventing the transmission of some viruses from mosquitoes to humans, making the optimization of Wolbachia propagation in a mosquito population a crucial issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08630v1</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.CA</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gr\'egoire Nadin, David Nahmani, Nicolas Vauchelet</dc:creator>
    </item>
    <item>
      <title>The Ergodic Linear-Quadratic Optimal Control Problems with Random Periodic Coefficients</title>
      <link>https://arxiv.org/abs/2601.08672</link>
      <description>arXiv:2601.08672v1 Announce Type: new 
Abstract: In this paper, we concern with the ergodic linear-quadratic closed-loop optimal control problems with random periodic coefficients. We put forward the random periodic mean-square exponentially stable condition, and prove the random periodicity of solutions to state equation based on it. Then we prove the existence and uniqueness of random periodic solutions to two types of backward stochastic differential equations which serve as stochastic Riccati equations in the procedure of completing the square. With the random periodicity of state equation and stochastic Riccati equations, the ergodic cost functional on infinite horizon is simplified to an equivalent cost functional over a single periodic interval without limit. Finally, the closed-loop optimal controls are explicitly given based on random periodic solutions to state equation and stochastic Riccati equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08672v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiacheng Wu, Qi Zhang</dc:creator>
    </item>
    <item>
      <title>Novel Dynamical Systems with Finite-Time and Fixed-Time Stability for Generalized Inverse Mixed Variational Inequality Problems</title>
      <link>https://arxiv.org/abs/2601.08700</link>
      <description>arXiv:2601.08700v1 Announce Type: new 
Abstract: This paper investigates a class of generalized inverse mixed variational inequality problems (GIMVIPs), which consist in finding a vector $\overline{w}\in \R^d$ such that \[ F(\bar w)\in \Omega \quad \text{and} \quad \langle h(\bar w), v-F(\bar w) \rangle + g(v)-g(F(\bar w)) \ge 0, \quad \forall v\in \Omega, \] where \(h,F:\R^d\to\R^d\) are single-valued operators, \(g:\Omega\to\R\cup\{+\infty\}\) is a proper function, and \(\Omega\) is a closed convex set.
  Two novel continuous-time dynamical systems are proposed to analyze the finite-time and fixed-time stability of solutions to GIMVIPs in finite-dimensional Hilbert spaces. Under suitable assumptions on the operators and model parameters, Lyapunov-based techniques are employed to establish finite-time and fixed-time convergence of the generated trajectories.
  While both systems exhibit accelerated convergence, the settling time of the finite-time stable system depends on the initial condition, whereas the fixed-time stable system admits a uniform upper bound on the convergence time that is independent of the initial state. Moreover, an explicit forward Euler discretization of the continuous-time dynamics leads to a proximal point-type algorithm that preserves the fixed-time convergence property. Rigorous convergence analysis of the resulting iterative scheme is provided. A numerical experiment is presented to demonstrate the effectiveness of the proposed methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08700v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nam Van Tran</dc:creator>
    </item>
    <item>
      <title>Portfolio Optimization with 'Physical' Decision Variables and Non-Linear Performance Metrics: Diversification Challenge and Proposals</title>
      <link>https://arxiv.org/abs/2601.08717</link>
      <description>arXiv:2601.08717v1 Announce Type: new 
Abstract: Portfolio optimization (PO) is a core tool in financial and operational decision-making, typically balancing expected profit and risk. In real-world applications, particularly in the energy sector, decision variables can be expressed as physical quantities (e.g., production volumes), and nonlinear performance metrics such as Return on Investment (ROI) may be requested. These modeling choices introduce challenges, including the non-additivity of the objective function. This often results in highly concentrated optimized portfolios and thus limited diversification, which can be problematic for decision-makers seeking balanced investment strategies. This paper proposes two strategies to enhance diversification in ROI-based PO models, both based on the Herfindahl-Hirschman Index (HHI). The first incorporates an HHI term directly into the objective function, with its corresponding weight allowing control over diversification. The second directly maximizes diversification while controlling expected profit and risk degradation around the optimum portfolio (obtained through conventional PO). Both strategies are evaluated using synthetic data (energy assets) to illustrate their behavior and practical trade-offs. The results highlight how each method can support different decision-making needs and enhance portfolio robustness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08717v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Isabel Barros Garcia, J\'er\'emie Messud</dc:creator>
    </item>
    <item>
      <title>Riemannian optimization with finite-difference gradient approximations</title>
      <link>https://arxiv.org/abs/2601.08751</link>
      <description>arXiv:2601.08751v1 Announce Type: new 
Abstract: Derivative-free Riemannian optimization (DFRO) aims to minimize an objective function using only function evaluations, under the constraint that the decision variables lie on a Riemannian manifold. The rapid increase in problem dimensions over the years calls for computationally cheap DFRO algorithms, that is, algorithms requiring as few function evaluations and retractions as possible. We propose a novel DFRO method based on finite-difference gradient approximations that relies on an adaptive selection of the finite-difference accuracy and stepsize that is novel even in the Euclidean setting. When endowed with an intrinsic finite-difference scheme, that measures variations of the objective in tangent directions using retractions, our proposed method requires $O(d\epsilon^{-2})$ function evaluations and retractions to find an $\epsilon$-critical point, where $d$ is the manifold dimension. We then propose a variant of our method when the search space is a Riemannian submanifold of an $n$-dimensional Euclidean space. This variant relies on an extrinsic finite-difference scheme, approximating the Riemannian gradient directly in the embedding space, assuming that the objective function can be evaluated outside of the manifold. This approach leads to worst-case complexity bounds of $O(d\epsilon^{-2})$ function evaluations and $O(\epsilon^{-2})$ retractions. We also present numerical results showing that the proposed methods achieve superior performance over existing derivative-free methods on various problems in both Euclidean and Riemannian settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08751v1</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timoth\'e Taminiau, Estelle Massart, Geovani Nunes Grapiglia</dc:creator>
    </item>
    <item>
      <title>Grid-Aware Charging and Operational Optimization for Mixed-Fleet Public Transit</title>
      <link>https://arxiv.org/abs/2601.08753</link>
      <description>arXiv:2601.08753v1 Announce Type: new 
Abstract: The rapid growth of urban populations and the increasing need for sustainable transportation solutions have prompted a shift towards electric buses in public transit systems. However, the effective management of mixed fleets consisting of both electric and diesel buses poses significant operational challenges. One major challenge is coping with dynamic electricity pricing, where charging costs vary throughout the day. Transit agencies must optimize charging assignments in response to such dynamism while accounting for secondary considerations such as seating constraints. This paper presents a comprehensive mixed-integer linear programming (MILP) model to address these challenges by jointly optimizing charging schedules and trip assignments for mixed (electric and diesel bus) fleets while considering factors such as dynamic electricity pricing, vehicle capacity, and route constraints. We address the potential computational intractability of the MILP formulation, which can arise even with relatively small fleets, by employing a hierarchical approach tailored to the fleet composition. By using real-world data from the city of Chattanooga, Tennessee, USA, we show that our approach can result in significant savings in the operating costs of the mixed transit fleets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08753v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/ITSC58415.2024.10920218</arxiv:DOI>
      <arxiv:journal_reference>2024 IEEE 27th International Conference on Intelligent Transportation Systems (ITSC), 2024</arxiv:journal_reference>
      <dc:creator>Rishav Sen, Amutheezan Sivagnanam, Aron Laszka, Ayan Mukhopadhyay, Abhishek Dubey</dc:creator>
    </item>
    <item>
      <title>NOVAK: Unified adaptive optimizer for deep neural networks</title>
      <link>https://arxiv.org/abs/2601.07876</link>
      <description>arXiv:2601.07876v1 Announce Type: cross 
Abstract: This work introduces NOVAK, a modular gradient-based optimization algorithm that integrates adaptive moment estimation, rectified learning-rate scheduling, decoupled weight regularization, multiple variants of Nesterov momentum, and lookahead synchronization into a unified, performance-oriented framework. NOVAK adopts a dual-mode architecture consisting of a streamlined fast path designed for production. The optimizer employs custom CUDA kernels that deliver substantial speedups (3-5 for critical operations) while preserving numerical stability under standard stochastic-optimization assumptions. We provide fully developed mathematical formulations for rectified adaptive learning rates, a memory-efficient lookahead mechanism that reduces overhead from O(2p) to O(p + p/k), and the synergistic coupling of complementary optimization components. Theoretical analysis establishes convergence guarantees and elucidates the stability and variance-reduction properties of the method. Extensive empirical evaluation on CIFAR-10, CIFAR-100, ImageNet, and ImageNette demonstrates NOVAK superiority over 14 contemporary optimizers, including Adam, AdamW, RAdam, Lion, and Adan. Across architectures such as ResNet-50, VGG-16, and ViT, NOVAK consistently achieves state-of-the-art accuracy, and exceptional robustness, attaining very high accuracy on VGG-16/ImageNette demonstrating superior architectural robustness compared to contemporary optimizers. The results highlight that NOVAKs architectural contributions (particularly rectification, decoupled decay, and hybrid momentum) are crucial for reliable training of deep plain networks lacking skip connections, addressing a long-standing limitation of existing adaptive optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07876v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergii Kavun</dc:creator>
    </item>
    <item>
      <title>Human as an Actuator Dynamic Model Identification</title>
      <link>https://arxiv.org/abs/2601.07956</link>
      <description>arXiv:2601.07956v1 Announce Type: cross 
Abstract: This paper presents a method for estimating parameters that form a general model for human pilot response for specific tasks. The human model is essential for the dynamic analysis of piloted vehicles. Data are generated on a simulator with multiple trials being incorporated to find the single model that best describes the data. The model is found entirely in the time domain by constructing a constrained optimization problem. This optimization problem implicitly represents the state of the underlying system, making it robust to natural variation in human responses. It is demonstrated by estimating the human response model for a position control task with a quadcopter drone.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.07956v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harrison M. Bonner, Matthew R. Kirchner</dc:creator>
    </item>
    <item>
      <title>Riemannian Zeroth-Order Gradient Estimation with Structure-Preserving Metrics for Geodesically Incomplete Manifolds</title>
      <link>https://arxiv.org/abs/2601.08039</link>
      <description>arXiv:2601.08039v1 Announce Type: cross 
Abstract: In this paper, we study Riemannian zeroth-order optimization in settings where the underlying Riemannian metric $g$ is geodesically incomplete, and the goal is to approximate stationary points with respect to this incomplete metric. To address this challenge, we construct structure-preserving metrics that are geodesically complete while ensuring that every stationary point under the new metric remains stationary under the original one. Building on this foundation, we revisit the classical symmetric two-point zeroth-order estimator and analyze its mean-squared error from a purely intrinsic perspective, depending only on the manifold's geometry rather than any ambient embedding. Leveraging this intrinsic analysis, we establish convergence guarantees for stochastic gradient descent with this intrinsic estimator. Under additional suitable conditions, an $\epsilon$-stationary point under the constructed metric $g'$ also corresponds to an $\epsilon$-stationary point under the original metric $g$, thereby matching the best-known complexity in the geodesically complete setting. Empirical studies on synthetic problems confirm our theoretical findings, and experiments on a practical mesh optimization task demonstrate that our framework maintains stable convergence even in the absence of geodesic completeness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08039v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shaocong Ma, Heng Huang</dc:creator>
    </item>
    <item>
      <title>Efficient Incremental SLAM via Information-Guided and Selective Optimization</title>
      <link>https://arxiv.org/abs/2601.08110</link>
      <description>arXiv:2601.08110v1 Announce Type: cross 
Abstract: We present an efficient incremental SLAM back-end that achieves the accuracy of full batch optimization while substantially reducing computational cost. The proposed approach combines two complementary ideas: information-guided gating (IGG) and selective partial optimization (SPO). IGG employs an information-theoretic criterion based on the log-determinant of the information matrix to quantify the contribution of new measurements, triggering global optimization only when a significant information gain is observed. This avoids unnecessary relinearization and factorization when incoming data provide little additional information. SPO executes multi-iteration Gauss-Newton (GN) updates but restricts each iteration to the subset of variables most affected by the new measurements, dynamically refining this active set until convergence. Together, these mechanisms retain all measurements to preserve global consistency while focusing computation on parts of the graph where it yields the greatest benefit. We provide theoretical analysis showing that the proposed approach maintains the convergence guarantees of full GN. Extensive experiments on benchmark SLAM datasets show that our approach consistently matches the estimation accuracy of batch solvers, while achieving significant computational savings compared to conventional incremental approaches. The results indicate that the proposed approach offers a principled balance between accuracy and efficiency, making it a robust and scalable solution for real-time operation in dynamic data-rich environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08110v1</guid>
      <category>cs.RO</category>
      <category>cs.IT</category>
      <category>cs.SY</category>
      <category>eess.SP</category>
      <category>eess.SY</category>
      <category>math.IT</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Reza Arablouei</dc:creator>
    </item>
    <item>
      <title>Optimization of maximal quantum f-divergences between unitary orbits</title>
      <link>https://arxiv.org/abs/2601.08268</link>
      <description>arXiv:2601.08268v1 Announce Type: cross 
Abstract: Maximal quantum $f$-divergences - defined via the commutant Radon-Nikodym derivative provide a fundamental measure of distinguishability between quantum states in the operator convex setting. In this work, we determine the exact extremal values of these divergences over the unitary orbits of two quantum states. Using the integral representation of operator convex functions, majorization theory, Lidskii-type inequalities, and structural properties of Kubo-Ando means, we derive fully explicit spectral formulas for \[ \min_{U\in \mathbb U_n} \tilde S_f(\rho\|U^{*}\sigma U) \quad\text{and}\quad \max_{U\in \mathbb U_n} \tilde S_f(\rho\|U^{*}\sigma U), \] and identify the unitaries achieving these extrema. We show that the optimization reduces to spectral rearrangement: the minimum occurs when the decreasing eigenvalues of $\rho$ and $\sigma$ are paired, while the maximum corresponds to pairing the decreasing eigenvalues of $\rho$ with the increasing spectrum of $\sigma$. Consequently, the full range of the divergence along the unitary orbit is exactly the closed interval between these two endpoints. We further compare our results with the recent unitary optimization framework for hockey-stick-based quantum $f$-divergences of Li and Yan (2025), highlighting fundamental structural differences between the two families. Our findings extend prior extremal analyses for Umegaki, R\'enyi, and Hellinger-type divergences, and illuminate the distinct noncommutative nature of maximal quantum $f$-divergences.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08268v1</guid>
      <category>math.QA</category>
      <category>math.FA</category>
      <category>math.OC</category>
      <category>math.SP</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hoang Minh Nguyen, Hoang An Nguyen, Cong Trinh Le</dc:creator>
    </item>
    <item>
      <title>Minimal Actuator Selection</title>
      <link>https://arxiv.org/abs/2601.08338</link>
      <description>arXiv:2601.08338v1 Announce Type: cross 
Abstract: Selecting a few available actuators to ensure the controllability of a linear system is a fundamental problem in control theory. Previous works either focus on optimal performance, simplifying the controllability issue, or make the system controllable under structural assumptions, such as in graphs or when the input matrix is a design parameter. We generalize these approaches to offer a precise characterization of the general minimal actuator selection problem where a set of actuators is given, described by a fixed input matrix, and goal is to choose the fewest actuators that make the system controllable. We show that this problem can be equivalently cast as an integer linear program and, if actuation channels are sufficiently independent, as a set multicover problem under multiplicity constraints. The latter equivalence is always true if the state matrix has all distinct eigenvalues, in which case it simplifies to the set cover problem. Such characterizations hold even when a robust selection that tolerates a given number of faulty actuators is desired. Our established connection legitimates a designer to use algorithms from the rich literature on the set multicover problem to select the smallest subset of actuators, including exact solutions that do not require brute-force search.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08338v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Ballotta, Geethu Joseph</dc:creator>
    </item>
    <item>
      <title>Determining the Winner in Alternating-Move Games</title>
      <link>https://arxiv.org/abs/2601.08359</link>
      <description>arXiv:2601.08359v1 Announce Type: cross 
Abstract: We provide a criterion for determining the winner in two-player win-lose alternating-move games on trees, in terms of the Hausdorff dimension of the target set. We focus our study on special cases, including the Gale-Stewart game on the complete binary tree and a family of Schmidt games. Building on the Hausdorff dimension games originally introduced by Das, Fishman, Simmons, and Urba{\'n}ski, which provide a game-theoretic approach for computing Hausdorff dimensions, we employ a generalized family of these games, and show that they are useful for analyzing sets underlying the win-lose games we study.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08359v1</guid>
      <category>math.DS</category>
      <category>cs.GT</category>
      <category>math.LO</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Itamar Bella\"iche, Auriel Rosenzweig</dc:creator>
    </item>
    <item>
      <title>Data-Driven Time-Limited h2 Optimal Model Reduction for Linear Discrete-Time Systems</title>
      <link>https://arxiv.org/abs/2601.08372</link>
      <description>arXiv:2601.08372v1 Announce Type: cross 
Abstract: This paper develops a data-driven h2 model reduction method for discrete-time linear time-invariant systems. Specifically, we solve the h2 model reduction problem defined over a finite horizon using only impulse response data. Furthermore, we show that the proposed data-driven algorithm converges to a stationary point under certain assumptions. Numerical experiments demonstrate that the proposed method constructs a good reduced-order model in terms of the h2 norm defined over the finite horizon using a SLICOT benchmark (the CD player model).</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08372v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroki Sakamoto, Kazuhiro Sato</dc:creator>
    </item>
    <item>
      <title>Differentiating through Stochastic Differential Equations: A Primer</title>
      <link>https://arxiv.org/abs/2601.08594</link>
      <description>arXiv:2601.08594v1 Announce Type: cross 
Abstract: Dynamical systems are essential to model various phenomena in physics, finance, economics, and are also of current interest in machine learning. A central modeling task is investigating parameter sensitivity, whether tuning atmospheric coefficients, computing financial Greeks, or optimizing neural networks. These sensitivities are mathematically expressed as derivatives of an objective function with respect to parameters of interest and are rarely available analytically, necessitating numerical methods for approximating them. While the literature for differentiation of deterministic systems is well-covered, the treatment of stochastic systems, such as stochastic differential equations (SDEs), in most curricula is less comprehensive than the subtleties arising from the interplay of noise and discretization require.
  This paper provides a primer on numerical differentiation of SDEs organized as a two-tale narrative. Tale 1 demonstrates differentiating through discretized SDEs, known the discretize-optimize approach, is reliable for both It\^{o} and Stratonovich calculus. Tale 2 examines the optimize-discretize approach, investigating the continuous limit of backward equations from Tale 1 corresponding to the desired gradients. Our aim is to equip readers with a clear guide on the numerical differentiation of SDEs: computing gradients correctly in both It\^{o} and Stratonovich settings, understanding when discretize-optimize and optimize-discretize agree or diverge, and developing intuition for reasoning about stochastic differentiation beyond the cases explicitly covered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08594v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Rishi Leburu, Levon Nurbekyan, Lars Ruthotto</dc:creator>
    </item>
    <item>
      <title>Simple repair policies and decompositions for semi-coherent systems with simultaneous failures</title>
      <link>https://arxiv.org/abs/2601.08786</link>
      <description>arXiv:2601.08786v1 Announce Type: cross 
Abstract: We consider semi-coherent binary systems that are subject to simultaneous failures of its components. These are systems whose components can be either working or failed; the system can also be working or failed depending on the state of the components; and repairing a component cannot cause the system to fail. We consider that one or more components can fail simultaneously, allowing us to model external shocks and disasters. For this, we use the L\'evy-frailty Marshall-Olkin (LFMO) multivariate distribution to model the failure times of the components. We aim to answer in which states of the system we should repair the components. This is a challenging question, as the number of repair policies grows super-exponentially in the number of components. To tackle this, we propose a simple family of repair policies, which we call $r$-out-of-$n$:R repair policies, where one repairs all failed components when the system fails or when there are $r$ or more failed components. Our main contribution is that we derive exact and simple expressions for key performance-evaluation quantities of the system operating under our proposed repair policies. That is, we give explicit expressions for the mean time-to-failure of the system, mean time-to-repair, probability of system-failure before repair, and component- and system-repair rate. We also give expressions for the expected cost and long-term average cost, when there are components' and system repair cost. The only relevant parameters involved in the derived expressions are the structural signature of the system, and the Laplace exponent associated to the LFMO distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.08786v1</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guido Lagos, Jorge Navarro, Hector Olivero</dc:creator>
    </item>
    <item>
      <title>First-order Methods for Unconstrained Vector Optimization Problems: A Unified Majorization-Minimization Perspective</title>
      <link>https://arxiv.org/abs/2407.13245</link>
      <description>arXiv:2407.13245v3 Announce Type: replace 
Abstract: In this paper, we develop a unified majorization-minimization scheme and convergence analysis with first-order surrogate functions for unconstrained vector optimization problems (VOPs). By selecting different surrogate functions, the unified method can be reduced to various existing first-order methods. The unified convergence analysis reveals that the slow convergence of the steepest descent method is primarily attributed to the significant gap between the surrogate and objective functions. Consequently, narrowing this surrogate gap can enhance the performance of first-order methods for VOPs. To strike a better trade-off in terms of surrogate gap and per-iteration cost, we reformulate the direction-finding subproblem and elucidate that selecting a tighter surrogate function is equivalent to using an appropriate base of the dual cone in the direction-finding subproblem. Building on this insight, we employ the Barzilai-Borwein method to narrow the surrogate gap and propose a Barzilai-Borwein descent method for VOPs (BBDVO) with polyhedral cones. By reformulating the corresponding subproblem, we provide a novel perspective on the Barzilai-Borwein descent method, bridging the gap between this method and the steepest descent method. Finally, several numerical experiments are presented to validate the efficiency of the BBDVO.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13245v3</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jian Chen, Jingjie Liu, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Stability of Primal-Dual Gradient Flow Dynamics for Multi-Block Convex Optimization Problems</title>
      <link>https://arxiv.org/abs/2408.15969</link>
      <description>arXiv:2408.15969v3 Announce Type: replace 
Abstract: We examine stability properties of primal-dual gradient flow dynamics for composite convex optimization problems with multiple, possibly nonsmooth, terms in the objective function under the generalized consensus constraint. The proposed dynamics are based on the proximal augmented Lagrangian and they provide a viable alternative to ADMM which faces significant challenges from both analysis and implementation viewpoints in large-scale multi-block scenarios. In contrast to customized algorithms with individualized convergence guarantees, we develop a systematic approach for solving a broad class of challenging composite optimization problems. We leverage various structural properties to establish global (exponential) convergence guarantees for the proposed dynamics. Our assumptions are much weaker than those required to prove (exponential) stability of primal-dual dynamics as well as (linear) convergence of discrete-time methods such as standard two-block and multi-block ADMM and EXTRA algorithms. Finally, we show necessity of some of our structural assumptions for exponential stability and provide computational experiments to demonstrate the convenience of the proposed approach for parallel and distributed computing applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.15969v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ibrahim K. Ozaslan, Panagiotis Patrinos, Mihailo R. Jovanovi\'c</dc:creator>
    </item>
    <item>
      <title>An emergence-oriented approach to circular formation</title>
      <link>https://arxiv.org/abs/2506.05157</link>
      <description>arXiv:2506.05157v2 Announce Type: replace 
Abstract: In this paper, we study the emergence of circular formation for agents in cyclic pursuit. Each agent is a unicycle traveling at a fixed common forward speed. We first establish a necessary and sufficient condition for the existence of circular formation in cyclic pursuit. Building on this theoretical foundation, we propose a control law that enables the spontaneous formation of circular formations through only local measurements. Notably, key geometric features -- the radius and agent spacing -- are not imposed externally but emerge naturally from the initial conditions of the group. This occurs because the closed-loop system possesses infinitely many non-isolated equilibria, each corresponding to a particular circular formation, and none are asymptotically stable. Consequently, analyzing individual equilibria is no longer informative, and attention is instead directed to the full invariant set (the set of all equilibria). Globally, it is disconnected. Locally, however, each equilibrium together with its neighboring equilibria forms a connected invariant set. This motivates a local stability analysis formulated at the level of invariant sets that are maximally connected. An accompanying stability criterion is then derived and applied to analyze small agent groups ($n \leq 3$), providing insights into the convergence mechanism. Finally, the proposed control law is extended to distance-dependent neighborhoods. Under this setting, the group converges into several clusters, most exhibiting a complete-graph topology. A preliminary stability analysis is then conducted for the case of a complete graph with $n=3$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.05157v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaozhan Yao, Yuhua Yao, Xiaoming Hu</dc:creator>
    </item>
    <item>
      <title>A reconsideration of quasimonotone variational inequality problems</title>
      <link>https://arxiv.org/abs/2506.09389</link>
      <description>arXiv:2506.09389v2 Announce Type: replace 
Abstract: This paper is based on Tseng's exgradient algorithm for solving variational inequality problems in real Hilbert spaces. Under the assumptions that the cost operator is quasimonotone and Lipschitz continuous, we establish the strong convergence, sublinear convergence, and Q-linear convergence of the algorithm. The results of this paper provide new insights into quasimonotone variational inequality problems, extending and enriching existing results in the literature. Finally, we conduct numerical experiments to illustrate the effectiveness and implementability of our proposed condition and algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.09389v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10589-025-00718-4</arxiv:DOI>
      <arxiv:journal_reference>Comput. Optim. Appl. 93, 373-395 (2026)</arxiv:journal_reference>
      <dc:creator>Meiying Wang, Hongwei Liu, Jun Yang</dc:creator>
    </item>
    <item>
      <title>Accelerated Gradient Methods with Biased Gradient Estimates: Risk Sensitivity, High-Probability Guarantees, and Large Deviation Bounds</title>
      <link>https://arxiv.org/abs/2509.13628</link>
      <description>arXiv:2509.13628v3 Announce Type: replace 
Abstract: We study trade-offs between convergence rate and robustness to gradient errors in the context of first-order methods. Our focus is on generalized momentum methods (GMMs)--a broad class that includes Nesterov's accelerated gradient, heavy-ball, and gradient descent methods--for minimizing smooth strongly convex objectives. We allow stochastic gradient errors that may be adversarial and biased, and quantify robustness of these methods to gradient errors via the risk-sensitive index (RSI) from robust control theory. For quadratic objectives with i.i.d. Gaussian noise, we give closed form expressions for RSI in terms of solutions to 2x2 matrix Riccati equations, revealing a Pareto frontier between RSI and convergence rate over the choice of step-size and momentum parameters. We then prove a large-deviation principle for time-averaged suboptimality in the large iteration limit and show that the rate function is, up to a scaling, the convex conjugate of the RSI function. We further show that the rate function and RSI are linked to the $H_\infty$-norm--a measure of robustness to the worst-case deterministic gradient errors--so that stronger worst-case robustness (smaller $H_\infty$-norm) leads to sharper decay of the tail probabilities for the average suboptimality. Beyond quadratics, under potentially biased sub-Gaussian gradient errors, we derive non-asymptotic bounds on a finite-time analogue of the RSI, yielding finite-time high-probability guarantees and non-asymptotic large-deviation bounds for the averaged iterates. In the case of smooth strongly convex functions, we also observe an analogous trade-off between RSI and convergence-rate bounds. To our knowledge, these are the first non-asymptotic guarantees for GMMs with biased gradients and the first risk-sensitive analysis of GMMs. Finally, we provide numerical experiments on a robust regression problem to illustrate our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13628v3</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mert G\"urb\"uzbalaban, Yasa Syed, Necdet Serhat Aybat</dc:creator>
    </item>
    <item>
      <title>Limited-Memory LRSGA: An Iterative Method for Computing Nash Equilibria in Competitive Optimization Problems</title>
      <link>https://arxiv.org/abs/2510.26983</link>
      <description>arXiv:2510.26983v2 Announce Type: replace 
Abstract: We introduce LMLRSGA, a limited memory variant of Low Rank Symplectic Gradient Adjustment (LRSGA) for differentiable games. It is an iterative scheme for approximating Nash equilibria with first order like cost while retaining the stabilizing effect of symplectic second order corrections via low rank information. By storing only a limited history of curvature pairs, LMLRSGA is well suited to high parameter competitive models such as GANs. In particular, we provide a per iteration spectral stability condition for LRSGA near Nash equilibria, a limited memory implementation (LMLRSGA) based on adapted two loop recursions together with a local convergence analysis for fixed history length, and an empirical evaluation on GAN training on MNIST and FashionMNIST, including spectral diagnostics of the training dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.26983v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Katherine Rossella Foglia, Francesco Sergio Pisani, Vittorio Colao</dc:creator>
    </item>
    <item>
      <title>On Intensity of Preference Rank Reversal in the AHP</title>
      <link>https://arxiv.org/abs/2512.11622</link>
      <description>arXiv:2512.11622v2 Announce Type: replace 
Abstract: The analytic hierarchy process (AHP) is one of the most widely used multicriteria decision-making methods, with applications from agriculture to space engineering. Despite its popularity, AHP has been repeatedly criticised for rank reversal, a phenomenon in which the ranking of alternatives changes after the addition or removal of an irrelevant or duplicate alternative.
  This paper introduces a new type of rank reversal in AHP, arising when the intensity of preferences is uniformly increased. We show that even when all pairwise preferences preserve their direction and are intensified identically, the eigenvector method may produce a different ordering of alternatives. In contrast, the geometric mean (GM) method is robust to this intensity-of-preference (IOP) rank reversal.
  The applicability of this result is shown through a real decision-making problem taken from a NASA manual concerning capability prioritisation for the planned lunar Gateway orbital station.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.11622v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Jiri Mazurek, Luis \'Angel Calvo</dc:creator>
    </item>
    <item>
      <title>Sum of Squares Decompositions and Rank Bounds for Biquadratic Forms</title>
      <link>https://arxiv.org/abs/2601.04965</link>
      <description>arXiv:2601.04965v2 Announce Type: replace 
Abstract: We study positive semi-definite (PSD) biquadratic forms and their sum-of-squares (SOS) representations. For the class of partially symmetric biquadratic forms, we establish necessary and sufficient conditions for positive semi-definiteness and prove that every PSD partially symmetric biquadratic form is a sum of squares of bilinear forms. This extends the known result for fully symmetric biquadratic forms. We describe an efficient computational procedure for constructing SOS decompositions, exploiting the Kronecker-product structure of the associated matrix representation. We present a $2 \times 2$ PSD biquadratic form, and show that it can be expressed as the sum of three squares, but cannot be expressed as the sum of two squares. Furthermore, we present a $3 \times 2$ PSD biquadratic form, and show that it can be expressed as the sum of four squares, but cannot be expressed as the sum of three squares. These show that previously proved results that a $2 \times 2$ PSD biquadratic form can be expressed as the sum of three squares, and a $3 \times 2$ PSD biquadratic form can be expressed as the sum of four squares, are tight. Moreover, we establish a universal upper bound SOS-rank$(P) \le mn-1$ for any SOS biquadratic form, which improves the trivial bound $mn$ and is tight in small dimensions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.04965v2</guid>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Liqun Qi, Chunfeng Cui, Yi Yu</dc:creator>
    </item>
    <item>
      <title>The radius of statistical efficiency</title>
      <link>https://arxiv.org/abs/2405.09676</link>
      <description>arXiv:2405.09676v2 Announce Type: replace-cross 
Abstract: Classical results in asymptotic statistics show that the Fisher information matrix controls the difficulty of estimating a statistical model from observed data. In this work, we introduce a companion measure of robustness of an estimation problem: the radius of statistical efficiency (RSE) is the size of the smallest perturbation to the problem data that renders the Fisher information matrix singular. We compute RSE up to numerical constants for a variety of testbed problems, including principal component analysis, generalized linear models, phase retrieval, bilinear sensing, and matrix completion. Interestingly, we observe a precise reciprocal relationship between RSE and the intrinsic complexity/sensitivity of the problem instance, paralleling the classical Eckart-Young theorem in numerical analysis. To establish our results, we develop theory for spectral functions of measures that extends well-known results from matrix analysis and eigenvalue optimization$-$a contribution that may be of interest beyond our immediate findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09676v2</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joshua Cutler, Mateo D\'iaz, Dmitriy Drusvyatskiy</dc:creator>
    </item>
    <item>
      <title>Cross-Dimensional Mathematics: A Foundation For STP/STA</title>
      <link>https://arxiv.org/abs/2406.12920</link>
      <description>arXiv:2406.12920v4 Announce Type: replace-cross 
Abstract: A new mathematical structure, called the cross-dimensional mathematics (CDM), is proposed. The CDM considered in this paper consists of three parts: hyper algebra, hyper geometry, and hyper Lie group/Lie algebra. Hyper algebra proposes some new algebraic structures such as hyper group, hyper ring, and hyper module over matrices and vectors with mixed dimensions (MVMDs). They have sets of classical groups, rings, and modules as their components and cross-dimensional connections among their components. Their basic properties are investigated. Hyper geometry starts from mixed dimensional Euclidian space, and hyper vector space. Then the hyper topological vector space, hyper inner product space, and hyper manifold are constructed. They have a joined cross-dimensional geometric structure. Finally, hyper metric space, topological hyper group and hyper Lie algebra are built gradually, and finally, the corresponding hyper Lie group is introduced. All these concepts are built over MVMDs, and to reach our purpose in addition to existing semi-tensor products (STPs) and semi-tensor additions (STAs), a couple of most general STP and STA are introduced. Some existing structures/results about STPs/STAs have also been resumed and integrated into this CDM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.12920v4</guid>
      <category>math.RA</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s11425-024-2528-4</arxiv:DOI>
      <dc:creator>Daizhan Cheng</dc:creator>
    </item>
    <item>
      <title>Gradient flow in parameter space is equivalent to linear interpolation in output space</title>
      <link>https://arxiv.org/abs/2408.01517</link>
      <description>arXiv:2408.01517v3 Announce Type: replace-cross 
Abstract: We prove that the standard gradient flow in parameter space that underlies many training algorithms in deep learning can be continuously deformed into an adapted gradient flow which yields (constrained) Euclidean gradient flow in output space. Moreover, for the $L^{2}$ loss, if the Jacobian of the outputs with respect to the parameters is full rank (for fixed training data), then the time variable can be reparametrized so that the resulting flow is simply linear interpolation, and a global minimum can be achieved. For the cross-entropy loss, under the same rank condition and assuming the labels have positive components, we derive an explicit formula for the unique global minimum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01517v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.geomphys.2026.105765</arxiv:DOI>
      <dc:creator>Thomas Chen, Patr\'icia Mu\~noz Ewald</dc:creator>
    </item>
    <item>
      <title>How Memory in Optimization Algorithms Implicitly Modifies the Loss</title>
      <link>https://arxiv.org/abs/2502.02132</link>
      <description>arXiv:2502.02132v3 Announce Type: replace-cross 
Abstract: In modern optimization methods used in deep learning, each update depends on the history of previous iterations, often referred to as memory, and this dependence decays fast as the iterates go further into the past. For example, gradient descent with momentum has exponentially decaying memory through exponentially averaged past gradients. We introduce a general technique for identifying a memoryless algorithm that approximates an optimization algorithm with memory. It is obtained by replacing all past iterates in the update by the current one, and then adding a correction term arising from memory (also a function of the current iterate). This correction term can be interpreted as a perturbation of the loss, and the nature of this perturbation can inform how memory implicitly (anti-)regularizes the optimization dynamics. As an application of our theory, we find that Lion does not have the kind of implicit anti-regularization induced by memory that AdamW does, providing a theory-based explanation for Lion's better generalization performance recently documented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.02132v3</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Boris Shigida</dc:creator>
    </item>
    <item>
      <title>Analog In-memory Training on General Non-ideal Resistive Elements: The Impact of Response Functions</title>
      <link>https://arxiv.org/abs/2502.06309</link>
      <description>arXiv:2502.06309v5 Announce Type: replace-cross 
Abstract: As the economic and environmental costs of training and deploying large vision or language models increase dramatically, analog in-memory computing (AIMC) emerges as a promising energy-efficient solution. However, the training perspective, especially its training dynamic, is underexplored. In AIMC hardware, the trainable weights are represented by the conductance of resistive elements and updated using consecutive electrical pulses. While the conductance changes by a constant in response to each pulse, in reality, the change is scaled by asymmetric and non-linear response functions, leading to a non-ideal training dynamic. This paper provides a theoretical foundation for gradient-based training on AIMC hardware with non-ideal response functions. We demonstrate that asymmetric response functions negatively impact Analog SGD by imposing an implicit penalty on the objective. To overcome the issue, we propose Residual Learning algorithm, which provably converges exactly to a critical point by solving a bilevel optimization problem. We demonstrate that the proposed method can be extended to address other hardware imperfections, such as limited response granularity. As we know, it is the first paper to investigate the impact of a class of generic non-ideal response functions. The conclusion is supported by simulations validating our theoretical insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06309v5</guid>
      <category>cs.LG</category>
      <category>cs.AR</category>
      <category>math.OC</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaoxian Wu, Quan Xiao, Tayfun Gokmen, Omobayode Fagbohungbe, Tianyi Chen</dc:creator>
    </item>
    <item>
      <title>A predictive modular approach to constraint satisfaction under uncertainty -- with application to glycosylation in continuous monoclonal antibody biosimilar production</title>
      <link>https://arxiv.org/abs/2508.16803</link>
      <description>arXiv:2508.16803v3 Announce Type: replace-cross 
Abstract: The paper proposes a modular-based approach to constraint handling in process optimization and control. This is partly motivated by the recent interest in learning-based methods, e.g., within bioproduction, for which constraint handling under uncertainty is a challenge. The proposed constraint handler, called predictive filter, is combined with an adaptive constraint margin and a constraint violation cost monitor to minimize the cost of violating soft constraints due to model uncertainty and disturbances. The module can be combined with any controller and is based on minimally modifying the controller output, in a least squares sense, such that constraints are satisfied within the considered horizon. The proposed method is computationally efficient and suitable for real-time applications. The effectiveness of the method is illustrated through a realistic case study of glycosylation constraint satisfaction in continuous monoclonal antibody biosimilar production using Chinese hamster ovary cells, employing a metabolic network model consisting of 23 extracellular metabolites and 126 reactions. In the case study, the average constraint-violation cost is reduced by more than 60% compared to the case without the proposed constraint-handling method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.16803v3</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>q-bio.QM</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yu Wang, Xiao Chen, Hubert Schwarz, V\'eronique Chotteau, Elling W. Jacobsen</dc:creator>
    </item>
    <item>
      <title>Joint Reproduction Number and Spatial Connectivity Structure Estimation via Graph Sparsity-Promoting Penalized Functional</title>
      <link>https://arxiv.org/abs/2509.20034</link>
      <description>arXiv:2509.20034v2 Announce Type: replace-cross 
Abstract: During an epidemic outbreak, decision makers crucially need accurate and robust tools to monitor the pathogen propagation. The effective reproduction number, defined as the expected number of secondary infections stemming from one contaminated individual, is a state-of-the-art indicator quantifying the epidemic intensity. Numerous estimators have been developed to precisely track the reproduction number temporal evolution. Yet, COVID-19 pandemic surveillance raised unprecedented challenges due to the poor quality of worldwide reported infection counts. When monitoring the epidemic in different territories simultaneously, leveraging the spatial structure of data significantly enhances both the accuracy and robustness of reproduction number estimates. However, this requires a good estimate of the spatial structure. To tackle this major limitation, the present work proposes a joint estimator of the reproduction number and connectivity structure. The procedure is assessed through intensive numerical simulations on carefully designed synthetic data and illustrated on real COVID-19 spatiotemporal infection counts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.20034v2</guid>
      <category>eess.SP</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Etienne Lasalle, Barbara Pascal</dc:creator>
    </item>
    <item>
      <title>Buffered AUC maximization for scoring systems via mixed-integer optimization</title>
      <link>https://arxiv.org/abs/2601.05544</link>
      <description>arXiv:2601.05544v2 Announce Type: replace-cross 
Abstract: A scoring system is a linear classifier composed of a small number of explanatory variables, each assigned a small integer coefficient. This system is highly interpretable and allows predictions to be made with simple manual calculations without the need for a calculator. Several previous studies have used mixed-integer optimization (MIO) techniques to develop scoring systems for binary classification; however, they have not focused on directly maximizing AUC (i.e., area under the receiver operating characteristic curve), even though AUC is recognized as an essential evaluation metric for scoring systems. Our goal herein is to establish an effective MIO framework for constructing scoring systems that directly maximize the buffered AUC (bAUC) as the tightest concave lower bound on AUC. Our optimization model is formulated as a mixed-integer linear optimization (MILO) problem that maximizes bAUC subject to a group sparsity constraint for limiting the number of questions in the scoring system. Computational experiments using publicly available real-world datasets demonstrate that our MILO method can build scoring systems with superior AUC values compared to the baseline methods based on regularization and stepwise regression. This research contributes to the advancement of MIO techniques for developing highly interpretable classification models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.05544v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <pubDate>Wed, 14 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Moe Shiina, Shunnosuke Ikeda, Yuichi Takano</dc:creator>
    </item>
  </channel>
</rss>
