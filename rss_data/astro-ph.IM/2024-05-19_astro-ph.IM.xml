<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>astro-ph.IM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/astro-ph.IM</link>
    <description>astro-ph.IM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/astro-ph.IM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Mon, 20 May 2024 04:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 20 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Reinforcement learning</title>
      <link>https://arxiv.org/abs/2405.10369</link>
      <description>arXiv:2405.10369v1 Announce Type: new 
Abstract: Observing celestial objects and advancing our scientific knowledge about them involves tedious planning, scheduling, data collection and data post-processing. Many of these operational aspects of astronomy are guided and executed by expert astronomers. Reinforcement learning is a mechanism where we (as humans and astronomers) can teach agents of artificial intelligence to perform some of these tedious tasks. In this paper, we will present a state of the art overview of reinforcement learning and how it can benefit astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10369v1</guid>
      <category>astro-ph.IM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sarod Yatawatta</dc:creator>
    </item>
    <item>
      <title>An upgraded 0.4-meter telescope fleet for Las Cumbres Observatory's Educational and Science Programs</title>
      <link>https://arxiv.org/abs/2405.10408</link>
      <description>arXiv:2405.10408v1 Announce Type: new 
Abstract: Las Cumbres Observatory (LCOGT) operates a global network of robotic 0.4, 1.0, and 2.0-meter telescopes to facilitate scientific research and education in time-domain astronomy. LCOGT's flagship educational program, Global Sky Partners (GSP), awards up to 1500 hours per year of telescope time to individuals and organizations that run their own, fully supported, educational programs. The GSP has a presence in 40 countries and 45% of the Partners target under-served, under-represented, and developing world audiences. The degradation and obsolescence of the original 0.4-meter telescope network prompted LCOGT to update the fleet of 10 telescopes to a new system consisting of predominantly off-the-shelf products. New PlaneWave DeltaRho 350 telescopes with Gemini Focuser/Rotators, LCOGT filter wheels, and QHY600 CMOS cameras, complement the original, custom-built mount. The deployment of all ten telescopes was completed in March 2024. We describe the design and performance of this new system and its components. We comment on modifications made to the QHY600 cameras, as well as on the treatment of random telegraph noise of its CMOS detectors within our data processing system BANZAI. The new telescope network supports the GSP program as well as multiple key science projects, including follow-up observations for the TESS satellite mission.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10408v1</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel-Rolf Harbeck, Brook Taylor, Annie Kirby, Mark Bowman, Steve Foale, Kal Kadlec, Curtis McCully, Matthew Daily, Jon DeVera, Dave Douglass, Mark Willis, Ian Baker, Nikolaus Volgenau, Patrick Conway, Brian Haworth, Jesus Estrada, Edward Gomez, Sandy Seale, Alice Hopkinson, Fernando Rios, Prerana Kotapali, Lisa Storrie-Lombardi, Wayne Rosing</dc:creator>
    </item>
    <item>
      <title>Rotation of the Globular Cluster Population of the Dark Matter Deficient Galaxy NGC 1052-DF4: Implication for the Total Mass</title>
      <link>https://arxiv.org/abs/2405.10462</link>
      <description>arXiv:2405.10462v1 Announce Type: new 
Abstract: We explore the globular cluster population of NGC 1052-DF4, a dark matter deficient galaxy, using Bayesian inference to search for the presence of rotation. The existence of such a rotating component is relevant to the estimation of the mass of the galaxy, and therefore the question of whether NGC 1052-DF4 is truly deficient of dark matter, similar to NGC 1052-DF2 another galaxy in the same group. The rotational characteristics of seven globular clusters in NGC 1052-DF4 were investigated, finding that a non-rotating kinematic model has a higher Bayesian evidence than a rotating model, by a factor of approximately 2.5. In addition, we find that under the assumption of rotation, its amplitude must be small. This distinct lack of rotation strengthens the case that, based on its intrinsic velocity dispersion, NGC 1052-DF4 is a truly dark matter deficient galaxy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10462v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>stat.AP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator> Yuan (Cher),  Li, Brendon J. Brewer, Geraint F. Lewis</dc:creator>
    </item>
    <item>
      <title>A Versatile Framework for Analyzing Galaxy Image Data by Implanting Human-in-the-loop on a Large Vision Model</title>
      <link>https://arxiv.org/abs/2405.10890</link>
      <description>arXiv:2405.10890v1 Announce Type: new 
Abstract: The exponential growth of astronomical datasets provides an unprecedented opportunity for humans to gain insight into the Universe. However, effectively analyzing this vast amount of data poses a significant challenge. Astronomers are turning to deep learning techniques to address this, but the methods are limited by their specific training sets, leading to considerable duplicate workloads too. Hence, as an example to present how to overcome the issue, we built a framework for general analysis of galaxy images, based on a large vision model (LVM) plus downstream tasks (DST), including galaxy morphological classification, image restoration, object detection, parameter extraction, and more. Considering the low signal-to-noise ratio of galaxy images and the imbalanced distribution of galaxy categories, we have incorporated a Human-in-the-loop (HITL) module into our large vision model, which leverages human knowledge to enhance the reliability and interpretability of processing galaxy images interactively. The proposed framework exhibits notable few-shot learning capabilities and versatile adaptability to all the abovementioned tasks on galaxy images in the DESI legacy imaging surveys. Expressly, for object detection, trained by 1000 data points, our DST upon the LVM achieves an accuracy of 96.7%, while ResNet50 plus Mask R-CNN gives an accuracy of 93.1%; for morphology classification, to obtain AUC ~0.9, LVM plus DST and HITL only requests 1/50 training sets compared to ResNet18. Expectedly, multimodal data can be integrated similarly, which opens up possibilities for conducting joint analyses with datasets spanning diverse domains in the era of multi-message astronomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10890v1</guid>
      <category>astro-ph.IM</category>
      <category>astro-ph.GA</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mingxiang Fu, Yu Song, Jiameng Lv, Liang Cao, Peng Jia, Nan Li, Xiangru Li, Jifeng Liu, A-Li Luo, Bo Qiu, Shiyin Shen, Liangping Tu, Lili Wang, Shoulin Wei, Haifeng Yang, Zhenping Yi, Zhiqiang Zou</dc:creator>
    </item>
    <item>
      <title>A New Monte-Carlo Model for the Space Environment</title>
      <link>https://arxiv.org/abs/2405.10430</link>
      <description>arXiv:2405.10430v1 Announce Type: cross 
Abstract: This paper introduces a novel Monte Carlo (MC) method to simulate the evolution of the low-earth orbit environment, enhancing the MIT Orbital Capacity Analysis Tool (MOCAT). In recent decades, numerous space environment models have been developed by government agencies and research groups to understand and predict the dynamics of space debris. Our MC approach advances this by simulating the trajectories of space objects and modeling their interactions, such as collisions and explosions. This aids in analyzing the trends of space-object and debris populations. A key innovation of our method is the computational efficiency in orbit propagation, which is crucial for handling potentially large numbers of objects over centuries. We present validation results against the IADC (Inter-Agency Space Debris Coordination Committee) study and explore various scenarios, including ones without future launches and those involving the launch of proposed megaconstellations with over 80,000 active payloads. With the improvement in computational efficiencies provided by this work, we can run these new scenarios that predict millions of trackable objects over a 200-year period. The previous state-of-the-art was 400,000 objects over the same period of time. Notably, while fewer megaconstellations are planned for altitudes above 800 km, even minimal failures in post-mission disposal or collision avoidance maneuvers can significantly impact orbital debris accumulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10430v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>physics.space-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Jang, Davide Gusmini, Peng Mun Siew, Andrea D'Ambrosio, Simone Servadio, Pablo Machuca, Richard Linares</dc:creator>
    </item>
    <item>
      <title>Confrontation between modelled solar integrated observables and direct observations I. Radial velocities and convective blueshift</title>
      <link>https://arxiv.org/abs/2405.10680</link>
      <description>arXiv:2405.10680v1 Announce Type: cross 
Abstract: Stellar variability strongly impacts the search for low-mass exoplanets with radial velocity techniques. Two types of planet-free time series can be used to quantify this impact: models and direct solar observations after a subtraction of the Solar System planetary contribution. Comparing these approaches is necessary for simulations. Our objective is to validate the amplitude of the convective blueshift in plages used in our previous works, particularly in blind tests, with HARPS-N solar data. We applied our model to the structures observed at the time of observations and compared the radial velocity time series. To complete our diagnosis, we studied the observed radial velocities separately for each diffraction order derived from the individual cross-correlation functions, as well as our line-by-line radial velocities. We find that our previous model had been underestimating the amplitude of the convective blueshift inhibition by a factor of about 2. A direct estimation of the convective blueshift in the spectra explains the difference with previous estimations obtained with MDI/SOHO Dopplergrams, based on the properties of the Ni line. We identified several instrumental systematics: the presence of a 2 m/s peak-to-peak signal with a period of about 200 days in radial velocity and bisector, which could be due to periodic detector warm-ups, a systematic dependence of the long-term trend on wavelength possibly related to the variability of the continuum over time, and/or an offset in radial velocity after the interruption of several months in Oct. 2017. A large amplitude in the convective blueshift inhibition of (360 m/s) must be used when building synthetic times series for blind tests. The presence of instrumental systematics should also be taken into account when using sophisticated methods based on line properties to mitigate stellar activity when searching for very weak signals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10680v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Nad\`ege Meunier, Anne-Marie Lagrange, Xavier Dumusque, Sophia Sulis</dc:creator>
    </item>
    <item>
      <title>Stellar Atmospheric Parameters From Gaia BP/RP Spectra using Uncertain Neural Networks</title>
      <link>https://arxiv.org/abs/2405.10699</link>
      <description>arXiv:2405.10699v1 Announce Type: cross 
Abstract: With the plentiful information available in the Gaia BP/RP spectra, there is significant scope for applying discriminative models to extract stellar atmospheric parameters and abundances. We describe an approach to leverage an `Uncertain Neural Network' model trained on APOGEE data to provide high-quality predictions with robust estimates for per-prediction uncertainty. We report median formal uncertainties of 0.068 dex, 69.1K, 0.14 dex, 0.031 dex, 0.040 dex, and 0.029 dex for [Fe/H], $T_\mathrm{eff}$, $\log g$, [C/Fe], [N/Fe], and [$\alpha$/M] respectively. We validate these predictions against our APOGEE training data, LAMOST, and Gaia GSP-Phot stellar parameters, and see a strong correlation between our predicted parameters and those derived from these surveys. We investigate the information content of the spectra by considering the `attention' our model pays to different spectral features compared to expectations from synthetic spectra calculations. Our model's predictions are applied to the Gaia dataset, and we produce a publicly available catalogue of our model's predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10699v1</guid>
      <category>astro-ph.SR</category>
      <category>astro-ph.GA</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Connor P. Fallows, Jason L. Sanders</dc:creator>
    </item>
    <item>
      <title>The Effect of Work Function on Dust Charging and Dynamics on the Airless Celestial Body</title>
      <link>https://arxiv.org/abs/2405.10744</link>
      <description>arXiv:2405.10744v1 Announce Type: cross 
Abstract: The charged dust on the surface of airless celestial bodies, such as the moon and asteroids, is a threat to space missions. Further research on the charged dust will contribute to the success of space missions. In this paper, we study the charging and dynamics of dust particles with different work functions. By integrating the photoelectron energy distribution function over four illuminated areas with different work functions, we evaluated the photoelectron concentration in these four areas. At each area, using the photoelectron concentration, we solve the dust charging and dynamics equations with two different gravitational acceleration values. The results reveal that the dust with a larger work function can reach higher equilibrium states. These states include dominant photoelectron-related charging currents, charge numbers, and levitation heights. We suggest that the equilibrium states all hold a clear inverse relationship with the work functions of dust particles when the solar zenith angle varies from 0 to 90 degrees, displaying consistent trends under different gravitational accelerations. We also find that dust particles seem unable to stably levitate at a critical solar zenith angle. The value of this critical SZA follows the same rule subjected to the work function.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10744v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <category>physics.space-ph</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ronghui Quan, Zhigui Liu, Zhiying Song</dc:creator>
    </item>
    <item>
      <title>The SNR of idealised radial velocity signals</title>
      <link>https://arxiv.org/abs/2405.10776</link>
      <description>arXiv:2405.10776v1 Announce Type: cross 
Abstract: One of the most basic quantities relevant to planning observations and assessing detection bias is the signal-to-noise ratio (SNR). Remarkably, the SNR of an idealised radial velocity (RV) signal has not been previously derived beyond scaling behaviours and ignoring orbital eccentricity. In this work, we derive the RV SNR for three relevant cases to observers. First, we consider a single mass orbiting a star, revealing the expected result that $\mathrm{SNR}\propto K \sqrt{T}$, where $T$ is the observing window, but an additional dependency on eccentricity and argument of periastron. We show that the RV method is biased towards companions with their semi-major axes aligned to the observer, which is physically intuitive, but also less obviously that the marginalised bias to eccentricity is negligible until one reaches very high eccentricities. Second, we derive the SNR necessary to discriminate eccentric companions from 2:1 resonance circular orbits, although our result is only valid for eccentricities $e\lesssim0.3$. We find that the discriminatory SNR is $(9/8) e^2 (1-e^2)^{-1/2}$ times that of the eccentric planet solution's SNR, and is thus typically an order-of-magnitude less. Finally, we have obtained a semi-empirical expression for the SNR of the idealised Rossiter-McLaughlin effect, revealing the bias with respect to spin-orbit alignment angle. Our formula is valid to within 10% accuracy in 95.45% of the training samples used (for $b\leq0.8$), but larger deviations occur when comparing to different RM models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10776v1</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Kipping, Xian-Yu Wang</dc:creator>
    </item>
    <item>
      <title>A Cohesive Deep Drilling Field Strategy for LSST Cosmology</title>
      <link>https://arxiv.org/abs/2405.10781</link>
      <description>arXiv:2405.10781v1 Announce Type: cross 
Abstract: The Vera C. Rubin Observatory Legacy Survey of Space and Time (LSST) will image billions of astronomical objects in the wide-fast-deep primary survey and in a set of minisurveys including intensive observations of a group of deep drilling fields (DDFs). The DDFs are a critical piece of three key aspects of the LSST Dark Energy Science Collaboration (DESC) cosmological measurements: they provide a required calibration for photometric redshifts and weak gravitational lensing measurements and they directly contribute to cosmological constraints from the most distant type Ia supernovae. We present a set of cohesive DDF strategies fulfilling science requirements relevant to DESC and following the guidelines of the Survey Cadence Optimization Committee. We propose a method to estimate the observing strategy parameters and we perform simulations of the corresponding surveys. We define a set of metrics for each of the science case to assess the performance of the proposed observing strategies. We show that the most promising results are achieved with deep rolling surveys characterized by two sets of fields: ultradeep fields (z&lt;1.1) observed at a high cadence with a large number of visits over a limited number of seasons; deep fields (z&lt;0.7), observed with a cadence of ~3 nights for ten years. These encouraging results should be confirmed with realistic simulations using the LSST scheduler. A DDF budget of ~8.5% is required to design observing strategies satisfying all the cosmological requirements. A lower DDF budget lead to surveys that either do not fulfill photo-z/WL requirements or are not optimal for SNe Ia cosmology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10781v1</guid>
      <category>astro-ph.CO</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philippe Gris, Humna Awan, Matthew R. Becker, Huan Lin, Eric Gawiser, Saurabh W. Jha</dc:creator>
    </item>
    <item>
      <title>Expected Gamma-Ray Burst Detection Rates and Redshift Distributions for the BlackCAT CubeSat Mission</title>
      <link>https://arxiv.org/abs/2405.10872</link>
      <description>arXiv:2405.10872v1 Announce Type: cross 
Abstract: We report the results of an extensive set of simulations exploring the sensitivity of the BlackCAT CubeSat to long-duration gamma-ray bursts (GRBs). BlackCAT is a NASA APRA-funded CubeSat mission for the detection and real-time sub-arcminute localization of high-redshift ($z\gtrsim 3.5$) GRBs. Thanks to their luminous and long-lived afterglow emissions, GRBs are uniquely valuable probes of high-redshift star-forming galaxies and the intergalactic medium. In addition, each detected GRB with a known redshift serves to localize a region of high-redshift star formation in three dimensions, enabling deep follow-on searches for host galaxies and associated local and large-scale structure. We explore two distinct models for the GRB redshift distribution and luminosity function, both consistent with \textit{Swift} observations. We find that, for either model, BlackCAT is expected to detect a mean of 42 bursts per year on-orbit, with 6.7% to 10% of these at $z&gt;3.5$. BlackCAT bursts will be localized to $r_{90} \lesssim 55^{\prime\prime}$ precision and reported to the community within seconds. Due to the mission orbit and pointing scheme, bursts will be located in the night sky and well-placed for deep multiwavelength follow-up observations. BlackCAT is on schedule to achieve launch readiness in 2025.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10872v1</guid>
      <category>astro-ph.HE</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Joseph M. Colosimo, Derek B. Fox, Abraham D. Falcone, David M. Palmer, Frederic Hancock, Michael Betts, William A. Bevidas Jr., Jacob C. Buffington, David N. Burrows, Zachary E. Catlin, Timothy Emeigh, Thomas Forstmeier, Kadri M. Nizam, Collin Reichard, Ana C. Scigliani, Lukas R. Stone, Ian Thornton, Mitchell Wages, Daniel Washington, Michael E. Zugger</dc:creator>
    </item>
    <item>
      <title>ATAT: Astronomical Transformer for time series And Tabular data</title>
      <link>https://arxiv.org/abs/2405.03078</link>
      <description>arXiv:2405.03078v2 Announce Type: replace 
Abstract: The advent of next-generation survey instruments, such as the Vera C. Rubin Observatory and its Legacy Survey of Space and Time (LSST), is opening a window for new research in time-domain astronomy. The Extended LSST Astronomical Time-Series Classification Challenge (ELAsTiCC) was created to test the capacity of brokers to deal with a simulated LSST stream. We describe ATAT, the Astronomical Transformer for time series And Tabular data, a classification model conceived by the ALeRCE alert broker to classify light-curves from next-generation alert streams. ATAT was tested in production during the first round of the ELAsTiCC campaigns. ATAT consists of two Transformer models that encode light curves and features using novel time modulation and quantile feature tokenizer mechanisms, respectively. ATAT was trained on different combinations of light curves, metadata, and features calculated over the light curves. We compare ATAT against the current ALeRCE classifier, a Balanced Hierarchical Random Forest (BHRF) trained on human-engineered features derived from light curves and metadata. When trained on light curves and metadata, ATAT achieves a macro F1-score of 82.9 +- 0.4 in 20 classes, outperforming the BHRF model trained on 429 features, which achieves a macro F1-score of 79.4 +- 0.1. The use of Transformer multimodal architectures, combining light curves and tabular data, opens new possibilities for classifying alerts from a new generation of large etendue telescopes, such as the Vera C. Rubin Observatory, in real-world brokering scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03078v2</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Cabrera-Vives, D. Moreno-Cartagena, N. Astorga, I. Reyes-Jainaga, F. F\"orster, P. Huijse, J. Arredondo, A. M. Mu\~noz Arancibia, A. Bayo, M. Catelan, P. A. Est\'evez, P. S\'anchez-S\'aez, A. \'Alvarez, P. Castellanos, P. Gallardo, A. Moya, D. Rodriguez-Mancini</dc:creator>
    </item>
    <item>
      <title>Identification of problematic epochs in astronomical time series through transfer learning</title>
      <link>https://arxiv.org/abs/2405.05591</link>
      <description>arXiv:2405.05591v3 Announce Type: replace 
Abstract: We present a novel method for detecting outliers in astronomical time series based on the combination of a deep neural network and a k-nearest neighbor algorithm with the aim of identifying and removing problematic epochs in the light curves of astronomical objects. We use an EfficientNet network pre-trained on ImageNet as a feature extractor and perform a k-nearest neighbor search in the resulting feature space to measure the distance from the first neighbor for each image. If the distance is above the one obtained for a stacked image, we flag the image as a potential outlier. We apply our method to time series obtained from the VLT Survey Telescope (VST) monitoring campaign of the Deep Drilling Fields of the Vera C. Rubin Legacy Survey of Space and Time (LSST). We show that our method can effectively identify and remove artifacts from the VST time series and improve the quality and reliability of the data. This approach may prove very useful in sight of the amount of data that will be provided by the LSST, which will prevent the inspection of individual light curves. We also discuss the advantages and limitations of our method and suggest possible directions for future work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.05591v3</guid>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Stefano Cavuoti, Demetra De Cicco, Lars Doorenbos, Massimo Brescia, Olena Torbaniuk, Giuseppe Longo, Maurizio Paolillo</dc:creator>
    </item>
    <item>
      <title>Results from the CsI Calorimeter onboard the 2023 ComPair Balloon Flight</title>
      <link>https://arxiv.org/abs/2405.06839</link>
      <description>arXiv:2405.06839v3 Announce Type: replace 
Abstract: The ComPair gamma-ray telescope is a technology demonstrator for a future gamma-ray telescope called the All-sky Medium Energy Gamma-ray Observatory (AMEGO). The instrument is composed of four subsystems, a double-sided silicon strip detector, a virtual Frisch grid CdZnTe calorimeter, a CsI:Tl based calorimeter, and an anti-coincidence detector (ACD). The CsI calorimeter's goal is to measure the position and energy deposited from high-energy events. To demonstrate the technological readiness, the calorimeter has flown onboard a NASA scientific balloon as part of the GRAPE-ComPair mission and accumulated around 3 hours of float time at an altitude of 40 km. During the flight, the CsI calorimeter observed background radiation, Regener-Pfotzer Maximum, and several gamma-ray activation lines originating from aluminum.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.06839v3</guid>
      <category>astro-ph.IM</category>
      <category>nucl-ex</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Daniel Shy, Richard S. Woolf, Clio Sleator, Bernard Phlips, J. Eric Grove, Eric A. Wulf, Mary Johnson-Rambert, Mitch Davis, Emily Kong, Thomas Caligiure, A. Wilder Crosier, Aleksey Bolotnikov, Nicholas Cannady, Gabriella A. Carini, Regina Caputo, Jack Fried, Priyarshini Ghosh, Sean Griffin, Elizabeth Hays, Sven Herrmann, Carolyn Kierans, Nicholas Kirschner, Iker Liceaga-Indart, Zachary Metzler, Julie McEnery, John Mitchell, A. A. Moiseev, Lucas Parker, Alfred Dellapenna, Jeremy S. Perkins, Makoto Sasaki, Adam J. Schoenwald, Lucas D. Smith, Janeth Valverde, Sambid Wasti, Anna Zajczyk</dc:creator>
    </item>
    <item>
      <title>nuance: Efficient detection of planets transiting active stars</title>
      <link>https://arxiv.org/abs/2402.06835</link>
      <description>arXiv:2402.06835v2 Announce Type: replace-cross 
Abstract: The detection of planetary transits in the light curves of active stars, featuring correlated noise in the form of stellar variability, remains a challenge. Depending on the noise characteristics, we show that the traditional technique that consists of detrending a light curve before searching for transits alters their signal-to-noise ratio, and hinders our capability to discover exoplanets transiting rapidly-rotating active stars. We present nuance, an algorithm to search for transits in light curves while simultaneously accounting for the presence of correlated noise, such as stellar variability and instrumental signals. We assess the performance of nuance on simulated light curves as well as on the TESS light curves of 438 rapidly-rotating M dwarfs. For each dataset, we compare our method to 5 commonly-used detrending techniques followed by a search with the Box-Least-Square algorithm. Overall, we demonstrate that nuance is the most performant method in 93% of cases, leading to both the highest number of true positives and the lowest number of false positive detections. Although simultaneously searching for transits while modeling correlated noise is expected to be computationally expensive, we make our algorithm tractable and available as the JAX-powered Python package nuance, allowing its use on distributed environments and GPU devices. Finally, we explore the prospects offered by the nuance formalism, and its use to advance our knowledge of planetary systems around active stars, both using space-based surveys and sparse ground-based observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.06835v2</guid>
      <category>astro-ph.EP</category>
      <category>astro-ph.IM</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lionel Garcia, Daniel Foreman-Mackey, Catriona A. Murray, Suzanne Aigrain, Dax L. Feliz, Francisco J. Pozuelos</dc:creator>
    </item>
  </channel>
</rss>
