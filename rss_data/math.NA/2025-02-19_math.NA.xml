<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.NA updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.NA</link>
    <description>math.NA updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.NA" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 19 Feb 2025 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Uncertainty quantification for stationary and time-dependent PDEs subject to Gevrey regular random domain deformations</title>
      <link>https://arxiv.org/abs/2502.12345</link>
      <description>arXiv:2502.12345v1 Announce Type: new 
Abstract: We study uncertainty quantification for partial differential equations subject to domain uncertainty. We parameterize the random domain using the model recently considered by Chernov and Le (2024) as well as Harbrecht, Schmidlin, and Schwab (2024) in which the input random field is assumed to belong to a Gevrey smoothness class. This approach has the advantage of being substantially more general than models which assume a particular parametric representation of the input random field such as a Karhunen-Loeve series expansion. We consider both the Poisson equation as well as the heat equation and design randomly shifted lattice quasi-Monte Carlo (QMC) cubature rules for the computation of the expected solution under domain uncertainty. We show that these QMC rules exhibit dimension-independent, essentially linear cubature convergence rates in this framework. In addition, we complete the error analysis by taking into account the approximation errors incurred by dimension truncation of the random input field and finite element discretization. Numerical experiments are presented to confirm the theoretical rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12345v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ana Djurdjevac, Vesa Kaarnioja, Claudia Schillings, Andr\'e-Alexander Zepernick</dc:creator>
    </item>
    <item>
      <title>Recovery of the rod cross section shape</title>
      <link>https://arxiv.org/abs/2502.12368</link>
      <description>arXiv:2502.12368v1 Announce Type: new 
Abstract: A direct method for solving the inverse problem of determining the shape of the cross section of a rod is proposed. The method is based on Neumann series of Bessel functions representations for solutions of Sturm-Liouville equations. The first coefficient of the representation is sufficient for the recovery of the unknown function. A system of linear algebraic equations for finding this coefficient is obtained. The proposed method leads to an efficient numerical algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12368v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.CA</category>
      <category>math.MP</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Vladislav V. Kravchenko, Sergii M. Torba, Alexander O. Vatulyan</dc:creator>
    </item>
    <item>
      <title>Schwartz duality for singularly perturbed nonlinear differential equations with Chebyshev spectral method</title>
      <link>https://arxiv.org/abs/2502.12432</link>
      <description>arXiv:2502.12432v1 Announce Type: new 
Abstract: Singularly perturbed differential equations with a Dirac delta function yield discontinuous solutions. Therefore, careful consideration is required when using numerical methods to solve these equations because of the Gibbs phenomenon. A remedy based on the Schwartz duality has been proposed, yielding superior results without oscillations. However, this approach has been limited to linear problems and still suffers from the Gibbs phenomenon for nonlinear problems. In this note, we propose a consistent yet simple approach based on Schwartz duality that can handle nonlinear problems. Our proposed approach utilizes a modified direct projection method with a discrete derivative of the Heaviside function, which directly approximates the Dirac delta function. This proposed method effectively eliminates Gibbs oscillations without the need for traditional regularization and demonstrates uniform error reduction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12432v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eunwoo Heo, Kwanghyuk Park, Jae-Hun Jung</dc:creator>
    </item>
    <item>
      <title>Quasi-Monte Carlo methods for uncertainty quantification of wave propagation and scattering problems modelled by the Helmholtz equation</title>
      <link>https://arxiv.org/abs/2502.12451</link>
      <description>arXiv:2502.12451v1 Announce Type: new 
Abstract: We analyse and implement a quasi-Monte Carlo (QMC) finite element method (FEM) for the forward problem of uncertainty quantification (UQ) for the Helmholtz equation with random coefficients, both in the second-order and zero-order terms of the equation, thus modelling wave scattering in random media. The problem is formulated on the infinite propagation domain, after scattering by the heterogeneity, and also (possibly) a bounded impenetrable scatterer. The spatial discretization scheme includes truncation to a bounded domain via a perfectly matched layer (PML) technique and then FEM approximation. A special case is the problem of an incident plane wave being scattered by a bounded sound-soft impenetrable obstacle surrounded by a random heterogeneous medium, or more simply, just scattering by the random medium. The random coefficients are assumed to be affine separable expansions with infinitely many independent uniformly distributed and bounded random parameters. As quantities of interest for the UQ, we consider the expectation of general linear functionals of the solution, with a special case being the far-field pattern of the scattered field. The numerical method consists of (a) dimension truncation in parameter space, (b) application of an adapted QMC method to compute expected values, and (c) computation of samples of the PDE solution via PML truncation and FEM approximation. Our error estimates are explicit in $s$ (the dimension truncation parameter), $N$ (the number of QMC points), $h$ (the FEM grid size) and (most importantly), $k$ (the Helmholtz wavenumber). The method is also exponentially accurate with respect to the PML truncation radius. Illustrative numerical experiments are given.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12451v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ivan G. Graham, Frances Y. Kuo, Dirk Nuyens, Ian H. Sloan, Euan A. Spence</dc:creator>
    </item>
    <item>
      <title>Regularity and Tailored Regularization of Deep Neural Networks, with application to parametric PDEs in uncertainty quantification</title>
      <link>https://arxiv.org/abs/2502.12496</link>
      <description>arXiv:2502.12496v1 Announce Type: new 
Abstract: In this paper we consider Deep Neural Networks (DNNs) with a smooth activation function as surrogates for high-dimensional functions that are somewhat smooth but costly to evaluate. We consider the standard (non-periodic) DNNs as well as propose a new model of periodic DNNs which are especially suited for a class of periodic target functions when Quasi-Monte Carlo lattice points are used as training points. We study the regularity of DNNs by obtaining explicit bounds on all mixed derivatives with respect to the input parameters. The bounds depend on the neural network parameters as well as the choice of activation function. By imposing restrictions on the network parameters to match the regularity features of the target functions, we prove that DNNs with $N$ tailor-constructed lattice training points can achieve the generalization error (or $L_2$ approximation error) bound ${\tt tol} + \mathcal{O}(N^{-r/2})$, where ${\tt tol}\in (0,1)$ is the tolerance achieved by the training error in practice, and $r = 1/p^*$, with $p^*$ being the ``summability exponent'' of a sequence that characterises the decay of the input variables in the target functions, and with the implied constant independent of the dimensionality of the input data. We apply our analysis to popular models of parametric elliptic PDEs in uncertainty quantification. In our numerical experiments, we restrict the network parameters during training by adding tailored regularization terms, and we show that for an algebraic equation mimicking the parametric PDE problems the DNNs trained with tailored regularization perform significantly better.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12496v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Alexander Keller, Frances Y. Kuo, Dirk Nuyens, Ian H. Sloan</dc:creator>
    </item>
    <item>
      <title>New Crouzeix-Raviart elements of even degree: theoretical aspects, numerical performance, and applications to the Stokes' equations</title>
      <link>https://arxiv.org/abs/2502.12609</link>
      <description>arXiv:2502.12609v1 Announce Type: new 
Abstract: We construct new Crouzeix-Raviart (CR) spaces of even degree $p$ that are spanned by basis functions mimicking those for the odd degree case. Compared to the standard CR gospel, the present construction allows for the use of nested bases of increasing degree and is particularly suited to design variable order CR methods. We analyze a nonconforming discretization of a two dimensional Poisson problem, which requires a DG-type stabilization; the employed stabilization parameter is considerably smaller than that needed in DG methods. Numerical results are presented, which exhibit the expected convergence rates for the $h$-, $p$-, and $hp$-versions of the scheme. We further investigate numerically the behaviour of new even degree CR-type discretizations of the Stokes' equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12609v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Andrea Bressan, Lorenzo Mascotto, Marialetizia Mosconi</dc:creator>
    </item>
    <item>
      <title>Role extraction by matrix equations and generalized random walks</title>
      <link>https://arxiv.org/abs/2502.12689</link>
      <description>arXiv:2502.12689v1 Announce Type: new 
Abstract: The nodes in a network can be grouped into 'roles' based on similar connection patterns. This is usually achieved by defining a pairwise node similarity matrix and then clustering rows and columns of this matrix. This paper presents a new similarity matrix for solving role extraction problems in directed networks, which is defined as the solution of a matrix equation and computes node similarities based on random walks that can proceed along the link direction and in the opposite direction. The resulting node similarity measure performs remarkably in role extraction tasks on directed networks with heterogeneous node degree distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12689v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>cs.SI</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dario Fasino</dc:creator>
    </item>
    <item>
      <title>Frequency-domain alignment of heterogeneous, multidimensional separations data through complex orthogonal Procrustes analysis</title>
      <link>https://arxiv.org/abs/2502.12810</link>
      <description>arXiv:2502.12810v1 Announce Type: new 
Abstract: Multidimensional separations data have the capacity to reveal detailed information about complex biological samples. However, data analysis has been an ongoing challenge in the area since the peaks that represent chemical factors may drift over the course of several analytical runs along the first and second dimension retention times. This makes higher-level analyses of the data difficult, since a 1-1 comparison of samples is seldom possible without sophisticated pre-processing routines. Further complicating the issue is the fact that closely co-eluting components will need to be resolved, typically using some variants of Parallel Factor Analysis (PARAFAC), Multivariate Curve Resolution (MCR), or the recently explored Shift-Invariant Multi-linearity. These algorithms work with a user-specified number of components, and regions of interest that are then summarized as a peak table that is invariant to shift. However, identifying regions of interest across truly heterogeneous data remains an ongoing issue, for automated deployment of these algorithms. This work offers a very simple solution to the alignment problem through a orthogonal Procrustes analysis of the frequency-domain representation of synthetic multidimensional separations data, for peaks that are logarithmically transformed to simulate shift while preserving the underlying topology of the data. Using this very simple method for analysis, two synthetic chromatograms can be compared under close to the worst possible scenarios for alignment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12810v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Michael Sorochan Armstrong</dc:creator>
    </item>
    <item>
      <title>Pushing the Limits of the Reactive Affine Shaker Algorithm to Higher Dimensions</title>
      <link>https://arxiv.org/abs/2502.12877</link>
      <description>arXiv:2502.12877v1 Announce Type: new 
Abstract: Bayesian Optimization (BO) for the minimization of expensive functions of continuous variables uses all the knowledge acquired from previous samples (${\boldsymbol x}_i$ and $f({\boldsymbol x}_i)$ values) to build a surrogate model based on Gaussian processes. The surrogate is then exploited to define the next point to sample, through a careful balance of exploration and exploitation. Initially intended for low-dimensional spaces, BO has recently been modified and used also for very large-dimensional spaces (up to about one thousand dimensions).
  In this paper we consider a much simpler algorithm, called "Reactive Affine Shaker" (RAS). The next sample is always generated with a uniform probability distribution inside a parallelepiped (the "box"). At each iteration, the form of the box is adapted during the search through an affine transformation, based only on the point $\boldsymbol x$ position and on the success or failure in improving the function. The function values are therefore not used directly to modify the search area and to generate the next sample. The entire dimensionality is kept (no active subspaces).
  Despite its extreme simplicity and its use of only stochastic local search, surprisingly the produced results are comparable to and not too far from the state-of-the-art results of high-dimensional versions of BO, although with some more function evaluations.
  An ablation study and an analysis of probability distribution of directions (improving steps and prevailing box orientation) in very large-dimensional spaces are conducted to understand more about the behavior of RAS and to assess the relative importance of the algorithmic building blocks for the final results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12877v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Roberto Battiti, Mauro Brunato</dc:creator>
    </item>
    <item>
      <title>Stochastic Parareal Algorithm for Stochastic Differential Equations</title>
      <link>https://arxiv.org/abs/2502.12909</link>
      <description>arXiv:2502.12909v1 Announce Type: new 
Abstract: This paper analyzes the SParareal algorithm for stochastic differential equations (SDEs). Compared to the classical Parareal algorithm, the SParareal algorithm accelerates convergence by introducing stochastic perturbations, achieving linear convergence over unbounded time intervals. We first revisit the classical Parareal algorithm and stochastic Parareal algorithm. Then we investigate mean-square stability of the SParareal algorithm based on the stochastic $\theta$-method for SDEs, deriving linear error bounds under four sampling rules. Numerical experiments demonstrate the superiority of the SParareal algorithm in solving both linear and nonlinear SDEs, reducing the number of iterations required compared to the classical Parareal algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12909v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huanxin Wang, Junhan Lyu, Zicheng Peng, Min Li</dc:creator>
    </item>
    <item>
      <title>How far are two symmetric matrices from commuting? With an application to object characterisation and identification in metal detection</title>
      <link>https://arxiv.org/abs/2502.13038</link>
      <description>arXiv:2502.13038v1 Announce Type: new 
Abstract: Examining the extent to which measurements of rotation matrices are close to each other is challenging due measurement noise. To overcome this, data is typically smoothed and Riemannian and Euclidean metrics are applied. However, if rotation matrices are not directly measured and are instead formed by eigenvectors of measured symmetric matrices, this can be problematic if the associated eigenvalues are close. In this work, we propose novel semi-metrics that can be used to approximate the Riemannian metric for small angles. Our new results do not require eigenvector information and are beneficial for measured datasets. There are also issues when using comparing rotational data arising from computational simulations and it is important that the impact of the approximations on the computed outputs is properly assessed to ensure that the approximations made and the finite precision arithmetic are not unduly polluting the results. In this work, we examine data arising from object characterisation in metal detection using the complex symmetric rank two magnetic polarizability tensor (MPT) description, we rigorously analyse the effects of our numerical approximations and apply our new approximate measures of distance to the commutator of the real and imaginary parts of the MPT to this application. Our new approximate measures of distance provide additional feature information, which is invariant of the object orientation, to aid with object identification using machine learning classifiers. We present Bayesian classification examples to demonstrate the success of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13038v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>P. D. Ledger, W. R. B. Lionheart, J. Elgy</dc:creator>
    </item>
    <item>
      <title>Symmetric Rank-One Quasi-Newton Methods for Deep Learning Using Cubic Regularization</title>
      <link>https://arxiv.org/abs/2502.12298</link>
      <description>arXiv:2502.12298v1 Announce Type: cross 
Abstract: Stochastic gradient descent and other first-order variants, such as Adam and AdaGrad, are commonly used in the field of deep learning due to their computational efficiency and low-storage memory requirements. However, these methods do not exploit curvature information. Consequently, iterates can converge to saddle points or poor local minima. On the other hand, Quasi-Newton methods compute Hessian approximations which exploit this information with a comparable computational budget. Quasi-Newton methods re-use previously computed iterates and gradients to compute a low-rank structured update. The most widely used quasi-Newton update is the L-BFGS, which guarantees a positive semi-definite Hessian approximation, making it suitable in a line search setting. However, the loss functions in DNNs are non-convex, where the Hessian is potentially non-positive definite. In this paper, we propose using a limited-memory symmetric rank-one quasi-Newton approach which allows for indefinite Hessian approximations, enabling directions of negative curvature to be exploited. Furthermore, we use a modified adaptive regularized cubics approach, which generates a sequence of cubic subproblems that have closed-form solutions with suitable regularization choices. We investigate the performance of our proposed method on autoencoders and feed-forward neural network models and compare our approach to state-of-the-art first-order adaptive stochastic methods as well as other quasi-Newton methods.x</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12298v1</guid>
      <category>math.OC</category>
      <category>cs.IT</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.IT</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aditya Ranganath, Mukesh Singhal, Roummel Marcia</dc:creator>
    </item>
    <item>
      <title>Tensor cross interpolation for global discrete optimization with application to Bayesian network inference</title>
      <link>https://arxiv.org/abs/2502.12940</link>
      <description>arXiv:2502.12940v1 Announce Type: cross 
Abstract: Global discrete optimization is notoriously difficult due to the lack of gradient information and the curse of dimensionality, making exhaustive search infeasible. Tensor cross approximation is an efficient technique to approximate multivariate tensors (and discretized functions) by tensor product decompositions based on a small number of tensor elements, evaluated on adaptively selected fibers of the tensor, that intersect on submatrices of (nearly) maximum volume. The submatrices of maximum volume are empirically known to contain large elements, hence the entries selected for cross interpolation can also be good candidates for the globally maximal element within the tensor. In this paper we consider evolution of epidemics on networks, and infer the contact network from observations of network nodal states over time. By numerical experiments we demonstrate that the contact network can be inferred accurately by finding the global maximum of the likelihood using tensor cross interpolation. The proposed tensor product approach is flexible and can be applied to global discrete optimization for other problems, e.g. discrete hyperparameter tuning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12940v1</guid>
      <category>stat.CO</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sergey Dolgov, Dmitry Savostyanov</dc:creator>
    </item>
    <item>
      <title>On Erlang mixture approximations for differential equations with distributed time delays</title>
      <link>https://arxiv.org/abs/2502.12984</link>
      <description>arXiv:2502.12984v1 Announce Type: cross 
Abstract: In this paper, we propose a general approach for approximate simulation and analysis of delay differential equations (DDEs) with distributed time delays based on methods for ordinary differential equations (ODEs). The key innovation is that we 1) approximate the kernel by the probability density function of an Erlang mixture and 2) use the linear chain trick to transform the approximate DDEs to ODEs. Furthermore, we prove that an approximation with infinitely many terms converges for continuous and bounded kernels and for specific choices of the coefficients. We compare the steady states of the original DDEs and their stability criteria to those of the approximate system of ODEs, and we propose an approach based on bisection and least-squares estimation for determining optimal parameter values in the approximation. Finally, we present numerical examples that demonstrate the accuracy and convergence rate obtained with the optimal parameters and the efficacy of the proposed approach for bifurcation analysis and Monte Carlo simulation. The numerical examples involve a modified logistic equation and a point reactor kinetics model of a molten salt nuclear fission reactor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.12984v1</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tobias K. S. Ritschel</dc:creator>
    </item>
    <item>
      <title>Enhanced uncertainty quantification variational autoencoders for the solution of Bayesian inverse problems</title>
      <link>https://arxiv.org/abs/2502.13105</link>
      <description>arXiv:2502.13105v1 Announce Type: cross 
Abstract: Among other uses, neural networks are a powerful tool for solving deterministic and Bayesian inverse problems in real-time. In the Bayesian framework, variational autoencoders, a specialized type of neural network, enable the estimation of model parameters and their distribution based on observational data allowing to perform real-time inverse uncertainty quantification. In this work, we build upon existing research [Goh, H. et al., Proceedings of Machine Learning Research, 2022] by proposing a novel loss function to train variational autoencoders for Bayesian inverse problems. When the forward map is affine, we provide a theoretical proof of the convergence of the latent states of variational autoencoders to the posterior distribution of the model parameters. We validate this theoretical result through numerical tests and we compare the proposed variational autoencoder with the existing one in the literature. Finally, we test the proposed variational autoencoder on the Laplace equation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.13105v1</guid>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Andrea Tonini, Luca Dede'</dc:creator>
    </item>
    <item>
      <title>Multilevel Picard algorithm for general semilinear parabolic PDEs with gradient-dependent nonlinearities</title>
      <link>https://arxiv.org/abs/2310.12545</link>
      <description>arXiv:2310.12545v5 Announce Type: replace 
Abstract: In this paper we introduce a multilevel Picard approximation algorithm for general semilinear parabolic PDEs with gradient-dependent nonlinearities whose coefficient functions do not need to be constant. We also provide a full convergence and complexity analysis of our algorithm. To obtain our main results, we consider a particular stochastic fixed-point equation (SFPE) motivated by the Feynman-Kac representation and the Bismut-Elworthy-Li formula. We show that the PDE under consideration has a unique viscosity solution which coincides with the first component of the unique solution of the stochastic fixed-point equation. Moreover, the gradient of the unique viscosity solution of the PDE exists and coincides with the second component of the unique solution of the stochastic fixed-point equation. Furthermore, we also provide a numerical example in up to $300$ dimensions to demonstrate the practical applicability of our multilevel Picard algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12545v5</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>math.PR</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ariel Neufeld, Sizhou Wu</dc:creator>
    </item>
    <item>
      <title>A Type II Hamiltonian Variational Principle and Adjoint Systems for Lie Groups</title>
      <link>https://arxiv.org/abs/2311.03527</link>
      <description>arXiv:2311.03527v2 Announce Type: replace 
Abstract: We present a novel Type II variational principle on the cotangent bundle of a Lie group which enforces Type II boundary conditions, i.e., fixed initial position and final momentum. In general, such Type II variational principles are only globally defined on vector spaces or locally defined on general manifolds; however, by left translation, we are able to define this variational principle globally on cotangent bundles of Lie groups. Type II boundary conditions are particularly important for adjoint sensitivity analysis, which is our motivating application. As such, we additionally discuss adjoint systems on Lie groups, their properties, and how they can be used to solve optimization problems subject to dynamics on Lie groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.03527v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/s10883-025-09730-7</arxiv:DOI>
      <arxiv:journal_reference>J Dyn Control Syst 31, 8 (2025)</arxiv:journal_reference>
      <dc:creator>Brian K. Tran, Melvin Leok</dc:creator>
    </item>
    <item>
      <title>A Physics-Informed Neural Network approach for compartmental epidemiological models</title>
      <link>https://arxiv.org/abs/2311.09944</link>
      <description>arXiv:2311.09944v2 Announce Type: replace 
Abstract: Compartmental models provide simple and efficient tools to analyze the relevant transmission processes during an outbreak, to produce short-term forecasts or transmission scenarios, and to assess the impact of vaccination campaigns. However, their calibration is not straightforward, since many factors contribute to the rapid change of the transmission dynamics during an epidemic. For example, there might be changes in the individual awareness, the imposition of non-pharmacological interventions and the emergence of new variants. As a consequence, model parameters such as the transmission rate are doomed to change in time, making their assessment more challenging. Here, we propose to use Physics-Informed Neural Networks (PINNs) to track the temporal changes in the model parameters and provide an estimate of the model state variables. PINNs recently gained attention in many engineering applications thanks to their ability to consider both the information from data (typically uncertain) and the governing equations of the system. The ability of PINNs to identify unknown model parameters makes them particularly suitable to solve ill-posed inverse problems, such as those arising in the application of epidemiological models. Here, we develop a reduced-split approach for the implementation of PINNs to estimate the temporal changes in the state variables and transmission rate of an epidemic based on the SIR model equation and infectious data. The main idea is to split the training first on the epidemiological data, and then on the residual of the system equations. The proposed method is applied to five synthetic test cases and two real scenarios reproducing the first months of the COVID-19 Italian pandemic. Our results show that the split implementation of PINNs outperforms the standard approach in terms of accuracy (up to one order of magnitude) and computational times (speed up of 20%).</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.09944v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1371/journal.pcbi.1012387</arxiv:DOI>
      <dc:creator>Caterina Millevoi, Damiano Pasetto, Massimiliano Ferronato</dc:creator>
    </item>
    <item>
      <title>Spatio-temporal Lie-Poisson discretization for incompressible magnetohydrodynamics on the sphere</title>
      <link>https://arxiv.org/abs/2311.16045</link>
      <description>arXiv:2311.16045v3 Announce Type: replace 
Abstract: We give a structure preserving spatio-temporal discretization for incompressible magnetohydrodynamics (MHD) on the sphere. Discretization in space is based on the theory of geometric quantization, which yields a spatially discretized analogue of the MHD equations as a finite-dimensional Lie--Poisson system on the dual of the magnetic extension Lie algebra $\mathfrak{f}=\mathfrak{su}(N)\ltimes\mathfrak{su}(N)^{*}$. We also give accompanying structure preserving time discretizations for Lie--Poisson systems on the dual of semi-direct product Lie algebras of the form $\mathfrak{f}=\mathfrak{g}\ltimes\mathfrak{g^{*}}$, where $\mathfrak{g}$ is a $J$-quadratic Lie algebra. The time integration method is free of computationally costly matrix exponentials. We prove that the full method preserves a modified Lie--Poisson structure and corresponding Casimir functions, and that the modified structure and Casimirs converge to the continuous ones. The method is demonstrated for two models of magnetic fluids: incompressible magnetohydrodynamics and Hazeltine's model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.16045v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math-ph</category>
      <category>math.DG</category>
      <category>math.MP</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Klas Modin, Michael Roop</dc:creator>
    </item>
    <item>
      <title>A primal-dual adaptive finite element method for total variation minimization</title>
      <link>https://arxiv.org/abs/2404.03125</link>
      <description>arXiv:2404.03125v2 Announce Type: replace 
Abstract: Based on previous work we extend a primal-dual semi-smooth Newton method for minimizing a general $L^1$-$L^2$-$TV$ functional over the space of functions of bounded variations by adaptivity in a finite element setting. For automatically generating an adaptive grid we introduce indicators based on a-posteriori error estimates. Further we discuss data interpolation methods on unstructured grids in the context of image processing and present a pixel-based interpolation method. The efficiency of our derived adaptive finite element scheme is demonstrated on image inpainting and the task of computing the optical flow in image sequences. In particular, for optical flow estimation we derive an adaptive finite element coarse-to-fine scheme which allows resolving large displacements and speeds-up the computing time significantly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03125v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Martin Alk\"amper, Stephan Hilb, Andreas Langer</dc:creator>
    </item>
    <item>
      <title>A deep learning-based surrogate model for seismic data assimilation in fault activation modeling</title>
      <link>https://arxiv.org/abs/2409.01215</link>
      <description>arXiv:2409.01215v2 Announce Type: replace 
Abstract: Assessing the safety and environmental impacts of subsurface resource exploitation and management is critical and requires robust geomechanical modeling. However, uncertainties stemming from model assumptions, intrinsic variability of governing parameters, and data errors challenge the reliability of predictions. In the absence of direct measurements, inverse modeling and stochastic data assimilation methods can offer reliable solutions, but in complex and large-scale settings, the computational expense can become prohibitive.
  To address these challenges, this paper presents a deep learning-based surrogate model (SurMoDeL) designed for seismic data assimilation in fault activation modeling. The surrogate model leverages neural networks to provide simplified yet accurate representations of complex geophysical systems, enabling faster simulations and analyses essential for uncertainty quantification. The work proposes two different methods to integrate an understanding of fault behavior into the model, thereby enhancing the accuracy of its predictions. The application of the proxy model to integrate seismic data through effective data assimilation techniques efficiently constrains the uncertain parameters, thus bridging the gap between theoretical models and real-world observations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01215v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Caterina Millevoi, Claudia Zoccarato, Massimiliano Ferronato</dc:creator>
    </item>
    <item>
      <title>Transient subtraction: A control variate method for computing transport coefficients</title>
      <link>https://arxiv.org/abs/2410.00212</link>
      <description>arXiv:2410.00212v3 Announce Type: replace 
Abstract: In molecular dynamics, transport coefficients measure the sensitivity of the invariant probability measure of the stochastic dynamics at hand with respect to some perturbation. They are typically computed using either the linear response of nonequilibrium dynamics, or the Green--Kubo formula. The estimators for both approaches have large variances, which motivates the study of variance reduction techniques for computing transport coefficients. We present an alternative approach, called the \emph{transient subtraction technique} (inspired by early work by Ciccotti and Jaccucci in 1975), which amounts to simulating a transient dynamics started off equilibrium and relaxing towards the equilibrium state, from which we subtract a sensibly coupled equilibrium trajectory, resulting in an estimator with smaller variance. We present the mathematical formulation of the transient subtraction technique, give error estimates on the bias and variance of the associated estimator, and demonstrate the relevance of the method through numerical illustrations for various systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.00212v3</guid>
      <category>math.NA</category>
      <category>cond-mat.stat-mech</category>
      <category>cs.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pierre Monmarch\'e, Renato Spacek, Gabriel Stoltz</dc:creator>
    </item>
    <item>
      <title>In search of rogue waves: a novel proposal distribution for parallelized rejection sampling of the truncated KdV Gibbs measure</title>
      <link>https://arxiv.org/abs/2411.16952</link>
      <description>arXiv:2411.16952v2 Announce Type: replace 
Abstract: The Gibbs ensemble of the truncated KdV (TKdV) equation has been shown to accurately describe the anomalous wave statistics observed in laboratory experiments, in particular the emergence of extreme events. Here, we introduce a novel proposal distribution that facilitates efficient rejection sampling of the TKdV Gibbs measure. Within parameter regimes accessible to laboratory experiments and capable of producing extreme events, the proposal distribution generates 1-6 orders of magnitude more accepted samples than does a naive, uniform distribution. When equipped with the new proposal distribution, a simple rejection algorithm enjoys key advantages over a Markov chain Monte Carlo algorithm, include better parallelization properties and generation of uncorrelated samples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16952v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.data-an</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicholas J. Moore, Brendan Foerster</dc:creator>
    </item>
    <item>
      <title>Optimization on product manifolds under a preconditioned metric</title>
      <link>https://arxiv.org/abs/2306.08873</link>
      <description>arXiv:2306.08873v3 Announce Type: replace-cross 
Abstract: Since optimization on Riemannian manifolds relies on the chosen metric, it is appealing to know that how the performance of a Riemannian optimization method varies with different metrics and how to exquisitely construct a metric such that a method can be accelerated. To this end, we propose a general framework for optimization problems on product manifolds endowed with a preconditioned metric, and we develop Riemannian methods under this metric. Generally, the metric is constructed by an operator that aims to approximate the diagonal blocks of the Riemannian Hessian of the cost function. We propose three specific approaches to design the operator: exact block diagonal preconditioning, left and right preconditioning, and Gauss--Newton type preconditioning. Specifically, we tailor new preconditioned metrics and adapt the proposed Riemannian methods to the canonical correlation analysis and the truncated singular value decomposition problems, which provably accelerate the Riemannian methods. Additionally, we adopt the Gauss--Newton type preconditioning to solve the tensor ring completion problem. Numerical results among these applications verify that a delicate metric does accelerate the Riemannian optimization methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.08873v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bin Gao, Renfeng Peng, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Chebyshev approximation and composition of functions in matrix product states for quantum-inspired numerical analysis</title>
      <link>https://arxiv.org/abs/2407.09609</link>
      <description>arXiv:2407.09609v2 Announce Type: replace-cross 
Abstract: This work explores the representation of univariate and multivariate functions as matrix product states (MPS), also known as quantized tensor-trains (QTT). It proposes an algorithm that employs iterative Chebyshev expansions and Clenshaw evaluations to represent analytic and highly differentiable functions as MPS Chebyshev interpolants. It demonstrates rapid convergence for highly-differentiable functions, aligning with theoretical predictions, and generalizes efficiently to multidimensional scenarios. The performance of the algorithm is compared with that of tensor cross-interpolation (TCI) and multiscale interpolative constructions through a comprehensive comparative study. When function evaluation is inexpensive or when the function is not analytical, TCI is generally more efficient for function loading. However, the proposed method shows competitive performance, outperforming TCI in certain multivariate scenarios. Moreover, it shows advantageous scaling rates and generalizes to a wider range of tasks by providing a framework for function composition in MPS, which is useful for non-linear problems and many-body statistical physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09609v2</guid>
      <category>quant-ph</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juan Jos\'e Rodr\'iguez-Aldavero, Paula Garc\'ia-Molina, Luca Tagliacozzo, Juan Jos\'e Garc\'ia-Ripoll</dc:creator>
    </item>
    <item>
      <title>On an inverse tridiagonal eigenvalue problem and its application to synchronization of network motion</title>
      <link>https://arxiv.org/abs/2408.01066</link>
      <description>arXiv:2408.01066v2 Announce Type: replace-cross 
Abstract: In this work, motivated by the study of stability of the synchronous orbit of a network with tridiagonal Laplacian matrix, we first solve an inverse eigenvalue problem which builds a tridiagonal Laplacian matrix with eigenvalues $\lambda_1=0&lt;\lambda_2&lt;\cdots &lt;\lambda_N$ and null-vector $\boldsymbol{e} = \begin{bmatrix} 1 \\ \vdots \\ 1 \end{bmatrix}$. Then, we show how this result can be used to guarantee -- if possible -- that a synchronous orbit of a connected tridiagonal network associated to the matrix $L$ above is asymptotically stable, in the sense of having an associated negative Master Stability Function (MSF). We further show that there are limitations when we also impose symmetry for $L$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.01066v2</guid>
      <category>math.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 19 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Luca Dieci, Cinzia Elia, Alessandro Pugliese</dc:creator>
    </item>
  </channel>
</rss>
