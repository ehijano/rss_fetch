<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 05 Jun 2025 01:38:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Practical Linear Time Algorithm for Optimal Tree Decomposition of Halin Graphs</title>
      <link>https://arxiv.org/abs/2506.02346</link>
      <description>arXiv:2506.02346v1 Announce Type: new 
Abstract: This work proposes \textsc{H-Td}, a practical linear-time algorithm for computing an optimal-width tree decomposition of Halin graphs. Unlike state-of-the-art methods based on reduction rules or separators, \textsc{H-Td} exploits the structural properties of Halin graphs. Although two theoretical linear-time algorithms exist that can be applied to graphs of treewidth three, no practical implementation has been made publicly available. Furthermore, extending reduction-based approaches to partial $k$-trees with $k &gt; 3$ results in increasingly complex rules that are challenging to implement. This motivates the exploration of alternative strategies that leverage structural insights specific to certain graph classes. Experimental validation against the winners of the Parameterized Algorithms and Computational Experiments Challenge (PACE) 2017 and the treewidth library \texttt{libtw} demonstrates the advantage of \textsc{H-Td} when the input is known to be a Halin graph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02346v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>J. A. Alejandro-Soto, Joel Antonio Trejo-Sanchez, Carlos Segura</dc:creator>
    </item>
    <item>
      <title>On the Inversion Modulo a Power of an Integer</title>
      <link>https://arxiv.org/abs/2506.02491</link>
      <description>arXiv:2506.02491v2 Announce Type: new 
Abstract: Recently, Koc proposed a neat and efficient algorithm for computing $x = a^{-1} \pmod {p^k}$ for a prime $p$ based on the exact solution of linear equations using $p$-adic expansions. The algorithm requires only addition and right shift per step. In this paper, we design an algorithm that computes $x = a^{-1} \pmod {n^k}$ for any integer $n&gt;1$. The algorithm has a motivation from the schoolbook multiplication and achieves both efficiency and generality. The greater flexibility of our algorithm is explored by utilizing the build-in arithmetic of computer architecture, e.g., $n=2^{64}$, and experimental results show significant improvements. This paper also contains some results on modular inverse based on an alternative proof of correctness of Koc algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02491v2</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Guangwu Xu, Yunxiao Tian, Bingxin Yang</dc:creator>
    </item>
    <item>
      <title>Cartesian Forest Matching</title>
      <link>https://arxiv.org/abs/2506.02704</link>
      <description>arXiv:2506.02704v1 Announce Type: new 
Abstract: In this paper, we introduce the notion of Cartesian Forest, which generalizes Cartesian Trees, in order to deal with partially ordered sequences. We show that algorithms that solve both exact and approximate Cartesian Tree Matching can be adapted to solve Cartesian Forest Matching in average linear time. We adapt the notion of Cartesian Tree Signature to Cartesian Forests and show how filters can be used to experimentally improve the algorithm for the exact matching. We also show a one to one correspondence between Cartesian Forests and Schr\"oder Trees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02704v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bastien Auvray, Julien David, Richard Groult, Thierry Lecroq</dc:creator>
    </item>
    <item>
      <title>Upper bounds on the theta function of random graphs</title>
      <link>https://arxiv.org/abs/2506.02952</link>
      <description>arXiv:2506.02952v1 Announce Type: new 
Abstract: The theta function of Lovasz is a graph parameter that can be computed up to arbitrary precision in polynomial time. It plays a key role in algorithms that approximate graph parameters such as maximum independent set, maximum clique and chromatic number, or even compute them exactly in some models of random and semi-random graphs. For Erdos-Renyi random $G_{n,1/2}$ graphs, the expected value of the theta function is known to be at most $2\sqrt{n}$ and at least $\sqrt{n}$. These bounds have not been improved in over 40 years.
  In this work, we introduce a new class of polynomial time computable graph parameters, where every parameter in this class is an upper bound on the theta function. We also present heuristic arguments for determining the expected values of parameters from this class in random graphs. The values suggested by these heuristic arguments are in agreement with results that we obtain experimentally, by sampling graphs at random and computing the value of the respective parameter. Based on parameters from this new class, we feel safe in conjecturing that for $G_{n,1/2}$, the expected value of the theta function is below $1.55 \sqrt{n}$. Our paper falls short of rigorously proving such an upper bound, because our analysis makes use of unproven assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02952v1</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Uriel Feige, Vadim Grinberg</dc:creator>
    </item>
    <item>
      <title>GPU-Parallelizable Randomized Sketch-and-Precondition for Linear Regression using Sparse Sign Sketches</title>
      <link>https://arxiv.org/abs/2506.03070</link>
      <description>arXiv:2506.03070v1 Announce Type: new 
Abstract: A litany of theoretical and numerical results have established the sketch-and-precondition paradigm as a powerful approach to solving large linear regression problems in standard computing environments. Perhaps surprisingly, much less work has been done on understanding how sketch-and-precondition performs on graphics processing unit (GPU) systems. We address this gap by benchmarking an implementation of sketch-and-precondition based on sparse sign-sketches on single and multi-GPU systems. In doing so, we describe a novel, easily parallelized, rejection-sampling based method for generating sparse sign sketches. Our approach, which is particularly well-suited for GPUs, is easily adapted to a variety of computing environments. Taken as a whole, our numerical experiments indicate that sketch-and-precondition with sparse sign sketches is particularly well-suited for GPUs, and may be suitable for use in black-box least-squares solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03070v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tyler Chen, Pradeep Niroula, Archan Ray, Pragna Subrahmanya, Marco Pistoia, Niraj Kumar</dc:creator>
    </item>
    <item>
      <title>Labelling Data with Unknown References</title>
      <link>https://arxiv.org/abs/2506.03083</link>
      <description>arXiv:2506.03083v1 Announce Type: new 
Abstract: An evaluator is trustworthy when there exists some agreed-upon way to measure its performance as a labeller. The two ways to establish trustworthiness are either by testing it, or by assuming the evaluator `knows' somehow the way to label the corpus. However, if labelled references (e.g., a development set) are unavailable, neither of these approaches work: the former requires the data, and the latter is an assumption, not evidence. To address this, we introduce an algorithm (the `No-Data Algorithm') by which to establish trust in an evaluator without any existing references. Our algorithm works by successively posing challenges to said evaluator. We show that this is sufficient to establish trustworthiness w.h.p., in such a way that when the evaluator actually knows the way to label the corpus, the No-Data Algorithm accepts its output; and, conversely, flags untrustworthy evaluators when these are unable to prove it. We present formal proofs of correctness and limited experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.03083v1</guid>
      <category>cs.DS</category>
      <category>cs.AI</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Adrian de Wynter</dc:creator>
    </item>
    <item>
      <title>Fairly Wired: Towards Leximin-Optimal Division of Electricity</title>
      <link>https://arxiv.org/abs/2506.02193</link>
      <description>arXiv:2506.02193v1 Announce Type: cross 
Abstract: In many parts of the world - particularly in developing countries - the demand for electricity exceeds the available supply. In such cases, it is impossible to provide electricity to all households simultaneously. This raises a fundamental question: how should electricity be allocated fairly? In this paper, we explore this question through the lens of egalitarianism - a principle that emphasizes equality by prioritizing the welfare of the worst-off households. One natural rule that aligns with this principle is to maximize the egalitarian welfare - the smallest utility across all households. We show that computing such an allocation is NP-hard, even under strong simplifying assumptions. Leximin is a stronger fairness notion that generalizes the egalitarian welfare: it also requires to maximize the smallest utility, but then, subject to that, the second-smallest, then the third, and so on. The hardness results extends directly to leximin as well. Despite this, we present a Fully Polynomial-Time Approximation Scheme (FPTAS) for leximin in the special case where the network connectivity graph is a tree. This means that we can efficiently approximate leximin - and, in particular, the egalitarian welfare - to any desired level of accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02193v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eden Hartman, Dinesh Kumar Baghel, Erel Segal-Halevi</dc:creator>
    </item>
    <item>
      <title>Learning Optimal Posted Prices for a Unit-Demand Buyer</title>
      <link>https://arxiv.org/abs/2506.02284</link>
      <description>arXiv:2506.02284v1 Announce Type: cross 
Abstract: We study the problem of learning the optimal item pricing for a unit-demand buyer with independent item values, and the learner has query access to the buyer's value distributions. We consider two common query models in the literature: the sample access model where the learner can obtain a sample of each item value, and the pricing query model where the learner can set a price for an item and obtain a binary signal on whether the sampled value of the item is greater than our proposed price. In this work, we give nearly tight sample complexity and pricing query complexity of the unit-demand pricing problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02284v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifeng Teng, Yifan Wang</dc:creator>
    </item>
    <item>
      <title>Sensitivity-Aware Density Estimation in Multiple Dimensions</title>
      <link>https://arxiv.org/abs/2506.02323</link>
      <description>arXiv:2506.02323v1 Announce Type: cross 
Abstract: We formulate an optimization problem to estimate probability densities in the context of multidimensional problems that are sampled with uneven probability. It considers detector sensitivity as an heterogeneous density and takes advantage of the computational speed and flexible boundary conditions offered by splines on a grid. We choose to regularize the Hessian of the spline via the nuclear norm to promote sparsity. As a result, the method is spatially adaptive and stable against the choice of the regularization parameter, which plays the role of the bandwidth. We test our computational pipeline on standard densities and provide software. We also present a new approach to PET rebinning as an application of our framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02323v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CE</category>
      <category>cs.DS</category>
      <category>eess.SP</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/TPAMI.2024.3388370</arxiv:DOI>
      <arxiv:journal_reference>IEEE Transactions on Pattern Analysis and Machine Intelligence ( Volume: 46, Issue: 11, November 2024)</arxiv:journal_reference>
      <dc:creator>Aleix Boquet-Pujadas, Pol del Aguila Pla, Michael Unser</dc:creator>
    </item>
    <item>
      <title>The power of mediators: Price of anarchy and stability in Bayesian games with submodular social welfare</title>
      <link>https://arxiv.org/abs/2506.02655</link>
      <description>arXiv:2506.02655v1 Announce Type: cross 
Abstract: This paper investigates the role of mediators in Bayesian games by examining their impact on social welfare through the price of anarchy (PoA) and price of stability (PoS). Mediators can communicate with players to guide them toward equilibria of varying quality, and different communication protocols lead to a variety of equilibrium concepts collectively known as Bayes (coarse) correlated equilibria. To analyze these equilibrium concepts, we consider a general class of Bayesian games with submodular social welfare, which naturally extends valid utility games and their variant, basic utility games. These frameworks, introduced by Vetta (2002), have been developed to analyze the social welfare guarantees of equilibria in games such as competitive facility location, influence maximization, and other resource allocation problems.
  We provide upper and lower bounds on the PoA and PoS for a broad class of Bayes (coarse) correlated equilibria. Central to our analysis is the strategy representability gap, which measures the multiplicative gap between the optimal social welfare achievable with and without knowledge of other players' types. For monotone submodular social welfare functions, we show that this gap is $1-1/\mathrm{e}$ for independent priors and $\Theta(1/\sqrt{n})$ for correlated priors, where $n$ is the number of players. These bounds directly lead to upper and lower bounds on the PoA and PoS for various equilibrium concepts, while we also derive improved bounds for specific concepts by developing smoothness arguments. Notably, we identify a fundamental gap in the PoA and PoS across different classes of Bayes correlated equilibria, highlighting essential distinctions among these concepts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.02655v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kaito Fujii</dc:creator>
    </item>
    <item>
      <title>PECANN: Parallel Efficient Clustering with Graph-Based Approximate Nearest Neighbor Search</title>
      <link>https://arxiv.org/abs/2312.03940</link>
      <description>arXiv:2312.03940v3 Announce Type: replace 
Abstract: This paper studies density-based clustering of point sets. These methods use dense regions of points to detect clusters of arbitrary shapes. In particular, we study variants of density peaks clustering, a popular type of algorithm that has been shown to work well in practice. Our goal is to cluster large high-dimensional datasets, which are prevalent in practice. Prior solutions are either sequential, and cannot scale to large data, or are specialized for low-dimensional data.
  This paper unifies the different variants of density peaks clustering into a single framework, PECANN, by abstracting out several key steps common to this class of algorithms. One such key step is to find nearest neighbors that satisfy a predicate function, and one of the main contributions of this paper is an efficient way to do this predicate search using graph-based approximate nearest neighbor search (ANNS). To provide ample parallelism, we propose a doubling search technique that enables points to find an approximate nearest neighbor satisfying the predicate in a small number of rounds. Our technique can be applied to many existing graph-based ANNS algorithms, which can all be plugged into PECANN.
  We implement five clustering algorithms with PECANN and evaluate them on synthetic and real-world datasets with up to 1.28 million points and up to 1024 dimensions on a 30-core machine with two-way hyper-threading. Compared to the state-of-the-art FASTDP algorithm for high-dimensional density peaks clustering, which is sequential, our best algorithm is 45x-734x faster while achieving competitive ARI scores. Compared to the state-of-the-art parallel DPC-based algorithm, which is optimized for low dimensions, we show that PECANN is two orders of magnitude faster. As far as we know, our work is the first to evaluate DPC variants on large high-dimensional real-world image and text embedding datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.03940v3</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shangdi Yu, Joshua Engels, Yihao Huang, Julian Shun</dc:creator>
    </item>
    <item>
      <title>Distributed Distance Sensitivity Oracles</title>
      <link>https://arxiv.org/abs/2411.13728</link>
      <description>arXiv:2411.13728v3 Announce Type: replace 
Abstract: We present results for the distance sensitivity oracle (DSO) problem, where one needs to preprocess a given directed weighted graph $G=(V,E)$ in order to answer queries about the shortest path distance from $s$ to $t$ in $G$ that avoids edge $e$, for any $s,t \in V, e \in E$. No non-trivial results are known for DSO in the distributed CONGEST model even though it is of importance to maintain efficient communication under an edge failure. We present DSO algorithms with different tradeoffs between preprocessing and query cost -- one that optimizes query response rounds, and another that prioritizes preprocessing rounds. We complement these algorithms with unconditional CONGEST lower bounds. Additionally, we present almost-optimal upper and lower bounds for the related all pairs second simple shortest path (2-APSiSP) problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13728v3</guid>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vignesh Manoharan, Vijaya Ramachandran</dc:creator>
    </item>
    <item>
      <title>Dynamic Consistent $k$-Center Clustering with Optimal Recourse</title>
      <link>https://arxiv.org/abs/2412.03238</link>
      <description>arXiv:2412.03238v3 Announce Type: replace 
Abstract: Given points from an arbitrary metric space and a sequence of point updates sent by an adversary, what is the minimum recourse per update (i.e., the minimum number of changes needed to the set of centers after an update), in order to maintain a constant-factor approximation to a $k$-clustering problem? This question has received attention in recent years under the name consistent clustering.
  Previous works by Lattanzi and Vassilvitskii [ICLM '17] and Fichtenberger, Lattanzi, Norouzi-Fard, and Svensson [SODA '21] studied $k$-clustering objectives, including the $k$-center and the $k$-median objectives, under only point insertions. In this paper we study the $k$-center objective in the fully dynamic setting, where the update is either a point insertion or a point deletion. Before our work, {\L}\k{a}cki, Haeupler, Grunau, Rozho\v{n}, and Jayaram [SODA '24] gave a deterministic fully dynamic constant-factor approximation algorithm for the $k$-center objective with worst-case recourse of $2$ per update.
  In this work, we prove that the $k$-center clustering problem admits optimal recourse bounds by developing a deterministic fully dynamic constant-factor approximation algorithm with worst-case recourse of $1$ per update. Moreover our algorithm performs simple choices based on light data structures, and thus is arguably more direct and faster than the previous one which uses a sophisticated combinatorial structure. Additionally, we develop a new deterministic decremental algorithm and a new deterministic incremental algorithm, both of which maintain a $6$-approximate $k$-center solution with worst-case recourse of $1$ per update. Our incremental algorithm improves over the $8$-approximation algorithm by Charikar, Chekuri, Feder, and Motwani [STOC '97]. Finally, we remark that since all three of our algorithms are deterministic, they work against an adaptive adversary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.03238v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sebastian Forster, Antonis Skarlatos</dc:creator>
    </item>
    <item>
      <title>On the query complexity of sampling from non-log-concave distributions</title>
      <link>https://arxiv.org/abs/2502.06200</link>
      <description>arXiv:2502.06200v3 Announce Type: replace 
Abstract: We study the problem of sampling from a $d$-dimensional distribution with density $p(x)\propto e^{-f(x)}$, which does not necessarily satisfy good isoperimetric conditions.
  Specifically, we show that for any $L,M$ satisfying $LM\ge d\ge 5$, $\epsilon\in \left(0,\frac{1}{32}\right)$, and any algorithm with query accesses to the value of $f(x)$ and $\nabla f(x)$, there exists an $L$-log-smooth distribution with second moment at most $M$ such that the algorithm requires $\left(\frac{LM}{d\epsilon}\right)^{\Omega(d)}$ queries to compute a sample whose distribution is within $\epsilon$ in total variation distance to the target distribution. We complement the lower bound with an algorithm requiring $\left(\frac{LM}{d\epsilon}\right)^{\mathcal{O}(d)}$ queries, thereby characterizing the tight (up to the constant in the exponent) query complexity for sampling from the family of non-log-concave distributions.
  Our results are in sharp contrast with the recent work of Huang et al. (COLT'24), where an algorithm with quasi-polynomial query complexity was proposed for sampling from a non-log-concave distribution when $M=\mathtt{poly}(d)$. Their algorithm works under the stronger condition that all distributions along the trajectory of the Ornstein-Uhlenbeck process, starting from the target distribution, are $\mathcal{O}(1)$-log-smooth. We investigate this condition and prove that it is strictly stronger than requiring the target distribution to be $\mathcal O(1)$-log-smooth. Additionally, we study this condition in the context of mixtures of Gaussians.
  Finally, we place our results within the broader theme of ``sampling versus optimization'', as studied in Ma et al. (PNAS'19). We show that for a wide range of parameters, sampling is strictly easier than optimization by a super-exponential factor in the dimension $d$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.06200v3</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yuchen He, Chihao Zhang</dc:creator>
    </item>
    <item>
      <title>Algorithms for the Diverse-k-SAT problem: the geometry of satisfying assignments</title>
      <link>https://arxiv.org/abs/2408.03465</link>
      <description>arXiv:2408.03465v2 Announce Type: replace-cross 
Abstract: Given a $k$-CNF formula and an integer $s$, we study algorithms that obtain $s$ solutions to the formula that are maximally dispersed. For $s=2$, the problem of computing the diameter of a $k$-CNF formula was initiated by Creszenzi and Rossi, who showed strong hardness results even for $k=2$. Assuming SETH, the current best upper bound [Angelsmark and Thapper '04] goes to $4^n$ as $k \rightarrow \infty$. As our first result, we give exact algorithms for using the Fast Fourier Transform and clique-finding that run in $O^*(2^{(s-1)n})$ and $O^*(s^2 |\Omega_{F}|^{\omega \lceil s/3 \rceil})$ respectively, where $|\Omega_{F}|$ is the size of the solution space of the formula $F$ and $\omega$ is the matrix multiplication exponent.
  As our main result, we re-analyze the popular PPZ (Paturi, Pudlak, Zane '97) and Sch\"{o}ning's ('02) algorithms (which find one solution in time $O^*(2^{\varepsilon_{k}n})$ for $\varepsilon_{k} \approx 1-\Theta(1/k)$), and show that in the same time, they can be used to approximate the diameter as well as the dispersion ($s&gt;2$) problems. While we need to modify Sch\"{o}ning's original algorithm, we show that the PPZ algorithm, without any modification, samples solutions in a geometric sense. We believe that this property may be of independent interest.
  Finally, we present algorithms to output approximately diverse, approximately optimal solutions to NP-complete optimization problems running in time $\text{poly}(s)O^*(2^{\varepsilon n})$ with $\varepsilon&lt;1$ for several problems such as Minimum Hitting Set and Feedback Vertex Set. For these problems, all existing exact methods for finding optimal diverse solutions have a runtime with at least an exponential dependence on the number of solutions $s$. Our methods find bi-approximations with polynomial dependence on $s$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.03465v2</guid>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Per Austrin, Ioana O. Bercea, Mayank Goswami, Nutan Limaye, Adarsh Srinivasan</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Newsvendor on a Metric</title>
      <link>https://arxiv.org/abs/2410.12134</link>
      <description>arXiv:2410.12134v2 Announce Type: replace-cross 
Abstract: We consider a fundamental generalization of the classical newsvendor problem where the seller needs to decide on the inventory of a product jointly for multiple locations on a metric as well as a fulfillment policy to satisfy the uncertain demand that arises sequentially over time after the inventory decisions have been made. To address the distributional ambiguity, we consider a distributionally robust setting where the decision-maker only knows the mean and variance of the demand, and the goal is to make inventory and fulfillment decisions to minimize the worst-case expected inventory and fulfillment cost. We design a near-optimal policy for the problem with theoretical guarantees on its performance. Our policy generalizes the classical solution of Scarf (1957), maintaining its simplicity and interpretability: it identifies a hierarchical set of clusters, assigns a ``virtual" underage cost to each cluster, then makes sure that each cluster holds at least the inventory suggested by Scarf's solution if the cluster behaved as a single point with ``virtual" underage cost. As demand arrives sequentially, our policy fulfills orders from nearby clusters, minimizing fulfilment costs, while balancing inventory consumption across the clusters to avoid depleting any single one. We show that the policy achieves a poly-logarithmic approximation. To the best of our knowledge, this is the first algorithm with provable performance guarantees. Furthermore, our numerical experiments show that the policy performs well in practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12134v2</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ayoub Foussoul, Vineet Goyal</dc:creator>
    </item>
    <item>
      <title>Improved Margin Generalization Bounds for Voting Classifiers</title>
      <link>https://arxiv.org/abs/2502.16462</link>
      <description>arXiv:2502.16462v2 Announce Type: replace-cross 
Abstract: In this paper we establish a new margin-based generalization bound for voting classifiers, refining existing results and yielding tighter generalization guarantees for widely used boosting algorithms such as AdaBoost (Freund and Schapire, 1997). Furthermore, the new margin-based generalization bound enables the derivation of an optimal weak-to-strong learner: a Majority-of-3 large-margin classifiers with an expected error matching the theoretical lower bound. This result provides a more natural alternative to the Majority-of-5 algorithm by (H{\o}gsgaard et al., 2024), and matches the Majority-of-3 result by (Aden-Ali et al., 2024) for the realizable prediction model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16462v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Wed, 04 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikael M{\o}ller H{\o}gsgaard, Kasper Green Larsen</dc:creator>
    </item>
  </channel>
</rss>
