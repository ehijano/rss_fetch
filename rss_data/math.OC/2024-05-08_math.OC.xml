<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 08 May 2024 04:00:41 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 08 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Measurized Discounted Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2405.03888</link>
      <description>arXiv:2405.03888v1 Announce Type: new 
Abstract: In this paper, we build a framework that facilitates the analysis of discounted infinite horizon Markov Decision Processes (MDPs) by visualizing them as deterministic processes where the states are probability measures on the original state space and the actions are stochastic kernels on the original action space. We provide a simple general algebraic approach to lifting any MDP to this space of measures; we call this to measurize the original stochastic MDP. We show that measurized MDPs are in fact a generalization of stochastic MDPs, thus the measurized framework can be deployed without loss of fidelity. Lifting an MDP can be convenient because the measurized framework enables constraints and value function approximations that are not easily available from the standard MDP setting. For instance, one can add restrictions or build approximations based on moments, quantiles, risk measures, etc. Moreover, since the measurized counterpart to any MDP is deterministic, the measurized optimality equations trade the complexity of dealing with the expected value function that appears in the stochastic optimality equations with a more complex state space.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03888v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Adelman, Alba V. Olivares-Nadal</dc:creator>
    </item>
    <item>
      <title>Generalized Nash equilibrium problems with quasi-linear constraints</title>
      <link>https://arxiv.org/abs/2405.03926</link>
      <description>arXiv:2405.03926v1 Announce Type: new 
Abstract: We study generalized Nash equilibrium problems (GNEPs) such that objectives are polynomial functions, and each player's constraints are linear in their own strategy. For such GNEPs, the KKT sets can be represented as unions of simpler sets by Carath\'{e}odory's theorem. We give a convenient representation for KKT sets using partial Lagrange multiplier expressions. This produces a set of branch polynomial optimization problems, which can be efficiently solved by Moment-SOS relaxations. By doing this, we can compute all generalized Nash equilibria or detect their nonexistence. Numerical experiments are also provided to demonstrate the computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03926v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiyoung Choi, Jiawang Nie, Xindong Tang, Suhan Zhong</dc:creator>
    </item>
    <item>
      <title>Subdifferentially polynomially bounded functions and Gaussian smoothing-based zeroth-order optimization</title>
      <link>https://arxiv.org/abs/2405.04150</link>
      <description>arXiv:2405.04150v1 Announce Type: new 
Abstract: We introduce the class of subdifferentially polynomially bounded (SPB) functions, which is a rich class of locally Lipschitz functions that encompasses all Lipschitz functions, all gradient- or Hessian-Lipschitz functions, and even some non-smooth locally Lipschitz functions. We show that SPB functions are compatible with Gaussian smoothing (GS), in the sense that the GS of any SPB function is well-defined and satisfies a descent lemma akin to gradient-Lipschitz functions, with the Lipschitz constant replaced by a polynomial function. Leveraging this descent lemma, we propose GS-based zeroth-order optimization algorithms with an adaptive stepsize strategy for constrained minimization of SPB functions, and analyze their iteration complexity. An important instrument in our analysis, which could be of independent interest, is the quantification of Goldstein stationarity via the GS gradient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04150v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Lei, Ting Kei Pong, Shuqin Sun, Man-Chung Yue</dc:creator>
    </item>
    <item>
      <title>An efficient active-set method with applications to sparse approximations and risk minimization</title>
      <link>https://arxiv.org/abs/2405.04172</link>
      <description>arXiv:2405.04172v1 Announce Type: new 
Abstract: In this paper we present an efficient active-set method for the solution of convex quadratic programming problems with general piecewise-linear terms in the objective, with applications to sparse approximations and risk-minimization. The algorithm is derived by combining a proximal method of multipliers (PMM) with a standard semismooth Newton method (SSN), and is shown to be globally convergent under minimal assumptions. Further local linear (and potentially superlinear) convergence is shown under standard additional conditions. The major computational bottleneck of the proposed approach arises from the solution of the associated SSN linear systems. These are solved using a Krylov-subspace method, accelerated by certain novel general-purpose preconditioners which are shown to be optimal with respect to the proximal penalty parameters. The preconditioners are easy to store and invert, since they exploit the structure of the nonsmooth terms appearing in the problem's objective to significantly reduce their memory requirements. We showcase the efficiency, robustness, and scalability of the proposed solver on a variety of problems arising in risk-averse portfolio selection, $L^1$-regularized partial differential equation constrained optimization, quantile regression, and binary classification via linear support vector machines. We provide computational evidence, on real-world datasets, to demonstrate the ability of the solver to efficiently and competitively handle a diverse set of medium- and large-scale optimization instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04172v1</guid>
      <category>math.OC</category>
      <category>cs.MS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Spyridon Pougkakiotis, Jacek Gondzio, Dionysis Kalogerias</dc:creator>
    </item>
    <item>
      <title>Control in the coefficients of an elliptic differential operator: topological derivatives and Pontryagin maximum principle</title>
      <link>https://arxiv.org/abs/2405.04204</link>
      <description>arXiv:2405.04204v1 Announce Type: new 
Abstract: We consider optimal control problems, where the control appears in the main part of the operator. We derive the Pontryagin maximum principle as a necessary optimality condition. The proof uses the concept of topological derivatives. In contrast to earlier works, we do not need continuity assumptions for the coefficient or gradients of solutions of partial differential equations. Following classical proofs, we consider perturbations of optimal controls by multiples of characteristic functions of sets, whose scaling factor is send to zero. For $2d$ problems, we can perform an optimization over the elliptic shapes of such sets leading to stronger optimality conditions involving a variational inequality of a new type.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04204v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Wachsmuth</dc:creator>
    </item>
    <item>
      <title>Deck of Cards method for Hierarchical, Robust and Stochastic Ordinal Regression</title>
      <link>https://arxiv.org/abs/2405.04313</link>
      <description>arXiv:2405.04313v1 Announce Type: new 
Abstract: In this paper, we consider the recently introduced application of the Deck of Cards Method (DCM) to ordinal regression proposing an extension to Robust Ordinal Regression and Stochastic Multiattribute Acceptability Analysis. In Multiple Criteria Decision Aiding context, the proposed methodology permits to assign a value to each alternative evaluated on a set of criteria hierarchically structured. The Decision Maker can provide precise or imprecise information at different levels of the hierarchy of criteria using the classical DCM framework. This information is therefore used to infer a value function compatible with it. The compatible value function can be a simple weighted sum, a piecewise linear value function, a general monotonic value function, or a Choquet integral. To provide robust recommendations to the Decision Maker, we consider the Robust Ordinal Regression and the Stochastic Multicriteria Acceptability Analysis because, even if in different ways, both of them take into account the whole set of models compatible with the preference information provided by the Decision Maker. The applicability of the proposed methodology is shown by a didactic example in which Italian regions are evaluated on criteria representing Circular Economy, Innovation Driven Development and Smart Specialization Strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04313v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Salvatore Corrente, Salvatore Greco, Silvano Zappal\'a</dc:creator>
    </item>
    <item>
      <title>Packings of Smoothed Polygons</title>
      <link>https://arxiv.org/abs/2405.04331</link>
      <description>arXiv:2405.04331v1 Announce Type: new 
Abstract: This book uses optimal control theory to prove that the most unpackable centrally symmetric convex disk in the plane is a smoothed polygon. A smoothed polygon is a polygon whose corners have been rounded in a special way by arcs of hyperbolas. To be highly unpackable means that even densest packing of that disk has low density.
  Motivated by Minkowski's geometry of numbers, researchers began to search for the most unpackable centrally symmetric convex disk (in brief, the most unpackable disk) starting in the early 1920s. In 1934, Reinhardt conjectured that the most unpackable disk is a smoothed octagon. Working independently of Reinhardt, Mahler attempted without success in 1947 to prove that the most unpackable disk must be a smoothed polygon. This book proves what Mahler set out to prove: Mahler's First conjecture on smoothed polygons. His second conjecture is identical to the Reinhardt conjecture, which remains open.
  This book explores the many remarkable structures of this packing problem, formulated as a problem in optimal control theory on a Lie group, with connections to hyperbolic geometry and Hamiltonian mechanics. Bang-bang Pontryagin extremals to the optimal control problem are smoothed polygons. Extreme difficulties arise in the proof because of chattering behavior in the optimal control problem, corresponding to possible smoothed polygons with infinitely many sides that need to be ruled out. To analyze and eliminate the possibility of chattering solutions, the book introduces a discrete dynamical system (the Poincare first recurrence map) and gives a full description of its fixed points, stable and unstable manifolds, and basin of attraction on a blowup centered at a singular set. Some proofs in this book are computer-assisted using a computer algebra system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04331v1</guid>
      <category>math.OC</category>
      <category>math.MG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thomas Hales, Koundinya Vajjha</dc:creator>
    </item>
    <item>
      <title>Decision-Dependent Uncertainty-Aware Distribution System Planning Under Wildfire Risk</title>
      <link>https://arxiv.org/abs/2405.04350</link>
      <description>arXiv:2405.04350v1 Announce Type: new 
Abstract: The interaction between power systems and wildfires can be dangerous and costly. Damaged structures, load shedding, and high operational costs are potential consequences when the grid is unprepared. In fact, the operation of distribution grids can be liable for the outbreak of wildfires when extreme weather conditions arise. Within this context, investment planning should consider the impact of operational actions on the uncertainty related to wildfires that can directly affect line failure likelihood. Neglecting this can compromise the cost-benefit evaluation in planning system investments for wildfire risk. In this paper, we propose a decision-dependent uncertainty (DDU) aware methodology that provides the optimal portfolio of investments for distribution systems while considering that high power-flow levels through line segments in high-threat areas can ignite wildfires and, therefore, increase the probability of line failures. The methodology identifies the best combination of system upgrades (installation of new lines, hardening existing lines, and placement of switching devices) to provide the necessary leeway to operate the distribution system under wildfire-prone conditions. Our case study demonstrates that by modeling the DDU relationship between power flow prescriptions and line failures, investment decisions are more accurate and better prepare the grid infrastructure to deal with wildfire risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04350v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Pianc\'o, Alexandre Moreira, Bruno Fanzeres, Ruiwei Jiang, Chaoyue Zhao, Miguel Heleno</dc:creator>
    </item>
    <item>
      <title>Preserving Nonlinear Constraints in Variational Flow Filtering Data Assimilation</title>
      <link>https://arxiv.org/abs/2405.04380</link>
      <description>arXiv:2405.04380v1 Announce Type: new 
Abstract: Data assimilation aims to estimate the states of a dynamical system by optimally combining sparse and noisy observations of the physical system with uncertain forecasts produced by a computational model. The states of many dynamical systems of interest obey nonlinear physical constraints, and the corresponding dynamics is confined to a certain sub-manifold of the state space. Standard data assimilation techniques applied to such systems yield posterior states lying outside the manifold, violating the physical constraints. This work focuses on particle flow filters which use stochastic differential equations to evolve state samples from a prior distribution to samples from an observation-informed posterior distribution. The variational Fokker-Planck (VFP) -- a generic particle flow filtering framework -- is extended to incorporate non-linear, equality state constraints in the analysis. To this end, two algorithmic approaches that modify the VFP stochastic differential equation are discussed: (i) VFPSTAB, to inexactly preserve constraints with the addition of a stabilizing drift term, and (ii) VFPDAE, to exactly preserve constraints by treating the VFP dynamics as a stochastic differential-algebraic equation (SDAE). Additionally, an implicit-explicit time integrator is developed to evolve the VFPDAE dynamics. The strength of the proposed approach for constraint preservation in data assimilation is demonstrated on three test problems: the double pendulum, Korteweg-de-Vries, and the incompressible Navier-Stokes equations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04380v1</guid>
      <category>math.OC</category>
      <category>cs.CE</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amit N. Subrahmanya, Andrey A. Popov, Reid J. Gomillion, Adrian Sandu</dc:creator>
    </item>
    <item>
      <title>On Bias and Its Reduction via Standardization in Source Localization Problems</title>
      <link>https://arxiv.org/abs/2405.04409</link>
      <description>arXiv:2405.04409v1 Announce Type: new 
Abstract: In source localization problems, the aim is to locate the sources within a domain that causes given measurements on the boundary. In this type of problem, biasing of the solution is one of the main causes of mislocalization. A technique called standardization was developed to reduce biasing. However, the lack of a mathematical background for this method can cause difficulties in its application and confusion regarding the reliability of solutions. Here, we give a rigorous and generalized background for the technique using the Bayesian framework to shed light on the technique's abilities and limitations. In addition, we take a look at the noise robustness of the method that is widely reported in numerical studies. The paper starts by giving a gentle introduction to the problem and its bias and works its way toward standardization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04409v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Joonas Lahtinen</dc:creator>
    </item>
    <item>
      <title>Provable Preconditioned Plug-and-Play Approach for Compressed Sensing MRI Reconstruction</title>
      <link>https://arxiv.org/abs/2405.03854</link>
      <description>arXiv:2405.03854v1 Announce Type: cross 
Abstract: Model-based methods play a key role in the reconstruction of compressed sensing (CS) MRI. Finding an effective prior to describe the statistical distribution of the image family of interest is crucial for model-based methods. Plug-and-play (PnP) is a general framework that uses denoising algorithms as the prior or regularizer. Recent work showed that PnP methods with denoisers based on pretrained convolutional neural networks outperform other classical regularizers in CS MRI reconstruction. However, the numerical solvers for PnP can be slow for CS MRI reconstruction. This paper proposes a preconditioned PnP (P^2nP) method to accelerate the convergence speed. Moreover, we provide proofs of the fixed-point convergence of the P^2nP iterates. Numerical experiments on CS MRI reconstruction with non-Cartesian sampling trajectories illustrate the effectiveness and efficiency of the P^2nP approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03854v1</guid>
      <category>eess.IV</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Hong, Xiaojian Xu, Jason Hu, Jeffrey A. Fessler</dc:creator>
    </item>
    <item>
      <title>An Improved Finite-time Analysis of Temporal Difference Learning with Deep Neural Networks</title>
      <link>https://arxiv.org/abs/2405.04017</link>
      <description>arXiv:2405.04017v1 Announce Type: cross 
Abstract: Temporal difference (TD) learning algorithms with neural network function parameterization have well-established empirical success in many practical large-scale reinforcement learning tasks. However, theoretical understanding of these algorithms remains challenging due to the nonlinearity of the action-value approximation. In this paper, we develop an improved non-asymptotic analysis of the neural TD method with a general $L$-layer neural network. New proof techniques are developed and an improved new $\tilde{\mathcal{O}}(\epsilon^{-1})$ sample complexity is derived. To our best knowledge, this is the first finite-time analysis of neural TD that achieves an $\tilde{\mathcal{O}}(\epsilon^{-1})$ complexity under the Markovian sampling, as opposed to the best known $\tilde{\mathcal{O}}(\epsilon^{-2})$ complexity in the existing literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04017v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhifa Ke, Zaiwen Wen, Junyu Zhang</dc:creator>
    </item>
    <item>
      <title>Variance-Reduced Accelerated First-order Methods: Central Limit Theorems and Confidence Statements</title>
      <link>https://arxiv.org/abs/2006.07769</link>
      <description>arXiv:2006.07769v3 Announce Type: replace 
Abstract: In this paper, we study a stochastic strongly convex optimization problem and propose three classes of variable sample-size stochastic first-order methods including the standard stochastic gradient descent method, its accelerated variant, and the stochastic heavy ball method. In the iterates of each scheme, the unavailable exact gradients are approximated by averaging across an increasing batch size of sampled gradients. We prove that when the sample-size increases geometrically, the generated estimates converge in mean to the optimal solution at a geometric rate. Based on this result, we provide a unified framework to show that the rescaled estimation errors converge in distribution to a normal distribution, in which the covariance matrix depends on the Hessian matrix, covariance of the gradient noise, and the steplength. If the sample-size increases at a polynomial rate, we show that the estimation errors decay at the corresponding polynomial rate and establish the corresponding central limit theorems (CLTs). Finally, we provide an avenue to construct confidence regions for the optimal solution based on the established CLTs, and test the theoretic findings on a stochastic parameter estimation problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2006.07769v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jinlong Lei, Uday V. Shanbhag</dc:creator>
    </item>
    <item>
      <title>Projective splitting with backward, half-forward and proximal-Newton steps</title>
      <link>https://arxiv.org/abs/2208.10680</link>
      <description>arXiv:2208.10680v2 Announce Type: replace 
Abstract: We propose and study the weak convergence of a projective splitting algorithm for solving multi-term composite monotone inclusion problems involving the finite sum of $n$ maximal monotone operators, each of which having an inner four-block structure: sum of maximal monotone, Lipschitz continuous, cocoercive and smooth differentiable operators. We show how to perform backward and half-forward steps with respect to the maximal monotone and Lipschitz$+$cocoercive components, respectively, while performing proximal-Newton steps with respect to smooth differentiable blocks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2208.10680v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. Marques Alves</dc:creator>
    </item>
    <item>
      <title>A Neural Network Approach for Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2209.13104</link>
      <description>arXiv:2209.13104v3 Announce Type: replace 
Abstract: We present a neural network approach for approximating the value function of high-dimensional stochastic control problems. Our training process simultaneously updates our value function estimate and identifies the part of the state space likely to be visited by optimal trajectories. Our approach leverages insights from optimal control theory and the fundamental relation between semi-linear parabolic partial differential equations and forward-backward stochastic differential equations. To focus the sampling on relevant states during neural network training, we use the stochastic Pontryagin maximum principle (PMP) to obtain the optimal controls for the current value function estimate. By design, our approach coincides with the method of characteristics for the non-viscous Hamilton-Jacobi-Bellman equation arising in deterministic control problems. Our training loss consists of a weighted sum of the objective functional of the control problem and penalty terms that enforce the HJB equations along the sampled trajectories. Importantly, training is unsupervised in that it does not require solutions of the control problem.
  Our numerical experiments highlight our scheme's ability to identify the relevant parts of the state space and produce meaningful value estimates. Using a two-dimensional model problem, we demonstrate the importance of the stochastic PMP to inform the sampling and compare to a finite element approach. With a nonlinear control affine quadcopter example, we illustrate that our approach can handle complicated dynamics. For a 100-dimensional benchmark problem, we demonstrate that our approach improves accuracy and time-to-solution and, via a modification, we show the wider applicability of our scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.13104v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xingjian Li, Deepanshu Verma, Lars Ruthotto</dc:creator>
    </item>
    <item>
      <title>Reoptimization Nearly Solves Weakly Coupled Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2211.01961</link>
      <description>arXiv:2211.01961v2 Announce Type: replace 
Abstract: We propose a new policy, called the LP-update policy, to solve finite horizon weakly-coupled Markov decision processes. The latter can be seen as multi-constraint multi-action bandits, and generalize the classical restless bandit problems. Our solution is based on re-solving periodically a relaxed version of the original problem, that can be cast as a linear program (LP). When the problem is made of $N$ statistically identical sub-components, we show that the LP-update policy becomes asymptotically optimal at rate $O(T^2/\sqrt{N})$. This rate can be improved to $O(T/\sqrt{N})$ if the problem satisfies some ergodicity property and to $O(1/N)$ if the problem is non-degenerate. The definition of non-degeneracy extends the same notion for restless bandits. By using this property, we also improve the computational efficiency of the LP-update policy. We illustrate the performance of our policy on randomly generated examples, as well as a generalized applicant screening problem, and show that it outperforms existing heuristics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01961v2</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nicolas Gast, Bruno Gaujal, Chen Yan</dc:creator>
    </item>
    <item>
      <title>A Homogeneous Second-Order Descent Method for Nonconvex Optimization</title>
      <link>https://arxiv.org/abs/2211.08212</link>
      <description>arXiv:2211.08212v5 Announce Type: replace 
Abstract: In this paper, we introduce a Homogeneous Second-Order Descent Method (HSODM) using the homogenized quadratic approximation to the original function. The merit of homogenization is that only the leftmost eigenvector of a gradient-Hessian integrated matrix is computed at each iteration. Therefore, the algorithm is a single-loop method that does not need to switch to other sophisticated algorithms and is easy to implement. We show that HSODM has a global convergence rate of $O(\epsilon^{-3/2})$ to find an $\epsilon$-approximate second-order stationary point, and has a local quadratic convergence rate under the standard assumptions. The numerical results demonstrate the advantage of the proposed method over other second-order methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.08212v5</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Chuwen Zhang, Dongdong Ge, Chang He, Bo Jiang, Yuntian Jiang, Chenyu Xue, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Yuille-Poggio's Flow and Global Minimizer of Polynomials through Convexification by Heat Evolution</title>
      <link>https://arxiv.org/abs/2301.00326</link>
      <description>arXiv:2301.00326v2 Announce Type: replace 
Abstract: This study examines the convexification version of the backward differential flow algorithm for the global minimization of polynomials, introduced by O. Arikan \textit{et al} in \cite{ABK}. It investigates why this approach might fail with high-degree polynomials yet succeeds with quartic polynomials. We employ the heat evolution method for convexification combined with Gaussian filtering, which acts as a cumulative form of Steklov's regularization. In this context, we apply the fingerprint theory from computer vision. Originally developed by A.L. Yuille and T. Poggio in the 1980s for computer vision, the fingerprint theory, particularly the fingerprint trajectory equation, is used to illustrate the scaling (temporal) evolution of minimizers. In the case of general polynomials, our research has led to the creation of the Yuille-Poggio flow and a broader interpretation of the fingerprint concepts, in particular we establish the condition both sufficient and necessary for the convexified backward differential flow algorithms to successfully achieve global minimization. For quartic polynomials, our analysis not only reflects the results of O. Arikan et al. \cite{ABK} but also presents a significantly simpler version of Newton's method that can always globally minimize quartic polynomials without convexification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2301.00326v2</guid>
      <category>math.OC</category>
      <category>cs.CV</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiao Wang</dc:creator>
    </item>
    <item>
      <title>Unifying Chance-Constrained and Robust Optimal Power Flow for Resilient Network Operations</title>
      <link>https://arxiv.org/abs/2303.05412</link>
      <description>arXiv:2303.05412v2 Announce Type: replace 
Abstract: Uncertainty in renewable energy generation has the potential to adversely impact the operation of electric networks. Numerous approaches to manage this impact have been proposed, ranging from stochastic and chance-constrained programming to robust optimization. However, these approaches either tend to be conservative or leave the system vulnerable to low probability, high impact uncertainty realizations. To address this issue, we propose a new formulation for stochastic optimal power flow that explicitly distinguishes between "normal operation", in which automatic generation control (AGC) is sufficient to guarantee system security, and "adverse operation", in which the system operator is required to take additional actions, e.g., manual reserve deployment. The new formulation has been compared with the classical ones in a case study on the IEEE-118 and IEEE-300 bus systems. We observe that our consideration of extreme scenarios enables solutions that are more secure than typical chance-constrained formulations, yet less costly than solutions that guarantee robust feasibility with only AGC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.05412v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>\'Alvaro Porras, Line Roald, Juan Miguel Morales, Salvador Pineda</dc:creator>
    </item>
    <item>
      <title>Completely mixed linear games and irreducibility concepts for Z-transformations over self-dual cones</title>
      <link>https://arxiv.org/abs/2310.13464</link>
      <description>arXiv:2310.13464v2 Announce Type: replace 
Abstract: In the setting of a self-dual cone in a finite-dimensional inner product space, we consider (zero-sum) linear games. In our previous work, we showed that a Z-transformation with positive value is completely mixed. The present paper considers the case when the value is zero. Motivated by the matrix game result that a Z-matrix with value zero is completely mixed if and only if it is irreducible, we formulate our general results based on the concepts of cone-irreducibility and space-irreducibility. While the concept of cone-irreducibility for a positive linear transformation is well-known, we introduce space-irreducibility for a general linear transformation by reformulating the irreducibility concept of Elsner. Our main result is that for a Z-transformation with value zero, space-irreducibility is necessary and sufficient for the completely mixed property. We also extend a recent result of Parthasarathy et al. on matrix games with value zero to the setting of a symmetric cone (in a Euclidean Jordan algebra). Additionally, we present a refined cone/space-irreducibility result for positive transformations on symmetric cones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.13464v2</guid>
      <category>math.OC</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Muddappa Seetharama Gowda</dc:creator>
    </item>
    <item>
      <title>Identification of High-dimensional ARMA Models with Binary-Valued Observations</title>
      <link>https://arxiv.org/abs/2404.01613</link>
      <description>arXiv:2404.01613v3 Announce Type: replace 
Abstract: This paper studies system identification of high-dimensional ARMA models with binary-valued observations. Compared with existing quantized identification of ARMA models, this problem is more challenging since the accessible information is much less. Different from the identification of FIR models with binary-valued observations, the prediction of original system output and the parameter both need to be estimated in ARMA models. We propose an online identification algorithm consisting of parameter estimation and prediction of original system output. The parameter estimation and the prediction of original output are strongly coupled but mutually reinforcing. By analyzing the two estimates at the same time instead of analyzing separately, we finally prove that the parameter estimate can converge to the true parameter with convergence rate $O(1/k)$ under certain conditions. Simulations are given to demonstrate the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.01613v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Li, Ting Wang, Jin Guo, Yanlong Zhao</dc:creator>
    </item>
    <item>
      <title>A decomposition-based approach for large-scale pickup and delivery problems</title>
      <link>https://arxiv.org/abs/2405.00230</link>
      <description>arXiv:2405.00230v2 Announce Type: replace 
Abstract: With the advent of self-driving cars, experts envision autonomous mobility-on-demand services in the near future to cope with overloaded transportation systems in cities worldwide. Efficient operations are imperative to unlock such a system's maximum improvement potential. Existing approaches either consider a narrow planning horizon or ignore essential characteristics of the underlying problem. In this paper, we develop an algorithmic framework that allows the study of very large-scale pickup and delivery routing problems with more than 20 thousand requests, which arise in the context of integrated request pooling and vehicle-to-request dispatching. We conduct a computational study and present comparative results showing the characteristics of the developed approaches. Furthermore, we apply our algorithm to related benchmark instances from the literature to show the efficacy. Finally, we solve very large-scale instances and derive insights on upper-bound improvements regarding fleet sizing and customer delay acceptance from a practical perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00230v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>G. Hiermann, M. Schiffer</dc:creator>
    </item>
    <item>
      <title>General Procedure to Provide High-Probability Guarantees for Stochastic Saddle Point Problems</title>
      <link>https://arxiv.org/abs/2405.03219</link>
      <description>arXiv:2405.03219v2 Announce Type: replace 
Abstract: This paper considers smooth strongly convex and strongly concave (SC-SC) stochastic saddle point (SSP) problems. Suppose there is an arbitrary oracle that in expectation returns an $\epsilon$-solution in the sense of certain gaps, which can be the duality gap or its weaker variants. We propose a general PB-SSP framework to guarantee an $\epsilon$ small duality gap solution with high probability via only $\mathcal{O}\big(\log \frac{1}{p}\cdot\text{poly}(\log \kappa)\big)$ calls of this oracle, where $p\in(0,1)$ is the confidence level and $\kappa$ is the condition number. When applied to the sample average approximation (SAA) oracle, in addition to equipping the solution with high probability, our approach even improves the sample complexity by a factor of $\text{poly}(\kappa)$, since the high-probability argument enables us to circumvent some key difficulties of the uniform stability analysis of SAA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.03219v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dongyang Li, Haobin Li, Junyu Zhang</dc:creator>
    </item>
    <item>
      <title>Continuity, Uniqueness and Long-Term Behavior of Nash Flows Over Time</title>
      <link>https://arxiv.org/abs/2111.06877</link>
      <description>arXiv:2111.06877v2 Announce Type: replace-cross 
Abstract: We consider a dynamic model of traffic that has received a lot of attention in the past few years. Users control infinitesimal flow particles aiming to travel from an origin to a destination as quickly as possible. Flow patterns vary over time, and congestion effects are modeled via queues, which form whenever the inflow into a link exceeds its capacity. Despite lots of interest, some very basic questions remain open in this model. We resolve a number of them:
  - We show uniqueness of journey times in equilibria.
  - We show continuity of equilibria: small perturbations to the instance or to the traffic situation at some moment cannot lead to wildly different equilibrium evolutions.
  - We demonstrate that, assuming constant inflow into the network at the source, equilibria always settle down into a "steady state" in which the behavior extends forever in a linear fashion.
  One of our main conceptual contributions is to show that the answer to the first two questions, on uniqueness and continuity, are intimately connected to the third. To resolve the third question, we substantially extend the approach of Cominetti et al., who show a steady-state result in the regime where the input flow rate is smaller than the network capacity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2111.06877v2</guid>
      <category>cs.GT</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/FOCS52979.2021.00087</arxiv:DOI>
      <dc:creator>Neil Olver, Leon Sering, Laura Vargas Koch</dc:creator>
    </item>
    <item>
      <title>Density Stabilization Strategies for Nonholonomic Agents on Compact Manifolds</title>
      <link>https://arxiv.org/abs/2308.15755</link>
      <description>arXiv:2308.15755v2 Announce Type: replace-cross 
Abstract: In this article, we consider the problem of stabilizing stochastic processes, which are constrained to a bounded Euclidean domain or a compact smooth manifold, to a given target probability density. Most existing works on modeling and control of robotic swarms that use PDE models assume that the robots' dynamics are holonomic, and hence, the associated stochastic processes have generators that are elliptic. We relax this assumption on the ellipticity of the generator of the stochastic processes, and consider the more practical case of the stabilization problem for a swarm of agents whose dynamics are given by a controllable driftless control-affine system. We construct state-feedback control laws that exponentially stabilize a swarm of nonholonomic agents to a target probability density that is sufficiently regular. State-feedback laws can stabilize a swarm only to target probability densities that are positive everywhere. To stabilize the swarm to probability densities that possibly have disconnected supports, we introduce a semilinear PDE model of a collection of interacting agents governed by a hybrid switching diffusion process. The interaction between the agents is modeled using a (mean-field) feedback law that is a function of the local density of the swarm, with the switching parameters as the control inputs. We show that the semilinear PDE system is globally asymptotically stable about the given target probability density. The stabilization strategies are verified without inter-agent interactions is verified numerically for agents that evolve according to the Brockett integrator and a nonholonomic system on the special orthogonal group of 3-dimensional rotations $SO(3)$. The stabilization strategy with inter-agent interactions is verified numerically for agents that evolve according to the Brockett integrator and a holonomic system on the sphere $S^2$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.15755v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Elamvazhuthi, Spring Berman</dc:creator>
    </item>
    <item>
      <title>Boolean Variation and Boolean Logic BackPropagation</title>
      <link>https://arxiv.org/abs/2311.07427</link>
      <description>arXiv:2311.07427v2 Announce Type: replace-cross 
Abstract: The notion of variation is introduced for the Boolean set and based on which Boolean logic backpropagation principle is developed. Using this concept, deep models can be built with weights and activations being Boolean numbers and operated with Boolean logic instead of real arithmetic. In particular, Boolean deep models can be trained directly in the Boolean domain without latent weights. No gradient but logic is synthesized and backpropagated through layers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07427v2</guid>
      <category>cs.LG</category>
      <category>cs.DM</category>
      <category>cs.LO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Van Minh Nguyen</dc:creator>
    </item>
    <item>
      <title>Leveraging Hamilton-Jacobi PDEs with time-dependent Hamiltonians for continual scientific machine learning</title>
      <link>https://arxiv.org/abs/2311.07790</link>
      <description>arXiv:2311.07790v2 Announce Type: replace-cross 
Abstract: We address two major challenges in scientific machine learning (SciML): interpretability and computational efficiency. We increase the interpretability of certain learning processes by establishing a new theoretical connection between optimization problems arising from SciML and a generalized Hopf formula, which represents the viscosity solution to a Hamilton-Jacobi partial differential equation (HJ PDE) with time-dependent Hamiltonian. Namely, we show that when we solve certain regularized learning problems with integral-type losses, we actually solve an optimal control problem and its associated HJ PDE with time-dependent Hamiltonian. This connection allows us to reinterpret incremental updates to learned models as the evolution of an associated HJ PDE and optimal control problem in time, where all of the previous information is intrinsically encoded in the solution to the HJ PDE. As a result, existing HJ PDE solvers and optimal control algorithms can be reused to design new efficient training approaches for SciML that naturally coincide with the continual learning framework, while avoiding catastrophic forgetting. As a first exploration of this connection, we consider the special case of linear regression and leverage our connection to develop a new Riccati-based methodology for solving these learning problems that is amenable to continual learning applications. We also provide some corresponding numerical examples that demonstrate the potential computational and memory advantages our Riccati-based approach can provide.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.07790v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Paula Chen, Tingwei Meng, Zongren Zou, J\'er\^ome Darbon, George Em Karniadakis</dc:creator>
    </item>
    <item>
      <title>Recursive identification with regularization and on-line hyperparameters estimation</title>
      <link>https://arxiv.org/abs/2401.00097</link>
      <description>arXiv:2401.00097v2 Announce Type: replace-cross 
Abstract: This paper presents a regularized recursive identification algorithm with simultaneous on-line estimation of both the model parameters and the algorithms hyperparameters. A new kernel is proposed to facilitate the algorithm development. The performance of this novel scheme is compared with that of the recursive least squares algorithm in simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.00097v2</guid>
      <category>stat.ME</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Bernard Vau, Tudor-Bogdan Airimitoaie</dc:creator>
    </item>
    <item>
      <title>Generative AI and Process Systems Engineering: The Next Frontier</title>
      <link>https://arxiv.org/abs/2402.10977</link>
      <description>arXiv:2402.10977v2 Announce Type: replace-cross 
Abstract: This article explores how emerging generative artificial intelligence (GenAI) models, such as large language models (LLMs), can enhance solution methodologies within process systems engineering (PSE). These cutting-edge GenAI models, particularly foundation models (FMs), which are pre-trained on extensive, general-purpose datasets, offer versatile adaptability for a broad range of tasks, including responding to queries, image generation, and complex decision-making. Given the close relationship between advancements in PSE and developments in computing and systems technologies, exploring the synergy between GenAI and PSE is essential. We begin our discussion with a compact overview of both classic and emerging GenAI models, including FMs, and then dive into their applications within key PSE domains: synthesis and design, optimization and integration, and process monitoring and control. In each domain, we explore how GenAI models could potentially advance PSE methodologies, providing insights and prospects for each area. Furthermore, the article identifies and discusses potential challenges in fully leveraging GenAI within PSE, including multiscale modeling, data requirements, evaluation metrics and benchmarks, and trust and safety, thereby deepening the discourse on effective GenAI integration into systems analysis, design, optimization, operations, monitoring, and control. This paper provides a guide for future research focused on the applications of emerging GenAI in PSE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.10977v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Decardi-Nelson, Abdulelah S. Alshehri, Akshay Ajagekar, Fengqi You</dc:creator>
    </item>
  </channel>
</rss>
