<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 04 Oct 2024 02:08:52 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>MDDC: An R and Python Package for Adverse Event Identification in Pharmacovigilance Data</title>
      <link>https://arxiv.org/abs/2410.01168</link>
      <description>arXiv:2410.01168v1 Announce Type: new 
Abstract: The safety of medical products continues to be a significant health concern worldwide. Spontaneous reporting systems (SRS) and pharmacovigilance databases are essential tools for postmarketing surveillance of medical products. Various SRS are employed globally, such as the Food and Drug Administration Adverse Event Reporting System (FAERS), EudraVigilance, and VigiBase. In the pharmacovigilance literature, numerous methods have been proposed to assess product - adverse event pairs for potential signals. In this paper, we introduce an R and Python package that implements a novel pattern discovery method for postmarketing adverse event identification, named Modified Detecting Deviating Cells (MDDC). The package also includes a data generation function that considers adverse events as groups, as well as additional utility functions. We illustrate the usage of the package through the analysis of real datasets derived from the FAERS database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01168v1</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Anran Liu, Raktim Mukhopadhyay, Marianthi Markatou</dc:creator>
    </item>
    <item>
      <title>Statistical Taylor Expansion</title>
      <link>https://arxiv.org/abs/2410.01223</link>
      <description>arXiv:2410.01223v1 Announce Type: new 
Abstract: Statistical Taylor expansion replaces the input precise variables in a conventional Taylor expansion with random variables each with known mean and deviation, to calculate the result mean and deviation. It is based on the uncorrelated uncertainty assumption: Each input variable is measured independently with fine enough statistical precision, so that their uncertainties are independent of each other. Statistical Taylor expansion reviews that the intermediate analytic expressions can no longer be regarded as independent of each other, and the result of analytic expression should be path independent. This conclusion differs fundamentally from the conventional common approach in applied mathematics to find the best execution path for a result. This paper also presents an implementation of statistical Taylor expansion called variance arithmetic, and the tests on variance arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01223v1</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengpu Wang</dc:creator>
    </item>
    <item>
      <title>GPTreeO: An R package for continual regression with dividing local Gaussian processes</title>
      <link>https://arxiv.org/abs/2410.01024</link>
      <description>arXiv:2410.01024v1 Announce Type: cross 
Abstract: We introduce GPTreeO, a flexible R package for scalable Gaussian process (GP) regression, particularly tailored to continual learning problems. GPTreeO builds upon the Dividing Local Gaussian Processes (DLGP) algorithm, in which a binary tree of local GP regressors is dynamically constructed using a continual stream of input data. In GPTreeO we extend the original DLGP algorithm by allowing continual optimisation of the GP hyperparameters, incorporating uncertainty calibration, and introducing new strategies for how the local partitions are created. Moreover, the modular code structure allows users to interface their favourite GP library to perform the local GP regression in GPTreeO. The flexibility of GPTreeO gives the user fine-grained control of the balance between computational speed, accuracy, stability and smoothness. We conduct a sensitivity analysis to show how GPTreeO's configurable features impact the regression performance in a continual learning setting.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01024v1</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Timo Braun, Anders Kvellestad, Riccardo De Bin</dc:creator>
    </item>
    <item>
      <title>FastLexRank: Efficient Lexical Ranking for Structuring Social Media Posts</title>
      <link>https://arxiv.org/abs/2410.01183</link>
      <description>arXiv:2410.01183v1 Announce Type: cross 
Abstract: We present FastLexRank\footnote{https://github.com/LiMaoUM/FastLexRank}, an efficient and scalable implementation of the LexRank algorithm for text ranking. Designed to address the computational and memory complexities of the original LexRank method, FastLexRank significantly reduces time and memory requirements from $\mathcal{O}(n^2)$ to $\mathcal{O}(n)$ without compromising the quality or accuracy of the results. By employing an optimized approach to calculating the stationary distribution of sentence graphs, FastLexRank maintains an identical results with the original LexRank scores while enhancing computational efficiency. This paper details the algorithmic improvements that enable the processing of large datasets, such as social media corpora, in real-time. Empirical results demonstrate its effectiveness, and we propose its use in identifying central tweets, which can be further analyzed using advanced NLP techniques. FastLexRank offers a scalable solution for text centrality calculation, addressing the growing need for efficient processing of digital content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01183v1</guid>
      <category>cs.CL</category>
      <category>stat.CO</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Mao Li, Frederick Conrad, Johann Gagnon-Bartsch</dc:creator>
    </item>
    <item>
      <title>Bayesian estimation for novel geometric INGARCH model</title>
      <link>https://arxiv.org/abs/2410.01283</link>
      <description>arXiv:2410.01283v1 Announce Type: cross 
Abstract: This paper introduces an integer-valued generalized autoregressive conditional heteroskedasticity (INGARCH) model based on the novel geometric distribution and discusses some of its properties. The parameter estimation problem of the models are studied by conditional maximum likelihood and Bayesian approach using Hamiltonian Monte Carlo (HMC) algorithm. The results of the simulation studies and real data analysis affirm the good performance of the estimators and the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01283v1</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Divya Kuttenchalil Andrews, N. Balakrishna</dc:creator>
    </item>
    <item>
      <title>Fast Summation of Radial Kernels via QMC Slicing</title>
      <link>https://arxiv.org/abs/2410.01316</link>
      <description>arXiv:2410.01316v1 Announce Type: cross 
Abstract: The fast computation of large kernel sums is a challenging task, which arises as a subproblem in any kernel method. We approach the problem by slicing, which relies on random projections to one-dimensional subspaces and fast Fourier summation. We prove bounds for the slicing error and propose a quasi-Monte Carlo (QMC) approach for selecting the projections based on spherical quadrature rules. Numerical examples demonstrate that our QMC-slicing approach significantly outperforms existing methods like (QMC-)random Fourier features, orthogonal Fourier features or non-QMC slicing on standard test datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01316v1</guid>
      <category>math.NA</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Johannes Hertrich, Tim Jahn, Michael Quellmalz</dc:creator>
    </item>
    <item>
      <title>Efficient Statistics With Unknown Truncation, Polynomial Time Algorithms, Beyond Gaussians</title>
      <link>https://arxiv.org/abs/2410.01656</link>
      <description>arXiv:2410.01656v1 Announce Type: cross 
Abstract: We study the estimation of distributional parameters when samples are shown only if they fall in some unknown set $S \subseteq \mathbb{R}^d$. Kontonis, Tzamos, and Zampetakis (FOCS'19) gave a $d^{\mathrm{poly}(1/\varepsilon)}$ time algorithm for finding $\varepsilon$-accurate parameters for the special case of Gaussian distributions with diagonal covariance matrix. Recently, Diakonikolas, Kane, Pittas, and Zarifis (COLT'24) showed that this exponential dependence on $1/\varepsilon$ is necessary even when $S$ belongs to some well-behaved classes. These works leave the following open problems which we address in this work: Can we estimate the parameters of any Gaussian or even extend beyond Gaussians? Can we design $\mathrm{poly}(d/\varepsilon)$ time algorithms when $S$ is a simple set such as a halfspace?
  We make progress on both of these questions by providing the following results:
  1. Toward the first question, we give a $d^{\mathrm{poly}(\ell/\varepsilon)}$ time algorithm for any exponential family that satisfies some structural assumptions and any unknown set $S$ that is $\varepsilon$-approximable by degree-$\ell$ polynomials. This result has two important applications:
  1a) The first algorithm for estimating arbitrary Gaussian distributions from samples truncated to an unknown $S$; and
  1b) The first algorithm for linear regression with unknown truncation and Gaussian features.
  2. To address the second question, we provide an algorithm with runtime $\mathrm{poly}(d/\varepsilon)$ that works for a set of exponential families (containing all Gaussians) when $S$ is a halfspace or an axis-aligned rectangle.
  Along the way, we develop tools that may be of independent interest, including, a reduction from PAC learning with positive and unlabeled samples to PAC learning with positive and negative samples that is robust to certain covariate shifts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01656v1</guid>
      <category>math.ST</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jane H. Lee, Anay Mehrotra, Manolis Zampetakis</dc:creator>
    </item>
    <item>
      <title>On metric choice in dimension reduction for Fr\'echet regression</title>
      <link>https://arxiv.org/abs/2410.01783</link>
      <description>arXiv:2410.01783v1 Announce Type: cross 
Abstract: Fr\'echet regression is becoming a mainstay in modern data analysis for analyzing non-traditional data types belonging to general metric spaces. This novel regression method utilizes the pairwise distances between the random objects, which makes the choice of metric crucial in the estimation. In this paper, the effect of metric choice on the estimation of the dimension reduction subspace for the regression between random responses and Euclidean predictors is investigated. Extensive numerical studies illustrate how different metrics affect the central and central mean space estimates for regression involving responses belonging to some popular metric spaces versus Euclidean predictors. An analysis of the distributions of glycaemia based on continuous glucose monitoring data demonstrate how metric choice can influence findings in real applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01783v1</guid>
      <category>stat.ME</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul-Nasah Soale, Congli Ma, Siyu Chen, Obed Koomson</dc:creator>
    </item>
    <item>
      <title>Niching Subset Simulation</title>
      <link>https://arxiv.org/abs/2209.02468</link>
      <description>arXiv:2209.02468v4 Announce Type: replace 
Abstract: Subset Simulation is a Markov chain Monte Carlo method used to compute small failure probabilities in structural reliability problems. This is done by iteratively sampling from nested subsets in the input space of a performance function, i.e. a function describing the behaviour of a physical system. When the performance function has features such as multimodality or rapidly changing output, it is not uncommon for Subset Simulation to suffer from ergodicity problems. To address these problems, this paper proposes a new framework that enhances Subset Simulation with niching, a concept from the field of evolutionary multimodal optimisation. Niching subset simulation dynamically partitions the input space using support vector machines, and recursively begins anew in each set of the partition. A new niching technique, which uses community detection methods and is specifically designed for high-dimensional problems, is also introduced. It is shown that Niching Subset Simulation is robust against ergodicty problems and can also offer additional insight into the topology of challenging reliability problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.02468v4</guid>
      <category>stat.CO</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hugh J. Kinnear, F. A. DiazDelaO</dc:creator>
    </item>
    <item>
      <title>Importance is Important: Generalized Markov Chain Importance Sampling Methods</title>
      <link>https://arxiv.org/abs/2304.06251</link>
      <description>arXiv:2304.06251v2 Announce Type: replace 
Abstract: We show that for any multiple-try Metropolis algorithm, one can always accept the proposal and evaluate the importance weight that is needed to correct for the bias without extra computational cost. This results in a general, convenient, and rejection-free Markov chain Monte Carlo (MCMC) sampling scheme. By further leveraging the importance sampling perspective on Metropolis--Hastings algorithms, we propose an alternative MCMC sampler on discrete spaces that is also outside the Metropolis--Hastings framework, along with a general theory on its complexity. Numerical examples suggest that the proposed algorithms are consistently more efficient than the original Metropolis--Hastings versions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06251v2</guid>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guanxun Li, Aaron Smith, Quan Zhou</dc:creator>
    </item>
    <item>
      <title>Differential Quantile-Based Sensitivity in Discontinuous Models</title>
      <link>https://arxiv.org/abs/2310.06151</link>
      <description>arXiv:2310.06151v2 Announce Type: replace 
Abstract: Differential sensitivity measures provide valuable tools for interpreting complex computational models used in applications ranging from simulation to algorithmic prediction. Taking the derivative of the model output in direction of a model parameter can reveal input-output relations and the relative importance of model parameters and input variables. Nonetheless, it is unclear how such derivatives should be taken when the model function has discontinuities and/or input variables are discrete. We present a general framework for addressing such problems, considering derivatives of quantile-based output risk measures, with respect to distortions to random input variables (risk factors), which impact the model output through step-functions. We prove that, subject to weak technical conditions, the derivatives are well-defined and derive the corresponding formulas. We apply our results to the sensitivity analysis of compound risk models and to a numerical study of reinsurance credit risk in a multi-line insurance portfolio.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.06151v2</guid>
      <category>stat.CO</category>
      <category>q-fin.RM</category>
      <category>q-fin.ST</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Silvana M. Pesenti, Pietro Millossovich, Andreas Tsanakas</dc:creator>
    </item>
    <item>
      <title>Optimization by Parallel Quasi-Quantum Annealing with Gradient-Based Sampling</title>
      <link>https://arxiv.org/abs/2409.02135</link>
      <description>arXiv:2409.02135v2 Announce Type: replace-cross 
Abstract: Learning-based methods have gained attention as general-purpose solvers due to their ability to automatically learn problem-specific heuristics, reducing the need for manually crafted heuristics. However, these methods often face scalability challenges. To address these issues, the improved Sampling algorithm for Combinatorial Optimization (iSCO), using discrete Langevin dynamics, has been proposed, demonstrating better performance than several learning-based solvers. This study proposes a different approach that integrates gradient-based update through continuous relaxation, combined with Quasi-Quantum Annealing (QQA). QQA smoothly transitions the objective function, starting from a simple convex function, minimized at half-integral values, to the original objective function, where the relaxed variables are minimized only in the discrete space. Furthermore, we incorporate parallel run communication leveraging GPUs to enhance exploration capabilities and accelerate convergence. Numerical experiments demonstrate that our method is a competitive general-purpose solver, achieving performance comparable to iSCO and learning-based solvers across various benchmark problems. Notably, our method exhibits superior speed-quality trade-offs for large-scale instances compared to iSCO, learning-based solvers, commercial solvers, and specialized algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.02135v2</guid>
      <category>cs.LG</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <pubDate>Thu, 03 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuma Ichikawa, Yamato Arai</dc:creator>
    </item>
  </channel>
</rss>
