<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Aug 2025 01:34:21 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Consistent DAG selection for Bayesian causal discovery under general error distributions</title>
      <link>https://arxiv.org/abs/2508.00993</link>
      <description>arXiv:2508.00993v1 Announce Type: new 
Abstract: We consider the problem of learning the underlying causal structure among a set of variables, which are assumed to follow a Bayesian network or, more specifically, a linear recursive structural equation model (SEM) with the associated errors being independent and allowed to be non-Gaussian. A Bayesian hierarchical model is proposed to identify the true data-generating directed acyclic graph (DAG) structure where the nodes and edges represent the variables and the direct causal effects, respectively. Moreover, incorporating the information of non-Gaussian errors, we characterize the distribution equivalence class of the true DAG, which specifies the best possible extent to which the DAG can be identified based on purely observational data. Furthermore, under the consideration that the errors are distributed as some scale mixture of Gaussian, where the mixing distribution is unspecified, and mild distributional assumptions, we establish that by employing a non-standard DAG prior, the posterior probability of the distribution equivalence class of the true DAG converges to unity as the sample size grows. This shows that the proposed method achieves the posterior DAG selection consistency, which is further illustrated with examples and simulation studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00993v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anamitra Chaudhuri, Anirban Bhattacharya, Yang Ni</dc:creator>
    </item>
    <item>
      <title>Asymptotic guarantees for Bayesian phylogenetic tree reconstruction</title>
      <link>https://arxiv.org/abs/2508.00995</link>
      <description>arXiv:2508.00995v1 Announce Type: new 
Abstract: We derive tractable criteria for the consistency of Bayesian tree reconstruction procedures, which constitute a central class of algorithms for inferring common ancestry among DNA sequence samples in phylogenetics. Our results encompass several Bayesian algorithms in widespread use, such as BEAST, MrBayes, and RevBayes. Unlike essentially all existing asymptotic guarantees for tree reconstruction, we require no discretization or boundedness assumptions on branch lengths. Our results are also very flexible, and easy to adapt to variations of the underlying inference problem. We demonstrate the practicality of our criteria on two examples: a Kingman coalescent prior on rooted, ultrametric trees, and an independence prior on unconstrained binary trees, though we emphasize that our result also applies to non-binary tree models. In both cases, the convergence rate we obtain matches known, frequentist results obtained using stronger boundedness assumptions, up to logarithmic factors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.00995v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1080/01621459.2025.2485359</arxiv:DOI>
      <dc:creator>Alisa Kirichenko, Luke J. Kelly, Jere Koskela</dc:creator>
    </item>
    <item>
      <title>Likelihood Functions with Parameter-Dependent Support: A Survey of the Cram\'{e}r-Rao-Leibniz Lower Bound</title>
      <link>https://arxiv.org/abs/2508.01145</link>
      <description>arXiv:2508.01145v1 Announce Type: new 
Abstract: Parameter estimation is a fundamental problem in science and engineering. In many safety-critical applications, one is not only interested in a {\it point} estimator, but also the uncertainty bound that can self-assess the accuracy of the estimator. In this regard, the Cram\'{e}r-Rao lower bound (CRLB) is of great importance, as it provides a lower bound on the variance of {\it any} unbiased estimator. In many cases, it is the only way of evaluating, without recourse to simulations, the expected accuracy of numerically obtainable estimates. For the existence of the CRLB, there have been widely accepted regularity conditions, one of which is that the support of the likelihood function (LF) -- the pdf of the observations conditioned on the parameter of interest -- should be independent of the parameter to be estimated. This paper starts from reviewing the derivations of the classical CRLB under the condition that the LF has parameter-independent support. To cope with the case of parameter-dependent support, we generalize the CRLB to the {\it Cram\'{e}r-Rao-Leibniz lower bound (CRLLB)}, by leveraging the general Leibniz integral rule. Notably, the existing results on CRLLB and CRLB are unified under the framework of CRLLB with multidimensional parameters. Then, we survey existing examples of LFs to illustrate the usefulness of the CRLLB in providing valid covariance bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01145v1</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qin Lu, Yaakov Bar-Shalom, Peter Willett</dc:creator>
    </item>
    <item>
      <title>M-estimation for Gaussian processes with time-inhomogeneous drifts from high-frequency data</title>
      <link>https://arxiv.org/abs/2508.01164</link>
      <description>arXiv:2508.01164v1 Announce Type: new 
Abstract: We propose a contrast-based estimation method for Gaussian processes with time-inhomogeneous drifts, observed under high-frequency sampling. The process is modeled as the sum of a deterministic drift function and a stationary Gaussian component with a parametric kernel. Our method constructs a local contrast function from adjacent increments, which avoids inversion of large covariance matrices and allows for efficient computation. We prove consistency and asymptotic normality of the resulting estimators under general ergodicity conditions. A distinctive feature of our approach is that the drift estimator attains a nonstandard convergence rate, stemming from the direct Riemann integrability of the drift density. This highlights a fundamental difference from standard estimation regimes. Furthermore, when the local contrast fails to identify all parameters in the covariance kernel, moment-based corrections can be incorporated to recover identifiability. The proposed framework is simple, flexible, and particularly well suited for high-frequency inference with time-inhomogeneous structure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01164v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yasutaka Shimizu</dc:creator>
    </item>
    <item>
      <title>Central Limit Theorems for Transition Probabilities of Controlled Markov Chains</title>
      <link>https://arxiv.org/abs/2508.01517</link>
      <description>arXiv:2508.01517v1 Announce Type: new 
Abstract: We develop a central limit theorem (CLT) for the non-parametric estimator of the transition matrices in controlled Markov chains (CMCs) with finite state-action spaces. Our results establish precise conditions on the logging policy under which the estimator is asymptotically normal, and reveal settings in which no CLT can exist. We then build upon it to derive CLTs for the value, Q-, and advantage functions of any stationary stochastic policy, including the optimal policy recovered from the estimated model. Goodness-of-fit tests are derived as a corollary, which enable us to test whether the logged data is stochastic. These results provide new statistical tools for offline policy evaluation and optimal policy recovery, and enable hypothesis tests for transition probabilities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01517v1</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ziwei Su, Imon Banerjee, Diego Klabjan</dc:creator>
    </item>
    <item>
      <title>From Thomas Bayes to Big Data: On the feasibility of being a subjective Bayesian</title>
      <link>https://arxiv.org/abs/2508.01642</link>
      <description>arXiv:2508.01642v1 Announce Type: new 
Abstract: We argue that the Bayesian paradigm, of a prior which represents the beliefs of the statistician before observing the data, is not feasible in ultra-high-dimensional models. We claim that natural priors that represent the a priori beliefs fail in unpredictable ways under values of the parameters that cannot be honestly ignored. We do not claim that the frequentist estimators we present cannot be mimicked by Bayesian procedures, but that these Bayesian procedures do not represent beliefs. They were created with the frequentist analysis in mind, and in most cases, they cannot represent a consistent set of beliefs about the parameters (for example, since they depend on the loss function, the particular functional of interest, and not only on the a priori knowledge, different priors should be used for different analyses of the same data set). In a way, these are frequentist procedures using a Bayesian technique.
  The paper presents different examples where the subjective point of view fails. It is argued that the arguments based on Wald's and Savage's seminal works are not relevant to the validity of the subjective Bayesian paradigm. The discussion tries to deal with the fundamentals, but the argument is based on a firm mathematical proofs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01642v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ya'acov Ritov</dc:creator>
    </item>
    <item>
      <title>Distribution-free data-driven smooth tests without $\chi^2$</title>
      <link>https://arxiv.org/abs/2508.01973</link>
      <description>arXiv:2508.01973v1 Announce Type: new 
Abstract: This article demonstrates how recent developments in the theory of empirical processes allow us to construct a new family of asymptotically distribution-free smooth test statistics. Their distribution-free property is preserved even when the parameters are estimated, model selection is performed, and the sample size is only moderately large. A computationally efficient alternative to the classical parametric bootstrap is also discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01973v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangyu Zhang, Sara Algeri</dc:creator>
    </item>
    <item>
      <title>Estimation of Algebraic Sets: Extending PCA Beyond Linearity</title>
      <link>https://arxiv.org/abs/2508.01976</link>
      <description>arXiv:2508.01976v1 Announce Type: new 
Abstract: An algebraic set is defined as the zero locus of a system of real polynomial equations. In this paper we address the problem of recovering an unknown algebraic set $\mathcal{A}$ from noisy observations of latent points lying on $\mathcal{A}$ -- a task that extends principal component analysis, which corresponds to the purely linear case. Our procedure consists of three steps: (i) constructing the {\it moment matrix} from the Vandermonde matrix associated with the data set and the degree of the fitted polynomials, (ii) debiasing this moment matrix to remove the noise-induced bias, (iii) extracting its kernel via an eigenvalue decomposition of the debiased moment matrix. These steps yield $n^{-1/2}$-consistent estimators of the coefficients of a set of generators for the ideal of polynomials vanishing on $\mathcal{A}$. To reconstruct $\mathcal{A}$ itself, we propose three complementary strategies: (a) compute the zero set of the fitted polynomials; (b) build a semi-algebraic approximation that encloses $\mathcal{A}$; (c) when structural prior information is available, project the estimated coefficients onto the corresponding constrained space. We prove (nearly) parametric asymptotic error bounds and show that each approach recovers $\mathcal{A}$ under mild regularity conditions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01976v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alberto Gonz\'alez-Sanz, Gilles Mordant, \'Alvaro Samperio, Bodhisattva Sen</dc:creator>
    </item>
    <item>
      <title>Unsupervised linear discrimination using skewness</title>
      <link>https://arxiv.org/abs/2508.02412</link>
      <description>arXiv:2508.02412v1 Announce Type: new 
Abstract: It is well-known that, in Gaussian two-group separation, the optimally discriminating projection direction can be estimated without any knowledge on the group labels. In this work, we \revision{gather} several such unsupervised estimators based on skewness and derive their limiting distributions. As one of our main results, we show that all affine equivariant estimators of the optimal direction have proportional asymptotic covariance matrices, making their comparison straightforward. Two of our four estimators are novel and two have been proposed already earlier. We use simulations to verify our results and to inspect the finite-sample behaviors of the estimators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02412v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Una Radojicic, Klaus Nordhausen, Joni Virta</dc:creator>
    </item>
    <item>
      <title>Variational Bernstein-von Mises theorem with increasing parameter dimension</title>
      <link>https://arxiv.org/abs/2508.02585</link>
      <description>arXiv:2508.02585v1 Announce Type: new 
Abstract: Variational Bayes (VB) provides a computationally efficient alternative to Markov Chain Monte Carlo, especially for high-dimensional and large-scale inference. However, existing theory on VB primarily focuses on fixed-dimensional settings or specific models. To address this limitation, this paper develops a finite-sample theory for VB in a broad class of parametric models with latent variables. We establish theoretical properties of the VB posterior, including a non-asymptotic variational Bernstein--von Mises theorem. Furthermore, we derive consistency and asymptotic normality of the VB estimator. An application to multivariate Gaussian mixture models is presented for illustration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02585v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Yan, Peirong Xu, Tao Wang</dc:creator>
    </item>
    <item>
      <title>Bayesian Conformal Prediction via the Bayesian Bootstrap</title>
      <link>https://arxiv.org/abs/2508.01418</link>
      <description>arXiv:2508.01418v1 Announce Type: cross 
Abstract: Reliable uncertainty quantification remains a central challenge in predictive modeling. While Bayesian methods are theoretically appealing, their predictive intervals can exhibit poor frequentist calibration, particularly with small sample sizes or model misspecification. We introduce a practical and broadly applicable Bayesian conformal approach based on the influence-function Bayesian bootstrap (BB) with data-driven tuning of the Dirichlet concentration parameter, {\alpha}. By efficiently approximating the Bayesian bootstrap predictive distribution via influence functions and calibrating {\alpha} to optimize empirical coverage or average log-probability, our method constructs prediction intervals and distributions that are both well-calibrated and sharp. Across a range of regression models and data settings, this Bayesian conformal framework consistently yields improved empirical coverage and log-score compared to standard Bayesian posteriors. Our procedure is fast, easy to implement, and offers a flexible approach for distributional calibration in predictive modeling.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01418v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Graham Gibson</dc:creator>
    </item>
    <item>
      <title>Singular values of sparse random rectangular matrices: Emergence of outliers at criticality</title>
      <link>https://arxiv.org/abs/2508.01456</link>
      <description>arXiv:2508.01456v1 Announce Type: cross 
Abstract: Consider the random bipartite Erd\H{o}s-R\'{e}nyi graph $\mathbb{G}(n, m, p)$, where each edge with one vertex in $V_{1}=[n]$ and the other vertex in $V_{2} =[m]$ is connected with probability $p$, and $n=\lfloor \gamma m\rfloor$ for a constant aspect ratio $\gamma \geq 1$. It is well known that the empirical spectral measure of its centered and normalized adjacency matrix converges to the Mar\v{c}enko-Pastur (MP) distribution. However, largest and smallest singular values may not converge to the right and left edges, respectively, especially when $p = o(1)$. Notably, it was proved by Dumitriu and Zhu (2024) that there are almost surely no singular value outside the compact support of the MP law when $np = \omega(\log(n))$. In this paper, we consider the critical sparsity regime where $p = b\log(n)/\sqrt{mn}$ for some constant $b&gt;0$. We quantitatively characterize the emergence of outlier singular values as follows. For explicit $b_{*}$ and $b^{*}$ functions of $\gamma$, we prove that when $b &gt; b_{*}$, there is no outlier outside the bulk; when $b^{*}&lt; b &lt; b_{*}$, outliers are present only outside the right edge of the MP law; and when $b &lt; b^{*}$, outliers are present on both sides, all with high probability. Moreover, locations of those outliers are precisely characterized by a function depending on the largest and smallest degree vertices of the random graph. We estimate the number of outliers as well. Our results follow the path forged by Alt, Ducatez and Knowles (2021), and can be extended to sparse random rectangular matrices with bounded entries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01456v1</guid>
      <category>math.PR</category>
      <category>cs.NA</category>
      <category>math.CO</category>
      <category>math.NA</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ioana Dumitriu, Hai-Xiao Wang, Zhichao Wang, Yizhe Zhu</dc:creator>
    </item>
    <item>
      <title>Central Limit Theorems for Sample Average Approximations in Stochastic Optimal Control</title>
      <link>https://arxiv.org/abs/2508.01942</link>
      <description>arXiv:2508.01942v1 Announce Type: cross 
Abstract: We establish central limit theorems for the Sample Average Approximation (SAA) method in discrete-time, finite-horizon Stochastic Optimal Control. Using the dynamic programming principle and backward induction, we characterize the limiting distributions of the SAA value functions. The asymptotic variance at each stage decomposes into two components: a current-stage variance arising from immediate randomness, and a propagated future variance accumulated from subsequent stages. This decomposition clarifies how statistical uncertainty propagates backward through time. Our derivation relies on a stochastic equicontinuity condition, for which we provide sufficient conditions. We illustrate the variance decomposition using the classical Linear Quadratic Regulator (LQR) problem. Although its unbounded state and control spaces violate the compactness assumptions of our framework, the LQR setting enables explicit computation and visualization of both variance components.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01942v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Johannes Milz, Alexander Shapiro</dc:creator>
    </item>
    <item>
      <title>Decision Theory For Large Scale Outlier Detection Using Aleatoric Uncertainty: With a Note on Bayesian FDR</title>
      <link>https://arxiv.org/abs/2508.01988</link>
      <description>arXiv:2508.01988v1 Announce Type: cross 
Abstract: Aleatoric and Epistemic uncertainty have achieved recent attention in the literature as different sources from which uncertainty can emerge in stochastic modeling. Epistemic being intrinsic or model based notions of uncertainty, and aleatoric being the uncertainty inherent in the data. We propose a novel decision theoretic framework for outlier detection in the context of aleatoric uncertainty; in the context of Bayesian modeling. The model incorporates bayesian false discovery rate control for multiplicty adjustment, and a new generalization of Bayesian FDR is introduced. The model is applied to simulations based on temporally fluctuating outlier detection where fixing thresholds often results in poor performance due to nonstationarity, and a case study is outlined on on a novel cybersecurity detection. Cyberthreat signals are highly nonstationary; giving a credible stress test of the model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.01988v1</guid>
      <category>stat.ME</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Ryan Warnick</dc:creator>
    </item>
    <item>
      <title>Robust Detection of Planted Subgraphs in Semi-Random Models</title>
      <link>https://arxiv.org/abs/2508.02158</link>
      <description>arXiv:2508.02158v1 Announce Type: cross 
Abstract: Detection of planted subgraphs in Erd\"os-R\'enyi random graphs has been extensively studied, leading to a rich body of results characterizing both statistical and computational thresholds. However, most prior work assumes a purely random generative model, making the resulting algorithms potentially fragile in the face of real-world perturbations. In this work, we initiate the study of semi-random models for the planted subgraph detection problem, wherein an adversary is allowed to remove edges outside the planted subgraph before the graph is revealed to the statistician. Crucially, the statistician remains unaware of which edges have been removed, introducing fundamental challenges to the inference task. We establish fundamental statistical limits for detection under this semi-random model, revealing a sharp dichotomy. Specifically, for planted subgraphs with strongly sub-logarithmic maximum density detection becomes information-theoretically impossible in the presence of an adversary, despite being possible in the classical random model. In stark contrast, for subgraphs with super-logarithmic density, the statistical limits remain essentially unchanged; we prove that the optimal (albeit computationally intractable) likelihood ratio test remains robust. Beyond these statistical boundaries, we design a new computationally efficient and robust detection algorithm, and provide rigorous statistical guarantees for its performance. Our results establish the first robust framework for planted subgraph detection and open new directions in the study of semi-random models, computational-statistical trade-offs, and robustness in graph inference problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02158v1</guid>
      <category>cs.IT</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.IT</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dor Elimelech, Wasim Huleihel</dc:creator>
    </item>
    <item>
      <title>Optimal Adjustment and Combination of Independent Discrete $p$-Values</title>
      <link>https://arxiv.org/abs/2508.02647</link>
      <description>arXiv:2508.02647v1 Announce Type: cross 
Abstract: Combining p-values from multiple independent tests is a fundamental task in statistical inference, but presents unique challenges when the p-values are discrete. We extend a recent optimal transport-based framework for combining discrete p-values, which constructs a continuous surrogate distribution by minimizing the Wasserstein distance between the transformed discrete null and its continuous analogue. We provide a unified approach for several classical combination methods, including Fisher's, Pearson's, George's, Stouffer's, and Edgington's statistics. Our theoretical analysis and extensive simulations show that accurate Type I error control is achieved when the variance of the adjusted discrete statistic closely matches that of the continuous case. We further demonstrate that, when the likelihood ratio test is a monotonic function of a combination statistic, the proposed approximation achieves power comparable to the uniformly most powerful (UMP) test. The methodology is illustrated with a genetic association study of rare variants using case-control data, and is implemented in the R package DPComb.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.02647v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gonzalo Contador, Zheyang Wu</dc:creator>
    </item>
    <item>
      <title>Yurinskii's Coupling for Martingales</title>
      <link>https://arxiv.org/abs/2210.00362</link>
      <description>arXiv:2210.00362v4 Announce Type: replace 
Abstract: Yurinskii's coupling is a popular theoretical tool for non-asymptotic distributional analysis in mathematical statistics and applied probability, offering a Gaussian strong approximation with an explicit error bound under easily verifiable conditions. Originally stated in $\ell_2$-norm for sums of independent random vectors, it has recently been extended both to the $\ell_p$-norm, for $1 \leq p \leq \infty$, and to vector-valued martingales in $\ell_2$-norm, under some strong conditions. We present as our main result a Yurinskii coupling for approximate martingales in $\ell_p$-norm, under substantially weaker conditions than those previously imposed. Our formulation further allows for the coupling variable to follow a more general Gaussian mixture distribution, and we provide a novel third-order coupling method which gives tighter approximations in certain settings. We specialize our main result to mixingales, martingales, and independent data, and derive uniform Gaussian mixture strong approximations for martingale empirical processes. Applications to nonparametric partitioning-based and local polynomial regression procedures are provided, alongside central limit theorems for high-dimensional martingale vectors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.00362v4</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matias D. Cattaneo, Ricardo P. Masini, William G. Underwood</dc:creator>
    </item>
    <item>
      <title>Optimal Discriminant Analysis in High-Dimensional Latent Factor Models</title>
      <link>https://arxiv.org/abs/2210.12862</link>
      <description>arXiv:2210.12862v2 Announce Type: replace 
Abstract: In high-dimensional classification problems, a commonly used approach is to first project the high-dimensional features into a lower dimensional space, and base the classification on the resulting lower dimensional projections. In this paper, we formulate a latent-variable model with a hidden low-dimensional structure to justify this two-step procedure and to guide which projection to choose. We propose a computationally efficient classifier that takes certain principal components (PCs) of the observed features as projections, with the number of retained PCs selected in a data-driven way. A general theory is established for analyzing such two-step classifiers based on any projections. We derive explicit rates of convergence of the excess risk of the proposed PC-based classifier. The obtained rates are further shown to be optimal up to logarithmic factors in the minimax sense. Our theory allows the lower-dimension to grow with the sample size and is also valid even when the feature dimension (greatly) exceeds the sample size. Extensive simulations corroborate our theoretical findings. The proposed method also performs favorably relative to other existing discriminant methods on three real data examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.12862v2</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Bing, Marten Wegkamp</dc:creator>
    </item>
    <item>
      <title>Distribution-free inference with hierarchical data</title>
      <link>https://arxiv.org/abs/2306.06342</link>
      <description>arXiv:2306.06342v4 Announce Type: replace 
Abstract: This paper studies distribution-free inference in settings where the data set has a hierarchical structure -- for example, groups of observations, or repeated measurements. In such settings, standard notions of exchangeability may not hold. To address this challenge, a hierarchical form of exchangeability is derived, facilitating extensions of distribution-free methods, including conformal prediction and jackknife+. While the standard theoretical guarantee obtained by the conformal prediction framework is a marginal predictive coverage guarantee, in the special case of independent repeated measurements, it is possible to achieve a stronger form of coverage -- the "second-moment coverage" property -- to provide better control of conditional miscoverage rates, and distribution-free prediction sets that achieve this property are constructed. Simulations illustrate that this guarantee indeed leads to uniformly small conditional miscoverage rates. Empirically, this stronger guarantee comes at the cost of a larger width of the prediction set in scenarios where the fitted model is poorly calibrated, but this cost is very mild in cases where the fitted model is accurate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.06342v4</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yonghoon Lee, Rina Foygel Barber, Rebecca Willett</dc:creator>
    </item>
    <item>
      <title>Thresholded Lasso for high dimensional variable selection</title>
      <link>https://arxiv.org/abs/2309.15355</link>
      <description>arXiv:2309.15355v2 Announce Type: replace 
Abstract: Given $n$ noisy samples with $p$ dimensions, where $n \ll p$, we show that the multi-step thresholding procedure based on the Lasso -- we call it the {\it Thresholded Lasso}, can accurately estimate a sparse vector $\beta \in {\mathbb R}^p$ in a linear model $Y = X \beta + \epsilon$, where $X_{n \times p}$ is a design matrix normalized to have column $\ell_2$-norm $\sqrt{n}$, and $\epsilon \sim N(0, \sigma^2 I_n)$. We show that under the restricted eigenvalue (RE) condition, it is possible to achieve the $\ell_2$ loss within a logarithmic factor of the ideal mean square error one would achieve with an $oracle$ while selecting a sufficiently sparse model -- hence achieving $sparse \ oracle \ inequalities$; the oracle would supply perfect information about which coordinates are non-zero and which are above the noise level. We also show for the Gauss-Dantzig selector (Cand\`{e}s-Tao 07), if $X$ obeys a uniform uncertainty principle, one will achieve the sparse oracle inequalities as above, while allowing at most $s_0$ irrelevant variables in the model in the worst case, where $s_0 \leq s$ is the smallest integer such that for $\lambda = \sqrt{2 \log p/n}$, $\sum_{i=1}^p \min(\beta_i^2, \lambda^2 \sigma^2) \leq s_0 \lambda^2 \sigma^2$. Our simulation results on the Thresholded Lasso match our theoretical analysis excellently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.15355v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuheng Zhou</dc:creator>
    </item>
    <item>
      <title>Estimation of on- and off-time distributions in a dynamic Erd\H{o}s-R\'enyi random graph</title>
      <link>https://arxiv.org/abs/2401.14531</link>
      <description>arXiv:2401.14531v5 Announce Type: replace 
Abstract: In this paper we consider a dynamic Erd\H{o}s-R\'enyi graph in which edges, according to an alternating renewal process, change from present to absent and vice versa. The objective is to estimate the on- and off-time distributions while only observing the aggregate number of edges. This inverse problem is dealt with, in a parametric context, by setting up an estimator based on the method of moments. We provide conditions under which the estimator is asymptotically normal, and we point out how the corresponding covariance matrix can be identified. It is also demonstrated how to adapt the estimation procedure if alternative subgraph counts are observed, such as the number of wedges or triangles.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.14531v5</guid>
      <category>math.ST</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Michel Mandjes, Jiesen Wang</dc:creator>
    </item>
    <item>
      <title>Revisiting Step-Size Assumptions in Stochastic Approximation</title>
      <link>https://arxiv.org/abs/2405.17834</link>
      <description>arXiv:2405.17834v3 Announce Type: replace 
Abstract: Many machine learning and optimization algorithms are built upon the framework of stochastic approximation (SA), for which the selection of step-size (or learning rate) $\{\alpha_n\}$ is crucial for success. An essential condition for convergence is the assumption that $\sum_n \alpha_n = \infty$. Moreover, in all theory to date it is assumed that $\sum_n \alpha_n^2 &lt; \infty$ (the sequence is square summable). In this paper it is shown for the first time that this assumption is not required for convergence and finer results.
  The main results are restricted to the special case $\alpha_n = \alpha_0 n^{-\rho}$ with $\rho \in (0,1)$. The theory allows for parameter dependent Markovian noise as found in many applications of interest to the machine learning and optimization research communities. Rates of convergence are obtained for the standard algorithm, and for estimates obtained via the averaging technique of Polyak and Ruppert.
  $\bullet$ Parameter estimates converge with probability one, and in $L_p$ for any $p\ge 1$. Moreover, the rate of convergence of the the mean-squared error (MSE) is $O(\alpha_n)$, which is improved to $O(\max\{ \alpha_n^2,1/n \})$ with averaging.
  Finer results are obtained for linear SA:
  $\bullet$ The covariance of the estimates is optimal in the sense of prior work of Polyak and Ruppert.
  $\bullet$ Conditions are identified under which the bias decays faster than $O(1/n)$. When these conditions are violated, the bias at iteration $n$ is approximately $\beta_\theta\alpha_n$ for a vector $\beta_\theta$ identified in the paper. Results from numerical experiments illustrate that $\beta_\theta$ may be large due to a combination of multiplicative noise and Markovian memory.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17834v3</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Caio Kalil Lauand, Sean Meyn</dc:creator>
    </item>
    <item>
      <title>On the optimality of coin-betting for mean estimation</title>
      <link>https://arxiv.org/abs/2412.02640</link>
      <description>arXiv:2412.02640v4 Announce Type: replace 
Abstract: We consider the problem of testing the mean of a bounded real random variable. We introduce a notion of optimal classes for e-variables and e-processes, and establish the optimality of the coin-betting formulation among e-variable-based algorithmic frameworks for testing and estimating the (conditional) mean. As a consequence, we provide a direct and explicit characterisation of all valid e-variables and e-processes for this testing problem. In the language of classical statistical decision theory, we fully describe the set of all admissible e-variables and e-processes, and identify the corresponding minimal complete class.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02640v4</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eugenio Clerico</dc:creator>
    </item>
    <item>
      <title>Functional independent component analysis by choice of norm: a framework for near-perfect classification</title>
      <link>https://arxiv.org/abs/2412.17971</link>
      <description>arXiv:2412.17971v2 Announce Type: replace 
Abstract: We develop a theory for functional independent component analysis in an infinite-dimensional framework using Sobolev spaces that accommodate smoother functions. The notion of penalized kurtosis is introduced motivated by Silverman's method for smoothing principal components. This approach allows for a classical definition of independent components obtained via projection onto the eigenfunctions of a smoothed kurtosis operator mapping a whitened functional random variable. We discuss the theoretical properties of this operator in relation to a generalized Fisher discriminant function and the relationship it entails with the Feldman-H\'ajek dichotomy for Gaussian measures, both of which are critical to the principles of functional classification. The proposed estimators are a particularly competitive alternative in binary classification of functional data and can eventually achieve the so-called near-perfect classification, which is a genuine phenomenon of high-dimensional data. Our methods are illustrated through simulations, various real datasets, and used to model electroencephalographic biomarkers for the diagnosis of depressive disorder.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17971v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Vidal, Marc Leman, Ana M. Aguilera</dc:creator>
    </item>
    <item>
      <title>Robust Tail Index Estimation under Random Censoring via Minimum Density Power Divergence</title>
      <link>https://arxiv.org/abs/2507.18737</link>
      <description>arXiv:2507.18737v4 Announce Type: replace 
Abstract: We introduce a robust estimator for the tail index of a Pareto-type distribution under random right censoring, developed within the framework of the minimum density power divergence. To the best of our knowledge, this is the first approach to integrate density power divergence into the context of randomly censored extreme value models, thus opening a new path for robust inference in this setting. Under general regularity conditions, the proposed estimator is shown to be consistent and asymptotically normal. Its finite-sample behavior is thoroughly assessed through an extensive simulation study, which highlights its improved robustness and efficiency compared to existing methods. Finally, the practical relevance of the method is illustrated through an application to a real AIDS survival dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.18737v4</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nour Elhouda Guesmia, Abdelhakim Necir, Djamel Meraghni</dc:creator>
    </item>
    <item>
      <title>Functional limit theorems and parameter inference for multiscale stochastic models of enzyme kinetics</title>
      <link>https://arxiv.org/abs/2409.06565</link>
      <description>arXiv:2409.06565v2 Announce Type: replace-cross 
Abstract: We study a class of Stochastic Differential Equations (SDEs) with jumps modeling multistage Michaelis--Menten enzyme kinetics, in which a substrate is sequentially transformed into a product via a cascade of intermediate complexes. These networks are typically high dimensional and exhibit multiscale behavior with strong coupling between different components, posing substantial analytical and computational challenges. In particular, the problem of statistical inference of reaction rates is significantly difficult, and becomes even more intricate when direct observations of system states are unavailable and only a random sample of product formation times is observed. We address this in two stages. First, in a suitable scaling regime consistent with the Quasi-Steady State Approximation (QSSA), we rigorously establish two asymptotic results: (i) a stochastic averaging principle yielding a reduced model for the product--substrate dynamics; and (ii) a Functional Central Limit Theorem (FCLT) characterizing the associated fluctuations. Guided by the reduced-order dynamics, we next construct a novel Interacting Particle System (IPS) that approximates the product-substrate process at the particle level. This IPS plays a pivotal role in the inference methodology; in particular, we establish a propagation of chaos result that mathematically justifies an approximate product-form likelihood based solely on a random sample of product formation times, without requiring access to the system states. Numerical examples are presented to demonstrate the accuracy and applicability of the theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.06565v2</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Arnab Ganguly, Wasiur R. KhudaBukhsh</dc:creator>
    </item>
    <item>
      <title>Learning large softmax mixtures with warm start EM</title>
      <link>https://arxiv.org/abs/2409.09903</link>
      <description>arXiv:2409.09903v2 Announce Type: replace-cross 
Abstract: Softmax mixture models (SMMs) are discrete $K$-mixtures introduced to model the probability of choosing an attribute $x_j \in \RR^L$ from $p$ candidates, in heterogeneous populations. They have been known as mixed multinomial logits in the econometrics literature, and are gaining traction in the LLM literature, where single softmax models are routinely used in the final layer of a neural network. This paper provides a comprehensive analysis of the EM algorithm for SMMs in high dimensions. Its population-level theoretical analysis forms the basis for proving (i) local identifiability, in SSMs with generic features and, further, via a stochastic argument, (ii) full identifiability in SSMs with random features, when $p$ is large enough. These are the first results in this direction for SSMs with $L &gt; 1$. The population-level EM analysis characterizes the initialization radius for algorithmic convergence. This also guides the construction of warm starts of the sample level EM. Under suitable initialization, the EM algorithm is shown to recover the mixture atoms of the SSM at near-parametric rate. We provide two main directions for warm start construction, both based on a new method for estimating the moments of the mixing measure underlying an SSM with random design. First, we construct a method of moments (MoM) estimator of the mixture parameters, and provide its first theoretical analysis. While MoM can enjoy parametric rates of convergence, and thus can serve as a warm-start, the estimator's quality degrades exponentially in $K$. Our recommendation, when $K$ is not small, is to run the EM algorithm several times with random initializations. We again make use of the novel latent moments estimation method to estimate the $K$-dimensional subspace of the mixture atoms. Sampling from this subspace reduces substantially the number of required draws.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.09903v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Bing, Florentina Bunea, Jonathan Niles-Weed, Marten Wegkamp</dc:creator>
    </item>
    <item>
      <title>Learning to Fuse Temporal Proximity Networks: A Case Study in Chimpanzee Social Interactions</title>
      <link>https://arxiv.org/abs/2502.00302</link>
      <description>arXiv:2502.00302v3 Announce Type: replace-cross 
Abstract: How can we identify groups of primate individuals which could be conjectured to drive social structure? To address this question, one of us has collected a time series of data for social interactions between chimpanzees. Here we use a network representation, leading to the task of combining these data into a time series of a single weighted network per time stamp, where different proximities should be given different weights reflecting their relative importance. We optimize these proximity-type weights in a principled way, using an innovative loss function which rewards structural consistency for consecutive time steps. The approach is empirically validated by carefully designed synthetic data. Using statistical tests, we provide a way of identifying groups of individuals that stay related for a significant length of time. Applying the approach to the chimpanzee data set, we detect cliques in the animal social network time series, which can be validated by real-world intuition from prior research and qualitative observations by chimpanzee experts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.00302v3</guid>
      <category>stat.ML</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yixuan He, Aaron Sandel, David Wipf, Mihai Cucuringu, John Mitani, Gesine Reinert</dc:creator>
    </item>
    <item>
      <title>Robustly Learning Monotone Generalized Linear Models via Data Augmentation</title>
      <link>https://arxiv.org/abs/2502.08611</link>
      <description>arXiv:2502.08611v2 Announce Type: replace-cross 
Abstract: We study the task of learning Generalized Linear models (GLMs) in the agnostic model under the Gaussian distribution. We give the first polynomial-time algorithm that achieves a constant-factor approximation for \textit{any} monotone Lipschitz activation. Prior constant-factor GLM learners succeed for a substantially smaller class of activations. Our work resolves a well-known open problem, by developing a robust counterpart to the classical GLMtron algorithm (Kakade et al., 2011). Our robust learner applies more generally, encompassing all monotone activations with bounded $(2+\zeta)$-moments, for any fixed $\zeta&gt;0$ -- a condition that is essentially necessary. To obtain our results, we leverage a novel data augmentation technique with decreasing Gaussian noise injection and prove a number of structural results that may be useful in other settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08611v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikos Zarifis, Puqian Wang, Ilias Diakonikolas, Jelena Diakonikolas</dc:creator>
    </item>
    <item>
      <title>GMM and M Estimation under Network Dependence</title>
      <link>https://arxiv.org/abs/2503.00290</link>
      <description>arXiv:2503.00290v2 Announce Type: replace-cross 
Abstract: This paper presents GMM and M estimators and their asymptotic properties for network-dependent data. To this end, I build on Kojevnikov, Marmer, and Song (KMS, 2021) and develop a novel uniform law of large numbers (ULLN), which is essential to ensure desired asymptotic behaviors of nonlinear estimators (e.g., Newey and McFadden, 1994, Section 2). Using this ULLN, I establish the consistency and asymptotic normality of both GMM and M estimators. For practical convenience, complete estimation and inference procedures are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00290v2</guid>
      <category>econ.EM</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Yuya Sasaki</dc:creator>
    </item>
    <item>
      <title>Semi-Parametric Batched Global Multi-Armed Bandits with Covariates</title>
      <link>https://arxiv.org/abs/2503.00565</link>
      <description>arXiv:2503.00565v2 Announce Type: replace-cross 
Abstract: The multi-armed bandits (MAB) framework is a widely used approach for sequential decision-making, where a decision-maker selects an arm in each round with the goal of maximizing long-term rewards. Moreover, in many practical applications, such as personalized medicine and recommendation systems, feedback is provided in batches, contextual information is available at the time of decision-making, and rewards from different arms are related rather than independent. We propose a novel semi-parametric framework for batched bandits with covariates and a shared parameter across arms, leveraging the single-index regression (SIR) model to capture relationships between arm rewards while balancing interpretability and flexibility. Our algorithm, Batched single-Index Dynamic binning and Successive arm elimination (BIDS), employs a batched successive arm elimination strategy with a dynamic binning mechanism guided by the single-index direction. We consider two settings: one where a pilot direction is available and another where the direction is estimated from data, deriving theoretical regret bounds for both cases. When a pilot direction is available with sufficient accuracy, our approach achieves minimax-optimal rates (with $d = 1$) for nonparametric batched bandits, circumventing the curse of dimensionality. Extensive experiments on simulated and real-world datasets demonstrate the effectiveness of our algorithm compared to the nonparametric batched bandit method introduced by \cite{jiang2024batched}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.00565v2</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sakshi Arya, Hyebin Song</dc:creator>
    </item>
    <item>
      <title>Resolving Memorization in Empirical Diffusion Model for Manifold Data in High-Dimensional Spaces</title>
      <link>https://arxiv.org/abs/2505.02508</link>
      <description>arXiv:2505.02508v3 Announce Type: replace-cross 
Abstract: Diffusion models are popular tools for generating new data samples, using a forward process that adds noise to data and a reverse process to denoise and produce samples. However, when the data distribution consists of n points, empirical diffusion models tend to reproduce existing data points, a phenomenon known as the memorization effect. Current literature often addresses this with complex machine learning techniques. This work shows that the memorization issue can be solved simply by applying an inertia update at the end of the empirical diffusion simulation. Our inertial diffusion model requires only the empirical score function and no additional training. We demonstrate that the distribution of samples from this model approximates the true data distribution on a $C^2$ manifold of dimension $d$, within a Wasserstein-1 distance of order $O(n^{-\frac{2}{d+4}})$. This bound significantly shrinks the Wasserstein distance between the population and empirical distributions, confirming that the inertial diffusion model produces new and diverse samples. Remarkably, this estimate is independent of the ambient space dimension, as no further training is needed. Our analysis shows that the inertial diffusion samples resemble Gaussian kernel density estimations on the manifold, revealing a novel connection between diffusion models and manifold learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.02508v3</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yang Lyu, Tan Minh Nguyen, Yuchun Qian, Xin T. Tong</dc:creator>
    </item>
    <item>
      <title>Local empirical Bayes correction for Bayesian modeling</title>
      <link>https://arxiv.org/abs/2506.11424</link>
      <description>arXiv:2506.11424v4 Announce Type: replace-cross 
Abstract: The James-Stein estimator has attracted much interest as a shrinkage estimator that yields better estimates than the maximum likelihood estimator. The James-Stein estimator is also very useful as an argument in favor of empirical Bayesian methods. However, for problems involving large-scale data, such as differential gene expression data, the distribution is considered a mixture distribution with different means that cannot be considered sufficiently close. Therefore, it is not appropriate to apply the James-Stein estimator. Efron (2011) proposed a local empirical Bayes correction that attempted to correct a selection bias for large-scale data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.11424v4</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <pubDate>Tue, 05 Aug 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.24644/keidaironshu.68.4_161</arxiv:DOI>
      <arxiv:journal_reference>Osaka Keidai Ronshu, vol.68, no.4, pp.161-172, 2017</arxiv:journal_reference>
      <dc:creator>Yoshiko Hayashi</dc:creator>
    </item>
  </channel>
</rss>
