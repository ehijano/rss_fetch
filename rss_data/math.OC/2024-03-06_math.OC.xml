<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 06 Mar 2024 05:00:05 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 06 Mar 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Connections between Bressan's Mixing Conjecture, the Branched Optimal Transport and Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2403.02433</link>
      <description>arXiv:2403.02433v1 Announce Type: new 
Abstract: We investigate the 1D version of the notable Bressan's mixing conjecture, and introduce various formulation in the classical optimal transport setting, the branched optimal transport setting and a combinatorial optimization. In the discrete case of the combinatorial problem, we prove the number of admissible solutions is on the Catalan number. Our investigation sheds light on the intricate relationship between mixing problem in the fluid dynamics and many other popular fields, leaving many interesting open questions in both theoretical and practical applications across disciplines.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02433v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bohan Zhou</dc:creator>
    </item>
    <item>
      <title>Soft quasi-Newton: Guaranteed positive definiteness by relaxing the secant constraint</title>
      <link>https://arxiv.org/abs/2403.02448</link>
      <description>arXiv:2403.02448v1 Announce Type: new 
Abstract: We propose a novel algorithm, termed soft quasi-Newton (soft QN), for optimization in the presence of bounded noise. Traditional quasi-Newton algorithms are vulnerable to such perturbations. To develop a more robust quasi-Newton method, we replace the secant condition in the matrix optimization problem for the Hessian update with a penalty term in its objective and derive a closed-form update formula. A key feature of our approach is its ability to maintain positive definiteness of the Hessian inverse approximation. Furthermore, we establish the following properties of soft QN: it recovers the BFGS method under specific limits, it treats positive and negative curvature equally, and it is scale invariant. Collectively, these features enhance the efficacy of soft QN in noisy environments. For strongly convex objective functions and Hessian approximations obtained using soft QN, we develop an algorithm that exhibits linear convergence toward a neighborhood of the optimal solution, even if gradient and function evaluations are subject to bounded perturbations. Through numerical experiments, we demonstrate superior performance of soft QN compared to state-of-the-art methods in various scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02448v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Erik Berglund, Jiaojiao Zhang, Mikael Johansson</dc:creator>
    </item>
    <item>
      <title>A Primal-dual hybrid gradient method for solving optimal control problems and the corresponding Hamilton-Jacobi PDEs</title>
      <link>https://arxiv.org/abs/2403.02468</link>
      <description>arXiv:2403.02468v1 Announce Type: new 
Abstract: Optimal control problems are crucial in various domains, including path planning, robotics, and humanoid control, demonstrating their broad applicability. The connection between optimal control and Hamilton-Jacobi (HJ) partial differential equations (PDEs) underscores the need for solving HJ PDEs to address these control problems effectively. While numerous numerical methods exist for tackling HJ PDEs across different dimensions, this paper introduces an innovative optimization-based approach that reformulates optimal control problems and HJ PDEs into a saddle point problem using a Lagrange multiplier. Our method, based on the preconditioned primal-dual hybrid gradient (PDHG) method, offers a solution to HJ PDEs with first-order accuracy and numerical unconditional stability, enabling larger time steps and avoiding the limitations of explicit time discretization methods. Our approach has ability to handle a wide variety of Hamiltonian functions, including those that are non-smooth and dependent on time and space, through a simplified saddle point formulation that facilitates easy and parallelizable updates. Furthermore, our framework extends to viscous HJ PDEs and stochastic optimal control problems, showcasing its versatility. Through a series of numerical examples, we demonstrate the method's effectiveness in managing diverse Hamiltonians and achieving efficient parallel computation, highlighting its potential for wide-ranging applications in optimal control and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02468v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Tingwei Meng, Siting Liu, Wuchen Li, Stanley Osher</dc:creator>
    </item>
    <item>
      <title>Projected gradient descent accumulates at Bouligand stationary points</title>
      <link>https://arxiv.org/abs/2403.02530</link>
      <description>arXiv:2403.02530v1 Announce Type: new 
Abstract: This paper concerns the projected gradient descent (PGD) algorithm for the problem of minimizing a continuously differentiable function on a nonempty closed subset of a Euclidean vector space. Without further assumptions, this problem is intractable and devoted algorithms are only expected to find a stationary point. PGD is known to generate a sequence whose accumulation points are Mordukhovich stationary. In this paper, these accumulation points are proven to be Bouligand stationary, and even proximally stationary if the gradient is locally Lipschitz continuous. These are the strongest stationarity properties that can be expected for the considered problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02530v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guillaume Olikier, Ir\`ene Waldspurger</dc:creator>
    </item>
    <item>
      <title>Regularized Benders Decomposition for High Performance Capacity Expansion Models</title>
      <link>https://arxiv.org/abs/2403.02559</link>
      <description>arXiv:2403.02559v1 Announce Type: new 
Abstract: We consider electricity capacity expansion models, which optimize investment and retirement decisions by minimizing both investment and operation costs. In order to provide credible support for planning and policy decisions, these models need to include detailed operations and time-coupling constraints, and allow modeling of discrete planning decisions. Such requirements result in large-scale mixed integer optimization problems that are intractable with off-the-shelf solvers. Hence, practical solution approaches often rely on carefully designed abstraction techniques to find the best compromise between reduced temporal and spatial resolutions and model accuracy. Benders decomposition methods offer scalable approaches to leverage distributed computing resources and enable models with both high resolution and computational performance. Unfortunately, such algorithms are known to suffer from instabilities, resulting in oscillations between extreme planning decisions that slows convergence. In this study, we implement and evaluate several level-set regularization schemes to avoid the selection of extreme planning decisions. Using a large capacity expansion model of the Continental United States with over 70 million variables as a case study, we find that a regularization scheme that selects planning decisions in the interior of the feasible set shows superior performance compared to previously published methods, enabling high-resolution, mixed-integer planning problems with unprecedented computational performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02559v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Pecci, Jesse D. Jenkins</dc:creator>
    </item>
    <item>
      <title>MUSIC: Accelerated Convergence for Distributed Optimization With Inexact and Exact Methods</title>
      <link>https://arxiv.org/abs/2403.02589</link>
      <description>arXiv:2403.02589v1 Announce Type: new 
Abstract: Gradient-type distributed optimization methods have blossomed into one of the most important tools for solving a minimization learning task over a networked agent system. However, only one gradient update per iteration is difficult to achieve a substantive acceleration of convergence. In this paper, we propose an accelerated framework named as MUSIC allowing each agent to perform multiple local updates and a single combination in each iteration. More importantly, we equip inexact and exact distributed optimization methods into this framework, thereby developing two new algorithms that exhibit accelerated linear convergence and high communication efficiency. Our rigorous convergence analysis reveals the sources of steady-state errors arising from inexact policies and offers effective solutions. Numerical results based on synthetic and real datasets demonstrate both our theoretical motivations and analysis, as well as performance advantages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02589v1</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mou Wu, Haibin Liao, Zhengtao Ding, Yonggang Xiao</dc:creator>
    </item>
    <item>
      <title>On the convergence of conditional gradient method for unbounded multiobjective optimization problems</title>
      <link>https://arxiv.org/abs/2403.02671</link>
      <description>arXiv:2403.02671v1 Announce Type: new 
Abstract: This paper focuses on developing a conditional gradient algorithm for multiobjective optimization problems with an unbounded feasible region. We employ the concept of recession cone to establish the well-defined nature of the algorithm. The asymptotic convergence property and the iteration-complexity bound are established under mild assumptions. Numerical examples are provided to verify the algorithmic performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02671v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wang Chen, Yong Zhao, Liping Tang, Xinmin Yang</dc:creator>
    </item>
    <item>
      <title>Projected Gradient Descent Algorithm for Low-Rank Matrix Estimation</title>
      <link>https://arxiv.org/abs/2403.02704</link>
      <description>arXiv:2403.02704v1 Announce Type: new 
Abstract: Most existing methodologies of estimating low-rank matrices rely on Burer-Monteiro factorization, but these approaches can suffer from slow convergence, especially when dealing with solutions characterized by a large condition number, defined by the ratio of the largest to the $r$-th singular values, where $r$ is the search rank. While methods such as Scaled Gradient Descent have been proposed to address this issue, such methods are more complicated and sometimes have weaker theoretical guarantees, for example, in the rank-deficient setting. In contrast, this paper demonstrates the effectiveness of the projected gradient descent algorithm. Firstly, its local convergence rate is independent of the condition number. Secondly, under conditions where the objective function is rank-$2r$ restricted $L$-smooth and $\mu$-strongly convex, with $L/\mu &lt; 3$, projected gradient descent with appropriate step size converges linearly to the solution. Moreover, a perturbed version of this algorithm effectively navigates away from saddle points, converging to an approximate solution or a second-order local minimizer across a wide range of step sizes. Furthermore, we establish that there are no spurious local minimizers in estimating asymmetric low-rank matrices when the objective function satisfies $L/\mu&lt;3.$</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02704v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Teng Zhang, Xing Fan</dc:creator>
    </item>
    <item>
      <title>Unbalanced L1 optimal transport for vector valued measures and application to Full Waveform Inversion</title>
      <link>https://arxiv.org/abs/2403.02764</link>
      <description>arXiv:2403.02764v1 Announce Type: new 
Abstract: Optimal transport has recently started to be successfully employed to define misfit or loss functions in inverse problems. However, it is a problem intrinsically defined for positive (probability) measures and therefore strategies are needed for its applications in more general settings of interest. In this paper we introduce an unbalanced optimal transport problem for vector valued measures starting from the $L^1$ optimal transport. By lifting data in a self-dual cone of a higher dimensional vector space, we show that one can recover a meaningful transport problem. We show that the favorable computational complexity of the $L^1$ problem, an advantage compared to other formulations of optimal transport, is inherited by our vector extension. We consider both a one-homogeneous and a two-homogeneous penalization for the imbalance of mass, the latter being potentially relevant for applications to physics based problems. In particular, we demonstrate the potential of our strategy for full waveform inversion, an inverse problem for high resolution seismic imaging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02764v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Gabriele TodeschiLIGM, Ludovic M\'etivierCNRS, ISTerre, LJK, Jean-Marie MirebeauCNRS, CB</dc:creator>
    </item>
    <item>
      <title>Linear quadratic control of nonlinear systems with Koopman operator learning and the Nystr\"om method</title>
      <link>https://arxiv.org/abs/2403.02811</link>
      <description>arXiv:2403.02811v1 Announce Type: new 
Abstract: In this paper, we study how the Koopman operator framework can be combined with kernel methods to effectively control nonlinear dynamical systems. While kernel methods have typically large computational requirements, we show how random subspaces (Nystr\"om approximation) can be used to achieve huge computational savings while preserving accuracy. Our main technical contribution is deriving theoretical guarantees on the effect of the Nystr\"om approximation. More precisely, we study the linear quadratic regulator problem, showing that both the approximated Riccati operator and the regulator objective, for the associated solution of the optimal control problem, converge at the rate $m^{-1/2}$, where $m$ is the random subspace size. Theoretical findings are complemented by numerical experiments corroborating our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02811v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>stat.ML</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Edoardo Caldarelli, Antoine Chatalic, Adri\`a Colom\'e, Cesare Molinari, Carlos Ocampo-Martinez, Carme Torras, Lorenzo Rosasco</dc:creator>
    </item>
    <item>
      <title>Impact of domain reduction techniques in polynomial optimization: A computational study</title>
      <link>https://arxiv.org/abs/2403.02823</link>
      <description>arXiv:2403.02823v1 Announce Type: new 
Abstract: Domain reduction techniques are at the core of any global optimization solver for NLP or MINLP problems. In this paper, we delve into several of these techniques and assess the impact they may have in the performance of an RLT-based algorithm for polynomial optimization problems. These techniques include i) the use of (nonlinear) conic relaxations for optimality-based bound tightening, ii) the use of Lagrangian dual information to enhance feasibility-based bound tightening, and iii) different strategies for branching point selection. We also explore how a solver equipped with these domain reduction enhancements can further improve its performance by using machine learning to better choose the best domain reduction approach to use on a given instance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02823v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ignacio G\'omez-Casares, Brais Gonz\'alez-Rodr\'iguez, Julio Gonz\'alez-D\'iaz, Pablo Rodr\'iguez-Fern\'andez</dc:creator>
    </item>
    <item>
      <title>Low-rank Tensor Autoregressive Predictor for Third-Order Time-Series Forecasting</title>
      <link>https://arxiv.org/abs/2403.02835</link>
      <description>arXiv:2403.02835v1 Announce Type: new 
Abstract: Recently, tensor time-series forecasting has gained increasing attention, whose core requirement is how to perform dimensionality reduction. Among all multidimensional data, third-order tensor is the most prevalent structure in real-world scenarios, such as RGB images and network traffic data. Previous studies in this field are mainly based on tensor Tucker decomposition and such methods have limitations in terms of computational cost, with iteration complexity of approximately $O(2n^3r)$, where $n$ and $r$ are the dimension and rank of original tensor data. Moreover, many real-world data does not exhibit the low-rank property under Tucker decomposition, which may fail the dimensionality reduction. In this paper, we pioneer the application of tensor singular value decomposition (t-SVD) to third-order time-series, which builds an efficient forecasting algorithm, called Low-rank Tensor Autoregressive Predictor (LOTAP). We observe that tensor tubal rank in t-SVD is always less than Tucker rank, which leads to great benefit in computational complexity. By combining it with the autoregressive (AR) model, the forecasting problem is formulated as a least squares optimization. We divide such an optimization problem by fast Fourier transformation into four decoupled subproblems, whose variables include regressive coefficient, f-diagonal tensor, left and right orthogonal tensors. The alternating minimization algorithm is proposed with iteration complexity of about $O(n^3 + n^2r^2)$, in which each subproblem has a closed-form solution. Numerical experiments show that, compared to Tucker-decomposition-based algorithms, LOTAP achieves a speed improvement ranging from 2 to 6 times while maintaining accurate forecasting performance in all four baseline tasks. In addition, LOTAP is applicable to a wider range of tensor forecasting tasks due to its more effective dimensionality reduction ability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02835v1</guid>
      <category>math.OC</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haoning Wang, Liping Zhang, Shengbo Eben Li</dc:creator>
    </item>
    <item>
      <title>Forced Symmetric Formation Control</title>
      <link>https://arxiv.org/abs/2403.02836</link>
      <description>arXiv:2403.02836v1 Announce Type: new 
Abstract: This work considers the distance constrained formation control problem with an additional constraint requiring that the formation exhibits a specified spatial symmetry. We employ recent results from the theory of symmetry-forced rigidity to construct an appropriate potential function that leads to a gradient dynamical system driving the agents to the desired formation. We show that only $(1+1/|\Gamma|)n$ edges are sufficient to implement the control strategy when there are $n$ agents and the underlying symmetry group is $\Gamma$. This number is considerably smaller than what is typically required from classic rigidity-theory based strategies ($2n-3$ edges). We also provide an augmented control strategy that ensures the agents can converge to a formation with respect to an arbitrary centroid. Numerous numerical examples are provided to illustrate the main results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02836v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Daniel Zelazo, Shin-ichi Tanigawa, Bernd Schulze</dc:creator>
    </item>
    <item>
      <title>Trajectory stabilization of nonlocal continuity equations by localized controls</title>
      <link>https://arxiv.org/abs/2403.02837</link>
      <description>arXiv:2403.02837v1 Announce Type: new 
Abstract: We discuss stabilization around trajectories of the continuity equation with nonlocal vector fields, where the control is localized, i.e., it acts on a fixed subset of the configuration space. We first show that the correct definition of stabilization is the following: given an initial error of order $\varepsilon$, measured in Wasserstein distance, one can improve the final error to an order $\varepsilon^{1+\kappa}$ with $\kappa&gt;0$. We then prove the main result: assuming that the trajectory crosses the subset of control action, stabilization can be achieved. The key problem lies in regularity issues: the reference trajectory needs to be absolutely continuous, while the initial state to be stabilized needs to be realized by a small Lipschitz perturbation or being in a very small neighborhood of it.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02837v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikolay Pogodaev, Francesco Rossi</dc:creator>
    </item>
    <item>
      <title>Novel Limited Memory Quasi-Newton Methods Based On Optimal Matrix Approximation</title>
      <link>https://arxiv.org/abs/2403.02860</link>
      <description>arXiv:2403.02860v1 Announce Type: new 
Abstract: Update formulas for the Hessian approximations in quasi-Newton methods such as BFGS can be derived as analytical solutions to certain nearest-matrix problems. In this article, we propose a similar idea for deriving new limited memory versions of quasi-Newton methods. Most limited memory quasi-Newton methods make use of Hessian approximations that can be written as a scaled identity matrix plus a symmetric matrix with limited rank. We derive a way of finding the nearest matrix of this type to an arbitrary symmetric matrix, in either the Frobenius norm, the induced $l^2$ norm, or a dissimilarity measure for positive definite matrices in terms of trace and determinant. In doing so, we lay down a framework for more general matrix optimization problems with unitarily invariant matrix norms and arbitrary constraints on the set of eigenvalues. We then propose a trust region method in which the Hessian approximation, after having been updated by a Broyden class formula and used to solve a trust-region problem, is replaced by one of its closest limited memory approximations. We propose to store the Hessian approximation in terms of its eigenvectors and eigenvalues in a way that completely defines its eigenvalue decomposition, as this simplifies both the solution of the trust region subproblem and the nearest limited memory matrix problem. Our method is compared to a reference trust region method with the usual limited memory BFGS updates, and is shown to require fewer iterations and the storage of fewer vectors for a variety of test problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02860v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Erik Berglund, Mikael Johansson</dc:creator>
    </item>
    <item>
      <title>Efficient sparse probability measures recovery via Bregman gradient</title>
      <link>https://arxiv.org/abs/2403.02861</link>
      <description>arXiv:2403.02861v1 Announce Type: new 
Abstract: This paper presents an algorithm tailored for the efficient recovery of sparse probability measures incorporating $\ell_0$-sparse regularization within the probability simplex constraint. Employing the Bregman proximal gradient method, our algorithm achieves sparsity by explicitly solving underlying subproblems. We rigorously establish the convergence properties of the algorithm, showcasing its capacity to converge to a local minimum with a convergence rate of $O(1/k)$ under mild assumptions. To substantiate the efficacy of our algorithm, we conduct numerical experiments, offering a compelling demonstration of its efficiency in recovering sparse probability measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02861v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jianting Pan, Ming Yan</dc:creator>
    </item>
    <item>
      <title>Design of full order proportional-integral observer for the state estimation of discrete-time linear time-invariant systems</title>
      <link>https://arxiv.org/abs/2403.02891</link>
      <description>arXiv:2403.02891v1 Announce Type: new 
Abstract: This paper is devoted to the design of full order proportional-integral observer for the state estimation of discrete-time linear time-invariant systems. In particular, explicit necessary and sufficient conditions are established for the existence of proportional-integral observer for the state estimation of discrete-time linear time-invariant systems and a simple procedure is given for the construction of the observer. Our approach is based on properties of real and polynomial matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02891v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstadinos H. Kiritsis</dc:creator>
    </item>
    <item>
      <title>Mirror Descent Algorithms with Nearly Dimension-Independent Rates for Differentially-Private Stochastic Saddle-Point Problems</title>
      <link>https://arxiv.org/abs/2403.02912</link>
      <description>arXiv:2403.02912v1 Announce Type: new 
Abstract: We study the problem of differentially-private (DP) stochastic (convex-concave) saddle-points in the polyhedral setting. We propose $(\varepsilon, \delta)$-DP algorithms based on stochastic mirror descent that attain nearly dimension-independent convergence rates for the expected duality gap, a type of guarantee that was known before only for bilinear objectives. For convex-concave and first-order-smooth stochastic objectives, our algorithms attain a rate of $\sqrt{\log(d)/n} + (\log(d)^{3/2}/[n\varepsilon])^{1/3}$, where $d$ is the dimension of the problem and $n$ the dataset size. Under an additional second-order-smoothness assumption, we improve the rate on the expected gap to $\sqrt{\log(d)/n} + (\log(d)^{3/2}/[n\varepsilon])^{2/5}$. Under this additional assumption, we also show, by using bias-reduced gradient estimators, that the duality gap is bounded by $\log(d)/\sqrt{n} + \log(d)/[n\varepsilon]^{1/2}$ with constant success probability. This result provides evidence of the near-optimality of the approach. Finally, we show that combining our methods with acceleration techniques from online learning leads to the first algorithm for DP Stochastic Convex Optimization in the polyhedral setting that is not based on Frank-Wolfe methods. For convex and first-order-smooth stochastic objectives, our algorithms attain an excess risk of $\sqrt{\log(d)/n} + \log(d)^{7/10}/[n\varepsilon]^{2/5}$, and when additionally assuming second-order-smoothness, we improve the rate to $\sqrt{\log(d)/n} + \log(d)/\sqrt{n\varepsilon}$. Instrumental to all of these results are various extensions of the classical Maurey Sparsification Lemma, which may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02912v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tom\'as Gonz\'alez, Crist\'obal Guzm\'an, Courtney Paquette</dc:creator>
    </item>
    <item>
      <title>Risk-Constrained Community Battery Utilisation Optimisation for Electric Vehicle Charging with Photovoltaic Resources</title>
      <link>https://arxiv.org/abs/2403.02927</link>
      <description>arXiv:2403.02927v1 Announce Type: new 
Abstract: High penetration of renewable generation in the electricity grid presents power system operators with challenges including voltage instability mainly due to fluctuating power generation. To cope with intermittent generation, community batteries introduce an elegant solution for storing excess generation of renewable resources and reverting to the grid in peak demand periods. The question of the right battery type and size coupled with the right investment is challenging. Furthermore, the growth in adapting EVs imposes additional demand challenges on the power system compared to traditional industrial and household demand. This paper introduces long-term planning for community batteries to capture the surplus generation of PV resources for a given area and redirect these resources to charge EVs, without direct injection to the grid. For long-term investment planning on batteries, we consider 15 years' worth of historical data associated with solar irradiance, temperature, EV demands, and household demands. A novel stochastic mathematical model is proposed for decision-making on battery specifications (the type and capacity per year) based on the four standard battery types provided by the CSIRO in Australia. Uncertainties related to the EVs and RESs are captured by a non-parametric robust technique, named information gap decision theory, from optimistic and pessimistic perspectives. The investment decision-making part is formulated as mixed-integer linear programming taking advantage of the powerful commercial solver -- GUROBI -- which leads to finding feasible global solutions with low computational burden. The outcomes of this investigation not only detect optimal battery installation strategies to improve the stability profile of the grid by capturing the excess generation of PV resources but also facilitate EV integration in the community toward reaching net-zero emissions targets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02927v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Khalil Gholami, Asef Nazari, Dhnanjay Thiruvady, Valeh Moghaddam, Sutharshan Rajasegarar, Wei-Yu Chiu</dc:creator>
    </item>
    <item>
      <title>Non-Convex Stochastic Composite Optimization with Polyak Momentum</title>
      <link>https://arxiv.org/abs/2403.02967</link>
      <description>arXiv:2403.02967v1 Announce Type: new 
Abstract: The stochastic proximal gradient method is a powerful generalization of the widely used stochastic gradient descent (SGD) method and has found numerous applications in Machine Learning. However, it is notoriously known that this method fails to converge in non-convex settings where the stochastic noise is significant (i.e. when only small or bounded batch sizes are used). In this paper, we focus on the stochastic proximal gradient method with Polyak momentum. We prove this method attains an optimal convergence rate for non-convex composite optimization problems, regardless of batch size. Additionally, we rigorously analyze the variance reduction effect of the Polyak momentum in the composite optimization setting and we show the method also converges when the proximal step can only be solved inexactly. Finally, we provide numerical experiments to validate our theoretical results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02967v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuan Gao, Anton Rodomanov, Sebastian U. Stich</dc:creator>
    </item>
    <item>
      <title>Model Predictive Control for setpoint tracking</title>
      <link>https://arxiv.org/abs/2403.02973</link>
      <description>arXiv:2403.02973v1 Announce Type: new 
Abstract: The main objective of tracking control is to steer the tracking error, that is the difference between the reference and the output, to zero while the plant's operation limits are satisfied. This requires that some assumptions on the evolution of the future values of the reference must be taken into account. Typically a simple evolution of the reference is considered, such as step, ramp, or parabolic reference signals. It is important to notice that the tracking problem considers possible variations in the reference to be tracked, such as steps or slope variations of the ramps. Then the tracking control problem is inherently uncertain, since the reference may differ from what is expected. If the value of the reference is changed, then there is no guarantee that the feasibility and stability properties of the resulting control law hold. This report presents the MPC for tracking (MPCT) approach, which ensures recursive feasibility and asymptotic stability of the setpoint when the value of the reference is changed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02973v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Limon, Antonio Ferramosca, Ignacio Alvarado, Teodoro Alamo</dc:creator>
    </item>
    <item>
      <title>A hybrid optimization framework for the General Continuous Energy-Constrained Scheduling Problem</title>
      <link>https://arxiv.org/abs/2403.03039</link>
      <description>arXiv:2403.03039v1 Announce Type: new 
Abstract: We present a hybrid optimization framework for a class of problems, formalized as a generalization of the Continuous Energy-Con\-strained Scheduling Problem (CECSP), introduced by Nattaf et al. (2014). This class is obtained from challenges concerning demand response in energy networks. Our framework extends a previously developed approach. A set of jobs has to be processed on a continuous, shared resource. Consequently, a schedule for a job does not only contain a start and completion time, but also a resource consumption profile, where we have to respect lower and upper bounds on resource consumption during processing. In this work, we develop a hybrid approach for the case where the objective is a step-wise increasing function of completion time, using local search, linear programming and O(n) lower bounds. We exploit that the costs are known in the local search and use bounds to assess feasibility more efficiently than by LP. We compare its performance to a mixed-integer linear program. After that, we extend this to a hybrid optimization framework for the General CECSP. This uses an event-based model, and applies a decomposition in two parts: 1) determining the order of events and 2) finding the event times, and hence the start and completion times of jobs, together with the resource consumption profiles. We argue the broad applicability of this framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03039v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roel Brouwer, Marjan van den Akker, Han Hoogeveen</dc:creator>
    </item>
    <item>
      <title>Geometry-dependent matching pursuit: a transition phase for convergence on linear regression and LASSO</title>
      <link>https://arxiv.org/abs/2403.03072</link>
      <description>arXiv:2403.03072v1 Announce Type: new 
Abstract: Greedy first-order methods, such as coordinate descent with Gauss-Southwell rule or matching pursuit, have become popular in optimization due to their natural tendency to propose sparse solutions and their refined convergence guarantees. In this work, we propose a principled approach to generating (regularized) matching pursuit algorithms adapted to the geometry of the problem at hand, as well as their convergence guarantees. Building on these results, we derive approximate convergence guarantees and describe a transition phenomenon in the convergence of (regularized) matching pursuit from underparametrized to overparametrized models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03072v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>C\'eline Moucer, Adrien Taylor, Francis Bach</dc:creator>
    </item>
    <item>
      <title>Low-rank approximated Kalman-Bucy filters using Oja's principal component flow for linear time-invariant systems</title>
      <link>https://arxiv.org/abs/2403.03104</link>
      <description>arXiv:2403.03104v1 Announce Type: new 
Abstract: The Kalman-Bucy filter is widely used in various applications. However, the filter becomes computationally complex under large-scale systems. To address this problem, a low-rank approximated Kalman-Bucy filter consisting of Oja's principal component flow and a low-dimensional Riccati differential equation was proposed. However, the estimation error was established only for linear time-invariant systems with a symmetric system matrix. This study removes restrictions on the symmetricity of the system matrix and reveals the equilibrium points of the Oja flow and their stability for general real square matrices. In addition, the attraction domain for a set of stable equilibrium points is estimated. Based on these results, we demonstrate that the low-rank approximated Kalman-Bucy filter has a bounded estimation error covariance matrix when the system is controllable and observable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03104v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daiki Tsuzuki, Kentaro Ohki</dc:creator>
    </item>
    <item>
      <title>Grid-constrained online scheduling of flexible electric vehicle charging</title>
      <link>https://arxiv.org/abs/2403.03109</link>
      <description>arXiv:2403.03109v1 Announce Type: new 
Abstract: We study Electric Vehicle (EV) charging from a scheduling perspective, aiming to minimize delays while respecting the grid constraints. A network of parking lots is considered, each with a given number of charging stations for electric vehicles. Some of the parking lots have a roof with solar panels. The demand that can be served at each parking lot is limited by the capacity of the cables connecting them to the grid. We assume that EVs arrive at the parking lots according to a known distribution. Upon arrival, we learn the desired departure time, the amount of electrical energy it needs to charge its battery, and the range of rates that it can be charged at. Vehicle arrival patterns, connection times, and charging volume are based on data collected in the city of Utrecht. The departure time of an EV is delayed if it has not finished charging in time for its desired departure. We aim to minimize the total delay. We present a novel approach, based on an online variant of well-known schedule generation schemes. We extend these schemes and include them in a destroy-and-repair heuristic. This resulted in several scheduling strategies. We show their effectiveness using a discrete event simulation. With this, we show that applying scheduling approaches increases the amount of EVs that can be charged at a site and reduces the average delay. Furthermore, we argue the importance of considering aspects of the grid layout in electricity networks and show the benefits of using flexible charging rates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03109v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emily van Huffelen, Roel Brouwer, Marjan van den Akker</dc:creator>
    </item>
    <item>
      <title>A Comprehensive Stochastic Programming Model for Transfer Synchronization in Transit Networks</title>
      <link>https://arxiv.org/abs/2403.03130</link>
      <description>arXiv:2403.03130v1 Announce Type: new 
Abstract: We investigate the stochastic transfer synchronization problem, which seeks to synchronize the timetables of different routes in a transit network to reduce transfer waiting times, delay times, and unnecessary in-vehicle times. We present a sophisticated two-stage stochastic mixed-integer programming model that takes into account variability in passenger walking times between bus stops, bus running times, dwell times, and demand uncertainty. Our model incorporates new features related to dwell time determination by considering passenger arrival patterns at bus stops which have been neglected in the literature on transfer synchronization and timetabling. We solve a sample average approximation of our model using a problem-based scenario reduction approach, and the progressive hedging algorithm. As a proof of concept, our computational experiments on two single transfer nodes in the City of Toronto, with a mixture of low- and high-frequency routes, demonstrate the potential advantages of the proposed model. Our findings highlight the necessity and value of incorporating stochasticity in transfer-based timetabling models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03130v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zahra Ansarilari, Merve Bodur, Amer Shalaby</dc:creator>
    </item>
    <item>
      <title>Shuffling Momentum Gradient Algorithm for Convex Optimization</title>
      <link>https://arxiv.org/abs/2403.03180</link>
      <description>arXiv:2403.03180v1 Announce Type: new 
Abstract: The Stochastic Gradient Descent method (SGD) and its stochastic variants have become methods of choice for solving finite-sum optimization problems arising from machine learning and data science thanks to their ability to handle large-scale applications and big datasets. In the last decades, researchers have made substantial effort to study the theoretical performance of SGD and its shuffling variants. However, only limited work has investigated its shuffling momentum variants, including shuffling heavy-ball momentum schemes for non-convex problems and Nesterov's momentum for convex settings. In this work, we extend the analysis of the shuffling momentum gradient method developed in [Tran et al (2021)] to both finite-sum convex and strongly convex optimization problems. We provide the first analysis of shuffling momentum-based methods for the strongly convex setting, attaining a convergence rate of $O(1/nT^2)$, where $n$ is the number of samples and $T$ is the number of training epochs. Our analysis is a state-of-the-art, matching the best rates of existing shuffling stochastic gradient algorithms in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03180v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Trang H. Tran, Quoc Tran-Dinh, Lam M. Nguyen</dc:creator>
    </item>
    <item>
      <title>On the impact of measure pre-conditionings on general parametric ML models and transfer learning via domain adaptation</title>
      <link>https://arxiv.org/abs/2403.02432</link>
      <description>arXiv:2403.02432v1 Announce Type: cross 
Abstract: We study a new technique for understanding convergence of learning agents under small modifications of data. We show that such convergence can be understood via an analogue of Fatou's lemma which yields gamma-convergence. We show it's relevance and applications in general machine learning tasks and domain adaptation transfer learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02432v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Joaqu\'in S\'anchez Garc\'ia</dc:creator>
    </item>
    <item>
      <title>A Simple Finite-Time Analysis of TD Learning with Linear Function Approximation</title>
      <link>https://arxiv.org/abs/2403.02476</link>
      <description>arXiv:2403.02476v1 Announce Type: cross 
Abstract: We study the finite-time convergence of TD learning with linear function approximation under Markovian sampling. Existing proofs for this setting either assume a projection step in the algorithm to simplify the analysis, or require a fairly intricate argument to ensure stability of the iterates. We ask: \textit{Is it possible to retain the simplicity of a projection-based analysis without actually performing a projection step in the algorithm?} Our main contribution is to show this is possible via a novel two-step argument. In the first step, we use induction to prove that under a standard choice of a constant step-size $\alpha$, the iterates generated by TD learning remain uniformly bounded in expectation. In the second step, we establish a recursion that mimics the steady-state dynamics of TD learning up to a bounded perturbation on the order of $O(\alpha^2)$ that captures the effect of Markovian sampling. Combining these pieces leads to an overall approach that considerably simplifies existing proofs. We conjecture that our inductive proof technique will find applications in the analyses of more complex stochastic approximation algorithms, and conclude by providing some examples of such applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02476v1</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Aritra Mitra</dc:creator>
    </item>
    <item>
      <title>DNNLasso: Scalable Graph Learning for Matrix-Variate Data</title>
      <link>https://arxiv.org/abs/2403.02608</link>
      <description>arXiv:2403.02608v1 Announce Type: cross 
Abstract: We consider the problem of jointly learning row-wise and column-wise dependencies of matrix-variate observations, which are modelled separately by two precision matrices. Due to the complicated structure of Kronecker-product precision matrices in the commonly used matrix-variate Gaussian graphical models, a sparser Kronecker-sum structure was proposed recently based on the Cartesian product of graphs. However, existing methods for estimating Kronecker-sum structured precision matrices do not scale well to large scale datasets. In this paper, we introduce DNNLasso, a diagonally non-negative graphical lasso model for estimating the Kronecker-sum structured precision matrix, which outperforms the state-of-the-art methods by a large margin in both accuracy and computational time. Our code is available at https://github.com/YangjingZhang/DNNLasso.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02608v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Meixia Lin, Yangjing Zhang</dc:creator>
    </item>
    <item>
      <title>Privacy in Multi-agent Systems</title>
      <link>https://arxiv.org/abs/2403.02631</link>
      <description>arXiv:2403.02631v1 Announce Type: cross 
Abstract: With the increasing awareness of privacy and the deployment of legislations in various multi-agent system application domains such as power systems and intelligent transportation, the privacy protection problem for multi-agent systems is gaining increased traction in recent years. This article discusses some of the representative advancements in the filed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02631v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yongqiang Wang</dc:creator>
    </item>
    <item>
      <title>Remove that Square Root: A New Efficient Scale-Invariant Version of AdaGrad</title>
      <link>https://arxiv.org/abs/2403.02648</link>
      <description>arXiv:2403.02648v1 Announce Type: cross 
Abstract: Adaptive methods are extremely popular in machine learning as they make learning rate tuning less expensive. This paper introduces a novel optimization algorithm named KATE, which presents a scale-invariant adaptation of the well-known AdaGrad algorithm. We prove the scale-invariance of KATE for the case of Generalized Linear Models. Moreover, for general smooth non-convex problems, we establish a convergence rate of $O \left(\frac{\log T}{\sqrt{T}} \right)$ for KATE, matching the best-known ones for AdaGrad and Adam. We also compare KATE to other state-of-the-art adaptive algorithms Adam and AdaGrad in numerical experiments with different problems, including complex machine learning tasks like image classification and text classification on real data. The results indicate that KATE consistently outperforms AdaGrad and matches/surpasses the performance of Adam in all considered scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02648v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sayantan Choudhury, Nazarii Tupitsa, Nicolas Loizou, Samuel Horvath, Martin Takac, Eduard Gorbunov</dc:creator>
    </item>
    <item>
      <title>SGD with Partial Hessian for Deep Neural Networks Optimization</title>
      <link>https://arxiv.org/abs/2403.02681</link>
      <description>arXiv:2403.02681v1 Announce Type: cross 
Abstract: Due to the effectiveness of second-order algorithms in solving classical optimization problems, designing second-order optimizers to train deep neural networks (DNNs) has attracted much research interest in recent years. However, because of the very high dimension of intermediate features in DNNs, it is difficult to directly compute and store the Hessian matrix for network optimization. Most of the previous second-order methods approximate the Hessian information imprecisely, resulting in unstable performance. In this work, we propose a compound optimizer, which is a combination of a second-order optimizer with a precise partial Hessian matrix for updating channel-wise parameters and the first-order stochastic gradient descent (SGD) optimizer for updating the other parameters. We show that the associated Hessian matrices of channel-wise parameters are diagonal and can be extracted directly and precisely from Hessian-free methods. The proposed method, namely SGD with Partial Hessian (SGD-PH), inherits the advantages of both first-order and second-order optimizers. Compared with first-order optimizers, it adopts a certain amount of information from the Hessian matrix to assist optimization, while compared with the existing second-order optimizers, it keeps the good generalization performance of first-order optimizers. Experiments on image classification tasks demonstrate the effectiveness of our proposed optimizer SGD-PH. The code is publicly available at \url{https://github.com/myingysun/SGDPH}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02681v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ying Sun, Hongwei Yong, Lei Zhang</dc:creator>
    </item>
    <item>
      <title>A Two-Stage Training Method for Modeling Constrained Systems With Neural Networks</title>
      <link>https://arxiv.org/abs/2403.02730</link>
      <description>arXiv:2403.02730v1 Announce Type: cross 
Abstract: Real-world systems are often formulated as constrained optimization problems. Techniques to incorporate constraints into Neural Networks (NN), such as Neural Ordinary Differential Equations (Neural ODEs), have been used. However, these introduce hyperparameters that require manual tuning through trial and error, raising doubts about the successful incorporation of constraints into the generated model. This paper describes in detail the two-stage training method for Neural ODEs, a simple, effective, and penalty parameter-free approach to model constrained systems. In this approach the constrained optimization problem is rewritten as two unconstrained sub-problems that are solved in two stages. The first stage aims at finding feasible NN parameters by minimizing a measure of constraints violation. The second stage aims to find the optimal NN parameters by minimizing the loss function while keeping inside the feasible region. We experimentally demonstrate that our method produces models that satisfy the constraints and also improves their predictive performance. Thus, ensuring compliance with critical system properties and also contributing to reducing data quantity requirements. Furthermore, we show that the proposed method improves the convergence to an optimal solution and improves the explainability of Neural ODE models. Our proposed two-stage training method can be used with any NN architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02730v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>C. Coelho, M. Fernanda P. Costa, L. L. Ferr\'as</dc:creator>
    </item>
    <item>
      <title>Data Collaboration Analysis Over Matrix Manifolds</title>
      <link>https://arxiv.org/abs/2403.02780</link>
      <description>arXiv:2403.02780v1 Announce Type: cross 
Abstract: The effectiveness of machine learning (ML) algorithms is deeply intertwined with the quality and diversity of their training datasets. Improved datasets, marked by superior quality, enhance the predictive accuracy and broaden the applicability of models across varied scenarios. Researchers often integrate data from multiple sources to mitigate biases and limitations of single-source datasets. However, this extensive data amalgamation raises significant ethical concerns, particularly regarding user privacy and the risk of unauthorized data disclosure. Various global legislative frameworks have been established to address these privacy issues. While crucial for safeguarding privacy, these regulations can complicate the practical deployment of ML technologies. Privacy-Preserving Machine Learning (PPML) addresses this challenge by safeguarding sensitive information, from health records to geolocation data, while enabling the secure use of this data in developing robust ML models. Within this realm, the Non-Readily Identifiable Data Collaboration (NRI-DC) framework emerges as an innovative approach, potentially resolving the 'data island' issue among institutions through non-iterative communication and robust privacy protections. However, in its current state, the NRI-DC framework faces model performance instability due to theoretical unsteadiness in creating collaboration functions. This study establishes a rigorous theoretical foundation for these collaboration functions and introduces new formulations through optimization problems on matrix manifolds and efficient solutions. Empirical analyses demonstrate that the proposed approach, particularly the formulation over orthogonal matrix manifolds, significantly enhances performance, maintaining consistency and efficiency without compromising communication efficiency or privacy protections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02780v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Keiyu Nosaka, Akiko Yoshise</dc:creator>
    </item>
    <item>
      <title>An Adaptive Hydropower Management Approach for Downstream Ecosystem Preservation</title>
      <link>https://arxiv.org/abs/2403.02821</link>
      <description>arXiv:2403.02821v1 Announce Type: cross 
Abstract: Hydropower plants play a pivotal role in advancing clean and sustainable energy production, contributing significantly to the global transition towards renewable energy sources. However, hydropower plants are currently perceived both positively as sources of renewable energy and negatively as disruptors of ecosystems. In this work, we highlight the overlooked potential of using hydropower plant as protectors of ecosystems by using adaptive ecological discharges. To advocate for this perspective, we propose using a neural network to predict the minimum ecological discharge value at each desired time. Additionally, we present a novel framework that seamlessly integrates it into hydropower management software, taking advantage of the well-established approach of using traditional constrained optimisation algorithms. This novel approach not only protects the ecosystems from climate change but also contributes to potentially increase the electricity production.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02821v1</guid>
      <category>cs.LG</category>
      <category>cs.CE</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>C. Coelho, M. Jing, M. Fernanda P. Costa, L. L. Ferr\'as</dc:creator>
    </item>
    <item>
      <title>ISC: an RADI-type method for stochastic continuous-time algebraic Riccati equations</title>
      <link>https://arxiv.org/abs/2403.02940</link>
      <description>arXiv:2403.02940v1 Announce Type: cross 
Abstract: In this paper, we propose an RADI-type method for large-scale stochastic continuous-time algebraic Riccati equations with sparse and low-rank structures. The so-called ISC method is developed by using the Incorporation idea together with different Shifts to accelerate the convergence and Compressions to reduce the storage and complexity. Numerical experiments are given to show its efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02940v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhen-Chen Guo, Xin Liang</dc:creator>
    </item>
    <item>
      <title>A Convex Optimization Framework for Computing Robustness Margins of Kalman Filters</title>
      <link>https://arxiv.org/abs/2403.02996</link>
      <description>arXiv:2403.02996v1 Announce Type: cross 
Abstract: This paper proposes a novel convex optimization framework for designing robust Kalman filters that guarantee a user-specified steady-state error while maximizing process and sensor noise. The proposed framework simultaneously determines the Kalman gain and the robustness margin in terms of the process and sensor noise. This is the first paper to present such a joint formulation for Kalman filtering. The proposed methodology is validated through two distinct examples: the Clohessy-Wiltshire-Hill equations for a chaser spacecraft in an elliptical orbit and the longitudinal motion model of an F-16 aircraft.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02996v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Himanshu Prabhat, Raktim Bhattacharya</dc:creator>
    </item>
    <item>
      <title>Unifying Controller Design for Stabilizing Nonlinear Systems with Norm-Bounded Control Inputs</title>
      <link>https://arxiv.org/abs/2403.03030</link>
      <description>arXiv:2403.03030v1 Announce Type: cross 
Abstract: This paper revisits a classical challenge in the design of stabilizing controllers for nonlinear systems with a norm-bounded input constraint. By extending Lin-Sontag's universal formula and introducing a generic (state-dependent) scaling term, a unifying controller design method is proposed. The incorporation of this generic scaling term gives a unified controller and enables the derivation of alternative universal formulas with various favorable properties, which makes it suitable for tailored control designs to meet specific requirements and provides versatility across different control scenarios. Additionally, we present a constructive approach to determine the optimal scaling term, leading to an explicit solution to an optimization problem, named optimization-based universal formula. The resulting controller ensures asymptotic stability, satisfies a norm-bounded input constraint, and optimizes a predefined cost function. Finally, the essential properties of the unified controllers are analyzed, including smoothness, continuity at the origin, stability margin, and inverse optimality. Simulations validate the approach, showcasing its effectiveness in addressing a challenging stabilizing control problem of a nonlinear system.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03030v1</guid>
      <category>eess.SY</category>
      <category>cs.AI</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ming Li, Zhiyong Sun, Siep Weiland</dc:creator>
    </item>
    <item>
      <title>Learning Explicitly Conditioned Sparsifying Transforms</title>
      <link>https://arxiv.org/abs/2403.03168</link>
      <description>arXiv:2403.03168v1 Announce Type: cross 
Abstract: Sparsifying transforms became in the last decades widely known tools for finding structured sparse representations of signals in certain transform domains. Despite the popularity of classical transforms such as DCT and Wavelet, learning optimal transforms that guarantee good representations of data into the sparse domain has been recently analyzed in a series of papers. Typically, the conditioning number and representation ability are complementary key features of learning square transforms that may not be explicitly controlled in a given optimization model. Unlike the existing approaches from the literature, in our paper, we consider a new sparsifying transform model that enforces explicit control over the data representation quality and the condition number of the learned transforms. We confirm through numerical experiments that our model presents better numerical behavior than the state-of-the-art.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03168v1</guid>
      <category>math.NA</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrei P\u{a}tra\c{s}cu, Cristian Rusu, Paul Irofti</dc:creator>
    </item>
    <item>
      <title>How Well Can Transformers Emulate In-context Newton's Method?</title>
      <link>https://arxiv.org/abs/2403.03183</link>
      <description>arXiv:2403.03183v1 Announce Type: cross 
Abstract: Transformer-based models have demonstrated remarkable in-context learning capabilities, prompting extensive research into its underlying mechanisms. Recent studies have suggested that Transformers can implement first-order optimization algorithms for in-context learning and even second order ones for the case of linear regression. In this work, we study whether Transformers can perform higher order optimization methods, beyond the case of linear regression. We establish that linear attention Transformers with ReLU layers can approximate second order optimization algorithms for the task of logistic regression and achieve $\epsilon$ error with only a logarithmic to the error more layers. As a by-product we demonstrate the ability of even linear attention-only Transformers in implementing a single step of Newton's iteration for matrix inversion with merely two layers. These results suggest the ability of the Transformer architecture to implement complex algorithms, beyond gradient descent.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03183v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Angeliki Giannou, Liu Yang, Tianhao Wang, Dimitris Papailiopoulos, Jason D. Lee</dc:creator>
    </item>
    <item>
      <title>Optimal actuator design based on shape calculus</title>
      <link>https://arxiv.org/abs/1711.01183</link>
      <description>arXiv:1711.01183v2 Announce Type: replace 
Abstract: An approach to optimal actuator design based on shape and topology optimisation techniques is presented. For linear diffusion equations, two scenarios are considered. For the first one, best actuators are determined depending on a given initial condition. In the second scenario, optimal actuators are determined based on all initial conditions not exceeding a chosen norm. Shape and topological sensitivities of these cost functionals are determined. A numerical algorithm for optimal actuator design based on the sensitivities and a level-set method is presented. Numerical results support the proposed methodology.</description>
      <guid isPermaLink="false">oai:arXiv.org:1711.01183v2</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dante Kalise, Karl Kunisch, Kevin Sturm</dc:creator>
    </item>
    <item>
      <title>Solving Low-Rank Semidefinite Programs via Manifold Optimization</title>
      <link>https://arxiv.org/abs/2303.01722</link>
      <description>arXiv:2303.01722v3 Announce Type: replace 
Abstract: We propose a manifold optimization approach to solve linear semidefinite programs (SDP) with low-rank solutions. This approach incorporates the inexact augmented Lagrangian method (ALM) and the Burer-Monteiro factorization, and features the self-adaptive strategies for updating the factorization size and the penalty parameter. We establish global convergence of the inexact ALM, despite the non-convexity brought by the Burer-Monteiro factorization. We provide a practical algorithm building on the inexact ALM, and along with the algorithm we release an open-source SDP solver ManiSDP. Comprehensive numerical experiments demonstrate that ManiSDP achieves state-of-the-art in terms of efficiency, accuracy, and scalability, and is faster than several advanced SDP solvers (MOSEK, SDPLR, SDPNAL+, STRIDE) by up to orders of magnitudes on a variety of linear SDPs. The largest SDP solved by ManiSDP (in about 8.5 hours with maximal KKT residue 3.5e-13) is the second-order moment relaxation of a binary quadratic program with 120 variables, which has matrix dimension 7261 and contains 17,869,161 affine constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.01722v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Wang, Liangbing Hu</dc:creator>
    </item>
    <item>
      <title>Approximate propagation of normal distributions for stochastic optimal control of nonsmooth systems</title>
      <link>https://arxiv.org/abs/2308.03431</link>
      <description>arXiv:2308.03431v2 Announce Type: replace 
Abstract: We present a method for the approximate propagation of mean and covariance of a probability distribution through ordinary differential equations (ODE) with discontinous right-hand side. For piecewise affine systems, a normalization of the propagated probability distribution at every time step allows us to analytically compute the expectation integrals of the mean and covariance dynamics while explicitly taking into account the discontinuity. This leads to a natural smoothing of the discontinuity such that for relevant levels of uncertainty the resulting ODE can be integrated directly with standard schemes and it is neither necessary to prespecify the switching sequence nor to use a switch detection method. We then show how this result can be employed in the more general case of piecewise smooth functions based on a structure preserving linearization scheme. The resulting dynamics can be straightforwardly used within standard formulations of stochastic optimal control problems with chance constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.03431v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Florian Messerer, Katrin Baumg\"artner, Armin Nurkanovi\'c, Moritz Diehl</dc:creator>
    </item>
    <item>
      <title>Bilinear control of semilinear elliptic PDEs: Convergence of a semismooth Newton method</title>
      <link>https://arxiv.org/abs/2309.07554</link>
      <description>arXiv:2309.07554v2 Announce Type: replace 
Abstract: In this paper, we carry out the analysis of the semismooth Newton method for bilinear control problems related to semilinear elliptic PDEs. We prove existence, uniqueness and regularity for the solution of the state equation, as well as differentiability properties of the control to state mapping. Then, first and second order optimality conditions are obtained. Finally, we prove the superlinear convergence of the semismooth Newton method to local solutions satisfying no-gap second order sufficient optimality conditions as well as a strict complementarity condition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.07554v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Eduardo Casas, Konstantinos Chrysafinos, Mariano Mateos</dc:creator>
    </item>
    <item>
      <title>A Nationwide Multi-Location Multi-Resource Stochastic Programming Based Energy Planning Framework</title>
      <link>https://arxiv.org/abs/2310.04441</link>
      <description>arXiv:2310.04441v2 Announce Type: replace 
Abstract: The global increase in energy consumption and demand has forced many countries to transition into including more diverse energy sources in their electricity market. To efficiently utilize the available fuel resources, all energy sources must be optimized simultaneously. However, the inherent variability in variable renewable energy generators makes deterministic models ineffective. On the other hand, comprehensive stochastic models, including all sources of generation across a nation, can become computationally intractable. This work proposes a comprehensive national energy planning framework from a policymaker's perspective, which is generalizable to any country, region, or any group of countries in energy trade agreements. Given its relative land area and energy consumption globally, the United States is selected as a case study. A two-stage stochastic programming approach is adopted, and a scenario-based Benders decomposition modeling approach is employed to achieve computational efficiency for the large-scale model. Data is obtained from the U.S. Energy Information Administration's online data collection. Scenarios for the uncertain parameters are developed using a k-means clustering algorithm. Various cases are compared from a financial perspective to inform policymaking by identifying implementable cost-reduction strategies. The findings underscore the importance of promoting resource coordination and demonstrate the impact of increasing interchange and renewable energy capacity on overall gains. Moreover, the study highlights the value of stochastic optimization modeling compared to deterministic modeling to make energy planning decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.04441v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Razan A. H. Al-Lawati, Tasnim Ibn Faiz, Md. Noor-E-Alam</dc:creator>
    </item>
    <item>
      <title>Near-Optimal Convex Simple Bilevel Optimization with a Bisection Method</title>
      <link>https://arxiv.org/abs/2402.05415</link>
      <description>arXiv:2402.05415v2 Announce Type: replace 
Abstract: This paper studies a class of simple bilevel optimization problems where we minimize a composite convex function at the upper-level subject to a composite convex lower-level problem. Existing methods either provide asymptotic guarantees for the upper-level objective or attain slow sublinear convergence rates. We propose a bisection algorithm to find a solution that is $\epsilon_f$-optimal for the upper-level objective and $\epsilon_g$-optimal for the lower-level objective. In each iteration, the binary search narrows the interval by assessing inequality system feasibility. Under mild conditions, the total operation complexity of our method is ${\tilde {\mathcal{O}}}\left(\max\{\sqrt{L_{f_1}/\epsilon_f},\sqrt{L_{g_1}/\epsilon_g} \} \right)$. Here, a unit operation can be a function evaluation, gradient evaluation, or the invocation of the proximal mapping, $L_{f_1}$ and $L_{g_1}$ are the Lipschitz constants of the upper- and lower-level objectives' smooth components, and ${\tilde {\mathcal{O}}}$ hides logarithmic terms. Our approach achieves a near-optimal rate, matching the optimal rate in unconstrained smooth or composite convex optimization when disregarding logarithmic terms. Numerical experiments demonstrate the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.05415v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiulin Wang, Xu Shi, Rujun Jiang</dc:creator>
    </item>
    <item>
      <title>Primal-Dual iLQR</title>
      <link>https://arxiv.org/abs/2403.00748</link>
      <description>arXiv:2403.00748v2 Announce Type: replace 
Abstract: We introduce a new algorithm for solving unconstrained discrete-time optimal control problems. Our method follows a direct multiple shooting approach, and consists of applying the SQP method together with an $\ell_2$ augmented Lagrangian primal-dual merit function. We use the LQR algorithm to efficiently solve the primal-dual SQP problem. As our algorithm is a specialization of NPSQP (Gill et al. 1992), it inherits its generic properties, including global convergence, fast local convergence, and the lack of need for second order corrections, improving on existing direct multiple shooting approaches such as GNMS (Giftthaler et al. 2018) and FDDP (Mastalli et al. 2020).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.00748v2</guid>
      <category>math.OC</category>
      <category>cs.RO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jo\~ao Sousa-Pinto, Dominique Orban</dc:creator>
    </item>
    <item>
      <title>LLaMoCo: Instruction Tuning of Large Language Models for Optimization Code Generation</title>
      <link>https://arxiv.org/abs/2403.01131</link>
      <description>arXiv:2403.01131v2 Announce Type: replace 
Abstract: Recent research explores optimization using large language models (LLMs) by either iteratively seeking next-step solutions from LLMs or directly prompting LLMs for an optimizer. However, these approaches exhibit inherent limitations, including low operational efficiency, high sensitivity to prompt design, and a lack of domain-specific knowledge. We introduce LLaMoCo, the first instruction-tuning framework designed to adapt LLMs for solving optimization problems in a code-to-code manner. Specifically, we establish a comprehensive instruction set containing well-described problem prompts and effective optimization codes. We then develop a novel two-phase learning strategy that incorporates a contrastive learning-based warm-up procedure before the instruction-tuning phase to enhance the convergence behavior during model fine-tuning. The experiment results demonstrate that a CodeGen (350M) model fine-tuned by our LLaMoCo achieves superior optimization performance compared to GPT-4 Turbo and the other competitors across both synthetic and realistic problem sets. The fine-tuned model and the usage instructions are available at https://anonymous.4open.science/r/LLaMoCo-722A.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.01131v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.LG</category>
      <category>cs.NE</category>
      <category>cs.SE</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zeyuan Ma, Hongshu Guo, Jiacheng Chen, Guojun Peng, Zhiguang Cao, Yining Ma, Yue-Jiao Gong</dc:creator>
    </item>
    <item>
      <title>Sophia: A Scalable Stochastic Second-order Optimizer for Language Model Pre-training</title>
      <link>https://arxiv.org/abs/2305.14342</link>
      <description>arXiv:2305.14342v4 Announce Type: replace-cross 
Abstract: Given the massive cost of language model pre-training, a non-trivial improvement of the optimization algorithm would lead to a material reduction on the time and cost of training. Adam and its variants have been state-of-the-art for years, and more sophisticated second-order (Hessian-based) optimizers often incur too much per-step overhead. In this paper, we propose Sophia, Second-order Clipped Stochastic Optimization, a simple scalable second-order optimizer that uses a light-weight estimate of the diagonal Hessian as the pre-conditioner. The update is the moving average of the gradients divided by the moving average of the estimated Hessian, followed by element-wise clipping. The clipping controls the worst-case update size and tames the negative impact of non-convexity and rapid change of Hessian along the trajectory. Sophia only estimates the diagonal Hessian every handful of iterations, which has negligible average per-step time and memory overhead. On language modeling with GPT models of sizes ranging from 125M to 1.5B, Sophia achieves a 2x speed-up compared to Adam in the number of steps, total compute, and wall-clock time, achieving the same perplexity with 50% fewer steps, less total compute, and reduced wall-clock time. Theoretically, we show that Sophia, in a much simplified setting, adapts to the heterogeneous curvatures in different parameter dimensions, and thus has a run-time bound that does not depend on the condition number of the loss.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.14342v4</guid>
      <category>cs.LG</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hong Liu, Zhiyuan Li, David Hall, Percy Liang, Tengyu Ma</dc:creator>
    </item>
    <item>
      <title>Reflections on BSDEs</title>
      <link>https://arxiv.org/abs/2306.14615</link>
      <description>arXiv:2306.14615v2 Announce Type: replace-cross 
Abstract: We prove well-posedness results for backward stochastic differential equations (BSDEs) and reflected BSDEs with an optional obstacle process in the case of appropriately weighted $\mathbb{L}^2$-data when the generator is integrated with respect to a possibly purely discontinuous process. This leads to a unified treatment of discrete-time and continuous-time (reflected) BSDEs. We compare our well-posedness results with the current literature and highlight that our results are sharp and cannot be improved within the framework presented here. Finally, we provide sufficient conditions for a comparison principle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.14615v2</guid>
      <category>math.PR</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Dylan Possama\"i, Marco Rodrigues</dc:creator>
    </item>
    <item>
      <title>Momentum Benefits Non-IID Federated Learning Simply and Provably</title>
      <link>https://arxiv.org/abs/2306.16504</link>
      <description>arXiv:2306.16504v3 Announce Type: replace-cross 
Abstract: Federated learning is a powerful paradigm for large-scale machine learning, but it faces significant challenges due to unreliable network connections, slow communication, and substantial data heterogeneity across clients. FedAvg and SCAFFOLD are two prominent algorithms to address these challenges. In particular, FedAvg employs multiple local updates before communicating with a central server, while SCAFFOLD maintains a control variable on each client to compensate for ``client drift'' in its local updates. Various methods have been proposed to enhance the convergence of these two algorithms, but they either make impractical adjustments to the algorithmic structure or rely on the assumption of bounded data heterogeneity.
  This paper explores the utilization of momentum to enhance the performance of FedAvg and SCAFFOLD. When all clients participate in the training process, we demonstrate that incorporating momentum allows FedAvg to converge without relying on the assumption of bounded data heterogeneity even using a constant local learning rate. This is novel and fairly surprising as existing analyses for FedAvg require bounded data heterogeneity even with diminishing local learning rates. In partial client participation, we show that momentum enables SCAFFOLD to converge provably faster without imposing any additional assumptions. Furthermore, we use momentum to develop new variance-reduced extensions of FedAvg and SCAFFOLD, which exhibit state-of-the-art convergence rates. Our experimental results support all theoretical findings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.16504v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziheng Cheng, Xinmeng Huang, Pengfei Wu, Kun Yuan</dc:creator>
    </item>
    <item>
      <title>A Self-Adaptive Penalty Method for Integrating Prior Knowledge Constraints into Neural ODEs</title>
      <link>https://arxiv.org/abs/2307.14940</link>
      <description>arXiv:2307.14940v3 Announce Type: replace-cross 
Abstract: The continuous dynamics of natural systems has been effectively modelled using Neural Ordinary Differential Equations (Neural ODEs). However, for accurate and meaningful predictions, it is crucial that the models follow the underlying rules or laws that govern these systems. In this work, we propose a self-adaptive penalty algorithm for Neural ODEs to enable modelling of constrained natural systems. The proposed self-adaptive penalty function can dynamically adjust the penalty parameters. The explicit introduction of prior knowledge helps to increase the interpretability of Neural ODE -based models. We validate the proposed approach by modelling three natural systems with prior knowledge constraints: population growth, chemical reaction evolution, and damped harmonic oscillator motion. The numerical experiments and a comparison with other penalty Neural ODE approaches and \emph{vanilla} Neural ODE, demonstrate the effectiveness of the proposed self-adaptive penalty algorithm for Neural ODEs in modelling constrained natural systems. Moreover, the self-adaptive penalty approach provides more accurate and robust models with reliable and meaningful predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.14940v3</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>C. Coelho, M. Fernanda P. Costa, L. L. Ferr\'as</dc:creator>
    </item>
    <item>
      <title>Certifying ground-state properties of quantum many-body systems</title>
      <link>https://arxiv.org/abs/2310.05844</link>
      <description>arXiv:2310.05844v4 Announce Type: replace-cross 
Abstract: A ubiquitous problem in quantum physics is to understand the ground-state properties of many-body systems. Confronted with the fact that exact diagonalisation quickly becomes impossible when increasing the system size, variational approaches are typically employed as a scalable alternative: energy is minimised over a subset of all possible states and then different physical quantities are computed over the solution state. Despite remarkable success, rigorously speaking, all what variational methods offer are upper bounds on the ground-state energy. On the other hand, so-called relaxations of the ground-state problem based on semidefinite programming represent a complementary approach, providing lower bounds to the ground-state energy. However, in their current implementation, neither variational nor relaxation methods offer provable bound on other observables in the ground state beyond the energy. In this work, we show that the combination of the two classes of approaches can be used to derive certifiable bounds on the value of any observable in the ground state, such as correlation functions of arbitrary order, structure factors, or order parameters. We illustrate the power of this approach in paradigmatic examples of 1D and 2D spin-one-half Heisenberg models. To improve the scalability of the method, we exploit the symmetries and sparsity of the considered systems to reach sizes of hundreds of particles at much higher precision than previous works. Our analysis therefore shows how to obtain certifiable bounds on many-body ground-state properties beyond energy in a scalable way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.05844v4</guid>
      <category>quant-ph</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Wang, Jacopo Surace, Ir\'en\'ee Fr\'erot, Beno\^it Legat, Marc-Olivier Renou, Victor Magron, Antonio Ac\'in</dc:creator>
    </item>
    <item>
      <title>Online Local False Discovery Rate Control: A Resource Allocation Approach</title>
      <link>https://arxiv.org/abs/2402.11425</link>
      <description>arXiv:2402.11425v2 Announce Type: replace-cross 
Abstract: We consider the problem of online local false discovery rate (FDR) control where multiple tests are conducted sequentially, with the goal of maximizing the total expected number of discoveries. We formulate the problem as an online resource allocation problem with accept/reject decisions, which from a high level can be viewed as an online knapsack problem, with the additional uncertainty of exogenous random budget replenishment. We start with general arrival distributions and propose a simple policy that achieves a $O(\sqrt{T})$ regret. We complement the result by showing that such regret rate is in general not improvable. We then shift our focus to discrete arrival distributions. We find that many existing re-solving heuristics in the online resource allocation literature, albeit achieve bounded loss in canonical settings, may incur a $\Omega(\sqrt{T})$ or even a $\Omega(T)$ regret. With the observation that canonical policies tend to be too optimistic and over accept arrivals, we propose a novel policy that incorporates budget buffers. We show that small additional logarithmic buffers suffice to reduce the regret from $\Omega(\sqrt{T})$ or even $\Omega(T)$ to $O(\ln^2 T)$. Numerical experiments are conducted to validate our theoretical findings. Our formulation may have wider applications beyond the problem considered in this paper, and our results emphasize how effective policies should be designed to reach a balance between circumventing wrong accept and reducing wrong reject in online resource allocation problems with exogenous budget replenishment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11425v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruicheng Ao, Hongyu Chen, David Simchi-Levi, Feng Zhu</dc:creator>
    </item>
    <item>
      <title>Optimal Transport on the Lie Group of Roto-translations</title>
      <link>https://arxiv.org/abs/2402.15322</link>
      <description>arXiv:2402.15322v2 Announce Type: replace-cross 
Abstract: The roto-translation group SE2 has been of active interest in image analysis due to methods that lift the image data to multi-orientation representations defined on this Lie group. This has led to impactful applications of crossing-preserving flows for image de-noising, geodesic tracking, and roto-translation equivariant deep learning. In this paper, we develop a computational framework for optimal transportation over Lie groups, with a special focus on SE2. We make several theoretical contributions (generalizable to matrix Lie groups) such as the non-optimality of group actions as transport maps, invariance and equivariance of optimal transport, and the quality of the entropic-regularized optimal transport plan using geodesic distance approximations. We develop a Sinkhorn like algorithm that can be efficiently implemented using fast and accurate distance approximations of the Lie group and GPU-friendly group convolutions. We report valuable advancements in the experiments on 1) image barycentric interpolation, 2) interpolation of planar orientation fields, and 3) Wasserstein gradient flows on SE2. We observe that our framework of lifting images to SE2 and optimal transport with left-invariant anisotropic metrics leads to equivariant transport along dominant contours and salient line structures in the image. This yields sharper and more meaningful interpolations compared to their counterparts on R^2</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.15322v2</guid>
      <category>cs.CV</category>
      <category>math.DG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daan Bon, Gautam Pai, Gijs Bellaard, Olga Mula, Remco Duits</dc:creator>
    </item>
  </channel>
</rss>
