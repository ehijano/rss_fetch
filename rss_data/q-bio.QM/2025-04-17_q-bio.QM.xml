<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Apr 2025 01:43:45 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Advances in Surrogate Modeling for Biological Agent-Based Simulations: Trends, Challenges, and Future Prospects</title>
      <link>https://arxiv.org/abs/2504.11617</link>
      <description>arXiv:2504.11617v1 Announce Type: new 
Abstract: Agent-based modeling (ABM) is a powerful computational approach for studying complex biological and biomedical systems, yet its widespread use remains limited by significant computational demands. As models become increasingly sophisticated, the number of parameters and interactions rises rapidly, exacerbating the so-called curse of dimensionality and making comprehensive parameter exploration and uncertainty analyses computationally prohibitive. Surrogate modeling provides a promising solution by approximating ABM behavior through computationally efficient alternatives, greatly reducing the runtime needed for parameter estimation, sensitivity analysis, and uncertainty quantification. In this review, we examine traditional approaches for performing these tasks directly within ABMs -- providing a baseline for comparison -- and then synthesize recent developments in surrogate-assisted methodologies for biological and biomedical applications. We cover statistical, mechanistic, and machine-learning-based approaches, emphasizing emerging hybrid strategies that integrate mechanistic insights with machine learning to balance interpretability and scalability. Finally, we discuss current challenges and outline directions for future research, including the development of standardized benchmarks to enhance methodological rigor and facilitate the broad adoption of surrogate-assisted ABMs in biology and medicine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11617v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Kerri-Ann Norton, Daniel Bergman, Harsh Vardhan Jain, Trachette Jackson</dc:creator>
    </item>
    <item>
      <title>Generalized probabilistic canonical correlation analysis for multi-modal data integration with full or partial observations</title>
      <link>https://arxiv.org/abs/2504.11610</link>
      <description>arXiv:2504.11610v1 Announce Type: cross 
Abstract: Background: The integration and analysis of multi-modal data are increasingly essential across various domains including bioinformatics. As the volume and complexity of such data grow, there is a pressing need for computational models that not only integrate diverse modalities but also leverage their complementary information to improve clustering accuracy and insights, especially when dealing with partial observations with missing data. Results: We propose Generalized Probabilistic Canonical Correlation Analysis (GPCCA), an unsupervised method for the integration and joint dimensionality reduction of multi-modal data. GPCCA addresses key challenges in multi-modal data analysis by handling missing values within the model, enabling the integration of more than two modalities, and identifying informative features while accounting for correlations within individual modalities. The model demonstrates robustness to various missing data patterns and provides low-dimensional embeddings that facilitate downstream clustering and analysis. In a range of simulation settings, GPCCA outperforms existing methods in capturing essential patterns across modalities. Additionally, we demonstrate its applicability to multi-omics data from TCGA cancer datasets and a multi-view image dataset. Conclusion: GPCCA offers a useful framework for multi-modal data integration, effectively handling missing data and providing informative low-dimensional embeddings. Its performance across cancer genomics and multi-view image data highlights its robustness and potential for broad application. To make the method accessible to the wider research community, we have released an R package, GPCCA, which is available at https://github.com/Kaversoniano/GPCCA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11610v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Tianjian Yang, Wei Vivian Li</dc:creator>
    </item>
    <item>
      <title>Single-shot Star-convex Polygon-based Instance Segmentation for Spatially-correlated Biomedical Objects</title>
      <link>https://arxiv.org/abs/2504.12078</link>
      <description>arXiv:2504.12078v1 Announce Type: cross 
Abstract: Biomedical images often contain objects known to be spatially correlated or nested due to their inherent properties, leading to semantic relations. Examples include cell nuclei being nested within eukaryotic cells and colonies growing exclusively within their culture dishes. While these semantic relations bear key importance, detection tasks are often formulated independently, requiring multi-shot analysis pipelines. Importantly, spatial correlation could constitute a fundamental prior facilitating learning of more meaningful representations for tasks like instance segmentation. This knowledge has, thus far, not been utilised by the biomedical computer vision community. We argue that the instance segmentation of two or more categories of objects can be achieved in parallel. We achieve this via two architectures HydraStarDist (HSD) and the novel (HSD-WBR) based on the widely-used StarDist (SD), to take advantage of the star-convexity of our target objects. HSD and HSD-WBR are constructed to be capable of incorporating their interactions as constraints into account. HSD implicitly incorporates spatial correlation priors based on object interaction through a joint encoder. HSD-WBR further enforces the prior in a regularisation layer with the penalty we proposed named Within Boundary Regularisation Penalty (WBR). Both architectures achieve nested instance segmentation in a single shot. We demonstrate their competitiveness based on $IoU_R$ and AP and superiority in a new, task-relevant criteria, Joint TP rate (JTPR) compared to their baseline SD and Cellpose. Our approach can be further modified to capture partial-inclusion/-exclusion in multi-object interactions in fluorescent or brightfield microscopy or digital imaging. Finally, our strategy suggests gains by making this learning single-shot and computationally efficient.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12078v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Trina De, Adrian Urbanski, Artur Yakimovich</dc:creator>
    </item>
    <item>
      <title>Hemodynamic Markers: CFD-Based Prediction of Cerebral Aneurysm Rupture Risk</title>
      <link>https://arxiv.org/abs/2504.10524</link>
      <description>arXiv:2504.10524v2 Announce Type: replace 
Abstract: This study investigates the influence of aneurysm evolution on hemodynamic characteristics within the sac region. Using computational fluid dynamics (CFD), blood flow through the parent vessel and aneurysm sac was analyzed to assess the impact on wall shear stress (WSS), time-averaged wall shear stress (TAWSS), and the oscillatory shear index (OSI), key indicators of rupture risk. Additionally, Relative Residence Time (RRT) and Endothelial Cell Activation Potential (ECAP) were examined to provide a broader understanding of the aneurysm's hemodynamic environment. Six distinct cerebral aneurysm (CA) models, all from individuals of the same gender, were selected to minimize gender-related variability.
  Results showed that unruptured cases exhibited higher WSS and TAWSS, along with lower OSI and RRT values patterns consistent with stable flow conditions supporting vascular integrity. In contrast, ruptured cases had lower WSS and TAWSS, coupled with elevated OSI and RRT, suggesting disturbed and oscillatory flow commonly linked to aneurysm wall weakening. ECAP was also higher in ruptured cases, indicating increased endothelial activation under unstable flow. Notably, areas with the highest OSI and RRT often aligned with vortex centers, reinforcing the association between disturbed flow and aneurysm instability.
  These findings highlight the value of combining multiple hemodynamic parameters for rupture risk assessment. Including RRT and ECAP provides deeper insight into flow endothelium-interactions, offering a stronger basis for evaluating aneurysm stability and guiding treatment decisions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.10524v2</guid>
      <category>q-bio.QM</category>
      <category>physics.bio-ph</category>
      <category>physics.med-ph</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Reza Bozorgpour, Jacob R. Rammer</dc:creator>
    </item>
    <item>
      <title>Chemical Language Model Linker: blending text and molecules with modular adapters</title>
      <link>https://arxiv.org/abs/2410.20182</link>
      <description>arXiv:2410.20182v2 Announce Type: replace-cross 
Abstract: The development of large language models and multi-modal models has enabled the appealing idea of generating novel molecules from text descriptions. Generative modeling would shift the paradigm from relying on large-scale chemical screening to find molecules with desired properties to directly generating those molecules. However, multi-modal models combining text and molecules are often trained from scratch, without leveraging existing high-quality pretrained models. Training from scratch consumes more computational resources and prohibits model scaling. In contrast, we propose a lightweight adapter-based strategy named Chemical Language Model Linker (ChemLML). ChemLML blends the two single domain models and obtains conditional molecular generation from text descriptions while still operating in the specialized embedding spaces of the molecular domain. ChemLML can tailor diverse pretrained text models for molecule generation by training relatively few adapter parameters. We find that the choice of molecular representation used within ChemLML, SMILES versus SELFIES, has a strong influence on conditional molecular generation performance. SMILES is often preferable despite not guaranteeing valid molecules. We raise issues in using the entire PubChem dataset of molecules and their associated descriptions for evaluating molecule generation and provide a filtered version of the dataset as a generation test set. To demonstrate how ChemLML could be used in practice, we generate candidate protein inhibitors and use docking to assess their quality and also generate candidate membrane permeable molecules.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.20182v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yifan Deng, Spencer S. Ericksen, Anthony Gitter</dc:creator>
    </item>
    <item>
      <title>BioMaze: Benchmarking and Enhancing Large Language Models for Biological Pathway Reasoning</title>
      <link>https://arxiv.org/abs/2502.16660</link>
      <description>arXiv:2502.16660v4 Announce Type: replace-cross 
Abstract: The applications of large language models (LLMs) in various biological domains have been explored recently, but their reasoning ability in complex biological systems, such as pathways, remains underexplored, which is crucial for predicting biological phenomena, formulating hypotheses, and designing experiments. This work explores the potential of LLMs in pathway reasoning. We introduce BioMaze, a dataset with 5.1K complex pathway problems derived from real research, covering various biological contexts including natural dynamic changes, disturbances, additional intervention conditions, and multi-scale research targets. Our evaluation of methods such as CoT and graph-augmented reasoning, shows that LLMs struggle with pathway reasoning, especially in perturbed systems. To address this, we propose PathSeeker, an LLM agent that enhances reasoning through interactive subgraph-based navigation, enabling a more effective approach to handling the complexities of biological systems in a scientifically aligned manner. The dataset and code are available at https://github.com/zhao-ht/BioMaze.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.16660v4</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Haiteng Zhao, Chang Ma, Fangzhi Xu, Lingpeng Kong, Zhi-Hong Deng</dc:creator>
    </item>
    <item>
      <title>Redefining Fitness: Evolution as a Dynamic Learning Process</title>
      <link>https://arxiv.org/abs/2503.09057</link>
      <description>arXiv:2503.09057v2 Announce Type: replace-cross 
Abstract: Evolution is the process of optimal adaptation of biological populations to their living environments. This is expressed via the concept of fitness, defined as relative reproductive success. However, it has been pointed out that this definition is incomplete and logically circular. To address this issue, several authors have called for new ways to specify fitness explicitly in terms of the relationship between phenotypes and their environment. Here, we show that fitness, defined as the likelihood function that follows from mapping population dynamics to Bayesian learning, provides a general solution to this problem. We show how probabilistic models of fitness can easily be constructed in this way, and how their averages acquire meaning as information. We also show how this approach leads to powerful tools to analyze challenging problems of evolution in variable environments, game theory, and selection in group-structured populations. The approach is general and creates an explicit bridge between population dynamics under selection, statistical learning theory, and emerging models of artificial intelligence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.09057v2</guid>
      <category>q-bio.PE</category>
      <category>nlin.AO</category>
      <category>physics.bio-ph</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lu\'is MA Bettencourt, Brandon J Grandison, Jordan T Kemp</dc:creator>
    </item>
    <item>
      <title>Elucidating the Design Space of Multimodal Protein Language Models</title>
      <link>https://arxiv.org/abs/2504.11454</link>
      <description>arXiv:2504.11454v2 Announce Type: replace-cross 
Abstract: Multimodal protein language models (PLMs) integrate sequence and token-based structural information, serving as a powerful foundation for protein modeling, generation, and design. However, the reliance on tokenizing 3D structures into discrete tokens causes substantial loss of fidelity about fine-grained structural details and correlations. In this paper, we systematically elucidate the design space of multimodal PLMs to overcome their limitations. We identify tokenization loss and inaccurate structure token predictions by the PLMs as major bottlenecks. To address these, our proposed design space covers improved generative modeling, structure-aware architectures and representation learning, and data exploration. Our advancements approach finer-grained supervision, demonstrating that token-based multimodal PLMs can achieve robust structural modeling. The effective design methods dramatically improve the structure generation diversity, and notably, folding abilities of our 650M model by reducing the RMSD from 5.52 to 2.36 on PDB testset, even outperforming 3B baselines and on par with the specialized folding models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.11454v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Thu, 17 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Cheng-Yen Hsieh, Xinyou Wang, Daiheng Zhang, Dongyu Xue, Fei Ye, Shujian Huang, Zaixiang Zheng, Quanquan Gu</dc:creator>
    </item>
  </channel>
</rss>
