<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 04:10:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A decomposition from a substitutable many-to-one matching market to a one-to-one matching market</title>
      <link>https://arxiv.org/abs/2411.00564</link>
      <description>arXiv:2411.00564v1 Announce Type: new 
Abstract: For a many-to-one market with substitutable preferences on the firm's side, based on the Aizerman-Malishevski decomposition, we define an associated one-to-one market. Given that the usual notion of stability for a one-to-one market does not fit well for this associated one-to-one market, we introduce a new notion of stability. This notion allows us to establish an isomorphism between the set of stable matchings in the many-to-one market and the matchings in the associated one-to-one market that meet this new stability criterion. Furthermore, we present an adaptation of the well-known deferred acceptance algorithm to compute a matching that satisfies this new notion of stability for the associated one-to-one market.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00564v1</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Pablo Neme, Jorge Oviedo</dc:creator>
    </item>
    <item>
      <title>Matching With Pre-Existing Binding Agreements: The Agreeable Core</title>
      <link>https://arxiv.org/abs/2406.08700</link>
      <description>arXiv:2406.08700v2 Announce Type: replace 
Abstract: Matching market models ignore prior commitments. Yet many job seekers, for example, are already employed, and the same holds for many other matching markets. I analyze two-sided matching markets with pre-existing binding agreements between market participants. In this model, a pair of participants bound to each other by a pre-existing agreement must agree to any action they take. To analyze their behavior, I propose a new solution concept, the agreeable core, consisting of the matches which cannot be renegotiated without violating the binding agreements. My main contribution is an algorithm that constructs such a match by a novel combination of the Deferred Acceptance and Top Trading Cycles algorithms. The algorithm is robust to various manipulations and has applications to numerous markets including the resident-to-hospital match, college admissions, school choice, and labor markets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.08700v2</guid>
      <category>econ.TH</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peter Doe</dc:creator>
    </item>
    <item>
      <title>Generalized Principal-Agent Problem with a Learning Agent</title>
      <link>https://arxiv.org/abs/2402.09721</link>
      <description>arXiv:2402.09721v4 Announce Type: replace-cross 
Abstract: Classic principal-agent problems such as Stackelberg games, contract design, and Bayesian persuasion, often assume that the agent is able to best respond to the principal's committed strategy. We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction, we show that: (1) If the agent uses contextual no-regret learning algorithms with regret $\mathrm{Reg}(T)$, then the principal can guarantee utility at least $U^* - \Theta\big(\sqrt{\tfrac{\mathrm{Reg}(T)}{T}}\big)$, where $U^*$ is the principal's optimal utility in the classic model with a best-responding agent. (2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\mathrm{SReg}(T)$, then the principal cannot obtain utility more than $U^* + O(\frac{\mathrm{SReg(T)}}{T})$. But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret), then the principal can sometimes do significantly better than $U^*$. These results not only refine previous results in Stackelberg games and contract design, but also lead to new results for Bayesian persuasion with a learning agent and all generalized principal-agent problems where the agent does not have private information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09721v4</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Yiling Chen</dc:creator>
    </item>
    <item>
      <title>Decision-Making Behavior Evaluation Framework for LLMs under Uncertain Context</title>
      <link>https://arxiv.org/abs/2406.05972</link>
      <description>arXiv:2406.05972v2 Announce Type: replace-cross 
Abstract: When making decisions under uncertainty, individuals often deviate from rational behavior, which can be evaluated across three dimensions: risk preference, probability weighting, and loss aversion. Given the widespread use of large language models (LLMs) in decision-making processes, it is crucial to assess whether their behavior aligns with human norms and ethical expectations or exhibits potential biases. Several empirical studies have investigated the rationality and social behavior performance of LLMs, yet their internal decision-making tendencies and capabilities remain inadequately understood. This paper proposes a framework, grounded in behavioral economics, to evaluate the decision-making behaviors of LLMs. Through a multiple-choice-list experiment, we estimate the degree of risk preference, probability weighting, and loss aversion in a context-free setting for three commercial LLMs: ChatGPT-4.0-Turbo, Claude-3-Opus, and Gemini-1.0-pro. Our results reveal that LLMs generally exhibit patterns similar to humans, such as risk aversion and loss aversion, with a tendency to overweight small probabilities. However, there are significant variations in the degree to which these behaviors are expressed across different LLMs. We also explore their behavior when embedded with socio-demographic features, uncovering significant disparities. For instance, when modeled with attributes of sexual minority groups or physical disabilities, Claude-3-Opus displays increased risk aversion, leading to more conservative choices. These findings underscore the need for careful consideration of the ethical implications and potential biases in deploying LLMs in decision-making scenarios. Therefore, this study advocates for developing standards and guidelines to ensure that LLMs operate within ethical boundaries while enhancing their utility in complex decision-making environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.05972v2</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Mon, 04 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingru Jia, Zehua Yuan, Junhao Pan, Paul E. McNamara, Deming Chen</dc:creator>
    </item>
  </channel>
</rss>
