<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Nov 2025 05:00:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>A Simple Analysis of Ranking in General Graphs</title>
      <link>https://arxiv.org/abs/2511.08801</link>
      <description>arXiv:2511.08801v1 Announce Type: new 
Abstract: We provide a simple combinatorial analysis of the Ranking algorithm, originally introduced in the seminal work by Karp, Vazirani, and Vazirani [KVV90], demonstrating that it achieves a $(1/2 + c)$-approximate matching for general graphs for $c \geq 0.005$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08801v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mahsa Derakhshan, Mohammad Roghani, Mohammad Saneian, Tao Yu</dc:creator>
    </item>
    <item>
      <title>Space-Efficient and Output-Sensitive Algorithms for the Longest Common Bitonic Subsequence</title>
      <link>https://arxiv.org/abs/2511.08958</link>
      <description>arXiv:2511.08958v1 Announce Type: new 
Abstract: The longest common bitonic subsequence (LCBS) of two sequences A and B is the longest subsequence that increases to a single peak and then decreases while appearing, in order, in both inputs. Although LCBS naturally models rise-fall patterns in bioinformatics, finance, and signal analysis, the only previously documented solution was a quadratic dynamic program that needs {\theta}(nm) time and space. We show that this space barrier is not inherent: a refined rolling-row implementation evaluates the same recurrence in {\theta}(nm) time with only {\theta}(min(n, m)) additional memory. By isolating the M symbol matches and their C bitonic-compatible pairs, we cast LCBS as a longest-path problem in a sparse DAG and solve it in O((n + m) log n + M log M) time and O(M) space, which is asymptotically faster than the quadratic baseline whenever M &lt;&lt; n m. These results make exact LCBS computation practical for inputs that were previously out of reach and expose a new fine-grained complexity landscape that invites further exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08958v1</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Md. Tanzeem Rahat, Md. Manzurul Hasan</dc:creator>
    </item>
    <item>
      <title>Prophet and Secretary at the Same Time</title>
      <link>https://arxiv.org/abs/2511.09531</link>
      <description>arXiv:2511.09531v1 Announce Type: new 
Abstract: Many online problems are studied in stochastic settings for which inputs are samples from a known distribution, given in advance, or from an unknown distribution. Such distributions model both beyond-worst-case inputs and, when given, partial foreknowledge for the online algorithm. But how robust can such algorithms be to misspecification of the given distribution? When is this detectable, and when does it matter? When can algorithms give good competitive ratios both when the input distribution is as specified, and when it is not?
  We consider these questions in the setting of optimal stopping, where the cases of known and unknown distributions correspond to the well-known prophet inequality and to the secretary problem, respectively. Here we ask: Can a stopping rule be competitive for the i.i.d. prophet inequality problem and the secretary problem at the same time? We constrain the Pareto frontier of simultaneous approximation ratios $(\alpha, \beta)$ that a stopping rule can attain.
  We introduce a family of algorithms that give nontrivial joint guarantees and are optimal for the extremal i.i.d. prophet and secretary problems. We also prove impossibilities, identifying $(\alpha, \beta)$ unattainable by any adaptive stopping rule. Our results hold for both $n$ fixed arrivals and for arrivals from a Poisson process with rate $n$. We work primarily in the Poisson setting, and provide reductions between the Poisson and $n$-arrival settings that may be of broader interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09531v1</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gregory Kehne, Thomas Kesselheim</dc:creator>
    </item>
    <item>
      <title>A Spanning-Tree-Based Algorithm for Planar Graph Dismantling</title>
      <link>https://arxiv.org/abs/2511.09132</link>
      <description>arXiv:2511.09132v1 Announce Type: cross 
Abstract: In spatially embedded networks such as transportation and power grids, understanding how edge removals affect connectivity is crucial for robustness analysis. This paper studies a planar graph dismantling problem under an edge-budget constraint. We propose a spanning-tree-skeleton dual-path framework that first samples multiple uniform spanning trees to capture network backbones and then adaptively selects between two complementary paths according to the budget. The small-budget path estimates a dismantlable subgraph fraction using a logarithmic density feature, while the large-budget path predicts the optimal partition count through a slope-based model. Experiments on random planar graphs demonstrate near-linear runtime scaling, consistent reductions in the largest connected component ratio, and clear budget-fragmentation trends. The method provides an interpretable and efficient approach for planar-network robustness analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09132v1</guid>
      <category>cs.SI</category>
      <category>cs.DS</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fangchen You</dc:creator>
    </item>
    <item>
      <title>No Cords Attached: Coordination-Free Concurrent Lock-Free Queues</title>
      <link>https://arxiv.org/abs/2511.09410</link>
      <description>arXiv:2511.09410v1 Announce Type: cross 
Abstract: The queue is conceptually one of the simplest data structures-a basic FIFO container. However, ensuring correctness in the presence of concurrency makes existing lock-free implementations significantly more complex than their original form. Coordination mechanisms introduced to prevent hazards such as ABA, use-after-free, and unsafe reclamation often dominate the design, overshadowing the queue itself. Many schemes compromise strict FIFO ordering, unbounded capacity, or lock-free progress to mask coordination overheads. Yet the true source of complexity lies in the pursuit of infinite protection against reclamation hazards--theoretically sound but impractical and costly. This pursuit not only drives unnecessary complexity but also creates a protection paradox where excessive protection reduces system resilience rather than improving it. While such costs may be tolerable in conventional workloads, the AI era has shifted the paradigm: training and inference pipelines involve hundreds to thousands of concurrent threads per node, and at this scale, protection and coordination overheads dominate, often far heavier than the basic queue operations themselves.
  This paper introduces Cyclic Memory Protection (CMP), a coordination-free queue that preserves strict FIFO semantics, unbounded capacity, and lock-free progress while restoring simplicity. CMP reclaims the strict FIFO that other approaches sacrificed through bounded protection windows that provide practical reclamation guarantees. We prove strict FIFO and safety via linearizability and bounded reclamation analysis, and show experimentally that CMP outperforms state-of-the-art lock-free queues by up to 1.72-4x under high contention while maintaining scalability to hundreds of threads. Our work demonstrates that highly concurrent queues can return to their fundamental simplicity without weakening queue semantics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09410v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.PF</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yusuf Motiwala</dc:creator>
    </item>
    <item>
      <title>Differentiable Extensions with Rounding Guarantees for Combinatorial Optimization over Permutations</title>
      <link>https://arxiv.org/abs/2411.10707</link>
      <description>arXiv:2411.10707v2 Announce Type: replace 
Abstract: Continuously extending combinatorial optimization objectives is a powerful technique commonly applied to the optimization of set functions. However, few such methods exist for extending functions on permutations, despite the fact that many combinatorial optimization problems, such as the quadratic assignment problem (QAP) and the traveling salesperson problem (TSP), are inherently optimization over permutations. We present Birkhoff Extension (BE), an almost-everywhere-differentiable continuous polytime-computable extension of any real-valued function on permutations to doubly stochastic matrices. Key to this construction is our introduction of a continuous variant of the well-known Birkhoff decomposition. Our extension has several nice properties making it appealing for optimization problems. First, BE provides a rounding guarantee, namely any solution to the extension can be efficiently rounded to a permutation without increasing the function value. Furthermore, an approximate solution in the relaxed case will give rise to an approximate solution in the space of permutations. Second, using BE, any real-valued optimization objective on permutations can be extended to an almost-everywhere-differentiable objective function over the space of doubly stochastic matrices. This makes our BE amenable to not only gradient-descent based optimization, but also unsupervised neural combinatorial optimization where training often requires a differentiable loss. Third, based on the above properties, we present a simple optimization procedure which can be readily combined with existing optimization approaches to offer local improvements (i.e., the quality of the final solution is no worse than the initial solution). Finally, we also adapt our extension to optimization problems over a class of trees, such as Steiner tree and optimization-based hierarchical clustering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.10707v2</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Robert R. Nerem, Zhishang Luo, Akbar Rafiey, Yusu Wang</dc:creator>
    </item>
    <item>
      <title>Rapid Mixing on Random Regular Graphs beyond Uniqueness</title>
      <link>https://arxiv.org/abs/2504.03406</link>
      <description>arXiv:2504.03406v2 Announce Type: replace 
Abstract: The hardcore model is a fundamental probabilistic model extensively studied in statistical physics, probability theory, and computer science. For graphs of maximum degree $\Delta$, a well-known computational phase transition occurs at the tree-uniqueness threshold $\lambda_c(\Delta) = \frac{(\Delta-1)^{\Delta-1}}{(\Delta-2)^\Delta}$, where the mixing behavior of the Glauber dynamics (a simple Markov chain) undergoes a sharp transition.
  It is conjectured that random regular graphs exhibit different mixing behavior, with the slowdown occurring far beyond the uniqueness threshold. We confirm this conjecture by showing that, for the hardcore model on random $\Delta$-regular graphs, the Glauber dynamics mixes rapidly with high probability when $\lambda = O(1/\sqrt{\Delta})$, which is significantly beyond the uniqueness threshold $\lambda_c(\Delta) \approx e/\Delta$. Our result establishes a sharp distinction between the hardcore model on worst-case and beyond-worst-case instances, showing that the worst-case and average-case complexities of sampling and counting are fundamentally different.
  This result of rapid mixing on random instances follows from a new criterion we establish for rapid mixing of Glauber dynamics for any distribution supported on a downward closed set family. Our criterion is simple, general, and easy to check. In addition to proving new mixing conditions for the hardcore model, we also establish improved mixing time bounds for sampling uniform matchings or $b$ matchings on graphs, the random cluster model on matroids with $q \in [0,1)$, and the determinantal point process. Our proof of this new criterion for rapid mixing combines and generalizes several recent tools in a novel way, including a trickle down theorem for field dynamics, spectral/entropic stability, and a new comparison result between field dynamics and Glauber dynamics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03406v2</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyu Chen, Zejia Chen, Zongchen Chen, Yitong Yin, Xinyuan Zhang</dc:creator>
    </item>
    <item>
      <title>Splittable Spanning Trees and Balanced Forests in Dense Random Graphs</title>
      <link>https://arxiv.org/abs/2507.12707</link>
      <description>arXiv:2507.12707v2 Announce Type: replace 
Abstract: We consider the probability that a spanning tree chosen uniformly at random from a graph can be partitioned into a fixed number $k$ of trees of equal size by removing $k-1$ edges. In that case, the spanning tree is called {\em splittable}. Splittable spanning trees are useful in algorithms for sampling {\em balanced forests}, forests whose components are of equal size, and for sampling partitions of a graph into components of equal size, with applications in redistricting, network algorithms, and image decomposition. Cannon et al.~recently showed that spanning trees on grid and grid-like graphs on $n$ vertices are splittable into $k$ equal sized components with probability at least $n^{-2k}$, leading to the first rigorous sampling algorithm for balanced forests in any class of graphs. Focusing on the complementary case of dense random graphs, we show that random spanning trees have inverse polynomial probability of being splittable; specifically, a random spanning tree is splittable with probability at least $n^{(-k/2)}$ for both the $G(n,p)$ and $G(n,m)$ models when $p = \Omega(1/\log n)$, giving the first dense class of graphs where partitions of equal size can be sampled efficiently.
  In addition, we present an infinite family of graphs with properties that have been conjectured to ensure splittability (i.e., Hamiltonian subgraphs of the triangular lattice) and prove that random spanning trees are not splittable with more than exponentially small probability. As a consequence, we show that a family of widely-used Markov chain algorithms for sampling equal-size partitions will fail on this family of graphs if their state spaces are restricted to equal-size partitions. Moreover, we show these algorithms will be inefficient if their state spaces are generalized to include any unbalanced partitions, suggesting barriers for sampling balanced partitions in sparse graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.12707v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Gillman, Jacob Platnick, Dana Randall</dc:creator>
    </item>
    <item>
      <title>Tight Bounds for Answering Adaptively Chosen Concentrated Queries</title>
      <link>https://arxiv.org/abs/2507.13700</link>
      <description>arXiv:2507.13700v2 Announce Type: replace 
Abstract: Most work on adaptive data analysis assumes that samples in the dataset are independent. When correlations are allowed, even the non-adaptive setting can become intractable, unless some structural constraints are imposed. To address this, Bassily and Freund [2016] introduced the elegant framework of concentrated queries, which requires the analyst to restrict itself to queries that are concentrated around their expected value. While this assumption makes the problem trivial in the non-adaptive setting, in the adaptive setting it remains quite challenging. In fact, all known algorithms in this framework support significantly fewer queries than in the independent case: At most $O(n)$ queries for a sample of size $n$, compared to $O(n^2)$ in the independent setting.
  In this work, we prove that this utility gap is inherent under the current formulation of the concentrated queries framework, assuming some natural conditions on the algorithm. Additionally, we present a simplified version of the best-known algorithms that match our impossibility result.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13700v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emma Rapoport, Edith Cohen, Uri Stemmer</dc:creator>
    </item>
    <item>
      <title>Sparse Graph Reconstruction and Seriation for Large-Scale Image Stacks</title>
      <link>https://arxiv.org/abs/2509.23084</link>
      <description>arXiv:2509.23084v2 Announce Type: replace 
Abstract: We study recovering a 1D order from a noisy, locally sampled pairwise comparison matrix under a tight query budget. We recast the task as reconstructing a sparse, noisy line graph and present, to our knowledge, the first method that provably builds a sparse graph containing all edges needed for exact seriation using only O(N(log N + K)) oracle queries, which is near-linear in N for fixed window K. The approach is parallelizable and supports both binary and bounded-noise distance oracles. Our five-stage pipeline consists of: (i) a random-hook Boruvka step to connect components via short-range edges in O(N log N) queries; (ii) iterative condensation to bound graph diameter; (iii) a double-sweep BFS to obtain a provisional global order; (iv) fixed-window densification around that order; and (v) a greedy SuperChain that assembles the final permutation. Under a simple top-1 margin and bounded relative noise we prove exact recovery; empirically, SuperChain still succeeds when only about 2N/3 of true adjacencies are present. On wafer-scale serial-section EM, our method outperforms spectral, MST, and TSP baselines with far fewer comparisons, and is applicable to other locally structured sequencing tasks such as temporal snapshot ordering, archaeological seriation, and playlist/tour construction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.23084v2</guid>
      <category>cs.DS</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fuming Yang, Yaron Meirovitch, Jeff W. Lichtman</dc:creator>
    </item>
    <item>
      <title>Hiding, Shuffling, and Cycle Finding: Quantum Algorithms on Edge Lists</title>
      <link>https://arxiv.org/abs/2412.17786</link>
      <description>arXiv:2412.17786v3 Announce Type: replace-cross 
Abstract: The edge list model is arguably the simplest input model for graphs, where the graph is specified by a list of its edges. In this model, we study the quantum query complexity of three variants of the triangle finding problem. The first asks whether there exists a triangle containing a target edge and raises general questions about the hiding of a problem's input among irrelevant data. The second asks whether there exists a triangle containing a target vertex and raises general questions about the shuffling of a problem's input. The third asks whether there exists a triangle; this problem bridges the $3$-distinctness and $3$-sum problems, which have been extensively studied by both cryptographers and complexity theorists. We provide tight or nearly tight results for these problems as well as some first answers to the general questions they raise.
  Furthermore, given any graph with low maximum degree, such as a typical random sparse graph, we prove that the quantum query complexity of finding a length-$k$ cycle in its length-$m$ edge list is $m^{3/4-1/(2^{k+2}-4)\pm o(1)}$, which matches the best-known upper bound for the quantum query complexity of $k$-distinctness on length-$m$ inputs up to an $m^{o(1)}$ factor. We prove the lower bound by developing new techniques within Zhandry's recording query framework [CRYPTO '19] as generalized by Hamoudi and Magniez [ToCT '23]. These techniques extend the framework to treat any non-product distribution that results from conditioning a product distribution on the absence of rare events. We prove the upper bound by adapting Belovs's learning graph algorithm for $k$-distinctness [FOCS '12]. Finally, assuming a plausible conjecture concerning only cycle finding, we show that the lower bound can be lifted to an essentially tight lower bound on the quantum query complexity of $k$-distinctness, which is a long-standing open question.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.17786v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Amin Shiraz Gilani, Daochen Wang, Pei Wu, Xingyu Zhou</dc:creator>
    </item>
    <item>
      <title>Reconquering Bell sampling on qudits: stabilizer learning and testing, quantum pseudorandomness bounds, and more</title>
      <link>https://arxiv.org/abs/2510.06848</link>
      <description>arXiv:2510.06848v2 Announce Type: replace-cross 
Abstract: Bell sampling is a simple yet powerful tool based on measuring two copies of a quantum state in the Bell basis, and has found applications in a plethora of problems related to stabiliser states and measures of magic. However, it was not known how to generalise the procedure from qubits to $d$-level systems -- qudits -- for all dimensions $d &gt; 2$ in a useful way. Indeed, a prior work of the authors (arXiv'24) showed that the natural extension of Bell sampling to arbitrary dimensions fails to provide meaningful information about the quantum states being measured. In this paper, we overcome the difficulties encountered in previous works and develop a useful generalisation of Bell sampling to qudits of all $d\geq 2$. At the heart of our primitive is a new unitary, based on Lagrange's four-square theorem, that maps four copies of any stabiliser state $|\mathcal{S}\rangle$ to four copies of its complex conjugate $|\mathcal{S}^\ast\rangle$ (up to some Pauli operator), which may be of independent interest. We then demonstrate the utility of our new Bell sampling technique by lifting several known results from qubits to qudits for any $d\geq 2$:
  1. Learning stabiliser states in $O(n^3)$ time with $O(n)$ samples;
  2. Solving the Hidden Stabiliser Group Problem in $\tilde{O}(n^3/\varepsilon)$ time with $\tilde{O}(n/\varepsilon)$ samples;
  3. Testing whether $|\psi\rangle$ has stabiliser size at least $d^t$ or is $\varepsilon$-far from all such states in $\tilde{O}(n^3/\varepsilon)$ time with $\tilde{O}(n/\varepsilon)$ samples;
  4. Clifford circuits with at most $n/2$ single-qudit non-Clifford gates cannot prepare pseudorandom states;
  5. Testing whether $|\psi\rangle$ has stabiliser fidelity at least $1-\varepsilon_1$ or at most $1-\varepsilon_2$ with $O(d^2/\varepsilon_2)$ samples if $\varepsilon_1 = 0$ or $O(d^2/\varepsilon_2^2)$ samples if $\varepsilon_1 = O(d^{-2})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.06848v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Thu, 13 Nov 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan Allcock, Joao F. Doriguello, G\'abor Ivanyos, Miklos Santha</dc:creator>
    </item>
  </channel>
</rss>
