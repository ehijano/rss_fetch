<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 10 Apr 2024 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 10 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>An Online Algorithm for Solving Feedback Optimal Control Problems with Partial Observations</title>
      <link>https://arxiv.org/abs/2404.05734</link>
      <description>arXiv:2404.05734v1 Announce Type: new 
Abstract: This paper presents a novel methodology to tackle feedback optimal control problems in scenarios where the exact state of the controlled process is unknown. It integrates data assimilation techniques and optimal control solvers to manage partial observation of the state process, a common occurrence in practical scenarios. Traditional stochastic optimal control methods assume full state observation, which is often not feasible in real-world applications. Our approach underscores the significance of utilizing observational data to inform control policy design. Specifically, we introduce a kernel learning backward stochastic differential equation (SDE) filter to enhance data assimilation efficiency and propose a sample-wise stochastic optimization method within the stochastic maximum principle framework. Numerical experiments validate the efficacy and accuracy of our algorithm, showcasing its high efficiency in solving feedback optimal control problems with partial observation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05734v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Siming Liang, Ruoyu Hu, Feng Bao, Richard Archibald, Guannan Zhang</dc:creator>
    </item>
    <item>
      <title>On the existence of reduced order proportional-integral observer for the state estimation of continuous-time linear time-invariant systems</title>
      <link>https://arxiv.org/abs/2404.05739</link>
      <description>arXiv:2404.05739v1 Announce Type: new 
Abstract: In this paper the explicit necessary and sufficient conditions for the existence of reduced order proportional-integral observer for the state estimation of continuous-time linear time-invariant systems are established. A procedure is given for the calculation of observer matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05739v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstadinos H. Kiritsis</dc:creator>
    </item>
    <item>
      <title>Distributionally Robust Optimization with Decision-Dependent Information Discovery</title>
      <link>https://arxiv.org/abs/2404.05900</link>
      <description>arXiv:2404.05900v1 Announce Type: new 
Abstract: We study two-stage distributionally robust optimization (DRO) problems with decision-dependent information discovery (DDID) wherein (a portion of) the uncertain parameters are revealed only if an (often costly) investment is made in the first stage. This class of problems finds many important applications in selection problems (e.g., in hiring, project portfolio optimization, or optimal sensor location). Despite the problem's wide applicability, it has not been previously studied. We propose a framework for modeling and approximately solving DRO problems with DDID. We formulate the problem as a min-max-min-max problem and adopt the popular K-adaptability approximation scheme, which chooses K candidate recourse actions here-and-now and implements the best of those actions after the uncertain parameters that were chosen to be observed are revealed. We then present a decomposition algorithm that solves the K-adaptable formulation exactly. In particular, we devise a cutting plane algorithm which iteratively solves a relaxed version of the problem, evaluates the true objective value of the corresponding solution, generates valid cuts, and imposes them in the relaxed problem. For the evaluation problem, we develop a branch-and-cut algorithm that provably converges to an optimal solution. We showcase the effectiveness of our framework on the R&amp;D project portfolio optimization problem and the best box problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05900v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qing Jin, Angelos Georghiou, Phebe Vayanos, Grani A. Hanasusanto</dc:creator>
    </item>
    <item>
      <title>Multi-Agent Coverage Control with Transient Behavior Consideration</title>
      <link>https://arxiv.org/abs/2404.05995</link>
      <description>arXiv:2404.05995v1 Announce Type: new 
Abstract: This paper studies the multi-agent coverage control (MAC) problem where agents must dynamically learn an unknown density function while performing coverage tasks. Unlike many current theoretical frameworks that concentrate solely on the regret occurring at specific targeted sensory locations, our approach additionally considers the regret caused by transient behavior - the path from one location and another. We propose the multi-agent coverage control with the doubling trick (MAC-DT) algorithm and demonstrate that it achieves (approximated) regret of $\widetilde{O}(\sqrt{T})$ even when accounting for the transient behavior. Our result is also supported by numerical experiments, showcasing that the proposed algorithm manages to match or even outperform the baseline algorithms in simulation environments. We also show how our algorithm can be modified to handle safety constraints and further implement the algorithm on a real-robotic testbed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05995v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runyu Zhang, Haitong Ma, Na Li</dc:creator>
    </item>
    <item>
      <title>The turnpike property for high-dimensional interacting agent systems in discrete time</title>
      <link>https://arxiv.org/abs/2404.06134</link>
      <description>arXiv:2404.06134v1 Announce Type: new 
Abstract: We investigate the interior turnpike phenomenon for discrete-time multi-agent optimal control problems. While for continuous systems the turnpike property has been established, we focus here on first-order discretizations of such systems. It is shown that the resulting time-discrete system inherits the turnpike property with estimates of the same type as in the continuous case. In particular, we prove that the discrete time optimal control problem is strictly dissipative and the cheap control assumption holds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06134v1</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Gugat, Michael Herty, Jiehong Liu, Chiara Segala</dc:creator>
    </item>
    <item>
      <title>Inexact Policy Iteration Methods for Large-Scale Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2404.06136</link>
      <description>arXiv:2404.06136v1 Announce Type: new 
Abstract: We consider inexact policy iteration methods for large-scale infinite-horizon discounted MDPs with finite spaces, a variant of policy iteration where the policy evaluation step is implemented inexactly using an iterative solver for linear systems. In the classical dynamic programming literature, a similar principle is deployed in optimistic policy iteration, where an a-priori fixed-number of iterations of value iteration is used to inexactly solve the policy evaluation step. Inspired by the connection between policy iteration and semismooth Newton's method, we investigate a class of iPI methods that mimic the inexact variants of semismooth Newton's method by adopting a parametric stopping condition to regulate the level of inexactness of the policy evaluation step. For this class of methods we discuss local and global convergence properties and derive a practical range of values for the stopping-condition parameter that provide contraction guarantees. Our analysis is general and therefore encompasses a variety of iterative solvers for policy evaluation, including the standard value iteration as well as more sophisticated ones such as GMRES. As underlined by our analysis, the selection of the inner solver is of fundamental importance for the performance of the overall method. We therefore consider different iterative methods to solve the policy evaluation step and analyze their applicability and contraction properties when used for policy evaluation. We show that the contraction properties of these methods tend to be enhanced by the specific structure of policy evaluation and that there is margin for substantial improvement in terms of convergence rate. Finally, we study the numerical performance of different instances of inexact policy iteration on large-scale MDPs for the design of health policies to control the spread of infectious diseases in epidemiology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06136v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matilde Gargiani, Robin Sieber, Efe Balta, Dominic Liao-McPherson, John Lygeros</dc:creator>
    </item>
    <item>
      <title>On checking $\mathrm{L}^p$-admissibility for parabolic control systems</title>
      <link>https://arxiv.org/abs/2404.06250</link>
      <description>arXiv:2404.06250v1 Announce Type: new 
Abstract: In this note we discuss the difficulty of verifying $\mathrm{L}^p$-admissibility for $p\neq 2$ -- that even manifests in the presence of a self-adjoint semigroup generator on a Hilbert space -- and survey tests for $\mathrm{L}^p$-admissibility of given control operators. These tests are obtained by virtue of either mapping properties of boundary trace operators, yielding a characterization of admissibility via abstract interpolation spaces; or through Laplace--Carleson embeddings, slightly extending results from Jacob, Partington and Pott to a class of systems which are not necessarily diagonal with respect to sequence spaces. Special focus is laid on illustrating the theory by means of examples based on the heat equation on various domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06250v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philip Preu{\ss}ler, Felix L. Schwenninger</dc:creator>
    </item>
    <item>
      <title>An Overview of Absolute Value Equations: From Theory to Solution Methods and Challenges</title>
      <link>https://arxiv.org/abs/2404.06319</link>
      <description>arXiv:2404.06319v1 Announce Type: new 
Abstract: This paper provides a thorough exploration of the absolute value equations $Ax-|x|=b$, a seemingly straightforward concept that has gained heightened attention in recent years. It is an NP-hard and nondifferentiable problem and equivalent with the standard linear complementarity problem. Offering a comprehensive review of existing literature, the study delves into theorems concerning the existence and nonexistence of solutions to the absolute value equations, along with numerical methods for effectively addressing this complex equation. Going beyond conventional approaches, the paper investigates strategies for obtaining solutions with minimal norms, techniques for correcting infeasible systems, and other pertinent topics. By pinpointing challenging issues and emphasizing open problems, this paper serves as a valuable guide for shaping the future research trajectory in this dynamic and multifaceted field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06319v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Milan Hlad\'ik, Hossein Moosaei, Fakhrodin Hashemi, Saeed Ketabchi, Panos M. Pardalos</dc:creator>
    </item>
    <item>
      <title>Enhancing Pharmaceutical Cold Supply Chain: Integrating Medication Synchronization and Diverse Delivery Modes</title>
      <link>https://arxiv.org/abs/2404.06373</link>
      <description>arXiv:2404.06373v1 Announce Type: new 
Abstract: The significance of last-mile logistics in the healthcare supply chain is growing steadily, especially in pharmacies where the growing prevalence of medication delivery to patients' homes is remarkable. This paper proposes a novel mathematical model for the last-mile logistics of the pharmaceutical supply chain and optimizes a pharmacy's logistical financial outcome while considering medication synchronization, different delivery modes, and temperature requirements of medicines. We propose a mathematical formulation of the problem using Mixed Integer Linear Programming (MILP) evolved from the actual problem of an outpatient pharmacy of a Dutch hospital. We create a case study by gathering, preparing, processing, and analyzing the associated data. We find the optimal solution, using Python MIP package and the Gurobi solver, which indicates the number of order batches, the composition of these batches, and the number of staff related to the preparation of the order batches. Our results show that our optimal solution increases the pharmacy's logistical financial outcome by 34 percent. Moreover, we propose other model variations and perform extensive scenario analysis to provide managerial insights applicable to other pharmacies and distributors in the last step of cold supply chains. Based on our scenario analysis, we conclude that improving medication synchronization can significantly enhance the pharmacy's logistical financial outcome.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06373v1</guid>
      <category>math.OC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.2139/ssrn.4550876</arxiv:DOI>
      <dc:creator>Elise Potters, Behzad Mosalla Nezhad, Viktor Huiskes, Erwin Hans, Amin Asadi</dc:creator>
    </item>
    <item>
      <title>Parameter-Adaptive Approximate MPC: Tuning Neural-Network Controllers without Re-Training</title>
      <link>https://arxiv.org/abs/2404.05835</link>
      <description>arXiv:2404.05835v1 Announce Type: cross 
Abstract: Model Predictive Control (MPC) is a method to control nonlinear systems with guaranteed stability and constraint satisfaction but suffers from high computation times. Approximate MPC (AMPC) with neural networks (NNs) has emerged to address this limitation, enabling deployment on resource-constrained embedded systems. However, when tuning AMPCs for real-world systems, large datasets need to be regenerated and the NN needs to be retrained at every tuning step. This work introduces a novel, parameter-adaptive AMPC architecture capable of online tuning without recomputing large datasets and retraining. By incorporating local sensitivities of nonlinear programs, the proposed method not only mimics optimal MPC inputs but also adjusts to changes in physical parameters of the model using linear predictions while still guaranteeing stability. We showcase the effectiveness of parameter-adaptive AMPC by controlling the swing-ups of two different real cartpole systems with a severely resource-constrained microcontroller (MCU). We use the same NN across both system instances that have different parameters. This work not only represents the first experimental demonstration of AMPC for fast-moving systems on low-cost MCUs to the best of our knowledge, but also showcases generalization across system instances and variations through our parameter-adaptation method. Taken together, these contributions represent a marked step toward the practical application of AMPC in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05835v1</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henrik Hose, Alexander Gr\"afe, Sebastian Trimpe</dc:creator>
    </item>
    <item>
      <title>Design of Transit-Centric Multimodal Urban Mobility System with Autonomous Mobility-on-Demand</title>
      <link>https://arxiv.org/abs/2404.05885</link>
      <description>arXiv:2404.05885v1 Announce Type: cross 
Abstract: This paper addresses the pressing challenge of urban mobility in the context of growing urban populations, changing demand patterns for urban mobility, and emerging technologies like Mobility-on-Demand (MoD) platforms and Autonomous Vehicle (AV). As urban areas swell and demand pattern changes, the integration of Autonomous Mobility-on-Demand (AMoD) systems with existing public transit (PT) networks presents great opportunities to enhancing urban mobility. We propose a novel optimization framework for solving the Transit-Centric Multimodal Urban Mobility with Autonomous Mobility-on-Demand (TCMUM-AMoD) at scale. The system operator (public transit agency) determines the network design and frequency settings of the PT network, fleet sizing and allocations of AMoD system, and the pricing for using the multimodal system with the goal of minimizing passenger disutility. Passengers' mode and route choice behaviors are modeled explicitly using discrete choice models. A first-order approximation algorithm is introduced to solve the problem at scale. Using a case study in Chicago, we showcase the potential to optimize urban mobility across different demand scenarios. To our knowledge, ours is the first paper to jointly optimize transit network design, fleet sizing, and pricing for the multimodal mobility system while considering passengers' mode and route choices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.05885v1</guid>
      <category>cs.SI</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaotong Guo, Jinhua Zhao</dc:creator>
    </item>
    <item>
      <title>Feel-Good Thompson Sampling for Contextual Dueling Bandits</title>
      <link>https://arxiv.org/abs/2404.06013</link>
      <description>arXiv:2404.06013v1 Announce Type: cross 
Abstract: Contextual dueling bandits, where a learner compares two options based on context and receives feedback indicating which was preferred, extends classic dueling bandits by incorporating contextual information for decision-making and preference learning. Several algorithms based on the upper confidence bound (UCB) have been proposed for linear contextual dueling bandits. However, no algorithm based on posterior sampling has been developed in this setting, despite the empirical success observed in traditional contextual bandits. In this paper, we propose a Thompson sampling algorithm, named FGTS.CDB, for linear contextual dueling bandits. At the core of our algorithm is a new Feel-Good exploration term specifically tailored for dueling bandits. This term leverages the independence of the two selected arms, thereby avoiding a cross term in the analysis. We show that our algorithm achieves nearly minimax-optimal regret, i.e., $\tilde{\mathcal{O}}(d\sqrt T)$, where $d$ is the model dimension and $T$ is the time horizon. Finally, we evaluate our algorithm on synthetic data and observe that FGTS.CDB outperforms existing algorithms by a large margin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06013v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuheng Li, Heyang Zhao, Quanquan Gu</dc:creator>
    </item>
    <item>
      <title>Prelimit Coupling and Steady-State Convergence of Constant-stepsize Nonsmooth Contractive SA</title>
      <link>https://arxiv.org/abs/2404.06023</link>
      <description>arXiv:2404.06023v1 Announce Type: cross 
Abstract: Motivated by Q-learning, we study nonsmooth contractive stochastic approximation (SA) with constant stepsize. We focus on two important classes of dynamics: 1) nonsmooth contractive SA with additive noise, and 2) synchronous and asynchronous Q-learning, which features both additive and multiplicative noise. For both dynamics, we establish weak convergence of the iterates to a stationary limit distribution in Wasserstein distance. Furthermore, we propose a prelimit coupling technique for establishing steady-state convergence and characterize the limit of the stationary distribution as the stepsize goes to zero. Using this result, we derive that the asymptotic bias of nonsmooth SA is proportional to the square root of the stepsize, which stands in sharp contrast to smooth SA. This bias characterization allows for the use of Richardson-Romberg extrapolation for bias reduction in nonsmooth SA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06023v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>math.PR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yixuan Zhang, Dongyan Huo, Yudong Chen, Qiaomin Xie</dc:creator>
    </item>
    <item>
      <title>Optimization methods for solving matrix equations</title>
      <link>https://arxiv.org/abs/2404.06030</link>
      <description>arXiv:2404.06030v1 Announce Type: cross 
Abstract: In this paper, we focus on using optimization methods to solve matrix equations by transforming the problem of solving the Sylvester matrix equation or continuous algebraic Riccati equation into an optimization problem. Initially, we use a constrained convex optimization method (CCOM) to solve the Sylvester matrix equation with $\ell_{2,1}$-norm, where we provide a convergence analysis and numerical examples of CCOM; however, the results show that the algorithm is not efficient. To address this issue, we employ classical quasi-Newton methods such as DFP and BFGS algorithms to solve the Sylvester matrix equation and present the convergence and numerical results of the algorithm. Additionally, we compare these algorithms with the CG algorithm and AR algorithm, and our results demonstrate that the presented algorithms are effective. Furthermore, we propose a unified framework of the alternating direction multiplier method (ADMM) for directly solving the continuous algebraic Riccati equation (CARE), and we provide the convergence and numerical results of ADMM. Our experimental results indicate that ADMM is an effective optimization algorithm for solving CARE. Finally, to improve the effectiveness of the optimization method for solving Riccati equation, we propose the Newton-ADMM algorithm framework, where the outer iteration of this method is the classical Newton method, and the inner iteration involves using ADMM to solve Lyapunov matrix equations inexactly. We also provide the convergence and numerical results of this algorithm, which our results demonstrate are more efficient than ADMM for solving CARE.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06030v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Juan Zhang, Xiao Luo</dc:creator>
    </item>
    <item>
      <title>Minimizing the determinant of the graph Laplacian</title>
      <link>https://arxiv.org/abs/2404.06363</link>
      <description>arXiv:2404.06363v1 Announce Type: cross 
Abstract: In this paper, we study extremal values for the determinant of the weighted graph Laplacian under simple nondegeneracy conditions on the weights. We derive necessary and sufficient conditions for the determinant of the Laplacian to be bounded away from zero and for the existence of a minimizing set of weights. These conditions are given both in terms of properties of random spanning trees and in terms of a type of density on graphs. These results generalize and extend the work of [7].</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06363v1</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nathan Albin, Joan Lind, Anna Melikyan, Pietro Poggi-Corradini</dc:creator>
    </item>
    <item>
      <title>Large Language Models to the Rescue: Deadlock Resolution in Multi-Robot Systems</title>
      <link>https://arxiv.org/abs/2404.06413</link>
      <description>arXiv:2404.06413v1 Announce Type: cross 
Abstract: Multi-agent robotic systems are prone to deadlocks in an obstacle environment where the system can get stuck away from its desired location under a smooth low-level control policy. Without an external intervention, often in terms of a high-level command, it is not possible to guarantee that just a low-level control policy can resolve such deadlocks. Utilizing the generalizability and low data requirements of large language models (LLMs), this paper explores the possibility of using LLMs for deadlock resolution. We propose a hierarchical control framework where an LLM resolves deadlocks by assigning a leader and direction for the leader to move along. A graph neural network (GNN) based low-level distributed control policy executes the assigned plan. We systematically study various prompting techniques to improve LLM's performance in resolving deadlocks. In particular, as part of prompt engineering, we provide in-context examples for LLMs. We conducted extensive experiments on various multi-robot environments with up to 15 agents and 40 obstacles. Our results demonstrate that LLM-based high-level planners are effective in resolving deadlocks in MRS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06413v1</guid>
      <category>cs.RO</category>
      <category>cs.CL</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kunal Garg, Jacob Arkin, Songyuan Zhang, Nicholas Roy, Chuchu Fan</dc:creator>
    </item>
    <item>
      <title>The Central Spanning Tree Problem</title>
      <link>https://arxiv.org/abs/2404.06447</link>
      <description>arXiv:2404.06447v1 Announce Type: cross 
Abstract: Spanning trees are an important primitive in many data analysis tasks, when a data set needs to be summarized in terms of its "skeleton", or when a tree-shaped graph over all observations is required for downstream processing. Popular definitions of spanning trees include the minimum spanning tree and the optimum distance spanning tree, a.k.a. the minimum routing cost tree. When searching for the shortest spanning tree but admitting additional branching points, even shorter spanning trees can be realized: Steiner trees. Unfortunately, both minimum spanning and Steiner trees are not robust with respect to noise in the observations; that is, small perturbations of the original data set often lead to drastic changes in the associated spanning trees. In response, we make two contributions when the data lies in a Euclidean space: on the theoretical side, we introduce a new optimization problem, the "(branched) central spanning tree", which subsumes all previously mentioned definitions as special cases. On the practical side, we show empirically that the (branched) central spanning tree is more robust to noise in the data, and as such is better suited to summarize a data set in terms of its skeleton. We also propose a heuristic to address the NP-hard optimization problem, and illustrate its use on single cell RNA expression data from biology and 3D point clouds of plants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.06447v1</guid>
      <category>cs.DM</category>
      <category>cs.CV</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Enrique Fita Sanmart\'in, Christoph Schn\"orr, Fred A. Hamprecht</dc:creator>
    </item>
    <item>
      <title>Single-Projection Procedure for Infinite Dimensional Convex Optimization Problems</title>
      <link>https://arxiv.org/abs/2210.11252</link>
      <description>arXiv:2210.11252v2 Announce Type: replace 
Abstract: In this work, we consider a class of convex optimization problems in a real Hilbert space that can be solved by performing a single projection, i.e., by projecting an infeasible point onto the feasible set. Our results improve those established for the linear programming setting in Nurminski (2015) by considering problems that: (i) may have multiple solutions, (ii) do not satisfy strict complementary conditions, and (iii) possess non-linear convex constraints. As a by-product of our analysis, we provide a quantitative estimate on the required distance between the infeasible point and the feasible set in order for its projection to be a solution of the problem. Our analysis relies on a "sharpness" property of the constraint set; a new property we introduce here.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.11252v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Hoa T. Bui, Regina S. Burachik, Evgeni A. Nurminski, Matthew K. Tam</dc:creator>
    </item>
    <item>
      <title>From approximate to exact integer programming</title>
      <link>https://arxiv.org/abs/2211.03859</link>
      <description>arXiv:2211.03859v4 Announce Type: replace 
Abstract: Approximate integer programming is the following: For a convex body $K \subseteq \mathbb{R}^n$, either determine whether $K \cap \mathbb{Z}^n$ is empty, or find an integer point in the convex body scaled by $2$ from its center of gravity $c$. Approximate integer programming can be solved in time $2^{O(n)}$ while the fastest known methods for exact integer programming run in time $2^{O(n)} \cdot n^n$. So far, there are no efficient methods for integer programming known that are based on approximate integer programming. Our main contribution are two such methods, each yielding novel complexity results.
  First, we show that an integer point $x^* \in (K \cap \mathbb{Z}^n)$ can be found in time $2^{O(n)}$, provided that the remainders of each component $x_i^* \mod{\ell}$ for some arbitrarily fixed $\ell \geq 5(n+1)$ of $x^*$ are given. The algorithm is based on a cutting-plane technique, iteratively halving the volume of the feasible set. The cutting planes are determined via approximate integer programming. Enumeration of the possible remainders gives a $2^{O(n)}n^n$ algorithm for general integer programming. This matches the current best bound of an algorithm by Dadush (2012) that is considerably more involved. Our algorithm also relies on a new asymmetric approximate Carath\'eodory theorem that might be of interest on its own.
  Our second method concerns integer programming problems in equation-standard form $Ax = b, 0 \leq x \leq u, \, x \in \mathbb{Z}^n$ . Such a problem can be reduced to the solution of $\prod_i O(\log u_i +1)$ approximate integer programming problems. This implies, for example that knapsack or subset-sum problems with polynomial variable range $0 \leq x_i \leq p(n)$ can be solved in time $(\log n)^{O(n)}$. For these problems, the best running time so far was $n^n \cdot 2^{O(n)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.03859v4</guid>
      <category>math.OC</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Daniel Dadush, Friedrich Eisenbrand, Thomas Rothvoss</dc:creator>
    </item>
    <item>
      <title>Offline Supervised Learning V.S. Online Direct Policy Optimization: A Comparative Study and A Unified Training Paradigm for Neural Network-Based Optimal Feedback Control</title>
      <link>https://arxiv.org/abs/2211.15930</link>
      <description>arXiv:2211.15930v3 Announce Type: replace 
Abstract: This work is concerned with solving neural network-based feedback controllers efficiently for optimal control problems. We first conduct a comparative study of two prevalent approaches: offline supervised learning and online direct policy optimization. Albeit the training part of the supervised learning approach is relatively easy, the success of the method heavily depends on the optimal control dataset generated by open-loop optimal control solvers. In contrast, direct policy optimization turns the optimal control problem into an optimization problem directly without any requirement of pre-computing, but the dynamics-related objective can be hard to optimize when the problem is complicated. Our results underscore the superiority of offline supervised learning in terms of both optimality and training time. To overcome the main challenges, dataset and optimization, in the two approaches respectively, we complement them and propose the Pre-train and Fine-tune strategy as a unified training paradigm for optimal feedback control, which further improves the performance and robustness significantly. Our code is accessible at https://github.com/yzhao98/DeepOptimalControl.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.15930v3</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.physd.2024.134130</arxiv:DOI>
      <dc:creator>Yue Zhao, Jiequn Han</dc:creator>
    </item>
    <item>
      <title>Linear convergence of forward-backward accelerated algorithms without knowledge of the modulus of strong convexity</title>
      <link>https://arxiv.org/abs/2306.09694</link>
      <description>arXiv:2306.09694v2 Announce Type: replace 
Abstract: A significant milestone in modern gradient-based optimization was achieved with the development of Nesterov's accelerated gradient descent (NAG) method. This forward-backward technique has been further advanced with the introduction of its proximal generalization, commonly known as the fast iterative shrinkage-thresholding algorithm (FISTA), which enjoys widespread application in image science and engineering. Nonetheless, it remains unclear whether both NAG and FISTA exhibit linear convergence for strongly convex functions. Remarkably, these algorithms demonstrate convergence without requiring any prior knowledge of strongly convex modulus, and this intriguing characteristic has been acknowledged as an open problem in the comprehensive review [Chambolle and Pock, 2016, Appendix B]. In this paper, we address this question by utilizing the high-resolution ordinary differential equation (ODE) framework. Expanding upon the established phase-space representation, we emphasize the distinctive approach employed in crafting the Lyapunov function, which involves a dynamically adapting coefficient of kinetic energy that evolves throughout the iterations. Furthermore, we highlight that the linear convergence of both NAG and FISTA is independent of the parameter $r$. Additionally, we demonstrate that the square of the proximal subgradient norm likewise advances towards linear convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.09694v2</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Bowen Li, Bin Shi, Ya-xiang Yuan</dc:creator>
    </item>
    <item>
      <title>Convergence rate of entropy-regularized multi-marginal optimal transport costs</title>
      <link>https://arxiv.org/abs/2307.03023</link>
      <description>arXiv:2307.03023v3 Announce Type: replace 
Abstract: We investigate the convergence rate of multi-marginal optimal transport costs that are regularized with the Boltzmann-Shannon entropy, as the noise parameter $\varepsilon$ tends to $0$. We establish lower and upper bounds on the difference with the unregularized cost of the form $C\varepsilon\log(1/\varepsilon)+O(\varepsilon)$ for some explicit dimensional constants $C$ depending on the marginals and on the ground cost, but not on the optimal transport plans themselves. Upper bounds are obtained for Lipschitz costs or locally semi-concave costs for a finer estimate, and lower bounds for $\mathscr{C}^2$ costs satisfying some signature condition on the mixed second derivatives that may include degenerate costs, thus generalizing results previously in the two marginals case and for non-degenerate costs. We obtain in particular matching bounds in some typical situations where the optimal plan is deterministic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2307.03023v3</guid>
      <category>math.OC</category>
      <category>math.AP</category>
      <category>math.FA</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4153/S0008414X24000257</arxiv:DOI>
      <arxiv:journal_reference>Canadian Journal of Mathematics, March 2024, First View, pp. 1-21</arxiv:journal_reference>
      <dc:creator>Luca Nenna, Paul Pegon</dc:creator>
    </item>
    <item>
      <title>Stochastic Controlled Averaging for Federated Learning with Communication Compression</title>
      <link>https://arxiv.org/abs/2308.08165</link>
      <description>arXiv:2308.08165v2 Announce Type: replace 
Abstract: Communication compression, a technique aiming to reduce the information volume to be transmitted over the air, has gained great interests in Federated Learning (FL) for the potential of alleviating its communication overhead. However, communication compression brings forth new challenges in FL due to the interplay of compression-incurred information distortion and inherent characteristics of FL such as partial participation and data heterogeneity. Despite the recent development, the performance of compressed FL approaches has not been fully exploited. The existing approaches either cannot accommodate arbitrary data heterogeneity or partial participation, or require stringent conditions on compression.
  In this paper, we revisit the seminal stochastic controlled averaging method by proposing an equivalent but more efficient/simplified formulation with halved uplink communication costs. Building upon this implementation, we propose two compressed FL algorithms, SCALLION and SCAFCOM, to support unbiased and biased compression, respectively. Both the proposed methods outperform the existing compressed FL methods in terms of communication and computation complexities. Moreover, SCALLION and SCAFCOM accommodates arbitrary data heterogeneity and do not make any additional assumptions on compression errors. Experiments show that SCALLION and SCAFCOM can match the performance of corresponding full-precision FL approaches with substantially reduced uplink communication, and outperform recent compressed FL methods under the same communication budget.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.08165v2</guid>
      <category>math.OC</category>
      <category>cs.DC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xinmeng Huang, Ping Li, Xiaoyun Li</dc:creator>
    </item>
    <item>
      <title>Multistage Stochastic Program for Mitigating Power System Risks under Wildfire Disruptions</title>
      <link>https://arxiv.org/abs/2310.16544</link>
      <description>arXiv:2310.16544v3 Announce Type: replace 
Abstract: The frequency of wildfire disasters has surged five-fold in the past 50 years due to climate change. Preemptive de-energization is a potent strategy to mitigate wildfire risks but substantially impacts customers. We propose a multistage stochastic programming model for proactive de-energization planning, aiming to minimize economic loss while accomplishing a fair load delivery. We model wildfire disruptions as stochastic disruptions with varying timing and intensity, introduce a cutting-plane decomposition algorithm, and test our approach on the RTS-GLMC test case. Our model consistently offers a robust and fair de-energization plan that mitigates wildfire damage costs and minimizes load-shedding losses, particularly when pre-disruption restoration is considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.16544v3</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hanbin Yang, Noah Rhodes, Haoxiang Yang, Line Roald, Lewis Ntaimo</dc:creator>
    </item>
    <item>
      <title>Optimisation models for the design of multiple self-consumption loops in semi-rural areas</title>
      <link>https://arxiv.org/abs/2404.04428</link>
      <description>arXiv:2404.04428v2 Announce Type: replace 
Abstract: Collective electricity self-consumption gains increasing interest in a context where localised consumption of energy is a lever of sustainable development. While easing energy distribution networks, collective self-consumption requires complementary prosumers' profiles. Before determining the proper energy exchanges happening between these prosumers, one must ensure their compatibility in the context of collective self-consumption. Motivated by real use cases from a solar power producer, this article proposes network flow-based linear models to solve both the design aspect of the problem and the attribution of distribution flows between the involved prosumers. Two main models are proposed, handling (i) single collective self-consumption loop creation and (ii) multiple loop creation. One of the objectives of this work is to provide models that can be applied at a strategic level which implies their extension to large time scale and large spatial scale. To do so, associated Benders and Dantzig-Wolfe decompositions are proposed to ensure model scalability along temporal and spatial dimensions. The proposed models are tested on realistic use cases to assess their performances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04428v2</guid>
      <category>math.OC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohann Chasseray, Mathieu Besan\c{c}on, \'Eva Petitdemange, Xavier Lorca</dc:creator>
    </item>
    <item>
      <title>Convex Reformulation of LMI-Based Distributed Controller Design with a Class of Non-Block-Diagonal Lyapunov Functions</title>
      <link>https://arxiv.org/abs/2404.04576</link>
      <description>arXiv:2404.04576v2 Announce Type: replace 
Abstract: This study addresses a distributed state feedback controller design problem for continuous-time linear time-invariant systems by means of linear matrix inequalities (LMI). As the exact convexification is still open, the block-diagonal relaxation of Lyapunov functions has been prevalent despite its conservatism. In this work, we target a class of non-block-diagonal Lyapunov functions that has the same sparsity as distributed controllers. By leveraging a block-diagonal factorization of sparse matrices and Finsler's lemma, we first present a (nonlinear) matrix inequality for stabilizing distributed controllers with such Lyapunov functions, which boils down to a necessary and sufficient condition for such controllers if the sparsity pattern is chordal. As a relaxation of the inequality, we derive an LMI that completely covers the conventional relaxation and then provide analogous results for $H_\infty$ control. Lastly, numerical examples underscore the efficacy of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04576v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Yuto Watanabe, Sotaro Fushimi, Kazunori Sakurama</dc:creator>
    </item>
    <item>
      <title>Robustifying Conditional Portfolio Decisions via Optimal Transport</title>
      <link>https://arxiv.org/abs/2103.16451</link>
      <description>arXiv:2103.16451v3 Announce Type: replace-cross 
Abstract: We propose a data-driven portfolio selection model that integrates side information, conditional estimation and robustness using the framework of distributionally robust optimization. Conditioning on the observed side information, the portfolio manager solves an allocation problem that minimizes the worst-case conditional risk-return trade-off, subject to all possible perturbations of the covariate-return probability distribution in an optimal transport ambiguity set. Despite the non-linearity of the objective function in the probability measure, we show that the distributionally robust portfolio allocation with side information problem can be reformulated as a finite-dimensional optimization problem. If portfolio decisions are made based on either the mean-variance or the mean-Conditional Value-at-Risk criterion, the resulting reformulation can be further simplified to second-order or semi-definite cone programs. Empirical studies in the US equity market demonstrate the advantage of our integrative framework against other benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2103.16451v3</guid>
      <category>q-fin.PM</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Viet Anh Nguyen, Fan Zhang, Shanshan Wang, Jose Blanchet, Erick Delage, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Generalized Nash Equilibrium Problems with Mixed-Integer Variables</title>
      <link>https://arxiv.org/abs/2107.13298</link>
      <description>arXiv:2107.13298v3 Announce Type: replace-cross 
Abstract: We consider generalized Nash equilibrium problems (GNEPs) with non-convex strategy spaces and non-convex cost functions. This general class of games includes the important case of games with mixed-integer variables for which only a few results are known in the literature. We present a new approach to characterize equilibria via a convexification technique using the Nikaido-Isoda function. To any given instance of the GNEP, we construct a set of convexified instances and show that a feasible strategy profile is an equilibrium for the original instance if and only if it is an equilibrium for any convexified instance and the convexified cost functions coincide with the initial ones. We develop this convexification approach along three dimensions: We first show that for quasi-linear models, where a convexified instance exists in which for fixed strategies of the opponent players, the cost function of every player is linear and the respective strategy space is polyhedral, the convexification reduces the GNEP to a standard (non-linear) optimization problem. Secondly, we derive two complete characterizations of those GNEPs for which the convexification leads to a jointly constrained or a jointly convex GNEP, respectively. These characterizations require new concepts related to the interplay of the convex hull operator applied to restricted subsets of feasible strategies and may be interesting on their own. Note that this characterization is also computationally relevant as jointly convex GNEPs have been extensively studied in the literature. Finally, we demonstrate the applicability of our results by presenting a numerical study regarding the computation of equilibria for three classes of GNEPs related to integral network flows and discrete market equilibria.</description>
      <guid isPermaLink="false">oai:arXiv.org:2107.13298v3</guid>
      <category>cs.GT</category>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1007/s10107-024-02063-6</arxiv:DOI>
      <arxiv:journal_reference>Mathematical Programming (2024)</arxiv:journal_reference>
      <dc:creator>Tobias Harks, Julian Schwarz</dc:creator>
    </item>
    <item>
      <title>The out-of-sample prediction error of the square-root-LASSO and related estimators</title>
      <link>https://arxiv.org/abs/2211.07608</link>
      <description>arXiv:2211.07608v3 Announce Type: replace-cross 
Abstract: We study the classical problem of predicting an outcome variable, $Y$, using a linear combination of a $d$-dimensional covariate vector, $\mathbf{X}$. We are interested in linear predictors whose coefficients solve: % \begin{align*} \inf_{\boldsymbol{\beta} \in \mathbb{R}^d} \left( \mathbb{E}_{\mathbb{P}_n} \left[ \left(Y-\mathbf{X}^{\top}\beta \right)^r \right] \right)^{1/r} +\delta \, \rho\left(\boldsymbol{\beta}\right), \end{align*} where $\delta&gt;0$ is a regularization parameter, $\rho:\mathbb{R}^d\to \mathbb{R}_+$ is a convex penalty function, $\mathbb{P}_n$ is the empirical distribution of the data, and $r\geq 1$. We present three sets of new results. First, we provide conditions under which linear predictors based on these estimators % solve a \emph{distributionally robust optimization} problem: they minimize the worst-case prediction error over distributions that are close to each other in a type of \emph{max-sliced Wasserstein metric}. Second, we provide a detailed finite-sample and asymptotic analysis of the statistical properties of the balls of distributions over which the worst-case prediction error is analyzed. Third, we use the distributionally robust optimality and our statistical analysis to present i) an oracle recommendation for the choice of regularization parameter, $\delta$, that guarantees good out-of-sample prediction error; and ii) a test-statistic to rank the out-of-sample performance of two different linear estimators. None of our results rely on sparsity assumptions about the true data generating process; thus, they broaden the scope of use of the square-root lasso and related estimators in prediction problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.07608v3</guid>
      <category>math.ST</category>
      <category>math.OC</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jos\'e Luis Montiel Olea, Cynthia Rush, Amilcar Velez, Johannes Wiesel</dc:creator>
    </item>
    <item>
      <title>On the Circuit Diameter Conjecture for Counterexamples to the Hirsch Conjecture</title>
      <link>https://arxiv.org/abs/2302.03977</link>
      <description>arXiv:2302.03977v4 Announce Type: replace-cross 
Abstract: Circuit diameters of polyhedra are a fundamental tool for studying the complexity of circuit augmentation schemes for linear programming and for finding lower bounds on combinatorial diameters. The main open problem in this area is the circuit diameter conjecture, the analogue of the Hirsch conjecture in the circuit setting. A natural question is whether the well-known counterexamples to the Hirsch conjecture carry over. Previously, Stephen and Yusun showed that the Klee-Walkup counterexample to the unbounded Hirsch conjecture does not transfer to the circuit setting. Our main contribution is to show that the original counterexamples for the other variants, for bounded polytopes and using monotone walks, also do not transfer.
  Our results rely on new observations on structural properties of these counterexamples. To resolve the bounded case, we exploit the geometry of certain $2$-faces of the polytopes underlying all known bounded Hirsch counterexamples in Santos' work. For Todd's monotone Hirsch counterexample, we provide two alternative approaches. The first one uses sign-compatible circuit walks, and the second one uses the observation that Todd's polytope is anti-blocking. Along the way, we enumerate all linear programs over the polytope and find four new orientations that contradict the monotone Hirsch conjecture, while the remaining $7107$ satisfy the bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.03977v4</guid>
      <category>math.CO</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander E. Black, Steffen Borgwardt, Matthias Brugger</dc:creator>
    </item>
    <item>
      <title>Medical Image Registration using optimal control of a linear hyperbolic transport equation with a DG discretization</title>
      <link>https://arxiv.org/abs/2305.03020</link>
      <description>arXiv:2305.03020v2 Announce Type: replace-cross 
Abstract: Patient specific brain mesh generation from MRI can be a time consuming task and require manual corrections, e.g., for meshing the ventricular system or defining subdomains. To address this issue, we consider an image registration approach. The idea is to use the registration of an input magnetic resonance image (MRI) to a respective target in order to obtain a new mesh from a template mesh. To obtain the transformation, we solve an optimization problem that is constrained by a linear hyperbolic transport equation. We use a higher-order discontinuous Galerkin finite element method for discretization and motivate the numerical upwind scheme and its limitations from the continuous weak space--time formulation of the transport equation. We present a numerical implementation that builds on the finite element packages FEniCS and dolfin-adjoint. To demonstrate the efficacy of the proposed approach, numerical results for the registration of an input to a target MRI of two distinct individuals are presented. Moreover, it is shown that the registration transforms a manually crafted input mesh into a new mesh for the target subject whilst preserving mesh quality. Challenges of the algorithm are discussed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.03020v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bastian Zapf, Johannes Haubner, Lukas Baumg\"artner, Stephan Schmidt</dc:creator>
    </item>
    <item>
      <title>MPC-Inspired Reinforcement Learning for Verifiable Model-Free Control</title>
      <link>https://arxiv.org/abs/2312.05332</link>
      <description>arXiv:2312.05332v5 Announce Type: replace-cross 
Abstract: In this paper, we introduce a new class of parameterized controllers, drawing inspiration from Model Predictive Control (MPC). The controller resembles a Quadratic Programming (QP) solver of a linear MPC problem, with the parameters of the controller being trained via Deep Reinforcement Learning (DRL) rather than derived from system models. This approach addresses the limitations of common controllers with Multi-Layer Perceptron (MLP) or other general neural network architecture used in DRL, in terms of verifiability and performance guarantees, and the learned controllers possess verifiable properties like persistent feasibility and asymptotic stability akin to MPC. On the other hand, numerical examples illustrate that the proposed controller empirically matches MPC and MLP controllers in terms of control performance and has superior robustness against modeling uncertainty and noises. Furthermore, the proposed controller is significantly more computationally efficient compared to MPC and requires fewer parameters to learn than MLP controllers. Real-world experiments on vehicle drift maneuvering task demonstrate the potential of these controllers for robotics and other demanding control tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05332v5</guid>
      <category>eess.SY</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yiwen Lu, Zishuo Li, Yihan Zhou, Na Li, Yilin Mo</dc:creator>
    </item>
    <item>
      <title>TS-RSR: A provably efficient approach for batch bayesian optimization</title>
      <link>https://arxiv.org/abs/2403.04764</link>
      <description>arXiv:2403.04764v2 Announce Type: replace-cross 
Abstract: This paper presents a new approach for batch Bayesian Optimization (BO) called Thompson Sampling-Regret to Sigma Ratio directed sampling (TS-RSR), where we sample a new batch of actions by minimizing a Thompson Sampling approximation of a regret to uncertainty ratio. Our sampling objective is able to coordinate the actions chosen in each batch in a way that minimizes redundancy between points whilst focusing on points with high predictive means or high uncertainty. We provide high-probability theoretical guarantees on the regret of our algorithm. Finally, numerically, we demonstrate that our method attains state-of-the-art performance on a range of challenging synthetic and realistic test functions, where it outperforms several competitive benchmark batch BO algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.04764v2</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhaolin Ren, Na Li</dc:creator>
    </item>
    <item>
      <title>Variational structures for the Fokker--Planck equation with general Dirichlet boundary conditions</title>
      <link>https://arxiv.org/abs/2403.07803</link>
      <description>arXiv:2403.07803v2 Announce Type: replace-cross 
Abstract: We prove the convergence of a modified Jordan--Kinderlehrer--Otto scheme to a solution to the Fokker--Planck equation in $\Omega \Subset \mathbb{R}^d$ with general, positive and temporally constant, Dirichlet boundary conditions. We work under mild assumptions on the domain, the drift, and the initial datum.
  In the special case where $\Omega$ is an interval in $\mathbb{R}^1$, we prove that such a solution is a gradient flow -- curve of maximal slope -- within a suitable space of measures, endowed with a modified Wasserstein distance.
  Our discrete scheme and modified distance draw inspiration from contributions by A. Figalli and N. Gigli [J. Math. Pures Appl. 94, (2010), pp. 107--130], and J. Morales [J. Math. Pures Appl. 112, (2018), pp. 41--88] on an optimal-transport approach to evolution equations with Dirichlet boundary conditions. Similarly to these works, we allow the mass to flow from/to the boundary $\partial \Omega$ throughout the evolution. However, our leading idea is to also keep track of the mass at the boundary by working with measures defined on the whole closure $\overline \Omega$.
  The driving functional is a modification of the classical relative entropy that also makes use of the information at the boundary. As an intermediate result, when $\Omega$ is an interval in $\mathbb{R}^1$, we find a formula for the descending slope of this geodesically nonconvex functional.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07803v2</guid>
      <category>math.AP</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Filippo Quattrocchi</dc:creator>
    </item>
    <item>
      <title>Towards Stable Machine Learning Model Retraining via Slowly Varying Sequences</title>
      <link>https://arxiv.org/abs/2403.19871</link>
      <description>arXiv:2403.19871v2 Announce Type: replace-cross 
Abstract: Retraining machine learning models remains an important task for real-world machine learning model deployment. Existing methods focus largely on greedy approaches to find the best-performing model without considering the stability of trained model structures across different retraining evolutions. In this study, we develop a mixed integer optimization algorithm that holistically considers the problem of retraining machine learning models across different data batch updates. Our method focuses on retaining consistent analytical insights - which is important to model interpretability, ease of implementation, and fostering trust with users - by using custom-defined distance metrics that can be directly incorporated into the optimization problem. Importantly, our method shows stronger stability than greedily trained models with a small, controllable sacrifice in model performance in a real-world production case study. Finally, important analytical insights, as demonstrated using SHAP feature importance, are shown to be consistent across retraining iterations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19871v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>math.OC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dimitris Bertsimas, Vassilis Digalakis Jr, Yu Ma, Phevos Paschalidis</dc:creator>
    </item>
  </channel>
</rss>
