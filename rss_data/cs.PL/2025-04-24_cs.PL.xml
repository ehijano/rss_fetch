<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 25 Apr 2025 01:43:32 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>IsaBIL: A Framework for Verifying (In)correctness of Binaries in Isabelle/HOL (Extended Version)</title>
      <link>https://arxiv.org/abs/2504.16775</link>
      <description>arXiv:2504.16775v1 Announce Type: new 
Abstract: This paper presents IsaBIL, a binary analysis framework in Isabelle/HOL that is based on the widely used Binary Analysis Platform (BAP). Specifically, in IsaBIL, we formalise BAP's intermediate language, called BIL and integrate it with Hoare logic (to enable proofs of correctness) as well as incorrectness logic (to enable proofs of incorrectness). IsaBIL inherits the full flexibility of BAP, allowing us to verify binaries for a wide range of languages (C, C++, Rust), toolchains (LLVM, Ghidra) and target architectures (x86, RISC-V), and can also be used when the source code for a binary is unavailable.
  To make verification tractable, we develop a number of big-step rules that combine BIL's existing small-step rules at different levels of abstraction to support reuse. We develop high-level reasoning rules for RISC-V instructions (our main target architecture) to further optimise verification. Additionally, we develop Isabelle proof tactics that exploit common patterns in C binaries for RISC-V to discharge large numbers of proof goals (often in the 100s) automatically. IsaBIL includes an Isabelle/ML based parser for BIL programs, allowing one to automatically generate the associated Isabelle/HOL program locale from a BAP output. Taken together, IsaBIL provides a highly flexible proof environment for program binaries. As examples, we prove correctness of key examples from the Joint Strike Fighter coding standards and the MITRE database.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16775v1</guid>
      <category>cs.PL</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Matt Griffin, Brijesh Dongol, Azalea Raad</dc:creator>
    </item>
    <item>
      <title>Hexcute: A Tile-based Programming Language with Automatic Layout and Task-Mapping Synthesis</title>
      <link>https://arxiv.org/abs/2504.16214</link>
      <description>arXiv:2504.16214v1 Announce Type: cross 
Abstract: Deep learning (DL) workloads mainly run on accelerators like GPUs. Recent DL quantization techniques demand a new matrix multiplication operator with mixed input data types, further complicating GPU optimization. Prior high-level compilers like Triton lack the expressiveness to implement key optimizations like fine-grained data pipelines and hardware-friendly memory layouts for these operators, while low-level programming models, such as Hidet, Graphene, and CUTLASS, require significant programming efforts. To balance expressiveness with engineering effort, we propose Hexcute, a tile-based programming language that exposes shared memory and register abstractions to enable fine-grained optimization for these operators. Additionally, Hexcute leverages task mapping to schedule the GPU program, and to reduce programming efforts, it automates layout and task mapping synthesis with a novel type-inference-based algorithm. Our evaluation shows that Hexcute generalizes to a wide range of DL operators, achieves 1.7-11.28$\times$ speedup over existing DL compilers for mixed-type operators, and brings up to 2.91$\times$ speedup in the end-to-end evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16214v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiao Zhang, Yaoyao Ding, Yang Hu, Gennady Pekhimenko</dc:creator>
    </item>
    <item>
      <title>Optimization Framework for Reducing Mid-circuit Measurements and Resets</title>
      <link>https://arxiv.org/abs/2504.16579</link>
      <description>arXiv:2504.16579v1 Announce Type: cross 
Abstract: The paper addresses the optimization of dynamic circuits in quantum computing, with a focus on reducing the cost of mid-circuit measurements and resets. We extend the probabilistic circuit model (PCM) and implement an optimization framework that targets both mid-circuit measurements and resets. To overcome the limitation of the prior PCM-based pass, where optimizations are only possible on pure single-qubit states, we incorporate circuit synthesis to enable optimizations on multi-qubit states. With a parameter $n_{pcm}$, our framework balances optimization level against resource usage.We evaluate our framework using a large dataset of randomly generated dynamic circuits. Experimental results demonstrate that our method is highly effective in reducing mid-circuit measurements and resets. In our demonstrative example, when applying our optimization framework to the Bernstein-Vazirani algorithm after employing qubit reuse, we significantly reduce its runtime overhead by removing all of the resets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.16579v1</guid>
      <category>quant-ph</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanbin Chen, Innocenzo Fulginiti, Christian B. Mendl</dc:creator>
    </item>
    <item>
      <title>A robust graph-based approach to observational equivalence</title>
      <link>https://arxiv.org/abs/1907.01257</link>
      <description>arXiv:1907.01257v5 Announce Type: replace 
Abstract: We propose a new step-wise approach to proving observational equivalence, and in particular reasoning about fragility of observational equivalence. Our approach is based on what we call local reasoning. The local reasoning exploits the graphical concept of neighbourhood, and it extracts a new, formal, concept of robustness as a key sufficient condition of observational equivalence. Moreover, our proof methodology is capable of proving a generalised notion of observational equivalence. The generalised notion can be quantified over syntactically restricted contexts instead of all contexts, and also quantitatively constrained in terms of the number of reduction steps. The operational machinery we use is given by a hypergraph-rewriting abstract machine inspired by Girard's Geometry of Interaction. The behaviour of language features, including function abstraction and application, is provided by hypergraph-rewriting rules. We demonstrate our proof methodology using the call-by-value lambda-calculus equipped with (higher-order) state.</description>
      <guid isPermaLink="false">oai:arXiv.org:1907.01257v5</guid>
      <category>cs.PL</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dan R. Ghica, Koko Muroya, Todd Waugh Ambridge</dc:creator>
    </item>
    <item>
      <title>ChatDBG: Augmenting Debugging with Large Language Models</title>
      <link>https://arxiv.org/abs/2403.16354</link>
      <description>arXiv:2403.16354v4 Announce Type: replace-cross 
Abstract: Debugging is a critical but challenging task for programmers. This paper proposes ChatDBG, an AI-powered debugging assistant. ChatDBG integrates large language models (LLMs) to significantly enhance the capabilities and user-friendliness of conventional debuggers. ChatDBG lets programmers engage in a collaborative dialogue with the debugger, allowing them to pose complex questions about program state, perform root cause analysis for crashes or assertion failures, and explore open-ended queries like "why is x null?". To handle these queries, ChatDBG grants the LLM autonomy to "take the wheel": it can act as an independent agent capable of querying and controlling the debugger to navigate through stacks and inspect program state. It then reports its findings and yields back control to the programmer. By leveraging the real-world knowledge embedded in LLMs, ChatDBG can diagnose issues identifiable only through the use of domain-specific reasoning. Our ChatDBG prototype integrates with standard debuggers including LLDB and GDB for native code and Pdb for Python. Our evaluation across a diverse set of code, including C/C++ code with known bugs and a suite of Python code including standalone scripts and Jupyter notebooks, demonstrates that ChatDBG can successfully analyze root causes, explain bugs, and generate accurate fixes for a wide range of real-world errors. For the Python programs, a single query led to an actionable bug fix 67% of the time; one additional follow-up query increased the success rate to 85%. ChatDBG has seen rapid uptake; it has already been downloaded more than 75,000 times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16354v4</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.PL</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3729355</arxiv:DOI>
      <dc:creator>Kyla H. Levin, Nicolas van Kempen, Emery D. Berger, Stephen N. Freund</dc:creator>
    </item>
    <item>
      <title>A Language for Smart Contracts with Secure Control Flow (Technical Report)</title>
      <link>https://arxiv.org/abs/2407.01204</link>
      <description>arXiv:2407.01204v2 Announce Type: replace-cross 
Abstract: Smart contracts are frequently vulnerable to control-flow attacks based on confused deputies, reentrancy, and incorrect error handling. These attacks exploit the complexity of interactions among multiple possibly unknown contracts. Existing best practices to prevent vulnerabilities rely on code patterns and heuristics that produce both false positives and false negatives. Even with extensive audits and heuristic tools, new vulnerabilities continue to arise, routinely costing tens of millions of dollars.
  We introduce SCIF, a language for secure smart contracts, that addresses these classes of control-flow attacks. By extending secure information flow mechanisms in a principled way, SCIF enforces both classic end-to-end information flow security and new security restrictions on control flow, even when SCIF contracts interact with malicious non-SCIF code. SCIF is implemented as a compiler to Solidity. We show how SCIF can secure contracts with minimal overhead through case studies of applications with intricate security reasoning and a large corpus of insecure code.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.01204v2</guid>
      <category>cs.CR</category>
      <category>cs.PL</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siqiu Yao, Haobin Ni, Stephanie Ma, Noah Schiff, Andrew C. Myers, Ethan Cecchetti</dc:creator>
    </item>
    <item>
      <title>Dead Gate Elimination</title>
      <link>https://arxiv.org/abs/2504.12729</link>
      <description>arXiv:2504.12729v2 Announce Type: replace-cross 
Abstract: Hybrid quantum algorithms combine the strengths of quantum and classical computing. Many quantum algorithms, such as the variational quantum eigensolver (VQE), leverage this synergy. However, quantum circuits are executed in full, even when only subsets of measurement outcomes contribute to subsequent classical computations. In this manuscript, we propose a novel circuit optimization technique that identifies and removes dead gates. We prove that the removal of dead gates has no influence on the probability distribution of the measurement outcomes that contribute to the subsequent calculation result. We implemented and evaluated our optimization on a VQE instance, a quantum phase estimation (QPE) instance, and hybrid programs embedded with random circuits of varying circuit width, confirming its capability to remove a non-trivial number of dead gates in real-world algorithms. The effect of our optimization scales up as more measurement outcomes are identified as non-contributory, resulting in a proportionally greater reduction of dead gates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12729v2</guid>
      <category>quant-ph</category>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Thu, 24 Apr 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yanbin Chen, Christian B. Mendl, Helmut Seidl</dc:creator>
    </item>
  </channel>
</rss>
