<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 17 Oct 2025 04:00:37 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>A Two-Feature Quantitative EEG Index of Pediatric Epilepsy Severity: External Pre-Validation on CHB-MIT and Roadmap to Dravet Cohorts</title>
      <link>https://arxiv.org/abs/2510.13815</link>
      <description>arXiv:2510.13815v1 Announce Type: new 
Abstract: Objective biomarkers for staging pediatric epileptic encephalopathies are scarce. We revisited a large open repository -- the CHB-MIT Scalp EEG Database, 22 subjects aged 1.5-19 y recorded at 256 Hz under the 10-20 montage -- to derive and validate a compact quantitative index, DS-Qi = (theta/alpha)_posterior + (1 - wPLI_beta). The first term captures excess posterior slow-wave power, a recognized marker of impaired cortical maturation; the second employs the debiased weighted Phase-Lag Index to measure loss of beta-band synchrony, robust to volume conduction and small-sample bias. In 30-min awake, eyes-open segments, DS-Qi was 1.69 +/- 0.21 in epilepsy versus 1.23 +/- 0.17 in age-matched normative EEG (Cohen's d = 1.1, p &lt; 0.001). A logistic model trained with 10 x 10-fold cross-validation yielded an AUC of 0.90 (95% CI 0.81-0.97) and optimal sensitivity/specificity of 86%/83% at DS-Qi = 1.46. Across multi-day recordings, test-retest reliability was ICC = 0.74, and higher DS-Qi correlated with greater seizure burden (rho = 0.58, p = 0.004). These results establish DS-Qi as a reproducible, single-number summary of electrophysiological severity that can be computed from short scalp EEG segments using only posterior and standard 10-20 electrodes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13815v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Khartik Uppalapati, Bora Yimenicioglu, Shakeel Abdulkareem, Bhavya Uppalapati, Viraj Kamath, Adan Eftekhari, Pranav Ayyappan</dc:creator>
    </item>
    <item>
      <title>Towards Neurocognitive-Inspired Intelligence: From AI's Structural Mimicry to Human-Like Functional Cognition</title>
      <link>https://arxiv.org/abs/2510.13826</link>
      <description>arXiv:2510.13826v1 Announce Type: new 
Abstract: Artificial intelligence has advanced significantly through deep learning, reinforcement learning, and large language and vision models. However, these systems often remain task specific, struggle to adapt to changing conditions, and cannot generalize in ways similar to human cognition. Additionally, they mainly focus on mimicking brain structures, which often leads to black-box models with limited transparency and adaptability. Inspired by the structure and function of biological cognition, this paper introduces the concept of "Neurocognitive-Inspired Intelligence (NII)," a hybrid approach that combines neuroscience, cognitive science, computer vision, and AI to develop more general, adaptive, and robust intelligent systems capable of rapid learning, learning from less data, and leveraging prior experience. These systems aim to emulate the human brain's ability to flexibly learn, reason, remember, perceive, and act in real-world settings with minimal supervision. We review the limitations of current AI methods, define core principles of neurocognitive-inspired intelligence, and propose a modular, biologically inspired architecture that emphasizes integration, embodiment, and adaptability. We also discuss potential implementation strategies and outline various real-world applications, from robotics to education and healthcare. Importantly, this paper offers a hybrid roadmap for future research, laying the groundwork for building AI systems that more closely resemble human cognition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13826v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noorbakhsh Amiri Golilarz, Hassan S. Al Khatib, Shahram Rahimi</dc:creator>
    </item>
    <item>
      <title>Hybrid Deep Learning Approaches for Classifying Autism from Brain MRI</title>
      <link>https://arxiv.org/abs/2510.13841</link>
      <description>arXiv:2510.13841v1 Announce Type: new 
Abstract: Autism spectrum disorder (ASD) is most often diagnosed using behavioral evaluations, which can vary between clinicians. Brain imaging, combined with machine learning, may help identify more objective patterns linked to ASD. This project used magnetic resonance imaging (MRI) data from the publicly available ABIDE I dataset (n = 1,112) to test two approaches for classifying ASD and control participants. The first was a 3D convolutional neural network (CNN) trained end-to-end. The second was a hybrid approach that used the CNN as a feature extractor and then applied a support vector machine (SVM) classifier. The baseline CNN reached moderate performance (accuracy = 0.66, AUC = 0.70), while the hybrid CNN + SVM achieved higher overall accuracy (0.76) and AUC (0.80). The hybrid model also produced more balanced results between ASD and control groups. Separating feature extraction and classification improved performance and reduced bias between diagnostic groups. These findings suggest that combining deep learning and traditional machine learning methods could enhance the reliability of MRI-based research on ASD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13841v1</guid>
      <category>q-bio.NC</category>
      <category>cs.LG</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ashley Chen</dc:creator>
    </item>
    <item>
      <title>Embodiment in multimodal large language models</title>
      <link>https://arxiv.org/abs/2510.13845</link>
      <description>arXiv:2510.13845v1 Announce Type: new 
Abstract: Multimodal Large Language Models (MLLMs) have demonstrated extraordinary progress in bridging textual and visual inputs. However, MLLMs still face challenges in situated physical and social interactions in sensorally rich, multimodal and real-world settings where the embodied experience of the living organism is essential. We posit that next frontiers for MLLM development require incorporating both internal and external embodiment -- modeling not only external interactions with the world, but also internal states and drives. Here, we describe mechanisms of internal and external embodiment in humans and relate these to current advances in MLLMs in early stages of aligning to human representations. Our dual-embodied framework proposes to model interactions between these forms of embodiment in MLLMs to bridge the gap between multimodal data and world experience.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13845v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Akila Kadambi, Lisa Aziz-Zadeh, Antonio Damasio, Marco Iacoboni, Srini Narayanan</dc:creator>
    </item>
    <item>
      <title>Large Language Model Agents Enable Autonomous Design and Image Analysis of Microwell Microfluidics</title>
      <link>https://arxiv.org/abs/2510.13883</link>
      <description>arXiv:2510.13883v1 Announce Type: new 
Abstract: Microwell microfluidics has been utilized for single-cell analysis to reveal heterogeneity in gene expression, signaling pathways, and phenotypic responses for identifying rare cell types, understanding disease progression, and developing more precise therapeutic strategies. However, designing microwell microfluidics is a considerably complex task, requiring knowledge, experience, and CAD software, as well as manual intervention, which often fails initial designs, demanding multiple costly and time-consuming iterations. In this study, we establish an autonomous large language model (LLM)-driven microwell design framework to generate code-based computer-aided design (CAD) scripts, that enables the rapid and reproducible creation of microwells with diverse geometries and imaging-based analysis. We propose a multimodal large language model (MLLM)-logistic regression framework based on integrating high-level semantic descriptions generated by MLLMs with image embeddings for image classification tasks, aiming to identify microwell occupancy and microwell shape. The fused multimodal representation is input to a logistic regression model, which is both interpretable and computationally efficient. We achieved significant improvements, exceeding 0.92 for occupancy classification and 0.99 for shape classification, across all evaluated MLLMs, compared with 0.50 and 0.55, respectively, when relying solely on direct classification. The MLLM-logistic regression framework is a scalable, efficient solution for high-throughput microwell image analysis. Our study demonstrates an autonomous design microwell platform by translating natural language prompts into optimized device geometries, CAD scripts and image analysis, facilitating the development of next-generation digital discovery by integration of literature mining, autonomous design and experimental data analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13883v1</guid>
      <category>q-bio.NC</category>
      <category>cs.MA</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dinh-Nguyen Nguyen, Sadia Shakil, Raymond Kai-Yu Tong, Ngoc-Duy Dinh</dc:creator>
    </item>
    <item>
      <title>Bayes or Heisenberg: Who(se) Rules?</title>
      <link>https://arxiv.org/abs/2510.13894</link>
      <description>arXiv:2510.13894v1 Announce Type: new 
Abstract: Although quantum systems are generally described by quantum state vectors, we show that in certain cases their measurement processes can be reformulated as probabilistic equations expressed in terms of probabilistic state vectors. These probabilistic representations can, in turn, be approximated by the neural network dynamics of the Tensor Brain (TB) model.
  The Tensor Brain is a recently proposed framework for modeling perception and memory in the brain, providing a biologically inspired mechanism for efficiently integrating generated symbolic representations into reasoning processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.13894v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>quant-ph</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Volker Tresp Hang Li, Federico Harjes, Yunpu Ma</dc:creator>
    </item>
    <item>
      <title>Using Information Geometry to Characterize Higher-Order Interactions in EEG</title>
      <link>https://arxiv.org/abs/2510.14188</link>
      <description>arXiv:2510.14188v1 Announce Type: new 
Abstract: In neuroscience, methods from information geometry (IG) have been successfully applied in the modelling of binary vectors from spike train data, using the orthogonal decomposition of the Kullback-Leibler divergence and mutual information to isolate different orders of interaction between neurons. While spike train data is well-approximated with a binary model, here we apply these IG methods to data from electroencephalography (EEG), a continuous signal requiring appropriate discretization strategies. We developed and compared three different binarization methods and used them to identify third-order interactions in an experiment involving imagined motor movements. The statistical significance of these interactions was assessed using phase-randomized surrogate data that eliminated higher-order dependencies while preserving the spectral characteristics of the original signals. We validated our approach by implementing known second- and third-order dependencies in a forward model and quantified information attenuation at different steps of the analysis. This revealed that the greatest loss in information occurred when going from the idealized binary case to enforcing these dependencies using oscillatory signals. When applied to the real EEG dataset, our analysis detected statistically significant third-order interactions during the task condition despite the relatively sparse data (45 trials per condition). This work demonstrates that IG methods can successfully extract genuine higher-order dependencies from continuous neural recordings when paired with appropriate binarization schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14188v1</guid>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Albers, Paul Marriott, Masami Tatsuno</dc:creator>
    </item>
    <item>
      <title>Sensorimotor Contingencies and The Sensorimotor Approach to Cognition</title>
      <link>https://arxiv.org/abs/2510.14227</link>
      <description>arXiv:2510.14227v1 Announce Type: new 
Abstract: 4E views of cognition seek to replace many of the long-held assumptions of tra- ditional cognitive science. One of the most radical shifts is the rejection of the sandwich model of cognition [8], which holds that mental processes are located be- tween action and perception. Subversion of such a long-held assumption requires an accessible theoretical alternative with firm experimental support. One unifying thread among the emerging 4E camps is their shared insistence that sensorimotor contingencies (SMCs) are such an alternative.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14227v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Denizhan Pak</dc:creator>
    </item>
    <item>
      <title>Joint encoding of "what" and "when" predictions through error-modulated plasticity in reservoir spiking networks</title>
      <link>https://arxiv.org/abs/2510.14382</link>
      <description>arXiv:2510.14382v1 Announce Type: new 
Abstract: The brain understands the external world through an internal model that generates predictions and refines them based on prediction errors. A complete prediction specifies what will happen, when it will happen, and with what probability, which we refer to as a "prediction object". Existing models typically capture only what and when, omit probabilities, and rely on biologically-implausible algorithms. Here we show that a single population of spiking neurons can jointly encode the prediction object through a biologically grounded learning mechanism. We implement a heterogeneous Izhikevich spiking reservoir with readouts trained by an error-modulated, attention-gated three-factor Hebbian rule and test it on a novel paradigm that controls both the timing and probability of upcoming stimuli. By integrating real-time learning of "when" with offline consolidation of "what", the model encodes the complete prediction object, firing at the correct times with magnitudes proportional to the probabilities. Critically, it rapidly adapts to changes in both stimulus timing and probability, an ability that global least-squares methods such as FORCE lack without explicit resets. During learning, the model self-organizes its readout weights into near-orthogonal subspaces for "what" and "when," showing that multiplexed encoding arises naturally from generic recurrent dynamics under local, error-gated modulation. These results challenge the view that "what" and "when" predictions require separate modules, suggesting instead that mixed selectivity within shared populations supports flexible predictive cognition. The model also predicts phase-specific neuromodulation and overlapping neural subspaces, offering a parsimonious alternative to hierarchical predictive-coding accounts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14382v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yohei Yamada, Zenas C. Chao</dc:creator>
    </item>
    <item>
      <title>Semantic representations emerge in biologically inspired ensembles of cross-supervising neural networks</title>
      <link>https://arxiv.org/abs/2510.14486</link>
      <description>arXiv:2510.14486v1 Announce Type: new 
Abstract: Brains learn to represent information from a large set of stimuli, typically by weak supervision. Unsupervised learning is therefore a natural approach for exploring the design of biological neural networks and their computations. Accordingly, redundancy reduction has been suggested as a prominent design principle of neural encoding, but its ``mechanistic'' biological implementation is unclear. Analogously, unsupervised training of artificial neural networks yields internal representations that allow for accurate stimulus classification or decoding, but typically rely on biologically-implausible implementations. We suggest that interactions between parallel subnetworks in the brain may underlie such learning: we present a model of representation learning by ensembles of neural networks, where each network learns to encode stimuli into an abstract representation space by cross-supervising interactions with other networks, for inputs they receive simultaneously or in close temporal proximity. Aiming for biological plausibility, each network has a small ``receptive field'', thus receiving a fixed part of the external input, and the networks do not share weights. We find that for different types of network architectures, and for both visual or neuronal stimuli, these cross-supervising networks learn semantic representations that are easily decodable and that decoding accuracy is comparable to supervised networks -- both at the level of single networks and the ensemble. We further show that performance is optimal for small receptive fields, and that sparse connectivity between networks is nearly as accurate as all-to-all interactions, with far fewer computations. We thus suggest a sparsely interacting collective of cross-supervising networks as an algorithmic framework for representational learning and collective computation in the brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14486v1</guid>
      <category>q-bio.NC</category>
      <category>cs.AI</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Roy Urbach, Elad Schneidman</dc:creator>
    </item>
    <item>
      <title>Nonlinear shift along the sensorimotor-association-axis in brain responses to task performance</title>
      <link>https://arxiv.org/abs/2510.14601</link>
      <description>arXiv:2510.14601v1 Announce Type: new 
Abstract: In the literature of cognitive neuroscience, researchers tend to assume a linear relationship between brain activation level and task performance; however, controversial findings have been reported in participants at different ages and different proficiency levels. Therefore, there may be a non-linear relationship between task performance and brain activation if a full range of task performance is considered. In the current study, using the Human Connectome Project (HCP) dataset we examined the relationship between brain activation and working memory performance in two conditions (i.e. faces and places). We found a gradual change from a U-shaped relationship to an inverted U-shaped relationship along the sensorimotor-association (S-A) axis in the face condition. In other words, in low-order sensorimotor areas, it is U-shaped and in the high-order prefrontal and association areas, it is inverted U-shaped, which suggests different properties in the encoding/representation region and in the cognitive calculation regions. However, in the place condition, such a shift is missing, presumably because most of the regions that are sensitive to task performance in the place condition are in the lower end of the S-A axis. Taken together, our study revealed a novel difference of functional property in response to task performance in the sensorimotor areas versus the association areas.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.14601v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Fan Cao, Yuqi Yuan, Xiaohui Yan, Bohan Zhang, Kyle Perkins</dc:creator>
    </item>
    <item>
      <title>Nonequilibrium physics of brain dynamics</title>
      <link>https://arxiv.org/abs/2504.12188</link>
      <description>arXiv:2504.12188v2 Announce Type: replace 
Abstract: Information processing in the brain is coordinated by the dynamic activity of neurons and neural populations at a range of spatiotemporal scales. These dynamics, captured in the form of electrophysiological recordings and neuroimaging, show evidence of time-irreversibility and broken detailed balance suggesting that the brain operates in a nonequilibrium stationary state. Furthermore, the level of nonequilibrium, measured by entropy production or irreversibility appears to be a crucial signature of cognitive complexity and consciousness. The subsequent study of neural dynamics from the perspective of nonequilibrium statistical physics is an emergent field that challenges the assumptions of symmetry and maximum-entropy that are common in traditional models. In this review, we discuss the plethora of exciting results emerging at the interface of nonequilibrium dynamics and neuroscience. We begin with an introduction to the mathematical paradigms necessary to understand nonequilibrium dynamics in both continuous and discrete state-spaces. Next, we review both model-free and model-based approaches to analysing nonequilibrium dynamics in both continuous-state recordings and neural spike-trains, as well as the results of such analyses. We briefly consider the topic of nonequilibrium computation in neural systems, before concluding with a discussion and outlook on the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.12188v2</guid>
      <category>q-bio.NC</category>
      <category>cond-mat.dis-nn</category>
      <category>cond-mat.stat-mech</category>
      <category>math.DS</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ram\'on Nartallo-Kaluarachchi, Morten L. Kringelbach, Gustavo Deco, Renaud Lambiotte, Alain Goriely</dc:creator>
    </item>
    <item>
      <title>The cognitive triple-slit experiment</title>
      <link>https://arxiv.org/abs/2505.05497</link>
      <description>arXiv:2505.05497v3 Announce Type: replace 
Abstract: Quantum cognition has made it possible to model human cognitive processes very effectively, revealing numerous parallels between the properties of conceptual entities tested by the human mind and those of microscopic entities tested by measurement apparatuses. The success of quantum cognition has also made it possible to formulate an interpretation of quantum mechanics, called the conceptuality interpretation, which ascribes to quantum entities a conceptual nature similar to that of human concepts. The present work fits into these lines of research by analyzing a cognitive version of single, double, and triple-slit experiments. The data clearly show the formation of the typical interference fringes between the slits as well as the embryos of secondary fringes. Our analysis also shows that while quantum entities and human concepts may share a same conceptual nature, the way they manifest it in specific contexts can be quite different. This is also evident from the significant deviation from zero observed for the Sorkin parameter, indicating the presence of strong irreducible third-order interference contributions in human decision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.05497v3</guid>
      <category>q-bio.NC</category>
      <category>quant-ph</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Luca Sassoli de Bianchi, Massimiliano Sassoli de Bianchi</dc:creator>
    </item>
    <item>
      <title>Personalized Detection of Stress via hdrEEG: Linking Neuro-markers to Cortisol, HRV, and Self-Report</title>
      <link>https://arxiv.org/abs/2509.13875</link>
      <description>arXiv:2509.13875v3 Announce Type: replace 
Abstract: Chronic stress is a risk factor for cognitive decline and illness, yet reliable individual markers remain limited. We tested whether two single channel high dynamic range EEG biomarkers, ST4 and T2, index stress responses by linking neural activity to validated physiological and subjective measures.
  Study 1 included 101 adults between 22 and 82 years of age who completed questionnaires on stress, resilience, and burnout, provided salivary cortisol, and performed resting, cognitive load, emotional, and startle conditions. Study 2 included 82 adults between 19 and 42 years who completed the State Trait Anxiety Inventory, underwent heart rate variability monitoring, and performed auditory, stress inducing, and emotional conditions. Correlations were considered meaningful when r was at least 0.30. Results showed that ST4 reflected physiological arousal and cognitive strain. In Study 1, resting ST4 was positively related to cortisol and lower in more resilient participants. In Study 2, ST4 correlated negatively with heart rate variability during stress and recovery. T2 reflected emotional and autonomic regulation. In Study 1, T2 tracked higher cortisol and was lower with greater resilience. In Study 2, T2 was higher with trait anxiety and correlated negatively with heart rate variability during stress and emotional conditions. Together, ST4 and T2 provide complementary portable markers of stress, supporting individualized assessment in clinical and real world contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13875v3</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>N. B. Maimon, Ganit Baruchin, Itamar Grotto, Lior Molcho, Nathan Intrator, Talya Zeimer, Ofir Chibotero, Nardeen Murad, Yori Gidron, Efrat Danino</dc:creator>
    </item>
    <item>
      <title>The Principle of Isomorphism: A Theory of Population Activity in Grid Cells and Beyond</title>
      <link>https://arxiv.org/abs/2510.02853</link>
      <description>arXiv:2510.02853v2 Announce Type: replace 
Abstract: Identifying the principles that determine neural population activity is paramount in the field of neuroscience. We propose the Principle of Isomorphism (PIso): population activity preserves the essential mathematical structures of the tasks it supports. Using grid cells as a model system, we show that the neural metric task is characterized by a flat Riemannian manifold, while path integration is characterized by an Abelian Lie group. We prove that each task independently constrains population activity to a toroidal topology. We further show that these perspectives are unified naturally in Euclidean space, where commutativity and flatness are intrinsically compatible and can be extended to related systems including head-direction cells and 3D grid cells. To examine how toroidal topology maps onto single-cell firing patterns, we develop a minimal network architecture that explicitly constrains population activity to toroidal manifolds. Our model robustly generates hexagonal firing fields and reveals systematic relationships between network parameters and grid spacings. Crucially, we demonstrate that conformal isometry, a commonly proposed hypothesis, alone is insufficient for hexagonal field formation. Our findings establish a direct link between computational tasks and the hexagonal-toroidal organization of grid cells, thereby providing a general framework for understanding population activity in neural systems and designing task-informed architectures in machine learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02853v2</guid>
      <category>q-bio.NC</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maoshen Xu, Fei Song, Yuxiu Shao, Bailu Si, Shanshan Qin</dc:creator>
    </item>
    <item>
      <title>MAPS: Masked Attribution-based Probing of Strategies- A computational framework to align human and model explanations</title>
      <link>https://arxiv.org/abs/2510.12141</link>
      <description>arXiv:2510.12141v2 Announce Type: replace 
Abstract: Human core object recognition depends on the selective use of visual information, but the strategies guiding these choices are difficult to measure directly. We present MAPS (Masked Attribution-based Probing of Strategies), a behaviorally validated computational tool that tests whether explanations derived from artificial neural networks (ANNs) can also explain human vision. MAPS converts attribution maps into explanation-masked images (EMIs) and compares image-by-image human accuracies on these minimal images with limited pixel budgets with accuracies on the full stimuli. MAPS provides a principled way to evaluate and choose among competing ANN interpretability methods. In silico, EMI-based behavioral similarity between models reliably recovers the ground-truth similarity computed from their attribution maps, establishing which explanation methods best capture the model's strategy. When applied to humans and macaques, MAPS identifies ANN-explanation combinations whose explanations align most closely with biological vision, achieving the behavioral validity of Bubble masks while requiring far fewer behavioral trials. Because it needs only access to model attributions and a modest set of behavioral data on the original images, MAPS avoids exhaustive psychophysics while offering a scalable tool for adjudicating explanations and linking human behavior, neural activity, and model decisions under a common standard.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.12141v2</guid>
      <category>q-bio.NC</category>
      <category>cs.CV</category>
      <pubDate>Fri, 17 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sabine Muzellec, Yousif Kashef Alghetaa, Simon Kornblith, Kohitij Kar</dc:creator>
    </item>
  </channel>
</rss>
