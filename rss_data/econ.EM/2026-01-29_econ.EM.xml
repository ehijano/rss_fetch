<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 29 Jan 2026 05:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>United in Currency, Divided in Growth: Dynamic Effects of Euro Adoption</title>
      <link>https://arxiv.org/abs/2601.20169</link>
      <description>arXiv:2601.20169v1 Announce Type: new 
Abstract: Does euro adoption affect long-run economic growth? Existing evidence is mixed, reflecting limited treated countries, long horizons that challenge inference, and heterogeneity across member states. We estimate causal dynamic and heterogeneous treatment effects using Causal Forests with Fixed Effects (CFFE), a machine-learning approach that combines causal forests with two-way fixed effects. Under a conditional parallel-trends assumption, we find that euro adoption reduced annual GDP growth by 0.3-0.4 percentage points on average. Effects emerge shortly after adoption and stabilize after roughly a decade.
  Average effects mask substantial heterogeneity. Countries with lower initial GDP per capita experience larger and more persistent growth shortfalls than core economies. Weaker consumption and productivity growth contribute to the overall effect, while improvements in net exports partially offset these declines.
  A two-country New Keynesian DSGE model with hysteresis generates qualitatively similar patterns: one-size-fits-all monetary policy and scarring mechanisms produce larger output losses under monetary union than under flexible exchange rates. By jointly estimating dynamic and heterogeneous treatment effects, the analysis highlights the importance of country characteristics in assessing the long-run consequences of monetary union.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20169v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Harry Aytug</dc:creator>
    </item>
    <item>
      <title>Realized range-based estimation of integrated variance</title>
      <link>https://arxiv.org/abs/2601.20463</link>
      <description>arXiv:2601.20463v1 Announce Type: new 
Abstract: We provide a set of probabilistic laws for estimating the quadratic variation of continuous semimartingales with realized range-based variance -- a statistic that replaces every squared return of realized variance with a normalized squared range. If the entire sample path of the process is available, and under a set of weak conditions, our statistic is consistent and has a mixed Gaussian limit, whose precision is five times greater than that of realized variance. In practice, of course, inference is drawn from discrete data and true ranges are unobserved, leading to downward bias. We solve this problem to get a consistent, mixed normal estimator, irrespective of non-trading effects. This estimator has varying degrees of efficiency over realized variance, depending on how many observations that are used to construct the high-low. The methodology is applied to TAQ data and compared with realized variance. Our findings suggest that the empirical path of quadratic variation is also estimated better with the realized range-based variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20463v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jeconom.2006.06.012</arxiv:DOI>
      <dc:creator>Kim Christensen, Mark Podolskij</dc:creator>
    </item>
    <item>
      <title>The realized empirical distribution function of stochastic variance with application to goodness-of-fit testing</title>
      <link>https://arxiv.org/abs/2601.20469</link>
      <description>arXiv:2601.20469v1 Announce Type: new 
Abstract: We propose a nonparametric estimator of the empirical distribution function (EDF) of the latent spot variance of the log-price of a financial asset. We show that over a fixed time span our realized EDF (or REDF) -- inferred from noisy high-frequency data -- is consistent as the mesh of the observation grid goes to zero. In a double-asymptotic framework, with time also increasing to infinity, the REDF converges to the cumulative distribution function of volatility, if it exists. We exploit these results to construct some new goodness-of-fit tests for stochastic volatility models. In a Monte Carlo study, the REDF is found to be accurate over the entire support of volatility. This leads to goodness-of-fit tests that are both correctly sized and relatively powerful against common alternatives. In an empirical application, we recover the REDF from stock market high-frequency data. We inspect the goodness-of-fit of several two-parameter marginal distributions that are inherent in standard stochastic volatility models. The inverse Gaussian offers the best overall description of random equity variation, but the fit is less than perfect. This suggests an extra parameter (as available in, e.g., the generalized inverse Gaussian) is required to model stochastic variance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20469v1</guid>
      <category>econ.EM</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1016/j.jeconom.2019.06.002</arxiv:DOI>
      <dc:creator>Kim Christensen, Martin Thyrsgaard, Bezirgen Veliyev</dc:creator>
    </item>
    <item>
      <title>Decoupling and randomization for double-indexed permutation statistics</title>
      <link>https://arxiv.org/abs/2601.20018</link>
      <description>arXiv:2601.20018v1 Announce Type: cross 
Abstract: This paper introduces a version of decoupling and randomization to establish concentration inequalities for double-indexed permutation statistics. The results yield, among other applications, a new combinatorial Hanson-Wright inequality and a new combinatorial Bennett inequality. Several illustrative examples from rank-based statistics, graph-based statistics, and causal inference are also provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20018v1</guid>
      <category>math.ST</category>
      <category>econ.EM</category>
      <category>math.PR</category>
      <category>stat.TH</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mingxuan Zou, Jingfan Xu, Peng Ding, Fang Han</dc:creator>
    </item>
    <item>
      <title>Bias-Reduced Estimation of Finite Mixtures: An Application to Latent Group Structures in Panel Data</title>
      <link>https://arxiv.org/abs/2601.20197</link>
      <description>arXiv:2601.20197v1 Announce Type: cross 
Abstract: Finite mixture models are widely used in econometric analyses to capture unobserved heterogeneity. This paper shows that maximum likelihood estimation of finite mixtures of parametric densities can suffer from substantial finite-sample bias in all parameters under mild regularity conditions. The bias arises from the influence of outliers in component densities with unbounded or large support and increases with the degree of overlap among mixture components. I show that maximizing the classification-mixture likelihood function, equipped with a consistent classifier, yields parameter estimates that are less biased than those obtained by standard maximum likelihood estimation (MLE). I then derive the asymptotic distribution of the resulting estimator and provide conditions under which oracle efficiency is achieved. Monte Carlo simulations show that conventional mixture MLE exhibits pronounced finite-sample bias, which diminishes as the sample size or the statistical distance between component densities tends to infinity. The simulations further show that the proposed estimation strategy generally outperforms standard MLE in finite samples in terms of both bias and mean squared errors under relatively weak assumptions. An empirical application to latent group panel structures using health administrative data shows that the proposed approach reduces out-of-sample prediction error by approximately 17.6% relative to the best results obtained from standard MLE procedures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.20197v1</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.CO</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Langevin</dc:creator>
    </item>
    <item>
      <title>Inflation Target at Risk: A Time-varying Parameter Distributional Regression</title>
      <link>https://arxiv.org/abs/2403.12456</link>
      <description>arXiv:2403.12456v3 Announce Type: replace 
Abstract: Inflation exhibits state-dependent, skewed, and fat-tailed dynamics that make risk a central concern for monetary policy. Accordingly, inflation risks are distributional and cannot be fully captured by mean-based models. We propose a flexible time-varying parameter distributional regression model that estimates the full conditional distribution of inflation, allowing macroeconomic drivers to have nonlinear and asymmetric effects across the distribution. Applied to U.S. inflation, the model captures major shifts in tail-risk probabilities. Analysis of risk drivers shows that deflationary pressures arise primarily from demand-side weakness and inflation persistence, whereas upside risks are driven mainly by supply-side shocks, particularly energy price inflation. Examining the impact of key drivers further reveals that the unemployment-inflation relationship weakens in the distributional tails. Energy price shocks, by contrast, have little effect on deflation risk but exhibit strongly time-varying and asymmetric effects on high-inflation risk.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12456v3</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yunyun Wang, Tatsushi Oka, Dan Zhu</dc:creator>
    </item>
    <item>
      <title>Can AI Master Econometrics? Evidence from Econometrics AI Agent on Expert-Level Tasks</title>
      <link>https://arxiv.org/abs/2506.00856</link>
      <description>arXiv:2506.00856v3 Announce Type: replace 
Abstract: Can AI effectively perform complex econometric analysis traditionally requiring human expertise? This paper evaluates AI agents' capability to master econometrics, focusing on empirical analysis performance. We develop ``MetricsAI'', an Econometrics AI Agent built on the open-source MetaGPT framework. This agent exhibits outstanding performance in: (1) planning econometric tasks strategically, (2) generating and executing code, (3) employing error-based reflection for improved robustness, and (4) allowing iterative refinement through multi-round conversations. We construct two datasets from academic coursework materials and published research papers to evaluate performance against real-world challenges. Comparative testing shows our domain-specialized AI agent significantly outperforms both benchmark large language models (LLMs) and general-purpose AI agents. This work establishes a testbed for exploring AI's impact on social science research and enables cost-effective integration of domain expertise, making advanced econometric methods accessible to users with minimal coding skills. Furthermore, our AI agent enhances research reproducibility and offers promising pedagogical applications for econometrics teaching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00856v3</guid>
      <category>econ.EM</category>
      <category>cs.AI</category>
      <pubDate>Thu, 29 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiang Chen, Tianyang Han, Jin Li, Ye Luo, Zigan Wang, Yuxiao Wu, Xiaowei Zhang, Tuo Zhou</dc:creator>
    </item>
  </channel>
</rss>
