<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.TH</link>
    <description>stat.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 20 Mar 2024 04:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 20 Mar 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Semidefinite programming on population clustering: a local analysis</title>
      <link>https://arxiv.org/abs/2403.12048</link>
      <description>arXiv:2403.12048v1 Announce Type: new 
Abstract: In this paper, we consider the problem of partitioning a small data sample of size $n$ drawn from a mixture of $2$ sub-gaussian distributions. In particular, we design and analyze two computational efficient algorithms to partition data into two groups approximately according to their population of origin given a small sample in a recent paper (Zhou 2023a). Our work is motivated by the application of clustering individuals according to their population of origin using markers, when the divergence between any two of the populations is small. Moreover, we are interested in the case that individual features are of low average quality $\gamma$, and we want to use as few of them as possible to correctly partition the sample. Here we use $p \gamma$ to denote the $\ell_2^2$ distance between two population centers (mean vectors), namely, $\mu^{(1)}$, $\mu^{(2)}$ $\in$ ${\mathbb R}^p$. We allow a full range of tradeoffs between $n, p, \gamma$ in the sense that partial recovery (success rate $&lt; 100\%$) is feasible once the signal to noise ratio $s^2 := \min\{np \gamma^2, p \gamma\}$ is lower bounded by a constant. Our work builds upon the semidefinite relaxation of an integer quadratic program that is formulated essentially as finding the maximum cut on a graph, where edge weights in the cut represent dissimilarity scores between two nodes based on their $p$ features in Zhou (2023a). More importantly, we prove that the misclassification error decays exponentially with respect to the SNR $s^2$ in the present paper. The significance of such an exponentially decaying error bound is: when $s^2 =\Omega(\log n)$, perfect recovery of the cluster structure is accomplished. This result was introduced in Zhou (2023a) without a proof. We therefore present the full proof in the present work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12048v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shuheng Zhou</dc:creator>
    </item>
    <item>
      <title>Robust estimations from distribution structures: I. Mean</title>
      <link>https://arxiv.org/abs/2403.12110</link>
      <description>arXiv:2403.12110v1 Announce Type: new 
Abstract: As the most fundamental problem in statistics, robust location estimation has many prominent solutions, such as the trimmed mean, Winsorized mean, Hodges Lehmann estimator, Huber M estimator, and median of means. Recent studies suggest that their maximum biases concerning the mean can be quite different, but the underlying mechanisms largely remain unclear. This study exploited a semiparametric method to classify distributions by the asymptotic orderliness of quantile combinations with varying breakdown points, showing their interrelations and connections to parametric distributions. Further deductions explain why the Winsorized mean typically has smaller biases compared to the trimmed mean; two sequences of semiparametric robust mean estimators emerge, particularly highlighting the superiority of the median Hodges Lehmann mean. This article sheds light on the understanding of the common nature of probability distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12110v1</guid>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.OT</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tuobang Li</dc:creator>
    </item>
    <item>
      <title>The Wreaths of KHAN: Uniform Graph Feature Selection with False Discovery Rate Control</title>
      <link>https://arxiv.org/abs/2403.12284</link>
      <description>arXiv:2403.12284v1 Announce Type: new 
Abstract: Graphical models find numerous applications in biology, chemistry, sociology, neuroscience, etc. While substantial progress has been made in graph estimation, it remains largely unexplored how to select significant graph signals with uncertainty assessment, especially those graph features related to topological structures including cycles (i.e., wreaths), cliques, hubs, etc. These features play a vital role in protein substructure analysis, drug molecular design, and brain network connectivity analysis. To fill the gap, we propose a novel inferential framework for general high dimensional graphical models to select graph features with false discovery rate controlled. Our method is based on the maximum of $p$-values from single edges that comprise the topological feature of interest, thus is able to detect weak signals. Moreover, we introduce the $K$-dimensional persistent Homology Adaptive selectioN (KHAN) algorithm to select all the homological features within $K$ dimensions with the uniform control of the false discovery rate over continuous filtration levels. The KHAN method applies a novel discrete Gram-Schmidt algorithm to select statistically significant generators from the homology group. We apply the structural screening method to identify the important residues of the SARS-CoV-2 spike protein during the binding process to the ACE2 receptors. We score the residues for all domains in the spike protein by the $p$-value weighted filtration level in the network persistent homology for the closed, partially open, and open states and identify the residues crucial for protein conformational changes and thus being potential targets for inhibition.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12284v1</guid>
      <category>math.ST</category>
      <category>q-bio.QM</category>
      <category>stat.AP</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiajun Liang, Yue Liu, Doudou Zhou, Sinian Zhang, Junwei Lu</dc:creator>
    </item>
    <item>
      <title>Selecting informative conformal prediction sets with false coverage rate control</title>
      <link>https://arxiv.org/abs/2403.12295</link>
      <description>arXiv:2403.12295v1 Announce Type: new 
Abstract: In supervised learning, including regression and classification, conformal methods provide prediction sets for the outcome/label with finite sample coverage for any machine learning predictors. We consider here the case where such prediction sets come after a selection process. The selection process requires that the selected prediction sets be `informative' in a well defined sense. We consider both the classification and regression settings where the analyst may consider as informative only the sample with prediction label sets or prediction intervals small enough, excluding null values, or obeying other appropriate `monotone' constraints. While this covers many settings of possible interest in various applications, we develop a unified framework for building such informative conformal prediction sets while controlling the false coverage rate (FCR) on the selected sample. While conformal prediction sets after selection have been the focus of much recent literature in the field, the new introduced procedures, called InfoSP and InfoSCOP, are to our knowledge the first ones providing FCR control for informative prediction sets. We show the usefulness of our resulting procedures on real and simulated data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12295v1</guid>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ulysse Gazin, Ruth Heller, Ariane Marandon, Etienne Roquain</dc:creator>
    </item>
    <item>
      <title>A consistent test of spherical symmetry for multivariate and high-dimensional data via data augmentation</title>
      <link>https://arxiv.org/abs/2403.12491</link>
      <description>arXiv:2403.12491v1 Announce Type: new 
Abstract: We develop a test for spherical symmetry of a multivariate distribution $P$ that works even when the dimension of the data $d$ is larger than the sample size $n$. We propose a non-negative measure $\zeta(P)$ such that $\zeta(P)=0$ if and only if $P$ is spherically symmetric. We construct a consistent estimator of $\zeta(P)$ using the data augmentation method and investigate its large sample properties. The proposed test based on this estimator is calibrated using a novel resampling algorithm. Our test controls the Type-I error, and it is consistent against general alternatives. We also study its behaviour for a sequence of alternatives $(1-\delta_n) F+\delta_n G$, where $\zeta(G)=0$ but $\zeta(F)&gt;0$, and $\delta_n \in [0,1]$. When $\lim\sup\delta_n&lt;1$, for any $G$, the power of our test converges to unity as $n$ increases. However, if $\lim\sup\delta_n=1$, the asymptotic power of our test depends on $\lim n(1-\delta_n)^2$. We establish this by proving the minimax rate optimality of our test over a suitable class of alternatives and showing that it is Pitman efficient when $\lim n(1-\delta_n)^2&gt;0$. Moreover, our test is provably consistent for high-dimensional data even when $d$ is larger than $n$. Our numerical results amply demonstrate the superiority of the proposed test over some state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12491v1</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bilol Banerjee, Anil K. Ghosh</dc:creator>
    </item>
    <item>
      <title>Asymptotic Error Rates for Point Process Classification</title>
      <link>https://arxiv.org/abs/2403.12531</link>
      <description>arXiv:2403.12531v1 Announce Type: new 
Abstract: Point processes are finding growing applications in numerous fields, such as neuroscience, high frequency finance and social media. So classic problems of classification and clustering are of increasing interest. However, analytic study of misclassification error probability in multi-class classification has barely begun. In this paper, we tackle the multi-class likelihood classification problem for point processes and develop, for the first time, both asymptotic upper and lower bounds on the error rate in terms of computable pair-wise affinities. We apply these general results to classifying renewal processes. Under some technical conditions, we show that the bounds have exponential decay and give explicit associated constants. The results are illustrated with a non-trivial simulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12531v1</guid>
      <category>math.ST</category>
      <category>eess.SP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Xinhui Rong, Victor Solo</dc:creator>
    </item>
    <item>
      <title>Tree-based conditional copula estimation</title>
      <link>https://arxiv.org/abs/2403.12565</link>
      <description>arXiv:2403.12565v1 Announce Type: new 
Abstract: This paper proposes a regression tree procedure to estimate conditional copulas. The associated algorithm determines classes of observations based on covariate values and fits a simple parametric copula model on each class. The association parameter changes from one class to another, allowing for non-linearity in the dependence structure modeling. It also allows the definition of classes of observations on which the so-called "simplifying assumption" [see Derumigny and Fermanian, 2017] holds reasonably well. When considering observations belonging to a given class separately, the association parameter no longer depends on the covariates according to our model. In this paper, we derive asymptotic consistency results for the regression tree procedure and show that the proposed pruning methodology, that is the model selection techniques selecting the appropriate number of classes, is optimal in some sense. Simulations provide finite sample results and an analysis of data of cases of human influenza presents the practical behavior of the procedure.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12565v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Francesco Bonacina, Olivier Lopez, Maud Thomas</dc:creator>
    </item>
    <item>
      <title>On high-dimensional classification by sparse generalized Bayesian logistic regression</title>
      <link>https://arxiv.org/abs/2403.12832</link>
      <description>arXiv:2403.12832v1 Announce Type: new 
Abstract: This work addresses the problem of high-dimensional classification by exploring the generalized Bayesian logistic regression method under a sparsity-inducing prior distribution. The method involves utilizing a fractional power of the likelihood resulting the fractional posterior. Our study yields concentration results for the fractional posterior, not only on the joint distribution of the predictor and response variable but also for the regression coefficients. Significantly, we derive novel findings concerning misclassification excess risk bounds using sparse generalized Bayesian logistic regression. These results parallel recent findings for penalized methods in the frequentist literature. Furthermore, we extend our results to the scenario of model misspecification, which is of critical importance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12832v1</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>The Tien Mai</dc:creator>
    </item>
    <item>
      <title>Variational Approach for Efficient KL Divergence Estimation in Dirichlet Mixture Models</title>
      <link>https://arxiv.org/abs/2403.12158</link>
      <description>arXiv:2403.12158v1 Announce Type: cross 
Abstract: This study tackles the efficient estimation of Kullback-Leibler (KL) Divergence in Dirichlet Mixture Models (DMM), crucial for clustering compositional data. Despite the significance of DMMs, obtaining an analytically tractable solution for KL Divergence has proven elusive. Past approaches relied on computationally demanding Monte Carlo methods, motivating our introduction of a novel variational approach. Our method offers a closed-form solution, significantly enhancing computational efficiency for swift model comparisons and robust estimation evaluations. Validation using real and simulated data showcases its superior efficiency and accuracy over traditional Monte Carlo-based methods, opening new avenues for rapid exploration of diverse DMM models and advancing statistical analyses of compositional data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12158v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samyajoy Pal, Christian Heumann</dc:creator>
    </item>
    <item>
      <title>Approximation of RKHS Functionals by Neural Networks</title>
      <link>https://arxiv.org/abs/2403.12187</link>
      <description>arXiv:2403.12187v1 Announce Type: cross 
Abstract: Motivated by the abundance of functional data such as time series and images, there has been a growing interest in integrating such data into neural networks and learning maps from function spaces to R (i.e., functionals). In this paper, we study the approximation of functionals on reproducing kernel Hilbert spaces (RKHS's) using neural networks. We establish the universality of the approximation of functionals on the RKHS's. Specifically, we derive explicit error bounds for those induced by inverse multiquadric, Gaussian, and Sobolev kernels. Moreover, we apply our findings to functional regression, proving that neural networks can accurately approximate the regression maps in generalized functional linear models. Existing works on functional learning require integration-type basis function expansions with a set of pre-specified basis functions. By leveraging the interpolating orthogonal projections in RKHS's, our proposed network is much simpler in that we use point evaluations to replace basis function expansions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12187v1</guid>
      <category>stat.ML</category>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tian-Yi Zhou, Namjoon Suh, Guang Cheng, Xiaoming Huo</dc:creator>
    </item>
    <item>
      <title>Parameter estimation and singularity of laws on the path space for SDEs driven by Rosenblatt processes</title>
      <link>https://arxiv.org/abs/2403.12610</link>
      <description>arXiv:2403.12610v1 Announce Type: cross 
Abstract: In this paper, we study parameter identification for solutions to (possibly non-linear) SDEs driven by additive Rosenblatt process and singularity of the induced laws on the path space. We propose a joint estimator for the drift parameter, diffusion intensity, and Hurst index that can be computed from discrete-time observations with a bounded time horizon and we prove its strong consistency (as well as the speed of convergence) under in-fill asymptotics with a fixed time horizon. As a consequence of this strong consistency, singularity of measures generated by the solutions with different drifts is shown. This results in the invalidity of a Girsanov-type theorem for Rosenblatt processes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12610v1</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Petr \v{C}oupek, Pavel K\v{r}\'i\v{z}, Bohdan Maslowski</dc:creator>
    </item>
    <item>
      <title>Tests for categorical data beyond Pearson: A distance covariance and energy distance approach</title>
      <link>https://arxiv.org/abs/2403.12711</link>
      <description>arXiv:2403.12711v1 Announce Type: cross 
Abstract: Categorical variables are of uttermost importance in biomedical research. When two of them are considered, it is often the case that one wants to test whether or not they are statistically dependent. We show weaknesses of classical methods -- such as Pearson's and the G-test -- and we propose testing strategies based on distances that lack those drawbacks. We first develop this theory for classical two-dimensional contingency tables, within the context of distance covariance, an association measure that characterises general statistical independence of two variables. We then apply the same fundamental ideas to one-dimensional tables, namely to the testing for goodness of fit to a discrete distribution, for which we resort to an analogous statistic called energy distance. We prove that our methodology has desirable theoretical properties, and we show how we can calibrate the null distribution of our test statistics without resorting to any resampling technique. We illustrate all this in simulations, as well as with some real data examples, demonstrating the adequate performance of our approach for biostatistical practice.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12711v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.AP</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Fernando Castro-Prado, Wenceslao Gonz\'alez-Manteiga, Javier Costas, Fernando Facal, Dominic Edelmann</dc:creator>
    </item>
    <item>
      <title>On Equivalence of Likelihood-Based Confidence Bands for Fatigue-Life and Fatigue-Strength Distributions</title>
      <link>https://arxiv.org/abs/2403.12757</link>
      <description>arXiv:2403.12757v1 Announce Type: cross 
Abstract: Fatigue data arise in many research and applied areas and there have been statistical methods developed to model and analyze such data. The distributions of fatigue life and fatigue strength are often of interest to engineers designing products that might fail due to fatigue from cyclic-stress loading. Based on a specified statistical model and the maximum likelihood method, the cumulative distribution function (cdf) and quantile function (qf) can be estimated for the fatigue-life and fatigue-strength distributions. Likelihood-based confidence bands then can be obtained for the cdf and qf. This paper provides equivalence results for confidence bands for fatigue-life and fatigue-strength models. These results are useful for data analysis and computing implementation. We show (a) the equivalence of the confidence bands for the fatigue-life cdf and the fatigue-life qf, (b) the equivalence of confidence bands for the fatigue-strength cdf and the fatigue-strength qf, and (c) the equivalence of confidence bands for the fatigue-life qf and the fatigue-strength qf. Then we illustrate the usefulness of those equivalence results with two examples using experimental fatigue data.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12757v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peng Liu, Yili Hong, Luis A. Escobar, William Q. Meeker</dc:creator>
    </item>
    <item>
      <title>A Unified Framework for Rerandomization using Quadratic Forms</title>
      <link>https://arxiv.org/abs/2403.12815</link>
      <description>arXiv:2403.12815v1 Announce Type: cross 
Abstract: In the design stage of a randomized experiment, one way to ensure treatment and control groups exhibit similar covariate distributions is to randomize treatment until some prespecified level of covariate balance is satisfied. This experimental design strategy is known as rerandomization. Most rerandomization methods utilize balance metrics based on a quadratic form $v^TAv$ , where $v$ is a vector of covariate mean differences and $A$ is a positive semi-definite matrix. In this work, we derive general results for treatment-versus-control rerandomization schemes that employ quadratic forms for covariate balance. In addition to allowing researchers to quickly derive properties of rerandomization schemes not previously considered, our theoretical results provide guidance on how to choose the matrix $A$ in practice. We find the Mahalanobis and Euclidean distances optimize different measures of covariate balance. Furthermore, we establish how the covariates' eigenstructure and their relationship to the outcomes dictates which matrix $A$ yields the most precise mean-difference estimator for the average treatment effect. We find that the Euclidean distance is minimax optimal, in the sense that the mean-difference estimator's precision is never too far from the optimal choice, regardless of the relationship between covariates and outcomes. Our theoretical results are verified via simulation, where we find that rerandomization using the Euclidean distance has better performance in high-dimensional settings and typically achieves greater variance reduction to the mean-difference estimator than other quadratic forms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12815v1</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kyle Schindl, Zach Branson</dc:creator>
    </item>
    <item>
      <title>Sample Complexity of Offline Distributionally Robust Linear Markov Decision Processes</title>
      <link>https://arxiv.org/abs/2403.12946</link>
      <description>arXiv:2403.12946v1 Announce Type: cross 
Abstract: In offline reinforcement learning (RL), the absence of active exploration calls for attention on the model robustness to tackle the sim-to-real gap, where the discrepancy between the simulated and deployed environments can significantly undermine the performance of the learned policy. To endow the learned policy with robustness in a sample-efficient manner in the presence of high-dimensional state-action space, this paper considers the sample complexity of distributionally robust linear Markov decision processes (MDPs) with an uncertainty set characterized by the total variation distance using offline data. We develop a pessimistic model-based algorithm and establish its sample complexity bound under minimal data coverage assumptions, which outperforms prior art by at least $\tilde{O}(d)$, where $d$ is the feature dimension. We further improve the performance guarantee of the proposed algorithm by incorporating a carefully-designed variance estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.12946v1</guid>
      <category>cs.LG</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>He Wang, Laixi Shi, Yuejie Chi</dc:creator>
    </item>
    <item>
      <title>Identifying the Most Appropriate Order for Categorical Responses</title>
      <link>https://arxiv.org/abs/2206.08235</link>
      <description>arXiv:2206.08235v3 Announce Type: replace 
Abstract: Categorical responses arise naturally within various scientific disciplines. In many circumstances, there is no predetermined order for the response categories, and the response has to be modeled as nominal. In this study, we regard the order of response categories as part of the statistical model, and show that the true order, when it exists, can be selected using likelihood-based model selection criteria. For predictive purposes, a statistical model with a chosen order may outperform models based on nominal responses, even if a true order does not exist. For multinomial logistic models, widely used for categorical responses, we show the existence of theoretically equivalent orders that cannot be differentiated based on likelihood criteria, and determine the connections between their maximum likelihood estimators. We use simulation studies and a real-data analysis to confirm the need and benefits of choosing the most appropriate order for categorical responses.</description>
      <guid isPermaLink="false">oai:arXiv.org:2206.08235v3</guid>
      <category>math.ST</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tianmeng Wang, Jie Yang</dc:creator>
    </item>
    <item>
      <title>Quantiles, Ranks and Signs in Metric Spaces</title>
      <link>https://arxiv.org/abs/2209.04090</link>
      <description>arXiv:2209.04090v2 Announce Type: replace 
Abstract: Non-Euclidean data become more prevalent in practice, necessitating the development of a framework for statistical inference analogous to that for Euclidean data. Quantile is one of the most important concepts in traditional statistical inference; we introduce the counterpart, both locally and globally, for data objects in metric spaces. This is realized by expanding upon the metric distribution function proposed by Wang et al. (2021). Rank and sign are defined at local and global levels as a natural consequence of the center-outward ordering of metric spaces brought about by the local and global quantiles. The theoretical properties are established, such as the root-$n$ consistency and uniform consistency of the local and global empirical quantiles and the distribution-freeness of ranks and signs. The empirical metric median, which is defined here as the 0th empirical global metric quantile, is proven to be resistant to contamination by means of both theoretical and numerical approaches. Quantiles have been shown to be valuable through extensive simulations in a number of metric spaces. Moreover, we introduce a family of fast rank-based independence tests for a generic metric space. Monte Carlo experiments show good finite-sample performance of the test.</description>
      <guid isPermaLink="false">oai:arXiv.org:2209.04090v2</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hang Liu, Xueqin Wang, Jin Zhu, Heping Zhang</dc:creator>
    </item>
    <item>
      <title>Regularizing nested Monte Carlo Sobol' index estimators to balance the trade-off between explorations and repetitions in global sensitivity analysis of stochastic models</title>
      <link>https://arxiv.org/abs/2210.08807</link>
      <description>arXiv:2210.08807v2 Announce Type: replace 
Abstract: Sobol' sensitivity index estimators for stochastic models are  functions of nested Monte Carlo estimators, which are estimators  built from two nested Monte Carlo loops.  The outer loop explores  the input space and, for each of the explorations, the inner loop  repeats model runs to estimate conditional expectations.  Although  the optimal allocation between explorations and repetitions of one's  computational budget is well-known for nested Monte Carlo  estimators, it is less clear how to deal with functions of nested  Monte Carlo estimators, especially when those functions have  unbounded Hessian matrices, as it is the case for Sobol' index  estimators.  To address this problem, a regularization method is  introduced to bound the mean squared error of functions of nested  Monte Carlo estimators. Based on a heuristic, an  allocation strategy that seeks to minimize a bias-variance trade-off  is proposed. The method is applied to Sobol' index estimators for  stochastic models.  A practical algorithm that adapts to the level  of intrinsic randomness in the models is given and illustrated on  numerical experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.08807v2</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Mermoz Kouye (MaIAGE), Gildas Mazo (MaIAGE)</dc:creator>
    </item>
    <item>
      <title>On the (in)compatibility between potential outcomes and structural causal models and its signification in counterfactual inference</title>
      <link>https://arxiv.org/abs/2309.05997</link>
      <description>arXiv:2309.05997v3 Announce Type: replace 
Abstract: Most of the scientific literature on causal modeling considers the structural framework of Pearl and the potential-outcome framework of Rubin to be formally equivalent, and therefore interchangeably uses the do-notation and the potential-outcome subscript notation to write counterfactual outcomes. In this paper, we agnostically superimpose the two causal models to specify under which mathematical conditions structural counterfactual outcomes and potential outcomes need to, do not need to, can, or cannot be equal (almost surely or law). Our comparison reminds that a structural causal model and a Rubin causal model compatible with the same observations do not have to coincide, and highlights real-world problems where they even cannot correspond. Then, we examine common claims and practices from the causal-inference literature in the light of these results. In doing so, we aim at clarifying the relationship between the two causal frameworks, and the interpretation of their respective counterfactuals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.05997v3</guid>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lucas de Lara (IMT, UT3)</dc:creator>
    </item>
    <item>
      <title>Exploiting deterministic algorithms to perform global sensitivity analysis of continuous-time Markov chain compartmental models with application to epidemiology</title>
      <link>https://arxiv.org/abs/2202.07277</link>
      <description>arXiv:2202.07277v3 Announce Type: replace-cross 
Abstract: In this paper, we propose a generic approach to perform global sensitivity analysis (GSA) for compartmental models based on continuous-time Markov chains (CTMC). This approach enables a complete GSA for epidemic models, in which not only the effects of uncertain parameters such as epidemic parameters (transmission rate, mean sojourn duration in compartments) are quantified, but also those of intrinsic randomness and interactions between the two. The main step in our approach is to build a deterministic representation of the underlying continuous-time Markov chain by controlling the latent variables modeling intrinsic randomness. Then, model output can be written as a deterministic function of both uncertain parameters and controlled latent variables, so that it becomespossible to compute standard variance-based sensitivity indices, e.g. the so-called Sobol' indices. However, different simulation algorithms lead to different representations. We exhibit in this work three different representations for CTMC stochastic compartmental models and discuss the results obtained by implementing and comparing GSAs based on each of these representations on a SARS-CoV-2 epidemic model.</description>
      <guid isPermaLink="false">oai:arXiv.org:2202.07277v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Henri Mermoz Kouye (INRAE, MaIAGE, AIRSEA), Gildas Mazo (INRAE, MaIAGE), Cl\'ementine Prieur (AIRSEA), Elisabeta Vergu (INRAE, MaIAGE)</dc:creator>
    </item>
    <item>
      <title>Turning the information-sharing dial: efficient inference from different data sources</title>
      <link>https://arxiv.org/abs/2207.08886</link>
      <description>arXiv:2207.08886v3 Announce Type: replace-cross 
Abstract: A fundamental aspect of statistics is the integration of data from different sources. Classically, Fisher and others were focused on how to integrate homogeneous (or only mildly heterogeneous) sets of data. More recently, as data are becoming more accessible, the question of if data sets from different sources should be integrated is becoming more relevant. The current literature treats this as a question with only two answers: integrate or don't. Here we take a different approach, motivated by information-sharing principles coming from the shrinkage estimation literature. In particular, we deviate from the do/don't perspective and propose a dial parameter that controls the extent to which two data sources are integrated. How far this dial parameter should be turned is shown to depend, for example, on the informativeness of the different data sources as measured by Fisher information. In the context of generalized linear models, this more nuanced data integration framework leads to relatively simple parameter estimates and valid tests/confidence intervals. Moreover, we demonstrate both theoretically and empirically that setting the dial parameter according to our recommendation leads to more efficient estimation compared to other binary data integration schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2207.08886v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Emily C. Hector, Ryan Martin</dc:creator>
    </item>
    <item>
      <title>Foundations of Causal Discovery on Groups of Variables</title>
      <link>https://arxiv.org/abs/2306.07047</link>
      <description>arXiv:2306.07047v3 Announce Type: replace-cross 
Abstract: Discovering causal relationships from observational data is a challenging task that relies on assumptions connecting statistical quantities to graphical or algebraic causal models. In this work, we focus on widely employed assumptions for causal discovery when objects of interest are (multivariate) groups of random variables rather than individual (univariate) random variables, as is the case in a variety of problems in scientific domains such as climate science or neuroscience. If the group-level causal models are derived from partitioning a micro-level model into groups, we explore the relationship between micro and group-level causal discovery assumptions. We investigate the conditions under which assumptions like Causal Faithfulness hold or fail to hold. Our analysis encompasses graphical causal models that contain cycles and bidirected edges. We also discuss grouped time series causal graphs and variants thereof as special cases of our general theoretical framework. Thereby, we aim to provide researchers with a solid theoretical foundation for the development and application of causal discovery methods for variable groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.07047v3</guid>
      <category>stat.ME</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Wahl, Urmi Ninad, Jakob Runge</dc:creator>
    </item>
    <item>
      <title>Simulating conditioned diffusions on manifolds</title>
      <link>https://arxiv.org/abs/2403.05409</link>
      <description>arXiv:2403.05409v2 Announce Type: replace-cross 
Abstract: To date, most methods for simulating conditioned diffusions are limited to the Euclidean setting. The conditioned process can be constructed using a change of measure known as Doob's $h$-transform. The specific type of conditioning depends on a function $h$ which is typically unknown in closed form. To resolve this, we extend the notion of guided processes to a manifold $M$, where one replaces $h$ by a function based on the heat kernel on $M$. We consider the case of a Brownian motion with drift, constructed using the frame bundle of $M$, conditioned to hit a point $x_T$ at time $T$. We prove equivalence of the laws of the conditioned process and the guided process with a tractable Radon-Nikodym derivative. Subsequently, we show how one can obtain guided processes on any manifold $N$ that is diffeomorphic to $M$ without assuming knowledge of the heat kernel on $N$.
  We illustrate our results with numerical simulations and an example of parameter estimation where a diffusion process on the torus is observed discretely in time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.05409v2</guid>
      <category>math.PR</category>
      <category>math.ST</category>
      <category>stat.TH</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marc Corstanje, Frank van der Meulen, Moritz Schauer, Stefan Sommer</dc:creator>
    </item>
  </channel>
</rss>
