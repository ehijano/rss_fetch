<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.TH updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.TH</link>
    <description>econ.TH updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.TH" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 26 Nov 2024 05:00:08 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Marginal Reputation</title>
      <link>https://arxiv.org/abs/2411.15317</link>
      <description>arXiv:2411.15317v1 Announce Type: new 
Abstract: We study reputation formation where a long-run player repeatedly observes private signals and takes actions. Short-run players observe the long-run player's past actions but not her past signals. The long-run player can thus develop a reputation for playing a distribution over actions, but not necessarily for playing a particular mapping from signals to actions. Nonetheless, we show that the long-run player can secure her Stackelberg payoff if distinct commitment types are statistically distinguishable and the Stackelberg strategy is confound-defeating. This property holds if and only if the Stackelberg strategy is the unique solution to an optimal transport problem. If the long-run player's payoff is supermodular in one-dimensional signals and actions, she secures the Stackelberg payoff if and only if the Stackelberg strategy is monotone. An application of our results provides a reputational foundation for a class of Bayesian persuasion solutions when the sender has a small lying cost. Our results extend to the case where distinct commitment types may be indistinguishable but the Stackelberg type is salient under the prior.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15317v1</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Daniel Luo, Alexander Wolitzky</dc:creator>
    </item>
    <item>
      <title>The reference interval in higher-order stochastic dominance</title>
      <link>https://arxiv.org/abs/2411.15401</link>
      <description>arXiv:2411.15401v1 Announce Type: cross 
Abstract: Given two random variables taking values in a bounded interval, we study whether one dominates the other in higher-order stochastic dominance depends on the reference interval in the model setting. We obtain two results. First, the stochastic dominance relations get strictly stronger when the reference interval shrinks if and only if the order of stochastic dominance is larger than three. Second, for mean-preserving stochastic dominance relations, the reference interval is irrelevant if and only if the difference between the degree of the stochastic dominance and the number of moments is no larger than three. These results highlight complications arising from using higher-order stochastic dominance in economic applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.15401v1</guid>
      <category>math.PR</category>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruodu Wang, Qinyu Wu</dc:creator>
    </item>
    <item>
      <title>Strictly Proper Scoring Mechanisms Without Expected Arbitrage</title>
      <link>https://arxiv.org/abs/2409.07046</link>
      <description>arXiv:2409.07046v2 Announce Type: replace 
Abstract: When eliciting forecasts from a group of experts, it is important to reward predictions so that market participants are incentivized to tell the truth. Existing mechanisms partially accomplish this but remain susceptible to groups of experts colluding to increase their expected reward, meaning that no aggregation of predictions can be fully trusted to represent the true beliefs of forecasters. This paper presents two novel scoring mechanisms which elicit truthful forecasts from any group of experts, even if they can collude or access each other's predictions. The key insight of this approach is a randomization component which maintains strict properness but prevents experts from coordinating dishonest reports in advance. These mechanisms are strictly proper and do not admit expected arbitrage, resolving an open question in the field.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07046v2</guid>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jack Edwards</dc:creator>
    </item>
    <item>
      <title>Incentivizing Information Acquisition</title>
      <link>https://arxiv.org/abs/2410.13978</link>
      <description>arXiv:2410.13978v2 Announce Type: replace 
Abstract: I study a principal-agent model in which a principal hires an agent to collect information about an unknown continuous state. The agent acquires a signal whose distribution is centered around the state, controlling the signal's precision at a cost. The principal observes neither the precision nor the signal, but rather, using transfers that can depend on the state, incentivizes the agent to choose high precision and report the signal truthfully. I identify a sufficient and necessary condition on the agent's information structure which ensures that there exists an optimal transfer with a simple cutoff structure: the agent receives a fixed prize when his prediction is close enough to the state and receives nothing otherwise. This condition is mild and applies to all signal distributions commonly used in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.13978v2</guid>
      <category>econ.TH</category>
      <category>cs.GT</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fan Wu</dc:creator>
    </item>
    <item>
      <title>Generalized Principal-Agent Problem with a Learning Agent</title>
      <link>https://arxiv.org/abs/2402.09721</link>
      <description>arXiv:2402.09721v5 Announce Type: replace-cross 
Abstract: Classic principal-agent problems such as Stackelberg games, contract design, and Bayesian persuasion, often assume that the agent is able to best respond to the principal's committed strategy. We study repeated generalized principal-agent problems under the assumption that the principal does not have commitment power and the agent uses algorithms to learn to respond to the principal. We reduce this problem to a one-shot generalized principal-agent problem where the agent approximately best responds. Using this reduction, we show that: (1) If the agent uses contextual no-regret learning algorithms with regret $\mathrm{Reg}(T)$, then the principal can guarantee utility at least $U^* - \Theta\big(\sqrt{\tfrac{\mathrm{Reg}(T)}{T}}\big)$, where $U^*$ is the principal's optimal utility in the classic model with a best-responding agent. (2) If the agent uses contextual no-swap-regret learning algorithms with swap-regret $\mathrm{SReg}(T)$, then the principal cannot obtain utility more than $U^* + O(\frac{\mathrm{SReg(T)}}{T})$. But (3) if the agent uses mean-based learning algorithms (which can be no-regret but not no-swap-regret), then the principal can sometimes do significantly better than $U^*$. These results not only refine previous results in Stackelberg games and contract design, but also lead to new results for Bayesian persuasion with a learning agent and all generalized principal-agent problems where the agent does not have private information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09721v5</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tao Lin, Yiling Chen</dc:creator>
    </item>
    <item>
      <title>Equitable Core Imputations via a New Adaptation of The Primal-Dual Framework</title>
      <link>https://arxiv.org/abs/2402.11437</link>
      <description>arXiv:2402.11437v3 Announce Type: replace-cross 
Abstract: The classic paper of Shapley and Shubik \cite{Shapley1971assignment} characterized the core of the assignment game. We observe that a sub-coalition consisting of one player (or a set of players from the same side of the bipartition) can make zero profit, and therefore its profit under a core imputation can be an arbitrary amount. Hence an arbitrary core imputation makes {\em no fairness guarantee at the level of individual agents}. Can this deficiency be addressed by picking a ``good'' core imputation?
  To arrive at an appropriate solution concept, we give specific criteria for picking a special core imputation, and we undertake a detailed comparison of four solution concepts. Leximin and leximax core imputations come out as clear winners; we define these to be {\em equitable core imputations}. These imputations achieve ``fairness'' in different ways: whereas leximin tries to make poor agents more rich, leximax tries to make rich agents less rich.
  We give combinatorial strongly polynomial algorithms for computing these imputations via a novel adaptation of the classical primal-dual paradigm. The ``engine'' driving them involves insights into core imputations obtained via complementarity. It will not be surprising if our work leads to new uses of this powerful technique. Furthermore, we expect more work on computing the leximin and leximax core imputations of other natural games, in addition to the recent follow-up work \cite{Leximin-max}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.11437v3</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 26 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vijay V. Vazirani</dc:creator>
    </item>
  </channel>
</rss>
