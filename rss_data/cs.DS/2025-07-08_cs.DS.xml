<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DS updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DS</link>
    <description>cs.DS updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DS" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 08 Jul 2025 04:00:28 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Barvinok's interpolation method meets Weitz's correlation decay approach</title>
      <link>https://arxiv.org/abs/2507.03135</link>
      <description>arXiv:2507.03135v1 Announce Type: new 
Abstract: In this paper we take inspiration from Weit'z algorithm for approximating the independence polynomial to provide a new algorithm for computing the coefficients of the Taylor series of the logarithm of the independence polynomial. Hereby we provide a clear connections between Barvinok's interpolation method and Weitz's algorithm. Our algorithm easily extends to other graph polynomials and partition functions and we illustrate this by applying it to the chromatic polynomial and to the graph homomorphism partition function. Our approach arguably yields a simpler and more transparent algorithm than the algorithm of Patel and the second author.
  As an application of our algorithmic approach we moreover derive, using the interpolation method, a deterministic $O(n(m/\varepsilon)^{7})$-time algorithm that on input of an $n$-vertex and $m$-edge graph of minimum degree at least $3$ and $\varepsilon&gt;0$ approximately computes the number of sink-free orientations of $G$ up to a multiplicative $\exp(\varepsilon)$ factor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03135v1</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ferenc Bencs, Guus Regts</dc:creator>
    </item>
    <item>
      <title>Going Beyond Surfaces in Diameter Approximation</title>
      <link>https://arxiv.org/abs/2507.03447</link>
      <description>arXiv:2507.03447v1 Announce Type: new 
Abstract: Calculating the diameter of an undirected graph requires quadratic running time under the Strong Exponential Time Hypothesis and this barrier works even against any approximation better than 3/2. For planar graphs with positive edge weights, there are known $(1+\varepsilon)$-approximation algorithms with running time $poly(1/\epsilon, \log n) \cdot n$. However, these algorithms rely on shortest path separators and this technique falls short to yield efficient algorithms beyond graphs of bounded genus.
  In this work we depart from embedding-based arguments and obtain diameter approximations relying on VC set systems and the local treewidth property. We present two orthogonal extensions of the planar case by giving $(1+\varepsilon)$-approximation algorithms with the following running times:
  1. $O_h((1/\varepsilon)^{O(h)} \cdot n \log^2 n)$-time algorithm for graphs excluding an apex graph of size h as a minor,
  2. $O_d((1/\varepsilon)^{O(d)} \cdot n \log^2 n)$-time algorithm for the class of d-apex graphs.
  As a stepping stone, we obtain efficient (1+\varepsilon)-approximate distance oracles for graphs excluding an apex graph of size h as a minor. Our oracle has preprocessing time $O_h((1/\varepsilon)^8\cdot n \log n \log W)$ and query time $O((1/\varepsilon)^2 * \log n \log W)$, where $W$ is the metric stretch. Such oracles have been so far only known for bounded genus graphs. All our algorithms are deterministic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03447v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Micha{\l} W{\l}odarczyk</dc:creator>
    </item>
    <item>
      <title>On the Approximability of Train Routing and the Min-Max Disjoint Paths Problem</title>
      <link>https://arxiv.org/abs/2507.03687</link>
      <description>arXiv:2507.03687v1 Announce Type: new 
Abstract: In train routing, the headway is the minimum distance that must be maintained between successive trains for safety and robustness. We introduce a model for train routing that requires a fixed headway to be maintained between trains, and study the problem of minimizing the makespan, i.e., the arrival time of the last train, in a single-source single-sink network. For this problem, we first show that there exists an optimal solution where trains move in convoys, that is, the optimal paths for any two trains are either the same or are arc-disjoint. Via this insight, we are able to reduce the approximability of our train routing problem to that of the min-max disjoint paths problem, which asks for a collection of disjoint paths where the maximum length of any path in the collection is as small as possible. While min-max disjoint paths inherits a strong inapproximability result on directed acyclic graphs from the multi-level bottleneck assignment problem, we show that a natural greedy composition approach yields a logarithmic approximation in the number of disjoint paths for series-parallel graphs. We also present an alternative analysis of this approach that yields a guarantee depending on how often the decomposition tree of the series-parallel graph alternates between series and parallel compositions on any root-leaf path.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03687v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Umang Bhaskar, Katharina Eickhoff, Lennart Kauther, Jannik Matuschke, Britta Peis, Laura Vargas Koch</dc:creator>
    </item>
    <item>
      <title>A simple algorithm for Combinatorial n-fold ILPs using the Steinitz Lemma</title>
      <link>https://arxiv.org/abs/2507.03766</link>
      <description>arXiv:2507.03766v1 Announce Type: new 
Abstract: We present an algorithm for a class of $n$-fold ILPs: whose existing algorithms in literature typically (1) are based on the \textit{augmentation framework} where one starts with an arbitrary solution and then iteratively moves towards an optimal solution by solving appropriate programs; and (2) require solving a linear relaxation of the program. Combinatorial $n$-fold ILPs is a class introduced and studied by Knop et al. [MP2020] that captures several other problems in a variety of domains. We present a simple and direct algorithm that solves Combinatorial $n$-fold ILPs with unbounded non-negative variables via an application of the Steinitz lemma, a classic result regarding reordering of vectors. Depending on the structure of the input, we also improve upon the existing algorithms in literature in terms of the running time, thereby showing an improvement that mirrors the one shown by Rohwedder [ICALP2025] contemporaneously and independently.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03766v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sushmita Gupta, Pallavi Jain, Sanjay Seetharaman, Meirav Zehavi</dc:creator>
    </item>
    <item>
      <title>Bicriteria approximation for $k$-edge-connectivity</title>
      <link>https://arxiv.org/abs/2507.03786</link>
      <description>arXiv:2507.03786v1 Announce Type: new 
Abstract: In the $k$-Edge Connected Spanning Subgraph ($k$-ECSS) problem we are given a (multi-)graph $G=(V,E)$ with edge costs and an integer $k$, and seek a min-cost $k$-edge-connected spanning subgraph of $G$. The problem admits a $2$-approximation algorithm and no better approximation ratio is known. Recently, Hershkowitz, Klein, and Zenklusen [STOC 24] gave a bicriteria $(1,k-10)$-approximation algorithm that computes a $(k-10)$-edge-connected spanning subgraph of cost at most the optimal value of a standard Cut-LP for $k$-ECSS. We improve the bicriteria approximation to $(1,k-4)$, and also give another non-trivial bicriteria approximation $(3/2,k-2)$. The $k$-Edge-Connected Spanning Multi-subgraph ($k$-ECSM) problem is almost the same as $k$-ECSS, except that any edge can be selected multiple times at the same cost. A $(1,k-p)$ bicriteria approximation for $k$-ECSS w.r.t. Cut-LP implies approximation ratio $1+p/k$ for $k$-ECSM, hence our result also improves the approximation ratio for $k$-ECSM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03786v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zeev Nutov, Reut Cohen</dc:creator>
    </item>
    <item>
      <title>A note on finding long directed cycles above the minimum degree bound in 2-connected digraphs</title>
      <link>https://arxiv.org/abs/2507.03807</link>
      <description>arXiv:2507.03807v1 Announce Type: new 
Abstract: For a directed graph $G$, let $\mathrm{mindeg}(G)$ be the minimum among in-degrees and out-degrees of all vertices of $G$. It is easy to see that $G$ contains a directed cycle of length at least $\mathrm{mindeg}(G)+1$. In this note, we show that, even if $G$ is $2$-connected, it is NP-hard to check if $G$ contains a cycle of length at least $\mathrm{mindeg}(G)+3$. This is in contrast with recent algorithmic results of Fomin, Golovach, Sagunov, and Simonov [SODA 2022] for analogous questions in undirected graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03807v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jadwiga Czy\.zewska, Marcin Pilipczuk</dc:creator>
    </item>
    <item>
      <title>Maximizing the Margin between Desirable and Undesirable Elements in a Covering Problem</title>
      <link>https://arxiv.org/abs/2507.03817</link>
      <description>arXiv:2507.03817v1 Announce Type: new 
Abstract: In many covering settings, it is natural to consider the simultaneous presence of desirable elements (that we seek to include) and undesirable elements (that we seek to avoid). This paper introduces a novel combinatorial problem formalizing this tradeoff: from a collection of sets containing both "desirable" and "undesirable" items, pick the subcollection that maximizes the margin between the number of desirable and undesirable elements covered. We call this the Target Approximation Problem (TAP) and argue that many real-world scenarios are naturally modeled via this objective. We first show that TAP is hard, even when restricted to cases where the given sets are small or where elements appear in only a small number of sets. In a large subset of these cases, we show that TAP is hard to even approximate. We then exhibit exact polynomial-time algorithms for other restricted cases and provide an efficient 0.5-approximation for the case where elements occur at most twice, derived through a tight connection to the greedy algorithm for Unweighted Set Cover.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03817v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sophie Boileau, Andrew Hong, David Liben-Nowell, Alistair Pattison, Anna N. Rafferty, Charlie Roslansky</dc:creator>
    </item>
    <item>
      <title>Online Makespan Scheduling under Scenarios</title>
      <link>https://arxiv.org/abs/2507.04016</link>
      <description>arXiv:2507.04016v1 Announce Type: new 
Abstract: We consider a natural extension of online makespan scheduling on identical parallel machines by introducing scenarios. A scenario is a subset of jobs, and the task of our problem is to find a global assignment of the jobs to machines so that the maximum makespan under a scenario, i.e., the maximum makespan of any schedule restricted to a scenario, is minimized.
  For varying values of the number of scenarios and machines, we explore the competitiveness of online algorithms. We prove tight and near-tight bounds, several of which are achieved through novel constructions. In particular, we leverage the interplay between the unit processing time case of our problem and the hypergraph coloring problem both ways: We use hypergraph coloring techniques to steer an adversarial family of instances proving lower bounds, which in turn leads to lower bounds for several variants of online hypergraph coloring.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04016v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ekin Ergen</dc:creator>
    </item>
    <item>
      <title>HiPerMotif: Novel Parallel Subgraph Isomorphism in Large-Scale Property Graphs</title>
      <link>https://arxiv.org/abs/2507.04130</link>
      <description>arXiv:2507.04130v1 Announce Type: new 
Abstract: Subgraph isomorphism, essential for pattern detection in large-scale graphs, faces scalability challenges in attribute-rich property graphs used in neuroscience, systems biology, and social network analysis. Traditional algorithms explore search spaces vertex-by-vertex from empty mappings, leading to extensive early-stage exploration with limited pruning opportunities. We introduce HiPerMotif, a novel hybrid parallel algorithm that fundamentally shifts the search initialization strategy. After structurally reordering the pattern graph to prioritize high-degree vertices, HiPerMotif systematically identifies all possible mappings for the first edge (vertices 0,1) in the target graph, validates these edge candidates using efficient vertex and edge validators, and injects the validated partial mappings as states at depth 2. The algorithm then continues with traditional vertex-by-vertex exploration from these pre-validated starting points, effectively pruning the expensive early search tree branches while enabling natural parallelization over edge candidates. Our contributions include the edge-centric initialization paradigm with state injection, a structural reordering strategy achieving up to 5x speedup, rapid edge and vertex validators for attribute-rich graphs, and efficient parallel enumeration over target graph edges. Implemented in the open-source Arachne framework, HiPerMotif achieves up to 66x speedup over state-of-the-art baselines (VF2-PS, VF3P, Glasgow) on diverse datasets where baselines successfully complete execution. Additionally, HiPerMotif successfully processes massive datasets such as the H01 connectome with 147 million edges, which existing methods cannot handle due to memory constraints. Comprehensive evaluation across synthetic and real-world graphs demonstrates HiPerMotif's scalability, enabling advanced analysis in computational neuroscience and beyond.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04130v1</guid>
      <category>cs.DS</category>
      <category>cs.DC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mohammad Dindoost, Oliver Alvarado Rodriguez, Bartosz Bryg, Ioannis Koutis, David A. Bader</dc:creator>
    </item>
    <item>
      <title>Tight Guarantees for Cut-Relative Survivable Network Design via a Decomposition Technique</title>
      <link>https://arxiv.org/abs/2507.04473</link>
      <description>arXiv:2507.04473v1 Announce Type: new 
Abstract: In the classical \emph{survivable-network-design problem} (SNDP), we are given an undirected graph $G = (V, E)$, non-negative edge costs, and some $(s_i,t_i,r_i)$ tuples, where $s_i,t_i\in V$ and $r_i\in\mathbb{Z}_+$. We seek a minimum-cost subset $H \subseteq E$ such that each $s_i$-$t_i$ pair remains connected even if any $r_i-1$ edges fail. It is well-known that SNDP can be equivalently modeled using a weakly-supermodular \emph{cut-requirement function} $f$, where we seek a minimum-cost edge-set containing at least $f(S)$ edges across every cut $S \subseteq V$.
  Recently, Dinitz et al. proposed a variant of SNDP that enforces a \emph{relative} level of fault tolerance with respect to $G$, where the goal is to find a solution $H$ that is at least as fault-tolerant as $G$ itself. They formalize this in terms of paths and fault-sets, which gives rise to \emph{path-relative SNDP}. Along these lines, we introduce a new model of relative network design, called \emph{cut-relative SNDP} (CR-SNDP), where the goal is to select a minimum-cost subset of edges that satisfies the given (weakly-supermodular) cut-requirement function to the maximum extent possible, i.e., by picking $\min\{f(S),|\delta_G(S)|\}$ edges across every cut $S\subseteq V$.
  Unlike SNDP, the cut-relative and path-relative versions of SNDP are not equivalent. The resulting cut-requirement function for CR-SNDP (as also path-relative SNDP) is not weakly supermodular, and extreme-point solutions to the natural LP-relaxation need not correspond to a laminar family of tight cut constraints. Consequently, standard techniques cannot be used directly to design approximation algorithms for this problem. We develop a \emph{novel decomposition technique} to circumvent this difficulty and use it to give a \emph{tight $2$-approximation algorithm for CR-SNDP}. We also show new hardness results for these relative-SNDP problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04473v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikhil Kumar, JJ Nan, Chaitanya Swamy</dc:creator>
    </item>
    <item>
      <title>The planar edge-coloring theorem of Vizing in $O(n\log n)$ time</title>
      <link>https://arxiv.org/abs/2507.04516</link>
      <description>arXiv:2507.04516v1 Announce Type: new 
Abstract: In 1965, Vizing [Diskret. Analiz, 1965] showed that every planar graph of maximum degree $\Delta\ge 8$ can be edge-colored using $\Delta$ colors. The direct implementation of the Vizing's proof gives an algorithm that finds the coloring in $O(n^2)$ time for an $n$-vertex input graph. Chrobak and Nishizeki [J. Algorithms, 1990] have shown a more careful algorithm, which improves the time to $O(n\log n)$ time, though only for $\Delta\ge 9$. In this paper, we extend their ideas to get an algorithm also for the missing case $\Delta=8$. To this end, we modify the original recoloring procedure of Vizing. This generalizes to bounded genus graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04516v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Patryk J\k{e}drzejczak, {\L}ukasz Kowalik</dc:creator>
    </item>
    <item>
      <title>The Fair Periodic Assignment Problem</title>
      <link>https://arxiv.org/abs/2507.04537</link>
      <description>arXiv:2507.04537v1 Announce Type: new 
Abstract: We study the periodic assignment problem, in which a set of periodically repeating tasks must be assigned to workers within a repeating schedule. The classical efficiency objective is to minimize the number of workers required to operate the schedule. We propose a O(n log n) algorithm to solve this problem. Next, we formalize a notion of fairness among workers, and impose that each worker performs the same work over time. We analyze the resulting trade-off between efficiency and fairness, showing that the price of fairness is at most one extra worker, and that such a fair solution can always be found using the Nearest Neighbor heuristic. We characterize all instances that admit a solution that is both fair and efficient, and use this result to develop a O(n log n) exact algorithm for the fair periodic assignment problem. Finally, we show that allowing aperiodic schedules never reduces the price of fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04537v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rolf van Lieshout, Bart van Rossum</dc:creator>
    </item>
    <item>
      <title>Greedy Dynamic Matching</title>
      <link>https://arxiv.org/abs/2507.04551</link>
      <description>arXiv:2507.04551v1 Announce Type: new 
Abstract: We study a foundational model of dynamic matching market with abandonment. This model has been studied by Collina et al (2020) and Aouad and Saritac (2022), and many other papers have considered special cases. We compare the performance of greedy policies -- which identify a set of "acceptable" matches up front, and perform these matches as soon as possible -- to that of an omniscient benchmark which knows the full arrival and departure sequence.
  We use a novel family of linear programs ($LP^{ALG}$) to identify which greedy policy to follow. We show that the value of $LP^ALG$ is a *lower bound* on the value of the greedy policy that it identifies in two settings of interest:
  -When all types have the same departure rate.
  -The bipartite case where types on the same side of the market have the same departure rate.
  The proofs of these results use a new result (Lemma 1), which relates the *probability* that at least one agent from a set of types is present in the system to the expected number of such agents.
  We also show that the value of $LP^{ALG}$ is at least 1/2 of the reward rate earned by the omniscient policy (Proposition 4). Therefore, for both settings above, our greedy policy provably earns at least half of the omniscient reward rate. This improves upon the bound of 1/8 from Collina (2020). In both settings our competitive ratio of 1/2 is the best possible: no online policy can provide a better guarantee (Theorem 2).
  To show these results we introduce a new linear program that upper bounds the objective value of the omniscient policy (Proposition 3). This improves upon the upper bounds presented by Collina et al (2020) and Kessel et al (2022).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04551v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Nick Arnosti, Felipe Simon</dc:creator>
    </item>
    <item>
      <title>Color Distance Oracles and Snippets: Separation Between Exact and Approximate Solutions</title>
      <link>https://arxiv.org/abs/2507.04578</link>
      <description>arXiv:2507.04578v1 Announce Type: new 
Abstract: In the snippets problem, the goal is to preprocess text $T$ so that given two patterns $P_1$ and $P_2$, one can locate the occurrences of the two patterns in $T$ that are closest to each other, or report their distance. Kopelowitz and Krauthgamer [CPM2016] showed upper bound tradeoffs and conditional lower bounds tradeoffs for the snippets problem, by utilizing connections between the snippets problem and the problem of constructing a color distance oracle (CDO), which is a data structure that preprocess a set of points with associated colors so that given two colors $c$ and $c'$ one can quickly find the (distance between the) closest pair of points with colors $c$ and $c'$. However, the existing upper bound and lower bound curves are not tight.
  Inspired by recent advances by Kopelowitz and Vassilevska-Williams [ICALP2020] regarding Set-disjointness data structures, we introduce new conditionally optimal algorithms for $(1+\varepsilon)$ approximation versions of the snippets problem and the CDO problem, by applying fast matrix multiplication. For example, for CDO on $n$ points in an array with preprocessing time $\tilde{O}(n^a)$ and query time $\tilde{O}(n^b)$, assuming that $\omega=2$ (where $\omega$ is the exponent of $n$ in the runtime of the fastest matrix multiplication algorithm on two squared matrices of size $n\times n$), we show that approximate CDO can be solved with the following tradeoff
  $$ a + 2b = 2 \text{ if } 0 \leq b \leq \frac1 3$$ $$ 2a + b = 3 \text{ if } \frac13\leq b \leq 1.$$
  Moreover, we prove that for exact CDO on points in an array, the algorithm of Kopelowitz and Krauthgamer [CPM2016], is essentially optimal assuming that the strong APSP hypothesis holds for randomized algorithms. Thus, the exact version of CDO is strictly harder than the approximate version.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04578v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Noam Horowicz, Tsvi Kopelowitz</dc:creator>
    </item>
    <item>
      <title>Improved Algorithms for Effective Resistance Computation on Graphs</title>
      <link>https://arxiv.org/abs/2507.04674</link>
      <description>arXiv:2507.04674v1 Announce Type: new 
Abstract: Effective Resistance (ER) is a fundamental tool in various graph learning tasks. In this paper, we address the problem of efficiently approximating ER on a graph $\mathcal{G}=(\mathcal{V},\mathcal{E})$ with $n$ vertices and $m$ edges. First, we focus on local online-computation algorithms for ER approximation, aiming to improve the dependency on the approximation error parameter $\epsilon$. Specifically, for a given vertex pair $(s,t)$, we propose a local algorithm with a time complexity of $\tilde{O}(\sqrt{d}/\epsilon)$ to compute an $\epsilon$-approximation of the $s,t$-ER value for expander graphs, where $d=\min \{d_s,d_t\}$. This improves upon the previous state-of-the-art, including an $\tilde{O}(1/\epsilon^2)$ time algorithm based on random walk sampling by Andoni et al. (ITCS'19) and Peng et al. (KDD'21). Our method achieves this improvement by combining deterministic search with random walk sampling to reduce variance. Second, we establish a lower bound for ER approximation on expander graphs. We prove that for any $\epsilon\in (0,1)$, there exist an expander graph and a vertex pair $(s,t)$ such that any local algorithm requires at least $\Omega(1/\epsilon)$ time to compute the $\epsilon$-approximation of the $s,t$-ER value. Finally, we extend our techniques to index-based algorithms for ER computation. We propose an algorithm with $\tilde{O}(\min \{m+n/\epsilon^{1.5},\sqrt{nm}/\epsilon\})$ processing time, $\tilde{O}(n/\epsilon)$ space complexity and $O(1)$ query complexity, which returns an $\epsilon$-approximation of the $s,t$-ER value for any $s,t\in \mathcal{V}$ for expander graphs. Our approach improves upon the state-of-the-art $\tilde{O}(m/\epsilon)$ processing time by Dwaraknath et al. (NeurIPS'24) and the $\tilde{O}(m+n/\epsilon^2)$ processing time by Li and Sachdeva (SODA'23).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04674v1</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yichun Yang, Rong-Hua Li, Meihao Liao, Guoren Wang</dc:creator>
    </item>
    <item>
      <title>Recent Advances in Maximum-Entropy Sampling</title>
      <link>https://arxiv.org/abs/2507.05066</link>
      <description>arXiv:2507.05066v1 Announce Type: new 
Abstract: In 2022, we published a book, \emph{Maximum-Entropy Sampling: Algorithms and Application (Springer)}. Since then, there have been several notable advancements on this topic. In this manuscript, we survey some recent highlights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.05066v1</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marcia Fampa, Jon Lee</dc:creator>
    </item>
    <item>
      <title>Discovering Algorithms with Computational Language Processing</title>
      <link>https://arxiv.org/abs/2507.03190</link>
      <description>arXiv:2507.03190v1 Announce Type: cross 
Abstract: Algorithms are the engine for reproducible problem-solving. We present a framework automating algorithm discovery by conceptualizing them as sequences of operations, represented as tokens. These computational tokens are chained using a grammar, enabling the formation of increasingly sophisticated procedures. Our ensemble Monte Carlo tree search (MCTS) guided by reinforcement learning (RL) explores token chaining and drives the creation of new tokens. This methodology rediscovers, improves, and generates new algorithms that substantially outperform existing methods for strongly NP-hard combinatorial optimization problems and foundational quantum computing approaches such as Grover's and Quantum Approximate Optimization Algorithm. Operating at the computational rather than code-generation level, our framework produces algorithms that can be tailored specifically to problem instances, not merely classes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03190v1</guid>
      <category>cs.AI</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Theo Bourdais, Abeynaya Gnanasekaran, Houman Owhadi, Tuhin Sahai</dc:creator>
    </item>
    <item>
      <title>Bayesian Optimal Stopping with Maximum Value Knowledge</title>
      <link>https://arxiv.org/abs/2507.03497</link>
      <description>arXiv:2507.03497v1 Announce Type: cross 
Abstract: We consider an optimal stopping problem with n correlated offers where the goal is to design a (randomized) stopping strategy that maximizes the expected value of the offer in the sequence at which we stop. Instead of assuming to know the complete correlation structure, which is unrealistic in practice, we only assume to have knowledge of the distribution of the maximum value of the sequence, and want to analyze the worst-case correlation structure whose maximum follows this distribution. This can be seen as a trade-off between the setting in which no distributional information is known, and the Bayesian setting in which the (possibly correlated) distributions of all the individual offers are known. As our first main result we show that a deterministic threshold strategy using the monopoly price of the distribution of the maximum value is asymptotically optimal assuming that the expectation of the maximum value grows sublinearly in n. In our second main result, we further tighten this bound by deriving a tight quadratic convergence guarantee for sufficiently smooth distributions of the maximum value. Our results also give rise to a more fine-grained picture regarding prophet inequalities with correlated values, for which distribution-free bounds often only yield a performance guarantee that is of the order 1/n.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03497v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Pieter Kleer, Daan Noordenbos</dc:creator>
    </item>
    <item>
      <title>Combination generators with optimal cache utilization and communication free parallel execution</title>
      <link>https://arxiv.org/abs/2507.03980</link>
      <description>arXiv:2507.03980v1 Announce Type: cross 
Abstract: We introduce an efficient and elegant combination generator for producing all combinations of size less than or equal to K, designed for exhaustive generation and combinatorial optimization tasks. This generator can be implemented to achieve what we define as optimal efficiency: constant amortized time, optimal cache utilization, embarrassingly parallel execution, and a recursive structure compatible with pruning-based search. These properties are difficult to satisfy simultaneously in existing generators. For example, classical Gray code or lexicographic generators are typically list-based and sequentially defined, making them difficult to vectorized, inefficient in cache usage, and inherently hard to parallelize. Generators based on unranking methods, while easy to parallelize, are non-recursive. These limitations reduce their applicability in our target applications, where both computational efficiency and recursion are crucial. We adapt Bird's algebra of programming-style calculation to derive our algorithms, a formalism for developing correct-by-construction programs from specifications. As a result, all generators in this paper are first formulated in their clearest specification, and efficient definitions are derived constructively through equational reasoning, resulting in concise and elegant divide-and-conquer definitions. Beyond presenting a combination generator, we extend our approach to construct generators for K-permutations, nested combinations of combinations, and nested permutation-combination structures. To the best of our knowledge, the literature has not previously reported generators for these nested structures. We also develop sequential variants that produce configurations in Gray code-compatible orders -- such as the revolving door ordering -- which are particularly useful for constructing nested generators.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.03980v1</guid>
      <category>cs.DM</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Xi He, Max. A. Little</dc:creator>
    </item>
    <item>
      <title>Online Convex Optimization with Switching Cost with Only One Single Gradient Evaluation</title>
      <link>https://arxiv.org/abs/2507.04133</link>
      <description>arXiv:2507.04133v1 Announce Type: cross 
Abstract: Online convex optimization with switching cost is considered under the frugal information setting where at time $t$, before action $x_t$ is taken, only a single function evaluation and a single gradient is available at the previously chosen action $x_{t-1}$ for either the current cost function $f_t$ or the most recent cost function $f_{t-1}$. When the switching cost is linear, online algorithms with optimal order-wise competitive ratios are derived for the frugal setting. When the gradient information is noisy, an online algorithm whose competitive ratio grows quadratically with the noise magnitude is derived.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04133v1</guid>
      <category>math.OC</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Harsh Shah, Purna Chandrasekhar, Rahul Vaze</dc:creator>
    </item>
    <item>
      <title>Quantum Algorithms for Bandits with Knapsacks with Improved Regret and Time Complexities</title>
      <link>https://arxiv.org/abs/2507.04438</link>
      <description>arXiv:2507.04438v1 Announce Type: cross 
Abstract: Bandits with knapsacks (BwK) constitute a fundamental model that combines aspects of stochastic integer programming with online learning. Classical algorithms for BwK with a time horizon $T$ achieve a problem-independent regret bound of ${O}(\sqrt{T})$ and a problem-dependent bound of ${O}(\log T)$. In this paper, we initiate the study of the BwK model in the setting of quantum computing, where both reward and resource consumption can be accessed via quantum oracles. We establish both problem-independent and problem-dependent regret bounds for quantum BwK algorithms. For the problem-independent case, we demonstrate that a quantum approach can improve the classical regret bound by a factor of $(1+\sqrt{B/\mathrm{OPT}_\mathrm{LP}})$, where $B$ is budget constraint in BwK and $\mathrm{OPT}_{\mathrm{LP}}$ denotes the optimal value of a linear programming relaxation of the BwK problem. For the problem-dependent setting, we develop a quantum algorithm using an inexact quantum linear programming solver. This algorithm achieves a quadratic improvement in terms of the problem-dependent parameters, as well as a polynomial speedup of time complexity on problem's dimensions compared to classical counterparts. Compared to previous works on quantum algorithms for multi-armed bandits, our study is the first to consider bandit models with resource constraints and hence shed light on operations research.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04438v1</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuexin Su, Ziyi Yang, Peiyuan Huang, Tongyang Li, Yinyu Ye</dc:creator>
    </item>
    <item>
      <title>Agentic Distributed Computing</title>
      <link>https://arxiv.org/abs/2507.04459</link>
      <description>arXiv:2507.04459v1 Announce Type: cross 
Abstract: The most celebrated and extensively studied model of distributed computing is the {\em message-passing model,} in which each vertex/node of the (distributed network) graph corresponds to a static computational device that communicates with other devices through passing messages. In this paper, we consider the {\em agentic model} of distributed computing which extends the message-passing model in a new direction. In the agentic model, computational devices are modeled as relocatable or mobile computational devices (called agents in this paper), i.e., each vertex/node of the graph serves as a container for the devices, and hence communicating with another device requires relocating to the same node. We study two fundamental graph level tasks, leader election, and minimum spanning tree, in the agentic model, which will enhance our understanding of distributed computation across paradigms. The objective is to minimize both time and memory complexities. Following the literature, we consider the synchronous setting in which each agent performs its operations synchronously with others, and hence the time complexity can be measured in rounds. In this paper, we present two deterministic algorithms for leader election: one for the case of $k&lt;n$ and another for the case of $k=n$, minimizing both time and memory complexities, where $k$ and $n$, respectively, are the number of agents and number of nodes of the graph. Using these leader election results, we develop deterministic algorithms for agents to construct a minimum spanning tree of the graph, minimizing both time and memory complexities. To the best of our knowledge, this is the first study of distributed graph level tasks in the agentic model with $k\leq n$. Previous studies only considered the case of $k=n$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04459v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ajay D. Kshemkalyani, Manish Kumar, Anisur Rahaman Molla, Gokarna Sharma</dc:creator>
    </item>
    <item>
      <title>Heights of butterfly trees</title>
      <link>https://arxiv.org/abs/2507.04505</link>
      <description>arXiv:2507.04505v1 Announce Type: cross 
Abstract: Binary search trees (BSTs) are fundamental data structures whose performance is largely governed by tree height. We introduce a block model for constructing BSTs by embedding internal BSTs into the nodes of an external BST -- a structure motivated by parallel data architectures -- corresponding to composite permutations formed via Kronecker or wreath products. Extending Devroye's result that the height $h_n$ of a random BST satisfies $h_n / \log n \to c^* \approx 4.311$, we show that block BSTs with $nm$ nodes and fixed external size $m$ satisfy $h_{n,m} / \log n \to c^* + h_m$ in distribution. We then analyze height growth under iterated products. For simple butterfly trees (from iterated Kronecker products of $S_2$), we give a full distributional description showing polynomial height growth: $\mathbb{E} h_n^{\operatorname{B}} = \Theta(N^\alpha)$ with $\alpha \approx 0.58496$. For nonsimple butterfly trees (from wreath products), we prove power-law bounds: $cN^\alpha\cdot (1 + o(1)) \le \mathbb{E} h_n^{\operatorname{B}} \le dN^\beta\cdot (1 + o(1))$, with $\beta \approx 0.913189$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04505v1</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Peca-Medlin, Chenyang Zhong</dc:creator>
    </item>
    <item>
      <title>Decremental Greedy Polygons and Polyhedra Without Sharp Angles</title>
      <link>https://arxiv.org/abs/2507.04538</link>
      <description>arXiv:2507.04538v1 Announce Type: cross 
Abstract: We show that the max-min-angle polygon in a planar point set can be found in time $O(n\log n)$ and a max-min-solid-angle convex polyhedron in a three-dimensional point set can be found in time $O(n^2)$. We also study the maxmin-angle polygonal curve in 3d, which we show to be $\mathsf{NP}$-hard to find if repetitions are forbidden but can be found in near-cubic time if repeated vertices or line segments are allowed, by reducing the problem to finding a bottleneck cycle in a graph. We formalize a class of problems on which a decremental greedy algorithm can be guaranteed to find an optimal solution, generalizing our max-min-angle and bottleneck cycle algorithms, together with a known algorithm for graph degeneracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04538v1</guid>
      <category>cs.CG</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Eppstein</dc:creator>
    </item>
    <item>
      <title>Truthful, Credible, and Optimal Auctions for Matroids via Blockchains and Commitments</title>
      <link>https://arxiv.org/abs/2507.04592</link>
      <description>arXiv:2507.04592v1 Announce Type: cross 
Abstract: We consider a revenue-optimizing auctioneer in single-dimensional environments with matroid feasibility constraints. Akbarpour and Li (2020) argue that any revenue-optimal, truthful, and credible mechanism requires unbounded communication. Recent works (Ferreira and Weinberg, 2020; Essaidi et al., 2022; Chitra et al., 2024) circumvent their impossibility for the single-item setting through the use of cryptographic commitments and blockchains. We extend their results to matroid feasibility constraints.
  At a high level, the two-round Deferred-Revelation Auction (DRA) discussed by Ferreira and Weinberg (2020) and Chitra et al., (2024) requires each bidder to submit a deposit, which is slashed upon presenting verifiable evidence indicating a deviation from the behaviour prescribed by the mechanism. We prove that the DRA satisfies truthfulness, credibility and revenue-optimality for all matroid environments when bidders' values are drawn from $\alpha$-strongly regular distributions for $\alpha &gt; 0$. Further, we argue that the DRA is not credible for any feasibility constraint beyond matroids and for any smaller deposits than suggested by previous literature even in single-item environments.
  Finally, we modify the Ascending Deferred-Revelation Auction (ADRA) for single-item settings proposed by Essaidi et al., (2022) for arbitrary bidder value distributions. We implement a deferred-revelation variant of the deferred-acceptance auction for matroids due to Bikhchandani et al., (2011), which requires the same bounded communication as the ADRA.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04592v1</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3736252.3742652</arxiv:DOI>
      <dc:creator>Aadityan Ganesh, Qianfan Zhang</dc:creator>
    </item>
    <item>
      <title>Liar's vertex-edge domination in subclasses of chordal graphs</title>
      <link>https://arxiv.org/abs/2507.04721</link>
      <description>arXiv:2507.04721v1 Announce Type: cross 
Abstract: Let $G=(V, E)$ be an undirected graph. The set $N_G[x]=\{y\in V|xy\in E\}\cup \{x\}$ is called the closed neighbourhood of a vertex $x\in V$ and for an edge $e=xy\in E$, the closed neighbourhood of $e$ is the set $N_G[x]\cup N_G[y]$, which is denoted by $N_G[e]$ or $N_G[xy]$. A set $L\subseteq V$ is called \emph{liar's vertex-edge dominating set} of a graph $G=(V,E)$ if for every $e_i\in E$, $|N_G[e_i]\cap L|\geq 2$ and for every pair of distinct edges $e_i,e_j\in E$, $|(N_G[e_i]\cup N_G[e_j])\cap L|\geq 3$. The notion of liar's vertex-edge domination arises naturally from some applications in communication networks. Given a graph $G$, the \textsc{Minimum Liar's Vertex-Edge Domination Problem} (\textsc{MinLVEDP}) asks to find a liar's vertex-edge dominating set of $G$ of minimum cardinality. In this paper, we study this problem from an algorithmic point of view. We design two linear time algorithms for \textsc{MinLVEDP} in block graphs and proper interval graphs, respectively. On the negative side, we show that the decision version of liar's vertex-edge domination problem is NP-complete for undirected path graphs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04721v1</guid>
      <category>math.CO</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Debojyoti Bhattacharya, Subhabrata Paul</dc:creator>
    </item>
    <item>
      <title>Distributed Approximation Algorithms for Minimum Dominating Set in Locally Nice Graphs</title>
      <link>https://arxiv.org/abs/2507.04960</link>
      <description>arXiv:2507.04960v1 Announce Type: cross 
Abstract: We give a new, short proof that graphs embeddable in a given Euler genus-$g$ surface admit a simple $f(g)$-round $\alpha$-approximation distributed algorithm for Minimum Dominating Set (MDS), where the approximation ratio $\alpha \le 906$. Using tricks from Heydt et al. [European Journal of Combinatorics (2025)], we in fact derive that $\alpha \le 34 +\varepsilon$, therefore improving upon the current state of the art of $24g+O(1)$ due to Amiri et al. [ACM Transactions on Algorithms (2019)]. It also improves the approximation ratio of $91+\varepsilon$ due to Czygrinow et al. [Theoretical Computer Science (2019)] in the particular case of orientable surfaces.
  All our distributed algorithms work in the deterministic LOCAL model. They do not require any preliminary embedding of the graph and only rely on two things: a LOCAL algorithm for MDS on planar graphs with ``uniform'' approximation guarantees and the knowledge that graphs embeddable in bounded Euler genus surfaces have asymptotic dimension $2$.
  More generally, our algorithms work in any graph class of bounded asymptotic dimension where ``most vertices'' are locally in a graph class that admits a LOCAL algorithm for MDS with uniform approximation guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.04960v1</guid>
      <category>cs.DC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marthe Bonamy, Cyril Gavoille, Timoth\'e Picavet, Alexandra Wesolek</dc:creator>
    </item>
    <item>
      <title>Improved Approximation Algorithms for Capacitated Vehicle Routing with Fixed Capacity</title>
      <link>https://arxiv.org/abs/2210.16534</link>
      <description>arXiv:2210.16534v3 Announce Type: replace 
Abstract: The Capacitated Vehicle Routing Problem (CVRP) is one of the most extensively studied problems in combinatorial optimization. Based on customer demand, we distinguish three variants of CVRP: unit-demand, splittable, and unsplittable. In this paper, we consider $k$-CVRP in general metrics and on general graphs, where $k$ is the vehicle capacity. All three versions are APX-hard for any fixed $k\geq3$. Assume that the approximation ratio of metric TSP is $\frac{3}{2}$. We present a $(\frac{5}{2}-\Theta(\frac{1}{\sqrt{k}}))$-approximation algorithm for the splittable and unit-demand cases, and a $(\frac{5}{2}+\ln2-\Theta(\frac{1}{\sqrt{k}}))$-approximation algorithm for the unsplittable case. Our approximation ratio is better than the previous results when $k$ is less than a sufficiently large value, approximately $1.7\times10^7$.
  For small values of $k$, we design independent and elegant algorithms with further improvements. For the splittable and unit-demand cases, we improve the approximation ratio from $1.792$ to $1.500$ for $k=3$, and from $1.750$ to $1.500$ for $k=4$. For the unsplittable case, we improve the approximation ratio from $1.792$ to $1.500$ for $k=3$, from $2.051$ to $1.750$ for $k=4$, and from $2.249$ to $2.157$ for $k=5$. The approximation ratio for $k=3$ surprisingly achieves the same value as in the splittable case. Our techniques, such as EX-ITP -- an extension of the classic ITP method, have the potential to improve algorithms for other routing problems as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.16534v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jingyang Zhao, Mingyu Xiao</dc:creator>
    </item>
    <item>
      <title>Dynamic online matching with budget refills</title>
      <link>https://arxiv.org/abs/2405.09920</link>
      <description>arXiv:2405.09920v3 Announce Type: replace 
Abstract: Inspired by sequential budgeted allocation problems, we study the online matching problem with budget refills. In this context, we consider an online bipartite graph $G=(U,V,E)$, where the nodes in $V$ are discovered sequentially and nodes in $U$ are known beforehand. Each $u\in U$ is endowed with a budget $b_{u,t}\in \mathbb{N}$ that dynamically evolves over time. Unlike the canonical setting, in many applications, the budget can be refilled from time to time, which leads to a much richer dynamic that we consider here. Intuitively, adding extra budgets in $U$ seems to ease the matching task, and our results support this intuition. In fact, for the stochastic framework considered where we studied the matching size built by Greedy algorithm on an Erd\H{o}s-R{\'e}yni random graph, we showed that the matching size generated by Greedy converges with high probability to a solution of an explicit system of ODE. Moreover, under specific conditions, the competitive ratio (performance measure of the algorithm) can even tend to 1. For the adversarial part, where the graph considered is deterministic and the algorithm used is Balance, the $b$-matching bound holds when the refills are scarce. However, when refills are regular, our results suggest a potential improvement in algorithm performance. In both cases, Balance algorithm manages to reach the performance of the upper bound on the adversarial graphs considered.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.09920v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Maria Cherifa (ENSAE Paris), Cl\'ement Calauz\`enes (ENSAE Paris), Vianney Perchet (ENSAE Paris)</dc:creator>
    </item>
    <item>
      <title>Locally Stationary Distributions: A Framework for Analyzing Slow-Mixing Markov Chains</title>
      <link>https://arxiv.org/abs/2405.20849</link>
      <description>arXiv:2405.20849v4 Announce Type: replace 
Abstract: Many natural Markov chains fail to mix to their stationary distribution in polynomially many steps. Often, this slow mixing is inevitable since it is computationally intractable to sample from their stationary measure.
  Nevertheless, Markov chains can be shown to always converge quickly to measures that are locally stationary, i.e., measures that don't change over a small number of steps. These locally stationary measures are analogous to local minima in continuous optimization, while stationary measures correspond to global minima.
  While locally stationary measures can be statistically far from stationary measures, do they enjoy provable theoretical guarantees that have algorithmic implications? We study this question in this work and demonstrate three algorithmic applications of locally stationary measures:
  1. We show that Glauber dynamics on the hardcore model can be used to find independent sets of size $\Omega\left(\frac{\log d}{d} \cdot n\right)$ in triangle-free graphs of degree at most $d$.
  2. Let $W$ be a symmetric real matrix with bounded spectral diameter and $v$ be a unit vector. Given the matrix $M = \lambda vv^\top + W$ with a planted rank-one spike along vector $v$, for sufficiently large constant $\lambda$, Glauber dynamics on the Ising model defined by $M$ samples vectors $x \in \{\pm 1\}^n$ that have constant correlation with the vector $v$.
  3. Let $M = A_{\mathbf{G}} - \frac{d}{n}\mathbf{1}\mathbf{1}^\top$ be a centered version of the adjacency matrix where the graph $\mathbf{G}$ is drawn from a sparse 2-community stochastic block model. We show that for sufficiently large constant signal-to-noise ratio, Glauber dynamics on the Ising model defined by $M$ samples vectors $x \in \{\pm 1\}^n$ that have constant correlation with the hidden community vector $\mathbf{\sigma}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.20849v4</guid>
      <category>cs.DS</category>
      <category>math.PR</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kuikui Liu, Sidhanth Mohanty, Prasad Raghavendra, Amit Rajaraman, David X. Wu</dc:creator>
    </item>
    <item>
      <title>Core-Sparse Monge Matrix Multiplication: Improved Algorithm and Applications</title>
      <link>https://arxiv.org/abs/2408.04613</link>
      <description>arXiv:2408.04613v2 Announce Type: replace 
Abstract: Min-plus matrix multiplication is used in many problems operating on distances in graphs or solvable by dynamic programming. Assuming the APSP hypothesis, there is no subcubic-time algorithm for the min-plus product of two general $n\times n$ matrices, but structured matrices admit faster solutions. Planar graph algorithms often use Monge matrices, which have an $O(n^2)$-time min-plus multiplication procedure. Many results for sequence alignment problems, such as edit distance and longest increasing subsequence, apply simple unit-Monge matrices, whose min-plus product can be computed in $O(n\log n)$ time [Tiskin, SODA'10]. Russo [SPIRE'11] identified the core size $\delta$ as the structural parameter behind the underlying matrix representation and showed an $O((n+\delta)\log^3 n)$-time min-plus multiplication procedure for arbitrary Monge matrices.
  In this work, we prove a linear bound on the core size of the product matrix in terms of the core sizes of the input matrices and show how to solve the core-sparse Monge matrix multiplication problem in $O((n+\delta)\log n)$ time, matching the complexity for simple unit-Monge matrices, where $\delta = O(n)$. As witnessed by the recent work of Gorbachev and Kociumaka [STOC'25] for edit distance with integer weights, our generalization opens up the possibility of speed-ups for weighted sequence alignment problems. Furthermore, our multiplication algorithm can efficiently recover the witness for any entry of the output matrix. This allows us, for example, to preprocess an integer array of size $n$ in $\tilde{O}(n)$ time so that the longest increasing subsequence of any sub-array can be reconstructed in $\tilde{O}(\ell)$ time, where $\ell$ is the length of the reported subsequence. In comparison, Karthik C. S. and Rahul [arXiv, 2024] recently achieved $\tilde{O}(\ell+n^{1/2})$-time reporting after $\tilde{O}(n^{3/2})$-time preprocessing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.04613v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Pawe{\l} Gawrychowski, Egor Gorbachev, Tomasz Kociumaka</dc:creator>
    </item>
    <item>
      <title>Maximum And- vs. Even-SAT</title>
      <link>https://arxiv.org/abs/2409.07837</link>
      <description>arXiv:2409.07837v3 Announce Type: replace 
Abstract: A multiset of literals, called a clause, is \emph{strongly satisfied} by an assignment if \emph{no} literal evaluates to false. Finding an assignment that maximises the number of strongly satisfied clauses is NP-hard. We present a simple algorithm that finds, given a multiset of clauses that admits an assignment that strongly satisfies $\rho$ of the clauses, an assignment in which at least $\rho$ of the clauses are \emph{weakly satisfied}, in the sense that an \emph{even} number of literals evaluate to false. In particular, this implies an efficient algorithm for finding an undirected cut of value $\rho$ in a graph $G$ given that a directed cut of value $\rho$ in $G$ is promised to exist. A similar argument also gives an efficient algorithm for finding an acyclic subgraph of $G$ with $\rho$ edges under the same promise.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07837v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tamio-Vesa Nakajima, Stanislav \v{Z}ivn\'y</dc:creator>
    </item>
    <item>
      <title>Faster Algorithms for Graph Monopolarity</title>
      <link>https://arxiv.org/abs/2410.06337</link>
      <description>arXiv:2410.06337v2 Announce Type: replace 
Abstract: A graph $G = (V,E)$ is $\textit{monopolar}$ if its vertex set admits a partition $V = (C \uplus{} I)$ where $G[C]$ is a $\textit{cluster graph}$ and $I$ is an $\textit{independent set}$ in $G$; this is a \textit{monopolar partition} of $G$. The MONOPOLAR RECOGNITION problem -- deciding whether an input graph is monopolar -- is known to be NP-Hard in very restricted graph classes such as sub-cubic planar graphs.
  We derive a polynomial-time algorithm that takes (i) a graph $G=(V,E)$ and (ii) a vertex modulator $S$ of $G$ to chair-free graphs as inputs, and checks whether $G$ has a monopolar partition $V=(C\uplus{}I)$ where set $S$ is contained in the cluster part. We build on this algorithm to develop fast exact exponential-time and parameterized algorithms for MONOPOLAR RECOGNITION.
  Our exact algorithm solves MONOPOLAR RECOGNITION in $\mathcal{O}^{\star}(1.3734^{n})$ time on input graphs with $n$ vertices, where the $\mathcal{O}^{\star}()$ notation hides polynomial factors. In fact, we solve the more general problems MONOPOLAR EXTENSTION and LIST-MONOPOLAR PARTITION in $\mathcal{O}^{\star}(1.3734^{n})$ time. These are the first improvements over the trivial $\mathcal{O}^{\star}(2^{n})$-time algorithms for all these problems. It is known that -- assuming ETH -- these problems cannot be solved in $\mathcal{O}^{\star}(2^{o(n)})$ time.
  Our FPT algorithms solve MONOPOLAR RECOGNITION in $\mathcal{O}^{\star}(3.076^{k_{v}})$ and $\mathcal{O}^{\star}(2.253^{k_{e}})$ time where $k_{v}$ and $k_{e}$ are, respectively, the sizes of the smallest vertex and edge modulators of the input graph to claw-free graphs. These results are a significant addition to the small number of FPT algorithms currently known for MONOPOLAR RECOGNITION.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.06337v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geevarghese Philip, Shrinidhi Teganahally Sridhara</dc:creator>
    </item>
    <item>
      <title>Grandchildren-weight-balanced binary search trees</title>
      <link>https://arxiv.org/abs/2410.08825</link>
      <description>arXiv:2410.08825v2 Announce Type: replace 
Abstract: We revisit weight-balanced trees, also known as trees of bounded balance. This class of binary search trees was invented by Nievergelt and Reingold in 1972. Such trees are obtained by assigning a weight to each node and requesting that the weight of each node should be quite larger than the weights of its children, the precise meaning of ``quite larger'' depending on a real-valued parameter~$\gamma$. Blum and Mehlhorn then showed how to maintain these trees in a recursive (bottom-up) fashion when~$2/11 \leqslant \gamma \leqslant 1-1/\sqrt{2}$, their algorithm requiring only an amortised constant number of tree rebalancing operations per update (insertion or deletion). Later, in 1993, Lai and Wood proposed a top-down procedure for updating these trees when~$2/11 \leqslant \gamma \leqslant 1/4$.
  Our contribution is two-fold. First, we strengthen the requirements of Nievergelt and Reingold, by also requesting that each node should have a substantially larger weight than its grand-children, thereby obtaining what we call grand-children balanced trees. Grand-children balanced trees are not harder to maintain than weight-balanced trees, but enjoy a smaller node depth, both in the worst case (with a 6~\% decrease) and on average (with a 1.6~\% decrease). In particular, unlike standard weight-balanced trees, all grand-children balanced trees with $n$ nodes are of height less than $2 \log_2(n)$.
  Second, we adapt the algorithm of Lai and Wood to all weight-balanced trees, i.e., to all parameter values~$\gamma$ such that~$2/11 \leqslant \gamma \leqslant 1-1/\sqrt{2}$. More precisely, we adapt it to all grand-children balanced trees for which~$1/4 &lt; \gamma \leqslant 1 - 1/\sqrt{2}$. Finally, we show that, except in critical cases, all these algorithms result in making a constant amortised number of tree rebalancing operations per tree update.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.08825v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4230/LIPIcs.WADS.2025.14</arxiv:DOI>
      <dc:creator>Vincent Jug\'e</dc:creator>
    </item>
    <item>
      <title>Optimized 2-Approximation of Treewidth</title>
      <link>https://arxiv.org/abs/2411.16918</link>
      <description>arXiv:2411.16918v3 Announce Type: replace 
Abstract: This paper presents a linear FPT algorithm to find a tree decomposition with a 2-approximation of the treewidth with a significantly smaller exponential dependence on the treewidth. The algorithm runs in time $O(\text{poly}(k) 81^k n)$, compared to Korhonen's running time of $O(\text{poly}(k) 1782^k n)$ = $O(2^{10.8k} n)$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.16918v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Belbasi, Martin F\"urer, Medha Kumar</dc:creator>
    </item>
    <item>
      <title>Induced Minor Models. II. Sufficient conditions for polynomial-time detection of induced minors</title>
      <link>https://arxiv.org/abs/2501.00161</link>
      <description>arXiv:2501.00161v3 Announce Type: replace 
Abstract: The $H$-Induced Minor Containment problem ($H$-IMC) consists in deciding if a fixed graph $H$ is an induced minor of a graph $G$ given as input, that is, whether $H$ can be obtained from $G$ by deleting vertices and contracting edges. Equivalently, the problem asks if there exists an induced minor model of $H$ in $G$, that is, a collection of disjoint subsets of vertices of $G$, each inducing a connected subgraph, such that contracting each subgraph into a single vertex results in $H$.
  It is known that $H$-IMC is NP-complete for several graphs $H$, even when $H$ is a tree. In this work, we investigate which properties of $H$ guarantee the existence of an induced minor model whose structure can be leveraged to solve the problem in polynomial time. This allows us to identify four infinite families of graphs $H$ that enjoy such properties. Moreover, we show that if the input graph $G$ excludes long induced paths, then $H$-IMC is polynomial-time solvable for any fixed graph $H$. As a byproduct of our results, this implies that $H$-IMC is polynomial-time solvable for all graphs $H$ with at most $5$ vertices, except for three open cases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.00161v3</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cl\'ement Dallard, Ma\"el Dumas, Claire Hilaire, Anthony Perez</dc:creator>
    </item>
    <item>
      <title>The Planted Spanning Tree Problem</title>
      <link>https://arxiv.org/abs/2502.08790</link>
      <description>arXiv:2502.08790v2 Announce Type: replace 
Abstract: We study the problem of detecting and recovering a planted spanning tree $M_n^*$ hidden within a complete, randomly weighted graph $G_n$. Specifically, each edge $e$ has a non-negative weight drawn independently from $P_n$ if $e \in M_n^*$ and from $Q_n$ otherwise, where $P_n \equiv P$ is fixed and $Q_n$ scales with $n$ such that its density at the origin satisfies $\lim_{n\to\infty} n Q'_n(0)=1.$ We consider two representative cases: when $M_n^*$ is either a uniform spanning tree or a uniform Hamiltonian path. We analyze the recovery performance of the minimum spanning tree (MST) algorithm and derive a fixed-point equation that characterizes the asymptotic fraction of edges in $M_n^*$ successfully recovered by the MST as $n \to \infty.$ Furthermore, we establish the asymptotic mean weight of the MST, extending Frieze's $\zeta(3)$ result to the planted model. Leveraging this result, we design an efficient test based on the MST weight and show that it can distinguish the planted model from the unplanted model with vanishing testing error as $n \to \infty.$ Our analysis relies on an asymptotic characterization of the local structure of the planted model, employing the framework of local weak convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.08790v2</guid>
      <category>cs.DS</category>
      <category>cs.DM</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mehrdad Moharrami, Cristopher Moore, Jiaming Xu</dc:creator>
    </item>
    <item>
      <title>Approximate $2$-hop neighborhoods on incremental graphs: An efficient lazy approach</title>
      <link>https://arxiv.org/abs/2502.19205</link>
      <description>arXiv:2502.19205v2 Announce Type: replace 
Abstract: In this work, we propose, analyze and empirically validate a lazy-update approach to maintain accurate approximations of the $2$-hop neighborhoods of dynamic graphs resulting from sequences of edge insertions.
  We first show that under random input sequences, our algorithm exhibits an optimal trade-off between accuracy and insertion cost: it only performs $O(\frac{1}{\varepsilon})$ (amortized) updates per edge insertion, while the estimated size of any vertex's $2$-hop neighborhood is at most a factor $\varepsilon$ away from its true value in most cases, regardless of the underlying graph topology and for any $\varepsilon &gt; 0$.
  As a further theoretical contribution, we explore adversarial scenarios that can force our approach into a worst-case behavior at any given time $t$ of interest. We show that while worst-case input sequences do exist, a necessary condition for them to occur is that the girth of the graph released up to time $t$ be at most $4$.
  Finally, we conduct extensive experiments on a collection of real, incremental social networks of different sizes, which typically have low girth. Empirical results are consistent with and typically better than our theoretical analysis anticipates. This further supports the robustness of our theoretical findings: forcing our algorithm into a worst-case behavior not only requires topologies characterized by a low girth, but also carefully crafted input sequences that are unlikely to occur in practice.
  Combined with standard sketching techniques, our lazy approach proves an effective and efficient tool to support key neighborhood queries on large, incremental graphs, including neighborhood size, Jaccard similarity between neighborhoods and, in general, functions of the union and/or intersection of $2$-hop neighborhoods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.19205v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Luca Becchetti, Andrea Clementi, Luciano Gual\`a, Luca Pep\`e Sciarria, Alessandro Straziota, Matteo Stromieri</dc:creator>
    </item>
    <item>
      <title>Fast online node labeling with graph subsampling</title>
      <link>https://arxiv.org/abs/2503.16755</link>
      <description>arXiv:2503.16755v2 Announce Type: replace 
Abstract: Large data applications rely on storing data in massive, sparse graphs with millions to trillions of nodes. Graph-based methods, such as node prediction, aim for computational efficiency regardless of graph size. Techniques like localized approximate personalized page rank (APPR) solve sparse linear systems with complexity independent of graph size, but is in terms of the maximum node degree, which can be much larger in practice than the average node degree for real-world large graphs. In this paper, we consider an \emph{online subsampled APPR method}, where messages are intentionally dropped at random. We use tools from graph sparsifiers and matrix linear algebra to give approximation bounds on the graph's spectral properties ($O(1/\epsilon^2)$ edges), and node classification performance (added $O(n\epsilon)$ overhead).</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.16755v2</guid>
      <category>cs.DS</category>
      <category>cs.LG</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yushen Huang, Ertai Luo, Reza Babenezhad, Yifan Sun</dc:creator>
    </item>
    <item>
      <title>Online Metric TSP</title>
      <link>https://arxiv.org/abs/2504.17716</link>
      <description>arXiv:2504.17716v3 Announce Type: replace 
Abstract: In the online metric traveling salesperson problem, $n$ points of a metric space arrive one by one and have to be placed (immediately and irrevocably) into empty cells of a size-$n$ array. The goal is to minimize the sum of distances between consecutive points in the array. This problem was introduced by Abrahamsen, Bercea, Beretta, Klausen, and Kozma [ESA'24] as a generalization of the online sorting problem, which was introduced by Aamand, Abrahamsen, Beretta, and Kleist [SODA'23] as a tool in their study of online geometric packing problems.
  Online metric TSP has been studied for a range of fixed metric spaces. For 1-dimensional Euclidean space, the problem is equivalent to online sorting, where an optimal competitive ratio of $\Theta(\sqrt n)$ is known. For $d$-dimensional Euclidean space, the best-known upper bound is $O(2^{d} \sqrt{dn\log n})$, leaving a gap to the $\Omega(\sqrt n)$ lower bound. Finally, for the uniform metric, where all distances are 0 or 1, the optimal competitive ratio is known to be $\Theta(\log n)$.
  We study the problem for a general metric space, presenting an algorithm with competitive ratio $O(\sqrt n)$. In particular, we close the gap for $d$-dimensional Euclidean space, completely removing the dependence on dimension. One might hope to simultaneously guarantee competitive ratio $O(\sqrt n)$ in general and $O(\log n)$ for the uniform metric, but we show that this is impossible.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.17716v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Bertram</dc:creator>
    </item>
    <item>
      <title>Faster Dynamic $(\Delta+1)$-Coloring Against Adaptive Adversaries</title>
      <link>https://arxiv.org/abs/2504.19729</link>
      <description>arXiv:2504.19729v2 Announce Type: replace 
Abstract: We consider the problem of maintaining a proper $(\Delta + 1)$-vertex coloring in a graph on $n$-vertices and maximum degree $\Delta$ undergoing edge insertions and deletions. We give a randomized algorithm with amortized update time $\widetilde{O}( n^{2/3} )$ against adaptive adversaries, meaning that updates may depend on past decisions by the algorithm. This improves on the very recent $\widetilde{O}( n^{8/9} )$-update-time algorithm by Behnezhad, Rajaraman, and Wasim (SODA 2025) and matches a natural barrier for dynamic $(\Delta+1)$-coloring algorithms. The main improvements are in the densest regions of the graph, where we use structural hints from the study of distributed graph algorithms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.19729v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Maxime Flin, Magn\'us M. Halld\'orsson</dc:creator>
    </item>
    <item>
      <title>Unsolvability and Beyond in Many-To-Many Non-Bipartite Stable Matching</title>
      <link>https://arxiv.org/abs/2505.11456</link>
      <description>arXiv:2505.11456v2 Announce Type: replace 
Abstract: We study the Stable Fixtures problem, a many-to-many generalisation of the classical non-bipartite Stable Roommates matching problem. Building on the foundational work of Tan on stable partitions, we extend his results to this significantly more general setting and develop a rich framework for understanding stable structures in many-to-many contexts. Our main contribution, the notion of a generalised stable partition (GSP), not only characterises the solution space of this problem, but also serves as a versatile tool for reasoning about ordinal preference systems with capacity constraints.
  We show that a GSP can be computed efficiently and and can provide an elegant representation of key aspects of a preference system. Leveraging a connection to stable half-matchings, we also establish a non-bipartite analogue of the Rural Hospitals Theorem for stable half-matchings and GSPs, and connect our results to recent work on near-feasible matchings, providing a simpler algorithm and tighter analysis for this problem.
  Our work also addresses the computational challenges of finding optimal stable half-matchings and GSPs, presenting a flexible integer linear programming model for various objectives. Beyond theoretical insights, we conduct the first empirical analysis of random Stable Fixtures instances, uncovering surprising results, such as the impact of capacity functions on the solvability likelihood. Our work not only unifies and extends classical and recent perspectives on stability in non-bipartite stable matching but also establishes new tools, techniques, and directions for advancing the study of stable matchings and their applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11456v2</guid>
      <category>cs.DS</category>
      <category>cs.GT</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Frederik Glitzner, David Manlove</dc:creator>
    </item>
    <item>
      <title>LMQ-Sketch: Lagom Multi-Query Sketch for High-Rate Online Analytics</title>
      <link>https://arxiv.org/abs/2506.16928</link>
      <description>arXiv:2506.16928v2 Announce Type: replace 
Abstract: Data sketches balance resource efficiency with controllable approximations for extracting features in high-volume, high-rate data. Two important points of interest are highlighted separately in recent works; namely, to (1) answer multiple types of queries from one pass, and (2) query concurrently with updates. Several fundamental challenges arise when integrating these directions, which we tackle in this work. We investigate the trade-offs to be balanced and synthesize key ideas into LMQ-Sketch, a single, composite data sketch supporting multiple queries (frequency point queries, frequency moments F1, and F2) concurrently with updates. Our method 'Lagom' is a cornerstone of LMQ-Sketch for low-latency global querying (&lt;100 us), combining freshness, timeliness, and accuracy with a low memory footprint and high throughput (&gt;2B updates/s). We analyze and evaluate the accuracy of Lagom, which builds on a simple geometric argument and efficiently combines work distribution with synchronization for proper concurrency semantics -- monotonicity of operations and intermediate value linearizability. Comparing with state-of-the-art methods (which, as mentioned, only cover either mixed queries or concurrency), LMQ-Sketch shows highly competitive throughput, with additional accuracy guarantees and concurrency semantics, while also reducing the required memory budget by an order of magnitude. We expect the methodology to have broader impact on concurrent multi-query sketches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.16928v2</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martin Hilgendorf, Marina Papatriantafilou</dc:creator>
    </item>
    <item>
      <title>Review of Three Variants of the k-d Tree</title>
      <link>https://arxiv.org/abs/2506.20687</link>
      <description>arXiv:2506.20687v3 Announce Type: replace 
Abstract: The original description of the k-d tree recognized that rebalancing techniques, such as used to build an AVL tree or a red-black tree, are not applicable to a k-d tree. Hence, in order to build a balanced k-d tree, it is necessary to find the median of a set of data for each recursive subdivision of that set. The sort or selection used to find the median, and the technique used to partition the set about that median, strongly influence the computational complexity of building a k-d tree. This article describes and contrasts three variants of the k-d tree that differ in their technique used to partition the set, and compares the performance of those variants. In addition, dual-threaded execution is proposed and analyzed for one of the three variants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.20687v3</guid>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Russell A. Brown</dc:creator>
    </item>
    <item>
      <title>Dominating Set Knapsack: Profit Optimization on Dominating Sets</title>
      <link>https://arxiv.org/abs/2506.24032</link>
      <description>arXiv:2506.24032v2 Announce Type: replace 
Abstract: In a large-scale network, we want to choose some influential nodes to make a profit by paying some cost within a limited budget so that we do not have to spend more budget on some nodes adjacent to the chosen nodes; our problem is the graph-theoretic representation of it. We define our problem Dominating Set Knapsack by attaching Knapsack Problem with Dominating Set on graphs. Each vertex is associated with a cost factor and a profit amount. We aim to choose some vertices within a fixed budget that gives maximum profit so that we do not need to choose their 1-hop neighbors. We show that the Dominating Set Knapsack problem is strongly NP-complete even when restricted to Bipartite graphs but weakly NP-complete for Star graphs. We present a pseudo-polynomial time algorithm for Trees in time $O(n\cdot min\{s^2, (\alpha(V))^2\})$. We show that Dominating Set Knapsack is very unlikely to be Fixed Parameter Tractable(FPT) by proving that it is in W[2]-hard parameterized by the solution size. We developed FPT algorithms with running time $O(4^{tw}\cdot n^{O(1)} \cdot min\{s^2, ((\alpha(V))^2\})$ and $O(2^{vck-1}\cdot n^{O(1)} \cdot min\{s^2,(\alpha(V))^2\})$, where $tw$ represents the treewidth of the given graph, $vck$ is the solution size of the Vertex Cover Knapsack, $s$ is the size of the knapsack and $\alpha(V)=\sum_{v\in V}\alpha(v)$. We obtained similar results for other variants k-Dominating Set Knapsack and Minimal Dominating Set Knapsack. We obtained similar results for other variants k-Dominating Set Knapsack and Minimal Dominating Set Knapsack.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24032v2</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sipra Singh</dc:creator>
    </item>
    <item>
      <title>A Tensor Network based Decision Diagram for Representation of Quantum Circuits</title>
      <link>https://arxiv.org/abs/2009.02618</link>
      <description>arXiv:2009.02618v3 Announce Type: replace-cross 
Abstract: Tensor networks have been successfully applied in simulation of quantum physical systems for decades. Recently, they have also been employed in classical simulation of quantum computing, in particular, random quantum circuits. This paper proposes a decision diagram style data structure, called TDD (Tensor Decision Diagram), for more principled and convenient applications of tensor networks. This new data structure provides a compact and canonical representation for quantum circuits. By exploiting circuit partition, the TDD of a quantum circuit can be computed efficiently. Furthermore, we show that the operations of tensor networks essential in their applications (e.g., addition and contraction), can also be implemented efficiently in TDDs. A proof-of-concept implementation of TDDs is presented and its efficiency is evaluated on a set of benchmark quantum circuits. It is expected that TDDs will play an important role in various design automation tasks related to quantum circuits, including but not limited to equivalence checking, error detection, synthesis, simulation, and verification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2009.02618v3</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xin Hong, Xiangzhen Zhou, Sanjiang Li, Yuan Feng, Mingsheng Ying</dc:creator>
    </item>
    <item>
      <title>Sharp Thresholds for the Overlap Gap Property: Ising $p$-Spin Glass and Random $k$-SAT</title>
      <link>https://arxiv.org/abs/2309.09913</link>
      <description>arXiv:2309.09913v2 Announce Type: replace-cross 
Abstract: The Ising $p$-spin glass and random $k$-SAT are two canonical examples of disordered systems that play a central role in understanding the link between geometric features of optimization landscapes and computational tractability. Both models exhibit hard regimes where all known polynomial-time algorithms fail and possess the multi Overlap Gap Property ($m$-OGP), an intricate geometrical property that rigorously rules out a broad class of algorithms exhibiting input stability.
  We establish that, in both models, the symmetric $m$-OGP undergoes a sharp phase transition, and we pinpoint its exact threshold. For the Ising $p$-spin glass, our results hold for all sufficiently large $p$; for the random $k$-SAT, they apply to all $k$ growing mildly with the number of Boolean variables. Notably, our findings yield qualitative insights into the power of OGP-based arguments. A particular consequence for the Ising $p$-spin glass is that the strength of the $m$-OGP in establishing algorithmic hardness grows without bound as $m$ increases.
  These are the first sharp threshold results for the $m$-OGP. Our analysis hinges on a judicious application of the second moment method, enhanced by concentration. While a direct second moment calculation fails, we overcome this via a refined approach that leverages an argument of~\cite{frieze1990independence} and exploiting concentration properties of carefully constructed random variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.09913v2</guid>
      <category>math.PR</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <category>math-ph</category>
      <category>math.MP</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Eren C. K{\i}z{\i}lda\u{g}</dc:creator>
    </item>
    <item>
      <title>Quantum Realization of the Finite Element Method</title>
      <link>https://arxiv.org/abs/2403.19512</link>
      <description>arXiv:2403.19512v4 Announce Type: replace-cross 
Abstract: This paper presents a quantum algorithm for the solution of prototypical second-order linear elliptic partial differential equations discretized by $d$-linear finite elements on Cartesian grids of a bounded $d$-dimensional domain. An essential step in the construction is a BPX preconditioner, which transforms the linear system into a sufficiently well-conditioned one, making it amenable to quantum computation. We provide a constructive proof demonstrating that, for any fixed dimension, our quantum algorithm can compute suitable functionals of the solution to a given tolerance $\mathtt{tol}$ with an optimal complexity of order $\mathtt{tol}^{-1}$ up to logarithmic terms, significantly improving over existing approaches. Notably, this approach does not rely on regularity of the solution and achieves quantum advantage over classical solvers in two dimensions, whereas prior quantum methods required at least four dimensions for asymptotic benefits. We further detail the design and implementation of a quantum circuit capable of executing our algorithm, present simulator results, and report numerical experiments on current quantum hardware, confirming the feasibility of preconditioned finite element methods for near-term quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.19512v4</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Matthias Deiml, Daniel Peterseim</dc:creator>
    </item>
    <item>
      <title>Classical Algorithms for Constant Approximation of the Ground State Energy of Local Hamiltonians</title>
      <link>https://arxiv.org/abs/2410.21833</link>
      <description>arXiv:2410.21833v3 Announce Type: replace-cross 
Abstract: We construct classical algorithms computing an approximation of the ground state energy of an arbitrary $k$-local Hamiltonian acting on $n$ qubits.
  We first consider the setting where a good ``guiding state'' is available, which is the main setting where quantum algorithms are expected to achieve an exponential speedup over classical methods. We show that a constant approximation (i.e., an approximation with constant relative accuracy) of the ground state energy can be computed classically in $\mathrm{poly}\left(1/\chi,n\right)$ time and $\mathrm{poly}(n)$ space, where $\chi$ denotes the overlap between the guiding state and the ground state (as in prior works in dequantization, we assume sample-and-query access to the guiding state). This gives a significant improvement over the recent classical algorithm by Gharibian and Le Gall (SICOMP 2023), and matches (up a to polynomial overhead) both the time and space complexities of quantum algorithms for constant approximation of the ground state energy. We also obtain classical algorithms for higher-precision approximation.
  For the setting where no guided state is given (i.e., the standard version of the local Hamiltonian problem), we obtain a classical algorithm computing a constant approximation of the ground state energy in $2^{O(n)}$ time and $\mathrm{poly}(n)$ space. To our knowledge, before this work it was unknown how to classically achieve these bounds simultaneously, even for constant approximation. We also discuss complexity-theoretic aspects of our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.21833v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fran\c{c}ois Le Gall</dc:creator>
    </item>
    <item>
      <title>Unstructured Adiabatic Quantum Optimization: Optimality with Limitations</title>
      <link>https://arxiv.org/abs/2411.05736</link>
      <description>arXiv:2411.05736v3 Announce Type: replace-cross 
Abstract: In the circuit model of quantum computing, amplitude amplification techniques can be used to find solutions to NP-hard problems defined on $n$-bits in time $\text{poly}(n) 2^{n/2}$. In this work, we investigate whether such general statements can be made for adiabatic quantum optimization, as provable results regarding its performance are mostly unknown. Although a lower bound of $\Omega(2^{n/2})$ has existed in such a setting for over a decade, a purely adiabatic algorithm with this running time has been absent. We show that adiabatic quantum optimization using an unstructured search approach results in a running time that matches this lower bound (up to a polylogarithmic factor) for a broad class of classical local spin Hamiltonians. For this, it is necessary to bound the spectral gap throughout the adiabatic evolution and compute beforehand the position of the avoided crossing with sufficient precision so as to adapt the adiabatic schedule accordingly. However, we show that the position of the avoided crossing is approximately given by a quantity that depends on the degeneracies and inverse gaps of the problem Hamiltonian and is NP-hard to compute even within a low additive precision. Furthermore, computing it exactly (or nearly exactly) is \#P-hard. Our work indicates a possible limitation of adiabatic quantum optimization algorithms, leaving open the question of whether provable Grover-like speed-ups can be obtained for any optimization problem using this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.05736v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Arthur Braida, Shantanav Chakraborty, Alapan Chaudhuri, Joseph Cunningham, Rutvij Menavlikar, Leonardo Novo, J\'er\'emie Roland</dc:creator>
    </item>
    <item>
      <title>Towards Efficient Contrastive PAC Learning</title>
      <link>https://arxiv.org/abs/2502.15962</link>
      <description>arXiv:2502.15962v2 Announce Type: replace-cross 
Abstract: We study contrastive learning under the PAC learning framework. While a series of recent works have shown statistical results for learning under contrastive loss, based either on the VC-dimension or Rademacher complexity, their algorithms are inherently inefficient or not implying PAC guarantees. In this paper, we consider contrastive learning of the fundamental concept of linear representations. Surprisingly, even under such basic setting, the existence of efficient PAC learners is largely open. We first show that the problem of contrastive PAC learning of linear representations is intractable to solve in general. We then show that it can be relaxed to a semi-definite program when the distance between contrastive samples is measured by the $\ell_2$-norm. We then establish generalization guarantees based on Rademacher complexity, and connect it to PAC guarantees under certain contrastive large-margin conditions. To the best of our knowledge, this is the first efficient PAC learning algorithm for contrastive learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.15962v2</guid>
      <category>cs.LG</category>
      <category>cs.DS</category>
      <category>stat.ML</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jie Shen</dc:creator>
    </item>
    <item>
      <title>On estimating the quantum $\ell_{\alpha}$ distance</title>
      <link>https://arxiv.org/abs/2505.00457</link>
      <description>arXiv:2505.00457v2 Announce Type: replace-cross 
Abstract: We study the computational complexity of estimating the quantum $\ell_{\alpha}$ distance ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$, defined via the Schatten $\alpha$-norm $\|A\|_{\alpha} = \mathrm{tr}(|A|^{\alpha})^{1/\alpha}$, given $\operatorname{poly}(n)$-size state-preparation circuits of $n$-qubit quantum states $\rho_0$ and $\rho_1$. This quantity serves as a lower bound on the trace distance for $\alpha &gt; 1$. For any constant $\alpha &gt; 1$, we develop an efficient rank-independent quantum estimator for ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$ with time complexity $\operatorname{poly}(n)$, achieving an exponential speedup over the prior best results of $\exp(n)$ due to Wang, Guan, Liu, Zhang, and Ying (TIT 2024). Our improvement leverages efficiently computable uniform polynomial approximations of signed positive power functions within quantum singular value transformation, thereby eliminating the dependence on the rank of the quantum states.
  Our quantum algorithm reveals a dichotomy in the computational complexity of the Quantum State Distinguishability Problem with Schatten $\alpha$-norm (QSD$_{\alpha}$), which involves deciding whether ${\mathrm{T}_\alpha}(\rho_0,\rho_1)$ is at least $2/5$ or at most $1/5$. This dichotomy arises between the cases of constant $\alpha &gt; 1$ and $\alpha=1$:
  - For any $1+\Omega(1) \leq \alpha \leq O(1)$, QSD$_{\alpha}$ is $\mathsf{BQP}$-complete.
  - For any $1 \leq \alpha \leq 1+\frac{1}{n}$, QSD$_{\alpha}$ is $\mathsf{QSZK}$-complete, implying that no efficient quantum estimator for $\mathrm{T}_\alpha(\rho_0,\rho_1)$ exists unless $\mathsf{BQP} = \mathsf{QSZK}$.
  The hardness results follow from reductions based on new rank-dependent inequalities for the quantum $\ell_{\alpha}$ distance with $1\leq \alpha \leq \infty$, which are of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.00457v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yupan Liu, Qisheng Wang</dc:creator>
    </item>
    <item>
      <title>An Easy Proof of a Weak Version of Chernoff inequality</title>
      <link>https://arxiv.org/abs/2507.02759</link>
      <description>arXiv:2507.02759v2 Announce Type: replace-cross 
Abstract: We prove an easy but very weak version of Chernoff inequality. Namely, that the probability that in $6M$ throws of a fair coin, one gets at most $M$ heads is $\leq 1/2^M$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.02759v2</guid>
      <category>math.PR</category>
      <category>cs.DS</category>
      <category>math.CO</category>
      <pubDate>Tue, 08 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sariel Har-Peled</dc:creator>
    </item>
  </channel>
</rss>
