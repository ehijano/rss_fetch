<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 04 Jun 2025 01:54:16 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Empirical Validation of the Independent Chip Model</title>
      <link>https://arxiv.org/abs/2506.00180</link>
      <description>arXiv:2506.00180v1 Announce Type: new 
Abstract: The independent chip model (ICM) forms a cornerstone of all modern poker tournament strategy. However, despite its prominence, the ICM's performance in the real world has not been sufficiently scrutinized, especially at a large scale. In this paper, we introduce our new dataset of poker tournaments, consisting of results of over ten thousand events. Then, using this dataset, we perform two experiments as part of a large-scale empirical validation of the ICM. First, we verify that the ICM performs more accurately than a baseline we propose. Second, we obtain empirical evidence of the ICM underestimating the performances of players with larger stacks while overestimating those who are short-stacked. Our contributions may be useful to future researchers developing new algorithms for estimating a player's value in poker tournaments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00180v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Juho Kim</dc:creator>
    </item>
    <item>
      <title>Shill Bidding Prevention in Decentralized Auctions Using Smart Contracts</title>
      <link>https://arxiv.org/abs/2506.00282</link>
      <description>arXiv:2506.00282v1 Announce Type: new 
Abstract: In online auctions, fraudulent behaviors such as shill bidding pose significant risks. This paper presents a conceptual framework that applies dynamic, behavior-based penalties to deter auction fraud using blockchain smart contracts. Unlike traditional post-auction detection methods, this approach prevents manipulation in real-time by introducing an economic disincentive system where penalty severity scales with suspicious bidding patterns. The framework employs the proposed Bid Shill Score (BSS) to evaluate nine distinct bidding behaviors, dynamically adjusting the penalty fees to make fraudulent activity financially unaffordable while providing fair competition.
  The system is implemented within a decentralized English auction on the Ethereum blockchain, demonstrating how smart contracts enforce transparent auction rules without trusted intermediaries. Simulations confirm the effectiveness of the proposed model: the dynamic penalty mechanism reduces the profitability of shill bidding while keeping penalties low for honest bidders. Performance evaluation shows that the system introduces only moderate gas and latency overhead, keeping transaction costs and response times within practical bounds for real-world use. The approach provides a practical method for behaviour-based fraud prevention in decentralised systems where trust cannot be assumed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00282v1</guid>
      <category>cs.GT</category>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>M. A. Bouaicha, G. Destefanis, T. Montanaro, N. Lasla, L. Patrono</dc:creator>
    </item>
    <item>
      <title>Two-Sided Manipulation Games in Stable Matching Markets</title>
      <link>https://arxiv.org/abs/2506.00554</link>
      <description>arXiv:2506.00554v1 Announce Type: new 
Abstract: The Deferred Acceptance (DA) algorithm is an elegant procedure for finding a stable matching in two-sided matching markets. It ensures that no pair of agents prefers each other to their matched partners. In this work, we initiate the study of two-sided manipulations in matching markets as non-cooperative games. We introduce the accomplice manipulation game, where a man misreports to help a specific woman obtain a better partner, whenever possible. We provide a polynomial time algorithm for finding a pure strategy Nash equilibrium (NE) and show that our algorithm always yields a stable matching - although not every Nash equilibrium corresponds to a stable matching. Additionally, we show how our analytical techniques for the accomplice manipulation game can be applied to other manipulation games in matching markets, such as one-for-many and the standard self-manipulation games. We complement our theoretical findings with empirical evaluations of different properties of the resulting NE, such as the welfare of the agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00554v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hadi Hosseini, Grzegorz Lisowski, Shraddha Pathak</dc:creator>
    </item>
    <item>
      <title>The Disparate Effects of Partial Information in Bayesian Strategic Learning</title>
      <link>https://arxiv.org/abs/2506.00627</link>
      <description>arXiv:2506.00627v1 Announce Type: new 
Abstract: We study how partial information about scoring rules affects fairness in strategic learning settings. In strategic learning, a learner deploys a scoring rule, and agents respond strategically by modifying their features -- at some cost -- to improve their outcomes. However, in our work, agents do not observe the scoring rule directly; instead, they receive a noisy signal of said rule. We consider two different agent models: (i) naive agents, who take the noisy signal at face value, and (ii) Bayesian agents, who update a prior belief based on the signal.
  Our goal is to understand how disparities in outcomes arise between groups that differ in their costs of feature modification, and how these disparities vary with the level of transparency of the learner's rule. For naive agents, we show that utility disparities can grow unboundedly with noise, and that the group with lower costs can, perhaps counter-intuitively, be disproportionately harmed under limited transparency. In contrast, for Bayesian agents, disparities remain bounded. We provide a full characterization of disparities across groups as a function of the level of transparency and show that they can vary non-monotonically with noise; in particular, disparities are often minimized at intermediate levels of transparency. Finally, we extend our analysis to settings where groups differ not only in cost, but also in prior beliefs, and study how this asymmetry influences fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00627v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Srikanth Avasarala, Serena Wang, Juba Ziani</dc:creator>
    </item>
    <item>
      <title>Near-feasible Fair Allocations in Two-sided Markets</title>
      <link>https://arxiv.org/abs/2506.01178</link>
      <description>arXiv:2506.01178v1 Announce Type: new 
Abstract: We study resource allocation in two-sided markets from a fundamental perspective and introduce a general modeling and algorithmic framework to effectively incorporate the complex and multidimensional aspects of fairness. Our main technical contribution is to show the existence of a range of near-feasible resource allocations parameterized in different model primitives to give flexibility when balancing the different policymaking requirements, allowing policy designers to fix these values according to the specific application. To construct our near-feasible allocations, we start from a fractional resource allocation and perform an iterative rounding procedure to get an integer allocation. We show a simple yet flexible and strong sufficient condition for the target feasibility deviations to guarantee that the rounding procedure succeeds, exhibiting the underlying trade-offs between market capacities, agents' demand, and fairness. To showcase our framework's modeling and algorithmic capabilities, we consider three prominent market design problems: school allocation, stable matching with couples, and political apportionment. In each of them, we obtain strengthened guarantees on the existence of near-feasible allocations capturing the corresponding fairness notions, such as proportionality, envy-freeness, and stability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01178v1</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <category>math.OC</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Javier Cembrano, Andr\'es Moraga, Victor Verdugo</dc:creator>
    </item>
    <item>
      <title>General search techniques without common knowledge for imperfect-information games, and application to superhuman Fog of War chess</title>
      <link>https://arxiv.org/abs/2506.01242</link>
      <description>arXiv:2506.01242v1 Announce Type: new 
Abstract: Since the advent of AI, games have served as progress benchmarks. Meanwhile, imperfect-information variants of chess have existed for over a century, present extreme challenges, and have been the focus of significant AI research. Beyond calculation needed in regular chess, they require reasoning about information gathering, the opponent's knowledge, signaling, etc. The most popular variant, Fog of War (FoW) chess (aka. dark chess) is a recognized challenge problem in AI after superhuman performance was reached in no-limit Texas hold'em poker. We present Obscuro, the first superhuman AI for FoW chess. It introduces advances to search in imperfect-information games, enabling strong, scalable reasoning. Experiments against the prior state-of-the-art AI and human players -- including the world's best -- show that Obscuro is significantly stronger. FoW chess is the largest (by amount of imperfect information) turn-based game in which superhuman performance has been achieved and the largest game in which imperfect-information search has been successfully applied.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01242v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Brian Hu Zhang, Tuomas Sandholm</dc:creator>
    </item>
    <item>
      <title>A Reliable Vertical Federated Learning Framework for Traffic State Estimation with Data Selection and Incentive Mechanisms</title>
      <link>https://arxiv.org/abs/2506.01285</link>
      <description>arXiv:2506.01285v1 Announce Type: new 
Abstract: Vertical Federated Learning (VFL)-based Traffic State Estimation (TSE) offers a promising approach for integrating vertically distributed traffic data from municipal authorities (MA) and mobility providers (MP) while safeguarding privacy. However, given the variations in MPs' data collection capabilities and the potential for MPs to underperform in data provision, we propose a reliable VFL-based TSE framework that ensures model reliability during training and operation. The proposed framework comprises two components: data provider selection and incentive mechanism design. Data provider selection is conducted in three stages to identify the most qualified MPs for VFL model training with the MA. First, the MA partitions the transportation network into road segments. Then, a mutual information (MI) model is trained for each segment to capture the relationship between data and labels. Finally, using a sampling strategy and the MI model, the MA assesses each MP's competence in data provision and selects the most qualified MP for each segment. For the incentive mechanism design, given the MA can leverage the MI mode to inspect the data quality of MP, we formulate the interaction between MA and MP as a supervision game model. Upon this, we devise a penalty-based incentive mechanism to inhibit the lazy probability of MP, thereby guaranteeing the utility of MA. Numerical simulation on real-world datasets showcased that our proposed framework augments the traffic flow and density prediction accuracy by 11.23\% and 23.15\% and elevates the utility of MA by 130$\sim$400\$ compared to the benchmark.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01285v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Zijun Zhan, Yaxian Dong, Daniel Mawunyo Doe, Yuqing Hu, Shuai Li, Shaohua Cao, Zhu Han</dc:creator>
    </item>
    <item>
      <title>Polynomial Expectation Property for Max-Polymatrix Games</title>
      <link>https://arxiv.org/abs/2506.01343</link>
      <description>arXiv:2506.01343v1 Announce Type: new 
Abstract: We address an open question which addresses the computability of correlated equilibria in a variant of polymatrix where each player's utility is the maximum of their edge payoffs. We demonstrate that this max-variant game has the polynomial expectation property, and conclude that there indeed exists a polynomial correlated equilibrium scheme.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01343v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Howard Dai</dc:creator>
    </item>
    <item>
      <title>Geometry Meets Incentives: Sample-Efficient Incentivized Exploration with Linear Contexts</title>
      <link>https://arxiv.org/abs/2506.01685</link>
      <description>arXiv:2506.01685v1 Announce Type: new 
Abstract: In the incentivized exploration model, a principal aims to explore and learn over time by interacting with a sequence of self-interested agents. It has been recently understood that the main challenge in designing incentive-compatible algorithms for this problem is to gather a moderate amount of initial data, after which one can obtain near-optimal regret via posterior sampling. With high-dimensional contexts, however, this \emph{initial exploration} phase requires exponential sample complexity in some cases, which prevents efficient learning unless initial data can be acquired exogenously. We show that these barriers to exploration disappear under mild geometric conditions on the set of available actions, in which case incentive-compatibility does not preclude regret-optimality. Namely, we consider the linear bandit model with actions in the Euclidean unit ball, and give an incentive-compatible exploration algorithm with sample complexity that scales polynomially with the dimension and other parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01685v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Benjamin Schiffer, Mark Sellke</dc:creator>
    </item>
    <item>
      <title>The Complexity of Correlated Equilibria in Generalized Games</title>
      <link>https://arxiv.org/abs/2506.01899</link>
      <description>arXiv:2506.01899v1 Announce Type: new 
Abstract: Correlated equilibria -- and their generalization $\Phi$-equilibria -- are a fundamental object of study in game theory, offering a more tractable alternative to Nash equilibria in multi-player settings. While computational aspects of equilibrium computation are well-understood in some settings, fundamental questions are still open in generalized games, that is, games in which the set of strategies allowed to each player depends on the other players' strategies. These classes of games model fundamental settings in economics and have been a cornerstone of economics research since the seminal paper of Arrow and Debreu [1954]. Recently, there has been growing interest, both in economics and in computer science, in studying correlated equilibria in generalized games. It is known that finding a social welfare maximizing correlated equilibrium in generalized games is NP-hard. However, the existence of efficient algorithms to find any equilibrium remains an important open question. In this paper, we answer this question negatively, showing that this problem is PPAD-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01899v1</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Martino Bernasconi, Matteo Castiglioni, Andrea Celli, Gabriele Farina</dc:creator>
    </item>
    <item>
      <title>Online Competitive Information Gathering for Partially Observable Trajectory Games</title>
      <link>https://arxiv.org/abs/2506.01927</link>
      <description>arXiv:2506.01927v1 Announce Type: new 
Abstract: Game-theoretic agents must make plans that optimally gather information about their opponents. These problems are modeled by partially observable stochastic games (POSGs), but planning in fully continuous POSGs is intractable without heavy offline computation or assumptions on the order of belief maintained by each player. We formulate a finite history/horizon refinement of POSGs which admits competitive information gathering behavior in trajectory space, and through a series of approximations, we present an online method for computing rational trajectory plans in these games which leverages particle-based estimations of the joint state space and performs stochastic gradient play. We also provide the necessary adjustments required to deploy this method on individual agents. The method is tested in continuous pursuit-evasion and warehouse-pickup scenarios (alongside extensions to $N &gt; 2$ players and to more complex environments with visual and physical obstacles), demonstrating evidence of active information gathering and outperforming passive competitors.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01927v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mel Krusniak, Hang Xu, Parker Palermo, Forrest Laine</dc:creator>
    </item>
    <item>
      <title>Should Decision-Makers Reveal Classifiers in Online Strategic Classification?</title>
      <link>https://arxiv.org/abs/2506.01936</link>
      <description>arXiv:2506.01936v1 Announce Type: new 
Abstract: Strategic classification addresses a learning problem where a decision-maker implements a classifier over agents who may manipulate their features in order to receive favorable predictions. In the standard model of online strategic classification, in each round, the decision-maker implements and publicly reveals a classifier, after which agents perfectly best respond based on this knowledge. However, in practice, whether to disclose the classifier is often debated -- some decision-makers believe that hiding the classifier can prevent misclassification errors caused by manipulation.
  In this paper, we formally examine how limiting the agents' access to the current classifier affects the decision-maker's performance. Specifically, we consider an extended online strategic classification setting where agents lack direct knowledge about the current classifier and instead manipulate based on a weighted average of historically implemented classifiers. Our main result shows that in this setting, the decision-maker incurs $(1-\gamma)^{-1}$ or $k_{\text{in}}$ times more mistakes compared to the full-knowledge setting, where $k_{\text{in}}$ is the maximum in-degree of the manipulation graph (representing how many distinct feature vectors can be manipulated to appear as a single one), and $\gamma$ is the discount factor indicating agents' memory of past classifiers. Our results demonstrate how withholding access to the classifier can backfire and degrade the decision-maker's performance in online strategic classification.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01936v1</guid>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Han Shao, Shuo Xie, Kunhe Yang</dc:creator>
    </item>
    <item>
      <title>Reinforcement Learning for Hanabi</title>
      <link>https://arxiv.org/abs/2506.00458</link>
      <description>arXiv:2506.00458v1 Announce Type: cross 
Abstract: Hanabi has become a popular game for research when it comes to reinforcement learning (RL) as it is one of the few cooperative card games where you have incomplete knowledge of the entire environment, thus presenting a challenge for a RL agent. We explored different tabular and deep reinforcement learning algorithms to see which had the best performance both against an agent of the same type and also against other types of agents. We establish that certain agents played their highest scoring games against specific agents while others exhibited higher scores on average by adapting to the opposing agent's behavior. We attempted to quantify the conditions under which each algorithm provides the best advantage and identified the most interesting interactions between agents of different types. In the end, we found that temporal difference (TD) algorithms had better overall performance and balancing of play types compared to tabular agents. Specifically, tabular Expected SARSA and deep Q-Learning agents showed the best performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00458v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Nina Cohen, Kordel K. France</dc:creator>
    </item>
    <item>
      <title>Reasoning Like an Economist: Post-Training on Economic Problems Induces Strategic Generalization in LLMs</title>
      <link>https://arxiv.org/abs/2506.00577</link>
      <description>arXiv:2506.00577v1 Announce Type: cross 
Abstract: Directly training Large Language Models (LLMs) for Multi-Agent Systems (MAS) remains challenging due to intricate reward modeling, dynamic agent interactions, and demanding generalization requirements. This paper explores whether post-training techniques, specifically Supervised Fine-Tuning (SFT) and Reinforcement Learning with Verifiable Rewards (RLVR), can effectively $\textit{generalize}$ to multi-agent scenarios. We use economic reasoning as a testbed, leveraging its strong foundations in mathematics and game theory, its demand for structured analytical reasoning, and its relevance to real-world applications such as market design, resource allocation, and policy analysis. We introduce $\textbf{Recon}$ ($\textbf{R}$easoning like an $\textbf{ECON}$omist), a 7B-parameter open-source LLM post-trained on a hand-curated dataset of 2,100 high-quality economic reasoning problems. Comprehensive evaluation on economic reasoning benchmarks and multi-agent games reveals clear improvements in structured reasoning and economic rationality. These results underscore the promise of domain-aligned post-training for enhancing reasoning and agent alignment, shedding light on the roles of SFT and RL in shaping model behavior. Code is available at https://github.com/MasterZhou1/Recon .</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.00577v1</guid>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yufa Zhou, Shaobo Wang, Xingyu Dong, Xiangqi Jin, Yifang Chen, Yue Min, Kexin Yang, Xingzhang Ren, Dayiheng Liu, Linfeng Zhang</dc:creator>
    </item>
    <item>
      <title>Higher-Order Responsibility</title>
      <link>https://arxiv.org/abs/2506.01003</link>
      <description>arXiv:2506.01003v1 Announce Type: cross 
Abstract: In ethics, individual responsibility is often defined through Frankfurt's principle of alternative possibilities. This definition is not adequate in a group decision-making setting because it often results in the lack of a responsible party or "responsibility gap''. One of the existing approaches to address this problem is to consider group responsibility. Another, recently proposed, approach is "higher-order'' responsibility. The paper considers the problem of deciding if higher-order responsibility up to degree $d$ is enough to close the responsibility gap. The main technical result is that this problem is $\Pi_{2d+1}$-complete.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01003v1</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junli Jiang, Pavel Naumov</dc:creator>
    </item>
    <item>
      <title>Formal Security Analysis of SPV Clients Versus Home-Based Full Nodes in Bitcoin-Derived Systems</title>
      <link>https://arxiv.org/abs/2506.01384</link>
      <description>arXiv:2506.01384v1 Announce Type: cross 
Abstract: This paper presents a mathematically rigorous formal analysis of Simplified Payment Verification (SPV) clients, as specified in Section 8 of the original Bitcoin white paper, versus non-mining full nodes operated by home users. It defines security as resistance to divergence from global consensus and models transaction acceptance, enforcement capability, and divergence probability under adversarial conditions. The results demonstrate that SPV clients, despite omitting script verification, are cryptographically sufficient under honest-majority assumptions and topologically less vulnerable to attack than structurally passive, non-enforcing full nodes. The paper introduces new axioms on behavioral divergence and communication topology, proving that home-based full nodes increase systemic entropy without contributing to consensus integrity. Using a series of formally defined lemmas, propositions, and Monte Carlo simulation results, it is shown that SPV clients represent the rational equilibrium strategy for non-mining participants. This challenges the prevailing narrative that home validators enhance network security, providing formal and operational justifications for the sufficiency of SPV models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01384v1</guid>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <category>cs.GT</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Craig Steven Wright</dc:creator>
    </item>
    <item>
      <title>Approximability Landscape of Welfare Maximization within Fair Allocations</title>
      <link>https://arxiv.org/abs/2205.14296</link>
      <description>arXiv:2205.14296v3 Announce Type: replace 
Abstract: Fair allocation of indivisible goods studies allocating $m$ goods among $n$ agents in a fair manner. While fairness is a fundamental requirement in many real-world applications, it often conflicts with (economic) efficiency. This raises a natural and important question: How can we identify the most welfare-efficient allocation among all fair allocations? This paper answers from the perspective of computational complexity. Specifically, we study the problem of maximizing utilitarian social welfare under two widely studied fairness criteria: envy-freeness up to any item (EFX) and envy-freeness up to one item (EF1). We examine both normalized and unnormalized valuations, where normalized valuations require that each agent's total utility for all items is identical.
  The key contributions of this paper can be summarized as follows: (i) we sketch the complete complexity landscape of welfare maximization subject to fair allocation constraints; and (ii) we provide interesting bounds on the price of fairness for both EFX and EF1. Specifically: (1) For $n=2$ agents, we develop polynomial-time approximation schemes (PTAS) and provide NP-hardness results for EFX and EF1 constraints; (2) For $n&gt;2$ agents, under EFX constraints, we design algorithms that achieve approximation ratios of $O(n)$ and $O(\sqrt{n})$ for unnormalized and normalized valuations, respectively. These results are complemented by asymptotically tight inapproximability results. We also obtain similar results for EF1 constraints; (3) When the number of agents is a fixed constant, we show that the optimal solution can be computed in polynomial time by slightly relaxing the fairness constraints, whereas exact fairness leads to strong inapproximability; (4) Furthermore, our results imply the price of EFX is $\Theta(\sqrt{n})$ for normalized valuations, which is unknown in the literature.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.14296v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaolin Bu, Zihao Li, Shengxin Liu, Jiaxin Song, Biaoshuai Tao</dc:creator>
    </item>
    <item>
      <title>Data Monetization through Strategic Coordination of Privately Informed Agents</title>
      <link>https://arxiv.org/abs/2302.12223</link>
      <description>arXiv:2302.12223v2 Announce Type: replace 
Abstract: We consider linear-quadratic games of incomplete information with Gaussian uncertainty, in which players' payoffs depend both on a privately observed type and an unknown but common state. A monopolist data platform observes the state, elicits the players' types, and sells information back to them via (possibly correlated) action recommendations. We fully characterize the class of all such implementable Gaussian mechanisms (where the joint distribution of actions and signals is multivariate normal) as well as the player-optimal and revenue-maximizing mechanisms within this class. For games of strategic complements (substitutes), both optimal mechanisms maximally correlate (anticorrelate) the players' actions. When uncertainty over private types is large, the recommendations are deterministic and linear functions of the state and reported types but are not fully revealing. We apply our results to algorithmic pricing recommendations used by platforms such as Amazon and those challenged in U.S. v. RealPage.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.12223v2</guid>
      <category>cs.GT</category>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alessandro Bonatti, Munther A. Dahleh, Thibaut Horel</dc:creator>
    </item>
    <item>
      <title>Robust Stackelberg Equilibria</title>
      <link>https://arxiv.org/abs/2304.14990</link>
      <description>arXiv:2304.14990v3 Announce Type: replace 
Abstract: This paper provides a systematic study of the robust Stackelberg equilibrium (RSE), which naturally generalizes the widely adopted solution concept of the strong Stackelberg equilibrium (SSE). The RSE accounts for any possible up-to-$\delta$ suboptimal follower responses in Stackelberg games and is adopted to improve the robustness of the leader's strategy. While a few variants of robust Stackelberg equilibrium have been considered in previous literature, the RSE solution concept we consider is importantly different -- in some sense, it relaxes previously studied robust Stackelberg strategies and is applicable to much broader sources of uncertainties.
  We provide a thorough investigation of several fundamental properties of RSE, including its utility guarantees, algorithmics, and learnability. We first show that the RSE we defined always exists and thus is well-defined. Then we characterize how the leader's utility in RSE changes with the robustness level considered. On the algorithmic side, we show that, in sharp contrast to the tractability of computing an SSE, it is NP-hard to obtain a fully polynomial approximation scheme (FPTAS) for any constant robustness level. Nevertheless, we develop a quasi-polynomial approximation scheme (QPTAS) for RSE. Finally, we examine the learnability of the RSE in a natural learning scenario, where both players' utilities are not known in advance, and provide almost tight sample complexity results on learning the RSE. As a corollary of this result, we also obtain an algorithm for learning SSE, which strictly improves a key result of Bai et al. [2021] in terms of both utility guarantee and computational efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.14990v3</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>econ.TH</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiarui Gan, Minbiao Han, Jibang Wu, Haifeng Xu</dc:creator>
    </item>
    <item>
      <title>When Should a Leader Act Suboptimally? The Role of Inferability in Repeated Stackelberg Games</title>
      <link>https://arxiv.org/abs/2310.00468</link>
      <description>arXiv:2310.00468v3 Announce Type: replace 
Abstract: When interacting with other decision-making agents in non-adversarial scenarios, it is critical for an autonomous agent to have inferable behavior: The agent's actions must convey their intention and strategy. We model the inferability problem using Stackelberg games with observations where a leader and a follower repeatedly interact. During the interactions, the leader uses a fixed mixed strategy. The follower does not know the leader's strategy and dynamically reacts to the statistically inferred strategy based on the leader's previous actions. In the inference setting, the leader may have a lower performance compared to the setting where the follower has full information on the leader's strategy. We refer to the performance gap between these settings as the inferability gap. For a variety of game settings, we show that the inferability gap is upper-bounded by a function of the number of interactions and the stochasticity level of the leader's strategy, encouraging the use of inferable strategies with lower stochasticity levels. We also analyze bimatrix Stackelberg games and identify a set of games where the leader's near-optimal strategy may potentially suffer from a large inferability gap.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.00468v3</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mustafa O. Karabag, Sophia Smith, Negar Mehr, David Fridovich-Keil, Ufuk Topcu</dc:creator>
    </item>
    <item>
      <title>Mixed Strategy Constraints in Continuous Games</title>
      <link>https://arxiv.org/abs/2402.17874</link>
      <description>arXiv:2402.17874v2 Announce Type: replace 
Abstract: When modeling robot interactions as Nash equilibrium problems, it is desirable to place coupled constraints which restrict these interactions to be safe and acceptable (for instance, to avoid collisions). Such games are continuous with potential mixed strategy equilibria, and this combination of characteristics means special care must be given to setting coupled constraints in a way that respects mixed strategies while remaining compatible with continuous game solution methods. Here, we investigate the problem of constraint-setting in this context, primarily focusing on a chance-based method. We first motivate these chance constraints in a discrete setting, placing them on n-player matrix games as a justifiable approach to handling the probabilistic nature of mixing. Then, we describe a numerical solution method for these chance constrained, continuous games with simultaneous pure strategy optimization. Finally, using a modified pursuit-evasion game as a motivating example, we demonstrate the actual behavior of this solution method in terms of its fidelity, parameter sensitivity, and efficiency</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17874v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mel Krusniak, Forrest Laine</dc:creator>
    </item>
    <item>
      <title>Proof of Sampling: A Nash Equilibrium-Based Verification Protocol for Decentralized Systems</title>
      <link>https://arxiv.org/abs/2405.00295</link>
      <description>arXiv:2405.00295v3 Announce Type: replace 
Abstract: This paper introduces the Proof of Sampling (PoSP) protocol, a Nash Equilibrium-based verification mechanism, and its application to decentralized machine learning inference through spML. Our protocol has a pure strategy Nash Equilibrium, compelling rational participants to act honestly. It economically disincentivizes dishonest behavior, making it costly for participants to compromise the network's integrity. In our spML protocol, we apply PoSP to decentralized inference for AI applications via a novel cryptographic protocol. The resulting protocol is much more efficient than zero knowledge proof based approaches. Moreover, we anticipate that the PoSP protocol could be effectively utilized for designing verification mechanisms within Actively Validated Services (AVS) in restaking solutions. We further expect that the PoSP protocol could be applied to a variety of other decentralized applications. Our approach enhances the reliability and efficiency of decentralized systems, paving the way for a new generation of decentralized applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00295v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yue Zhang, Shouqiao Wang, Sijun Tan, Xiaoyuan Liu, Ciamac C. Moallemi, Raluca Ada Popa</dc:creator>
    </item>
    <item>
      <title>Social Learning with Limited Attention: Negative Reviews Persist under Newest First</title>
      <link>https://arxiv.org/abs/2406.06929</link>
      <description>arXiv:2406.06929v3 Announce Type: replace 
Abstract: We study a model of social learning from reviews where customers are computationally limited and make purchases based on reading only the first few reviews displayed by the platform. Under this limited attention, we establish that the review ordering policy can have a significant impact. In particular, the popular Newest First ordering induces a negative review to persist as the most recent review longer than a positive review. This phenomenon, which we term the Cost of Newest First, can make the long-term revenue unboundedly lower than a counterpart where reviews are exogenously drawn for each customer.
  We show that the impact of the Cost of Newest First can be mitigated under dynamic pricing, which allows the price to depend on the set of displayed reviews. Under the optimal dynamic pricing policy, the revenue loss is at most a factor of 2. On the way, we identify a structural property for this optimal dynamic pricing: the prices should ensure that the probability of a purchase is always the same, regardless of the state of reviews. We also consider a setting where product quality evolves over time according to a Markov chain; we find that Newest First better tracks current quality but still leads to lower revenue, highlighting a trade-off between customer belief accuracy and revenue. Finally, we support our theoretical findings with numerical simulations and an empirical analysis on reviews from Tripadvisor.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.06929v3</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jackie Baek, Atanas Dinev, Thodoris Lykouris</dc:creator>
    </item>
    <item>
      <title>Distortion of Multi-Winner Elections on the Line Metric: The Polar Comparison Rule</title>
      <link>https://arxiv.org/abs/2411.13720</link>
      <description>arXiv:2411.13720v2 Announce Type: replace 
Abstract: We study the problem of selecting a committee of size $k$ from a set of $m$ alternatives, based solely on the ordinal preferences of voters. Both voters and alternatives lie on the line metric, and the goal is to minimize a social cost function based on metric distances. While the distances to committee members fully determine the social cost, voting rules only have access to the ordinal preference list of each voter. The distortion of a voting rule is the worst-case ratio between the cost of the selected committee and the cost of the optimal one, over all consistent distance metrics. Extending distortion to multi-winner elections requires defining how a voter's cost is aggregated over the committee. Caragiannis et al. (2022) studied $q$-cost, where the cost is defined as the distance to the voter's $q$th closest committee member. In this work, we focus on the additive cost, where a voter's cost is the sum of their distances to all committee members. The overall social cost is either utilitarian (sum of individual costs) or egalitarian (maximum individual cost).
  We introduce a new voting rule, the Polar Comparison Rule, and analyze its distortion for the utilitarian additive cost. We show that it achieves a distortion of roughly $7/3$ for any committee size $k$. More specifically, for $k = 2$ and $k = 3$, we establish tight bounds of $1 + \sqrt{2} \approx 2.41$ and $7/3 \approx 2.33$, respectively. Moreover, we provide lower bounds that depend on the parity of $k$, and analyze both small and large committee sizes. Finally, we study the egalitarian additive cost and analyze the distortion bounds in multi-winner elections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.13720v2</guid>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Negar Babashah, Hasti Karimi, Masoud Seddighin, Golnoosh Shahkarami</dc:creator>
    </item>
    <item>
      <title>Quantifying Misalignment Between Agents: Towards a Sociotechnical Understanding of Alignment</title>
      <link>https://arxiv.org/abs/2406.04231</link>
      <description>arXiv:2406.04231v4 Announce Type: replace-cross 
Abstract: Existing work on the alignment problem has focused mainly on (1) qualitative descriptions of the alignment problem; (2) attempting to align AI actions with human interests by focusing on value specification and learning; and/or (3) focusing on a single agent or on humanity as a monolith. Recent sociotechnical approaches highlight the need to understand complex misalignment among multiple human and AI agents. We address this gap by adapting a computational social science model of human contention to the alignment problem. Our model quantifies misalignment in large, diverse agent groups with potentially conflicting goals across various problem areas. Misalignment scores in our framework depend on the observed agent population, the domain in question, and conflict between agents' weighted preferences. Through simulations, we demonstrate how our model captures intuitive aspects of misalignment across different scenarios. We then apply our model to two case studies, including an autonomous vehicle setting, showcasing its practical utility. Our approach offers enhanced explanatory power for complex sociotechnical environments and could inform the design of more aligned AI systems in real-world applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.04231v4</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Tue, 03 Jun 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1609/aaai.v39i26.34947</arxiv:DOI>
      <dc:creator>Aidan Kierans, Avijit Ghosh, Hananel Hazan, Shiri Dori-Hacohen</dc:creator>
    </item>
  </channel>
</rss>
