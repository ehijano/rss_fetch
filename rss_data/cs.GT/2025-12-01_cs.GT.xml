<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.GT updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.GT</link>
    <description>cs.GT updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.GT" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 02 Dec 2025 03:47:34 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Tacit Bidder-Side Collusion: Artificial Intelligence in Dynamic Auctions</title>
      <link>https://arxiv.org/abs/2511.21802</link>
      <description>arXiv:2511.21802v1 Announce Type: new 
Abstract: We study whether large language models acting as autonomous bidders can tacitly collude by coordinating when to accept platform posted payouts in repeated Dutch auctions, without any communication. We present a minimal repeated auction model that yields a simple incentive compatibility condition and a closed form threshold for sustainable collusion for subgame-perfect Nash equilibria. In controlled simulations with multiple language models, we observe systematic supra-competitive prices in small auction settings and a return to competitive behavior as the number of bidders in the market increases, consistent with the theoretical model. We also find LLMs use various mechanisms to facilitate tacit coordination, such as focal point acceptance timing versus patient strategies that track the theoretical incentives. The results provide, to our knowledge, the first evidence of bidder side tacit collusion by LLMs and show that market structure levers can be more effective than capability limits for mitigation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21802v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sriram Tolety</dc:creator>
    </item>
    <item>
      <title>The Evolution of Trust under Institutional Moral Hazard</title>
      <link>https://arxiv.org/abs/2511.21875</link>
      <description>arXiv:2511.21875v1 Announce Type: new 
Abstract: We study the behavior of for-profit institutions that broadcast reputations to foster trust among market participants. We develop a theoretical model in which buyers and sellers are matched on a platform to engage in transactions involving a moral hazard: sellers can either faithfully deliver goods after receiving payment, or not. Although the buyer does not know a seller's true type, the platform maintains a reputation system that probabilistically assigns binary reputation signals. Buyers make purchase decisions based on reputation signals, which influence the payoffs to sellers who then adapt their type over time. These market dynamics ultimately shape the platform's profit from commissions on sales. Our analysis reveals that platforms inherently have an incentive for rating inflation, driven by the desire to increase commission. This introduces a second layer of moral hazard: the platform's incentive to distort reputations for its own profit. Such distortion is self-limited by the platform's need to maintain enough accuracy that trustworthy sellers remain in the market, without which rational buyers would refrain from purchases altogether. Nonetheless, the optimal strategy for the platform can be to invest in order to reduce signal accuracy. When the platform can freely set commission fees, however, maximum profit may be achieved by costly investment in an accurate reputation system. These findings highlight the intricate tensions between platform incentives and resulting social utility for marketplace participants.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21875v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <category>econ.TH</category>
      <category>nlin.AO</category>
      <category>physics.soc-ph</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroaki Chiba-Okabe, Joshua B. Plotkin</dc:creator>
    </item>
    <item>
      <title>Aligning with Human Values to Enhance Interaction: An eHMI-Mediated Lane-Changing Negotiation Strategy Using Bayesian Inference</title>
      <link>https://arxiv.org/abs/2511.22061</link>
      <description>arXiv:2511.22061v1 Announce Type: new 
Abstract: As autonomous driving technology evolves, ensuring the stability and safety of Autonomous Driving Systems (ADS) through alignment with human values becomes increasingly crucial. While existing research emphasizes the adherence of AI to honest ethical principles, it overlooks the potential benefits of benevolent deception, which maximize overall payoffs. This study proposes a game-theoretic model for lane-changing scenarios, incorporating Bayesian inference to capture dynamic changes in human trust during interactions under external Human-Machine Interface (eHMI) disclosed information. Case studies reveal that benevolent deception can enhance the efficiency of interaction in up to 59.4% of scenarios and improve safety in up to 52.7%. However, in the most pronounced cases, deception also led to trust collapse in up to 36.9% of drivers, exposing a critical vulnerability in the ethical design of ADS. The findings suggest that aligning ADS with comprehensive human ethical values, including the conditional use of benevolent deception, can enhance human-machine interaction. Additionally, the risk of trust collapse remains a major ethical loophole that must be addressed in future ADS development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22061v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Boyao Peng, Linkun Liu</dc:creator>
    </item>
    <item>
      <title>On Computing the Shapley Value in Bankruptcy Games -llustrated by Rectified Linear Function Game-</title>
      <link>https://arxiv.org/abs/2511.22208</link>
      <description>arXiv:2511.22208v1 Announce Type: new 
Abstract: In this research, we discuss a problem of calculating the Shapley value in bankruptcy games. We show that the decision problem of computing the Shapley value in bankruptcy games is NP-complete. We also investigate the relationship between the Shapley value of bankruptcy games and the Shapley-Shubik index in weighted voting games. The relation naturally implies a dynamic programming technique for calculating the Shapley value. We also present two recursive algorithms for computing the Shapley value: the first is the recursive completion method originally proposed by O'Neill, and the second is our novel contribution based on the dual game formulation. These recursive approaches offer conceptual clarity and computational efficiency, especially when combined with memoisation technique. Finally, we propose a Fully Polynomial-Time Randomized Approximation Scheme (FPRAS) based on Monte Carlo sampling, providing an efficient approximation method for large-scale instances.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22208v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shunta Yamazaki, Tomomi Matsui</dc:creator>
    </item>
    <item>
      <title>Mechanism Design under Unawareness -- Extended Abstract</title>
      <link>https://arxiv.org/abs/2511.22369</link>
      <description>arXiv:2511.22369v1 Announce Type: new 
Abstract: We study the design of mechanisms under asymmetric awareness and information. While the mechanism designer cannot necessarily commit to a particular social choice function in the face of unawareness, she can at least commit to properties of social choice functions such as efficiency given ex post awareness. Assuming quasi-linear utilities and private values, we show that we can implement in conditional dominant strategies a social choice function that is utilitarian ex post efficient under pooled awareness without the need of the social planner being fully aware ex ante. To this end, we develop novel dynamic versions of Vickrey-Clarke-Groves mechanisms in which true types are revealed and subsequently elaborated at endogenous higher awareness levels. We explore how asymmetric awareness affects budget balance and participation constraints. We show that ex ante unforeseen contingencies are no excuse for deficits. Finally, we propose a dynamic elaboration reverse second price auction for efficient procurement of complex incompletely specified projects with budget balance and participation constraints.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22369v1</guid>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.1</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 1-13</arxiv:journal_reference>
      <dc:creator>Kym Pram (University of Nevada, Reno), Burkhard C. Schipper (University of California, Davis)</dc:creator>
    </item>
    <item>
      <title>Solving Four Open Problems about Core Stability in Altruistic Hedonic Games</title>
      <link>https://arxiv.org/abs/2511.22370</link>
      <description>arXiv:2511.22370v1 Announce Type: new 
Abstract: Hedonic games -- at the interface of cooperative game theory and computational social choice -- are coalition formation games in which the players have preferences over the coalitions they can join. Kerkmann et al. [13] introduced altruistic hedonic games where the players' utilities depend not only on their own but also on their friends' valuations of coalitions. The complexity of the verification problem for core stability has remained open in four variants of altruistic hedonic games: namely, for the variants with average- and minimum-based "equal-treatment" and "altruistic-treatment" preferences. We solve these four open questions by proving the corresponding problems coNP-complete; our reductions rely on rather intricate gadgets in the related networks of friends.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22370v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.3</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 15-29</arxiv:journal_reference>
      <dc:creator>J\"org Rothe, Ildik\'o Schlotter</dc:creator>
    </item>
    <item>
      <title>Common $p$-Belief with Plausibility Measures: Extended Abstract</title>
      <link>https://arxiv.org/abs/2511.22372</link>
      <description>arXiv:2511.22372v1 Announce Type: new 
Abstract: Aumann's famous Agreeing to Disagree Theorem states that if a group of agents share a common prior, update their beliefs by Bayesian conditioning based on private information, and have common knowledge of their posterior beliefs regarding some event, these posteriors must be identical. There is an elegant generalization of this theorem by Monderer and Samet, later refined by Neeman: if a group of agents share a common prior, update their beliefs using Bayesian conditioning on private information, and have common p-belief of their posteriors, these posteriors must be close (i.e., they cannot differ by more than 1 - p). Here, common p-belief generalizes the concept of common knowledge to probabilistic beliefs: agents commonly p-believe an event E if everyone believes E to at least degree p, everyone believes to at least degree p that everyone believes E to at least degree p, and so on.
  This paper further extends the Monderer-Samet-Neeman Agreement Theorem from classical probability measures to plausibility measures -- a very general framework introduced by Halpern that unifies many formal models of belief. To facilitate this extension, we provide a new proof of the Monderer-Samet-Neeman theorem in the classical setting. Building upon both the original proof and our new proof, we offer two different generalizations of the theorem to plausibility-based structures.
  We then apply these generalized results to several non-classical belief models, including conditional probability structures and lexicographic probability structures. Moreover, we show that whenever our generalized theorems do not apply, the Monderer-Samet-Neeman Agreement Theorem fails. These findings suggest that our results successfully identify the minimal conditions required for a belief model to satisfy the Monderer-Samet-Neeman Agreement Theorem.
</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22372v1</guid>
      <category>cs.GT</category>
      <category>cs.LO</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.10</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 66-79</arxiv:journal_reference>
      <dc:creator>Eric Pacuit (University of Maryland), Leo Yang (University of Maryland)</dc:creator>
    </item>
    <item>
      <title>Skating System Unveiled: Exploring Preference Aggregation in Ballroom Tournaments</title>
      <link>https://arxiv.org/abs/2511.22384</link>
      <description>arXiv:2511.22384v1 Announce Type: new 
Abstract: The Skating System, which originated from the scrutineering system in dance sport tournaments, can be formulated as a voting system: We introduce and formalize the Skating System Single (SkS, for short), a new voting system embedded into the framework of computational social choice. Although SkS has similarities with Bucklin voting, it differs from it because it is subject to additional constraints when determining the election winners. Through an analysis of the axiomatic properties of SkS and of its vulnerability to manipulative and electoral control attacks, we compare SkS with Bucklin voting and provide insights into its potential strengths and weaknesses. In particular, we show that SkS satisfies nondictatorship as well as the majority criterion, positive responsiveness, monotonicity, and citizens' sovereignty but violates the Condorcet criterion, strong monotonicity, independence of clones, consistency, participation, resoluteness, and strategy-proofness. Further, we study manipulation, i.e., where (groups of) voters vote strategically to improve the outcome of an election in their favor, showing that the constructive coalitional weighted manipulation problem for SkS is NP-complete, while the destructive variant can be solved in polynomial time. Lastly, we initiate the study of electoral control, where an external agent attempts to change the election outcome by interfering with the structure of the election. Here, we show NP-completeness for constructive and destructive control by deleting candidates as well as for constructive control by adding voters, whereas we show that the problem of destructive control by adding voters can be solved in polynomial time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22384v1</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.23</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 271-285</arxiv:journal_reference>
      <dc:creator>Laryssa Horn (Heinrich-Heine-Universit\"at D\"usseldorf), Paul N\"usken (Heinrich-Heine-Universit\"at D\"usseldorf), J\"org Rothe (Heinrich-Heine-Universit\"at D\"usseldorf), Tessa Seeger (Heinrich-Heine-Universit\"at D\"usseldorf)</dc:creator>
    </item>
    <item>
      <title>Prudent Rationalizability and the Best Rationalization Principle</title>
      <link>https://arxiv.org/abs/2511.22388</link>
      <description>arXiv:2511.22388v1 Announce Type: new 
Abstract: We study cautious reasoning in finite sequential games played by agents with perfect recall. Our contribution lies in formulating a definition of prudent rationalizability (Heifetz et al. 2021, BEJTE) as an iterative reduction procedure of beliefs. To this end, we represent the players' beliefs by systems of conditional non-standard probability measures. The key novelty is the notion of c-strong belief, a non-standard, "cautious" version of strong belief (Battigalli and Siniscalchi 2002, JET). Our formulation of prudent rationalizability embodies a "best rationalization principle" similar to the one that underlies the solution concept of strong rationalizability. The main results show the equivalence between the proposed definition with the one originally put forth by Heifetz et al. (2021) in terms of conditional beliefs represented by standard probabilities. In particular, it is shown that prudent rationalizability can be algorithmically characterized by iterated admissibility. Finally, our formulation can be extended to sequential games with unawareness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22388v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.27</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 334-349</arxiv:journal_reference>
      <dc:creator>Nicodemo De Vito (Deparment of Economics,Statistics, University of Salerno)</dc:creator>
    </item>
    <item>
      <title>Beyond Last-Click: An Optimal Mechanism for Ad Attribution</title>
      <link>https://arxiv.org/abs/2511.22918</link>
      <description>arXiv:2511.22918v1 Announce Type: new 
Abstract: Accurate attribution for multiple platforms is critical for evaluating performance-based advertising. However, existing attribution methods rely heavily on the heuristic methods, e.g., Last-Click Mechanism (LCM) which always allocates the attribution to the platform with the latest report, lacking theoretical guarantees for attribution accuracy. In this work, we propose a novel theoretical model for the advertising attribution problem, in which we aim to design the optimal dominant strategy incentive compatible (DSIC) mechanisms and evaluate their performance. We first show that LCM is not DSIC and performs poorly in terms of accuracy and fairness. To address this limitation, we introduce the Peer-Validated Mechanism (PVM), a DSIC mechanism in which a platform's attribution depends solely on the reports of other platforms. We then examine the accuracy of PVM across both homogeneous and heterogeneous settings, and provide provable accuracy bounds for each case. Notably, we show that PVM is the optimal DSIC mechanism in the homogeneous setting. Finally, numerical experiments are conducted to show that PVM consistently outperforms LCM in terms of attribution accuracy and fairness.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22918v1</guid>
      <category>cs.GT</category>
      <category>cs.CE</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nan An, Weian Li, Qi Qi, Changyuan Yu, Liang Zhang</dc:creator>
    </item>
    <item>
      <title>Merging Mechanisms for Ads and Organic Items in E-commerce Platforms</title>
      <link>https://arxiv.org/abs/2511.22925</link>
      <description>arXiv:2511.22925v1 Announce Type: new 
Abstract: In contemporary e-commerce platforms, search result pages display two types of items: ad items and organic items. Ad items are determined through an advertising auction system, while organic items are selected by a recommendation system. These systems have distinct optimization objectives, creating the challenge of effectively merging these two components. Recent research has explored merging mechanisms for e-commerce platforms, but none have simultaneously achieved all desirable properties: incentive compatibility, individual rationality, adaptability to multiple slots, integration of inseparable candidates, and avoidance of repeated exposure for ads and organic items. This paper addresses the design of a merging mechanism that satisfies all these properties. We first provide the necessary conditions for the optimal merging mechanisms. Next, we introduce two simple and effective mechanisms, termed the generalized fix mechanism and the generalized change mechanism. Finally, we theoretically prove that both mechanisms offer guaranteed approximation ratios compared to the optimal mechanism in both simplest and general settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22925v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1609/aaai.v39i13.33479</arxiv:DOI>
      <dc:creator>Nan An, Weian Li, Qi Qi, Liang Zhang</dc:creator>
    </item>
    <item>
      <title>Fairness in the Multi-Secretary Problem</title>
      <link>https://arxiv.org/abs/2511.23097</link>
      <description>arXiv:2511.23097v1 Announce Type: new 
Abstract: This paper bridges two perspectives: it studies the multi-secretary problem through the fairness lens of social choice, and examines multi-winner elections from the viewpoint of online decision making. After identifying the limitations of the prominent proportionality notion of Extended Justified Representation (EJR) in the online domain, the work proposes a set of mechanisms that merge techniques from online algorithms with rules from social choice -- such as the Method of Equal Shares and the Nash Rule -- and supports them through both theoretical analysis and extensive experimental evaluation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23097v1</guid>
      <category>cs.GT</category>
      <category>cs.AI</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Georgios Papasotiropoulos, Zein Pishbin</dc:creator>
    </item>
    <item>
      <title>Designing Rules for Choosing a Winner in a Debate</title>
      <link>https://arxiv.org/abs/2511.23454</link>
      <description>arXiv:2511.23454v1 Announce Type: new 
Abstract: We consider settings where an uninformed principal must hear arguments from two better-informed agents, corresponding to two possible courses of action that they argue for. The arguments are verifiable in the sense that the true state of the world restricts the arguments that can be made by the agents. Each agent simply wants to be chosen as the winner and does so strategically based on the rule set by the principal. How should the principal design the rule to choose the better action? We provide a formal framework for answering this question, exhibit some basic properties of it, study the computational problems of evaluating and optimizing the principal's policy, and provide key error bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23454v1</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexander Heckett, Vincent Conitzer</dc:creator>
    </item>
    <item>
      <title>NetworkGames: Simulating Cooperation in Network Games with Personality-driven LLM Agents</title>
      <link>https://arxiv.org/abs/2511.21783</link>
      <description>arXiv:2511.21783v1 Announce Type: cross 
Abstract: The advent of Large Language Models (LLMs) presents a novel opportunity to build high-fidelity agent-based models for simulating complex social systems. However, the behavior of these LLM-based agents in game-theoretic network games remains surprisingly unexplored. In this work, we introduce "NetworkGames," a novel simulation framework designed to investigate how network topology and agent personality jointly shape the evolution of cooperation in network games. We instantiate a population of LLM agents, each endowed with a distinct personality from the MBTI taxonomy, and situate them in various network structures (e.g., small-world and scale-free). Through extensive simulations of the Iterated Prisoner's Dilemma, we first establish a baseline dyadic interaction matrix, revealing nuanced cooperative preferences between all 16 personality pairs. We then demonstrate that macro-level cooperative outcomes are not predictable from dyadic interactions alone; they are co-determined by the network's connectivity and the spatial distribution of personalities. For instance, we find that small-world networks are detrimental to cooperation, while strategically placing pro-social personalities in hub positions within scale-free networks can significantly promote cooperative behavior. Our findings offer significant implications for designing healthier online social environments and forecasting collective behavior. We open-source our framework to foster further research in network game simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21783v1</guid>
      <category>physics.soc-ph</category>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuan Qiu</dc:creator>
    </item>
    <item>
      <title>Breaking Algorithmic Collusion in Human-AI Ecosystems</title>
      <link>https://arxiv.org/abs/2511.21935</link>
      <description>arXiv:2511.21935v1 Announce Type: cross 
Abstract: AI agents are increasingly deployed in ecosystems where they repeatedly interact not only with each other but also with humans. In this work, we study these human-AI ecosystems from a theoretical perspective, focusing on the classical framework of repeated pricing games. In our stylized model, the AI agents play equilibrium strategies, and one or more humans manually perform the pricing task instead of adopting an AI agent, thereby defecting to a no-regret strategy. Motivated by how populations of AI agents can sustain supracompetitive prices, we investigate whether high prices persist under such defections. Our main finding is that even a single human defection can destabilize collusion and drive down prices, and multiple defections push prices even closer to competitive levels. We further show how the nature of collusion changes under defection-aware AI agents. Taken together, our results characterize when algorithmic collusion is fragile--and when it persists--in mixed ecosystems of AI agents and humans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.21935v1</guid>
      <category>cs.LG</category>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Natalie Collina, Eshwar Ram Arunachaleswaran, Meena Jagadeesan</dc:creator>
    </item>
    <item>
      <title>Are Large Random Graphs Always Safe to Hide?</title>
      <link>https://arxiv.org/abs/2511.22387</link>
      <description>arXiv:2511.22387v1 Announce Type: cross 
Abstract: We discuss winning possibilities of players in various variants of cops and robber game played on large random graphs, a testbed for various kinds of network queries, search problems in particular. We explore the use of logic frameworks to investigate such results; in particular, we show that whenever a winning condition for either player can be expressed as a certain kind of formula in first-order logic, that player almost always wins. In the process, we obtain more insight into the logic-game connection from the zero-one law perspective.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22387v1</guid>
      <category>cs.LO</category>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.26</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 321-333</arxiv:journal_reference>
      <dc:creator>Sourav Chakraborty (Indian Statistical Institute), Sujata Ghosh (Indian Statistical Institute), Smiha Samanta (Indian Statistical Institute)</dc:creator>
    </item>
    <item>
      <title>A Computable Game-Theoretic Framework for Multi-Agent Theory of Mind</title>
      <link>https://arxiv.org/abs/2511.22536</link>
      <description>arXiv:2511.22536v1 Announce Type: cross 
Abstract: Originating in psychology, $\textit{Theory of Mind}$ (ToM) has attracted significant attention across multiple research communities, especially logic, economics, and robotics. Most psychological work does not aim at formalizing those central concepts, namely $\textit{goals}$, $\textit{intentions}$, and $\textit{beliefs}$, to automate a ToM-based computational process, which, by contrast, has been extensively studied by logicians. In this paper, we offer a different perspective by proposing a computational framework viewed through the lens of game theory. On the one hand, the framework prescribes how to make boudedly rational decisions while maintaining a theory of mind about others (and recursively, each of the others holding a theory of mind about the rest); on the other hand, it employs statistical techniques and approximate solutions to retain computability of the inherent computational problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.22536v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fengming Zhu, Yuxin Pan, Xiaomeng Zhu, Fangzhen Lin</dc:creator>
    </item>
    <item>
      <title>A Game-Theoretic Approach for Adversarial Information Fusion in Distributed Sensor Networks</title>
      <link>https://arxiv.org/abs/2511.23026</link>
      <description>arXiv:2511.23026v1 Announce Type: cross 
Abstract: Every day we share our personal information through digital systems which are constantly exposed to threats. For this reason, security-oriented disciplines of signal processing have received increasing attention in the last decades: multimedia forensics, digital watermarking, biometrics, network monitoring, steganography and steganalysis are just a few examples. Even though each of these fields has its own peculiarities, they all have to deal with a common problem: the presence of one or more adversaries aiming at making the system fail. Adversarial Signal Processing lays the basis of a general theory that takes into account the impact that the presence of an adversary has on the design of effective signal processing tools. By focusing on the application side of Adversarial Signal Processing, namely adversarial information fusion in distributed sensor networks, and adopting a game-theoretic approach, this thesis contributes to the above mission by addressing four issues. First, we address decision fusion in distributed sensor networks by developing a novel soft isolation defense scheme that protect the network from adversaries, specifically, Byzantines. Second, we develop an optimum decision fusion strategy in the presence of Byzantines. In the next step, we propose a technique to reduce the complexity of the optimum fusion by relying on a novel near-optimum message passing algorithm based on factor graphs. Finally, we introduce a defense mechanism to protect decentralized networks running consensus algorithm against data falsification attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.23026v1</guid>
      <category>cs.CR</category>
      <category>cs.GT</category>
      <category>cs.MA</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kassem Kallas</dc:creator>
    </item>
    <item>
      <title>Optimal Information Design in Sender-Receiver Cheap Talk Interactions</title>
      <link>https://arxiv.org/abs/2401.03671</link>
      <description>arXiv:2401.03671v2 Announce Type: replace 
Abstract: This paper considers the dynamics of cheap talk interactions between an oblivious receiver and a sender with different amounts of information. Even though it may seem that having additional information about the state of the game is always beneficial to the sender, we show that there are cases in which garbling the information of a fully informed sender can improve not only receiver's utility in equilibrium, but also that of the sender herself. We also provide efficient algorithms that output the optimal amount of information in sender-receiver scenarios with binary actions and extend some of these results to settings with multiple senders and one receiver.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.03671v2</guid>
      <category>cs.GT</category>
      <category>cs.DS</category>
      <category>econ.TH</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.437.5</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 437, 2025, pp. 31-45</arxiv:journal_reference>
      <dc:creator>Itai Arieli (Technion), Ivan Geffner (Utrecht University), Moshe Tennenholtz (Technion)</dc:creator>
    </item>
    <item>
      <title>Temporal Cooperative Games</title>
      <link>https://arxiv.org/abs/2510.11255</link>
      <description>arXiv:2510.11255v3 Announce Type: replace 
Abstract: Classical cooperative game theory assumes that the worth of a coalition depends only on the set of agents involved, but in practice, it may also depend on the order in which agents arrive. Motivated by such scenarios, we introduce temporal cooperative games (TCG), where the worth $v$ becomes a function of the sequence of agents $\pi$ rather than just the set $S$. This shift calls for rethinking the underlying axioms. A key property in this temporal framework is the incentive for optimal arrival (I4OA), which encourages agents to join in the order maximizing total worth. Alongside, we define two additional properties: online individual rationality (OIR), incentivizing earlier agents to invite more participants, and sequential efficiency (SE), ensuring that the total worth of any sequence is fully distributed among its agents. We identify a class of reward-sharing mechanisms uniquely characterized by these three properties. The classical Shapley value does not directly apply here, so we construct its natural analogs in two variants: the sequential world, where rewards are defined for each sequence-player pair, and the extended world, where rewards are defined for each player alone. Properties of efficiency, additivity, and null player uniquely determine these Shapley analogs in both worlds. Importantly, the Shapley analogs are disjoint from mechanisms satisfying I4OA, OIR, and SE, and this conflict persists even for restricted classes such as convex and simple TCGs. Our findings thus uncover a fundamental tension: when players arrive sequentially, reward-sharing mechanisms satisfying desirable temporal properties must inherently differ from Shapley-inspired ones, opening new questions for defining fair and efficient solution concepts in TCGs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.11255v3</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ashwin Goyal, Drashthi Doshi, Swaprava Nath</dc:creator>
    </item>
    <item>
      <title>Nash-equilibrium Seeking Algorithm for Power-Allocation Games on Networks of International Relations</title>
      <link>https://arxiv.org/abs/2511.08033</link>
      <description>arXiv:2511.08033v3 Announce Type: replace 
Abstract: In the field of international security, understanding the strategic interactions between countries within a networked context is crucial. Our previous research has introduced a ``games-on-signed graphs'' framework~\cite{LiMorse2022} to analyze these interactions. While the framework is intended to be basic and general, there is much left to be explored, particularly in capturing the complexity of strategic scenarios in international relations. Our paper aims to fill this gap in two key ways. First, we modify the existing preference axioms to allow for a more nuanced understanding of how countries pursue self-survival, defense of allies, and offense toward adversaries. Second, we introduce a novel algorithm that proves the existence of a pure-strategy Nash equilibrium for these revised games. To validate our model, we employ historical data from the year 1940 as the game input and predict countries' survivability. Our contributions thus extend the real-world applicability of the original framework, offering a more comprehensive view of strategic interactions in a networked security environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.08033v3</guid>
      <category>cs.GT</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chuanzhe Zhang, Yuke Li, Wenjun Mei</dc:creator>
    </item>
    <item>
      <title>Robust Resource Allocation via Competitive Subsidies</title>
      <link>https://arxiv.org/abs/2511.09934</link>
      <description>arXiv:2511.09934v2 Announce Type: replace 
Abstract: A canonical setting for non-monetary online resource allocation is one where agents compete over multiple rounds for a single item per round, with i.i.d. valuations and additive utilities across rounds. With $n$ symmetric agents, a natural benchmark for each agent is the utility realized by her favorite $1/n$-fraction of rounds; a line of work has demonstrated one can robustly guarantee each agent a constant fraction of this ideal utility, irrespective of how other agents behave. In particular, several mechanisms have been shown to be $1/2$-robust, and recent work established that repeated first-price auctions based on artificial credits have a robustness factor of $0.59$, which cannot be improved beyond $0.6$ using first-price and simple strategies. In contrast, even without strategic considerations, the best achievable factor is $1-1/e\approx 0.63$.
  In this work, we break the $0.6$ first-price barrier to get a new $0.625$-robust mechanism, which almost closes the gap to the non-strategic robustness bound. Surprisingly, we do so via a simple auction, where in each round, bidders decide if they ask for the item, and we allocate uniformly at random among those who ask. The main new ingredient is the idea of competitive subsidies, wherein we charge the winning agent an amount in artificial credits that decreases when fewer agents are bidding (specifically, when $k$ agents bid, then the winner pays proportional to $k/(k+1)$, varying the payment by a factor of 2 depending on the competition). Moreover, we show how it can be modified to get an equilibrium strategy with a slightly weaker robust guarantee of $5/(3e) \approx 0.61$ (and the optimal $1-1/e$ factor at equilibrium). Finally, we show that our mechanism gives the best possible bound under a wide class of auction-based mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.09934v2</guid>
      <category>cs.GT</category>
      <pubDate>Mon, 01 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David X. Lin, Giannis Fikioris, Siddhartha Banerjee, \'Eva Tardos</dc:creator>
    </item>
  </channel>
</rss>
