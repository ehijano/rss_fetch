<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.QM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.QM</link>
    <description>q-bio.QM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.QM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 27 Jan 2026 05:00:00 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Domain-Aware Geometric Multimodal Learning for Multi-Domain Protein-Ligand Affinity Prediction</title>
      <link>https://arxiv.org/abs/2601.17102</link>
      <description>arXiv:2601.17102v1 Announce Type: new 
Abstract: The accurate prediction of protein-ligand binding affinity is important for drug discovery yet remains challenging for multi-domain proteins, where inter-domain dynamics and flexible linkers govern molecular recognition. Current geometric deep learning methods typically treat proteins as monolithic graphs, failing to capture the distinct geometric and energetic signals at domain interfaces. To address this, we introduce DAGML (Domain-Aware Geometric Multimodal Learning), a hierarchical framework that explicitly models domain modularity. DAGML integrates a pre-trained protein language model with a novel domain-aware geometric encoder to distinguish intra- and inter-domain features, while a motif-centric ligand encoder captures pharmacophoric compatibility. We further curate a specialized multi-domain affinity benchmark, classifying complexes by binding topology (e.g., interface vs linker binders). Extensive experiments demonstrate that DAGML achieves a 21% reduction in MSE and a Pearson correlation of 0.726 compared to strong baselines. Ablation studies reveal that explicit modeling of domain interfaces is the primary driver of this improvement, particularly for ligands binding in the clefts between structural units. The code is available at https://github.com/jiankliu/DAGML.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17102v1</guid>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Zhang, Jian K. Liu</dc:creator>
    </item>
    <item>
      <title>GenAI-Net: A Generative AI Framework for Automated Biomolecular Network Design</title>
      <link>https://arxiv.org/abs/2601.17582</link>
      <description>arXiv:2601.17582v1 Announce Type: new 
Abstract: Biomolecular networks underpin emerging technologies in synthetic biology-from robust biomanufacturing and metabolic engineering to smart therapeutics and cell-based diagnostics-and also provide a mechanistic language for understanding complex dynamics in natural and ecological systems. Yet designing chemical reaction networks (CRNs) that implement a desired dynamical function remains largely manual: while a proposed network can be checked by simulation, the reverse problem of discovering a network from a behavioral specification is difficult, requiring substantial human insight to navigate a vast space of topologies and kinetic parameters with nonlinear and possibly stochastic dynamics. Here we introduce GenAI-Net, a generative AI framework that automates CRN design by coupling an agent that proposes reactions to simulation-based evaluation defined by a user-specified objective. GenAI-Net efficiently produces novel, topologically diverse solutions across multiple design tasks, including dose responses, complex logic gates, classifiers, oscillators, and robust perfect adaptation in deterministic and stochastic settings (including noise reduction). By turning specifications into families of circuit candidates and reusable motifs, GenAI-Net provides a general route to programmable biomolecular circuit design and accelerates the translation from desired function to implementable mechanisms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17582v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>q-bio.MN</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Maurice Filo, Nicol\`o Rossi, Zhou Fang, Mustafa Khammash</dc:creator>
    </item>
    <item>
      <title>Quantitative cancer-immunity cycle modeling to optimize bevacizumab and atezolizumab combination therapy for advanced renal cell carcinoma</title>
      <link>https://arxiv.org/abs/2601.17669</link>
      <description>arXiv:2601.17669v1 Announce Type: new 
Abstract: The incidence of advanced renal cell carcinoma(RCC) has been rising, presenting significant challenges due to the limited efficacy and severe side effects of traditional radiotherapy and chemotherapy. While combination immunotherapies show promise, optimizing treatment strategies remains difficult due to individual heterogeneity. To address this, we developed a Quantitative Cancer-Immunity Cycle (QCIC) model that integrates ordinary differential equations with stochastic modelling to quantitatively characterize and predict tumor evolution in patients with advanced RCC. By systematically integrating quantitative systems pharmacology principles with biological mechanistic knowledge, we constructed a virtual patient cohort and calibrated the model parameters using clinical immunohistochemistry data to ensure biological validity. To enhance predictive performance, we coupled the model with pharmacokinetic equations and defined the Tumor Response Index (TRI) as a quantitative metric of efficacy. Systematic analysis of the QCIC model allowed us to determine an optimal treatment regimen for the combination of bevacizumab and atezolizumab and identify tumor biomarkers with clinical predictive value. This study provides a theoretical framework and methodological support for precision medicine in the treatment of advanced RCC.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17669v1</guid>
      <category>q-bio.QM</category>
      <category>q-bio.TO</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Lei Du, Chenghang Li, Jinzhi Lei</dc:creator>
    </item>
    <item>
      <title>Point transformer for protein structural heterogeneity analysis using CryoEM</title>
      <link>https://arxiv.org/abs/2601.18713</link>
      <description>arXiv:2601.18713v1 Announce Type: new 
Abstract: Structural dynamics of macromolecules is critical to their structural-function relationship. Cryogenic electron microscopy (CryoEM) provides snapshots of vitrified protein at different compositional and conformational states, and the structural heterogeneity of proteins can be characterized through computational analysis of the images. For protein systems with multiple degrees of freedom, it is still challenging to disentangle and interpret the different modes of dynamics. Here, by implementing Point Transformer, a self-attention network designed for point cloud analysis, we are able to improve the performance of heterogeneity analysis on CryoEM data, and characterize the dynamics of highly complex protein systems in a more human-interpretable way.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.18713v1</guid>
      <category>q-bio.QM</category>
      <category>cs.AI</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muyuan Chen, Muchen Li, Renjie Liao</dc:creator>
    </item>
    <item>
      <title>Semi-Supervised Domain Adaptation with Latent Diffusion for Pathology Image Classification</title>
      <link>https://arxiv.org/abs/2601.17228</link>
      <description>arXiv:2601.17228v1 Announce Type: cross 
Abstract: Deep learning models in computational pathology often fail to generalize across cohorts and institutions due to domain shift. Existing approaches either fail to leverage unlabeled data from the target domain or rely on image-to-image translation, which can distort tissue structures and compromise model accuracy. In this work, we propose a semi-supervised domain adaptation (SSDA) framework that utilizes a latent diffusion model trained on unlabeled data from both the source and target domains to generate morphology-preserving and target-aware synthetic images. By conditioning the diffusion model on foundation model features, cohort identity, and tissue preparation method, we preserve tissue structure in the source domain while introducing target-domain appearance characteristics. The target-aware synthetic images, combined with real, labeled images from the source cohort, are subsequently used to train a downstream classifier, which is then tested on the target cohort. The effectiveness of the proposed SSDA framework is demonstrated on the task of lung adenocarcinoma prognostication. The proposed augmentation yielded substantially better performance on the held-out test set from the target cohort, without degrading source-cohort performance. The approach improved the weighted F1 score on the target-cohort held-out test set from 0.611 to 0.706 and the macro F1 score from 0.641 to 0.716. Our results demonstrate that target-aware diffusion-based synthetic data augmentation provides a promising and effective approach for improving domain generalization in computational pathology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17228v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tengyue Zhang, Ruiwen Ding, Luoting Zhuang, Yuxiao Wu, Erika F. Rodriguez, William Hsu</dc:creator>
    </item>
    <item>
      <title>BMDS-Net: A Bayesian Multi-Modal Deep Supervision Network for Robust Brain Tumor Segmentation</title>
      <link>https://arxiv.org/abs/2601.17504</link>
      <description>arXiv:2601.17504v1 Announce Type: cross 
Abstract: Accurate brain tumor segmentation from multi-modal magnetic resonance imaging (MRI) is a prerequisite for precise radiotherapy planning and surgical navigation. While recent Transformer-based models such as Swin UNETR have achieved impressive benchmark performance, their clinical utility is often compromised by two critical issues: sensitivity to missing modalities (common in clinical practice) and a lack of confidence calibration. Merely chasing higher Dice scores on idealized data fails to meet the safety requirements of real-world medical deployment. In this work, we propose BMDS-Net, a unified framework that prioritizes clinical robustness and trustworthiness over simple metric maximization. Our contribution is three-fold. First, we construct a robust deterministic backbone by integrating a Zero-Init Multimodal Contextual Fusion (MMCF) module and a Residual-Gated Deep Decoder Supervision (DDS) mechanism, enabling stable feature learning and precise boundary delineation with significantly reduced Hausdorff Distance, even under modality corruption. Second, and most importantly, we introduce a memory-efficient Bayesian fine-tuning strategy that transforms the network into a probabilistic predictor, providing voxel-wise uncertainty maps to highlight potential errors for clinicians. Third, comprehensive experiments on the BraTS 2021 dataset demonstrate that BMDS-Net not only maintains competitive accuracy but, more importantly, exhibits superior stability in missing-modality scenarios where baseline models fail. The source code is publicly available at https://github.com/RyanZhou168/BMDS-Net.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.17504v1</guid>
      <category>cs.CV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yan Zhou, Zhen Huang, Yingqiu Li, Yue Ouyang, Suncheng Xiang, Zehua Wang</dc:creator>
    </item>
    <item>
      <title>Toward Scalable Early Cancer Detection: Evaluating EHR-Based Predictive Models Against Traditional Screening Criteria</title>
      <link>https://arxiv.org/abs/2511.11293</link>
      <description>arXiv:2511.11293v2 Announce Type: replace-cross 
Abstract: Current cancer screening guidelines cover only a few cancer types and rely on narrowly defined criteria such as age or a single risk factor like smoking history, to identify high-risk individuals. Predictive models using electronic health records (EHRs), which capture large-scale longitudinal patient-level health information, may provide a more effective tool for identifying high-risk groups by detecting subtle prediagnostic signals of cancer. Recent advances in large language and foundation models have further expanded this potential, yet evidence remains limited on how useful EHR-based models are compared with traditional risk factors currently used in screening guidelines. We systematically evaluated the clinical utility of EHR-based predictive models against traditional risk factors, including gene mutations and family history of cancer, for identifying high-risk individuals across eight major cancers (breast, lung, colorectal, prostate, ovarian, liver, pancreatic, and stomach), using data from the All of Us Research Program, which integrates EHR, genomic, and survey data from over 865,000 participants. Even with a baseline modeling approach, EHR-based models achieved a 3- to 6-fold higher enrichment of true cancer cases among individuals identified as high risk compared with traditional risk factors alone, whether used as a standalone or complementary tool. The EHR foundation model, a state-of-the-art approach trained on comprehensive patient trajectories, further improved predictive performance across 26 cancer types, demonstrating the clinical potential of EHR-based predictive modeling to support more precise and scalable early detection strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2511.11293v2</guid>
      <category>cs.LG</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jiheum Park, Chao Pang, Tristan Y. Lee, Jeong Yun Yang, Jacob Berkowitz, Alexander Z. Wei, Nicholas Tatonetti</dc:creator>
    </item>
    <item>
      <title>Graph Neural Network Reveals the Local Cortical Morphology of Brain Aging in Normal Cognition and Alzheimers Disease</title>
      <link>https://arxiv.org/abs/2601.10912</link>
      <description>arXiv:2601.10912v4 Announce Type: replace-cross 
Abstract: Estimating brain age (BA) from T1-weighted magnetic resonance images (MRIs) provides a useful approach to map the anatomic features of brain senescence. Whereas global BA (GBA) summarizes overall brain health, local BA (LBA) can reveal spatially localized patterns of aging. Although previous studies have examined anatomical contributors to GBA, no framework has been established to compute LBA using cortical morphology. To address this gap, we introduce a novel graph neural network (GNN) that uses morphometric features (cortical thickness, curvature, surface area, gray/white matter intensity ratio and sulcal depth) to estimate LBA across the cortical surface at high spatial resolution (mean inter-vertex distance = 1.37 mm). Trained on cortical surface meshes extracted from the MRIs of cognitively normal adults (N = 14,250), our GNN identifies prefrontal and parietal association cortices as early sites of morphometric aging, in concordance with biological theories of brain aging. Feature comparison using integrated gradients reveals that morphological aging is driven primarily by changes in surface area (gyral crowns and highly folded regions) and cortical thickness (occipital lobes), with additional contributions from gray/white matter intensity ratio (frontal lobes and sulcal troughs) and curvature (sulcal troughs). In Alzheimers disease (AD), as expected, the model identifies widespread, excessive morphological aging in parahippocampal gyri and related temporal structures. Significant associations are found between regional LBA gaps and neuropsychological measures descriptive of AD-related cognitive impairment, suggesting an intimate relationship between morphological cortical aging and cognitive decline. These results highlight the ability of GNN-derived gero-morphometry to provide insights into local brain aging.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.10912v4</guid>
      <category>q-bio.NC</category>
      <category>eess.IV</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel D. Anderson, Nikhil N. Chaudhari, Nahian F. Chowdhury, Jordan Jomsky, Xiaoyu Rayne Zheng, Andrei Irimia, Alzheimers Disease Neuroimaging Initiative</dc:creator>
    </item>
    <item>
      <title>Empowering LLMs for Structure-Based Drug Design via Exploration-Augmented Latent Inference</title>
      <link>https://arxiv.org/abs/2601.15333</link>
      <description>arXiv:2601.15333v2 Announce Type: replace-cross 
Abstract: Large Language Models (LLMs) possess strong representation and reasoning capabilities, but their application to structure-based drug design (SBDD) is limited by insufficient understanding of protein structures and unpredictable molecular generation. To address these challenges, we propose Exploration-Augmented Latent Inference for LLMs (ELILLM), a framework that reinterprets the LLM generation process as an encoding, latent space exploration, and decoding workflow. ELILLM explicitly explores portions of the design problem beyond the model's current knowledge while using a decoding module to handle familiar regions, generating chemically valid and synthetically reasonable molecules. In our implementation, Bayesian optimization guides the systematic exploration of latent embeddings, and a position-aware surrogate model efficiently predicts binding affinity distributions to inform the search. Knowledge-guided decoding further reduces randomness and effectively imposes chemical validity constraints. We demonstrate ELILLM on the CrossDocked2020 benchmark, showing strong controlled exploration and high binding affinity scores compared with seven baseline methods. These results demonstrate that ELILLM can effectively enhance LLMs capabilities for SBDD.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15333v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xuanning Hu, Anchen Li, Qianli Xing, Jinglong Ji, Hao Tuo, Bo Yang</dc:creator>
    </item>
    <item>
      <title>Machine learning-enhanced non-amnestic Alzheimer's disease diagnosis from MRI and clinical features</title>
      <link>https://arxiv.org/abs/2601.15530</link>
      <description>arXiv:2601.15530v2 Announce Type: replace-cross 
Abstract: Alzheimer's disease (AD), defined as an abnormal buildup of amyloid plaques and tau tangles in the brain can be diagnosed with high accuracy based on protein biomarkers via PET or CSF analysis. However, due to the invasive nature of biomarker collection, most AD diagnoses are made in memory clinics using cognitive tests and evaluation of hippocampal atrophy based on MRI. While clinical assessment and hippocampal volume show high diagnostic accuracy for amnestic or typical AD (tAD), a substantial subgroup of AD patients with atypical presentation (atAD) are routinely misdiagnosed. To improve diagnosis of atAD patients, we propose a machine learning approach to distinguish between atAD and non-AD cognitive impairment using clinical testing battery and MRI data collected as standard-of-care. We develop and evaluate our approach using 1410 subjects across four groups (273 tAD, 184 atAD, 235 non-AD, and 685 cognitively normal) collected from one private data set and two public data sets from the National Alzheimer's Coordinating Center (NACC) and the Alzheimer's Disease Neuroimaging Initiative (ADNI). We perform multiple atAD vs. non-AD classification experiments using clinical features and hippocampal volume as well as a comprehensive set of MRI features from across the brain. The best performance is achieved by incorporating additional important MRI features, which outperforms using hippocampal volume alone. Furthermore, we use the Boruta statistical approach to identify and visualize significant brain regions distinguishing between diagnostic groups. Our ML approach improves the percentage of correctly diagnosed atAD cases (the recall) from 52% to 69% for NACC and from 34% to 77% for ADNI, while achieving high precision. The proposed approach has important implications for improving diagnostic accuracy for non-amnestic atAD in clinical settings using only clinical testing battery and MRI.</description>
      <guid isPermaLink="false">oai:arXiv.org:2601.15530v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>q-bio.QM</category>
      <pubDate>Tue, 27 Jan 2026 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Megan A. Witherow, Michael L. Evans, Ahmed Temtam, Hamid R. Okhravi, Khan M. Iftekharuddin</dc:creator>
    </item>
  </channel>
</rss>
