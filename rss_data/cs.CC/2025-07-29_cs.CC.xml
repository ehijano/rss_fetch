<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CC</link>
    <description>cs.CC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 30 Jul 2025 04:01:04 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Hierarchies within TFNP: building blocks and collapses</title>
      <link>https://arxiv.org/abs/2507.21550</link>
      <description>arXiv:2507.21550v1 Announce Type: new 
Abstract: We initiate the study of complexity classes $\mathsf{A^B}$ where $\mathsf{A}$ and $\mathsf{B}$ are both $\mathsf{TFNP}$ subclasses. For example, we consider complexity classes of the form $\mathsf{PPP^{PPP}}$, $\mathsf{PPAD^{PPA}}$, and $\mathsf{PPA^{PLS}}$. We define complete problems for such classes, and show that they belong in $\mathsf{TFNP}$. These definitions require some care, since unlike a class like $\mathsf{PPA^{NP}}$, where the $\mathsf{NP}$ oracle defines a function, in $\mathsf{PPA^{PPP}}$, the oracle is for a search problem with many possible solutions. Intuitively, the definitions we introduce quantify over all possible instantiations of the $\mathsf{PPP}$ oracle.
  With these notions in place, we then show that several $\mathsf{TFNP}$ subclasses are self-low. In particular, $\mathsf{PPA^{PPA}} = \mathsf{PPA}$, $\mathsf{PLS^{PLS}} = \mathsf{PLS}$, and $\mathsf{LOSSY^{LOSSY}} = \mathsf{LOSSY}$. These ideas introduce a novel approach for classifying computational problems within $\mathsf{TFNP}$, such as the problem of deterministically generating large primes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21550v1</guid>
      <category>cs.CC</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Surendra Ghentiyala, Zeyong Li</dc:creator>
    </item>
    <item>
      <title>Verification Cost Asymmetry in Cognitive Warfare: A Complexity-Theoretic Framework</title>
      <link>https://arxiv.org/abs/2507.21258</link>
      <description>arXiv:2507.21258v1 Announce Type: cross 
Abstract: Human verification under adversarial information flow operates as a cost-bounded decision procedure constrained by working memory limits and cognitive biases. We introduce the Verification Cost Asymmetry (VCA) coefficient, formalizing it as the ratio of expected verification work between populations under identical claim distributions. Drawing on probabilistically checkable proofs (PCP) and parameterized complexity theory, we construct dissemination protocols that reduce verification for trusted audiences to constant human effort while imposing superlinear costs on adversarial populations lacking cryptographic infrastructure. We prove theoretical guarantees for this asymmetry, validate the framework through controlled user studies measuring verification effort with and without spot-checkable provenance, and demonstrate practical encoding of real-world information campaigns. The results establish complexity-theoretic foundations for engineering democratic advantage in cognitive warfare, with immediate applications to content authentication, platform governance, and information operations doctrine.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21258v1</guid>
      <category>cs.CR</category>
      <category>cs.CC</category>
      <category>cs.CY</category>
      <category>cs.GT</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Joshua Luberisse</dc:creator>
    </item>
    <item>
      <title>Undecidability of the block gluing classes of homshifts</title>
      <link>https://arxiv.org/abs/2507.21342</link>
      <description>arXiv:2507.21342v1 Announce Type: cross 
Abstract: A homshift is a $d$-dimensional shift of finite type which arises as the space of graph homomorphisms from the grid graph $\mathbb Z^d$ to a finite connected undirected graph $G$. While shifts of finite type are known to be mired by the swamp of undecidability, homshifts seem to be better behaved and there was hope that all the properties of homshifts are decidable. In this paper we build on the work by Gangloff, Hellouin de Menibus and Oprocha (arxiv:2211.04075) to show that finer mixing properties are undecidable for reasons completely different than the ones used to prove undecidability for general multidimensional shifts of finite type. Inspired by the work of Gao, Jackson, Krohne and Seward (arxiv:1803.03872) and elementary algebraic topology, we interpret the square cover introduced by Gangloff, Hellouin de Menibus and Oprocha topologically. Using this interpretation, we prove that it is undecidable whether a homshift is $\Theta(n)$-block gluing or not, by relating this problem to the one of finiteness for finitely presented groups.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21342v1</guid>
      <category>math.DS</category>
      <category>cs.CC</category>
      <category>cs.DM</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nishant Chandgotia, Silv\`ere Gangloff, Benjamin Hellouin de Menibus, Piotr Oprocha</dc:creator>
    </item>
    <item>
      <title>Structural Parameters for Steiner Orientation</title>
      <link>https://arxiv.org/abs/2507.21445</link>
      <description>arXiv:2507.21445v1 Announce Type: cross 
Abstract: We consider the \textsc{Steiner Orientation} problem, where we are given as input a mixed graph $G=(V,E,A)$ and a set of $k$ demand pairs $(s_i,t_i)$, $i\in[k]$. The goal is to orient the undirected edges of $G$ in a way that the resulting directed graph has a directed path from $s_i$ to $t_i$ for all $i\in[k]$. We adopt the point of view of structural parameterized complexity and investigate the complexity of \textsc{Steiner Orientation} for standard measures, such as treewidth. Our results indicate that \textsc{Steiner Orientation} is a surprisingly hard problem from this point of view. In particular, our main contributions are the following: (1) We show that \textsc{Steiner Orientation} is NP-complete on instances where the underlying graph has feedback vertex number 2, treewidth 2, pathwidth 3, and vertex integrity 6; (2) We present an XP algorithm parameterized by vertex cover number $\mathrm{vc}$ of complexity $n^{\mathcal{O}(\mathrm{vc}^2)}$. Furthermore, we show that this running time is essentially optimal by proving that a running time of $n^{o(\mathrm{vc}^2)}$ would refute the ETH; (3) We consider parameterizations by the number of undirected or directed edges ($|E|$ or $|A|$) and we observe that the trivial $2^{|E|}n^{\mathcal{O}(1)}$-time algorithm for the former parameter is optimal under the SETH. Complementing this, we show that the problem admits a $2^{\mathcal{O}(|A|)}n^{\mathcal{O}(1)}$-time algorithm. In addition to the above, we consider the complexity of \textsc{Steiner Orientation} parameterized by $\mathrm{tw}+k$ (FPT), distance to clique (FPT), and $\mathrm{vc}+k$ (FPT with a polynomial kernel).</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.21445v1</guid>
      <category>cs.DS</category>
      <category>cs.CC</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tesshu Hanaka, Michael Lampis, Nikolaos Melissinos, Edouard Nemery, Hirotaka Ono, Manolis Vasilakis</dc:creator>
    </item>
    <item>
      <title>Pauli Measurements Are Near-Optimal for Single-Qubit Tomography</title>
      <link>https://arxiv.org/abs/2507.22001</link>
      <description>arXiv:2507.22001v1 Announce Type: cross 
Abstract: We provide the first non-trivial lower bounds for single-qubit tomography algorithms and show that at least ${\Omega}\left(\frac{10^N}{\sqrt{N} \varepsilon^2}\right)$ copies are required to learn an $N$-qubit state $\rho\in\mathbb{C}^{d\times d},d=2^N$ to within $\varepsilon$ trace distance. Pauli measurements, the most commonly used single-qubit measurement scheme, have recently been shown to require at most $O\left(\frac{10^N}{\varepsilon^2}\right)$ copies for this problem. Combining these results, we nearly settle the long-standing question of the complexity of single-qubit tomography.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.22001v1</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jayadev Acharya, Abhilash Dharmavarapu, Yuhan Liu, Nengkun Yu</dc:creator>
    </item>
    <item>
      <title>Improved Hardness of BDD and SVP Under Gap-(S)ETH</title>
      <link>https://arxiv.org/abs/2109.04025</link>
      <description>arXiv:2109.04025v3 Announce Type: replace 
Abstract: We show improved fine-grained hardness of two key lattice problems in the $\ell_p$ norm: Bounded Distance Decoding to within an $\alpha$ factor of the minimum distance ($\mathrm{BDD}_{p, \alpha}$) and the (decisional) $\gamma$-approximate Shortest Vector Problem ($\mathrm{SVP}_{p,\gamma}$), assuming variants of the Gap (Strong) Exponential Time Hypothesis (Gap-(S)ETH). Specifically, we show:
  1. For all $p \in [1, \infty)$, there is no $2^{o(n)}$-time algorithm for $\mathrm{BDD}_{p, \alpha}$ for any constant $\alpha &gt; \alpha_\mathsf{kn}$, where $\alpha_\mathsf{kn} = 2^{-c_\mathsf{kn}}$ and $c_\mathsf{kn}$ is the $\ell_2$ kissing-number constant, assuming $c_\mathsf{kn} &gt; 0$ and that non-uniform Gap-ETH holds.
  2. For all $p \in [1, \infty)$, there is no $2^{o(n)}$-time algorithm for $\mathrm{BDD}_{p, \alpha}$ for any constant $\alpha &gt; \alpha^\ddagger_p$, where $\alpha^\ddagger_p$ is explicit and satisfies $\alpha^\ddagger_p = 1$ for $1 \leq p \leq 2$, $\alpha^\ddagger_p &lt; 1$ for all $p &gt; 2$, and $\alpha^\ddagger_p \to 1/2$ as $p \to \infty$, unless randomized Gap-ETH is false.
  3. For all $p \in [1, \infty) \setminus 2 \mathbb{Z}$ and all $C &gt; 1$, there is no $2^{n/C}$-time algorithm for $\mathrm{BDD}_{p, \alpha}$ for any constant $\alpha &gt; \alpha^\dagger_{p, C}$, where $\alpha^\dagger_{p, C}$ is explicit and satisfies $\alpha^\dagger_{p, C} \to 1$ as $C \to \infty$ for any fixed $p \in [1, \infty)$, assuming $c_\mathsf{kn} &gt; 0$ and that non-uniform Gap-SETH holds.
  4. For all $p &gt; p_0 \approx 2.1397$, $p \notin 2\mathbb{Z}$, and all $C &gt; C_p$, there is no $2^{n/C}$-time algorithm for $\mathrm{SVP}_{p, \gamma}$ for some constant $\gamma &gt; 1$, where $C_p &gt; 1$ is explicit and satisfies $C_p \to 1$ as $p \to \infty$, unless randomized Gap-SETH is false.</description>
      <guid isPermaLink="false">oai:arXiv.org:2109.04025v3</guid>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Huck Bennett, Chris Peikert, Yi Tang</dc:creator>
    </item>
    <item>
      <title>The Complexity of Computing KKT Solutions of Quadratic Programs</title>
      <link>https://arxiv.org/abs/2311.13738</link>
      <description>arXiv:2311.13738v2 Announce Type: replace 
Abstract: It is well known that solving a (non-convex) quadratic program is NP-hard. We show that the problem remains hard even if we are only looking for a Karush-Kuhn-Tucker (KKT) point, instead of a global optimum. Namely, we prove that computing a KKT point of a quadratic polynomial over the domain $[0,1]^n$ is complete for the class CLS = PPAD$\cap$PLS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.13738v2</guid>
      <category>cs.CC</category>
      <category>math.OC</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>John Fearnley, Paul W. Goldberg, Alexandros Hollender, Rahul Savani</dc:creator>
    </item>
    <item>
      <title>Hedonic Seat Arrangement Problems</title>
      <link>https://arxiv.org/abs/2002.10898</link>
      <description>arXiv:2002.10898v2 Announce Type: replace-cross 
Abstract: In this paper, we study a variant of hedonic games, called \textsc{Seat Arrangement}. The model is defined by a bijection from agents with preferences for each other to vertices in a graph $G$. The utility of an agent depends on the neighbors assigned in the graph. More precisely, it is the sum over all neighbors of the preferences that the agent has towards the agent assigned to the neighbor. We first consider the price of stability and fairness for different classes of preferences. In particular, we show that there is an instance such that the price of fairness ({\sf PoF}) is unbounded in general. Moreover, we show an upper bound $\tilde{d}(G)$ and an almost tight lower bound $\tilde{d}(G)-1/4$ of {\sf PoF}, where $\tilde{d}(G)$ is the average degree of an input graph. Then we investigate the computational complexity of problems to find certain ``good'' seat arrangements, say \textsc{Utilitarian Arrangement}, \textsc{Egalitarian Arrangement}, \textsc{Stable Arrangement}, and \textsc{Envy-free Arrangement}. We give dichotomies of computational complexity of four \textsc{Seat Arrangement} problems from the perspective of the maximum order of connected components in an input graph. For the parameterized complexity, \textsc{Utilitarian Arrangement} can be solved in time $n^{O(\gamma)}$, while it cannot be solved in time $f(\gamma)n^{o(\gamma)}$ under ETH, where $n$ is the number of agents and $\gamma$ is the vertex cover number of an input graph. Moreover, we show that \textsc{Egalitarian Arrangement} and \textsc{Envy-free Arrangement} are weakly NP-hard even on graphs of bounded vertex cover number. Finally, we prove that determining whether a stable arrangement can be obtained from a given arrangement by $k$ swaps is W[1]-hard when parameterized by $k+\gamma$, whereas it can be solved in time $n^{O(k)}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2002.10898v2</guid>
      <category>cs.GT</category>
      <category>cs.CC</category>
      <category>cs.DS</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hans L. Bodlaender, Tesshu Hanaka, Lars Jaffke, Hirotaka Ono, Yota Otachi, Tom C. van der Zanden</dc:creator>
    </item>
    <item>
      <title>Unitary Complexity and the Uhlmann Transformation Problem</title>
      <link>https://arxiv.org/abs/2306.13073</link>
      <description>arXiv:2306.13073v3 Announce Type: replace-cross 
Abstract: State transformation problems such as compressing quantum information or breaking quantum commitments are fundamental quantum tasks. However, their computational difficulty cannot easily be characterized using traditional complexity theory, which focuses on tasks with classical inputs and outputs.
  To study the complexity of such state transformation tasks, we introduce a framework for unitary synthesis problems, including notions of reductions and unitary complexity classes. We use this framework to study the complexity of transforming one entangled state into another via local operations. We formalize this as the Uhlmann Transformation Problem, an algorithmic version of Uhlmann's theorem. Then, we prove structural results relating the complexity of the Uhlmann Transformation Problem, polynomial space quantum computation, and zero knowledge protocols.
  The Uhlmann Transformation Problem allows us to characterize the complexity of a variety of tasks in quantum information processing, including decoding noisy quantum channels, breaking falsifiable quantum cryptographic assumptions, implementing optimal prover strategies in quantum interactive proofs, and decoding the Hawking radiation of black holes. Our framework for unitary complexity thus provides new avenues for studying the computational complexity of many natural quantum information processing tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2306.13073v3</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Bostanci, Yuval Efron, Tony Metger, Alexander Poremba, Luowen Qian, Henry Yuen</dc:creator>
    </item>
    <item>
      <title>Intrinsic Barriers and Practical Pathways for Human-AI Alignment: An Agreement-Based Complexity Analysis</title>
      <link>https://arxiv.org/abs/2502.05934</link>
      <description>arXiv:2502.05934v2 Announce Type: replace-cross 
Abstract: We formalize AI alignment as a multi-objective optimization problem called $\langle M,N,\varepsilon,\delta\rangle$-agreement that generalizes prior approaches with fewer assumptions, in which a set of $N$ agents (including humans) must reach approximate ($\varepsilon$) agreement across $M$ candidate objectives with probability at least $1-\delta$. Using communication complexity, we prove an information-theoretic lower bound demonstrating that once either $M$ or $N$ is large enough, no interaction or rationality can avoid intrinsic alignment overheads. This barrier establishes rigorous intrinsic limits to alignment \emph{itself}, not merely to specific methods, clarifying a crucial ``no free lunch'' principle: encoding ``all human values'' inevitably leads to misalignment, requiring future methods to explicitly manage complexity through consensus-driven reduction or prioritization of objectives. Complementing this impossibility result, we provide explicit algorithms achieving alignment under both computationally unbounded and bounded rationality with noisy messages. Even in these best-case scenarios where alignment to arbitrary precision is theoretically guaranteed, our analysis identifies three critical scalability barriers: the number of tasks ($M$), agents ($N$), and task state space size ($D$); thereby highlighting fundamental complexity-theoretic constraints and providing guidelines for safer, scalable human-AI collaboration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.05934v2</guid>
      <category>cs.AI</category>
      <category>cs.CC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Wed, 30 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aran Nayebi</dc:creator>
    </item>
  </channel>
</rss>
