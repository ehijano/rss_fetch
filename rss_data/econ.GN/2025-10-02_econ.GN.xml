<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 03 Oct 2025 04:00:12 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Does Adoption of Zero Tillage Reduce Crop Residue Burning? Evidence from Satellite Remote Sensing and Household Survey Data in India</title>
      <link>https://arxiv.org/abs/2510.01351</link>
      <description>arXiv:2510.01351v1 Announce Type: new 
Abstract: Previous research indicates that zero tillage technology offers a profitable alternative to crop residue burning, with significant potential to reduce agricultural emissions and contribute to improvements in air quality and public health. Yet, empirical evidence on the link between zero tillage adoption and residue burning remains scarce, adding to the difficulties policy makers face in this context. This study addresses this gap by integrating high-resolution satellite imagery with household survey data from India to examine the empirical relationship between zero tillage and residue burning. We compare different methods for constructing burn indicators from remote-sensing data and assess their predictive power against survey-based measures. Our findings reveal a robust negative association between zero tillage and crop residue burning, with reductions in the incidence of burning of 50% or more across both survey data and satellite-derived indicators. By providing insights into optimal geospatial data integration methods, our study also makes a methodological contribution that can inform future research and support evidence-based policy interventions for more sustainable agricultural practices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01351v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1080/00036846.2025.2567582</arxiv:DOI>
      <dc:creator>Dominik Naeher, Virginia Ziulu</dc:creator>
    </item>
    <item>
      <title>Equity Market Price Changes Are Predictable: A Natural Science Approach</title>
      <link>https://arxiv.org/abs/2510.01542</link>
      <description>arXiv:2510.01542v1 Announce Type: new 
Abstract: Equity markets have long been regarded as unpredictable, with intraday price movements treated as stochastic noise. This study challenges that view by introducing the Extended Samuelson Model (ESM), a natural science-based framework that captures the dynamic, causal processes underlying market behavior. ESM identifies peaks, troughs, and turning points across multiple timescales and demonstrates temporal compatibility: finer timeframes contain all signals of broader ones while offering sharper directional guidance. Beyond theory, ESM translates into practical trading strategies. During intraday sessions, it reliably anticipates short-term reversals and longer-term trends, even under the influence of breaking news. Its eight market states and six directional signals provide actionable guardrails for traders, enabling consistent profit opportunities. Notably, even during calm periods, ESM can capture 10-point swings in the S&amp;P 500, equivalent to $500 per E-mini futures contract. These findings resonate with the state-based approaches attributed to Renaissance Technologies' Medallion Fund, which delivered extraordinary returns through systematic intraday trading. By bridging normal conditions with crisis dynamics, ESM not only advances the scientific understanding of market evolution but also provides a robust, actionable roadmap for profitable trading.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01542v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qingyuan Han</dc:creator>
    </item>
    <item>
      <title>The centripetal pull of climate: Evidence from European Parliament elections (1989-2019)</title>
      <link>https://arxiv.org/abs/2510.01551</link>
      <description>arXiv:2510.01551v1 Announce Type: new 
Abstract: This paper examines the impact of temperature shocks on European Parliament elections. We combine high-resolution climate data with results from parliamentary elections between 1989 and 2019, aggregated at the NUTS-2 regional level. Exploiting exogenous variation in unusually warm and hot days during the months preceding elections, we identify the effect of short-run temperature shocks on voting behaviour. We find that temperature shocks reduce ideological polarisation and increase vote concentration, as voters consolidate around larger, more moderate parties. This aggregated pattern is explained by a gain in support of liberal and, to a lesser extent, social democratic parties, while right-wing parties lose vote share. Consistent with a salience mechanism, complementary analysis of party manifestos shows greater emphasis on climate-related issues in warmer pre-electoral contexts. Overall, our findings indicate that climate shocks can shift party systems toward the centre and weaken political extremes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.01551v1</guid>
      <category>econ.GN</category>
      <category>physics.soc-ph</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marco Due\~nas, Hector Galindo-Silva, Antoine Mandel</dc:creator>
    </item>
    <item>
      <title>A Computational Approach to Sustainable Policies Evaluation of the Italian Wheat Production System</title>
      <link>https://arxiv.org/abs/2510.02154</link>
      <description>arXiv:2510.02154v1 Announce Type: new 
Abstract: This work outlines the modeling steps for developing a tool aimed at supporting policymakers in guiding policies toward more sustainable wheat production. In the agricultural sector,policies affect a highly diverse set of farms, which differ across several dimensions such as size,land composition, local climate, and irrigation availability. To address this significant heterogeneity, we construct an Agent-Based Model (ABM). The model is initialized using a representative survey of Italian farms, which captures their heterogeneity. The ABM is then scaled to include a number of farms comparable to those operating nationwide. To capture broader dynamics, the ABM is integrated with two additional components:a global model of international wheat markets and a tool for assessing the environmental impacts of wheat production. This integrated framework enables us to account for the feedback loop between global prices and local production while evaluating the environmental implications of policy measures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2510.02154v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gianfranco Giuloni, Edmondo Di Giuseppe, Arianna Di Paola</dc:creator>
    </item>
    <item>
      <title>The Unelected Hand? Bureaucratic Influence and Electoral Accountability</title>
      <link>https://arxiv.org/abs/2402.17526</link>
      <description>arXiv:2402.17526v4 Announce Type: replace 
Abstract: What role do non-elected bureaucrats play when elections provide imperfect accountability and create incentives for pandering? We develop a model where politicians and bureaucrats interact to implement policy. Both can either be good, sharing the voters' preferences over policies, or bad, intent on enacting policies that favor special interests. Our analysis identifies the conditions under which good bureaucrats choose to support, oppose, or force pandering. When bureaucrats wield significant influence over policy decisions, good politicians lose their incentives to pander, a shift that ultimately benefits voters. An intermediate level of bureaucratic influence over policymaking can be voter-optimal: large enough to prevent pandering but small enough to avoid granting excessive influence to potentially bad bureaucrats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17526v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Simon Lodato, Christos Mavridis, Federico Vaccari</dc:creator>
    </item>
    <item>
      <title>Solving Models of Economic Dynamics with Ridgeless Kernel Regressions</title>
      <link>https://arxiv.org/abs/2406.01898</link>
      <description>arXiv:2406.01898v3 Announce Type: replace 
Abstract: This paper proposes a ridgeless kernel method for solving infinite-horizon, deterministic, continuous-time models in economic dynamics, formulated as systems of differential-algebraic equations with asymptotic boundary conditions (e.g., transversality). Traditional shooting methods enforce the asymptotic boundary conditions by targeting a known steady state -- which is numerically unstable, hard to tune, and unable to address cases with steady-state multiplicity. Instead, our approach solves the underdetermined problem without imposing the asymptotic boundary condition, using regularization to select the unique solution fulfilling transversality among admissible trajectories. In particular, ridgeless kernel methods recover this path by selecting the minimum norm solution, coinciding with the non-explosive trajectory. We provide theoretical guarantees showing that kernel solutions satisfy asymptotic boundary conditions without imposing them directly, and we establish a consistency result ensuring convergence within the solution concept of differential-algebraic equations. Finally, we illustrate the method in canonical models and demonstrate its ability to handle problems with multiple steady states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.01898v3</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mahdi Ebrahimi Kahou, Jesse Perla, Geoff Pleiss</dc:creator>
    </item>
    <item>
      <title>Bitcoin and Shadow Exchange Rates</title>
      <link>https://arxiv.org/abs/2410.22443</link>
      <description>arXiv:2410.22443v2 Announce Type: replace 
Abstract: This research expands the existing literature on Bitcoin (BTC) price misalignments by incorporating transaction-level data from a peer-to-peer (P2P) exchange, LocalBitcoins.com (LB). It examines how broader economic and regulatory factors influence cryptocurrency markets and highlights the role of cryptocurrencies in facilitating international capital movements. By constructing shadow exchange rates (SERs) for national currencies against the US dollar based on BTC prices, we calculate discrepancies between these SERs and their official exchange rates (OERs), referred to as BTC premiums. We analyze various factors driving the BTC premiums on LB, including those sourced from the BTC blockchain, mainstream centralized BTC exchanges, and international capital transfer channels. Unlike in centralized markets, our results indicate that the microstructure of the BTC blockchain does not correlate with BTC premiums in the P2P market. Regarding frictions from international capital transfers, we interpret remittance costs as indicators of inefficiencies in traditional capital transfer systems. For constrained currencies subject to severe capital controls and managed exchange rate regimes, increased transaction costs in conventional currency exchange channels almost entirely translate into higher BTC premiums. Additionally, our analysis suggests that BTC premiums can serve as short-term predictors of future exchange rate depreciation for unconstrained currencies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.22443v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Yanan Niu</dc:creator>
    </item>
    <item>
      <title>How does online shopping affect offline price sensitivity?</title>
      <link>https://arxiv.org/abs/2506.15103</link>
      <description>arXiv:2506.15103v2 Announce Type: replace 
Abstract: The rapid rise of e-commerce has transformed consumer behavior, prompting questions about how online adoption influences offline shopping. We examine whether consumers who adopt a retailer's online shopping channels become more price-sensitive in their subsequent offline purchases with that retailer. Using transaction-level data from a large Brazilian pet supplies retailer operating both online and offline, we compare "adopters" -- customers who began shopping online after a period of offline-only purchasing -- with "non-adopters" who remained offline-only. We estimate a discrete choice logit model with individual-level heterogeneity, based on an algorithm that can handle both high-dimensional fixed effects and price endogeneity. We then apply a staggered difference-in-differences approach to the estimated price elasticities and obtain the Average Treatment Effect on the Treated (ATT). We find that offline price sensitivity increases significantly after online adoption in three out of four product categories, particularly in items with low switching costs, such as pet hygiene. These results underscore the importance of recognizing cross-channel effects in consumer behavior and contribute to the literature on pricing and multichannel retailing by identifying online adoption as a key driver of offline price sensitivity.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.15103v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shirsho Biswas, Hema Yoganarasimhan, Haonan Zhang</dc:creator>
    </item>
    <item>
      <title>Second-degree Price Discrimination: Theoretical Analysis, Experiment Design, and Empirical Estimation</title>
      <link>https://arxiv.org/abs/2507.13426</link>
      <description>arXiv:2507.13426v2 Announce Type: replace 
Abstract: We build on theoretical results from the mechanism design literature to analyze empirical models of second-degree price discrimination (2PD). We show that for a random-coefficients discrete choice ("BLP") model to be suitable for studying 2PD, it must capture the covariance between two key random effects: (i) the "baseline" willingness to pay (affecting all product versions), and (ii) the perceived differentiation between versions. We then develop an experimental design that, among other features, identifies this covariance under common data constraints in 2PD environments. We implement this experiment in the field in collaboration with an international airline. Estimating the theoretically motivated empirical model on the experimental data, we demonstrate its applicability to 2PD decisions. We also show that test statistics from our design can enable qualitative inference on optimal 2PD policy even before estimating a demand model. Our methodology applies broadly across second-degree price discrimination settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2507.13426v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Soheil Ghili, K. Sudhir, Nitish Jain, Ankur Garg</dc:creator>
    </item>
    <item>
      <title>Machines are more productive than humans until they aren't, and vice versa</title>
      <link>https://arxiv.org/abs/2509.14057</link>
      <description>arXiv:2509.14057v4 Announce Type: replace 
Abstract: With the growth of artificial skills, organizations are increasingly confronting the problem of optimizing skill policy decisions guided by economic principles. This paper addresses the underlying complexity of this challenge by developing an in-silico framework based on Monte Carlo simulations grounded in empirical realism to analyze the economic impact of human and machine skills, individually or jointly deployed, in the execution of tasks presenting varying levels of complexity. Our results provide quantitative support for the established notions that automation tends to be the most economically-effective strategy for tasks characterized by low-to-medium generalization difficulty, while automation may struggle to match the economic utility of human skills in more complex scenarios. Critically, our simulations highlight that, when a high level of generalization is required and the cost of errors is high, combining human and machine skills can be the most effective strategy, but only if genuine augmentation is achieved. In contrast, when failing to realize this synergy, the human-machine policy is severely penalized by the inherent costs of its dual skill structure, causing it to destroy value and become the worst choice from an economic perspective. The takeaway for decision-makers is unambiguous: in complex and critical contexts, simply allocating human and machine skills to a task may be insufficient, and a human-machine skill policy is neither a silver-bullet solution nor a low-risk compromise. Rather, it is a critical opportunity to boost competitiveness that demands a strong organizational commitment to enabling augmentation. Also, our findings show that improving the cost-effectiveness of machine skills over time, while useful, does not replace the fundamental need to focus on achieving augmentation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.14057v4</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Riccardo Zanardelli</dc:creator>
    </item>
    <item>
      <title>The AI Productivity Index (APEX)</title>
      <link>https://arxiv.org/abs/2509.25721</link>
      <description>arXiv:2509.25721v2 Announce Type: replace 
Abstract: We introduce the first version of the AI Productivity Index (APEX), a benchmark for assessing whether frontier AI models can perform knowledge work with high economic value. APEX addresses one of the largest inefficiencies in AI research: outside of coding, benchmarks often fail to test economically relevant capabilities. APEX-v1.0 contains 200 test cases and covers four domains: investment banking, management consulting, law, and primary medical care. It was built in three steps. First, we sourced experts with top-tier experience e.g., investment bankers from Goldman Sachs. Second, experts created prompts that reflect high-value tasks in their day-to-day work. Third, experts created rubrics for evaluating model responses. We evaluate 23 frontier models on APEX-v1.0 using an LM judge. GPT 5 (Thinking = High) achieves the highest mean score (64.2%), followed by Grok 4 (61.3%) and Gemini 2.5 Flash (Thinking = On) (60.4%). Qwen 3 235B is the best performing open-source model and seventh best overall. There is a large gap between the performance of even the best models and human experts, highlighting the need for better measurement of models' ability to produce economically valuable work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.25721v2</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bertie Vidgen, Abby Fennelly, Evan Pinnix, Chirag Mahapatra, Zach Richards, Austin Bridges, Calix Huang, Ben Hunsberger, Fez Zafar, Brendan Foody, Dominic Barton, Cass R. Sunstein, Eric Topol, Osvald Nitski</dc:creator>
    </item>
    <item>
      <title>Multi-Scale Node Embeddings for Graph Modeling and Generation</title>
      <link>https://arxiv.org/abs/2412.04354</link>
      <description>arXiv:2412.04354v2 Announce Type: replace-cross 
Abstract: Lying at the interface between Network Science and Machine Learning, node embedding algorithms take a graph as input and encode its structure onto output vectors that represent nodes in an abstract geometric space, enabling various vector-based downstream tasks such as network modelling, data compression, link prediction, and community detection. Two apparently unrelated limitations affect these algorithms. On one hand, it is not clear what the basic operation defining vector spaces, i.e. the vector sum, corresponds to in terms of the original nodes in the network. On the other hand, while the same input network can be represented at multiple levels of resolution by coarse-graining the constituent nodes into arbitrary block-nodes, the relationship between node embeddings obtained at different hierarchical levels is not understood. Here, building on recent results in network renormalization theory, we address these two limitations at once and define a multiscale node embedding method that, upon arbitrary coarse-grainings, ensures statistical consistency of the embedding vector of a block-node with the sum of the embedding vectors of its constituent nodes. We illustrate the power of this approach on two economic networks that can be naturally represented at multiple resolution levels: namely, the international trade between (sets of) countries and the input-output flows among (sets of) industries in the Netherlands. We confirm the statistical consistency between networks retrieved from coarse-grained node vectors and networks retrieved from sums of fine-grained node vectors, a result that cannot be achieved by alternative methods. Several key network properties, including a large number of triangles, are successfully replicated already from embeddings of very low dimensionality, allowing for the generation of faithful replicas of the original networks at arbitrary resolution levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.04354v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>physics.data-an</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 03 Oct 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Riccardo Milocco, Fabian Jansen, Diego Garlaschelli</dc:creator>
    </item>
  </channel>
</rss>
