<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>math.OC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/math.OC</link>
    <description>math.OC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/math.OC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Sep 2025 04:00:54 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>On damping a delay control system with global contraction on a temporal graph</title>
      <link>https://arxiv.org/abs/2509.02608</link>
      <description>arXiv:2509.02608v1 Announce Type: new 
Abstract: We consider the problem of damping a control system with delay described by first-order functional-differential equations on a temporal tree. The delay in the system is time-proportional and propagates through the internal vertices. The problem of minimizing the energy functional with account of the probabilities of the scenarios corresponding to different edges is studied. We establish the equivalence of this variational problem to a certain boundary value problem for second-order functional-diffferential equations on the tree, possessing both the global contractions and the global extensions, and prove the unique solvability of both problems. In particular, it is established that the optimal trajectory obeys Kirchhoff-type conditions at the internal vertices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02608v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aleksandr Lednov</dc:creator>
    </item>
    <item>
      <title>Regularization of Port-Hamiltonian Descriptor Systems</title>
      <link>https://arxiv.org/abs/2509.02715</link>
      <description>arXiv:2509.02715v1 Announce Type: new 
Abstract: We study the regularization problem for port-Hamiltonian descriptor systems by proportional and/or derivative output feedback. Necessary and sufficient conditions are given, which guarantee that there exist output feedbacks such that the closed-loop system is regular, has index at most one, and is still port-Hamiltonian with desired rank properties. All results are derived based on condensed forms, computations of these condensed form can be implemented using only orthogonal transformations and hence are numerically reliable.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02715v1</guid>
      <category>math.OC</category>
      <category>math.DS</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Delin Chu, Volker Mehrmann</dc:creator>
    </item>
    <item>
      <title>A Proximal Descent Method for Minimizing Weakly Convex Optimization</title>
      <link>https://arxiv.org/abs/2509.02804</link>
      <description>arXiv:2509.02804v1 Announce Type: new 
Abstract: We study the problem of minimizing a $m$-weakly convex and possibly nonsmooth function. Weak convexity provides a broad framework that subsumes convex, smooth, and many composite nonconvex functions. In this work, we propose a $\textit{proximal descent method}$, a simple and efficient first-order algorithm that combines the inexact proximal point method with classical convex bundle techniques. Our analysis establishes explicit non-asymptotic convergence rates in terms of $(\eta,\epsilon)$-inexact stationarity. In particular, the method finds an $(\eta,\epsilon)$-inexact stationary point using at most $\mathcal{O}\!\left( \Big(\tfrac{1}{\eta^2} + \tfrac{1}{\epsilon}\Big) \max\!\left\{\tfrac{1}{\eta^2}, \tfrac{1}{\epsilon}\right\} \right)$ function value and subgradient evaluations. Consequently, the algorithm also achieves the best-known complexity of $\mathcal{O}(1/\delta^4)$ for finding an approximate Moreau stationary point with $\|\nabla f_{2m}(x)\|\leq \delta$. A distinctive feature of our method is its \emph{automatic adaptivity}: with no parameter tuning or algorithmic modification, it accelerates to $\mathcal{O}(1/\delta^2)$ complexity under smoothness and further achieves linear convergence under quadratic growth. Overall, this work bridges convex bundle methods and weakly convex optimization, while providing accelerated guarantees under structural assumptions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02804v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Feng-Yi Liao, Yang Zheng</dc:creator>
    </item>
    <item>
      <title>Moment-SOS hierarchies for arrow-type polynomial matrix inequalities with applications to structural optimization</title>
      <link>https://arxiv.org/abs/2509.02849</link>
      <description>arXiv:2509.02849v1 Announce Type: new 
Abstract: The Arrow Decomposition (AD) technique, initially introduced in [Mathematical Programming 190(1-2) (2021), pp 105-134], demonstrated superior scalability over the classical chordal decomposition in the context of Linear Matrix Inequalities (LMIs) if the matrix in question satisfied suitable assumptions. The primary objective of this paper is to extend the AD method to address Polynomial Optimization Problems (POPs) involving large-scale Polynomial Matrix Inequalities (PMIs), with the solution framework relying on moment-sum of square (mSOS) hierarchies. As a first step, we revisit the LMI case and weaken the conditions necessary for the key AD theorem presented in [Mathematical Programming 190(1-2) (2021), pp 105-134]. This modification allows the method to be applied to a broader range of problems. Next, we propose a practical procedure that reduces the number of additional variables, drawing on physical interpretations often found in structural optimization applications. For the PMI case, we explore two distinct approaches to combine the AD technique with mSOS hierarchies. One approach involves applying AD to the original POP before implementing the mSOS relaxation. The other approach applies AD directly to the mSOS relaxations of the POP. We establish convergence guarantees for both approaches and prove that theoretical properties extend to the polynomial case. Finally, we illustrate the significant computational advantages offered by the application of AD, particularly in the context of structural optimization problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02849v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Marouan Handa, Marek Tyburec, Giovanni Fantuzzi, Victor Magron, Michal Ko\v{c}vara</dc:creator>
    </item>
    <item>
      <title>A proximal augmented Lagrangian method for nonconvex optimization with equality and inequality constraints</title>
      <link>https://arxiv.org/abs/2509.02894</link>
      <description>arXiv:2509.02894v1 Announce Type: new 
Abstract: We propose an inexact proximal augmented Lagrangian method (P-ALM) for nonconvex structured optimization problems. The proposed method features an easily implementable rule not only for updating the penalty parameters, but also for adaptively tuning the proximal term. It allows the penalty parameter to grow rapidly in the early stages to speed up progress, while ameliorating the issue of ill-conditioning in later iterations, a well-known drawback of the traditional approach of linearly increasing the penalty parameters. A key element in our analysis lies in the observation that the augmented Lagrangian can be controlled effectively along the iterates, provided an initial feasible point is available. Our analysis, while simple, provides a new theoretical perspective about P-ALM and, as a by-product, results in similar convergence properties for its non-proximal variant, the classical augmented Lagrangian method (ALM). Numerical experiments, including convex and nonconvex problem instances, demonstrate the effectiveness of our approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02894v1</guid>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Adeyemi D. Adeoye, Puya Latafat, Alberto Bemporad</dc:creator>
    </item>
    <item>
      <title>Stochastic versus Deterministic in Stochastic Gradient Descent</title>
      <link>https://arxiv.org/abs/2509.02912</link>
      <description>arXiv:2509.02912v1 Announce Type: new 
Abstract: This paper considers the mini-batch stochastic gradient descent (SGD) for a structured minimization problem involving a finite-sum function with its gradient being stochastically approximated, and an independent term with its gradient being deterministically computed. We focus on the stochastic versus deterministic behavior of the mini-batch SGD for this setting. A convergence analysis is provided that captures the different roles of these two parts. Linear convergence of the algorithm to a neighborhood of the minimizer is established under some smoothness and convexity assumptions. The step size, the convergence rate, and the radius of the convergence region depend asymmetrically on the characteristics of the two components, which shows the distinct impacts of stochastic approximation versus deterministic computation in the mini-batch SGD. Moreover, a better convergence rate can be obtained when the independent term endows the objective function with sufficient strong convexity. Also, the convergence rate of our algorithm in expectation approaches that of the classic gradient descent when the batch size increases. Numerical experiments are conducted to support the theoretical analysis as well.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02912v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Runze Li, Jintao Xu, Wenxun Xing</dc:creator>
    </item>
    <item>
      <title>Faster Gradient Methods for Highly-smooth Stochastic Bilevel Optimization</title>
      <link>https://arxiv.org/abs/2509.02937</link>
      <description>arXiv:2509.02937v1 Announce Type: new 
Abstract: This paper studies the complexity of finding an $\epsilon$-stationary point for stochastic bilevel optimization when the upper-level problem is nonconvex and the lower-level problem is strongly convex. Recent work proposed the first-order method, F${}^2$SA, achieving the $\tilde{\mathcal{O}}(\epsilon^{-6})$ upper complexity bound for first-order smooth problems. This is slower than the optimal $\Omega(\epsilon^{-4})$ complexity lower bound in its single-level counterpart. In this work, we show that faster rates are achievable for higher-order smooth problems. We first reformulate F$^2$SA as approximating the hyper-gradient with a forward difference. Based on this observation, we propose a class of methods F${}^2$SA-$p$ that uses $p$th-order finite difference for hyper-gradient approximation and improves the upper bound to $\tilde{\mathcal{O}}(p \epsilon^{4-p/2})$ for $p$th-order smooth problems. Finally, we demonstrate that the $\Omega(\epsilon^{-4})$ lower bound also holds for stochastic bilevel problems when the high-order smoothness holds for the lower-level variable, indicating that the upper bound of F${}^2$SA-$p$ is nearly optimal in the highly smooth region $p = \Omega( \log \epsilon^{-1} / \log \log \epsilon^{-1})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02937v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lesi Chen, Junru Li, Jingzhao Zhang</dc:creator>
    </item>
    <item>
      <title>Arbitrary matrix coefficient assignment for block matrix linear control systems by static output feedback</title>
      <link>https://arxiv.org/abs/2509.03040</link>
      <description>arXiv:2509.03040v1 Announce Type: new 
Abstract: This work has introduced a generalized formulation of the problem of eigenvalue spectrum assignment for block matrix systems. In this problem, it is required to construct a feedback that provides that the matrix of the closed-loop system is similar to a block companion matrix with arbitrary predetermined block matrix coefficients. Sufficient conditions for the resolvability of this problem by linear static output feedback are obtained when the coefficients of the system have a special form, namely, the state matrix is a lower block Frobenius matrix or a lower block Hessenberg matrix, and the input and output block matrix coefficients contain some zero blocks. These conditions are controllability-like rank conditions. Sufficient conditions are constructive. It is proved that, in particular cases, when the system has block scalar matrix coefficients, these conditions can be weakened. The results generalize the previous results obtained for the case of one-dimensional blocks and for the case of systems given by a linear differential equation of higher orders with a multidimensional state. Based on the main results, algorithms are developed that ensure the construction of a gain matrix. The algorithms are implemented on a modeling examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03040v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vasilii Zaitsev, Inna Kim</dc:creator>
    </item>
    <item>
      <title>Optimal Dividend Control with Transaction Costs under Exponential Parisian Ruin for a Refracted Levy Risk Model</title>
      <link>https://arxiv.org/abs/2509.03068</link>
      <description>arXiv:2509.03068v1 Announce Type: new 
Abstract: This paper concerns an optimal impulse control problem associated with a refracted L\'{e}vy process, involving the reduction of reserves to a predetermined level whenever they exceed a specified threshold. The ruin time is determined by Parisian exponential delays and limited by a lower ultimate bankrupt barrier. We initially obtained the necessary and sufficient conditions for the value function and the optimal impulse control policy. Given a candidate for the optimal strategy, the corresponding expected discounted dividend function is subsequently formulated in terms of the Parisian refracted scale function, which is employed to measure the expected discounted utility of the impulse control. Then, the optimality of the proposed impulse control is verified using the HJB inequalities, and a monotonicity-based criterion is established to identify the admissible region of optimal thresholds, which serves as the basis for the numerical computation of their optimal levels. Finally, we present applications and numerical examples related to Brownian risk process and Cram\'{e}r-Lundberg process with exponential claims, demonstrating the uniqueness of the optimal impulse strategy and exploring its sensitivity to parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03068v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhongqin Gao, Yan Lv, Jingmin He</dc:creator>
    </item>
    <item>
      <title>A Digital Twin Based Decision Support System for the Management of an Operating Room</title>
      <link>https://arxiv.org/abs/2509.03094</link>
      <description>arXiv:2509.03094v1 Announce Type: new 
Abstract: With healthcare demand rising worldwide, hospital services are increasingly needed. Hospitals' performance is tightly linked to their surgical suite performance, which makes it necessary for surgical suites to be efficient. In this paper, we focus on the operating room schedule execution and related decision-making. We thus propose a digital twin-based decision support system for the prospective and retrospective simulation and analysis of the operating room schedule execution. We describe the developed prototype (inputs/output/parameters/modeling) and its functionalities and show its application to an operating room inspired by a real case.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03094v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>14th Conference on Stochastic Models of Manufacturing and Service Operations (SMMSO 2024), Jun 2024, Naples, Italy</arxiv:journal_reference>
      <dc:creator>Leah Rifi (CGI), Canan Pehlivan (CGI), Cl\'ea Martinez (CGI), Maria Di Mascolo (G-SCOP, G-SCOP\_DOME2S), Franck Fontanili (CGI)</dc:creator>
    </item>
    <item>
      <title>Single and Multi-Objective Performance Optimization of an Algal-Bacterial Synthetic Process</title>
      <link>https://arxiv.org/abs/2509.03096</link>
      <description>arXiv:2509.03096v1 Announce Type: new 
Abstract: Microalgae are an important source of precursors (e.g. lipids) for a variety of biosynthetic processes (e.g. biofuel production). Their co-culturing with other organisms providing essential substrates for growth may reduce cost and provide new handles to control and robustify the production process. In previous work, we have introduced a nonlinear ordinary differential equation model for an optogenetically controllable algal-bacterial consortium, and studied maximization of algal biomass productivity in a continuous-flow bioreactor relative to optogenetic action and dilution rate.  In this work, we expand the investigation of steady-state production performance for different objective criteria and control knobs. We additionally consider a yield criterion and a cost criterion, as well as a multiobjective optimization problem whose solution is shown to directly relate with a notion of net process profit. We investigate dependence of the optimal solutions on all the available bioprocess control knobs (optogenetics, dilution rate, richness of input medium), providing analytical results to characterize the solutions from different criteria and the relations among them, as well as simulations illustrating our results for a realistic set of biological system parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03096v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>CDC 2025 - 64th IEEE Conference on Decision and Control, IEEE CSS, Dec 2025, Rio de Janeiro, Brazil</arxiv:journal_reference>
      <dc:creator>Rand Asswad (MICROCOSME, LIPhy), Jean-Luc Gouz\'e (MACBES, UniCA), Eugenio Cinquemani (MICROCOSME, BIOP-LIPhy)</dc:creator>
    </item>
    <item>
      <title>A modified exact penalty approach for general constrained $\ell_0$-sparse optimization problems</title>
      <link>https://arxiv.org/abs/2509.03203</link>
      <description>arXiv:2509.03203v1 Announce Type: new 
Abstract: We consider a general class of constrained optimization problems with an additional $\ell_0$- sparsity term in the objective function. Based on a recent reformulation of this difficult $\ell_0$-term, we consider a nonsmooth penalty approach which differs from the authors previous work by the fact that it can be directly applied to problems which do not necessarily contain nonnegativity constraints. This avoids a splitting of free variables into their positive and negative parts, reduces the dimension and fully exploits the one-to-one correspondence between local and global minima of the given $\ell_0$-sparse optimization problem and its reformulation. The penalty approach is shown to be exact in terms of minima and stationary points. Since the penalty function is (mildly) nonsmooth, we also present practical techniques for the solution of the subproblems arising within the penalty formulation. Finally, the results of an extensive numerical testing are provided.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03203v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Kanzow, Felix Wei{\ss}</dc:creator>
    </item>
    <item>
      <title>Mathematical Programs Using Tangential Subdifferentials</title>
      <link>https://arxiv.org/abs/2509.03205</link>
      <description>arXiv:2509.03205v1 Announce Type: new 
Abstract: In this paper, we deal with constraint qualifications, the stationary concept and the optimality conditions for nonsmooth mathematical programs with equilibrium constraints. The main tool of our study is the notion of tangential subdifferentials. Using the notion of tangential subdifferentials, we present constraint qualifications (namely, generalized standard Abadie, MPEC Abadie, MPEC Zangwill, constraint qualifications) and stationary concepts, and also establish relationships between constraint qualifications. Further, we establish sufficient optimality conditions for mathematical programs using tangential subdifferentials and suitable generalized convexity notion. We also give some examples that verify our results.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03205v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shashi Kant Mishra, Dheerendra Singh</dc:creator>
    </item>
    <item>
      <title>On space-time FEM for time-optimal control problems governed by parabolic equations with mixed and endpoints constraints</title>
      <link>https://arxiv.org/abs/2509.03207</link>
      <description>arXiv:2509.03207v1 Announce Type: new 
Abstract: In this paper, we consider a class of time-optimal control problems governed by linear parabolic equations with mixed control-state constraints and end-point constraints, and without Tikhonov regularization term in the objective function. By the finite element method, we discretize the optimal control problem to obtain a sequence of mathematical programming problems in finite-dimensional spaces. Under certain conditions, we show that the optimal solutions of the discrete problems converge to an optimal solution of the original problem. Besides, we show that if the second-order sufficient condition is satisfied, then some error estimates of approximate solutions are obtained.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03207v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Huynh Khanh, Bui Trong Kien</dc:creator>
    </item>
    <item>
      <title>Multi-period Asset-liability Management with Reinforcement Learning in a Regime-Switching Market</title>
      <link>https://arxiv.org/abs/2509.03251</link>
      <description>arXiv:2509.03251v1 Announce Type: new 
Abstract: This paper explores the mean-variance portfolio selection problem in a multi-period financial market characterized by regime-switching dynamics and uncontrollable liabilities. To address the uncertainty in the decision-making process within the financial market, we incorporate reinforcement learning (RL) techniques. Specifically, the study examines an exploratory mean-variance (EMV) framework where investors aim to minimize risk while maximizing returns under incomplete market information, influenced by shifting economic regimes. The market model includes risk-free and risky assets, with liability dynamics driven by a Markov regime-switching process. To align with real-world scenarios where financial decisions are made over discrete time periods, we adopt a multi-period dynamic model. We present an optimal portfolio strategy derived using RL techniques that adapt to these market conditions. The proposed solution addresses the inherent time inconsistency in classical mean-variance models by integrating a pre-committed strategy formulation. Furthermore, we incorporate partial market observability, employing stochastic filtering techniques to estimate unobservable market states. Numerical simulations and empirical tests on real financial data demonstrate that our method achieves superior returns, lower risk, and faster convergence compared to traditional models. These findings highlight the robustness and adaptability of our RL-based solution in dynamic and complex financial environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03251v1</guid>
      <category>math.OC</category>
      <category>math.PR</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Zhongqin Gao, Ping Chen, Xun Li, Yan Lv, Wenhao Zhang</dc:creator>
    </item>
    <item>
      <title>Linearly involved Generalized Moreau Enhanced Model with Non-quadratic Smooth Convex Data Fidelity Functions</title>
      <link>https://arxiv.org/abs/2509.03258</link>
      <description>arXiv:2509.03258v1 Announce Type: new 
Abstract: In this paper, we introduce an overall convex model incorporating a nonconvex regularizer. The proposed model is designed by extending the least squares term in the constrained LiGME model [Yata Yamagishi Yamada 2022] to fairly general smooth convex functions for flexible utilization of non-quadratic data fidelity functions. Under an overall convexity condition for the proposed model, we present sufficient conditions for the existence of a minimizer of the proposed model and an inner-loop free algorithm with guaranteed convergence to a global minimizer of the proposed model. To demonstrate the effectiveness of the proposed model and algorithm, we conduct numerical experiments in scenarios of Poisson denoising problem and simultaneous declipping and denoising problem.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03258v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wataru Yata, Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>On Optimality of Private Information in Bayesian Routing Games</title>
      <link>https://arxiv.org/abs/2509.03357</link>
      <description>arXiv:2509.03357v1 Announce Type: new 
Abstract: We study an information design problem in transportation networks, in the presence of a random state that affects the travel times on the links. An omniscient system planner -- aiming at reducing congestion -- observes the network state realization and sends private messages to the users -- who share a common prior on the network state but do not observe it directly -- in order to nudge them towards a socially desirable behavior. The desired effect of these private signals is to correlate the users' selfish decisions with the network state and align the resulting Bayesian Wardrop equilibrium with the system optimum flow. Our main contribution is to provide sufficient and necessary conditions under which optimality may be achieved by a fair private signal policy in transportation networks with injective link-path incidence matrix and affine travel time functions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03357v1</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alexia Ambrogio, Leonardo Cianfanelli, Giacomo Como</dc:creator>
    </item>
    <item>
      <title>On the Perturbed Projection-Based Distributed Gradient-Descent Algorithm: A Fully-Distributed Adaptive Redesign</title>
      <link>https://arxiv.org/abs/2509.03443</link>
      <description>arXiv:2509.03443v1 Announce Type: new 
Abstract: In this work, we revisit a classical distributed gradient-descent algorithm, introducing an interesting class of perturbed multi-agent systems. The state of each subsystem represents a local estimate of a solution to the global optimization problem. Thereby, the network is required to minimize local cost functions, while gathering the local estimates around a common value. Such a complex task suggests the interplay of consensus-based dynamics with gradient-descent dynamics. The latter descent dynamics involves the projection operator, which is assumed to provide corrupted projections of a specific form, reminiscent of existing (fast) projection algorithms. Hence, for the resulting class of perturbed networks, we are able to adaptively tune some gains in a fully distributed fashion, to approach the optimal consensus set up to arbitrary-desired precision.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03443v1</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Tarek Bazizi, Mohamed Maghenem, Paolo Frasca, Antonio Lor\`ia, Elena Panteley</dc:creator>
    </item>
    <item>
      <title>From Image Denoisers to Regularizing Imaging Inverse Problems: An Overview</title>
      <link>https://arxiv.org/abs/2509.03475</link>
      <description>arXiv:2509.03475v1 Announce Type: new 
Abstract: Inverse problems lie at the heart of modern imaging science, with broad applications in areas such as medical imaging, remote sensing, and microscopy. Recent years have witnessed a paradigm shift in solving imaging inverse problems, where data-driven regularizers are used increasingly, leading to remarkably high-fidelity reconstruction. A particularly notable approach for data-driven regularization is to use learned image denoisers as implicit priors in iterative image reconstruction algorithms. This survey presents a comprehensive overview of this powerful and emerging class of algorithms, commonly referred to as plug-and-play (PnP) methods. We begin by providing a brief background on image denoising and inverse problems, followed by a short review of traditional regularization strategies. We then explore how proximal splitting algorithms, such as the alternating direction method of multipliers (ADMM) and proximal gradient descent (PGD), can naturally accommodate learned denoisers in place of proximal operators, and under what conditions such replacements preserve convergence. The role of Tweedie's formula in connecting optimal Gaussian denoisers and score estimation is discussed, which lays the foundation for regularization-by-denoising (RED) and more recent diffusion-based posterior sampling methods. We discuss theoretical advances regarding the convergence of PnP algorithms, both within the RED and proximal settings, emphasizing the structural assumptions that the denoiser must satisfy for convergence, such as non-expansiveness, Lipschitz continuity, and local homogeneity. We also address practical considerations in algorithm design, including choices of denoiser architecture and acceleration strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03475v1</guid>
      <category>math.OC</category>
      <category>cs.LG</category>
      <category>eess.IV</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hong Ye Tan, Subhadip Mukherjee, Junqi Tang</dc:creator>
    </item>
    <item>
      <title>Approximate constrained stochastic optimal control via parameterized input inference</title>
      <link>https://arxiv.org/abs/2509.02922</link>
      <description>arXiv:2509.02922v1 Announce Type: cross 
Abstract: Approximate methods to solve stochastic optimal control (SOC) problems have received significant interest from researchers in the past decade. Probabilistic inference approaches to SOC have been developed to solve nonlinear quadratic Gaussian problems. In this work, we propose an Expectation-Maximization (EM) based inference procedure to generate state-feedback controls for constrained SOC problems. We consider the inequality constraints for the state and controls and also the structural constraints for the controls. We employ barrier functions to address state and control constraints. We show that the expectation step leads to smoothing of the state-control pair while the the maximization step on the non-zero subsets of the control parameters allows inference of structured stochastic optimal controllers. We demonstrate the effectiveness of the algorithm on unicycle obstacle avoidance, four-unicycle formation control, and quadcopter navigation in windy environment examples. In these examples, we perform an empirical study on the parametric effect of barrier functions on the state constraint satisfaction. We also present a comparative study of smoothing algorithms on the performance of the proposed approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02922v1</guid>
      <category>eess.SY</category>
      <category>cs.MA</category>
      <category>cs.RO</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>Automatica Volume 171, January 2025</arxiv:journal_reference>
      <dc:creator>Shahbaz P Qadri Syed, He Bai</dc:creator>
    </item>
    <item>
      <title>Delayed Momentum Aggregation: Communication-efficient Byzantine-robust Federated Learning with Partial Participation</title>
      <link>https://arxiv.org/abs/2509.02970</link>
      <description>arXiv:2509.02970v1 Announce Type: cross 
Abstract: Federated Learning (FL) allows distributed model training across multiple clients while preserving data privacy, but it remains vulnerable to Byzantine clients that exhibit malicious behavior. While existing Byzantine-robust FL methods provide strong convergence guarantees (e.g., to a stationary point in expectation) under Byzantine attacks, they typically assume full client participation, which is unrealistic due to communication constraints and client availability. Under partial participation, existing methods fail immediately after the sampled clients contain a Byzantine majority, creating a fundamental challenge for sparse communication. First, we introduce delayed momentum aggregation, a novel principle where the server aggregates the most recently received gradients from non-participating clients alongside fresh momentum from active clients. Our optimizer D-Byz-SGDM (Delayed Byzantine-robust SGD with Momentum) implements this delayed momentum aggregation principle for Byzantine-robust FL with partial participation. Then, we establish convergence guarantees that recover previous full participation results and match the fundamental lower bounds we prove for the partial participation setting. Experiments on deep learning tasks validated our theoretical findings, showing stable and robust training under various Byzantine attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02970v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kaoru Otsuka, Yuki Takezawa, Makoto Yamada</dc:creator>
    </item>
    <item>
      <title>AdaGrad Meets Muon: Adaptive Stepsizes for Orthogonal Updates</title>
      <link>https://arxiv.org/abs/2509.02981</link>
      <description>arXiv:2509.02981v1 Announce Type: cross 
Abstract: The recently proposed Muon optimizer updates weight matrices via orthogonalized momentum and has demonstrated strong empirical success in large language model training. However, it remains unclear how to determine the learning rates for such orthogonalized updates. AdaGrad, by contrast, is a widely used adaptive method that scales stochastic gradients by accumulated past gradients. We propose a new algorithm, AdaGO, which combines a norm-based AdaGrad-type stepsize with an orthogonalized update direction, bringing together the benefits of both approaches. Unlike other adaptive variants of Muon, AdaGO preserves the orthogonality of the update direction, which can be interpreted as a spectral descent direction, while adapting the stepsizes to the optimization landscape by scaling the direction with accumulated past gradient norms. The implementation of AdaGO requires only minimal modification to Muon, with a single additional scalar variable, the accumulated squared gradient norms, to be computed, making it computationally and memory efficient. Optimal theoretical convergence rates are established for nonconvex functions in both stochastic and deterministic settings under standard smoothness and unbiased bounded-variance noise assumptions. Empirical results on CIFAR-10 classification and function regression demonstrate that AdaGO outperforms Muon and Adam.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.02981v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Minxin Zhang, Yuxuan Liu, Hayden Schaeffer</dc:creator>
    </item>
    <item>
      <title>Rough Path Approaches to Stochastic Control, Filtering, and Stopping</title>
      <link>https://arxiv.org/abs/2509.03055</link>
      <description>arXiv:2509.03055v1 Announce Type: cross 
Abstract: This paper presents a unified exposition of rough path methods applied to optimal control, robust filtering, and optimal stopping, addressing a notable gap in the existing literature where no single treatment covers all three areas. By bringing together key elements from Lyons' theory of rough paths, Gubinelli's controlled rough paths, and related developments, we recast these classical problems within a deterministic, pathwise framework. Particular emphasis is placed on providing detailed proofs and explanations where these have been absent or incomplete, culminating in a proof of the central verification theorem, which is another key contribution of this paper. This result establishes the rigorous connection between candidate solutions to optimal control problems and the Hamilton-Jacobi-Bellman equation in the rough path setting. Alongside these contributions, we identify several theoretical challenges -- most notably, extending the verification theorem and associated results to general p-variation with -- and outline promising directions for future research. The paper is intended as a self-contained reference for researchers seeking to apply rough path theory to decision-making problems in stochastic analysis, mathematical finance, and engineering.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03055v1</guid>
      <category>q-fin.MF</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonathan A. Mavroforas, Anthony H. Dooley</dc:creator>
    </item>
    <item>
      <title>On the Smart Coordination of Flexibility Scheduling in Multi-carrier Integrated Energy Systems</title>
      <link>https://arxiv.org/abs/2509.03126</link>
      <description>arXiv:2509.03126v1 Announce Type: cross 
Abstract: Coordinating the interactions between flexibility assets in multi-carrier integrated energy systems (MIES) can lead to an efficient integration of variable renewable energy resources, and a cost-efficient energy transition. However, the proliferation of flexibility assets and their participation in active demand response increases the complexity of coordinating these interactions. This paper introduces different approaches to model the coordination of flexibility scheduling in MIES. We propose a market auction-inspired model coupling approach to address the challenges of preserving the autonomy and privacy of flexibility providers, and the issue of scalability. We benchmark our approach against co-optimization and an iterative price-response method by conducting experiments with varying problem sizes and computing infrastructure. We show that our approach scales well and is suitable for modeling flexibility in large-scale energy systems in a more realistic way. From an optimality standpoint, the flexibility dispatch schedules and electricity prices are ``near-optimal". Our methodology is implemented as a new open-source software, which offers several practical applications. For example, flexibility providers and network operators can couple their models to simulate the interaction between their systems without disclosing confidential information; policy regulators can use it to investigate new market design and regulations to optimize the utilization of flexibility in MIES.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03126v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>econ.GN</category>
      <category>math.OC</category>
      <category>q-fin.EC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Christian Doh Dinga, Sander van Rijn, Laurens de Vries, Milos Cvetkovic</dc:creator>
    </item>
    <item>
      <title>Hidden Convexity in Active Learning: A Convexified Online Input Design for ARX Systems</title>
      <link>https://arxiv.org/abs/2509.03257</link>
      <description>arXiv:2509.03257v1 Announce Type: cross 
Abstract: The goal of this work is to accelerate the identification of an unknown ARX system from trajectory data through online input design. Specifically, we present an active learning algorithm that sequentially selects the input to excite the system according to an experiment design criterion using the past measured data. The adopted criterion yields a non-convex optimization problem, but we provide an exact convex reformulation allowing to find the global optimizer in a computationally tractable way. Moreover, we give sample complexity bounds on the estimation error due to the stochastic noise. Numerical studies showcase the effectiveness of our algorithm and the benefits of the convex reformulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03257v1</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nicolas Chatzikiriakos, Bowen Song, Philipp Rank, Andrea Iannelli</dc:creator>
    </item>
    <item>
      <title>Geometric Foundations of Tuning without Forgetting in Neural ODEs</title>
      <link>https://arxiv.org/abs/2509.03474</link>
      <description>arXiv:2509.03474v1 Announce Type: cross 
Abstract: In our earlier work, we introduced the principle of Tuning without Forgetting (TwF) for sequential training of neural ODEs, where training samples are added iteratively and parameters are updated within the subspace of control functions that preserves the end-point mapping at previously learned samples on the manifold of output labels in the first-order approximation sense. In this letter, we prove that this parameter subspace forms a Banach submanifold of finite codimension under nonsingular controls, and we characterize its tangent space. This reveals that TwF corresponds to a continuation/deformation of the control function along the tangent space of this Banach submanifold, providing a theoretical foundation for its mapping-preserving (not forgetting) during the sequential training exactly, beyond first-order approximation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03474v1</guid>
      <category>cs.LG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Erkan Bayram, Mohamed-Ali Belabbas, Tamer Ba\c{s}ar</dc:creator>
    </item>
    <item>
      <title>Learning AC Power Flow Solutions using a Data-Dependent Variational Quantum Circuit</title>
      <link>https://arxiv.org/abs/2509.03495</link>
      <description>arXiv:2509.03495v1 Announce Type: cross 
Abstract: Interconnection studies require solving numerous instances of the AC load or power flow (AC PF) problem to simulate diverse scenarios as power systems navigate the ongoing energy transition. To expedite such studies, this work leverages recent advances in quantum computing to find or predict AC PF solutions using a variational quantum circuit (VQC). VQCs are trainable models that run on modern-day noisy intermediate-scale quantum (NISQ) hardware to accomplish elaborate optimization and machine learning (ML) tasks. Our first contribution is to pose a single instance of the AC PF as a nonlinear least-squares fit over the VQC trainable parameters (weights) and solve it using a hybrid classical/quantum computing approach. The second contribution is to feed PF specifications as features into a data-embedded VQC and train the resultant quantum ML (QML) model to predict general PF solutions. The third contribution is to develop a novel protocol to efficiently measure AC-PF quantum observables by exploiting the graph structure of a power network. Preliminary numerical tests indicate that the proposed VQC models attain enhanced prediction performance over a deep neural network despite using much fewer weights. The proposed quantum AC-PF framework sets the foundations for addressing more elaborate grid tasks via quantum computing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03495v1</guid>
      <category>quant-ph</category>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Thinh Viet Le, Md Obaidur Rahman, Vassilis Kekatos</dc:creator>
    </item>
    <item>
      <title>A Brenier Theorem on $(\mathcal{P}_2 (\mathcal{P}_2(\mathbb{R}^d )), W_2 )$ and Applications to Adapted Transport</title>
      <link>https://arxiv.org/abs/2509.03506</link>
      <description>arXiv:2509.03506v1 Announce Type: cross 
Abstract: Brenier's fundamental theorem characterizes optimal transport plans for measures $\mu, \nu$ on $\mathbb{R}^d$ and quadratic distance costs in terms of gradients of convex functions. In particular it guarantees the existence of optimal transport maps for measures which are absolutely continuous wrt Lebesgue measure.
  Our goal is to provide a version of this result for measures $P,Q$ on $\mathcal{P}_2(\mathbb{R}^d)$ and costs given by the squared Wasserstein distance $W_2^2(\mu, \nu)$. We characterize optimizers in terms of convexity of the Lions lift. This is based on an observation which seems to be of independent interest: the $c$-transform of a functional $\phi$, where $c(\mu, \nu)$ denotes maximal covariance of $\mu, \nu$ corresponds precisely to the Legendre transform of the Lions lift of $\phi$. Moreover we show that for typical $P \in\mathcal{P}_2(\mathbb{R}^d)$ the optimizer is unique and given by a transport map. In the absence of a canonical reference measure on $\mathcal{P}_2(\mathbb{R}^d)$ we use a topological notion to make `typical' precise. Specifically we show that the transport regular measures are of second Baire category.
  A particular motivation for our article stems from the theory of adapted transport where the adapted Wasserstein distance provides an adequate distance between stochastic processes. In contrast to other metrics, the adapted Wasserstein distance yields continuity of Doob-decomposition, optimal stopping and stochastic control problems. Based on our results for measures on $\mathcal{P}_2(\mathbb{R}^d)$ we obtain a first Brenier-type theorem for the adapted Wasserstein distance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.03506v1</guid>
      <category>math.PR</category>
      <category>math.FA</category>
      <category>math.MG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mathias Beiglb\"ock, Gudmund Pammer, Stefan Schrott</dc:creator>
    </item>
    <item>
      <title>An Exponentially Converging Particle Method for the Mixed Nash Equilibrium of Continuous Games</title>
      <link>https://arxiv.org/abs/2211.01280</link>
      <description>arXiv:2211.01280v4 Announce Type: replace 
Abstract: We consider the problem of computing mixed Nash equilibria of two-player zero-sum games with continuous sets of pure strategies and with first-order access to the payoff function. This problem arises for example in game-theory-inspired machine learning applications, such as distributionally-robust learning. In those applications, the strategy sets are high-dimensional and thus methods based on discretisation cannot tractably return high-accuracy solutions.
  In this paper, we introduce and analyze a particle-based method that enjoys guaranteed local convergence for this problem. This method consists in parametrizing the mixed strategies as atomic measures and applying proximal point updates to both the atoms' weights and positions. It can be interpreted as a time-implicit discretization of the "interacting" Wasserstein-Fisher-Rao gradient flow.
  We prove that, under non-degeneracy assumptions, this method converges at an exponential rate to the exact mixed Nash equilibrium from any initialization satisfying a natural notion of closeness to optimality. We illustrate our results with numerical experiments and discuss applications to max-margin and distributionally-robust classification using two-layer neural networks, where our method has a natural interpretation as a simultaneous training of the network's weights and of the adversarial distribution.</description>
      <guid isPermaLink="false">oai:arXiv.org:2211.01280v4</guid>
      <category>math.OC</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.5802/ojmo.37</arxiv:DOI>
      <arxiv:journal_reference>Open Journal of Mathematical Optimization, Volume 6 (2025), article no. 1, 66 p</arxiv:journal_reference>
      <dc:creator>Guillaume Wang, L\'ena\"ic Chizat</dc:creator>
    </item>
    <item>
      <title>MF-OML: Online Mean-Field Reinforcement Learning with Occupation Measures for Large Population Games</title>
      <link>https://arxiv.org/abs/2405.00282</link>
      <description>arXiv:2405.00282v2 Announce Type: replace 
Abstract: Reinforcement learning for multi-agent games has attracted lots of attention recently. However, given the challenge of solving Nash equilibria for large population games, existing works with guaranteed polynomial complexities either focus on variants of zero-sum and potential games, or aim at solving (coarse) correlated equilibria, or require access to simulators, or rely on certain assumptions that are hard to verify. This work proposes MF-OML (Mean-Field Occupation-Measure Learning), an online mean-field reinforcement learning algorithm for computing approximate Nash equilibria of large population sequential symmetric games. MF-OML is the first fully polynomial multi-agent reinforcement learning algorithm for provably solving Nash equilibria (up to mean-field approximation gaps that vanish as the number of players $N$ goes to infinity) beyond variants of zero-sum and potential games. When evaluated by the cumulative deviation from Nash equilibria, the algorithm is shown to achieve a high probability regret bound of $\tilde{O}(M^{3/4}+N^{-1/2}M)$ for games with the strong Lasry-Lions monotonicity condition, and a regret bound of $\tilde{O}(M^{11/12}+N^{- 1/6}M)$ for games with only the Lasry-Lions monotonicity condition, where $M$ is the total number of episodes and $N$ is the number of agents of the game. As a byproduct, we also obtain the first tractable globally convergent computational algorithm for computing approximate Nash equilibria of monotone mean-field games.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.00282v2</guid>
      <category>math.OC</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Anran Hu, Junzi Zhang</dc:creator>
    </item>
    <item>
      <title>Exact SDP relaxations for a class of quadratic programs with finite and infinite quadratic constraints</title>
      <link>https://arxiv.org/abs/2409.07213</link>
      <description>arXiv:2409.07213v2 Announce Type: replace 
Abstract: We investigate exact semidefinite programming (SDP) relaxations for the problem of minimizing a nonconvex quadratic objective function over a feasible region defined by both finitely and infinitely many nonconvex quadratic inequality constraints (semi-infinite QCQPs). Sufficient conditions for the exactness of SDP relaxations for QCQPs with finitely many constraints have been extensively studied, notably by Argue et al. (MOR, 48:100-126, 2023), Arima et al. (SIOPT, 34:3194-3211, 2024), and Joyse and Yang (MP, 205:539-558, 2024). In this work, we present three new sufficient conditions that generalize the existing conditions in these works for both finite and semi-infinite QCQPs. Specifically, we establish relationships among the proposed and existing conditions, and prove that one of the proposed conditions is the weakest among them. Illustrative examples are also provided to demonstrate the effectiveness of the proposed conditions in comparison to the existing ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.07213v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Naohiko Arima, Sunyoung Kim, Masakazu Kojima</dc:creator>
    </item>
    <item>
      <title>Curvature-Adaptive Perturbation and Subspace Descent for Robust Saddle Point Escape in High-Dimensional Optimization</title>
      <link>https://arxiv.org/abs/2409.12604</link>
      <description>arXiv:2409.12604v4 Announce Type: replace 
Abstract: High-dimensional non-convex optimization problems in engineering design, control, and learning are often hindered by saddle points, flat plateaus, and strongly anisotropic curvature. This paper develops a unified, curvature-adaptive framework that combines stochastic perturbations, adaptive learning rates, and randomized subspace descent to enhance escape efficiency and scalability. We show theoretically that gradient flow almost surely avoids strict saddles, with escape probability increasing exponentially in dimension. For noise-perturbed gradient descent, we derive explicit escape-time bounds that depend on local curvature and noise magnitude. Adaptive step sizes further reduce escape times by responding to local gradient variability, while randomized subspace descent preserves descent directions in low-dimensional projections and ensures global convergence with logarithmic dependence on dimension. Numerical experiments on nonlinear and constrained benchmarks validate these results, demonstrating faster escape, improved robustness to ill-conditioning, and lower total runtime compared to standard first- and second-order methods. The proposed approach offers practical tools for large-scale engineering optimization tasks where curvature, noise, and dimensionality interplay critically.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12604v4</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ronald Katende, Henry Kasumba</dc:creator>
    </item>
    <item>
      <title>Bounding the Optimal Number of Policies for Robust K-Adaptability</title>
      <link>https://arxiv.org/abs/2409.12630</link>
      <description>arXiv:2409.12630v3 Announce Type: replace 
Abstract: In the realm of robust optimization the k-adaptability approach is one promising method to derive approximate solutions for two-stage robust optimization problems. Instead of allowing all possible second-stage decisions, the k-adaptability approach aims at calculating a limited set of k such decisions already in the first-stage before the uncertainty is revealed. The parameter k can be adjusted to control the quality of the approximation. However, not much is known on how many solutions k are needed to achieve an optimal solution for the two-stage robust problem. In this work we derive bounds on k which guarantee optimality for general non-linear problems with integer decisions where the uncertainty appears in the objective function or in the constraints. For convex uncertainty sets we show that for objective uncertainty the bound depends linearly on the dimension of the uncertainty, while for constraint uncertainty the dependence can be exponential, still providing the first generic bound for a wide class of problems. Additionally, we provide approximation guarantees if k is smaller than the derived bounds. The results give new insights on how many solutions are needed for problems as the decision dependent information discovery problem or the capital budgeting problem with constraint uncertainty. Finally, for finite uncertainty sets we show that calculating the minimal k for which k-adaptable and two-stage problems are equivalent is NP-hard and derive a greedy method which approximates this k for the case where no first-stage decisions exist.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.12630v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jannis Kurtz</dc:creator>
    </item>
    <item>
      <title>Robust optimal stopping with regime switching</title>
      <link>https://arxiv.org/abs/2411.06522</link>
      <description>arXiv:2411.06522v3 Announce Type: replace 
Abstract: In this paper, we study an optimal stopping problem in the presence of model uncertainty and regime switching. The max-min formulation for robust control and the dynamic programming approach are adopted to establish a general theoretical framework for such kind of problem. First, based on the dynamic programming principle, the value function of the optimal stopping problem is characterized as the unique viscosity solution to the associated Hamilton-Jacobi-Bellman equation. Then, the so-called smooth-fit principle for optimal stopping problems is proved in the current context, and a verification theorem consisting of a set of sufficient conditions for robust optimality is established. Moreover, when the Markov chain has a large state space and exhibits a two-time-scale structure, a singular perturbation approach is utilized to reduce the complexity involved and obtain an asymptotically optimal solution. Finally, an example of choosing the best time to sell a stock is provided, in which numerical experiments are reported to illustrate the implications of model uncertainty and regime switching.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.06522v3</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siyu Lv, Zhen Wu, Jie Xiong, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>On Supportedness in Multi-Objective Combinatorial Optimization</title>
      <link>https://arxiv.org/abs/2501.13842</link>
      <description>arXiv:2501.13842v2 Announce Type: replace 
Abstract: This paper addresses an inconsistency in various definitions of supported non-dominated points within multi-objective combinatorial problems (MOCO). MOCO problems are known to contain supported and unsupported non-dominated points, with the latter typically outnumbering the former. Supported points are, in general, easier to determine, can serve as representations, and are used in two-phase methods to generate the entire non-dominated point set. Despite their importance, several different characterizations for supported efficient solutions (and supported non-dominated points) are used in the literature.
  While these definitions are equivalent for multi-objective linear problems, they can yield different sets of supported non-dominated points for MOCO problems. We show by an example that these definitions are not equivalent for MOCO or general multi-objective optimization problems. Moreover, we analyze the structural and computational properties of the resulting sets of supported non-dominated points. These considerations motivate us to summarize equivalent definitions and characterizations for supported efficient solutions and to introduce a distinction between supported and weakly supported efficient solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.13842v2</guid>
      <category>math.OC</category>
      <category>cs.DM</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>David K\"onen, Michael Stiglmayr</dc:creator>
    </item>
    <item>
      <title>A Universally Optimal Primal-Dual Method for Minimizing Heterogeneous Compositions</title>
      <link>https://arxiv.org/abs/2503.07566</link>
      <description>arXiv:2503.07566v2 Announce Type: replace 
Abstract: This paper proposes a universal, optimal algorithm for convex minimization problems of the composite form $g_0(x)+h(g_1(x),\dots, g_m(x)) + u(x)$. We allow each $g_j$ to independently range from being nonsmooth Lipschitz to smooth, from convex to strongly convex, described by notions of H\"older continuous gradients and uniform convexity. Note that, although the objective is built from a heterogeneous combination of such structured components, it does not necessarily possess smoothness, Lipschitzness, or any favorable structure overall other than convexity. Regardless, we provide a universal optimal method in terms of oracle access to (sub)gradients of each $g_j$. The key insight enabling our optimal universal analysis is the construction of two new constants, the Approximate Dualized Aggregate smoothness and strong convexity, which combine the benefits of each heterogeneous structure into single quantities amenable to analysis. As a key application, fixing $h$ as the nonpositive indicator function, this model readily captures functionally constrained minimization $g_0(x)+u(x)$ subject to $g_j(x)\leq 0$. In particular, our algorithm and analysis are directly inspired by the smooth constrained minimization method of Zhang and Lan and consequently recover and generalize their accelerated guarantees.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.07566v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aaron Zoll, Benjamin Grimmer</dc:creator>
    </item>
    <item>
      <title>A convexity preserving nonconvex regularization for inverse problems under non-Gaussian noise</title>
      <link>https://arxiv.org/abs/2503.13287</link>
      <description>arXiv:2503.13287v2 Announce Type: replace 
Abstract: We propose a nonconvexly regularized convex model for linear regression problems under non-Gaussian noise. The cost function of the proposed model is designed with a possibly non-quadratic data fidelity term and a nonconvex regularizer via the generalized Moreau enhancement of a seed convex regularizer. We present sufficient conditions (i) for the cost function of the proposed model to be convex over the entire space, and (ii) for the existence of a minimizer of the proposed model. Under such conditions, we propose a proximal splitting type algorithm with guaranteed convergence to a global minimizer of the proposed model. As an application, we enhance nonconvexly a convex sparsity-promoting regularizer in a scenario of simultaneous declipping and denoising.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.13287v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Wataru Yata, Keita Kume, Isao Yamada</dc:creator>
    </item>
    <item>
      <title>A generalized Hurwitz stability criterion via rectangular block Hankel matrices for nonmonic matrix polynomials</title>
      <link>https://arxiv.org/abs/2508.14376</link>
      <description>arXiv:2508.14376v3 Announce Type: replace 
Abstract: We develop a Hurwitz stability criterion for nonmonic matrix polynomials via column reduction, generalizing existing approaches constrained by the monic assumption, as well as Gantmacher's classical stability criterion via Markov parameters. Starting from redefining the associated Markov parameters through a column-wise adaptive splitting method, our framework constructs two structured matrices whose rectangular Hankel blocks are obtained via the extraction of these parameters. We establish an explicit interrelation between the inertias of column reduced matrix polynomials and the derived structured matrices. Furthermore, we demonstrate that the Hurwitz stability of column reduced matrix polynomials can be determined by the Hermitian positive definiteness of these rectangular block Hankel matrices.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.14376v3</guid>
      <category>math.OC</category>
      <category>cs.NA</category>
      <category>math.NA</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xuzhou Zhan, Zixiang Ni</dc:creator>
    </item>
    <item>
      <title>Discounted LQR: stabilizing (near-)optimal state-feedback laws</title>
      <link>https://arxiv.org/abs/2508.19599</link>
      <description>arXiv:2508.19599v2 Announce Type: replace 
Abstract: We study deterministic, discrete linear time-invariant systems with infinite-horizon discounted quadratic cost. It is well-known that standard stabilizability and detectability properties are not enough in general to conclude stability properties for the system in closed-loop with the optimal controller when the discount factor is small. In this context, we first review some of the stability conditions based on the optimal value function found in the learning and control literature and highlight their conservatism. We then propose novel (necessary and) sufficient conditions, still based on the optimal value function, under which stability of the origin for the optimal closed-loop system is guaranteed. Afterwards, we focus on the scenario where the optimal feedback law is not stabilizing because of the discount factor and the goal is to design an alternative stabilizing near-optimal static state-feedback law. We present both linear matrix inequality-based conditions and a variant of policy iteration to construct such stabilizing near-optimal controllers. The methods are illustrated via numerical examples.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.19599v2</guid>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonathan de Brusse, Jamal Daafouz, Mathieu Granzotto, Romain Postoyan, Dragan Nesic</dc:creator>
    </item>
    <item>
      <title>An Efficient Data-Driven Framework for Linear Quadratic Output Feedback Control</title>
      <link>https://arxiv.org/abs/2508.20748</link>
      <description>arXiv:2508.20748v2 Announce Type: replace 
Abstract: Linear quadratic regulator with unmeasurable states and unknown system matrix parameters better aligns with practical scenarios. However, for this problem, balancing the optimality of the resulting controller and the leniency of the algorithm's feasibility conditions remains a non-trivial challenge, as no well-established general method has yet been developed to address this trade-off. To address this gap, this study first develops a comprehensive theoretical framework for state parameterization that equivalently substitutes for unknown states. By analyzing the controllability of consistent systems satisfied by substitute states, this framework quantifies the capability of substitute state data matrices to parameterize unknown closed-loop systems and output feedback controllers, thereby constructing a modified state parameterization form that meets the complete data parameterization condition of Willems' Fundamental Lemma. Leveraging this framework, this study proposes efficient model-free off-policy policy iteration and value iteration algorithms with theoretical guarantees to solve for the optimal output feedback controller. Compared with existing studies, particularly for multi-output problems where existing model-free reinforcement learning algorithms may fail, the proposed method removes redundant information in substitute states and the additional full row rank condition on regression matrices, thereby ensuring the solution of optimal output feedback controllers equivalent to optimal state feedback controllers for multi-output systems. Furthermore, this study pioneers a comprehensive and highly scalable theoretical analysis of state parameterization from a data-driven viewpoint, and the proposed algorithms exhibit significant advantages in implementation conditions, data demand, unknown handling, and convergence speed.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20748v2</guid>
      <category>math.OC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jun Xie, Yuan-Hua Ni, Yiqin Yang, Bo Xu</dc:creator>
    </item>
    <item>
      <title>Cost-Driven Representation Learning for Linear Quadratic Gaussian Control: Part I</title>
      <link>https://arxiv.org/abs/2212.14511</link>
      <description>arXiv:2212.14511v3 Announce Type: replace-cross 
Abstract: We study the task of learning state representations from potentially high-dimensional observations, with the goal of controlling an unknown partially observable system. We pursue a cost-driven approach, where a dynamic model in some latent state space is learned by predicting the costs without predicting the observations or actions. In particular, we focus on an intuitive cost-driven state representation learning method for solving Linear Quadratic Gaussian (LQG) control, one of the most fundamental partially observable control problems. As our main results, we establish finite-sample guarantees of finding a near-optimal state representation function and a near-optimal controller using the directly learned latent model, for finite-horizon time-varying LQG control problems. To the best of our knowledge, despite various empirical successes, finite-sample guarantees of such a cost-driven approach remain elusive. Our result underscores the value of predicting multi-step costs, an idea that is key to our theory, and notably also an idea that is known to be empirically valuable for learning state representations. A second part of this work, that is to appear as Part II, addresses the infinite-horizon linear time-invariant setting; it also extends the results to an approach that implicitly learns the latent dynamics, inspired by the recent empirical breakthrough of MuZero in model-based reinforcement learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2212.14511v3</guid>
      <category>cs.LG</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <category>stat.ML</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi Tian, Kaiqing Zhang, Russ Tedrake, Suvrit Sra</dc:creator>
    </item>
    <item>
      <title>Graphical Quadratic Algebra</title>
      <link>https://arxiv.org/abs/2403.02284</link>
      <description>arXiv:2403.02284v3 Announce Type: replace-cross 
Abstract: Convex analysis and Gaussian probability are tightly connected, as mostly evident in the theory of linear regression. Our work introduces an algebraic perspective on such relationship, in the form of a diagrammatic calculus of string diagrams, called Graphical Quadratic Algebra (GQA). We show that GQA is a complete axiomatisation for the category of quadratic relations, a compositional formulation of quadratic problems. Moreover, we identify a sub-theory of GQA which is complete for the category of Gaussian probabilistic processes. We show how GQA may be used to study linear regression and probabilistic programming.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.02284v3</guid>
      <category>cs.LO</category>
      <category>math.CT</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dario Stein, Fabio Zanasi, Robin Piedeleu, Richard Samuelson</dc:creator>
    </item>
    <item>
      <title>Quotients of M-convex sets and M-convex functions</title>
      <link>https://arxiv.org/abs/2403.07751</link>
      <description>arXiv:2403.07751v2 Announce Type: replace-cross 
Abstract: We unify the study of quotients of matroids, polymatroids, valuated matroids and strong maps of submodular functions in the framework of Murota's discrete convex analysis. As a main result, we compile a list of ten equivalent characterizations of quotients for M-convex sets, generalizing existing formulations for (poly)matroids and submodular functions. We also initiate the study of quotients of M-convex functions, constructing a hierarchy of four separate characterizations. Our investigations yield new insights into the fundamental operation of induction, as well as the structure of linking sets and linking functions, which are generalizations of linking systems and bimatroids.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.07751v2</guid>
      <category>math.CO</category>
      <category>math.AG</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Marie-Charlotte Brandenburg, Georg Loho, Ben Smith</dc:creator>
    </item>
    <item>
      <title>Safe Sequences via Dominators in DAGs for Path-Covering Problems</title>
      <link>https://arxiv.org/abs/2411.03871</link>
      <description>arXiv:2411.03871v3 Announce Type: replace-cross 
Abstract: A path-covering problem on a directed acyclic graph (DAG) requires finding a set of source-to-sink paths that cover all the nodes, all the arcs, or subsets thereof, and additionally they are optimal with respect to some function. In this paper we study safe sequences of nodes or arcs, namely sequences that appear in some path of every path cover of a DAG.
  We show that safe sequences admit a simple characterization via cutnodes. Moreover, we establish a connection between maximal safe sequences and leaf-to-root paths in the source- and sink-dominator trees of the DAG, which may be of independent interest in the extensive literature on dominators. With dominator trees, safe sequences admit an O(n)-size representation and a linear-time output-sensitive enumeration algorithm running in time O(m + o), where n and m are the number of nodes and arcs, respectively, and o is the total length of the maximal safe sequences.
  We then apply maximal safe sequences to simplify Integer Linear Programs (ILPs) for two path-covering problems, LeastSquares and MinPathError, which are at the core of RNA transcript assembly problems from bioinformatics. On various datasets, maximal safe sequences can be computed in under 0.1 seconds per graph, on average, and ILP solvers whose search space is reduced in this manner exhibit significant speed-ups. For example on graphs with a large width, average speed-ups are in the range 50-250x for MinPathError and in the range 80-350x for LeastSquares. Optimizing ILPs using safe sequences can thus become a fast building block of practical RNA transcript assembly tools, and more generally, of path-covering problems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.03871v3</guid>
      <category>cs.DS</category>
      <category>math.OC</category>
      <category>q-bio.GN</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Francisco Sena, Romeo Rizzi, Alexandru I. Tomescu</dc:creator>
    </item>
    <item>
      <title>Direct comparison of stochastic driven nonlinear dynamical systems for combinatorial optimization</title>
      <link>https://arxiv.org/abs/2503.15427</link>
      <description>arXiv:2503.15427v3 Announce Type: replace-cross 
Abstract: Combinatorial optimization problems are ubiquitous in industrial applications. However, finding optimal or close-to-optimal solutions can often be extremely hard. Because some of these problems can be mapped to the ground-state search of the Ising model, tremendous effort has been devoted to developing solvers for Ising-type problems over the past decades. Recent advances in controlling and manipulating both quantum and classical systems have enabled novel computing paradigms such as quantum simulators and coherent Ising machines to tackle hard optimization problems. Here, we examine and benchmark several physics-inspired optimization algorithms, including coherent Ising machines, gain-dissipative algorithms, simulated bifurcation machines, and Hopfield neural networks, which we collectively refer to as stochastic-driven nonlinear dynamical systems. Most importantly, we benchmark these algorithms against random Ising problems with planted solutions and compare them to simulated annealing as a baseline leveraging the same software stack for all solvers. We further study how different numerical integration techniques and graph connectivity affect performance. This work provides an overview of a diverse set of new optimization paradigms.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.15427v3</guid>
      <category>quant-ph</category>
      <category>cond-mat.dis-nn</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1103/9vbb-h73q</arxiv:DOI>
      <arxiv:journal_reference>Phys. Rev. E 112, 035301 (2025)</arxiv:journal_reference>
      <dc:creator>Junpeng Hou, Amin Barzegar, Helmut G. Katzgraber</dc:creator>
    </item>
    <item>
      <title>Representation and Stability Analysis of 1D PDEs with Periodic Boundary Conditions</title>
      <link>https://arxiv.org/abs/2503.22896</link>
      <description>arXiv:2503.22896v5 Announce Type: replace-cross 
Abstract: PDEs with periodic boundary conditions are frequently used to model processes in large spatial environments, assuming solutions to extend periodically beyond some bounded interval. However, solutions to these PDEs often do not converge to a unique equilibrium, but instead converge to non-stationary trajectories existing in the nullspace of the spatial differential operator (e.g. $\frac{\partial^2}{\partial x^2}$). To analyse this convergence behaviour, in this paper, it is shown how such trajectories can be modeled for a broad class of linear, 2nd order, 1D PDEs with periodic as well as more general boundary conditions, using the Partial Integral Equation (PIE) representation. In particular, it is first shown how any PDE state satisfying these boundary conditions can be uniquely expressed in terms of two components, existing in the image and the nullspace of the differential operator $\frac{\partial^2}{\partial x^2}$, respectively. An equivalent representation of linear PDEs is then derived as a PIE, explicitly defining the dynamics of both state components. Finally, a notion of exponential stability is defined that requires only one of the state components to converge to zero, and it is shown how this stability notion can be tested by solving a linear operator inequality. The proposed methodology is applied to examples of heat and wave equations, demonstrating that exponential stability can be verified with tight bounds on the rate of decay.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.22896v5</guid>
      <category>math.AP</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Declan Jagt, Sergei Chernyshenko, Matthew Peet</dc:creator>
    </item>
    <item>
      <title>Update-Aware Robust Optimal Model Predictive Control for Nonlinear Systems</title>
      <link>https://arxiv.org/abs/2506.01729</link>
      <description>arXiv:2506.01729v2 Announce Type: replace-cross 
Abstract: Robust optimal or min-max model predictive control (MPC) approaches aim to guarantee constraint satisfaction over a known, bounded uncertainty set while minimizing a worst-case performance bound. Traditionally, these methods compute a trajectory that meets the desired properties over a fixed prediction horizon, apply a portion of the resulting input, and then re-solve the MPC problem using newly obtained measurements at the next time step. However, this approach fails to account for the fact that the control trajectory will be updated in the future, potentially leading to conservative designs. In this paper, we present a novel update-aware robust optimal MPC algorithm for decreasing horizon problems on nonlinear systems that explicitly accounts for future control trajectory updates. This additional insight allows our method to provably expand the feasible solution set and guarantee improved worst-case performance bounds compared to existing techniques. Our approach formulates the trajectory generation problem as a sequence of nested existence-constrained semi-infinite programs (SIPs), which can be efficiently solved using local reduction techniques. To demonstrate its effectiveness, we evaluate our approach on a planar quadrotor problem, where it clearly outperforms an equivalent method that does not account for future updates at the cost of increased computation time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.01729v2</guid>
      <category>eess.SY</category>
      <category>cs.SY</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1109/LCSYS.2025.3576534</arxiv:DOI>
      <dc:creator>J. Wehbeh, E. C. Kerrigan</dc:creator>
    </item>
    <item>
      <title>An Effective Two-Phase Genetic Algorithm for Solving the Resource Constrained Project Scheduling Problem (RCPSP)</title>
      <link>https://arxiv.org/abs/2506.21915</link>
      <description>arXiv:2506.21915v2 Announce Type: replace-cross 
Abstract: This note presents a simple and effective variation of genetic algorithm (GA) for solving RCPSP, denoted as 2-Phase Genetic Algorithm (2PGA). The 2PGA implements GA parent selection in two phases: Phase-1 includes the best current solutions in the parent pool, and Phase-2 excludes the best current solutions from the parent pool. The 2PGA carries out the GA evolution by alternating the two phases iteratively. In exploring a solution space, the Phase-1 emphasizes intensification in current neighborhood, while the Phase-2 emphasizes diversification to escape local traps. The 2PGA was tested on the standard benchmark problems in PSPLIB, the results have shown that the algorithm is effective and has improved some of the best heuristic solutions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.21915v2</guid>
      <category>cs.NE</category>
      <category>math.OC</category>
      <pubDate>Thu, 04 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>D. Sun, S. Zhou</dc:creator>
    </item>
  </channel>
</rss>
