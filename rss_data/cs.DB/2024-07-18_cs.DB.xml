<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.DB updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.DB</link>
    <description>cs.DB updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.DB" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 19 Jul 2024 04:00:19 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 19 Jul 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Data Collection and Labeling Techniques for Machine Learning</title>
      <link>https://arxiv.org/abs/2407.12793</link>
      <description>arXiv:2407.12793v1 Announce Type: new 
Abstract: Data collection and labeling are critical bottlenecks in the deployment of machine learning applications. With the increasing complexity and diversity of applications, the need for efficient and scalable data collection and labeling techniques has become paramount. This paper provides a review of the state-of-the-art methods in data collection, data labeling, and the improvement of existing data and models. By integrating perspectives from both the machine learning and data management communities, we aim to provide a holistic view of the current landscape and identify future research directions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12793v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianyu Huang, Tongfang Zhao</dc:creator>
    </item>
    <item>
      <title>Learned Graph Rewriting with Equality Saturation: A New Paradigm in Relational Query Rewrite and Beyond</title>
      <link>https://arxiv.org/abs/2407.12794</link>
      <description>arXiv:2407.12794v1 Announce Type: new 
Abstract: Query rewrite systems perform graph substitutions using rewrite rules to generate optimal SQL query plans. Rewriting logical and physical relational query plans is proven to be an NP-hard sequential decision-making problem with a search space exponential in the number of rewrite rules. In this paper, we address the query rewrite problem by interleaving Equality Saturation and Graph Reinforcement Learning (RL). The proposed system, Aurora, rewrites relational queries by guiding Equality Saturation, a method from compiler literature to perform non-destructive graph rewriting, with a novel RL agent that embeds both the spatial structure of the query graph as well as the temporal dimension associated with the sequential construction of query plans. Our results show Graph Reinforcement Learning for non-destructive graph rewriting yields SQL plans orders of magnitude faster than existing equality saturation solvers, while also achieving competitive results against mainstream query optimisers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12794v1</guid>
      <category>cs.DB</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>George-Octavian B\u{a}rbulescu, Taiyi Wang, Zak Singh, Eiko Yoneki</dc:creator>
    </item>
    <item>
      <title>SimClone: Detecting Tabular Data Clones using Value Similarity</title>
      <link>https://arxiv.org/abs/2407.12802</link>
      <description>arXiv:2407.12802v1 Announce Type: new 
Abstract: Data clones are defined as multiple copies of the same data among datasets. Presence of data clones between datasets can cause issues such as difficulties in managing data assets and data license violations when using datasets with clones to build AI software. However, detecting data clones is not trivial. Majority of the prior studies in this area rely on structural information to detect data clones (e.g., font size, column header). However, tabular datasets used to build AI software are typically stored without any structural information. In this paper, we propose a novel method called SimClone for data clone detection in tabular datasets without relying on structural information. SimClone method utilizes value similarities for data clone detection. We also propose a visualization approach as a part of our SimClone method to help locate the exact position of the cloned data between a dataset pair. Our results show that our SimClone outperforms the current state-of-the-art method by at least 20\% in terms of both F1-score and AUC. In addition, SimClone's visualization component helps identify the exact location of the data clone in a dataset with a Precision@10 value of 0.80 in the top 20 true positive predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.12802v1</guid>
      <category>cs.DB</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xu Yang (Jack), Gopi Krishnan Rajbahadur (Jack), Dayi Lin (Jack), Shaowei Wang (Jack), Zhen Ming (Jack),  Jiang</dc:creator>
    </item>
    <item>
      <title>Griffin: Fast Transactional Database Index with Hash and B+-Tree</title>
      <link>https://arxiv.org/abs/2407.13294</link>
      <description>arXiv:2407.13294v1 Announce Type: new 
Abstract: Index access is one of the dominant performance factors in transactional database systems. Many systems use a B+-tree or one of its variants to handle point and range operations. This access pattern has room for performance improvement. Firstly, point operations can potentially be processed in $O(1)$ with a hash table. Secondly, to ensure serializability of transactions, range operations incur overhead from phantom avoidance techniques that involve additional processing or synchronization, such as an extra traversal of the B+-tree. To address these issues, we propose a hybrid index architecture, Griffin. For point operations, Griffin has a hash table that provides access paths in $O(1)$ time, along with a B+-tree. For phantom avoidance, Griffin employs a precision locking method, which does not involve additional traversal of the B+-tree. Despite its hybrid architecture, Griffin transparently provides linearizable operations and an interface of a single database index. We built a Griffin index combining a hash table and BwTree. Compared to a baseline index that is composed of a BwTree only, it achieves up to 3.1x higher throughput in a point operation dominant workload, and up to 5.4x higher throughput in a range operation dominant workload.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13294v1</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sho Nakazono, Yutaro Bessho, Hideyuki Kawashima, Tatsuhiro Nakamori</dc:creator>
    </item>
    <item>
      <title>HHGT: Hierarchical Heterogeneous Graph Transformer for Heterogeneous Graph Representation Learning</title>
      <link>https://arxiv.org/abs/2407.13158</link>
      <description>arXiv:2407.13158v1 Announce Type: cross 
Abstract: Despite the success of Heterogeneous Graph Neural Networks (HGNNs) in modeling real-world Heterogeneous Information Networks (HINs), challenges such as expressiveness limitations and over-smoothing have prompted researchers to explore Graph Transformers (GTs) for enhanced HIN representation learning. However, research on GT in HINs remains limited, with two key shortcomings in existing work: (1) A node's neighbors at different distances in HINs convey diverse semantics. Unfortunately, existing methods ignore such differences and uniformly treat neighbors within a given distance in a coarse manner, which results in semantic confusion. (2) Nodes in HINs have various types, each with unique semantics. Nevertheless, existing methods mix nodes of different types during neighbor aggregation, hindering the capture of proper correlations between nodes of diverse types. To bridge these gaps, we design an innovative structure named (k,t)-ring neighborhood, where nodes are initially organized by their distance, forming different non-overlapping k-ring neighborhoods for each distance. Within each k-ring structure, nodes are further categorized into different groups according to their types, thus emphasizing the heterogeneity of both distances and types in HINs naturally. Based on this structure, we propose a novel Hierarchical Heterogeneous Graph Transformer (HHGT) model, which seamlessly integrates a Type-level Transformer for aggregating nodes of different types within each k-ring neighborhood, followed by a Ring-level Transformer for aggregating different k-ring neighborhoods in a hierarchical manner. Extensive experiments are conducted on downstream tasks to verify HHGT's superiority over 14 baselines, with a notable improvement of up to 24.75% in NMI and 29.25% in ARI for node clustering task on the ACM dataset compared to the best baseline.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13158v1</guid>
      <category>cs.LG</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qiuyu Zhu, Liang Zhang, Qianxiong Xu, Kaijun Liu, Cheng Long, Xiaoyang Wang</dc:creator>
    </item>
    <item>
      <title>PM-LLM-Benchmark: Evaluating Large Language Models on Process Mining Tasks</title>
      <link>https://arxiv.org/abs/2407.13244</link>
      <description>arXiv:2407.13244v1 Announce Type: cross 
Abstract: Large Language Models (LLMs) have the potential to semi-automate some process mining (PM) analyses. While commercial models are already adequate for many analytics tasks, the competitive level of open-source LLMs in PM tasks is unknown. In this paper, we propose PM-LLM-Benchmark, the first comprehensive benchmark for PM focusing on domain knowledge (process-mining-specific and process-specific) and on different implementation strategies. We focus also on the challenges in creating such a benchmark, related to the public availability of the data and on evaluation biases by the LLMs. Overall, we observe that most of the considered LLMs can perform some process mining tasks at a satisfactory level, but tiny models that would run on edge devices are still inadequate. We also conclude that while the proposed benchmark is useful for identifying LLMs that are adequate for process mining tasks, further research is needed to overcome the evaluation biases and perform a more thorough ranking of the competitive LLMs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13244v1</guid>
      <category>cs.CL</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Berti, Humam Kourani, Wil M. P. van der Aalst</dc:creator>
    </item>
    <item>
      <title>AI-Assisted SQL Authoring at Industry Scale</title>
      <link>https://arxiv.org/abs/2407.13280</link>
      <description>arXiv:2407.13280v1 Announce Type: cross 
Abstract: SqlCompose is a tool that uses generative AI to assist with data analytics tasks, specifically SQL queries. It addresses the challenges of SQL being declarative, having formal table schemas, and often being written in a non-linear manner. The authors develop an internal SQL benchmark to test the performance of the Public Llama model and find that it performs well, with a BLEU score of 53% for single-line predictions and 24% for multi-line predictions. They then fine-tune the Llama model on their internal data and database schemas, resulting in a substantial improvement in performance. They also develop a fill-in-the-middle model, SqlComposeFIM, which is aware of the context before and after the line(s) that need to be completed, and this model outperforms the other two models by 35 percentage points. Additionally, they measure how often the models get the correct table names and find that SqlComposeFIM is able to do this 75% of the time, a major improvement over the other two models. The authors also roll out SqlComposeFIM at Meta and receive positive feedback from users, including completing tedious or repetitive SQL clauses, suggesting boilerplate coding, and help in eliminating the need to remember difficult SQL syntax. However, some users report table and column name hallucinations, which has been reduced with the release of SqlComposeFIM. Overall, the SqlCompose models consistently outperform public and internal LLMs despite their smaller size, providing early indications that smaller specialist models can outperform larger general purpose models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13280v1</guid>
      <category>cs.SE</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chandra Maddila, Negar Ghorbani, Kosay Jabre, Vijayaraghavan Murali, Edwin Kim, Parth Thakkar, Nikolay Pavlovich Laptev, Olivia Harman, Diana Hsu, Rui Abreu, Peter C. Rigby</dc:creator>
    </item>
    <item>
      <title>PriPL-Tree: Accurate Range Query for Arbitrary Distribution under Local Differential Privacy</title>
      <link>https://arxiv.org/abs/2407.13532</link>
      <description>arXiv:2407.13532v1 Announce Type: cross 
Abstract: Answering range queries in the context of Local Differential Privacy (LDP) is a widely studied problem in Online Analytical Processing (OLAP). Existing LDP solutions all assume a uniform data distribution within each domain partition, which may not align with real-world scenarios where data distribution is varied, resulting in inaccurate estimates. To address this problem, we introduce PriPL-Tree, a novel data structure that combines hierarchical tree structures with piecewise linear (PL) functions to answer range queries for arbitrary distributions. PriPL-Tree precisely models the underlying data distribution with a few line segments, leading to more accurate results for range queries. Furthermore, we extend it to multi-dimensional cases with novel data-aware adaptive grids. These grids leverage the insights from marginal distributions obtained through PriPL-Trees to partition the grids adaptively, adapting the density of underlying distributions. Our extensive experiments on both real and synthetic datasets demonstrate the effectiveness and superiority of PriPL-Tree over state-of-the-art solutions in answering range queries across arbitrary data distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.13532v1</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leixia Wang, Qingqing Ye, Haibo Hu, Xiaofeng Meng</dc:creator>
    </item>
    <item>
      <title>GastCoCo: Graph Storage and Coroutine-Based Prefetch Co-Design for Dynamic Graph Processing</title>
      <link>https://arxiv.org/abs/2312.14396</link>
      <description>arXiv:2312.14396v3 Announce Type: replace 
Abstract: An efficient data structure is fundamental to meeting the growing demands in dynamic graph processing. However, the dual requirements for graph computation efficiency (with contiguous structures) and graph update efficiency (with linked list-like structures) present a conflict in the design principles of graph structures. After experimental studies of existing state-of-the-art dynamic graph structures, we observe that the overhead of cache misses accounts for a major portion of the graph computation time. This paper presents GastCoCo, a system with graph storage and coroutine-based prefetch co-design. By employing software prefetching via stackless coroutines and introducing a prefetch-friendly data structure CBList, GastCoCo significantly alleviates the performance degradation caused by cache misses. Our results show that GastCoCo outperforms state-of-the-art graph storage systems by 1.3x - 180x in graph updates and 1.4x - 41.1x in graph computation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.14396v3</guid>
      <category>cs.DB</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hongfu Li</dc:creator>
    </item>
    <item>
      <title>Resilient Consensus Sustained Collaboratively</title>
      <link>https://arxiv.org/abs/2302.02325</link>
      <description>arXiv:2302.02325v4 Announce Type: replace-cross 
Abstract: The recent growth of blockchain technology has accelerated research on decentralized platforms. Initial blockchain platforms decide on what should be added to the ledger based on Proof-of-Work (PoW) consensus protocol. PoW requires its participants to perform large computations and leads to massive energy wastage. Recent blockchains aim to replace PoW through Proof-of-Stake (PoS) and Malicious Fault-Tolerant (MFT) consensus protocols. However, the safety of the ledger created by these protocols is at the mercy of the long-term safe-keeping of the private keys of participants. As a result, these blockchains face long-range attacks. To ameliorate this situation, we present the design of our novel Power-of-Collaboration (PoC) protocol, which guards existing PoS and MFT blockchains against long-range attacks. We show that PoC can be easily appended to existing blockchains and only marginally degrades their throughputs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.02325v4</guid>
      <category>cs.CR</category>
      <category>cs.DB</category>
      <category>cs.DC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Junchao Chen, Suyash Gupta, Alberto Sonnino, Lefteris Kokoris-Kogias, Mohammad Sadoghi</dc:creator>
    </item>
  </channel>
</rss>
