<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.CR updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.CR</link>
    <description>cs.CR updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.CR" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Apr 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 18 Apr 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Phishing Website Detection Using a Combined Model of ANN and LSTM</title>
      <link>https://arxiv.org/abs/2404.10780</link>
      <description>arXiv:2404.10780v1 Announce Type: new 
Abstract: In this digital era, our lives highly depend on the internet and worldwide technology. Wide usage of technology and platforms of communication makes our lives better and easier. But on the other side it carries out some security issues and cruel activities, phishing is one activity of these cruel activities. It is a type of cybercrime, which has the purpose of stealing the personal information of the computer user, and enterprises, which carry out fake websites that are the copy of the original websites. The attackers used personal information like account IDs, passwords, and usernames for the purpose of some fraudulent activities against the user of the computer. To overcome this problem researchers focused on the machine learning and deep learning approaches. In our study, we are going to use machine learning and deep learning models to identify the fake web pages on the secondary dataset.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10780v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Muhammad Shoaib Farooq, Hina jabbar</dc:creator>
    </item>
    <item>
      <title>Authenticity in Authorship: The Writer's Integrity Framework for Verifying Human-Generated Text</title>
      <link>https://arxiv.org/abs/2404.10781</link>
      <description>arXiv:2404.10781v1 Announce Type: new 
Abstract: The "Writer's Integrity" framework introduces a paradigm shift in maintaining the sanctity of human-generated text in the realms of academia, research, and publishing. This innovative system circumvents the shortcomings of current AI detection tools by monitoring the writing process, rather than the product, capturing the distinct behavioral footprint of human authorship. Here, we offer a comprehensive examination of the framework, its development, and empirical results. We highlight its potential in revolutionizing the validation of human intellectual work, emphasizing its role in upholding academic integrity and intellectual property rights in the face of sophisticated AI models capable of emulating human-like text. This paper also discusses the implementation considerations, addressing potential user concerns regarding ease of use and privacy, and outlines a business model for tech companies to monetize the framework effectively. Through licensing, partnerships, and subscriptions, companies can cater to universities, publishers, and independent writers, ensuring the preservation of original thought and effort in written content. This framework is open source and available here, https://github.com/sanadv/Integrity.github.io</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10781v1</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sanad Aburass, Maha Abu Rumman</dc:creator>
    </item>
    <item>
      <title>Quantifying AI Vulnerabilities: A Synthesis of Complexity, Dynamical Systems, and Game Theory</title>
      <link>https://arxiv.org/abs/2404.10782</link>
      <description>arXiv:2404.10782v1 Announce Type: new 
Abstract: The rapid integration of Artificial Intelligence (AI) systems across critical domains necessitates robust security evaluation frameworks. We propose a novel approach that introduces three metrics: System Complexity Index (SCI), Lyapunov Exponent for AI Stability (LEAIS), and Nash Equilibrium Robustness (NER). SCI quantifies the inherent complexity of an AI system, LEAIS captures its stability and sensitivity to perturbations, and NER evaluates its strategic robustness against adversarial manipulation. Through comparative analysis, we demonstrate the advantages of our framework over existing techniques. We discuss the theoretical and practical implications, potential applications, limitations, and future research directions. Our work contributes to the development of secure and trustworthy AI technologies by providing a holistic, theoretically grounded approach to AI security evaluation. As AI continues to advance, prioritising and advancing AI security through interdisciplinary collaboration is crucial to ensure its responsible deployment for the benefit of society.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10782v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B Kereopa-Yorke</dc:creator>
    </item>
    <item>
      <title>The Path To Autonomous Cyber Defense</title>
      <link>https://arxiv.org/abs/2404.10788</link>
      <description>arXiv:2404.10788v1 Announce Type: new 
Abstract: Defenders are overwhelmed by the number and scale of attacks against their networks.This problem will only be exacerbated as attackers leverage artificial intelligence to automate their workflows. We propose a path to autonomous cyber agents able to augment defenders by automating critical steps in the cyber defense life cycle.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10788v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Sean Oesch, Phillipe Austria, Amul Chaulagain, Brian Weber, Cory Watson, Matthew Dixson, Amir Sadovnik</dc:creator>
    </item>
    <item>
      <title>PASA: Attack Agnostic Unsupervised Adversarial Detection using Prediction &amp; Attribution Sensitivity Analysis</title>
      <link>https://arxiv.org/abs/2404.10789</link>
      <description>arXiv:2404.10789v1 Announce Type: new 
Abstract: Deep neural networks for classification are vulnerable to adversarial attacks, where small perturbations to input samples lead to incorrect predictions. This susceptibility, combined with the black-box nature of such networks, limits their adoption in critical applications like autonomous driving. Feature-attribution-based explanation methods provide relevance of input features for model predictions on input samples, thus explaining model decisions. However, we observe that both model predictions and feature attributions for input samples are sensitive to noise. We develop a practical method for this characteristic of model prediction and feature attribution to detect adversarial samples. Our method, PASA, requires the computation of two test statistics using model prediction and feature attribution and can reliably detect adversarial samples using thresholds learned from benign samples. We validate our lightweight approach by evaluating the performance of PASA on varying strengths of FGSM, PGD, BIM, and CW attacks on multiple image and non-image datasets. On average, we outperform state-of-the-art statistical unsupervised adversarial detectors on CIFAR-10 and ImageNet by 14\% and 35\% ROC-AUC scores, respectively. Moreover, our approach demonstrates competitive performance even when an adversary is aware of the defense mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10789v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dipkamal Bhusal, Md Tanvirul Alam, Monish K. Veerabhadran, Michael Clifford, Sara Rampazzi, Nidhi Rastogi</dc:creator>
    </item>
    <item>
      <title>Multimodal Attack Detection for Action Recognition Models</title>
      <link>https://arxiv.org/abs/2404.10790</link>
      <description>arXiv:2404.10790v1 Announce Type: new 
Abstract: Adversarial machine learning attacks on video action recognition models is a growing research area and many effective attacks were introduced in recent years. These attacks show that action recognition models can be breached in many ways. Hence using these models in practice raises significant security concerns. However, there are very few works which focus on defending against or detecting attacks. In this work, we propose a novel universal detection method which is compatible with any action recognition model. In our extensive experiments, we show that our method consistently detects various attacks against different target models with high true positive rates while satisfying very low false positive rates. Tested against four state-of-the-art attacks targeting four action recognition models, the proposed detector achieves an average AUC of 0.911 over 16 test cases while the best performance achieved by the existing detectors is 0.645 average AUC. This 41.2% improvement is enabled by the robustness of the proposed detector to varying attack methods and target models. The lowest AUC achieved by our detector across the 16 test cases is 0.837 while the competing detector's performance drops as low as 0.211. We also show that the proposed detector is robust to varying attack strengths. In addition, we analyze our method's real-time performance with different hardware setups to demonstrate its potential as a practical defense mechanism.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10790v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Furkan Mumcu, Yasin Yilmaz</dc:creator>
    </item>
    <item>
      <title>Reconfigurable Edge Hardware for Intelligent IDS: Systematic Approach</title>
      <link>https://arxiv.org/abs/2404.10792</link>
      <description>arXiv:2404.10792v1 Announce Type: new 
Abstract: Intrusion detection systems (IDS) are crucial security measures nowadays to enforce network security. Their task is to detect anomalies in network communication and identify, if not thwart, possibly malicious behavior. Recently, machine learning has been deployed to construct intelligent IDS. This approach, however, is quite challenging particularly in distributed, highly dynamic, yet resource-constrained systems like Edge setups. In this paper, we tackle this issue from multiple angles by analyzing the concept of intelligent IDS (I-IDS) while addressing the specific requirements of Edge devices with a special focus on reconfigurability. Then, we introduce a systematic approach to constructing the I-IDS on reconfigurable Edge hardware. For this, we implemented our proposed IDS on state-of-the-art Field Programmable Gate Arrays (FPGAs) technology as (1) a purely FPGA-based dataflow processor (DFP) and (2) a co-designed approach featuring RISC-V soft-core as FPGA-based soft-core processor (SCP). We complete our paper with a comparison of the state of the art (SoA) in this domain. The results show that DFP and SCP are both suitable for Edge applications from hardware resource and energy efficiency perspectives. Our proposed DFP solution clearly outperforms the SoA and demonstrates that required high performance can be achieved without prohibitively high hardware costs. This makes our proposed DFP suitable for Edge-based high-speed applications like modern communication technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10792v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.LG</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-55673-9_4</arxiv:DOI>
      <arxiv:journal_reference>Applied Reconfigurable Computing. Architectures, Tools, and Applications. ARC 2024. Lecture Notes in Computer Science, vol 14553. Springer, Cham</arxiv:journal_reference>
      <dc:creator>Wadid Foudhaili, Anouar Nechi, Celine Thermann, Mohammad Al Johmani, Rainer Buchty, Mladen Berekovic, Saleh Mulhem</dc:creator>
    </item>
    <item>
      <title>Black-box Adversarial Transferability: An Empirical Study in Cybersecurity Perspective</title>
      <link>https://arxiv.org/abs/2404.10796</link>
      <description>arXiv:2404.10796v1 Announce Type: new 
Abstract: The rapid advancement of artificial intelligence within the realm of cybersecurity raises significant security concerns. The vulnerability of deep learning models in adversarial attacks is one of the major issues. In adversarial machine learning, malicious users try to fool the deep learning model by inserting adversarial perturbation inputs into the model during its training or testing phase. Subsequently, it reduces the model confidence score and results in incorrect classifications. The novel key contribution of the research is to empirically test the black-box adversarial transferability phenomena in cyber attack detection systems. It indicates that the adversarial perturbation input generated through the surrogate model has a similar impact on the target model in producing the incorrect classification. To empirically validate this phenomenon, surrogate and target models are used. The adversarial perturbation inputs are generated based on the surrogate-model for which the hacker has complete information. Based on these adversarial perturbation inputs, both surrogate and target models are evaluated during the inference phase. We have done extensive experimentation over the CICDDoS-2019 dataset, and the results are classified in terms of various performance metrics like accuracy, precision, recall, and f1-score. The findings indicate that any deep learning model is highly susceptible to adversarial attacks, even if the attacker does not have access to the internal details of the target model. The results also indicate that white-box adversarial attacks have a severe impact compared to black-box adversarial attacks. There is a need to investigate and explore adversarial defence techniques to increase the robustness of the deep learning models against adversarial attacks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10796v1</guid>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cose.2024.103853</arxiv:DOI>
      <dc:creator>Khushnaseeb Roshan, Aasim Zafar</dc:creator>
    </item>
    <item>
      <title>Advancing Network Intrusion Detection: Integrating Graph Neural Networks with Scattering Transform and Node2Vec for Enhanced Anomaly Detection</title>
      <link>https://arxiv.org/abs/2404.10800</link>
      <description>arXiv:2404.10800v1 Announce Type: new 
Abstract: In this paper, we present two novel methods in Network Intrusion Detection Systems (NIDS) using Graph Neural Networks (GNNs). The first approach, Scattering Transform with E-GraphSAGE (STEG), utilizes the scattering transform to conduct multi-resolution analysis of edge feature vectors. This provides a detailed representation that is essential for identifying subtle anomalies in network traffic. The second approach improves node representation by initiating with Node2Vec, diverging from standard methods of using uniform values, thereby capturing a more accurate and holistic network picture. Our methods have shown significant improvements in performance compared to existing state-of-the-art methods in benchmark NIDS datasets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10800v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdeljalil Zoubir, Badr Missaoui</dc:creator>
    </item>
    <item>
      <title>KernJC: Automated Vulnerable Environment Generation for Linux Kernel Vulnerabilities</title>
      <link>https://arxiv.org/abs/2404.11107</link>
      <description>arXiv:2404.11107v1 Announce Type: new 
Abstract: Linux kernel vulnerability reproduction is a critical task in system security. To reproduce a kernel vulnerability, the vulnerable environment and the Proof of Concept (PoC) program are needed. Most existing research focuses on the generation of PoC, while the construction of environment is overlooked. However, establishing an effective vulnerable environment to trigger a vulnerability is challenging. Firstly, it is hard to guarantee that the selected kernel version for reproduction is vulnerable, as the vulnerability version claims in online databases can occasionally be spurious. Secondly, many vulnerabilities can not be reproduced in kernels built with default configurations. Intricate non-default kernel configurations must be set to include and trigger a kernel vulnerability, but less information is available on how to recognize these configurations.
  To solve these challenges, we propose a patch-based approach to identify real vulnerable kernel versions and a graph-based approach to identify necessary configs for activating a specific vulnerability. We implement these approaches in a tool, KernJC, automating the generation of vulnerable environments for kernel vulnerabilities. To evaluate the efficacy of KernJC, we build a dataset containing 66 representative real-world vulnerabilities with PoCs from kernel vulnerability research in the past five years. The evaluation shows that KernJC builds vulnerable environments for all these vulnerabilities, 48.5% of which require non-default configs, and 4 have incorrect version claims in the National Vulnerability Database (NVD). Furthermore, we conduct large-scale spurious version detection on kernel vulnerabilities and identify 128 vulnerabilities which have spurious version claims in NVD. To foster future research, we release KernJC with the dataset in the community.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11107v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Bonan Ruan, Jiahao Liu, Chuqi Zhang, Zhenkai Liang</dc:creator>
    </item>
    <item>
      <title>TransLinkGuard: Safeguarding Transformer Models Against Model Stealing in Edge Deployment</title>
      <link>https://arxiv.org/abs/2404.11121</link>
      <description>arXiv:2404.11121v1 Announce Type: new 
Abstract: Proprietary large language models (LLMs) have been widely applied in various scenarios. Additionally, deploying LLMs on edge devices is trending for efficiency and privacy reasons. However, edge deployment of proprietary LLMs introduces new security challenges: edge-deployed models are exposed as white-box accessible to users, enabling adversaries to conduct effective model stealing (MS) attacks. Unfortunately, existing defense mechanisms fail to provide effective protection. Specifically, we identify four critical protection properties that existing methods fail to simultaneously satisfy: (1) maintaining protection after a model is physically copied; (2) authorizing model access at request level; (3) safeguarding runtime reverse engineering; (4) achieving high security with negligible runtime overhead. To address the above issues, we propose TransLinkGuard, a plug-and-play model protection approach against model stealing on edge devices. The core part of TransLinkGuard is a lightweight authorization module residing in a secure environment, e.g., TEE. The authorization module can freshly authorize each request based on its input. Extensive experiments show that TransLinkGuard achieves the same security protection as the black-box security guarantees with negligible overhead.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11121v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qinfeng Li, Zhiqiang Shen, Zhenghan Qin, Yangfan Xie, Xuhong Zhang, Tianyu Du, Jianwei Yin</dc:creator>
    </item>
    <item>
      <title>The Writing is on the Wall: Analyzing the Boom of Inscriptions and its Impact on Rollup Performance and Cost Efficiency</title>
      <link>https://arxiv.org/abs/2404.11189</link>
      <description>arXiv:2404.11189v1 Announce Type: new 
Abstract: Late 2023 witnessed significant user activity on EVM chains, resulting in a surge in transaction activity and putting many rollups into the first live test. While some rollups performed well, some others experienced downtime during this period, affecting transaction finality time and gas fees. To address the lack of empirical research on rollups, we perform the first study during a heightened activity during the late 2023 transaction boom, as attributed to inscriptions - a novel technique that enables NFT and ERC-20 token creation on Bitcoin and other blockchains. We observe that minting inscription-based meme tokens on zkSync Era allows for trading at a fraction of the costs, compared to the Bitcoin or Ethereum networks. We also found that the increased transaction activity, over 99% attributed to the minting of new inscription tokens, positively affected other users of zkSync Era, resulting in lowered gas fees. Unlike L1 blockchains, ZK rollups may experience lower gas fees with increased transaction volume. Lastly, the introduction of blobs - a form of temporary data storage - decreased the gas costs of Ethereum rollups, but also raised a number of questions about the security of inscription-based tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11189v1</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Gogol, Johnnatan Messias, Maria Ines Silva, Benjamin Livshits</dc:creator>
    </item>
    <item>
      <title>SoK: Decentralized Finance (DeFi) -- Fundamentals, Taxonomy and Risks</title>
      <link>https://arxiv.org/abs/2404.11281</link>
      <description>arXiv:2404.11281v1 Announce Type: new 
Abstract: Decentralized Finance (DeFi) refers to financial services that are not necessarily related to crypto-currencies. By employing blockchain for security and integrity, DeFi creates new possibilities that attract retail and institution users, including central banks. Given its novel applications and sophisticated designs, the distinction between DeFi services and understanding the risk involved is often complex. This work systematically presents the major categories of DeFi protocols that cover over 90\% of total value locked (TVL) in DeFi. It establishes a structured methodology to differentiate between DeFi protocols based on their design and architecture. Every DeFi protocol is classified into one of three groups: liquidity pools, pegged and synthetic tokens, and aggregator protocols, followed by risk analysis. In particular, we classify stablecoins, liquid staking tokens, and bridged (wrapped) assets as pegged tokens resembling similar risks. The full risk exposure of DeFi users is derived not only from the DeFi protocol design but also from how it is used and with which tokens.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11281v1</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Krzysztof Gogol, Christian Killer, Malte Schlosser, Thomas Bocek, Burkhard Stiller, Claudio Tessone</dc:creator>
    </item>
    <item>
      <title>Amplifying Main Memory-Based Timing Covert and Side Channels using Processing-in-Memory Operations</title>
      <link>https://arxiv.org/abs/2404.11284</link>
      <description>arXiv:2404.11284v1 Announce Type: new 
Abstract: The adoption of processing-in-memory (PiM) architectures has been gaining momentum because they provide high performance and low energy consumption by alleviating the data movement bottleneck. Yet, the security of such architectures has not been thoroughly explored. The adoption of PiM solutions provides a new way to directly access main memory, which can be potentially exploited by malicious user applications. We show that this new way to access main memory opens opportunities for high-throughput timing attack vectors that are hard-to-mitigate without significant performance overhead.
  We introduce IMPACT, a set of high-throughput main memory-based timing attacks that leverage characteristics of PiM architectures to establish covert and side channels. IMPACT enables high-throughput communication and private information leakage. To achieve this, IMPACT (i) eliminates expensive cache bypassing steps required by processor-centric main memory and cache-based timing attacks and (ii) leverages the intrinsic parallelism of PiM operations. First, we showcase two covert-channel attack variants that run on the host CPU and leverage PiM architectures to gain direct and fast access to main memory and establish high-throughput communication covert channels. Second, we showcase a side-channel attack on a DNA sequence analysis application that leaks the private characteristics of a user's sample genome by leveraging PiM operations. Our results demonstrate that (i) our covert channels achieve up to 14.16 Mb/s communication throughput, which is 6.38x faster than the state-of-the-art main memory-based covert channels, and (ii) our side-channel attack allows the attacker to determine the properties of a sample genome at a throughput of 7.5 Mb/s with 96% accuracy. We discuss and evaluate several countermeasures for IMPACT to enable secure and robust PiM architectures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11284v1</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Konstantinos Kanellopoulos, F. Nisa Bostanci, Ataberk Olgun, A. Giray Yaglikci, Ismail Emir Yuksel, Nika Mansouri Ghiasi, Zulal Bingol, Mohammad Sadrosadati, Onur Mutlu</dc:creator>
    </item>
    <item>
      <title>On Learning Parities with Dependent Noise</title>
      <link>https://arxiv.org/abs/2404.11325</link>
      <description>arXiv:2404.11325v1 Announce Type: new 
Abstract: In this expository note we show that the learning parities with noise (LPN) assumption is robust to weak dependencies in the noise distribution of small batches of samples. This provides a partial converse to the linearization technique of [AG11]. The material in this note is drawn from a recent work by the authors [GMR24], where the robustness guarantee was a key component in a cryptographic separation between reinforcement learning and supervised learning.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11325v1</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Noah Golowich, Ankur Moitra, Dhruv Rohatgi</dc:creator>
    </item>
    <item>
      <title>LLMs for Cyber Security: New Opportunities</title>
      <link>https://arxiv.org/abs/2404.11338</link>
      <description>arXiv:2404.11338v1 Announce Type: new 
Abstract: Large language models (LLMs) are a class of powerful and versatile models that are beneficial to many industries. With the emergence of LLMs, we take a fresh look at cyber security, specifically exploring and summarizing the potential of LLMs in addressing challenging problems in the security and safety domains.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11338v1</guid>
      <category>cs.CR</category>
      <category>cs.SE</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Dinil Mon Divakaran, Sai Teja Peddinti</dc:creator>
    </item>
    <item>
      <title>S3PHER: Secure and Searchable System for Patient-driven HEalth data shaRing</title>
      <link>https://arxiv.org/abs/2404.11372</link>
      <description>arXiv:2404.11372v1 Announce Type: new 
Abstract: Healthcare data contains some of the most sensitive information about an individual, yet sharing this data with healthcare practitioners can significantly enhance patient care and support research efforts. However, current systems for sharing health data between patients and caregivers do not fully address the critical security requirements of privacy, confidentiality, and consent management. Furthermore, compliance with regulatory laws such as GDPR and HIPAA is often deficient, largely because patients typically are asked to provide general consent for healthcare entities to access their data. Recognizing the limitations of existing systems, we present S3PHER, a novel approach to sharing health data that provides patients with control over who accesses their data, what data is accessed, and when. Our system ensures end to end privacy by integrating a Proxy ReEncryption Scheme with a Searchable Encryption Scheme, utilizing Homomorphic Encryption to enable healthcare practitioners to privately search and access patients' documents. The practicality and benefits of S3PHER are further validated through end to end deployment and use case analyses, with tests on real datasets demonstrating promising execution times.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11372v1</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ivan Costa, Ivone Amorim, Eva Maia, Pedro Barbosa, Isabel Praca</dc:creator>
    </item>
    <item>
      <title>Enhancing Data Privacy In Wireless Sensor Networks: Investigating Techniques And Protocols To Protect Privacy Of Data Transmitted Over Wireless Sensor Networks In Critical Applications Of Healthcare And National Security</title>
      <link>https://arxiv.org/abs/2404.11388</link>
      <description>arXiv:2404.11388v1 Announce Type: new 
Abstract: The article discusses the emergence of Wireless Sensor Networks (WSNs) as a groundbreaking technology in data processing and communication. It outlines how WSNs, composed of dispersed autonomous sensors, are utilized to monitor physical and environmental factors, transmitting data wirelessly for analysis. The article explores various applications of WSNs in healthcare, national security, emergency response, and infrastructure monitoring, highlighting their roles in enhancing patient care, public health surveillance, border security, disaster management, and military operations. Additionally, it examines the foundational concepts of data privacy in WSNs, focusing on encryption techniques, authentication mechanisms, anonymization techniques, and access control mechanisms. The article also addresses vulnerabilities, threats, and challenges related to data privacy in healthcare and national security contexts, emphasizing regulatory compliance, ethical considerations, and socio-economic factors. Furthermore, it introduces the Diffusion of Innovation Theory as a framework for understanding the adoption of privacy-enhancing technologies in WSNs. Finally, the article reviews empirical studies demonstrating the efficacy of security solutions in preserving data privacy in WSNs, offering insights into advancements in safeguarding sensitive information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11388v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.5121/ijnsa.2024.16204</arxiv:DOI>
      <dc:creator>Akinsola Ahmed, Ejiofor Oluomachi, Akinde Abdullah, Njoku Tochukwu</dc:creator>
    </item>
    <item>
      <title>SERENE: A Collusion Resilient Replication-based Verification Framework</title>
      <link>https://arxiv.org/abs/2404.11410</link>
      <description>arXiv:2404.11410v1 Announce Type: new 
Abstract: The rapid advancement of autonomous driving technology is accompanied by substantial challenges, particularly the reliance on remote task execution without ensuring a reliable and accurate returned results. This reliance on external compute servers, which may be malicious or rogue, represents a major security threat. While researchers have been exploring verifiable computing, and replication-based task verification as a simple, fast, and dependable method to assess the correctness of results. However, colluding malicious workers can easily defeat this method. Existing collusion detection and mitigation solutions often require the use of a trusted third party server or verified tasks which may be hard to guarantee, or solutions that assume the presence of a minority of colluding servers. We propose SERENE a collusion resilient replication-based verification framework that detects, and mitigates colluding workers. Unlike state-of-the-art solutions, SERENE uses a lightweight detection algorithm that detects collusion based on a single verification task. Mitigation requires a two stage process to group the workers and identifying colluding from honest workers. We implement and compare SERENE's performance to Staab et. al, resulting in an average of 50\% and 60\% accuracy improvement in detection and mitigation accuracy respectively.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11410v1</guid>
      <category>cs.CR</category>
      <category>cs.NI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Amir Esmaeili, Abderrahmen Mtibaa</dc:creator>
    </item>
    <item>
      <title>Assessing The Effectiveness Of Current Cybersecurity Regulations And Policies In The US</title>
      <link>https://arxiv.org/abs/2404.11473</link>
      <description>arXiv:2404.11473v1 Announce Type: new 
Abstract: This article assesses the effectiveness of current cybersecurity regulations and policies in the United States amidst the escalating frequency and sophistication of cyber threats. The focus is on the comprehensive framework established by the U.S. government, with a spotlight on the National Institute of Standards and Technology (NIST) Cybersecurity Framework and key regulations such as HIPAA, GLBA, FISMA, CISA, CCPA, and the DOD Cybersecurity Maturity Model Certification. The study evaluates the impact of these regulations on different sectors and analyzes trends in cybercrime data from 2000 to 2022. The findings highlight the challenges, successes, and the need for continuous adaptation in the face of evolving cyber threats</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11473v1</guid>
      <category>cs.CR</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.29322/IJSRP.14.02.2023.p14610</arxiv:DOI>
      <dc:creator>Ejiofor Oluomachi, Akinsola Ahmed, Wahab Ahmed, Edozie Samson</dc:creator>
    </item>
    <item>
      <title>Personalized Federated Learning via Stacking</title>
      <link>https://arxiv.org/abs/2404.10957</link>
      <description>arXiv:2404.10957v1 Announce Type: cross 
Abstract: Traditional Federated Learning (FL) methods typically train a single global model collaboratively without exchanging raw data. In contrast, Personalized Federated Learning (PFL) techniques aim to create multiple models that are better tailored to individual clients' data. We present a novel personalization approach based on stacked generalization where clients directly send each other privacy-preserving models to be used as base models to train a meta-model on private data. Our approach is flexible, accommodating various privacy-preserving techniques and model types, and can be applied in horizontal, hybrid, and vertically partitioned federations. Additionally, it offers a natural mechanism for assessing each client's contribution to the federation. Through comprehensive evaluations across diverse simulated data heterogeneity scenarios, we showcase the effectiveness of our method.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10957v1</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <category>cs.DC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Emilio Cantu-Cervini</dc:creator>
    </item>
    <item>
      <title>From Paper to Platform: Evolution of a Novel Learning Environment for Tabletop Exercises</title>
      <link>https://arxiv.org/abs/2404.10988</link>
      <description>arXiv:2404.10988v1 Announce Type: cross 
Abstract: For undergraduate students of computing, learning to solve complex practical problems in a team is an essential skill for their future careers. This skill is needed in various fields, such as in cybersecurity and IT governance. Tabletop exercises are an innovative teaching method used in practice for training teams in incident response and evaluation of contingency plans. However, tabletop exercises are not yet widely established in university education. This paper presents data and teaching experience from a cybersecurity course that introduces tabletop exercises in classrooms using a novel technology: INJECT Exercise Platform (IXP), a web-based learning environment for delivering and evaluating the exercises. This technology substantially improves the prior practice, since tabletop exercises worldwide have usually been conducted using pen and paper. Unlike in traditional tabletop exercises, which are difficult to evaluate manually, IXP provides insights into students' behavior and learning based on automated analysis of interaction data. We demonstrate IXP's capabilities and evolution by comparing exercise sessions hosted throughout three years at different stages of the platform's readiness. The analysis of student data is supplemented by the discussion of the lessons learned from employing IXP in computing education contexts. The data analytics enabled a detailed comparison of the teams' performance and behavior. Instructors who consider innovating their classes with tabletop exercises may use IXP and benefit from the insights in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10988v1</guid>
      <category>cs.CY</category>
      <category>cs.CR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3649217.3653639</arxiv:DOI>
      <dc:creator>Valdemar \v{S}v\'abensk\'y, Jan Vykopal, Martin Hor\'ak, Martin Hofbauer, Pavel \v{C}eleda</dc:creator>
    </item>
    <item>
      <title>Clipped SGD Algorithms for Privacy Preserving Performative Prediction: Bias Amplification and Remedies</title>
      <link>https://arxiv.org/abs/2404.10995</link>
      <description>arXiv:2404.10995v1 Announce Type: cross 
Abstract: Clipped stochastic gradient descent (SGD) algorithms are among the most popular algorithms for privacy preserving optimization that reduces the leakage of users' identity in model training. This paper studies the convergence properties of these algorithms in a performative prediction setting, where the data distribution may shift due to the deployed prediction model. For example, the latter is caused by strategical users during the training of loan policy for banks. Our contributions are two-fold. First, we show that the straightforward implementation of a projected clipped SGD (PCSGD) algorithm may converge to a biased solution compared to the performative stable solution. We quantify the lower and upper bound for the magnitude of the bias and demonstrate a bias amplification phenomenon where the bias grows with the sensitivity of the data distribution. Second, we suggest two remedies to the bias amplification effect. The first one utilizes an optimal step size design for PCSGD that takes the privacy guarantee into account. The second one uses the recently proposed DiceSGD algorithm [Zhang et al., 2024]. We show that the latter can successfully remove the bias and converge to the performative stable solution. Numerical experiments verify our analysis.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10995v1</guid>
      <category>math.OC</category>
      <category>cs.CR</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Michal Yemini, Hoi-To Wai</dc:creator>
    </item>
    <item>
      <title>LMEraser: Large Model Unlearning through Adaptive Prompt Tuning</title>
      <link>https://arxiv.org/abs/2404.11056</link>
      <description>arXiv:2404.11056v1 Announce Type: cross 
Abstract: To address the growing demand for privacy protection in machine learning, we propose a novel and efficient machine unlearning approach for \textbf{L}arge \textbf{M}odels, called \textbf{LM}Eraser. Existing unlearning research suffers from entangled training data and complex model architectures, incurring extremely high computational costs for large models. LMEraser takes a divide-and-conquer strategy with a prompt tuning architecture to isolate data influence. The training dataset is partitioned into public and private datasets. Public data are used to train the backbone of the model. Private data are adaptively clustered based on their diversity, and each cluster is used to optimize a prompt separately. This adaptive prompt tuning mechanism reduces unlearning costs and maintains model performance. Experiments demonstrate that LMEraser achieves a $100$-fold reduction in unlearning costs without compromising accuracy compared to prior work. Our code is available at: \url{https://github.com/lmeraser/lmeraser}.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11056v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jie Xu, Zihan Wu, Cong Wang, Xiaohua Jia</dc:creator>
    </item>
    <item>
      <title>Real-Time Trajectory Synthesis with Local Differential Privacy</title>
      <link>https://arxiv.org/abs/2404.11450</link>
      <description>arXiv:2404.11450v1 Announce Type: cross 
Abstract: Trajectory streams are being generated from location-aware devices, such as smartphones and in-vehicle navigation systems. Due to the sensitive nature of the location data, directly sharing user trajectories suffers from privacy leakage issues. Local differential privacy (LDP), which perturbs sensitive data on the user side before it is shared or analyzed, emerges as a promising solution for private trajectory stream collection and analysis. Unfortunately, existing stream release approaches often neglect the rich spatial-temporal context information within trajectory streams, resulting in suboptimal utility and limited types of downstream applications. To this end, we propose RetraSyn, a novel real-time trajectory synthesis framework, which is able to perform on-the-fly trajectory synthesis based on the mobility patterns privately extracted from users' trajectory streams. Thus, the downstream trajectory analysis can be performed on the high-utility synthesized data with privacy protection. We also take the genuine behaviors of real-world mobile travelers into consideration, ensuring authenticity and practicality. The key components of RetraSyn include the global mobility model, dynamic mobility update mechanism, real-time synthesis, and adaptive allocation strategy. We conduct extensive experiments on multiple real-world and synthetic trajectory datasets under various location-based utility metrics, encompassing both streaming and historical scenarios. The empirical results demonstrate the superiority and versatility of our proposed framework.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11450v1</guid>
      <category>cs.DB</category>
      <category>cs.CR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yujia Hu, Yuntao Du, Zhikun Zhang, Ziquan Fang, Lu Chen, Kai Zheng, Yunjun Gao</dc:creator>
    </item>
    <item>
      <title>A Large-scale Fine-grained Analysis of Packages in Open-Source Software Ecosystems</title>
      <link>https://arxiv.org/abs/2404.11467</link>
      <description>arXiv:2404.11467v1 Announce Type: cross 
Abstract: Package managers such as NPM, Maven, and PyPI play a pivotal role in open-source software (OSS) ecosystems, streamlining the distribution and management of various freely available packages. The fine-grained details within software packages can unveil potential risks within existing OSS ecosystems, offering valuable insights for detecting malicious packages. In this study, we undertake a large-scale empirical analysis focusing on fine-grained information (FGI): the metadata, static, and dynamic functions. Specifically, we investigate the FGI usage across a diverse set of 50,000+ legitimate and 1,000+ malicious packages. Based on this diverse data collection, we conducted a comparative analysis between legitimate and malicious packages. Our findings reveal that (1) malicious packages have less metadata content and utilize fewer static and dynamic functions than legitimate ones; (2) malicious packages demonstrate a higher tendency to invoke HTTP/URL functions as opposed to other application services, such as FTP or SMTP; (3) FGI serves as a distinguishable indicator between legitimate and malicious packages; and (4) one dimension in FGI has sufficient distinguishable capability to detect malicious packages, and combining all dimensions in FGI cannot significantly improve overall performance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.11467v1</guid>
      <category>cs.SE</category>
      <category>cs.CR</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaoyan Zhou, Feiran Liang, Zhaojie Xie, Yang Lan, Wenjia Niu, Jiqiang Liu, Haining Wang, Qiang Li</dc:creator>
    </item>
    <item>
      <title>Graph Set-colorings And Hypergraphs In Topological Coding</title>
      <link>https://arxiv.org/abs/2201.13354</link>
      <description>arXiv:2201.13354v2 Announce Type: replace 
Abstract: In order to make more complex number-based strings from topological coding for defending against the intelligent attacks equipped with quantum computing and providing effective protection technology for the age of quantum computing, we will introduce set-colored graphs admitting set-colorings that has been considerable cryptanalytic significance, and especially related with hypergraphs. We use the set-coloring of graphs to reflect the intersection of elements, and add other constraint requirements to express more connections between sets (as hyperedges). Since we try to find some easy and effective techniques based on graph theory for practical application, we use intersected-graphs admitting set-colorings defined on hyperedge sets to observe topological structures of hypergraphs, string-type Topcode-matrix, set-type Topcode-matrix, graph-type Topcode-matrix, hypergraph-type Topcode-matrix, matrix-type Topcode-matrix \emph{etc}. We will show that each connected graph is the intersected-graph of some hypergraph and investigate hypergraph's connectivity, colorings of hypergraphs, hypergraph homomorphism, hypernetworks, scale-free network generator, compound hypergraphs having their intersected-graphs with vertices to be hypergraphs (for high-dimensional extension diagram). Naturally, we get various graphic lattices, such as edge-coincided intersected-graph lattice, vertex-coincided intersected-graph lattice, edge-hamiltonian graphic lattice, hypergraph lattice and intersected-network lattice. Many techniques in this article can be translated into polynomial algorithms, since we are aiming to apply hypergraphs and graph set-colorings to homomorphic encryption and asymmetric cryptograph.</description>
      <guid isPermaLink="false">oai:arXiv.org:2201.13354v2</guid>
      <category>cs.CR</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Bing Yao, Fei Ma</dc:creator>
    </item>
    <item>
      <title>Design for Trust utilizing Rareness Reduction</title>
      <link>https://arxiv.org/abs/2302.08984</link>
      <description>arXiv:2302.08984v2 Announce Type: replace 
Abstract: Increasing design complexity and reduced time-to-market have motivated manufacturers to outsource some parts of the System-on-Chip (SoC) design flow to third-party vendors. This provides an opportunity for attackers to introduce hardware Trojans by constructing stealthy triggers consisting of rare events (e.g., rare signals, states, and transitions). There are promising test generation-based hardware Trojan detection techniques that rely on the activation of rare events. In this paper, we investigate rareness reduction as a design-for-trust solution to make it harder for an adversary to hide Trojans (easier for Trojan detection). Specifically, we analyze different avenues to reduce the potential rare trigger cases, including design diversity and area optimization. While there is a good understanding of the relationship between area, power, energy, and performance, this research provides a better insight into the dependency between area and security. Our experimental evaluation demonstrates that area reduction leads to a reduction in rareness. It also reveals that reducing rareness leads to faster Trojan detection as well as improved coverage by Trojan detection methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2302.08984v2</guid>
      <category>cs.CR</category>
      <category>cs.AR</category>
      <category>cs.LO</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/VLSID60093.2024.00079</arxiv:DOI>
      <dc:creator>Aruna Jayasena, Prabhat Mishra</dc:creator>
    </item>
    <item>
      <title>Composition in Differential Privacy for General Granularity Notions (Long Version)</title>
      <link>https://arxiv.org/abs/2308.14649</link>
      <description>arXiv:2308.14649v2 Announce Type: replace 
Abstract: The composition theorems of differential privacy (DP) allow data curators to combine different algorithms to obtain a new algorithm that continues to satisfy DP. However, new granularity notions (i.e., neighborhood definitions), data domains, and composition settings have appeared in the literature that the classical composition theorems do not cover. For instance, the original parallel composition theorem does not translate well to general granularity notions. This complicates the opportunity of composing DP mechanisms in new settings and obtaining accurate estimates of the incurred privacy loss after composition.
  To overcome these limitations, we study the composability of DP in a general framework and for any kind of data domain or neighborhood definition. We give a general composition theorem in both independent and adaptive versions and we provide analogous composition results for approximate, zero-concentrated, and Gaussian DP. Besides, we study the hypothesis needed to obtain the best composition bounds. Our theorems cover both parallel and sequential composition settings. Importantly, they also cover every setting in between, allowing us to compute the final privacy loss of a composition with greatly improved accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2308.14649v2</guid>
      <category>cs.CR</category>
      <category>cs.DS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Patricia Guerra-Balboa, \`Alex Miranda-Pascual, Javier Parra-Arnau, Thorsten Strufe</dc:creator>
    </item>
    <item>
      <title>Don't Let MEV Slip: The Costs of Swapping on the Uniswap Protocol</title>
      <link>https://arxiv.org/abs/2309.13648</link>
      <description>arXiv:2309.13648v2 Announce Type: replace 
Abstract: We present the first in-depth empirical characterization of the costs of trading on a decentralized exchange (DEX). Using quoted prices from the Uniswap Labs interface for two pools -- USDC-ETH (5bps) and PEPE-ETH (30bps) -- we evaluate the efficiency of trading on DEXs. Our main tool is slippage -- the difference between the realized execution price of a trade, and its quoted price -- which we breakdown into its benign and adversarial components. We also present an alternative way to quantify and identify slippage due to adversarial reordering of transactions, which we call reordering slippage, that does not require quoted prices or mempool data to calculate. We find that the composition of transaction costs varies tremendously with the trade's characteristics. Specifically, while for small swaps, gas costs dominate costs, for large swaps price-impact and slippage account for the majority of it. Moreover, when trading PEPE, a popular 'memecoin', the probability of adversarial slippage is about 80% higher than when trading a mature asset like USDC.
  Overall, our results provide preliminary evidence that DEXs offer a compelling trust-less alternative to centralized exchanges for trading digital assets.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.13648v2</guid>
      <category>cs.CR</category>
      <category>q-fin.TR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Austin Adams, Benjamin Y Chan, Sarit Markovich, Xin Wan</dc:creator>
    </item>
    <item>
      <title>ToDA: Target-oriented Diffusion Attacker against Recommendation System</title>
      <link>https://arxiv.org/abs/2401.12578</link>
      <description>arXiv:2401.12578v2 Announce Type: replace 
Abstract: Recommendation systems (RS) have become indispensable tools for web services to address information overload, thus enhancing user experiences and bolstering platforms' revenues. However, with their increasing ubiquity, security concerns have also emerged. As the public accessibility of RS, they are susceptible to specific malicious attacks where adversaries can manipulate user profiles, leading to biased recommendations. Recent research often integrates additional modules using generative models to craft these deceptive user profiles, ensuring them are imperceptible while causing the intended harm. Albeit their efficacy, these models face challenges of unstable training and the exploration-exploitation dilemma, which can lead to suboptimal results. In this paper, we pioneer to investigate the potential of diffusion models (DMs), for shilling attacks. Specifically, we propose a novel Target-oriented Diffusion Attack model (ToDA). It incorporates a pre-trained autoencoder that transforms user profiles into a high dimensional space, paired with a Latent Diffusion Attacker (LDA)-the core component of ToDA. LDA introduces noise into the profiles within this latent space, adeptly steering the approximation towards targeted items through cross-attention mechanisms. The global horizon, implemented by a bipartite graph, is involved in LDA and derived from the encoded user profile feature. This makes LDA possible to extend the generation outwards the on-processing user feature itself, and bridges the gap between diffused user features and target item features. Extensive experiments compared to several SOTA baselines demonstrate ToDA's effectiveness. Specific studies exploit the elaborative design of ToDA and underscore the potency of advanced generative models in such contexts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.12578v2</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xiaohao Liu, Zhulin Tao, Ting Jiang, He Chang, Yunshan Ma, Xianglin Huang, Xiang Wang</dc:creator>
    </item>
    <item>
      <title>An Innovative Information Theory-based Approach to Tackle and Enhance The Transparency in Phishing Detection</title>
      <link>https://arxiv.org/abs/2402.17092</link>
      <description>arXiv:2402.17092v2 Announce Type: replace 
Abstract: Phishing attacks have become a serious and challenging issue for detection, explanation, and defense. Despite more than a decade of research on phishing, encompassing both technical and non-technical remedies, phishing continues to be a serious problem. Nowadays, AI-based phishing detection stands out as one of the most effective solutions for defending against phishing attacks by providing vulnerability (i.e., phishing or benign) predictions for the data. However, it lacks explainability in terms of providing comprehensive interpretations for the predictions, such as identifying the specific information that causes the data to be classified as phishing. To this end, we propose an innovative deep learning-based approach for email (the most common phishing way) phishing attack localization. Our method can not only predict the vulnerability of the email data but also automatically learn and figure out the most important and phishing-relevant information (i.e., sentences) in the phishing email data where the selected information indicates useful and concise explanations for the vulnerability. The rigorous experiments on seven real-world diverse email datasets show the effectiveness and advancement of our proposed method in selecting crucial information, offering concise explanations (by successfully figuring out the most important and phishing-relevant information) for the vulnerability of the phishing email data. Particularly, our method achieves a significantly higher performance, ranging from approximately 1.5% to 3.5%, compared to state-of-the-art baselines, as measured by the combined average performance of two main metrics Label-Accuracy and Cognitive-True-Positive.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.17092v2</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Van Nguyen, Tingmin Wu, Xingliang Yuan, Marthie Grobler, Surya Nepal, Carsten Rudolph</dc:creator>
    </item>
    <item>
      <title>Ciphertext-Only Attack on a Secure $k$-NN Computation on Cloud</title>
      <link>https://arxiv.org/abs/2403.09080</link>
      <description>arXiv:2403.09080v2 Announce Type: replace 
Abstract: The rise of cloud computing has spurred a trend of transferring data storage and computational tasks to the cloud. To protect confidential information such as customer data and business details, it is essential to encrypt this sensitive data before cloud storage. Implementing encryption can prevent unauthorized access, data breaches, and the resultant financial loss, reputation damage, and legal issues. Moreover, to facilitate the execution of data mining algorithms on the cloud-stored data, the encryption needs to be compatible with domain computation. The $k$-nearest neighbor ($k$-NN) computation for a specific query vector is widely used in fields like location-based services. Sanyashi et al. (ICISS 2023) proposed an encryption scheme to facilitate privacy-preserving $k$-NN computation on the cloud by utilizing Asymmetric Scalar-Product-Preserving Encryption (ASPE).
  In this work, we identify a significant vulnerability in the aforementioned encryption scheme of Sanyashi et al. Specifically, we give an efficient algorithm and also empirically demonstrate that their encryption scheme is vulnerable to the ciphertext-only attack (COA).</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.09080v2</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Shyam Murthy, Santosh Kumar Upadhyaya, Srinivas Vivek</dc:creator>
    </item>
    <item>
      <title>Hidden You Malicious Goal Into Benign Narratives: Jailbreak Large Language Models through Logic Chain Injection</title>
      <link>https://arxiv.org/abs/2404.04849</link>
      <description>arXiv:2404.04849v2 Announce Type: replace 
Abstract: Jailbreak attacks on Language Model Models (LLMs) entail crafting prompts aimed at exploiting the models to generate malicious content. Existing jailbreak attacks can successfully deceive the LLMs, however they cannot deceive the human. This paper proposes a new type of jailbreak attacks which can deceive both the LLMs and human (i.e., security analyst). The key insight of our idea is borrowed from the social psychology - that is human are easily deceived if the lie is hidden in truth. Based on this insight, we proposed the logic-chain injection attacks to inject malicious intention into benign truth. Logic-chain injection attack firstly dissembles its malicious target into a chain of benign narrations, and then distribute narrations into a related benign article, with undoubted facts. In this way, newly generate prompt cannot only deceive the LLMs, but also deceive human.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.04849v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhilong Wang, Yebo Cao, Peng Liu</dc:creator>
    </item>
    <item>
      <title>LLM Agents can Autonomously Exploit One-day Vulnerabilities</title>
      <link>https://arxiv.org/abs/2404.08144</link>
      <description>arXiv:2404.08144v2 Announce Type: replace 
Abstract: LLMs have becoming increasingly powerful, both in their benign and malicious uses. With the increase in capabilities, researchers have been increasingly interested in their ability to exploit cybersecurity vulnerabilities. In particular, recent work has conducted preliminary studies on the ability of LLM agents to autonomously hack websites. However, these studies are limited to simple vulnerabilities.
  In this work, we show that LLM agents can autonomously exploit one-day vulnerabilities in real-world systems. To show this, we collected a dataset of 15 one-day vulnerabilities that include ones categorized as critical severity in the CVE description. When given the CVE description, GPT-4 is capable of exploiting 87% of these vulnerabilities compared to 0% for every other model we test (GPT-3.5, open-source LLMs) and open-source vulnerability scanners (ZAP and Metasploit). Fortunately, our GPT-4 agent requires the CVE description for high performance: without the description, GPT-4 can exploit only 7% of the vulnerabilities. Our findings raise questions around the widespread deployment of highly capable LLM agents.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.08144v2</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Richard Fang, Rohan Bindu, Akul Gupta, Daniel Kang</dc:creator>
    </item>
    <item>
      <title>Data Analysis Methods Preliminaries for a Photon-based Hardware Random Number Generator</title>
      <link>https://arxiv.org/abs/2404.09395</link>
      <description>arXiv:2404.09395v2 Announce Type: replace 
Abstract: High quality random numbers are necessary in the modern world. Ranging from encryption keys in cyber security to models and simulations for scientific use: it's important that these random numbers are of high quality and quickly attainable. One common solution to the generation of random numbers is that of pseudo-random number generators, or PRNGs. PRNGs generate random numbers by first quantifying some unpredictable phenomena into a number or string and feeding it into an algorithm which yields numbers randomly based on that seed. Easy places to find seeds include the user's mouse movements or the machine's uptime. These are only pseudorandom, however, as if given the same seed twice, the PRNG would generate the same 'random' output. This is great for games like Minecraft, but not so great for cybersecurity encryption key generation. By using a hardware random number generator (HRNG), random numbers that are not susceptible to the flaws found in PRNGs can be attained at a high rate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.09395v2</guid>
      <category>cs.CR</category>
      <category>physics.ins-det</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Dmitriy Beznosko, Keith Driscoll, Fernando Guadarrama, Steven Mai, Nikolas Thornton</dc:creator>
    </item>
    <item>
      <title>Sisu: Decentralized Trustless Bridge For Full Ethereum Node</title>
      <link>https://arxiv.org/abs/2404.10404</link>
      <description>arXiv:2404.10404v2 Announce Type: replace 
Abstract: In this paper, we present a detailed approach and implementation to prove Ethereum full node using recursive SNARK, distributed general GKR and Groth16. Our protocol's name is Sisu whose architecture is based on distributed Virgo in zkBridge with some major improvements. Besides proving signature aggregation, we provide solutions to 2 hard problems in proving Ethereum full node: 1) any public key is valid under previous beacon state and 2) all public keys are pairwise distinct. Our solution does not require worker-to-worker communication and therefore reduce total worker-to-worker network traffic from terabyte of data to zero compared to zkBridge. This makes our approach suitable for emerging distributed prover markets and more decentralized compared to zkBridge. Our design is highly parallelable and capable of running on GPU for most parts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.10404v2</guid>
      <category>cs.CR</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Billy Pham, Huy Le</dc:creator>
    </item>
    <item>
      <title>An efficient quantum parallel repetition theorem and applications</title>
      <link>https://arxiv.org/abs/2311.10681</link>
      <description>arXiv:2311.10681v2 Announce Type: replace-cross 
Abstract: We prove a tight parallel repetition theorem for $3$-message computationally-secure quantum interactive protocols between an efficient challenger and an efficient adversary. We also prove under plausible assumptions that the security of $4$-message computationally secure protocols does not generally decrease under parallel repetition. These mirror the classical results of Bellare, Impagliazzo, and Naor [BIN97]. Finally, we prove that all quantum argument systems can be generically compiled to an equivalent $3$-message argument system, mirroring the transformation for quantum proof systems [KW00, KKMV07].
  As immediate applications, we show how to derive hardness amplification theorems for quantum bit commitment schemes (answering a question of Yan [Yan22]), EFI pairs (answering a question of Brakerski, Canetti, and Qian [BCQ23]), public-key quantum money schemes (answering a question of Aaronson and Christiano [AC13]), and quantum zero-knowledge argument systems. We also derive an XOR lemma [Yao82] for quantum predicates as a corollary.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.10681v2</guid>
      <category>quant-ph</category>
      <category>cs.CC</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3618260.3649603</arxiv:DOI>
      <dc:creator>John Bostanci, Luowen Qian, Nicholas Spooner, Henry Yuen</dc:creator>
    </item>
    <item>
      <title>Differentially Private SGD Without Clipping Bias: An Error-Feedback Approach</title>
      <link>https://arxiv.org/abs/2311.14632</link>
      <description>arXiv:2311.14632v2 Announce Type: replace-cross 
Abstract: Differentially Private Stochastic Gradient Descent with Gradient Clipping (DPSGD-GC) is a powerful tool for training deep learning models using sensitive data, providing both a solid theoretical privacy guarantee and high efficiency. However, using DPSGD-GC to ensure Differential Privacy (DP) comes at the cost of model performance degradation due to DP noise injection and gradient clipping. Existing research has extensively analyzed the theoretical convergence of DPSGD-GC, and has shown that it only converges when using large clipping thresholds that are dependent on problem-specific parameters. Unfortunately, these parameters are often unknown in practice, making it hard to choose the optimal clipping threshold. Therefore, in practice, DPSGD-GC suffers from degraded performance due to the {\it constant} bias introduced by the clipping.
  In our work, we propose a new error-feedback (EF) DP algorithm as an alternative to DPSGD-GC, which not only offers a diminishing utility bound without inducing a constant clipping bias, but more importantly, it allows for an arbitrary choice of clipping threshold that is independent of the problem. We establish an algorithm-specific DP analysis for our proposed algorithm, providing privacy guarantees based on R{\'e}nyi DP. Additionally, we demonstrate that under mild conditions, our algorithm can achieve nearly the same utility bound as DPSGD without gradient clipping. Our empirical results on Cifar-10/100 and E2E datasets, show that the proposed algorithm achieves higher accuracies than DPSGD while maintaining the same level of DP guarantee.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14632v2</guid>
      <category>cs.LG</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinwei Zhang, Zhiqi Bu, Zhiwei Steven Wu, Mingyi Hong</dc:creator>
    </item>
    <item>
      <title>Web 3.0 and Quantum Security: Long-Distance Free-Space QSDC for Global Web 3.0 Networks</title>
      <link>https://arxiv.org/abs/2402.09108</link>
      <description>arXiv:2402.09108v3 Announce Type: replace-cross 
Abstract: With the advent of Web 3.0, the swift advancement of technology confronts an imminent threat from quantum computing. Security protocols safeguarding the integrity of Web 2.0 and Web 3.0 are growing more susceptible to both quantum attacks and sophisticated classical threats. The article introduces our novel long-distance free-space quantum secure direct communication (LF QSDC) as a method to safeguard against security breaches in both quantum and classical contexts. Differing from techniques like quantum key distribution (QKD), LF QSDC surpasses constraints by facilitating encrypted data transmission sans key exchanges, thus diminishing the inherent weaknesses of key-based systems. The distinctiveness of this attribute, coupled with its quantum mechanics base, protects against quantum computer assaults and advanced non-quantum dangers, harmonizing seamlessly with the untrustworthy tenets of the Web 3.0 age. The focus of our study is the technical design and incorporation of LF QSDC into web 3.0 network infrastructures, highlighting its efficacy for extended-range communication. LF QSDC is based on the memory DL04 protocol and enhanced with our novel Quantum-Aware Low-Density Parity Check (LDPC), Pointing, Acquisition, and Tracking (PAT) technologies, and Atmospheric Quantum Correction Algorithm (AQCA). Utilizing this method not only bolsters the security of worldwide Web 3.0 networks but also guarantees their endurance in a time when quantum and sophisticated classical threats exist simultaneously. Consequently, LF QSDC stands out as a robust security solution, well-suited for Web 3.0 systems amidst the constantly evolving digital environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.09108v3</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yew Kee Wong, Yifan Zhou, Xinlin Zhou, Yan Shing Liang, Zi Yan Li</dc:creator>
    </item>
    <item>
      <title>Off-Path TCP Hijacking in Wi-Fi Networks: A Packet-Size Side Channel Attack</title>
      <link>https://arxiv.org/abs/2402.12716</link>
      <description>arXiv:2402.12716v4 Announce Type: replace-cross 
Abstract: In this paper, we unveil a fundamental side channel in Wi-Fi networks, specifically the observable frame size, which can be exploited by attackers to conduct TCP hijacking attacks. Despite the various security mechanisms (e.g., WEP and WPA2/WPA3) implemented to safeguard Wi-Fi networks, our study reveals that an off path attacker can still extract sufficient information from the frame size side channel to hijack the victim's TCP connection. Our side channel attack is based on two significant findings: (i) response packets (e.g., ACK and RST) generated by TCP receivers vary in size, and (ii) the encrypted frames containing these response packets have consistent and distinguishable sizes. By observing the size of the victim's encrypted frames, the attacker can detect and hijack the victim's TCP connections. We validate the effectiveness of this side channel attack through two case studies, i.e., SSH DoS and web traffic manipulation. Precisely, our attack can terminate the victim's SSH session in 19 seconds and inject malicious data into the victim's web traffic within 28 seconds. Furthermore, we conduct extensive measurements to evaluate the impact of our attack on real-world Wi-Fi networks. We test 30 popular wireless routers from 9 well-known vendors, and none of these routers can protect victims from our attack. Besides, we implement our attack in 80 real-world Wi-Fi networks and successfully hijack the victim's TCP connections in 75 (93.75%) evaluated Wi-Fi networks. We have responsibly disclosed the vulnerability to the Wi-Fi Alliance and proposed several mitigation strategies to address this issue.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.12716v4</guid>
      <category>cs.NI</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ziqiang Wang, Xuewei Feng, Qi Li, Kun Sun, Yuxiang Yang, Mengyuan Li, Ganqiu Du, Ke Xu, Jianping Wu</dc:creator>
    </item>
    <item>
      <title>Real-Valued Somewhat-Pseudorandom Unitaries</title>
      <link>https://arxiv.org/abs/2403.16704</link>
      <description>arXiv:2403.16704v2 Announce Type: replace-cross 
Abstract: We explore a very simple distribution of unitaries: random (binary) phase -- Hadamard -- random (binary) phase -- random computational-basis permutation. We show that this distribution is statistically indistinguishable from random Haar unitaries for any polynomial set of orthogonal input states (in any basis) with polynomial multiplicity. This shows that even though real-valued unitaries cannot be completely pseudorandom (Haug, Bharti, Koh, arXiv:2306.11677), we can still obtain some pseudorandom properties without giving up on the simplicity of a real-valued unitary.
  Our analysis shows that an even simpler construction: applying a random (binary) phase followed by a random computational-basis permutation, would suffice, assuming that the input is orthogonal and \emph{flat} (that is, has high min-entropy when measured in the computational basis).
  Using quantum-secure one-way functions (which imply quantum-secure pseudorandom functions and permutations), we obtain an efficient cryptographic instantiation of the above.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.16704v2</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zvika Brakerski, Nir Magrafta</dc:creator>
    </item>
    <item>
      <title>Commitments are equivalent to one-way state generators</title>
      <link>https://arxiv.org/abs/2404.03220</link>
      <description>arXiv:2404.03220v2 Announce Type: replace-cross 
Abstract: One-way state generators (OWSG) are natural quantum analogs to classical one-way functions. We show that $O\left(\frac{n}{\log(n)}\right)$-copy OWSGs ($n$ represents the input length) are equivalent to $poly(n)$-copy OWSG and to quantum commitments. Since known results show that $o\left(\frac{n}{\log(n)}\right)$-copy OWSG cannot imply commitments, this shows that $O\left(\frac{n}{\log(n)}\right)$-copy OWSGs are the weakest OWSGs from which we can get commitments (and hence much of quantum cryptography).
  Our construction follows along the lines of H\r{a}stad, Impagliazzo, Levin and Luby [HILL], who obtained classical pseudorandom generators (PRG) from classical one-way functions (OWF), however with crucial modifications. Our construction, when applied to the classical case, provides an alternative to the construction provided by [HILL]. Since we do not argue conditioned on the output of the one-way function, our construction and analysis are arguably simpler and may be of independent interest.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.03220v2</guid>
      <category>quant-ph</category>
      <category>cs.CR</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rishabh Batra, Rahul Jain</dc:creator>
    </item>
  </channel>
</rss>
