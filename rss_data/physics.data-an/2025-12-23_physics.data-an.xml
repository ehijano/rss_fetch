<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.data-an updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.data-an</link>
    <description>physics.data-an updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.data-an" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 23 Dec 2025 05:01:03 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Robust and scalable simulation-based inference for gravitational wave signals with gaps</title>
      <link>https://arxiv.org/abs/2512.18290</link>
      <description>arXiv:2512.18290v1 Announce Type: cross 
Abstract: The Laser Interferometer Space Antenna (LISA) data stream will inevitably contain gaps due to maintenance and environmental disturbances, introducing nonstationarities and spectral leakage that compromise standard frequency-domain likelihood evaluations. We present a scalable Simulation-Based Inference (SBI) framework capable of robust parameter estimation directly from gapped time-series data. We employ Flow Matching Posterior Estimation (FMPE) conditioned on a learned summary of the data, optimized through an end-to-end training strategy. To address the computational challenges of long-duration signals, we propose a dual-pathway summarizer architecture: a 1D Convolutional Neural Network (CNN) operating on the time domain for high precision, and a novel wavelet-based 2D CNN utilizing asymmetric, dilated kernels to achieve scalability for datasets spanning months. We demonstrate the efficacy of this framework on simulated Galactic Binary-like signals, showing that our joint training approach yields tighter, unbiased posteriors compared to two-stage reconstruction pipelines. Furthermore, we provide the first systematic comparison showing that FMPE offers superior stability and coverage calibration over conventional Normalizing Flows in the presence of severe data artifacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18290v1</guid>
      <category>astro-ph.IM</category>
      <category>gr-qc</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruiting Mao, Jeong Eun Lee, Matthew C. Edwards</dc:creator>
    </item>
    <item>
      <title>Source quantification by mobile gamma-ray spectrometry systems: A Bayesian approach</title>
      <link>https://arxiv.org/abs/2512.18769</link>
      <description>arXiv:2512.18769v1 Announce Type: cross 
Abstract: Accurately quantifying gamma-ray sources from mobile gamma-ray spectrometry surveys has remained a fundamentally elusive, long-standing inverse problem at the interface of nuclear and computational physics. Here, we present a full-spectrum Bayesian inference framework that resolves this inverse problem by combining high-fidelity, platform-dynamic Monte Carlo template generation with Bayesian inversion. Applying this methodology to airborne measurements benchmarked against laboratory and in-situ ground truths, we demonstrate accurate and robust quantification of both natural and anthropogenic radionuclides under field conditions. By improving activity estimates by an order of magnitude, providing principled uncertainty quantification, and rigorously accounting for overdispersion, this framework opens the way to a more statistically rigorous and physics-informed era of mobile gamma-ray spectrometry, unlocking enhanced inference capabilities in emergency response, environmental monitoring, nuclear security, and planetary exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18769v1</guid>
      <category>physics.ins-det</category>
      <category>physics.app-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>David Breitenmoser, Alberto Stabilini, Malgorzata Magdalena Kasprzak, Sabine Mayer</dc:creator>
    </item>
    <item>
      <title>Needles in a haystack: using forensic network science to uncover insider trading</title>
      <link>https://arxiv.org/abs/2512.18918</link>
      <description>arXiv:2512.18918v1 Announce Type: cross 
Abstract: Although the automation and digitisation of anti-financial crime investigation has made significant progress in recent years, detecting insider trading remains a unique challenge, partly due to the limited availability of labelled data. To address this challenge, we propose using a data-driven networks approach that flags groups of corporate insiders who report coordinated transactions that are indicative of insider trading. Specifically, we leverage data on 2.9 million trades reported to the U.S. Securities and Exchange Commission (SEC) by company insiders (C-suite executives, board members and major shareholders) between 2014 and 2024. Our proposed algorithm constructs weighted edges between insiders based on the temporal similarity of their trades over the 10-year timeframe. Within this network we then uncover trends that indicate insider trading by focusing on central nodes and anomalous subgraphs. To highlight the validity of our approach we evaluate our findings with reference to two null models, generated by running our algorithm on synthetic empirically calibrated and shuffled datasets. The results indicate that our approach can be used to detect pairs or clusters of insiders whose behaviour suggests insider trading and/or market manipulation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.18918v1</guid>
      <category>cs.SI</category>
      <category>physics.data-an</category>
      <category>q-fin.CP</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Gian Jaeger, Wang Ngai Yeung, Renaud Lambiotte</dc:creator>
    </item>
    <item>
      <title>The asymptotic distribution of the likelihood ratio test statistic in two-peak discovery experiments</title>
      <link>https://arxiv.org/abs/2512.19333</link>
      <description>arXiv:2512.19333v1 Announce Type: cross 
Abstract: Likelihood ratio tests are widely used in high-energy physics, where the test statistic is usually assumed to follow a chi-squared distribution with a number of degrees of freedom specified by Wilks' theorem. This assumption breaks down when parameters such as signal or coupling strengths are restricted to be non-negative and their values under the null hypothesis lie on the boundary of the parameter space. Based on a recent clarification concerning the correct asymptotic distribution of the likelihood ratio test statistic for cases where two of the parameters are on the boundary, we revisit the the question of significance estimation for two-peak signal-plus-background counting experiments. In the high-energy physics literature, such experiments are commonly analyzed using Wilks' chi-squared distribution or the one-parameter Chernoff limit. We demonstrate that these approaches can lead to strongly miscalibrated significances, and that the test statistic distribution is instead well described by a chi-squared mixture with weights determined by the Fisher information matrix. Our results highlight the need for boundary-aware asymptotics in the analysis of two-peak counting experiments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19333v1</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <category>stat.AP</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Clara Bertinelli Salucci, Hedvig Borgen Reiersrud, A. L. Read, Anders Kvellestad, Riccardo De Bin</dc:creator>
    </item>
    <item>
      <title>Machine learning for the early classification of broad-lined Ic supernovae</title>
      <link>https://arxiv.org/abs/2512.19386</link>
      <description>arXiv:2512.19386v1 Announce Type: cross 
Abstract: Science is currently at an age where there is more data than we know how to deal with. Machine learning (ML) is an emerging tool that is useful in drawing valuable science out of incomprehensibly large datasets, identifying complex trends in data that are otherwise overlooked. Moreover, ML can potentially enhance the quality and quantity of scientific data as it is collected. This paper explores how a new ML method can improve the rate of classification of rare Ic-BL supernovae (SNe). New parameters called magnitude rates were introduced to train ML models to identify SNe Ic-BL in large datasets. The same methodology was applied to a population of SN Ia transients to see if the methodology could be reproducible with another SN class. Three magnitudes, three time differences, two magnitude rates and the second derivative of these rates were calculated using the first three available photometric data points in a single filter. Initial investigations show that the Random Forest algorithm provides a strong foundation for the early classifications SNe Ic-BL and SNe Ia. Testing this model again on an unseen dataset shows that the model can identify upward of 13% of the total true SN Ic-BL population, significantly improving upon current methods. By implementing a dedicated observation campaign using this model, the number of SN Ic-BL classified and the quality of early-time data collected each year will see considerable growth in the near future.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19386v1</guid>
      <category>astro-ph.HE</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laura Cotter, Antonio Martin Carrillo, Joseph Fisher, Gabriel Finneran, Gregory Corcoran, Jennifer Lebron</dc:creator>
    </item>
    <item>
      <title>Transformer-Based Approach to Enhance Positron Tracking Performance in MEG II</title>
      <link>https://arxiv.org/abs/2512.19482</link>
      <description>arXiv:2512.19482v1 Announce Type: cross 
Abstract: We developed a Transformer-based pattern recognition method for positron track reconstruction in the MEG II experiment. The model acts as a classifier to remove pileup hits in the MEG II drift chamber, which operates under a high pileup occupancy of 35 - 50 %. The trained model significantly improved hit purity, leading to enhancements in tracking efficiency and resolution by 15 % and 5 %, respectively, at a muon stopping rate of $5\times 10^7 \mu$/sec. This improvement translates into an approximately 10 % increase in the sensitivity of the $\mu\to e\gamma$ branching ratio measurement.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.19482v1</guid>
      <category>hep-ex</category>
      <category>physics.data-an</category>
      <category>physics.ins-det</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Lapo Dispoto, Fedor Ignatov, Atsushi Oya, Yusuke Uchiyama, Antoine Venturini</dc:creator>
    </item>
    <item>
      <title>Renormalization group for spectral collapse in random matrices with power-law variance profiles</title>
      <link>https://arxiv.org/abs/2512.13883</link>
      <description>arXiv:2512.13883v2 Announce Type: replace-cross 
Abstract: We propose a renormalization group (RG) approach to compare and collapse eigenvalue densities of random matrix models of complex systems across different system sizes. The approach is to fix a natural spectral scale by letting the model normalization run with size, turning raw spectra into comparable, collapsed density curves. We demonstrate this approach on generalizations of two classic random matrix ensembles--Wigner and Wishart--modified to have power-law variance profiles. We use random matrix theory methods to derive self-consistent fixed-point equations for the resolvent to compute their eigenvalue densities, we define an RG scheme based on matrix decimation, and compute the Beta function controlling the RG flow as a function of the variance profile power-law exponent. The running normalization leads to spectral collapse which we confirm in simulations and solutions of the fixed-point equations. We expect this RG approach to carry over to other ensembles, providing a method for data analysis of a broad range of complex systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2512.13883v2</guid>
      <category>cond-mat.stat-mech</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 23 Dec 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Philipp Fleig</dc:creator>
    </item>
  </channel>
</rss>
