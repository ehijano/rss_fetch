<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>q-bio.NC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/q-bio.NC</link>
    <description>q-bio.NC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/q-bio.NC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 05 Nov 2024 05:00:40 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>The Dynamics of Triple Interactions in Resting fMRI: Insights into Psychotic Disorders</title>
      <link>https://arxiv.org/abs/2411.00982</link>
      <description>arXiv:2411.00982v1 Announce Type: new 
Abstract: The human brain dynamically integrated and configured information to adapt to the environment. To capture these changes over time, dynamic second-order functional connectivity was typically used to capture transient brain patterns. However, dynamic second-order functional connectivity typically ignored interactions beyond pairwise relationships. To address this limitation, we utilized dynamic triple interactions to investigate multiscale network interactions in the brain. In this study, we evaluated a resting-state fMRI dataset that included individuals with psychotic disorders (PD). We first estimated dynamic triple interactions using resting-state fMRI. After clustering, we estimated cohort-specific and cohort-common states for controls (CN), schizophrenia (SZ), and schizoaffective disorder (SAD). From the cohort-specific states, we observed significant triple interactions, particularly among visual, subcortical, and somatomotor networks, as well as temporal and higher cognitive networks in SZ. In SAD, key interactions involved temporal networks in the initial state and somatomotor networks in subsequent states. From the cohort-common states, we observed that high-cognitive networks were primarily involved in SZ and SAD compared to CN. Furthermore, the most significant differences between SZ and SAD also existed in high-cognitive networks. In summary, we studied PD using dynamic triple interaction, the first time such an approach has been used to study PD. Our findings highlighted the significant potential of dynamic high-order functional connectivity, paving the way for new avenues in the study of the healthy and disordered human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00982v1</guid>
      <category>q-bio.NC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Vince D. Calhoun, Armin Iraji</dc:creator>
    </item>
    <item>
      <title>Correlation of Correlation Networks: High-Order Interactions in the Topology of Brain Networks</title>
      <link>https://arxiv.org/abs/2411.00992</link>
      <description>arXiv:2411.00992v1 Announce Type: new 
Abstract: To understand collective network behavior in the complex human brain, pairwise correlation networks alone are insufficient for capturing the high-order interactions that extend beyond pairwise interactions and play a crucial role in brain network dynamics. These interactions often reveal intricate relationships among multiple brain networks, significantly influencing cognitive processes. In this study, we explored the correlation of correlation networks and topological network analysis with resting-state fMRI to gain deeper insights into these higher-order interactions and their impact on the topology of brain networks, ultimately enhancing our understanding of brain function. We observed that the correlation of correlation networks highlighted network connections while preserving the topological structure of correlation networks. Our findings suggested that the correlation of correlation networks surpassed traditional correlation networks, showcasing considerable potential for applications in various areas of network science. Moreover, after applying topological network analysis to the correlation of correlation networks, we observed that some high-order interaction hubs predominantly occurred in primary and high-level cognitive areas, such as the visual and fronto-parietal regions. These high-order hubs played a crucial role in information integration within the human brain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00992v1</guid>
      <category>q-bio.NC</category>
      <category>stat.CO</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Qiang Li, Jingyu Liu, Vince D. Calhoun</dc:creator>
    </item>
    <item>
      <title>Why Does the Cortex Have Such a Vast Storage Capacity?</title>
      <link>https://arxiv.org/abs/2411.01164</link>
      <description>arXiv:2411.01164v1 Announce Type: new 
Abstract: The capacity of long-term memory seems to be extremely large, capable of storing information spanning almost a lifetime. Why does it have such a vast capacity? Why are some memories so enduring? What is the actual physical form of long-term memory? In the movie Inside Out, it is depicted as individual orbs containing information. Is that really the case? Simply explaining this by saying that the cortex has many neurons, numerous neural connections, and complex electrochemical activity between them is not sufficient to answer these fundamental questions. We need to uncover the theory hidden behind these phenomena.In essence, a neural network is equivalent to a very large directed graph, with a massive number of nodes and directed connections. This paper posits that the physical form of long-term memory is a connected subgraph within this complex directed graph. This subgraph is capable of linking together the disparate fragments of the same event, spread across different sensory cortices, to form associations. This provides a physical realization of the engram theory. The robustness of the connected subgraph and the resources it consumes can explain various memory behaviors.Based on anatomical, brain imaging and electrophysiological evidence, this paper constructs a probabilistic connectivity model and uses theorems from graph theory to prove the ease of constructing connected subgraphs. Finally, it explains why the potential capacity for memory is immense.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01164v1</guid>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Hui Wei, Surun Yang, Yangwang Li</dc:creator>
    </item>
    <item>
      <title>Are EEG functional networks really describing the brain? A comparison with other information-processing complex systems</title>
      <link>https://arxiv.org/abs/2411.01522</link>
      <description>arXiv:2411.01522v1 Announce Type: new 
Abstract: Functional networks representing human brain dynamics have become a standard tool in neuroscience, providing an accessible way of depicting the computation performed by the brain in healthy and pathological conditions. Yet, these networks share multiple characteristics with those representing other natural and man-made complex systems, leading to the question of whether they are actually capturing the uniqueness of the human brain. By resorting to a large set of data representing multiple financial, technological, social, and natural complex systems, and by relying on Deep Learning classification models, we show how they are highly similar. We specifically reach the conclusion that, under some general reconstruction methodological choices, it is as difficult to understand whether a network represents a human brain or a financial market, as to diagnose a major pathology. This suggests that functional networks are describing information processing mechanisms that are common across complex systems; but that are not currently defining the uniqueness of the human mind. We discuss the consequence of these findings for neuroscience and complexity science in general, and suggest future avenues for exploring this interesting topic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01522v1</guid>
      <category>q-bio.NC</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Sofia Gil-Rodrigo, Ra\'ul L\'opez-Mart\'in, G\"orsev Yener, Jan R. Wiersema, Bahar G\"untekin, Massimiliano Zanin</dc:creator>
    </item>
    <item>
      <title>Topology-Aware Graph Augmentation for Predicting Clinical Trajectories in Neurocognitive Disorders</title>
      <link>https://arxiv.org/abs/2411.00888</link>
      <description>arXiv:2411.00888v1 Announce Type: cross 
Abstract: Brain networks/graphs derived from resting-state functional MRI (fMRI) help study underlying pathophysiology of neurocognitive disorders by measuring neuronal activities in the brain. Some studies utilize learning-based methods for brain network analysis, but typically suffer from low model generalizability caused by scarce labeled fMRI data. As a notable self-supervised strategy, graph contrastive learning helps leverage auxiliary unlabeled data. But existing methods generally arbitrarily perturb graph nodes/edges to generate augmented graphs, without considering essential topology information of brain networks. To this end, we propose a topology-aware graph augmentation (TGA) framework, comprising a pretext model to train a generalizable encoder on large-scale unlabeled fMRI cohorts and a task-specific model to perform downstream tasks on a small target dataset. In the pretext model, we design two novel topology-aware graph augmentation strategies: (1) hub-preserving node dropping that prioritizes preserving brain hub regions according to node importance, and (2) weight-dependent edge removing that focuses on keeping important functional connectivities based on edge weights. Experiments on 1, 688 fMRI scans suggest that TGA outperforms several state-of-the-art methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00888v1</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Qianqian Wang, Wei Wang, Yuqi Fang, Hong-Jun Li, Andrea Bozoki, Mingxia Liu</dc:creator>
    </item>
    <item>
      <title>Taking AI Welfare Seriously</title>
      <link>https://arxiv.org/abs/2411.00986</link>
      <description>arXiv:2411.00986v1 Announce Type: cross 
Abstract: In this report, we argue that there is a realistic possibility that some AI systems will be conscious and/or robustly agentic in the near future. That means that the prospect of AI welfare and moral patienthood, i.e. of AI systems with their own interests and moral significance, is no longer an issue only for sci-fi or the distant future. It is an issue for the near future, and AI companies and other actors have a responsibility to start taking it seriously. We also recommend three early steps that AI companies and other actors can take: They can (1) acknowledge that AI welfare is an important and difficult issue (and ensure that language model outputs do the same), (2) start assessing AI systems for evidence of consciousness and robust agency, and (3) prepare policies and procedures for treating AI systems with an appropriate level of moral concern. To be clear, our argument in this report is not that AI systems definitely are, or will be, conscious, robustly agentic, or otherwise morally significant. Instead, our argument is that there is substantial uncertainty about these possibilities, and so we need to improve our understanding of AI welfare and our ability to make wise decisions about this issue. Otherwise there is a significant risk that we will mishandle decisions about AI welfare, mistakenly harming AI systems that matter morally and/or mistakenly caring for AI systems that do not.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.00986v1</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Long, Jeff Sebo, Patrick Butlin, Kathleen Finlinson, Kyle Fish, Jacqueline Harding, Jacob Pfau, Toni Sims, Jonathan Birch, David Chalmers</dc:creator>
    </item>
    <item>
      <title>Cost efficiency of fMRI studies using resting-state vs task-based functional connectivity</title>
      <link>https://arxiv.org/abs/2411.01092</link>
      <description>arXiv:2411.01092v1 Announce Type: cross 
Abstract: We investigate whether and how we can improve the cost efficiency of neuroimaging studies with well-tailored fMRI tasks. The comparative study is conducted using a novel network science-driven Bayesian connectome-based predictive method, which incorporates network theories in model building and substantially improves precision and robustness in imaging biomarker detection. The robustness of the method lays the foundation for identifying predictive power differential across fMRI task conditions if such difference exists. When applied to a clinically heterogeneous transdiagnostic cohort, we found shared and distinct functional fingerprints of neuropsychological outcomes across seven fMRI conditions. For example, emotional N-back memory task was found to be less optimal for negative emotion outcomes, and gradual-onset continuous performance task was found to have stronger links with sensitivity and sociability outcomes than with cognitive control outcomes. Together, our results show that there are unique optimal pairings of task-based fMRI conditions and neuropsychological outcomes that should not be ignored when designing well-powered neuroimaging studies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2411.01092v1</guid>
      <category>stat.AP</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xinzhi Zhang, Leslie A Hulvershorn, Todd Constable, Yize Zhao, Selena Wang</dc:creator>
    </item>
    <item>
      <title>Where are the bits in atoms? A perspective on the physical origin and evolutionary nature of information</title>
      <link>https://arxiv.org/abs/2407.09567</link>
      <description>arXiv:2407.09567v3 Announce Type: replace 
Abstract: Information is a structural pattern that represents another structural pattern. This perspective hypothesizes that modelling of structure creation through causal sets can elucidate the natural origin, evolution and ontology of information.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.09567v3</guid>
      <category>q-bio.NC</category>
      <category>cs.IT</category>
      <category>math.IT</category>
      <category>physics.hist-ph</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wouter van der Wijngaart</dc:creator>
    </item>
    <item>
      <title>BG-GAN: Generative AI Enables Representing Brain Structure-Function Connections for Alzheimer's Disease</title>
      <link>https://arxiv.org/abs/2309.08916</link>
      <description>arXiv:2309.08916v3 Announce Type: replace-cross 
Abstract: The relationship between brain structure and function is critical for revealing the pathogenesis of brain disease, including Alzheimer's disease (AD). However, it is a great challenge to map brain structure-function connections due to various reasons. In this work, a bidirectional graph generative adversarial networks (BG-GAN) is proposed to represent brain structure-function connections. Specifically, by designing a module incorporating inner graph convolution network (InnerGCN), the generators of BG-GAN can employ features of direct and indirect brain regions to learn the mapping function between structural domain and functional domain. Besides, a new module named Balancer is designed to counterpoise the optimization between generators and discriminators. By introducing the Balancer into BG-GAN, both the structural generator and functional generator can not only alleviate the issue of mode collapse but also learn complementarity of structural and functional features. Experimental results using ADNI datasets show that the both the generated structure connections and generated function connections can improve the identification accuracy of AD. More importantly, based the proposed model, it is found that the relationship between brain structure and function is not a complete one-to-one correspondence. Brain structure is the basis of brain function. The strong structural connections are almost accompanied by strong functional connections.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08916v3</guid>
      <category>cs.AI</category>
      <category>eess.IV</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changhong Jing, Chen Ding, Shuqiang Wang</dc:creator>
    </item>
    <item>
      <title>fMRI predictors based on language models of increasing complexity recover brain left lateralization</title>
      <link>https://arxiv.org/abs/2405.17992</link>
      <description>arXiv:2405.17992v2 Announce Type: replace-cross 
Abstract: Over the past decade, studies of naturalistic language processing where participants are scanned while listening to continuous text have flourished. Using word embeddings at first, then large language models, researchers have created encoding models to analyze the brain signals. Presenting these models with the same text as the participants allows to identify brain areas where there is a significant correlation between the functional magnetic resonance imaging (fMRI) time series and the ones predicted by the models' artificial neurons. One intriguing finding from these studies is that they have revealed highly symmetric bilateral activation patterns, somewhat at odds with the well-known left lateralization of language processing. Here, we report analyses of an fMRI dataset where we manipulate the complexity of large language models, testing 28 pretrained models from 8 different families, ranging from 124M to 14.2B parameters. First, we observe that the performance of models in predicting brain responses follows a scaling law, where the fit with brain activity increases linearly with the logarithm of the number of parameters of the model (and its performance on natural language processing tasks). Second, although this effect is present in both hemispheres, it is stronger in the left than in the right hemisphere. Specifically, the left-right difference in brain correlation follows a scaling law with the number of parameters. This finding reconciles computational analyses of brain activity using large language models with the classic observation from aphasic patients showing left hemisphere dominance for language.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17992v2</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Laurent Bonnasse-Gahot, Christophe Pallier</dc:creator>
    </item>
    <item>
      <title>Inferring stochastic low-rank recurrent neural networks from neural data</title>
      <link>https://arxiv.org/abs/2406.16749</link>
      <description>arXiv:2406.16749v2 Announce Type: replace-cross 
Abstract: A central aim in computational neuroscience is to relate the activity of large populations of neurons to an underlying dynamical system. Models of these neural dynamics should ideally be both interpretable and fit the observed data well. Low-rank recurrent neural networks (RNNs) exhibit such interpretability by having tractable dynamics. However, it is unclear how to best fit low-rank RNNs to data consisting of noisy observations of an underlying stochastic system. Here, we propose to fit stochastic low-rank RNNs with variational sequential Monte Carlo methods. We validate our method on several datasets consisting of both continuous and spiking neural data, where we obtain lower dimensional latent dynamics than current state of the art methods. Additionally, for low-rank models with piecewise linear nonlinearities, we show how to efficiently identify all fixed points in polynomial rather than exponential cost in the number of units, making analysis of the inferred dynamics tractable for large RNNs. Our method both elucidates the dynamical systems underlying experimental recordings and provides a generative model whose trajectories match observed variability.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.16749v2</guid>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <category>stat.ML</category>
      <pubDate>Tue, 05 Nov 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:journal_reference>The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS) 2024</arxiv:journal_reference>
      <dc:creator>Matthijs Pals, A Erdem Sa\u{g}tekin, Felix Pei, Manuel Gloeckler, Jakob H Macke</dc:creator>
    </item>
  </channel>
</rss>
