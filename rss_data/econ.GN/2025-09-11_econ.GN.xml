<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.GN updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.GN</link>
    <description>econ.GN updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.GN" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 12 Sep 2025 04:00:47 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Specialization, Complexity &amp; Resilience in Supply Chains</title>
      <link>https://arxiv.org/abs/2509.08981</link>
      <description>arXiv:2509.08981v1 Announce Type: new 
Abstract: Despite growing policy interest, the determinants of supply chain resilience are still not well understood. We propose a new theory of supply chain formation with compatibility frictions: only compatible inputs can be used in final good production. Intermediate producers choose the degree of specialization of their goods, trading off higher productivity against a lower share of compatible final producers. We model supply chains as complex production processes in which multiple complementary inputs must be sourced for final production to take place. Specialization choices, production complexity, and search frictions jointly determine supply chain resilience. Relative to the efficient allocation, the equilibrium is characterized by over-specialization due to a novel network externality arising from the interplay between frictional markets, endogenous specialization, and complex production. Over-specialization makes supply chains more productive in normal times but less resilient to disruptions than socially desirable. We show how a targeted transaction subsidy can decentralize efficient resilience in supply chains, and examine the implications of setting compatibility standards.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.08981v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessandro Ferrari, Lorenzo Pesaresi</dc:creator>
    </item>
    <item>
      <title>Rethinking Cost-Sharing Policies: Enhancing Chronic Disease Management for Disadvantaged Populations</title>
      <link>https://arxiv.org/abs/2509.09223</link>
      <description>arXiv:2509.09223v1 Announce Type: new 
Abstract: The increasing prevalence of chronic diseases poses a significant challenge to global efforts to alleviate poverty, promote health equity, and control healthcare costs. This study adopts a structural approach to explore how patients manage chronic diseases by making trade-offs between inpatient care and ambulatory care outpatient services. Specifically, it investigates whether disadvantaged populations make distinct trade-offs compared to the general population and examines the impact of anti-poverty programs that reduce inpatient cost-sharing.
  Using health insurance claims data from a rural county in China, the study reveals that disadvantaged individuals tend to avoid ambulatory care unless it substantially lowers medical expenses. In contrast, the general population is more likely to prioritize ambulatory care, even at higher costs, to prevent disease progression. The findings also indicate that current anti-poverty insurance policies, which focus predominantly on hospitalization, inadvertently decrease ambulatory care usage by 23\%, resulting in increased healthcare costs and a 46.2\% decline in patient welfare. Counterfactual analysis suggests that reducing cost-sharing for ambulatory care would be a more cost-effective strategy for improving health outcomes and supporting disadvantaged populations than providing travel subsidies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09223v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jia Dan, Xu Pai</dc:creator>
    </item>
    <item>
      <title>Ancestral origins of attention to environmental issues</title>
      <link>https://arxiv.org/abs/2509.09598</link>
      <description>arXiv:2509.09598v1 Announce Type: new 
Abstract: How does the climatic experience of previous generations affect today's attention to environmental questions? Using self-reported beliefs and environmental themes in folklore, we show empirically that the realized intensity of deviations from typical climate conditions in ancestral generations influences how much descendants care about the environment. The effect exhibits a U-shape where more stable and more unstable ancestral climates lead to higher attention today, with a dip for intermediate realizations. We propose a theoretical framework where the value of costly attention to environmental conditions depends on the perceived stability of the environment, prior beliefs about which are shaped through cultural transmission by the experience of ethnic ancestors. The U-shape is rationalized by a double purpose of learning about the environment: optimal utilization of typical conditions and protection against extreme events.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.09598v1</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C\'esar Barilla, Palaash Bhargava</dc:creator>
    </item>
    <item>
      <title>Algorithmic Collusion by Large Language Models</title>
      <link>https://arxiv.org/abs/2404.00806</link>
      <description>arXiv:2404.00806v4 Announce Type: replace 
Abstract: The rise of algorithmic pricing raises concerns of algorithmic collusion. We conduct experiments with algorithmic pricing agents based on Large Language Models (LLMs). We find that LLM-based pricing agents quickly and autonomously reach supracompetitive prices and profits in oligopoly settings and that variation in seemingly innocuous phrases in LLM instructions ("prompts") may substantially influence the degree of supracompetitive pricing. Off-path analysis using novel techniques uncovers price-war concerns as contributing to these phenomena. Our results extend to auction settings. Our findings uncover unique challenges to any future regulation of LLM-based pricing agents, and AI-based pricing agents more broadly.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.00806v4</guid>
      <category>econ.GN</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Sara Fish, Yannai A. Gonczarowski, Ran I. Shorrer</dc:creator>
    </item>
    <item>
      <title>Generative AI at the Crossroads: Light Bulb, Dynamo, or Microscope?</title>
      <link>https://arxiv.org/abs/2505.14588</link>
      <description>arXiv:2505.14588v4 Announce Type: replace 
Abstract: With the advent of generative AI (genAI), the potential scope of artificial intelligence has increased dramatically, but the future effect of genAI on productivity remains uncertain. The effect of the technology on the innovation process is a crucial open question. Some inventions, such as the light bulb, temporarily raise productivity growth as adoption spreads, but the effect fades when the market is saturated; that is, the level of output per hour is permanently higher but the growth rate is not. In contrast, two types of technologies stand out as having longer-lived effects on productivity growth. First, there are technologies known as general-purpose technologies (GPTs). GPTs (1) are widely adopted, (2) spur abundant knock-on innovations (new goods and services, process efficiencies, and business reorganization), and (3) show continual improvement, refreshing this innovation cycle; the electric dynamo is an example. Second, there are inventions of methods of invention (IMIs). IMIs increase the efficiency of the research and development process via improvements to observation, analysis, communication, or organization; the compound microscope is an example. We show that GenAI has the characteristics of both a GPT and an IMI -- an encouraging sign that genAI will raise the \textit{level} of productivity. Even so, genAI's contribution to productivity \textit{growth} will depend on the speed with which that level is attained and, historically, integrating revolutionary technologies into the economy is a protracted process.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.14588v4</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Martin Baily, David Byrne, Aidan Kane, Paul Soto</dc:creator>
    </item>
    <item>
      <title>Predicting Qualification Thresholds in UEFA's incomplete round-robin tournaments</title>
      <link>https://arxiv.org/abs/2508.20075</link>
      <description>arXiv:2508.20075v2 Announce Type: replace 
Abstract: For the 2024/25 season, the Union of European Football Associations (UEFA) introduced an incomplete round-robin format in the Champions League, Europa League, and Conference League, replacing the traditional group stage with a single league table of all 36 teams. Under this structure, the top eight teams advance directly to the round of 16, while those ranked 9th-24th compete in a play-off round. Simulation-based analyses, such as those by commercial data analyst Opta, provide indicative point thresholds for qualification but reveal deviations when compared with actual outcomes in the first season. To overcome these discrepancies, we employ a bivariate Dixon-Coles model that accounts for the lower frequency of draws observed in the 2024/25 UCL season, with team strengths proxied by Elo ratings. This framework enables the simulation of match outcomes and the estimation of qualification thresholds for both direct advancement and play-off participation. Our results provide scientific guidance for clubs and managers, supporting strategic decision-making under uncertainty regarding their progression prospects in the new UEFA club competition formats.</description>
      <guid isPermaLink="false">oai:arXiv.org:2508.20075v2</guid>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Winkelmann, Rouven Michels, Christian Deutscher</dc:creator>
    </item>
    <item>
      <title>DeepVoting: Learning and Fine-Tuning Voting Rules with Canonical Embeddings</title>
      <link>https://arxiv.org/abs/2408.13630</link>
      <description>arXiv:2408.13630v2 Announce Type: replace-cross 
Abstract: Aggregating agent preferences into a collective decision is an important step in many problems (e.g., hiring, elections, peer review) and across areas of computer science (e.g., reinforcement learning, recommender systems). As Social Choice Theory has shown, the problem of designing aggregation rules with specific sets of properties (axioms) can be difficult, or provably impossible in some cases. Instead of designing algorithms by hand, one can learn aggregation rules, particularly voting rules, from data. However, prior work in this area has required extremely large models or been limited by the choice of preference representation, i.e., embedding. We recast the problem of designing voting rules with desirable properties into one of learning probabilistic functions that output distributions over a set of candidates. Specifically, we use neural networks to learn probabilistic social choice functions. Using standard embeddings from the social choice literature we show that preference profile encoding has significant impact on the efficiency and ability of neural networks to learn rules, allowing us to learn rules faster and with smaller networks than previous work. Moreover, we show that our learned rules can be fine-tuned using axiomatic properties to create novel voting rules and make them resistant to specific types of "attack". Namely, we fine-tune rules to resist a probabilistic version of the No Show Paradox.</description>
      <guid isPermaLink="false">oai:arXiv.org:2408.13630v2</guid>
      <category>cs.MA</category>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.LG</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <pubDate>Fri, 12 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Leonardo Matone, Ben Abramowitz, Ben Armstrong, Avinash Balakrishnan, Nicholas Mattei</dc:creator>
    </item>
  </channel>
</rss>
