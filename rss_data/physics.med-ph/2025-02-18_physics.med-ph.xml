<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.med-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.med-ph</link>
    <description>physics.med-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.med-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 18 Feb 2025 05:01:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>3D printed human skull phantoms for transcranial photoacoustic imaging</title>
      <link>https://arxiv.org/abs/2502.10910</link>
      <description>arXiv:2502.10910v1 Announce Type: new 
Abstract: Photoacoustic (PA) waves are strongly distorted and attenuated in skull bone. To study these effects on PA imaging, we designed and 3D-printed tissue-mimicking phantoms of human skull. We present a comparison of results in phantom and ex vivo skull.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10910v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hannah Linde, Saskia Menzer, Jan Laufer, Thomas Kirchner</dc:creator>
    </item>
    <item>
      <title>DLBayesian: An Alternative Bayesian Reconstruction of Limited-view CT by Optimizing Deep Learning Parameters</title>
      <link>https://arxiv.org/abs/2502.11156</link>
      <description>arXiv:2502.11156v1 Announce Type: new 
Abstract: Limited-view computed tomography (CT) presents significant potential for reducing radiation exposure and expediting the scanning process. While deep learning (DL) methods have exhibited promising results in mitigating streaking artifacts caused by a reduced number of projection views, their generalization remains challenging. In this work, we proposed a DL-driven alternative Bayesian reconstruction method (DLBayesian) that efficiently integrates data-driven priors and data consistency constraints. DLBayesian comprises three stages: group-level embedding, significance evaluation, and individual-level consistency adaptation. Firstly, DL network parameters are optimized to learn how to eliminate the general limited-view artifacts on a large-scale paired dataset. Then, we introduced a significance score to quantitatively evaluate the contribution of parameters in DL models as a guide for the subsequent individual-level adaptation. Finally, in the Bayesian adaptation stage, an alternative Bayesian reconstruction further optimizes the DL network parameters precisely according to the projection data of the target case. We validated DLBayesian with sparse-view (90 views) projections from a circular trajectory CT and a special data missing case from a multi-segment linear trajectory CT. The results underscore DLBayesian's superior generalization capabilities across variations in patients, anatomic structures, and data distribution, as well as excelling in contextual structure recovery compared to networks solely trained via supervised loss. Real experiments on a dead rat demonstrate its capability in practical CT scans.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11156v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Changyu Chen, Li Zhang, Yuxiang Xing, Zhiqiang Chen</dc:creator>
    </item>
    <item>
      <title>Design and Fabrication of Low Cost Cardiopulmonary Resuscitaion Device | A Novel Mechatronics System</title>
      <link>https://arxiv.org/abs/2502.11171</link>
      <description>arXiv:2502.11171v1 Announce Type: new 
Abstract: Cardiac arrest is very common nowadays. Sudden heart attack is a condition where the heart suddenly stops beating causing a significant decrease in blood flow to the brain. The first step in medical point of view is for a patient experiencing sudden heart attack is Cardiopulmonary Resuscitation (CPR).Moreover, compression rate needed for CPR process is far beyond for humans to provide manually. So, there is intense need of mechanical device which can perform resuscitation. Cardiopulmonary resuscitation device is used to augment the blood flow and maintain hemodynamic cycle of human body. CPR device is proposed to meet the effective and unique blood flow mechanism, feedback system. In term of effective and unique blood flow mechanism design and fabrication of low cost cardiopulmonary resuscitation device based on principle of CPR and two concepts. It is combined Sterno-Thoracic Cardiopulmonary Resuscitation. The "cardiac pump" generates blood flow by squeezing blood out of the heart as the sternum is depressed. The "thoracic pump" increases intrathoracic pressure due to elastic recoil of ribs. In order to meet the American Heart Association standard guidelines a feedback system has established through closed loop control system, and integration of processing controllers. Specifically, a small HMI (Human machine interface) device has been established to control the whole mechanism which would be used for child, Adults and Senior citizens as a manual intelligence system. Henceforth, feedback system act as backbone for this device.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11171v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Nabeel Ahmad Khan Jadoon</dc:creator>
    </item>
    <item>
      <title>Exploiting network optimization stability for enhanced PET image denoising using deep image prior</title>
      <link>https://arxiv.org/abs/2502.11259</link>
      <description>arXiv:2502.11259v1 Announce Type: new 
Abstract: PET is affected by statistical noise due to constraints on tracer dose and scan duration, impacting both diagnostic performance and quantitative accuracy. While deep learning (DL)-based PET denoising methods have been used to improve image quality, they may introduce over-smoothing, compromising quantitative accuracy. We propose a method for making a DL solution more reliable and apply it to the conditional deep image prior (DIP). We introduce the idea of stability information in the optimization process of conditional DIP, enabling the identification of unstable regions within the network's optimization trajectory. Our method incorporates a stability map, which is derived from multiple intermediate outputs of moderate network at different optimization steps. The final denoised image is then obtained by computing linear combination of the DIP output and the original reconstructed image, weighted by the stability map. Our method effectively reduces noise while preserving small structure details in brain FDG images. Results demonstrated that our approach outperformed existing methods in peak-to-valley ratio and noise suppression across various low-dose levels. Region-of-interest analysis confirmed that the proposed method maintains quantitative accuracy without introducing under- or over-estimation. We applied our method to full-dose PET data to assess its impact on image quality. The results revealed that the proposed method significantly reduced background noise while preserving the peak-to-valley ratio at a level comparable to that of unfiltered full-dose PET images. The proposed method introduces a robust approach to DL-based PET denoising, enhancing its reliability and preserving quantitative accuracy. This strategy has the potential to advance performance in high-sensitivity PET scanners, demonstrating that DL can extend PET imaging capabilities beyond low-dose applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11259v1</guid>
      <category>physics.med-ph</category>
      <category>cs.CV</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Fumio Hashimoto, Kibo Ote, Yuya Onishi, Hideaki Tashima, Go Akamatsu, Yuma Iwao, Miwako Takahashi, Taiga Yamaya</dc:creator>
    </item>
    <item>
      <title>Evaluation of the uncertainty in calculating nanodosimetric quantities due to the use of different interaction cross sections in Monte Carlo track structure codes</title>
      <link>https://arxiv.org/abs/2502.11991</link>
      <description>arXiv:2502.11991v1 Announce Type: new 
Abstract: This study evaluates the uncertainty in nanodosimetric calculations caused by variations in interaction cross sections within Monte Carlo Track Structure (MCTS) simulation codes. Nanodosimetry relies on accurately simulating particle interactions at the molecular scale. Different MCTS codes employ distinct physical models and datasets for electron interactions in liquid water, a surrogate for biological tissues. The paper focuses on the Ionization Cluster Size Distribution (ICSD) generated by electrons of varying energies in nanometric volumes. Seven MCTS codes were tested using their native cross sections and a common dataset derived from averaging data used in the participating codes. The results reveal significant discrepancies among the codes in ICSDs and derived biologically relevant nanodosimetric quantities such as mean ionization numbers (M1) and probabilities of obtaining two or more ionizations (F2). The largest variations were observed for low-energy electrons, where the contribution from interaction cross sections dominates the overall uncertainties. For instance, M1 values for ICSDs of electron of 20 eV can differ by around 45 % (RSD) and 34 % (RSD) was found for F2 values of ICSDs of electrons of 50 eV. Using common cross sections substantially reduced the discrepancies, suggesting that cross section datasets are the primary source of variability. Finally, estimates of deoxyribonucleic acid (DNA) damage using the PARTRAC code highlight tht cross section variations have a non-negligible impact simulated biological outcomes, particularly for double-strand breaks (DSBs) Indeed, despite the fact that many other parameters in the simulation that can greatly differ from one code to another, the different interaction cross-sections studied in this work can lead to differences in the number of DSBs calculated with the PARTRAC code of up to 15%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11991v1</guid>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carmen Villagrasa, Giorgio Baiocco, Zine-El-Abidine Chaoui, Michael Dingfelder, S\'ebastien Incerti, Pavel Kundr\'at, Ioanna Kyriakou, Yusuke Matsuya, Takeshi Kai, Alessio Paris, Yann Perrot, Marcin Pietrzak, Jan Schuemann, Hans Rabus</dc:creator>
    </item>
    <item>
      <title>Accelerating Quantitative MRI using Subspace Multiscale Energy Model (SS-MuSE)</title>
      <link>https://arxiv.org/abs/2502.10580</link>
      <description>arXiv:2502.10580v1 Announce Type: cross 
Abstract: Multi-contrast MRI methods acquire multiple images with different contrast weightings, which are used for the differentiation of the tissue types or quantitative mapping. However, the scan time needed to acquire multiple contrasts is prohibitively long for 3D acquisition schemes, which can offer isotropic image resolution. While deep learning-based methods have been extensively used to accelerate 2D and 2D + time problems, the high memory demand, computation time, and need for large training data sets make them challenging for large-scale volumes. To address these challenges, we generalize the plug-and-play multi-scale energy-based model (MuSE) to a regularized subspace recovery setting, where we jointly regularize the 3D multi-contrast spatial factors in a subspace formulation. The explicit energy-based formulation allows us to use variable splitting optimization methods for computationally efficient recovery.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10580v1</guid>
      <category>eess.IV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Yan Chen, Jyothi Rikhab Chand, Steven R. Kecskemeti, James H. Holmes, Mathews Jacob</dc:creator>
    </item>
    <item>
      <title>Hard X-ray/Soft gamma-ray Laue Lenses for High Energy Astrophysics</title>
      <link>https://arxiv.org/abs/2502.10845</link>
      <description>arXiv:2502.10845v1 Announce Type: cross 
Abstract: The study of the celestial phenomena in the hard X-ray/soft gamma-ray band(20 keV--1 MeV) is very intriguing but also very difficult to be performed with the needed sensitivity. In this review I will discuss the astrophysical importance of the soft gamma-ray astronomy, its difficulties to solve its issues with the current instrumentation, and a possible solution achievable using focusing Laue lens. Concerning these instruments, I will discuss their functioning principle, how to achieve a high reflection efficiency, their imaging properties, the current feasibility studies, the technological developments and observation prospects.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.10845v1</guid>
      <category>astro-ph.IM</category>
      <category>hep-ex</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:journal_reference>A chapter of the 3rd edition of the Springer Nature book "Observing Photons in Space - A Guide to Experimental Space Astronomy", 2025</arxiv:journal_reference>
      <dc:creator>Filippo Frontera</dc:creator>
    </item>
    <item>
      <title>Towards Automatic Identification of Missing Tissues using a Geometric-Learning Correspondence Model</title>
      <link>https://arxiv.org/abs/2502.11265</link>
      <description>arXiv:2502.11265v1 Announce Type: cross 
Abstract: Missing tissue presents a big challenge for dose mapping, e.g., in the reirradiation setting. We propose a pipeline to identify missing tissue on intra-patient structure meshes using a previously trained geometric-learning correspondence model. For our application, we relied on the prediction discrepancies between forward and backward correspondences of the input meshes, quantified using a correspondence-based Inverse Consistency Error (cICE). We optimised the threshold applied to cICE to identify missing points in a dataset of 35 simulated mandible resections. Our identified threshold, 5.5 mm, produced a balanced accuracy score of 0.883 in the training data, using an ensemble approach. This pipeline produced plausible results for a real case where ~25% of the mandible was removed after a surgical intervention. The pipeline, however, failed on a more extreme case where ~50% of the mandible was removed. This is the first time geometric-learning modelling is proposed to identify missing points in corresponding anatomy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2502.11265v1</guid>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Eliana M. Vasquez Osorio, Edward Henderson</dc:creator>
    </item>
    <item>
      <title>On undesired emergent behaviors in compound prostate cancer detection systems</title>
      <link>https://arxiv.org/abs/2309.08381</link>
      <description>arXiv:2309.08381v2 Announce Type: replace-cross 
Abstract: Artificial intelligence systems show promise to aid in the di- agnostic pathway of prostate cancer (PC), by supporting radiologists in interpreting magnetic resonance images (MRI) of the prostate. Most MRI-based systems are designed to detect clinically significant PC le- sions, with the main objective of preventing over-diagnosis. Typically, these systems involve an automatic prostate segmentation component and a clinically significant PC lesion detection component. In spite of the compound nature of the systems, evaluations are presented assum- ing a standalone clinically significant PC detection component. That is, they are evaluated in an idealized scenario and under the assumption that a highly accurate prostate segmentation is available at test time. In this work, we aim to evaluate a clinically significant PC lesion de- tection system accounting for its compound nature. For that purpose, we simulate a realistic deployment scenario and evaluate the effect of two non-ideal and previously validated prostate segmentation modules on the PC detection ability of the compound system. Following, we com- pare them with an idealized setting, where prostate segmentations are assumed to have no faults. We observe significant differences in the de- tection ability of the compound system in a realistic scenario and in the presence of the highest-performing prostate segmentation module (DSC: 90.07+-0.74), when compared to the idealized one (AUC: 77.93 +- 3.06 and 84.30+- 4.07, P&lt;.001). Our results depict the relevance of holistic evalu- ations for PC detection compound systems, where interactions between system components can lead to decreased performance and degradation at deployment time.</description>
      <guid isPermaLink="false">oai:arXiv.org:2309.08381v2</guid>
      <category>eess.IV</category>
      <category>cs.CV</category>
      <category>physics.med-ph</category>
      <pubDate>Tue, 18 Feb 2025 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1007/978-3-031-73376-5_7</arxiv:DOI>
      <dc:creator>Erlend Sortland Rolfsnes, Philip Thangngat, Trygve Eftest{\o}l, Tobias Nordstr\"om, Fredrik J\"aderling, Martin Eklund, Alvaro Fernandez-Quilez</dc:creator>
    </item>
  </channel>
</rss>
