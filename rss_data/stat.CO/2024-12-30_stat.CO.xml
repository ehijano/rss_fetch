<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>stat.CO updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/stat.CO</link>
    <description>stat.CO updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/stat.CO" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 31 Dec 2024 03:23:55 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>High-accuracy sampling from constrained spaces with the Metropolis-adjusted Preconditioned Langevin Algorithm</title>
      <link>https://arxiv.org/abs/2412.18701</link>
      <description>arXiv:2412.18701v1 Announce Type: new 
Abstract: In this work, we propose a first-order sampling method called the Metropolis-adjusted Preconditioned Langevin Algorithm for approximate sampling from a target distribution whose support is a proper convex subset of $\mathbb{R}^{d}$. Our proposed method is the result of applying a Metropolis-Hastings filter to the Markov chain formed by a single step of the preconditioned Langevin algorithm with a metric $\mathscr{G}$, and is motivated by the natural gradient descent algorithm for optimisation. We derive non-asymptotic upper bounds for the mixing time of this method for sampling from target distributions whose potentials are bounded relative to $\mathscr{G}$, and for exponential distributions restricted to the support. Our analysis suggests that if $\mathscr{G}$ satisfies stronger notions of self-concordance introduced in Kook and Vempala (2024), then these mixing time upper bounds have a strictly better dependence on the dimension than when is merely self-concordant. We also provide numerical experiments that demonstrates the practicality of our proposed method. Our method is a high-accuracy sampler due to the polylogarithmic dependence on the error tolerance in our mixing time upper bounds.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18701v1</guid>
      <category>stat.CO</category>
      <category>math.ST</category>
      <category>stat.ML</category>
      <category>stat.TH</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Vishwak Srinivasan, Andre Wibisono, Ashia Wilson</dc:creator>
    </item>
    <item>
      <title>Hybrid Population Monte Carlo</title>
      <link>https://arxiv.org/abs/2412.19576</link>
      <description>arXiv:2412.19576v1 Announce Type: new 
Abstract: Importance sampling (IS) is a powerful Monte Carlo (MC) technique for approximating intractable integrals, for instance in Bayesian inference. The performance of IS relies heavily on the appropriate choice of the so-called proposal distribution. Adaptive IS (AIS) methods iteratively improve target estimates by adapting the proposal distribution. Recent AIS research focuses on enhancing proposal adaptation for high-dimensional problems, while addressing the challenge of multi-modal targets. In this paper, a new class of AIS methods is presented, utilizing a hybrid approach that incorporates weighted samples and proposal distributions to enhance performance. This approach belongs to the family of population Monte Carlo (PMC) algorithms, where a population of proposals is adapted to better approximate the target distribution. The proposed hybrid population Monte Carlo (HPMC) implements a novel two-step adaptation mechanism. In the first step, a hybrid method is used to generate the population of the preliminary proposal locations based on both weighted samples and location parameters. We use Hamiltonian Monte Carlo (HMC) to generate the preliminary proposal locations. HMC has a good exploratory behavior, especially in high dimension scenarios. In the second step, the novel cooperation algorithms are performing to find the final proposals for the next iteration. HPMC achieves a significant performance improvement in high-dimensional problems when compared to the state-of-the-art algorithms. We discuss the statistical properties of HPMC and show its high performance in two challenging benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.19576v1</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ali Mousavi, V\'ictor Elvira</dc:creator>
    </item>
    <item>
      <title>Empirical likelihood for Fr\'echet means on open books</title>
      <link>https://arxiv.org/abs/2412.18818</link>
      <description>arXiv:2412.18818v1 Announce Type: cross 
Abstract: Empirical Likelihood (EL) is a type of nonparametric likelihood that is useful in many statistical inference problems, including confidence region construction and $k$-sample problems. It enjoys some remarkable theoretical properties, notably Bartlett correctability. One area where EL has potential but is under-developed is in non-Euclidean statistics where the Fr\'echet mean is the population characteristic of interest. Only recently has a general EL method been proposed for smooth manifolds. In this work, we continue progress in this direction and develop an EL method for the Fr\'echet mean on a stratified metric space that is not a manifold: the open book, obtained by gluing copies of a Euclidean space along their common boundaries. The structure of an open book captures the essential behaviour of the Fr\'echet mean around certain singular regions of more general stratified spaces for complex data objects, and relates intimately to the local geometry of non-binary trees in the well-studied phylogenetic treespace. We derive a version of Wilks' theorem for the EL statistic, and elucidate on the delicate interplay between the asymptotic distribution and topology of the neighbourhood around the population Fr\'echet mean. We then present a bootstrap calibration of the EL, which proves that under mild conditions, bootstrap calibration of EL confidence regions have coverage error of size $O(n^{-2})$ rather than $O(n^{-1})$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.18818v1</guid>
      <category>math.ST</category>
      <category>stat.CO</category>
      <category>stat.ME</category>
      <category>stat.TH</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Karthik Bharath, Huiling Le, Andrew T A Wood, Xi Yan</dc:creator>
    </item>
    <item>
      <title>Scalable marginalization of correlated latent variables with applications to learning particle interaction kernels</title>
      <link>https://arxiv.org/abs/2203.08389</link>
      <description>arXiv:2203.08389v4 Announce Type: replace 
Abstract: Marginalization of latent variables or nuisance parameters is a fundamental aspect of Bayesian inference and uncertainty quantification. In this work, we focus on scalable marginalization of latent variables in modeling correlated data, such as spatio-temporal or functional observations. We first introduce Gaussian processes (GPs) for modeling correlated data and highlight the computational challenge, where the computational complexity increases cubically fast along with the number of observations. We then review the connection between the state space model and GPs with Mat{\'e}rn covariance for temporal inputs. The Kalman filter and Rauch-Tung-Striebel smoother were introduced as a scalable marginalization technique for computing the likelihood and making predictions of GPs without approximation. We then introduce recent efforts on extending the scalable marginalization idea to the linear model of coregionalization for multivariate correlated output and spatio-temporal observations. In the final part of this work, we introduce a novel marginalization technique to estimate interaction kernels and forecast particle trajectories. The achievement lies in the sparse representation of covariance function, then applying conjugate gradient for solving the computational challenges and improving predictive accuracy. The computational advances achieved in this work outline a wide range of applications in molecular dynamic simulation, cellular migration, and agent-based models.</description>
      <guid isPermaLink="false">oai:arXiv.org:2203.08389v4</guid>
      <category>stat.CO</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.51387/22-NEJSDS13</arxiv:DOI>
      <arxiv:journal_reference>The New England Journal of Statistics in Data Science (2023), 1(2), 172-186</arxiv:journal_reference>
      <dc:creator>Mengyang Gu, Xubo Liu, Xinyi Fang, Sui Tang</dc:creator>
    </item>
    <item>
      <title>Policy Gradients for Optimal Parallel Tempering MCMC</title>
      <link>https://arxiv.org/abs/2409.01574</link>
      <description>arXiv:2409.01574v2 Announce Type: replace 
Abstract: Parallel tempering is a meta-algorithm for Markov Chain Monte Carlo that uses multiple chains to sample from tempered versions of the target distribution, enhancing mixing in multi-modal distributions that are challenging for traditional methods. The effectiveness of parallel tempering is heavily influenced by the selection of chain temperatures. Here, we present an adaptive temperature selection algorithm that dynamically adjusts temperatures during sampling using a policy gradient approach. Experiments demonstrate that our method can achieve lower integrated autocorrelation times compared to traditional geometrically spaced temperatures and uniform acceptance rate schemes on benchmark distributions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2409.01574v2</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <category>stat.ML</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Zhao, Natesh S. Pillai</dc:creator>
    </item>
    <item>
      <title>Statistical Taylor Expansion</title>
      <link>https://arxiv.org/abs/2410.01223</link>
      <description>arXiv:2410.01223v4 Announce Type: replace 
Abstract: Statistical Taylor expansion replaces the input precise variables in a conventional Taylor expansion with random variables each with known distribution, to calculate the result mean and deviation. It is based on the uncorrelated uncertainty assumption: Each input variable is measured independently with fine enough statistical precision, so that their uncertainties are independent of each other. Statistical Taylor expansion reviews that the intermediate analytic expressions can no longer be regarded as independent of each other, and the result of analytic expression should be path independent. This conclusion differs fundamentally from the conventional common approach in applied mathematics to find the best execution path for a result. This paper also presents an implementation of statistical Taylor expansion called variance arithmetic, and the tests on variance arithmetic.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.01223v4</guid>
      <category>stat.CO</category>
      <category>cs.LG</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Chengpu Wang</dc:creator>
    </item>
    <item>
      <title>Deep Bayes Factors</title>
      <link>https://arxiv.org/abs/2312.05411</link>
      <description>arXiv:2312.05411v3 Announce Type: replace-cross 
Abstract: The is no other model or hypothesis verification tool in Bayesian statistics that is as widely used as the Bayes factor. We focus on generative models that are likelihood-free and, therefore, render the computation of Bayes factors (marginal likelihood ratios) far from obvious. We propose a deep learning estimator of the Bayes factor based on simulated data from two competing models using the likelihood ratio trick. This estimator is devoid of summary statistics and obviates some of the difficulties with ABC model choice. We establish sufficient conditions for consistency of our Deep Bayes Factor estimator as well as its consistency as a model selection tool. We investigate the performance of our estimator on various examples using a wide range of quality metrics related to estimation and model decision accuracy. After training, our deep learning approach enables rapid evaluations of the Bayes factor estimator at any fictional data arriving from either hypothesized model, not just the observed data $Y_0$. This allows us to inspect entire Bayes factor distributions under the two models and to quantify the relative location of the Bayes factor evaluated at $Y_0$ in light of these distributions. Such tail area evaluations are not possible for Bayes factor estimators tailored to $Y_0$. We find the performance of our Deep Bayes Factors competitive with existing MCMC techniques that require the knowledge of the likelihood function. We also consider variants for posterior or intrinsic Bayes factors estimation. We demonstrate the usefulness of our approach on a relatively high-dimensional real data example about determining cognitive biases.</description>
      <guid isPermaLink="false">oai:arXiv.org:2312.05411v3</guid>
      <category>stat.ME</category>
      <category>stat.CO</category>
      <category>stat.ML</category>
      <pubDate>Mon, 30 Dec 2024 00:00:00 -0500</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jungeum Kim, Veronika Rockova</dc:creator>
    </item>
  </channel>
</rss>
