<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Wed, 02 Jul 2025 01:31:56 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Prediction of Protein Three-dimensional Structures via a Hardware-Executable Quantum Computing Framework</title>
      <link>https://arxiv.org/abs/2506.22677</link>
      <description>arXiv:2506.22677v1 Announce Type: new 
Abstract: Accurate prediction of protein active site structures remains a central challenge in structural biology, particularly for short and flexible peptide fragments where conventional methods often fail. Here, we present a quantum computing framework specifically developed for utility-level quantum processors to address this problem. Starting from an amino acid sequence, we formulate the structure prediction task as a ground-state energy minimization problem using the Variational Quantum Eigensolver (VQE). Amino acid connectivity is encoded on a tetrahedral lattice model, and structural constraints-including steric, geometric, and chirality terms-are mapped into a problem-specific Hamiltonian expressed as sparse Pauli operators. The optimization is executed via a two-stage architecture separating energy estimation and measurement decoding, allowing noise mitigation under realistic quantum device conditions. We evaluate the framework on 23 randomly selected real protein fragments from the PDBbind dataset, as well as 7 real fragments from proteins with therapeutic potential, and run the experiments on the IBM-Cleveland Clinic quantum processor. Structural predictions are benchmarked against AlphaFold3 (AF3) using identical postprocessing and docking procedures. Our quantum method outperformed AF3 in both RMSD (Root-Mean-Square Deviation) and docking efficacy. This work demonstrates, for the first time, a complete end-to-end pipeline for biologically relevant structure prediction on real quantum hardware, highlighting its engineering feasibility and practical advantage over existing classical and deep learning approaches.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22677v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuqi Zhang, Yuxin Yang, William Martin, Kingsten Lin, Zixu Wang, Cheng-Chang Lu, Weiwen Jiang, Ruth Nussinov, Joseph Loscalzo, Qiang Guan, Feixiong Cheng</dc:creator>
    </item>
    <item>
      <title>Stateful Logic In-Memory Using Gain-Cell eDRAM</title>
      <link>https://arxiv.org/abs/2506.23185</link>
      <description>arXiv:2506.23185v1 Announce Type: new 
Abstract: Modern data-intensive applications demand memory solutions that deliver high-density, low-power, and integrated computational capabilities to reduce data movement overhead. This paper presents the use of Gain-Cell embedded DRAM (GC-eDRAM) - a compelling alternative to traditional SRAM and eDRAM - for stateful, in-memory logic. We propose a circuit design that exploits GC-eDRAM's dual-port architecture and nondestructive read operation to perform logic functions directly within the GC-eDRAM memory array. Our simulation results demonstrate a 5us retention time coupled with a 99.5% success rate for computing the logic gates. By incorporating processing-in-memory (PIM) functionality into GC-eDRAM, our approach enhances memory and compute densities, lowers power consumption, and improves overall performance for data-intensive applications.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23185v1</guid>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Barak Hoffer, Shahar Kvatinsky</dc:creator>
    </item>
    <item>
      <title>CMOS+X: Stacking Persistent Embedded Memories based on Oxide Transistors upon GPGPU Platforms</title>
      <link>https://arxiv.org/abs/2506.23405</link>
      <description>arXiv:2506.23405v1 Announce Type: new 
Abstract: In contemporary general-purpose graphics processing units (GPGPUs), the continued increase in raw arithmetic throughput is constrained by the capabilities of the register file (single-cycle) and last-level cache (high bandwidth), which require the delivery of operands at a cadence demanded by wide single-instruction multiple-data (SIMD) lanes. Enhancing the capacity, density, or bandwidth of these memories can unlock substantial performance gains; however, the recent stagnation of SRAM bit-cell scaling leads to inequivalent losses in compute density.
  To address the challenges posed by SRAM's scaling and leakage power consumption, this paper explores the potential CMOS+X integration of amorphous oxide semiconductor (AOS) transistors in capacitive, persistent memory topologies (e.g., 1T1C eDRAM, 2T0C/3T0C Gain Cell) as alternative cells in multi-ported and high-bandwidth banked GPGPU memories. A detailed study of the density and energy tradeoffs of back-end-of-line (BEOL) integrated memories utilizing monolithic 3D (M3D)-integrated multiplexed arrays is conducted, while accounting for the macro-level limitations of integrating AOS candidate structures proposed by the device community (an aspect often overlooked in prior work). By exploiting the short lifetime of register operands, we propose a multi-ported AOS gain-cell capable of delivering 3x the read ports in ~76% of the footprint of SRAM with over 70% lower standby power, enabling enhancements to compute capacity, such as larger warp sizes or processor counts. Benchmarks run on a validated NVIDIA Ampere-class GPU model, using a modified version of Accel-Sim, demonstrate improvements of up to 5.2x the performance per watt and an average 8% higher geometric mean instruction per cycle (IPC) on various compute- and memory-bound tasks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23405v1</guid>
      <category>cs.ET</category>
      <category>cs.AR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Faaiq Waqar, Ming-Yen Lee, Seongwon Yoon, Seongkwang Lim, Shimeng Yu</dc:creator>
    </item>
    <item>
      <title>Towards the "Digital Me": A vision of authentic Conversational Agents powered by personal Human Digital Twins</title>
      <link>https://arxiv.org/abs/2506.23826</link>
      <description>arXiv:2506.23826v1 Announce Type: new 
Abstract: Human Digital Twins (HDTs) have traditionally been conceptualized as data-driven models designed to support decision-making across various domains. However, recent advancements in conversational AI open new possibilities for HDTs to function as authentic, interactive digital counterparts of individuals. This paper introduces a novel HDT system architecture that integrates large language models with dynamically updated personal data, enabling it to mirror an individual's conversational style, memories, and behaviors. To achieve this, our approach implements context-aware memory retrieval, neural plasticity-inspired consolidation, and adaptive learning mechanisms, creating a more natural and evolving digital persona. The resulting system does not only replicate an individual's unique conversational style depending on who they are speaking with, but also enriches responses with dynamically captured personal experiences, opinions, and memories. While this marks a significant step toward developing authentic virtual counterparts, it also raises critical ethical concerns regarding privacy, accountability, and the long-term implications of persistent digital identities. This study contributes to the field of HDTs by describing our novel system architecture, demonstrating its capabilities, and discussing future directions and emerging challenges to ensure the responsible and ethical development of HDTs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23826v1</guid>
      <category>cs.ET</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <category>cs.IR</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Llu\'is C. Coll, Martin W. Lauer-Schmaltz, Philip Cash, John P. Hansen, Anja Maier</dc:creator>
    </item>
    <item>
      <title>An Interpretable Transformer-Based Foundation Model for Cross-Procedural Skill Assessment Using Raw fNIRS Signals</title>
      <link>https://arxiv.org/abs/2506.22476</link>
      <description>arXiv:2506.22476v1 Announce Type: cross 
Abstract: Objective skill assessment in high-stakes procedural environments requires models that not only decode underlying cognitive and motor processes but also generalize across tasks, individuals, and experimental contexts. While prior work has demonstrated the potential of functional near-infrared spectroscopy (fNIRS) for evaluating cognitive-motor performance, existing approaches are often task-specific, rely on extensive preprocessing, and lack robustness to new procedures or conditions. Here, we introduce an interpretable transformer-based foundation model trained on minimally processed fNIRS signals for cross-procedural skill assessment. Pretrained using self-supervised learning on data from laparoscopic surgical tasks and endotracheal intubation (ETI), the model achieves greater than 88% classification accuracy on all tasks, with Matthews Correlation Coefficient exceeding 0.91 on ETI. It generalizes to a novel emergency airway procedure--cricothyrotomy--using fewer than 30 labeled samples and a lightweight (less than 2k parameter) adapter module, attaining an AUC greater than 87%. Interpretability is achieved via a novel channel attention mechanism--developed specifically for fNIRS--that identifies functionally coherent prefrontal sub-networks validated through ablation studies. Temporal attention patterns align with task-critical phases and capture stress-induced changes in neural variability, offering insight into dynamic cognitive states.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22476v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>q-bio.NC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>A. Subedi, S. De, L. Cavuoto, S. Schwaitzberg, M. Hackett, J. Norfleet</dc:creator>
    </item>
    <item>
      <title>Innovative Research on IoT Architecture and Robotic Operating Platforms: Applications of Large Language Models and Generative AI</title>
      <link>https://arxiv.org/abs/2506.22477</link>
      <description>arXiv:2506.22477v1 Announce Type: cross 
Abstract: This paper introduces an innovative design for robotic operating platforms, underpinned by a transformative Internet of Things (IoT) architecture, seamlessly integrating cutting-edge technologies such as large language models (LLMs), generative AI, edge computing, and 5G networks. The proposed platform aims to elevate the intelligence and autonomy of IoT systems and robotics, enabling them to make real-time decisions and adapt dynamically to changing environments. Through a series of compelling case studies across industries including smart manufacturing, healthcare, and service sectors, this paper demonstrates the substantial potential of IoT-enabled robotics to optimize operational workflows, enhance productivity, and deliver innovative, scalable solutions. By emphasizing the roles of LLMs and generative AI, the research highlights how these technologies drive the evolution of intelligent robotics and IoT, shaping the future of industry-specific advancements. The findings not only showcase the transformative power of these technologies but also offer a forward-looking perspective on their broader societal and industrial implications, positioning them as catalysts for next-generation automation and technological convergence.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22477v1</guid>
      <category>cs.NI</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.RO</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1109/RICAI64321.2024.10911316</arxiv:DOI>
      <arxiv:journal_reference>2024 6th International Conference on Robotics, Intelligent Control and Artificial Intelligence (RICAI), 2024, IEEE Xplore, pp. 881-886</arxiv:journal_reference>
      <dc:creator>Huiwen Han</dc:creator>
    </item>
    <item>
      <title>Towards an Optimized Multi-Cyclic Queuing and Forwarding in Time Sensitive Networking with Time Injection</title>
      <link>https://arxiv.org/abs/2506.22671</link>
      <description>arXiv:2506.22671v1 Announce Type: cross 
Abstract: Cyclic Queuing and Forwarding (CQF) is a Time-Sensitive Networking (TSN) shaping mechanism that provides bounded latency and deterministic Quality of Service (QoS). However, CQF's use of a single cycle restricts its ability to support TSN traffic with diverse timing requirements. Multi-Cyclic Queuing and Forwarding (Multi-CQF) is a new and emerging TSN shaping mechanism that uses multiple cycles on the same egress port, allowing it to accommodate TSN flows with varied timing requirements more effectively than CQF. Despite its potential, current Multi-CQF configuration studies are limited, leading to a lack of comprehensive research, poor understanding of the mechanism, and limited adoption of Multi-CQF in practical applications. Previous work has shown the impact of Time Injection (TI), defined as the start time of Time-Triggered (TT) flows at the source node, on CQF queue resource utilization. However, the impact of TI has not yet been explored in the context of Multi-CQF. This paper introduces a set of constraints and leverages Domain Specific Knowledge (DSK) to reduce the search space for Multi-CQF configuration. Building on this foundation, we develop an open-source Genetic Algorithm (GA) and a hybrid GA-Simulated Annealing (GASA) approach to efficiently configure Multi-CQF networks and introduce TI in Multi-CQF to enhance schedulability. Experimental results show that our proposed algorithms significantly increase the number of scheduled TT flows compared to the baseline Simulated Annealing (SA) model, improving scheduling by an average of 15%. Additionally, GASA achieves a 20% faster convergence rate and lower time complexity, outperforming the SA model in speed, and efficiency.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22671v1</guid>
      <category>cs.NI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Rubi Debnath, Mohammadreza Barzegaran, Sebastian Steinhorst</dc:creator>
    </item>
    <item>
      <title>TriADA: Massively Parallel Trilinear Matrix-by-Tensor Multiply-Add Algorithm and Device Architecture for the Acceleration of 3D Discrete Transformations</title>
      <link>https://arxiv.org/abs/2506.22818</link>
      <description>arXiv:2506.22818v1 Announce Type: cross 
Abstract: Multilinear transformations are key in high-performance computing (HPC) and artificial intelligence (AI) workloads, where data is represented as tensors. However, their high computational and memory demands, which grow with dimensionality, often slow down critical tasks. Moreover, scaling computation by enlarging the number of parallel processing units substantially increases energy consumption, limiting widespread adoption, especially for sparse data, which is common in HPC and AI applications. This paper introduces the Trilinear Algorithm and isomorphic to algorithm Device Architecture (TriADA) to address these challenges with the following innovations: (1) a massively parallel, low-rank algorithm for computing a family of trilinear (3D) discrete orthogonal transformations (3D-DXTs), which is a special case of the more general 3-mode matrix-by-tensor multiplication (3D-GEMT); (2) a new outer-product-based GEMM kernel with decoupled streaming active memory, specially designed to accelerate 3D-GEMT operation; (3) an isomorphic to the proposed algorithm, fully distributed 3D network of mesh interconnected processing elements or cells with a coordinate-free, data-driven local processing activity, which is independent of problem size; (4) an elastic sparse outer-product (ESOP) method that avoids unnecessary computing and communication operations with zero-valued operands, thereby enhancing energy efficiency, computational accuracy, and stability. TriADA is capable of performing a variety of trilinear transformations with hypercubic arithmetic complexity in a linear number of time-steps. The massively parallel, scalable, and energy-efficient architecture of TriADA is ideal for accelerating multilinear tensor operations, which are the most demanding parts of AI and HPC workloads.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22818v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.AR</category>
      <category>cs.ET</category>
      <category>eess.SP</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stanislav Sedukhin (The University of Aizu, Japan), Yoichi Tomioka (The University of Aizu, Japan), Kazuya Matsumoto (The University of Aizu, Japan), Yuichi Okuyama (The University of Aizu, Japan)</dc:creator>
    </item>
    <item>
      <title>Performance Measurements in the AI-Centric Computing Continuum Systems</title>
      <link>https://arxiv.org/abs/2506.22884</link>
      <description>arXiv:2506.22884v1 Announce Type: cross 
Abstract: Over the Eight decades, computing paradigms have shifted from large, centralized systems to compact, distributed architectures, leading to the rise of the Distributed Computing Continuum (DCC). In this model, multiple layers such as cloud, edge, Internet of Things (IoT), and mobile platforms work together to support a wide range of applications. Recently, the emergence of Generative AI and large language models has further intensified the demand for computational resources across this continuum. Although traditional performance metrics have provided a solid foundation, they need to be revisited and expanded to keep pace with changing computational demands and application requirements. Accurate performance measurements benefit both system designers and users by supporting improvements in efficiency and promoting alignment with system goals. In this context, we review commonly used metrics in DCC and IoT environments. We also discuss emerging performance dimensions that address evolving computing needs, such as sustainability, energy efficiency, and system observability. We also outline criteria and considerations for selecting appropriate metrics, aiming to inspire future research and development in this critical area.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.22884v1</guid>
      <category>cs.DC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.NI</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Praveen Kumar Donta, Qiyang Zhang, Schahram Dustdar</dc:creator>
    </item>
    <item>
      <title>The Societal Impact of Foundation Models: Advancing Evidence-based AI Policy</title>
      <link>https://arxiv.org/abs/2506.23123</link>
      <description>arXiv:2506.23123v1 Announce Type: cross 
Abstract: Artificial intelligence is humanity's most promising technology because of the remarkable capabilities offered by foundation models. Yet, the same technology brings confusion and consternation: foundation models are poorly understood and they may precipitate a wide array of harms. This dissertation explains how technology and society coevolve in the age of AI, organized around three themes. First, the conceptual framing: the capabilities, risks, and the supply chain that grounds foundation models in the broader economy. Second, the empirical insights that enrich the conceptual foundations: transparency created via evaluations at the model level and indexes at the organization level. Finally, the transition from understanding to action: superior understanding of the societal impact of foundation models advances evidence-based AI policy. View together, this dissertation makes inroads into achieving better societal outcomes in the age of AI by building the scientific foundations and research-policy interface required for better AI governance.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23123v1</guid>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Rishi Bommasani</dc:creator>
    </item>
    <item>
      <title>Mutli-Level Autoencoder: Deep Learning Based Channel Coding and Modulation</title>
      <link>https://arxiv.org/abs/2506.23511</link>
      <description>arXiv:2506.23511v1 Announce Type: cross 
Abstract: In this paper, we design a deep learning-based convolutional autoencoder for channel coding and modulation. The objective is to develop an adaptive scheme capable of operating at various signal-to-noise ratios (SNR)s without the need for re-training. Additionally, the proposed framework allows validation by testing all possible codes in the codebook, as opposed to previous AI-based encoder/decoder frameworks which relied on testing only a small subset of the available codes. This limitation in earlier methods often led to unreliable conclusions when generalized to larger codebooks. In contrast to previous methods, our multi-level encoding and decoding approach splits the message into blocks, where each encoder block processes a distinct group of $B$ bits. By doing so, the proposed scheme can exhaustively test $2^{B}$ possible codewords for each encoder/decoder level, constituting a layer of the overall scheme. The proposed model was compared to classical polar codes and TurboAE-MOD schemes, showing improved reliability with achieving comparable, or even superior results in some settings. Notably, the architecture can adapt to different SNRs by selectively removing one of the encoder/decoder layers without re-training, thus demonstrating flexibility and efficiency in practical wireless communication scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23511v1</guid>
      <category>eess.SP</category>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ahmad Abdel-Qader, Anas Chaaban, Mohamed S. Shehata</dc:creator>
    </item>
    <item>
      <title>Comparative Studies: Cloud-Enabled Adaptive Learning System for Scalable Education in Sub-Saharan</title>
      <link>https://arxiv.org/abs/2506.23851</link>
      <description>arXiv:2506.23851v1 Announce Type: cross 
Abstract: The integration of cloud computing in education can revolutionise learning in advanced (Australia &amp; South Korea) and middle-income (Ghana &amp; Nigeria) countries, while offering scalable, cost-effective and equitable access to adaptive learning systems. This paper explores how cloud computing and adaptive learning technologies are deployed across different socio-economic and infrastructure contexts. The study identifies enabling factors and systematic challenges, providing insights into how cloud-based education can be tailored to bridge the digital and educational divide globally.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23851v1</guid>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <category>cs.HC</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>Israel Fianyi, Soonja Yeom, Ju-Hyun Shin</dc:creator>
    </item>
    <item>
      <title>Green Metrics Tool: Measuring for fun and profit</title>
      <link>https://arxiv.org/abs/2506.23967</link>
      <description>arXiv:2506.23967v1 Announce Type: cross 
Abstract: The environmental impact of software is gaining increasing attention as the demand for computational resources continues to rise. In order to optimize software resource consumption and reduce carbon emissions, measuring and evaluating software is a first essential step. In this paper we discuss what metrics are important for fact base decision making. We introduce the Green Metrics Tool (GMT), a novel framework for accurately measuring the resource consumption of software. The tool provides a containerized, controlled, and reproducible life cycle-based approach, assessing the resource use of software during key phases. Finally, we discuss GMT features like visualization, comparability and rule- and LLM-based optimisations highlighting its potential to guide developers and researchers in reducing the environmental impact of their software.</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23967v1</guid>
      <category>cs.SE</category>
      <category>cs.CY</category>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Geerd-Dietger Hoffmann, Verena Majuntke</dc:creator>
    </item>
    <item>
      <title>Harnessing AI Agents to Advance Research on Refugee Child Mental Health</title>
      <link>https://arxiv.org/abs/2506.23992</link>
      <description>arXiv:2506.23992v1 Announce Type: cross 
Abstract: The international refugee crisis deepens, exposing millions of dis placed children to extreme psychological trauma. This research suggests a com pact, AI-based framework for processing unstructured refugee health data and distilling knowledge on child mental health. We compare two Retrieval-Aug mented Generation (RAG) pipelines, Zephyr-7B-beta and DeepSeek R1-7B, to determine how well they process challenging humanitarian datasets while avoid ing hallucination hazards. By combining cutting-edge AI methods with migration research and child psychology, this study presents a scalable strategy to assist policymakers, mental health practitioners, and humanitarian agencies to better assist displaced children and recognize their mental wellbeing. In total, both the models worked properly but significantly Deepseek R1 is superior to Zephyr with an accuracy of answer relevance 0.91</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.23992v1</guid>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Aditya Shrivastava, Komal Gupta, Shraddha Arora</dc:creator>
    </item>
    <item>
      <title>Spatial QUBO: Convolutional Formulation of Large-Scale Binary Optimization with Dense Interactions</title>
      <link>https://arxiv.org/abs/2506.24008</link>
      <description>arXiv:2506.24008v1 Announce Type: cross 
Abstract: The spatial photonic Ising machine (SPIM) is a promising optical hardware solver for large-scale combinatorial optimization problems with dense interactions. As the SPIM can represent Ising problems with rank-one coupling matrices, multiplexed versions have been proposed to enhance the applicability to higher-rank interactions. However, the multiplexing cost reduces the implementation efficiency, and even without multiplexing, the SPIM is known to represent coupling matrices beyond rank-one. In this paper, to clarify the intrinsic representation power of the original SPIM, we propose spatial QUBO (spQUBO), a formulation of Ising problems with spatially convolutional structures. We prove that any spQUBO reduces to a two-dimensional spQUBO, with the convolutional structure preserved, and that any two-dimensional spQUBO can be efficiently implemented on the SPIM without multiplexing. We further demonstrate its practical applicability to distance-based combinatorial optimization, such as placement problems and clustering problems. These results advance our understanding of the class of optimization problems where SPIMs exhibit superior efficiency and scalability. Furthermore, spQUBO's efficiency is not limited to the SPIM architecture; we show that its convolutional structure allows efficient computation using Fast Fourier Transforms (FFT).</description>
      <guid isPermaLink="false">oai:arXiv.org:2506.24008v1</guid>
      <category>cond-mat.dis-nn</category>
      <category>cs.ET</category>
      <category>physics.app-ph</category>
      <category>physics.optics</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Hiroshi Yamashita, Hideyuki Suzuki</dc:creator>
    </item>
    <item>
      <title>WeatherEdit: Controllable Weather Editing with 4D Gaussian Field</title>
      <link>https://arxiv.org/abs/2505.20471</link>
      <description>arXiv:2505.20471v2 Announce Type: replace-cross 
Abstract: In this work, we present WeatherEdit, a novel weather editing pipeline for generating realistic weather effects with controllable types and severity in 3D scenes. Our approach is structured into two key components: weather background editing and weather particle construction. For weather background editing, we introduce an all-in-one adapter that integrates multiple weather styles into a single pretrained diffusion model, enabling the generation of diverse weather effects in 2D image backgrounds. During inference, we design a Temporal-View (TV-) attention mechanism that follows a specific order to aggregate temporal and spatial information, ensuring consistent editing across multi-frame and multi-view images. To construct the weather particles, we first reconstruct a 3D scene using the edited images and then introduce a dynamic 4D Gaussian field to generate snowflakes, raindrops and fog in the scene. The attributes and dynamics of these particles are precisely controlled through physical-based modelling and simulation, ensuring realistic weather representation and flexible severity adjustments. Finally, we integrate the 4D Gaussian field with the 3D scene to render consistent and highly realistic weather effects. Experiments on multiple driving datasets demonstrate that WeatherEdit can generate diverse weather effects with controllable condition severity, highlighting its potential for autonomous driving simulation in adverse weather. See project page: https://jumponthemoon.github.io/w-edit</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.20471v2</guid>
      <category>cs.CV</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.LG</category>
      <category>cs.RO</category>
      <pubDate>Tue, 01 Jul 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chenghao Qian, Wenjing Li, Yuhu Guo, Gustav Markkula</dc:creator>
    </item>
  </channel>
</rss>
