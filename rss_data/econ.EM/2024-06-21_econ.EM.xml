<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>econ.EM updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/econ.EM</link>
    <description>econ.EM updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/econ.EM" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 21 Jun 2024 04:04:30 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Fri, 21 Jun 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Testing for Underpowered Literatures</title>
      <link>https://arxiv.org/abs/2406.13122</link>
      <description>arXiv:2406.13122v1 Announce Type: new 
Abstract: How many experimental studies would have come to different conclusions had they been run on larger samples? I show how to estimate the expected number of statistically significant results that a set of experiments would have reported had their sample sizes all been counterfactually increased by a chosen factor. The estimator is consistent and asymptotically normal. Unlike existing methods, my approach requires no assumptions about the distribution of true effects of the interventions being studied other than continuity. This method includes an adjustment for publication bias in the reported t-scores. An application to randomized controlled trials (RCTs) published in top economics journals finds that doubling every experiment's sample size would only increase the power of two-sided t-tests by 7.2 percentage points on average. This effect is small and is comparable to the effect for systematic replication projects in laboratory psychology where previous studies enabled accurate power calculations ex ante. These effects are both smaller than for non-RCTs. This comparison suggests that RCTs are on average relatively insensitive to sample size increases. The policy implication is that grant givers should generally fund more experiments rather than fewer, larger ones.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13122v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Stefan Faridani</dc:creator>
    </item>
    <item>
      <title>Bayesian Inference for Multidimensional Welfare Comparisons</title>
      <link>https://arxiv.org/abs/2406.13395</link>
      <description>arXiv:2406.13395v1 Announce Type: new 
Abstract: Using both single-index measures and stochastic dominance concepts, we show how Bayesian inference can be used to make multivariate welfare comparisons. A four-dimensional distribution for the well-being attributes income, mental health, education, and happiness are estimated via Bayesian Markov chain Monte Carlo using unit-record data taken from the Household, Income and Labour Dynamics in Australia survey. Marginal distributions of beta and gamma mixtures and discrete ordinal distributions are combined using a copula. Improvements in both well-being generally and poverty magnitude are assessed using posterior means of single-index measures and posterior probabilities of stochastic dominance. The conditions for stochastic dominance depend on the class of utility functions that is assumed to define a social welfare function and the number of attributes in the utility function. Three classes of utility functions are considered, and posterior probabilities of dominance are computed for one, two, and four-attribute utility functions for three time intervals within the period 2001 to 2019.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13395v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Gunawan, William Griffiths, Duangkamon Chotikapanich</dc:creator>
    </item>
    <item>
      <title>Testing identification in mediation and dynamic treatment models</title>
      <link>https://arxiv.org/abs/2406.13826</link>
      <description>arXiv:2406.13826v1 Announce Type: new 
Abstract: We propose a test for the identification of causal effects in mediation and dynamic treatment models that is based on two sets of observed variables, namely covariates to be controlled for and suspected instruments, building on the test by Huber and Kueck (2022) for single treatment models. We consider models with a sequential assignment of a treatment and a mediator to assess the direct treatment effect (net of the mediator), the indirect treatment effect (via the mediator), or the joint effect of both treatment and mediator. We establish testable conditions for identifying such effects in observational data. These conditions jointly imply (1) the exogeneity of the treatment and the mediator conditional on covariates and (2) the validity of distinct instruments for the treatment and the mediator, meaning that the instruments do not directly affect the outcome (other than through the treatment or mediator) and are unconfounded given the covariates. Our framework extends to post-treatment sample selection or attrition problems when replacing the mediator by a selection indicator for observing the outcome, enabling joint testing of the selectivity of treatment and attrition. We propose a machine learning-based test to control for covariates in a data-driven manner and analyze its finite sample performance in a simulation study. Additionally, we apply our method to Slovak labor market data and find that our testable implications are not rejected for a sequence of training programs typically considered in dynamic treatment evaluations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.13826v1</guid>
      <category>econ.EM</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Martin Huber, Kevin Kloiber, Lukas Laffers</dc:creator>
    </item>
    <item>
      <title>Estimating Time-Varying Parameters of Various Smoothness in Linear Models via Kernel Regression</title>
      <link>https://arxiv.org/abs/2406.14046</link>
      <description>arXiv:2406.14046v1 Announce Type: new 
Abstract: We consider estimating nonparametric time-varying parameters in linear models using kernel regression. Our contributions are twofold. First, We consider a broad class of time-varying parameters including deterministic smooth functions, the rescaled random walk, structural breaks, the threshold model and their mixtures. We show that those time-varying parameters can be consistently estimated by kernel regression. Our analysis exploits the smoothness of time-varying parameters rather than their specific form. The second contribution is to reveal that the bandwidth used in kernel regression determines the trade-off between the rate of convergence and the size of the class of time-varying parameters that can be estimated. An implication from our result is that the bandwidth should be proportional to $T^{-1/2}$ if the time-varying parameter follows the rescaled random walk, where $T$ is the sample size. We propose a specific choice of the bandwidth that accommodates a wide range of time-varying parameter models. An empirical application shows that the kernel-based estimator with this choice can capture the random-walk dynamics in time-varying parameters.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14046v1</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Mikihito Nishi</dc:creator>
    </item>
    <item>
      <title>Estimating Treatment Effects under Recommender Interference: A Structured Neural Networks Approach</title>
      <link>https://arxiv.org/abs/2406.14380</link>
      <description>arXiv:2406.14380v1 Announce Type: new 
Abstract: Recommender systems are essential for content-sharing platforms by curating personalized content. To evaluate updates of recommender systems targeting content creators, platforms frequently engage in creator-side randomized experiments to estimate treatment effect, defined as the difference in outcomes when a new (vs. the status quo) algorithm is deployed on the platform. We show that the standard difference-in-means estimator can lead to a biased treatment effect estimate. This bias arises because of recommender interference, which occurs when treated and control creators compete for exposure through the recommender system. We propose a "recommender choice model" that captures how an item is chosen among a pool comprised of both treated and control content items. By combining a structural choice model with neural networks, the framework directly models the interference pathway in a microfounded way while accounting for rich viewer-content heterogeneity. Using the model, we construct a double/debiased estimator of the treatment effect that is consistent and asymptotically normal. We demonstrate its empirical performance with a field experiment on Weixin short-video platform: besides the standard creator-side experiment, we carry out a costly blocked double-sided randomization design to obtain a benchmark estimate without interference bias. We show that the proposed estimator significantly reduces the bias in treatment effect estimates compared to the standard difference-in-means estimator.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14380v1</guid>
      <category>econ.EM</category>
      <category>cs.LG</category>
      <category>stat.ME</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ruohan Zhan, Shichao Han, Yuchen Hu, Zhenling Jiang</dc:creator>
    </item>
    <item>
      <title>Management Decisions in Manufacturing using Causal Machine Learning -- To Rework, or not to Rework?</title>
      <link>https://arxiv.org/abs/2406.11308</link>
      <description>arXiv:2406.11308v1 Announce Type: cross 
Abstract: In this paper, we present a data-driven model for estimating optimal rework policies in manufacturing systems. We consider a single production stage within a multistage, lot-based system that allows for optional rework steps. While the rework decision depends on an intermediate state of the lot and system, the final product inspection, and thus the assessment of the actual yield, is delayed until production is complete. Repair steps are applied uniformly to the lot, potentially improving some of the individual items while degrading others. The challenge is thus to balance potential yield improvement with the rework costs incurred. Given the inherently causal nature of this decision problem, we propose a causal model to estimate yield improvement. We apply methods from causal machine learning, in particular double/debiased machine learning (DML) techniques, to estimate conditional treatment effects from data and derive policies for rework decisions. We validate our decision model using real-world data from opto-electronic semiconductor manufacturing, achieving a yield improvement of 2 - 3% during the color-conversion process of white light-emitting diodes (LEDs).</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.11308v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Philipp Schwarz, Oliver Schacht, Sven Klaassen, Daniel Gr\"unbaum, Sebastian Imhof, Martin Spindler</dc:creator>
    </item>
    <item>
      <title>Temperature in the Iberian Peninsula: Trend, seasonality, and heterogeneity</title>
      <link>https://arxiv.org/abs/2406.14145</link>
      <description>arXiv:2406.14145v1 Announce Type: cross 
Abstract: In this paper, we propose fitting unobserved component models to represent the dynamic evolution of bivariate systems of centre and log-range temperatures obtained monthly from minimum/maximum temperatures observed at a given location. In doing so, the centre and log-range temperature are decomposed into potentially stochastic trends, seasonal, and transitory components. Since our model encompasses deterministic trends and seasonal components as limiting cases, we contribute to the debate on whether stochastic or deterministic components better represent the trend and seasonal components. The methodology is implemented to centre and log-range temperature observed in four locations in the Iberian Peninsula, namely, Barcelona, Coru\~{n}a, Madrid, and Seville. We show that, at each location, the centre temperature can be represented by a smooth integrated random walk with time-varying slope, while a stochastic level better represents the log-range. We also show that centre and log-range temperature are unrelated. The methodology is then extended to simultaneously model centre and log-range temperature observed at several locations in the Iberian Peninsula. We fit a multi-level dynamic factor model to extract potential commonalities among centre (log-range) temperature while also allowing for heterogeneity in different areas in the Iberian Peninsula. We show that, although the commonality in trends of average temperature is considerable, the regional components are also relevant.</description>
      <guid isPermaLink="false">oai:arXiv.org:2406.14145v1</guid>
      <category>stat.AP</category>
      <category>econ.EM</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>C. Vladimir Rodr\'iguez-Caballero, Esther Ruiz</dc:creator>
    </item>
    <item>
      <title>Treatment Effects in Bunching Designs: The Impact of Mandatory Overtime Pay on Hours</title>
      <link>https://arxiv.org/abs/2205.10310</link>
      <description>arXiv:2205.10310v4 Announce Type: replace 
Abstract: This paper studies the identifying power of bunching at kinks when the researcher does not assume a parametric choice model. I find that in a general choice model, identifying the average causal response to the policy switch at a kink amounts to confronting two extrapolation problems, each about the distribution of a counterfactual choice that is observed only in a censored manner. I apply this insight to partially identify the effect of overtime pay regulation on the hours of U.S. workers using administrative payroll data, assuming that each distribution satisfies a weak non-parametric shape constraint in the region where it is not observed. The resulting bounds are informative and indicate a relatively small elasticity of demand for weekly hours, addressing a long-standing question about the causal effects of the overtime mandate.</description>
      <guid isPermaLink="false">oai:arXiv.org:2205.10310v4</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Leonard Goff</dc:creator>
    </item>
    <item>
      <title>Sensitivity Analysis in Unconditional Quantile Effects</title>
      <link>https://arxiv.org/abs/2303.14298</link>
      <description>arXiv:2303.14298v3 Announce Type: replace 
Abstract: This paper proposes a framework to analyze the effects of counterfactual policies on the unconditional quantiles of an outcome variable. For a given counterfactual policy, we obtain identified sets for the effect of both marginal and global changes in the proportion of treated individuals. To conduct a sensitivity analysis, we introduce the quantile breakdown frontier, a curve that (i) indicates whether a sensitivity analysis is possible or not, and (ii) when a sensitivity analysis is possible, quantifies the amount of selection bias consistent with a given conclusion of interest across different quantiles. To illustrate our method, we perform a sensitivity analysis on the effect of unionizing low income workers on the quantiles of the distribution of (log) wages.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.14298v3</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Julian Martinez-Iriarte</dc:creator>
    </item>
    <item>
      <title>Impulse Response Analysis of Structural Nonlinear Time Series Models</title>
      <link>https://arxiv.org/abs/2305.19089</link>
      <description>arXiv:2305.19089v4 Announce Type: replace 
Abstract: This paper proposes a semiparametric sieve approach to estimate impulse response functions of nonlinear time series within a general class of structural autoregressive models. We prove that a two-step procedure can flexibly accommodate nonlinear specifications while avoiding the need to choose of fixed parametric forms. Sieve impulse responses are proven to be consistent by deriving uniform estimation guarantees, and an iterative algorithm makes it straightforward to compute them in practice. With simulations, we show that the proposed semiparametric approach proves effective against misspecification while suffering only minor efficiency losses. In a US monetary policy application, we find that the pointwise sieve GDP response associated with an interest rate increase is larger than that of a linear model. Finally, in an analysis of interest rate uncertainty shocks, sieve responses imply significantly more substantial contractionary effects both on production and inflation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.19089v4</guid>
      <category>econ.EM</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Giovanni Ballarin</dc:creator>
    </item>
    <item>
      <title>Testing the Fairness-Improvability of Algorithms</title>
      <link>https://arxiv.org/abs/2405.04816</link>
      <description>arXiv:2405.04816v2 Announce Type: replace 
Abstract: Many organizations use algorithms that have a disparate impact, i.e., the benefits or harms of the algorithm fall disproportionately on certain social groups. Addressing an algorithm's disparate impact can be challenging, especially because it is often unclear whether reducing this impact is possible without sacrificing other important objectives of the organization, such as accuracy or profit. Establishing the improvability of algorithms with respect to multiple criteria is of both conceptual and practical interest: in many settings, disparate impact that would otherwise be prohibited under US federal law is permissible if it is necessary to achieve a legitimate business interest. The question is how a policy-maker can formally substantiate, or refute, this necessity defense. In this paper, we provide an econometric framework for testing the hypothesis that it is possible to improve on the fairness of an algorithm without compromising on other pre-specified objectives. Our proposed test is simple to implement and can be applied under any exogenous constraint on the algorithm space. We establish the large-sample validity and consistency of our test, and illustrate its practical application by evaluating a healthcare algorithm originally considered by Obermeyer et al 2019. In this application, we reject the null hypothesis that it is not possible to reduce the algorithm's disparate impact without compromising on the accuracy of its predictions.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.04816v2</guid>
      <category>econ.EM</category>
      <category>cs.DS</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Eric Auerbach, Annie Liang, Kyohei Okumura, Max Tabord-Meehan</dc:creator>
    </item>
    <item>
      <title>Active Adaptive Experimental Design for Treatment Effect Estimation with Covariate Choices</title>
      <link>https://arxiv.org/abs/2403.03589</link>
      <description>arXiv:2403.03589v2 Announce Type: replace-cross 
Abstract: This study designs an adaptive experiment for efficiently estimating average treatment effects (ATEs). In each round of our adaptive experiment, an experimenter sequentially samples an experimental unit, assigns a treatment, and observes the corresponding outcome immediately. At the end of the experiment, the experimenter estimates an ATE using the gathered samples. The objective is to estimate the ATE with a smaller asymptotic variance. Existing studies have designed experiments that adaptively optimize the propensity score (treatment-assignment probability). As a generalization of such an approach, we propose optimizing the covariate density as well as the propensity score. First, we derive the efficient covariate density and propensity score that minimize the semiparametric efficiency bound and find that optimizing both covariate density and propensity score minimizes the semiparametric efficiency bound more effectively than optimizing only the propensity score. Next, we design an adaptive experiment using the efficient covariate density and propensity score sequentially estimated during the experiment. Lastly, we propose an ATE estimator whose asymptotic variance aligns with the minimized semiparametric efficiency bound.</description>
      <guid isPermaLink="false">oai:arXiv.org:2403.03589v2</guid>
      <category>stat.ME</category>
      <category>cs.LG</category>
      <category>econ.EM</category>
      <category>stat.ML</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Masahiro Kato, Akihiro Oga, Wataru Komatsubara, Ryo Inokuchi</dc:creator>
    </item>
  </channel>
</rss>
