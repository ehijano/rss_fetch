<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.HC updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.HC</link>
    <description>cs.HC updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.HC" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 28 May 2024 04:00:11 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 28 May 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>Human-Centered Automation</title>
      <link>https://arxiv.org/abs/2405.15960</link>
      <description>arXiv:2405.15960v1 Announce Type: new 
Abstract: The rapid advancement of Generative Artificial Intelligence (AI), such as Large Language Models (LLMs) and Multimodal Large Language Models (MLLM), has the potential to revolutionize the way we work and interact with digital systems across various industries. However, the current state of software automation, such as Robotic Process Automation (RPA) frameworks, often requires domain expertise and lacks visibility and intuitive interfaces, making it challenging for users to fully leverage these technologies. This position paper argues for the emerging area of Human-Centered Automation (HCA), which prioritizes user needs and preferences in the design and development of automation systems. Drawing on empirical evidence from human-computer interaction research and case studies, we highlight the importance of considering user perspectives in automation and propose a framework for designing human-centric automation solutions. The paper discusses the limitations of existing automation approaches, the challenges in integrating AI and RPA, and the benefits of human-centered automation for productivity, innovation, and democratizing access to these technologies. We emphasize the importance of open-source solutions and provide examples of how HCA can empower individuals and organizations in the era of rapidly progressing AI, helping them remain competitive. The paper also explores pathways to achieve more advanced and context-aware automation solutions. We conclude with a call to action for researchers and practitioners to focus on developing automation technologies that adapt to user needs, provide intuitive interfaces, and leverage the capabilities of high-end AI to create a more accessible and user-friendly future of automation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15960v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Carlos Toxtli</dc:creator>
    </item>
    <item>
      <title>The Impact and Opportunities of Generative AI in Fact-Checking</title>
      <link>https://arxiv.org/abs/2405.15985</link>
      <description>arXiv:2405.15985v1 Announce Type: new 
Abstract: Generative AI appears poised to transform white collar professions, with more than 90% of Fortune 500 companies using OpenAI's flagship GPT models, which have been characterized as "general purpose technologies" capable of effecting epochal changes in the economy. But how will such technologies impact organizations whose job is to verify and report factual information, and to ensure the health of the information ecosystem? To investigate this question, we conducted 30 interviews with N=38 participants working at 29 fact-checking organizations across six continents, asking about how they use generative AI and the opportunities and challenges they see in the technology. We found that uses of generative AI envisioned by fact-checkers differ based on organizational infrastructure, with applications for quality assurance in Editing, for trend analysis in Investigation, and for information literacy in Advocacy. We used the TOE framework to describe participant concerns ranging from the Technological (lack of transparency), to the Organizational (resource constraints), to the Environmental (uncertain and evolving policy). Building on the insights of our participants, we describe value tensions between fact-checking and generative AI, and propose a novel Verification dimension to the design space of generative models for information verification work. Finally, we outline an agenda for fairness, accountability, and transparency research to support the responsible use of generative AI in fact-checking. Throughout, we highlight the importance of human infrastructure and labor in producing verified information in collaboration with AI. We expect that this work will inform not only the scientific literature on fact-checking, but also contribute to understanding of organizational adaptation to a powerful but unreliable new technology.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15985v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658987</arxiv:DOI>
      <dc:creator>Robert Wolfe, Tanushree Mitra</dc:creator>
    </item>
    <item>
      <title>EEG-DBNet: A Dual-Branch Network for Motor-Imagery Brain-Computer Interfaces</title>
      <link>https://arxiv.org/abs/2405.16090</link>
      <description>arXiv:2405.16090v1 Announce Type: new 
Abstract: Motor imagery electroencephalogram (EEG)-based brain-computer interfaces (BCIs) aid individuals with restricted limb mobility. However, challenges like low signal-to-noise ratio and limited spatial resolution hinder accurate feature extraction from EEG signals, impacting classification. To tackle these issues, we propose an end-to-end dual-branch neural network (EEG-DBNet). This network decodes temporal and spectral sequences separately using distinct branches. Each branch has local and global convolution blocks for extracting local and global features. The temporal branch employs three convolutional layers with smaller kernels, fewer channels, and average pooling, while the spectral branch uses larger kernels, more channels, and max pooling. Global convolution blocks then extract comprehensive features. Outputs from both branches are concatenated and fed to fully connected layers for classification. Ablation experiments demonstrate that our architecture, with specialized convolutional parameters for temporal and spectral sequences, significantly improves classification accuracy compared to single-branch structures. The complementary relationship between local and global convolutional blocks compensates for traditional CNNs' limitations in global feature extraction. Our method achieves accuracies of 85.84% and 91.42% on BCI Competition 4-2a and 4-2b datasets, respectively, surpassing existing state-of-the-art models. Source code is available at https://github.com/xicheng105/EEG-DBNet.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16090v1</guid>
      <category>cs.HC</category>
      <category>eess.SP</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Xicheng Lou, Xinwei Li, Hongying Meng, Jun Hu, Meili Xu, Jiazhang Yang, Zhangyong Li</dc:creator>
    </item>
    <item>
      <title>Design and Implementation of an Emotion Analysis System Based on EEG Signals</title>
      <link>https://arxiv.org/abs/2405.16121</link>
      <description>arXiv:2405.16121v1 Announce Type: new 
Abstract: Traditional brain-computer systems are complex and expensive, and emotion classification algorithms lack repre-sentations of the intrinsic relationships between different channels of electroencephalogram (EEG) signals. There is still room for improvement in accuracy. To lower the research barrier for EEG and harness the rich information embedded in multi-channel EEG, we propose and implement a simple and user-friendly brain-computer system for classifying four emotions: happiness, sorrow, sadness, and tranquility. This system utilizes the fusion of convolutional attention mechanisms and fully pre-activated residual blocks, termed Attention-Convolution-based Pre-Activated Residual Network (ACPA-ResNet).In the hardware acquisition and preprocessing phase, we employ the ADS1299 integrated chip as the analog front-end and utilize the ESP32 microcontroller for initial EEG signal processing. Data is wirelessly transmitted to a PC through UDP protocol for further preprocessing. In the emotion analysis phase, ACPA-ResNet is designed to automatically extract and learn features from EEG signals, thereby enabling accurate classification of emotional states by learning time-frequency domain characteristics. ACPA-ResNet introduces an attention mechanism on the foundation of residual networks, adaptively assigning different weights to each channel. This allows it to focus on more meaningful EEG signals in both spatial and channel dimensions while avoiding the problems of gradient dispersion and explosion associated with deep network architectures.Through testing on 16 subjects, our system demonstrates stable EEG signal acquisition and transmission. The novel network significantly enhances emotion recognition accuracy, achieving an average emotion classification accuracy of 95.1%.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16121v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Zhang Yutian, Huang Shan, Zhang Jianing, Fan Ci'en</dc:creator>
    </item>
    <item>
      <title>Application of Artificial Intelligence in Hand Gesture Recognition with Virtual Reality: Survey and Analysis of Hand Gesture Hardware Selection</title>
      <link>https://arxiv.org/abs/2405.16264</link>
      <description>arXiv:2405.16264v1 Announce Type: new 
Abstract: The ongoing usage of artificial intelligence technologies in virtual reality has led to a large number of researchers exploring immersive virtual reality interaction. Gesture controllers and head-mounted displays are the primary pieces of hardware used in virtual reality applications. This article analyzes the advantages and disadvantages of various hardware tools as well as possible use cases for hand gesture recognition. Several popular data sets used in data pre-processing and hand gesture detection systems are also summarized. This paper's primary objectives are to evaluate the current state of the art in gesture recognition research and to offer potential routes for future study to guide researchers working on immersive virtual reality interaction. Comparing recent study results and taking into account the state of the development of human-computer interaction technology, a number of potential research directions are highlighted, including the following: input data noise should be filtered, a lightweight network should be designed, tactile feedback should be created, and eye and gesture data should be combined.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16264v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jindi Wang</dc:creator>
    </item>
    <item>
      <title>An Empirical Exploration of Trust Dynamics in LLM Supply Chains</title>
      <link>https://arxiv.org/abs/2405.16310</link>
      <description>arXiv:2405.16310v1 Announce Type: new 
Abstract: With the widespread proliferation of AI systems, trust in AI is an important and timely topic to navigate. Researchers so far have largely employed a myopic view of this relationship. In particular, a limited number of relevant trustors (e.g., end-users) and trustees (i.e., AI systems) have been considered, and empirical explorations have remained in laboratory settings, potentially overlooking factors that impact human-AI relationships in the real world. In this paper, we argue for broadening the scope of studies addressing `trust in AI' by accounting for the complex and dynamic supply chains that AI systems result from. AI supply chains entail various technical artifacts that diverse individuals, organizations, and stakeholders interact with, in a variety of ways. We present insights from an in-situ, empirical study of LLM supply chains. Our work reveals additional types of trustors and trustees and new factors impacting their trust relationships. These relationships were found to be central to the development and adoption of LLMs, but they can also be the terrain for uncalibrated trust and reliance on untrustworthy LLMs. Based on these findings, we discuss the implications for research on `trust in AI'. We highlight new research opportunities and challenges concerning the appropriate study of inter-actor relationships across the supply chain and the development of calibrated trust and meaningful reliance behaviors. We also question the meaning of building trust in the LLM supply chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16310v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agathe Balayn, Mireia Yurrita, Fanny Rancourt, Fabio Casati, Ujwal Gadiraju</dc:creator>
    </item>
    <item>
      <title>Understanding Stakeholders' Perceptions and Needs Across the LLM Supply Chain</title>
      <link>https://arxiv.org/abs/2405.16311</link>
      <description>arXiv:2405.16311v1 Announce Type: new 
Abstract: Explainability and transparency of AI systems are undeniably important, leading to several research studies and tools addressing them. Existing works fall short of accounting for the diverse stakeholders of the AI supply chain who may differ in their needs and consideration of the facets of explainability and transparency. In this paper, we argue for the need to revisit the inquiries of these vital constructs in the context of LLMs. To this end, we report on a qualitative study with 71 different stakeholders, where we explore the prevalent perceptions and needs around these concepts. This study not only confirms the importance of exploring the ``who'' in XAI and transparency for LLMs, but also reflects on best practices to do so while surfacing the often forgotten stakeholders and their information needs. Our insights suggest that researchers and practitioners should simultaneously clarify the ``who'' in considerations of explainability and transparency, the ``what'' in the information needs, and ``why'' they are needed to ensure responsible design and development across the LLM supply chain.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16311v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Agathe Balayn, Lorenzo Corti, Fanny Rancourt, Fabio Casati, Ujwal Gadiraju</dc:creator>
    </item>
    <item>
      <title>Navigating AI Fallibility: Examining People's Reactions and Perceptions of AI after Encountering Personality Misrepresentations</title>
      <link>https://arxiv.org/abs/2405.16355</link>
      <description>arXiv:2405.16355v1 Announce Type: new 
Abstract: Many hyper-personalized AI systems profile people's characteristics (e.g., personality traits) to provide personalized recommendations. These systems are increasingly used to facilitate interactions among people, such as providing teammate recommendations. Despite improved accuracy, such systems are not immune to errors when making inferences about people's most personal traits. These errors manifested as AI misrepresentations. However, the repercussions of such AI misrepresentations are unclear, especially on people's reactions and perceptions of the AI. We present two studies to examine how people react and perceive the AI after encountering personality misrepresentations in AI-facilitated team matching in a higher education context. Through semi-structured interviews (n=20) and a survey experiment (n=198), we pinpoint how people's existing and newly acquired AI knowledge could shape their perceptions and reactions of the AI after encountering AI misrepresentations. Specifically, we identified three rationales that people adopted through knowledge acquired from AI (mis)representations: AI works like a machine, human, and/or magic. These rationales are highly connected to people's reactions of over-trusting, rationalizing, and forgiving of AI misrepresentations. Finally, we found that people's existing AI knowledge, i.e., AI literacy, could moderate people's changes in their trust in AI after encountering AI misrepresentations, but not changes in people's social perceptions of AI. We discuss the role of people's AI knowledge when facing AI fallibility and implications for designing responsible mitigation and repair strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16355v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Qiaosi Wang (Georgia Institute of Technology), Chidimma L. Anyi (Georgia Institute of Technology), Vedant Das Swain (Northeastern University), Ashok K. Goel (Georgia Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>Improving Health Professionals' Onboarding with AI and XAI for Trustworthy Human-AI Collaborative Decision Making</title>
      <link>https://arxiv.org/abs/2405.16424</link>
      <description>arXiv:2405.16424v1 Announce Type: new 
Abstract: With advanced AI/ML, there has been growing research on explainable AI (XAI) and studies on how humans interact with AI and XAI for effective human-AI collaborative decision-making. However, we still have a lack of understanding of how AI systems and XAI should be first presented to users without technical backgrounds. In this paper, we present the findings of semi-structured interviews with health professionals (n=12) and students (n=4) majoring in medicine and health to study how to improve onboarding with AI and XAI. For the interviews, we built upon human-AI interaction guidelines to create onboarding materials of an AI system for stroke rehabilitation assessment and AI explanations and introduce them to the participants. Our findings reveal that beyond presenting traditional performance metrics on AI, participants desired benchmark information, the practical benefits of AI, and interaction trials to better contextualize AI performance, and refine the objectives and performance of AI. Based on these findings, we highlight directions for improving onboarding with AI and XAI and human-AI collaborative decision-making.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16424v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.LG</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Min Hun Lee, Silvana Xin Yi Choo, Shamala D/O Thilarajah</dc:creator>
    </item>
    <item>
      <title>Past, Present, and Future of Citation Practices in HCI</title>
      <link>https://arxiv.org/abs/2405.16526</link>
      <description>arXiv:2405.16526v1 Announce Type: new 
Abstract: Science is a complex system comprised of many scientists who individually make collective decisions that, due to the size and nature of the academic system, largely do not affect the system as a whole. However, certain decisions at the meso-level of research communities, such as the Human-Computer Interaction (HCI) community, may result in deep and long-lasting behavioral changes in scientists. In this article, we provide evidence on how a change in editorial policies introduced at the ACM CHI Conference in 2016 launched the CHI community on an expansive path, denoted by a year-by-year increase in the mean number of references included in CHI articles. If this near-linear trend continues undisrupted, an article in CHI 2030 will include on average almost 130 references. Our meta-research provides insights into how the nature and meaning of citation practices in HCI have changed, influenced by factors such as digital accessibility of resources and academic pressures. The observed trend towards more citations reflects a citation culture where quantity is prioritized over quality, contributing to both author and peer reviewer fatigue. This article underscores the value of meta-research for research communities and the profound impact that meso-level policy adjustments have on the evolution of scientific fields and disciplines, urging stakeholders to carefully consider the broader implications of such changes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16526v1</guid>
      <category>cs.HC</category>
      <category>cs.CY</category>
      <category>cs.DL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jonas Oppenlaender</dc:creator>
    </item>
    <item>
      <title>"I Searched for a Religious Song in Amharic and Got Sexual Content Instead": Investigating Online Harm in Low-Resourced Languages on YouTube</title>
      <link>https://arxiv.org/abs/2405.16656</link>
      <description>arXiv:2405.16656v1 Announce Type: new 
Abstract: Online social media platforms such as YouTube have a wide, global reach. However, little is known about the experience of low-resourced language speakers on such platforms; especially in how they experience and navigate harmful content. To better understand this, we (1) conducted semi-structured interviews (n=15) and (2) analyzed search results (n=9313), recommendations (n=3336), channels (n=120) and comments (n=406) of policy-violating sexual content on YouTube focusing on the Amharic language. Our findings reveal that -- although Amharic-speaking YouTube users find the platform crucial for several aspects of their lives -- participants reported unplanned exposure to policy-violating sexual content when searching for benign, popular queries. Furthermore, malicious content creators seem to exploit under-performing language technologies and content moderation to further target vulnerable groups of speakers, including migrant domestic workers, diaspora, and local Ethiopians. Overall, our study sheds light on how failures in low-resourced language technology may lead to exposure to harmful content and suggests implications for stakeholders in minimizing harm. Content Warning: This paper includes discussions of NSFW topics and harmful content (hate, abuse, sexual harassment, self-harm, misinformation). The authors do not support the creation or distribution of harmful content.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16656v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658546</arxiv:DOI>
      <dc:creator>Hellina Hailu Nigatu, Inioluwa Deborah Raji</dc:creator>
    </item>
    <item>
      <title>Low-resourced Languages and Online Knowledge Repositories: A Need-Finding Study</title>
      <link>https://arxiv.org/abs/2405.16669</link>
      <description>arXiv:2405.16669v1 Announce Type: new 
Abstract: Online Knowledge Repositories (OKRs) like Wikipedia offer communities a way to share and preserve information about themselves and their ways of living. However, for communities with low-resourced languages -- including most African communities -- the quality and volume of content available are often inadequate. One reason for this lack of adequate content could be that many OKRs embody Western ways of knowledge preservation and sharing, requiring many low-resourced language communities to adapt to new interactions. To understand the challenges faced by low-resourced language contributors on the popular OKR Wikipedia, we conducted (1) a thematic analysis of Wikipedia forum discussions and (2) a contextual inquiry study with 14 novice contributors. We focused on three Ethiopian languages: Afan Oromo, Amharic, and Tigrinya. Our analysis revealed several recurring themes; for example, contributors struggle to find resources to corroborate their articles in low-resourced languages, and language technology support, like translation systems and spellcheck, result in several errors that waste contributors' time. We hope our study will support designers in making online knowledge repositories accessible to low-resourced language speakers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16669v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3613904.3642605</arxiv:DOI>
      <dc:creator>Hellina Hailu Nigatu, John Canny, Sarah E. Chasins</dc:creator>
    </item>
    <item>
      <title>iDIGIT4L. Nuevos ecosistemas de digitalizaci\'on y aprendizaje hombre-m\'aquina para sistemas de fabricaci\'on industrial heredados</title>
      <link>https://arxiv.org/abs/2405.16676</link>
      <description>arXiv:2405.16676v1 Announce Type: new 
Abstract: The digitization of the productive ecosystem related to human-machine interaction has become a priority for small and medium-sized enterprises. Particularly to face the challenges of Industry 4.0 and advanced digital skills in the workplace. From the research point of view, digitization opens a global scenario for the generation of opportunities for learning in existing manufacturing systems. Mainly, traditional environments must deal with competitive pressures to incorporate new technologies and adapt the skills of workers. In this paper is presented the iDIGIT4L project, which was envisaged to research and develop a digitization ecosystem where people and systems interact in order to transform industrial processes in an intelligent and predictive way. The project contributes with a three-tier human-machine learning methodology that provides augmented and bi-directional interaction in a traditional manufacturing scenario. It is based on the implementation of a non-intrusively integrated digital twin, characterizing an old industrial milling machine for learning through knowledge models supported by the experience of skilled workers. As a result, it has been possible to simultaneously update the functionalities of the industrial system and the digital skills of the workers, becoming an integral part of the digital twin.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16676v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Alvaro Garc\'ia, Esteban Ca\~nibano</dc:creator>
    </item>
    <item>
      <title>The AI-DEC: A Card-based Design Method for User-centered AI Explanations</title>
      <link>https://arxiv.org/abs/2405.16711</link>
      <description>arXiv:2405.16711v1 Announce Type: new 
Abstract: Increasing evidence suggests that many deployed AI systems do not sufficiently support end-user interaction and information needs. Engaging end-users in the design of these systems can reveal user needs and expectations, yet effective ways of engaging end-users in the AI explanation design remain under-explored. To address this gap, we developed a design method, called AI-DEC, that defines four dimensions of AI explanations that are critical for the integration of AI systems -- communication content, modality, frequency, and direction -- and offers design examples for end-users to design AI explanations that meet their needs. We evaluated this method through co-design sessions with workers in healthcare, finance, and management industries who regularly use AI systems in their daily work. Findings indicate that the AI-DEC effectively supported workers in designing explanations that accommodated diverse levels of performance and autonomy needs, which varied depending on the AI system's workplace role and worker values. We discuss the implications of using the AI-DEC for the user-centered design of AI explanations in real-world systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16711v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3661576</arxiv:DOI>
      <arxiv:journal_reference>Designing Interactive Systems Conference, 2024, (DIS '24)</arxiv:journal_reference>
      <dc:creator>Christine P Lee, Min Kyung Lee, Bilge Mutlu</dc:creator>
    </item>
    <item>
      <title>Advancements in Tactile Hand Gesture Recognition for Enhanced Human-Machine Interaction</title>
      <link>https://arxiv.org/abs/2405.17038</link>
      <description>arXiv:2405.17038v1 Announce Type: new 
Abstract: Motivated by the growing interest in enhancing intuitive physical Human-Machine Interaction (HRI/HVI), this study aims to propose a robust tactile hand gesture recognition system. We performed a comprehensive evaluation of different hand gesture recognition approaches for a large area tactile sensing interface (touch interface) constructed from conductive textiles. Our evaluation encompassed traditional feature engineering methods, as well as contemporary deep learning techniques capable of real-time interpretation of a range of hand gestures, accommodating variations in hand sizes, movement velocities, applied pressure levels, and interaction points. Our extensive analysis of the various methods makes a significant contribution to tactile-based gesture recognition in the field of human-machine interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17038v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Chiara Fumelli, Anirvan Dutta, Mohsen Kaboli</dc:creator>
    </item>
    <item>
      <title>Collage is the New Writing: Exploring the Fragmentation of Text and User Interfaces in AI Tools</title>
      <link>https://arxiv.org/abs/2405.17217</link>
      <description>arXiv:2405.17217v1 Announce Type: new 
Abstract: This essay proposes and explores the concept of Collage for the design of AI writing tools, transferred from avant-garde literature with four facets: 1) fragmenting text in writing interfaces, 2) juxtaposing voices (content vs command), 3) integrating material from multiple sources (e.g. text suggestions), and 4) shifting from manual writing to editorial and compositional decision-making, such as selecting and arranging snippets. The essay then employs Collage as an analytical lens to analyse the user interface design of recent AI writing tools, and as a constructive lens to inspire new design directions. Finally, a critical perspective relates the concerns that writers historically expressed through literary collage to AI writing tools. In a broad view, this essay explores how literary concepts can help advance design theory around AI writing tools. It encourages creators of future writing tools to engage not only with new technological possibilities, but also with past writing innovations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17217v1</guid>
      <category>cs.HC</category>
      <category>cs.CL</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3660681</arxiv:DOI>
      <dc:creator>Daniel Buschek</dc:creator>
    </item>
    <item>
      <title>InsigHTable: Insight-driven Hierarchical Table Visualization with Reinforcement Learning</title>
      <link>https://arxiv.org/abs/2405.17229</link>
      <description>arXiv:2405.17229v1 Announce Type: new 
Abstract: Embedding visual representations within original hierarchical tables can mitigate additional cognitive load stemming from the division of users' attention. The created hierarchical table visualizations can help users understand and explore complex data with multi-level attributes. However, because of many options available for transforming hierarchical tables and selecting subsets for embedding, the design space of hierarchical table visualizations becomes vast, and the construction process turns out to be tedious, hindering users from constructing hierarchical table visualizations with many data insights efficiently. We propose InsigHTable, a mixed-initiative and insight-driven hierarchical table transformation and visualization system. We first define data insights within hierarchical tables, which consider the hierarchical structure in the table headers. Since hierarchical table visualization construction is a sequential decision-making process, InsigHTable integrates a deep reinforcement learning framework incorporating an auxiliary rewards mechanism. This mechanism addresses the challenge of sparse rewards in constructing hierarchical table visualizations. Within the deep reinforcement learning framework, the agent continuously optimizes its decision-making process to create hierarchical table visualizations to uncover more insights by collaborating with analysts. We demonstrate the usability and effectiveness of InsigHTable through two case studies and sets of experiments. The results validate the effectiveness of the deep reinforcement learning framework and show that InsigHTable can facilitate users to construct hierarchical table visualizations and understand underlying data insights.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17229v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Guozheng Li, Peng He, Xinyu Wang, Runfei Li, Chi Harold Liu, Chuangxin Ou, Dong He, Guoren Wang</dc:creator>
    </item>
    <item>
      <title>From Text to Blueprint: Leveraging Text-to-Image Tools for Floor Plan Creation</title>
      <link>https://arxiv.org/abs/2405.17236</link>
      <description>arXiv:2405.17236v1 Announce Type: new 
Abstract: Artificial intelligence is revolutionizing architecture through text-to-image synthesis, converting textual descriptions into detailed visual representations. We explore AI-assisted floor plan design, focusing on technical background, practical methods, and future directions. Using tools like, Stable Diffusion, AI leverages models such as Generative Adversarial Networks and Variational Autoencoders to generate complex and functional floorplans designs. We evaluates these AI models' effectiveness in generating residential floor plans from text prompts. Through experiments with reference images, text prompts, and sketches, we assess the strengths and limitations of current text-to-image technology in architectural visualization. Architects can use these AI tools to streamline design processes, create multiple design options, and enhance creativity and collaboration. We highlight AI's potential to drive smarter, more efficient floorplan design, contributing to ongoing discussions on AI integration in the design profession and its future impact.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17236v1</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiaoyu Li, Jonathan Benjamin, Xin Zhang</dc:creator>
    </item>
    <item>
      <title>Towards Fairness in Provably Communication-Efficient Federated Recommender Systems</title>
      <link>https://arxiv.org/abs/2405.15788</link>
      <description>arXiv:2405.15788v1 Announce Type: cross 
Abstract: To reduce the communication overhead caused by parallel training of multiple clients, various federated learning (FL) techniques use random client sampling. Nonetheless, ensuring the efficacy of random sampling and determining the optimal number of clients to sample in federated recommender systems (FRSs) remains challenging due to the isolated nature of each user as a separate client. This challenge is exacerbated in models where public and private features can be separated, and FL allows communication of only public features (item gradients). In this study, we establish sample complexity bounds that dictate the ideal number of clients required for improved communication efficiency and retained accuracy in such models. In line with our theoretical findings, we empirically demonstrate that RS-FairFRS reduces communication cost (~47%). Second, we demonstrate the presence of class imbalance among clients that raises a substantial equity concern for FRSs. Unlike centralized machine learning, clients in FRS can not share raw data, including sensitive attributes. For this, we introduce RS-FairFRS, first fairness under unawareness FRS built upon random sampling based FRS. While random sampling improves communication efficiency, we propose a novel two-phase dual-fair update technique to achieve fairness without revealing protected attributes of active clients participating in training. Our results on real-world datasets and different sensitive features illustrate a significant reduction in demographic bias (~approx40\%), offering a promising path to achieving fairness and communication efficiency in FRSs without compromising the overall accuracy of FRS.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15788v1</guid>
      <category>cs.IR</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Kirandeep Kaur, Sujit Gujar, Shweta Jain</dc:creator>
    </item>
    <item>
      <title>SWE-agent: Agent-Computer Interfaces Enable Automated Software Engineering</title>
      <link>https://arxiv.org/abs/2405.15793</link>
      <description>arXiv:2405.15793v1 Announce Type: cross 
Abstract: Software engineering is a challenging task requiring proficiency in both code generation and interacting with computers. In this paper, we introduce SWE-agent, an autonomous system that uses a language model to interact with a computer to solve software engineering tasks. We show that a custom-built agent-computer interface (ACI) greatly enhances the ability of an agent to create and edit code files, navigate entire repositories and execute programs. On SWE-bench, SWE-agent is able to solve 12.5% of issues, compared to the previous best of 3.8% achieved with retrieval-augmented generation (RAG). We explore how ACI design impacts an agent's behavior and performance, and provide insights on effective design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15793v1</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>John Yang, Carlos E. Jimenez, Alexander Wettig, Kilian Lieret, Shunyu Yao, Karthik Narasimhan, Ofir Press</dc:creator>
    </item>
    <item>
      <title>Hacc-Man: An Arcade Game for Jailbreaking LLMs</title>
      <link>https://arxiv.org/abs/2405.15902</link>
      <description>arXiv:2405.15902v1 Announce Type: cross 
Abstract: The recent leaps in complexity and fluency of Large Language Models (LLMs) mean that, for the first time in human history, people can interact with computers using natural language alone. This creates monumental possibilities of automation and accessibility of computing, but also raises severe security and safety threats: When everyone can interact with LLMs, everyone can potentially break into the systems running LLMs. All it takes is creative use of language. This paper presents Hacc-Man, a game which challenges its players to "jailbreak" an LLM: subvert the LLM to output something that it is not intended to. Jailbreaking is at the intersection between creative problem solving and LLM security. The purpose of the game is threefold: 1. To heighten awareness of the risks of deploying fragile LLMs in everyday systems, 2. To heighten people's self-efficacy in interacting with LLMs, and 3. To discover the creative problem solving strategies, people deploy in this novel context.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15902v1</guid>
      <category>cs.CR</category>
      <category>cs.AI</category>
      <category>cs.CL</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3656156.3665432</arxiv:DOI>
      <dc:creator>Matheus Valentim, Jeanette Falk, Nanna Inie</dc:creator>
    </item>
    <item>
      <title>Product Design Using Generative Adversarial Network: Incorporating Consumer Preference and External Data</title>
      <link>https://arxiv.org/abs/2405.15929</link>
      <description>arXiv:2405.15929v1 Announce Type: cross 
Abstract: The development of Generative AI enables large-scale automation of product design. However, this automated process usually does not incorporate consumer preference information from a company's internal dataset. Meanwhile, external sources such as social media and user-generated content (UGC) websites often contain rich product design and consumer preference information, but such information is not utilized by companies in design generation. We propose a semi-supervised deep generative framework that integrates consumer preferences and external data into product design, allowing companies to generate consumer-preferred designs in a cost-effective and scalable way. We train a predictor model to learn consumer preferences and use predicted popularity levels as additional input labels to guide the training of a Continuous Conditional Generative Adversarial Network (CcGAN). The CcGAN can be instructed to generate new designs of a certain popularity level, enabling companies to efficiently create consumer-preferred designs and save resources by avoiding developing and testing unpopular designs. The framework also incorporates existing product designs and consumer preference information from external sources, which is particularly helpful for small or start-up companies who have limited internal data and face the "cold-start" problem. We apply the proposed framework to a real business setting by helping a large self-aided photography chain in China design new photo templates. We show that our proposed model performs well in generating appealing template designs for the company.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15929v1</guid>
      <category>econ.GN</category>
      <category>cs.HC</category>
      <category>q-fin.EC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Hui Li, Jian Ni, Fangzhu Yang</dc:creator>
    </item>
    <item>
      <title>Automated Assessment and Adaptive Multimodal Formative Feedback Improves Psychomotor Skills Training Outcomes in Quadrotor Teleoperation</title>
      <link>https://arxiv.org/abs/2405.15982</link>
      <description>arXiv:2405.15982v1 Announce Type: cross 
Abstract: The workforce will need to continually upskill in order to meet the evolving demands of industry, especially working with robotic and autonomous systems. Current training methods are not scalable and do not adapt to the skills that learners already possess. In this work, we develop a system that automatically assesses learner skill in a quadrotor teleoperation task using temporal logic task specifications. This assessment is used to generate multimodal feedback based on the principles of effective formative feedback. Participants perceived the feedback positively. Those receiving formative feedback viewed the feedback as more actionable compared to receiving summary statistics. Participants in the multimodal feedback condition were more likely to achieve a safe landing and increased their safe landings more over the experiment compared to other feedback conditions. Finally, we identify themes to improve adaptive feedback and discuss and how training for complex psychomotor tasks can be integrated with learning theories.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.15982v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Emily Jensen, Sriram Sankaranarayanan, Bradley Hayes</dc:creator>
    </item>
    <item>
      <title>A Study on Developer Behaviors for Validating and Repairing LLM-Generated Code Using Eye Tracking and IDE Actions</title>
      <link>https://arxiv.org/abs/2405.16081</link>
      <description>arXiv:2405.16081v1 Announce Type: cross 
Abstract: The increasing use of large language model (LLM)-powered code generation tools, such as GitHub Copilot, is transforming software engineering practices. This paper investigates how developers validate and repair code generated by Copilot and examines the impact of code provenance awareness during these processes. We conducted a lab study with 28 participants, who were tasked with validating and repairing Copilot-generated code in three software projects. Participants were randomly divided into two groups: one informed about the provenance of LLM-generated code and the other not. We collected data on IDE interactions, eye-tracking, cognitive workload assessments, and conducted semi-structured interviews. Our results indicate that, without explicit information, developers often fail to identify the LLM origin of the code. Developers generally employ similar validation and repair strategies for LLM-generated code, but exhibit behaviors such as frequent switching between code and comments, different attentional focus, and a tendency to delete and rewrite code. Being aware of the code's provenance led to improved performance, increased search efforts, more frequent Copilot usage, and higher cognitive workload. These findings enhance our understanding of how developers interact with LLM-generated code and carry implications for designing tools that facilitate effective human-LLM collaboration in software development.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16081v1</guid>
      <category>cs.SE</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ningzhi Tang, Meng Chen, Zheng Ning, Aakash Bansal, Yu Huang, Collin McMillan, Toby Jia-Jun Li</dc:creator>
    </item>
    <item>
      <title>A Low-Cost Teleoperable Surgical Robot with a Macro-Micro Structure and a Continuum Tip for Open-Source Research</title>
      <link>https://arxiv.org/abs/2405.16084</link>
      <description>arXiv:2405.16084v1 Announce Type: cross 
Abstract: Surgical robotic systems equipped with microscale, high-dexterity manipulators have shown promising results in minimally invasive surgery (MIS). One barrier to the widespread adoption of such systems is the prohibitive cost of research and development efforts using current state-of-the-art equipment. To address this challenge, this paper proposes a low-cost and modifiable tendon-driven continuum manipulator for MIS applications. The device is capable of being teleoperated in conjunction with a macro-scale six-axis robotic arm using a haptic stylus. Its control software incorporates and extends freely available and open-source software packages. For verification, we perform teleoperation trials on the proposed continuum manipulator using an electromagnetic tracker. We then integrate the manipulator with a UR5e robotic arm. A series of simulated tumour biopsies were conducted using the integrated robotic system and an anatomical model (phantom), validating its potential efficacy in MIS applications. The complete source code, CAD files for all additively manufactured components, a parts list for the manipulator, and a demonstration video of the proposed system are made available in this work.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16084v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <category>cs.SY</category>
      <category>eess.SY</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lachlan Scott, Tangyou Liu, Liao Wu</dc:creator>
    </item>
    <item>
      <title>SuDA: Support-based Domain Adaptation for Sim2Real Motion Capture with Flexible Sensors</title>
      <link>https://arxiv.org/abs/2405.16152</link>
      <description>arXiv:2405.16152v1 Announce Type: cross 
Abstract: Flexible sensors hold promise for human motion capture (MoCap), offering advantages such as wearability, privacy preservation, and minimal constraints on natural movement. However, existing flexible sensor-based MoCap methods rely on deep learning and necessitate large and diverse labeled datasets for training. These data typically need to be collected in MoCap studios with specialized equipment and substantial manual labor, making them difficult and expensive to obtain at scale. Thanks to the high-linearity of flexible sensors, we address this challenge by proposing a novel Sim2Real Mocap solution based on domain adaptation, eliminating the need for labeled data yet achieving comparable accuracy to supervised learning. Our solution relies on a novel Support-based Domain Adaptation method, namely SuDA, which aligns the supports of the predictive functions rather than the instance-dependent distributions between the source and target domains. Extensive experimental results demonstrate the effectiveness of our method andits superiority over state-of-the-art distribution-based domain adaptation methods in our task.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16152v1</guid>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jiawei Fang, Haishan Song, Chengxu Zuo, Xiaoxia Gao, Xiaowei Chen, Shihui Guo, Yipeng Qin</dc:creator>
    </item>
    <item>
      <title>Cost-Effective Online Multi-LLM Selection with Versatile Reward Models</title>
      <link>https://arxiv.org/abs/2405.16587</link>
      <description>arXiv:2405.16587v1 Announce Type: cross 
Abstract: With the rapid advancement of large language models (LLMs), the diversity of multi-LLM tasks and the variability in their pricing structures have become increasingly important, as costs can vary greatly between different LLMs. To tackle these challenges, we introduce the \textit{C2MAB-V}, a \underline{C}ost-effective \underline{C}ombinatorial \underline{M}ulti-armed \underline{B}andit with \underline{V}ersatile reward models for optimal LLM selection and usage. This online model differs from traditional static approaches or those reliant on a single LLM without cost consideration. With multiple LLMs deployed on a scheduling cloud and a local server dedicated to handling user queries, \textit{C2MAB-V} facilitates the selection of multiple LLMs over a combinatorial search space, specifically tailored for various collaborative task types with different reward models. Based on our designed online feedback mechanism and confidence bound technique, \textit{C2MAB-V} can effectively address the multi-LLM selection challenge by managing the exploration-exploitation trade-off across different models, while also balancing cost and reward for diverse tasks. The NP-hard integer linear programming problem for selecting multiple LLMs with trade-off dilemmas is addressed by: i) decomposing the integer problem into a relaxed form by the local server, ii) utilizing a discretization rounding scheme that provides optimal LLM combinations by the scheduling cloud, and iii) continual online updates based on feedback. Theoretically, we prove that \textit{C2MAB-V} offers strict guarantees over versatile reward models, matching state-of-the-art results for regret and violations in some degenerate cases. Empirically, we show that \textit{C2MAB-V} effectively balances performance and cost-efficiency with nine LLMs for three application scenarios.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16587v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Xiangxiang Dai, Jin Li, Xutong Liu, Anqi Yu, John C. S. Lui</dc:creator>
    </item>
    <item>
      <title>Attaining Human`s Desirable Outcomes in Human-AI Interaction via Structural Causal Games</title>
      <link>https://arxiv.org/abs/2405.16588</link>
      <description>arXiv:2405.16588v1 Announce Type: cross 
Abstract: In human-AI interaction, a prominent goal is to attain human`s desirable outcome with the assistance of AI agents, which can be ideally delineated as a problem of seeking the optimal Nash Equilibrium that matches the human`s desirable outcome. However, reaching the outcome is usually challenging due to the existence of multiple Nash Equilibria that are related to the assisting task but do not correspond to the human`s desirable outcome. To tackle this issue, we employ a theoretical framework called structural causal game (SCG) to formalize the human-AI interactive process. Furthermore, we introduce a strategy referred to as pre-policy intervention on the SCG to steer AI agents towards attaining the human`s desirable outcome. In more detail, a pre-policy is learned as a generalized intervention to guide the agents` policy selection, under a transparent and interpretable procedure determined by the SCG. To make the framework practical, we propose a reinforcement learning-like algorithm to search out this pre-policy. The proposed algorithm is tested in both gridworld environments and realistic dialogue scenarios with large language models, demonstrating its adaptability in a broader class of problems and potential effectiveness in real-world situations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16588v1</guid>
      <category>cs.AI</category>
      <category>cs.GT</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Anjie Liu, Jianhong Wang, Haoxuan Li, Xu Chen, Jun Wang, Samuel Kaski, Mengyue Yang</dc:creator>
    </item>
    <item>
      <title>Ethics Pathways: A Design Activity for Reflecting on Ethics Engagement in HCI Research</title>
      <link>https://arxiv.org/abs/2405.16654</link>
      <description>arXiv:2405.16654v1 Announce Type: cross 
Abstract: This paper introduces Ethics Pathways, a design activity aimed at understanding HCI and design researchers' ethics engagements and flows during their research process. Despite a strong ethical commitment in these fields, challenges persist in grasping the complexity of researchers' engagement with ethics -- practices conducted to operationalize ethics -- in situated institutional contexts. Ethics Pathways, developed through six playtesting sessions, offers a design approach to understanding the complexities of researchers' past ethics engagements in their work. This activity involves four main tasks: recalling ethical incidents; describing stakeholders involved in the situation; recounting their actions or speculative alternatives; and reflection and emotion walk-through. The paper reflects on the role of design decisions and facilitation strategies in achieving these goals. The design activity contributes to the discourse on ethical HCI research by conceptualizing ethics engagement as a part of ongoing research processing, highlighting connections between individual affective experiences, social interactions across power differences, and institutional goals.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16654v1</guid>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3660714</arxiv:DOI>
      <dc:creator>Inha Cha, Ajit G. Pillai, Richmond Y. Wong</dc:creator>
    </item>
    <item>
      <title>REX: Designing User-centered Repair and Explanations to Address Robot Failures</title>
      <link>https://arxiv.org/abs/2405.16710</link>
      <description>arXiv:2405.16710v1 Announce Type: cross 
Abstract: Robots in real-world environments continuously engage with multiple users and encounter changes that lead to unexpected conflicts in fulfilling user requests. Recent technical advancements (e.g., large-language models (LLMs), program synthesis) offer various methods for automatically generating repair plans that address such conflicts. In this work, we understand how automated repair and explanations can be designed to improve user experience with robot failures through two user studies. In our first, online study ($n=162$), users expressed increased trust, satisfaction, and utility with the robot performing automated repair and explanations. However, we also identified risk factors -- safety, privacy, and complexity -- that require adaptive repair strategies. The second, in-person study ($n=24$) elucidated distinct repair and explanation strategies depending on the level of risk severity and type. Using a design-based approach, we explore automated repair with explanations as a solution for robots to handle conflicts and failures, complemented by adaptive strategies for risk factors. Finally, we discuss the implications of incorporating such strategies into robot designs to achieve seamless operation among changing user needs and environments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16710v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3661559</arxiv:DOI>
      <arxiv:journal_reference>Designing Interactive Systems Conference, 2024, (DIS '24)</arxiv:journal_reference>
      <dc:creator>Christine P Lee, Pragathi Praveena, Bilge Mutlu</dc:creator>
    </item>
    <item>
      <title>Advancing Behavior Generation in Mobile Robotics through High-Fidelity Procedural Simulations</title>
      <link>https://arxiv.org/abs/2405.16818</link>
      <description>arXiv:2405.16818v1 Announce Type: cross 
Abstract: This paper introduces YamaS, a simulator integrating Unity3D Engine with Robotic Operating System for robot navigation research and aims to facilitate the development of both Deep Reinforcement Learning (Deep-RL) and Natural Language Processing (NLP). It supports single and multi-agent configurations with features like procedural environment generation, RGB vision, and dynamic obstacle navigation. Unique to YamaS is its ability to construct single and multi-agent environments, as well as generating agent's behaviour through textual descriptions. The simulator's fidelity is underscored by comparisons with the real-world Yamabiko Beego robot, demonstrating high accuracy in sensor simulations and spatial reasoning. Moreover, YamaS integrates Virtual Reality (VR) to augment Human-Robot Interaction (HRI) studies, providing an immersive platform for developers and researchers. This fusion establishes YamaS as a versatile and valuable tool for the development and testing of autonomous systems, contributing to the fields of robot simulation and AI-driven training methodologies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16818v1</guid>
      <category>cs.RO</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Victor A. Kich, Jair A. Bottega, Raul Steinmetz, Ricardo B. Grando, Ayanori Yorozu, Akihisa Ohya</dc:creator>
    </item>
    <item>
      <title>Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT Even in Low-Resource Settings</title>
      <link>https://arxiv.org/abs/2405.16820</link>
      <description>arXiv:2405.16820v1 Announce Type: cross 
Abstract: The rapid proliferation of generative AI has raised questions about the competitiveness of lower-parameter, locally tunable, open-weight models relative to high-parameter, API-guarded, closed-weight models in terms of performance, domain adaptation, cost, and generalization. Centering under-resourced yet risk-intolerant settings in government, research, and healthcare, we see for-profit closed-weight models as incompatible with requirements for transparency, privacy, adaptability, and standards of evidence. Yet the performance penalty in using open-weight models, especially in low-data and low-resource settings, is unclear.
  We assess the feasibility of using smaller, open-weight models to replace GPT-4-Turbo in zero-shot, few-shot, and fine-tuned regimes, assuming access to only a single, low-cost GPU. We assess value-sensitive issues around bias, privacy, and abstention on three additional tasks relevant to those topics. We find that with relatively low effort, very low absolute monetary cost, and relatively little data for fine-tuning, small open-weight models can achieve competitive performance in domain-adapted tasks without sacrificing generality. We then run experiments considering practical issues in bias, privacy, and hallucination risk, finding that open models offer several benefits over closed models. We intend this work as a case study in understanding the opportunity cost of reproducibility and transparency over for-profit state-of-the-art zero shot performance, finding this cost to be marginal under realistic settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.16820v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3630106.3658966</arxiv:DOI>
      <dc:creator>Robert Wolfe, Isaac Slaughter, Bin Han, Bingbing Wen, Yiwei Yang, Lucas Rosenblatt, Bernease Herman, Eva Brown, Zening Qu, Nic Weber, Bill Howe</dc:creator>
    </item>
    <item>
      <title>Stop! In the Name of Flaws: Disentangling Personal Names and Sociodemographic Attributes in NLP</title>
      <link>https://arxiv.org/abs/2405.17159</link>
      <description>arXiv:2405.17159v1 Announce Type: cross 
Abstract: Personal names simultaneously differentiate individuals and categorize them in ways that are important in a given society. While the natural language processing community has thus associated personal names with sociodemographic characteristics in a variety of tasks, researchers have engaged to varying degrees with the established methodological problems in doing so. To guide future work, we present an interdisciplinary background on names and naming. We then survey the issues inherent to associating names with sociodemographic attributes, covering problems of validity (e.g., systematic error, construct validity), as well as ethical concerns (e.g., harms, differential impact, cultural insensitivity). Finally, we provide guiding questions along with normative recommendations to avoid validity and ethical pitfalls when dealing with names and sociodemographic characteristics in natural language processing.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17159v1</guid>
      <category>cs.CL</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Vagrant Gautam, Arjun Subramonian, Anne Lauscher, Os Keyes</dc:creator>
    </item>
    <item>
      <title>Socially-Aware Shared Control Navigation for Assistive Mobile Robots in the Built Environment</title>
      <link>https://arxiv.org/abs/2405.17279</link>
      <description>arXiv:2405.17279v1 Announce Type: cross 
Abstract: As the number of Persons with Disabilities (PWD), particularly those with one or more physical impairments, increases, there is an increasing demand for assistive robotic technologies that can support independent mobility in the built environment and reduce the burden on caregivers. Current assistive mobility platforms (e.g., robotic wheelchairs) often fail to incorporate user preferences and control, leading to reduced trust and efficiency. Existing shared control algorithms do not allow the incorporation of the user control preferences inside the navigation framework or the path planning algorithm. In addition, existing dynamic local planner algorithms for robotic wheelchairs do not take into account the social spaces of people, potentially leading such platforms to infringe upon these areas and cause discomfort. To address these concerns, this work introduces a novel socially-aware shared autonomy-based navigation system for assistive mobile robotic platforms.
  Our navigation framework comprises a Global Planner and a Local Planner. To implement the Global Planner, the proposed approach introduces a novel User Preference Field (UPF) theory within its global planning framework, explicitly acknowledging user preferences to adeptly navigate away from congested areas. For the Local Planner, we propose a Socially-aware Shared Control-based Model Predictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) to adjust movements in real-time, integrating user preferences for safer, more autonomous navigation. Evaluation results show that our Global Planner aligns closely with user preferences compared to baselines, and our Local Planner demonstrates enhanced safety and efficiency in dynamic and static scenarios. This integrated approach fosters trust and autonomy, crucial for the acceptance of assistive mobility technologies in the built environment.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17279v1</guid>
      <category>cs.RO</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yifan Xu, Qianwei Wang, Vineet Kamat, Carol Menassa</dc:creator>
    </item>
    <item>
      <title>The Peripatetic Hater: Predicting Movement Among Hate Subreddits</title>
      <link>https://arxiv.org/abs/2405.17410</link>
      <description>arXiv:2405.17410v1 Announce Type: cross 
Abstract: Many online hate groups exist to disparage others based on race, gender identity, sex, or other characteristics. The accessibility of these communities allows users to join multiple types of hate groups (e.g., a racist community and misogynistic community), which calls into question whether these peripatetic users could be further radicalized compared to users that stay in one type of hate group. However, little is known about the dynamics of joining multiple types of hate groups, nor the effect of these groups on peripatetic users. In this paper, we develop a new method to classify hate subreddits, and the identities they disparage, which we use to better understand how users become peripatetic (join different types of hate subreddits). The hate classification technique utilizes human-validated LLMs to extract the protected identities attacked, if any, across 168 subreddits. We then cluster identity-attacking subreddits to discover three broad categories of hate: racist, anti-LGBTQ, and misogynistic. We show that becoming active in a user's first hate subreddit can cause them to become active in additional hate subreddits of a different category. We also find that users who join additional hate subreddits, especially of a different category, become more active in hate subreddits as a whole and develop a wider hate group lexicon. We are therefore motivated to train an AI model that we find usefully predicts the hate categories users will become active in based on post text read and written. The accuracy of this model may be partly driven by peripatetic users often using the language of hate subreddits they eventually join. Overall, these results highlight the unique risks associated with hate communities on a social media platform, as discussion of alternative targets of hate may lead users to target more protected identities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.17410v1</guid>
      <category>cs.SI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Daniel Hickey, Daniel M. T. Fessler, Kristina Lerman, Keith Burghardt</dc:creator>
    </item>
    <item>
      <title>Mutual Theory of Mind for Human-AI Communication</title>
      <link>https://arxiv.org/abs/2210.03842</link>
      <description>arXiv:2210.03842v2 Announce Type: replace 
Abstract: New developments are enabling AI systems to perceive, recognize, and respond with social cues based on inferences made from humans' explicit or implicit behavioral and verbal cues. These AI systems, equipped with an equivalent of human's Theory of Mind (ToM) capability, are currently serving as matchmakers on dating platforms, assisting student learning as teaching assistants, and enhancing productivity as work partners. They mark a new era in human-AI interaction (HAI) that diverges from traditional human-computer interaction (HCI), where computers are commonly seen as tools instead of social actors. Designing and understanding the human perceptions and experiences in this emerging HAI era becomes an urgent and critical issue for AI systems to fulfill human needs and mitigate risks across social contexts. In this paper, we posit the Mutual Theory of Mind (MToM) framework, inspired by our capability of ToM in human-human communications, to guide this new generation of HAI research by highlighting the iterative and mutual shaping nature of human-AI communication. We discuss the motivation of the MToM framework and its three key components that iteratively shape the human-AI communication in three stages. We then describe two empirical studies inspired by the MToM framework to demonstrate the power of MToM in guiding the design and understanding of human-AI communication. Finally, we discuss future research opportunities in human-AI interaction through the lens of MToM.</description>
      <guid isPermaLink="false">oai:arXiv.org:2210.03842v2</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Qiaosi Wang (Georgia Institute of Technology), Ashok K. Goel (Georgia Institute of Technology)</dc:creator>
    </item>
    <item>
      <title>(Social) Trouble on the Road: Understanding and Addressing Social Discomfort in Shared Car Trips</title>
      <link>https://arxiv.org/abs/2311.04456</link>
      <description>arXiv:2311.04456v3 Announce Type: replace 
Abstract: Unpleasant social interactions on the road can negatively affect driving safety. At the same time, researchers have attempted to address social discomfort by exploring Conversational User Interfaces (CUIs) as social mediators. Before knowing whether CUIs could reduce social discomfort in a car, it is necessary to understand the nature of social discomfort in shared rides. To this end, we recorded nine families going on drives and performed interaction analysis on this data. We define three strategies to address social discomfort: contextual mediation, social mediation, and social support. We discuss considerations for engineering and design, and explore the limitations of current large language models in addressing social discomfort on the road.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.04456v3</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3640794.3665580</arxiv:DOI>
      <dc:creator>Alexandra Bremers, Natalie Friedman, Sam Lee, Tong Wu, Eric Laurier, Malte Jung, Jorge Ortiz, Wendy Ju</dc:creator>
    </item>
    <item>
      <title>SoundShift: Exploring Sound Manipulations for Accessible Mixed-Reality Awareness</title>
      <link>https://arxiv.org/abs/2401.11095</link>
      <description>arXiv:2401.11095v2 Announce Type: replace 
Abstract: Mixed-reality (MR) soundscapes blend real-world sound with virtual audio from hearing devices, presenting intricate auditory information that is hard to discern and differentiate. This is particularly challenging for blind or visually impaired individuals, who rely on sounds and descriptions in their everyday lives. To understand how complex audio information is consumed, we analyzed online forum posts within the blind community, identifying prevailing challenges, needs, and desired solutions. We synthesized the results and propose SoundShift for increasing MR sound awareness, which includes six sound manipulations: Transparency Shift, Envelope Shift, Position Shift, Style Shift, Time Shift, and Sound Append. To evaluate the effectiveness of SoundShift, we conducted a user study with 18 blind participants across three simulated MR scenarios, where participants identified specific sounds within intricate soundscapes. We found that SoundShift increased MR sound awareness and minimized cognitive load. Finally, we developed three real-world example applications to demonstrate the practicality of SoundShift.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.11095v2</guid>
      <category>cs.HC</category>
      <category>cs.SD</category>
      <category>eess.AS</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3661556</arxiv:DOI>
      <dc:creator>Ruei-Che Chang, Chia-Sheng Hung, Bing-Yu Chen, Dhruv Jain, Anhong Guo</dc:creator>
    </item>
    <item>
      <title>AINeedsPlanner: A Workbook to Support Effective Collaboration Between AI Experts and Clients</title>
      <link>https://arxiv.org/abs/2402.08938</link>
      <description>arXiv:2402.08938v3 Announce Type: replace 
Abstract: Clients often partner with AI experts to develop AI applications tailored to their needs. In these partnerships, careful planning and clear communication are critical, as inaccurate or incomplete specifications can result in misaligned model characteristics, expensive reworks, and potential friction between collaborators. Unfortunately, given the complexity of requirements ranging from functionality, data, and governance, effective guidelines for collaborative specification of requirements in client-AI expert collaborations are missing. In this work, we introduce AINeedsPlanner, a workbook that AI experts and clients can use to facilitate effective interchange and clear specifications. The workbook is based on (1) an interview of 10 completed AI application project teams, which identifies and characterizes steps in AI application planning and (2) a study with 12 AI experts, which defines a taxonomy of AI experts' information needs and dimensions that affect the information needs. Finally, we demonstrate the workbook's utility with two case studies in real-world settings.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.08938v3</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1145/3643834.3661577</arxiv:DOI>
      <dc:creator>Dae Hyun Kim, Hyungyu Shin, Shakhnozakhon Yadgarova, Jinho Son, Hariharan Subramonyam, Juho Kim</dc:creator>
    </item>
    <item>
      <title>User Decision Guidance with Selective Explanation Presentation from Explainable-AI</title>
      <link>https://arxiv.org/abs/2402.18016</link>
      <description>arXiv:2402.18016v3 Announce Type: replace 
Abstract: This paper addresses the challenge of selecting explanations for XAI (Explainable AI)-based Intelligent Decision Support Systems (IDSSs). IDSSs have shown promise in improving user decisions through XAI-generated explanations along with AI predictions, and the development of XAI made it possible to generate a variety of such explanations. However, how IDSSs should select explanations to enhance user decision-making remains an open question. This paper proposes X-Selector, a method for selectively presenting XAI explanations. It enables IDSSs to strategically guide users to an AI-suggested decision by predicting the impact of different combinations of explanations on a user's decision and selecting the combination that is expected to minimize the discrepancy between an AI suggestion and a user decision. We compared the efficacy of X-Selector with two naive strategies (all possible explanations and explanations only for the most likely prediction) and two baselines (no explanation and no AI support). The results suggest the potential of X-Selector to guide users to AI-suggested decisions and improve task performance under the condition of a high AI accuracy.</description>
      <guid isPermaLink="false">oai:arXiv.org:2402.18016v3</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yosuke Fukuchi, Seiji Yamada</dc:creator>
    </item>
    <item>
      <title>A Methodology and System For Big-Thick Data Collection</title>
      <link>https://arxiv.org/abs/2404.17602</link>
      <description>arXiv:2404.17602v2 Announce Type: replace 
Abstract: Pervasive sensors have become an essential component in research for gathering real-world data. Nevertheless, current studies on data collecting predominantly concentrate on the objective perception of reality, frequently disregarding the incorporation of subjective human contributions. We introduce an approach and system tailored for gathering big-thick data, a fusion of extensive sensor data (big data) with qualitative human feedback (thick data). Big-thick data enables effective two-way collaboration between humans and machines by supplying data that enables machine learning from human behaviour and activities, as well as data that captures the human interpretation of their actions. The system comprises of three key components: a) a tool for collecting sensor data and user feedback, b) planning and monitoring components for experiment planning and execution monitoring respectively, and c) a machine-learning component that utilizes the data to enhance human-machine interaction.</description>
      <guid isPermaLink="false">oai:arXiv.org:2404.17602v2</guid>
      <category>cs.HC</category>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Ivan Kayongo, Haonan Zhao, Leonardo Malcotti, Fausto Giunchiglia</dc:creator>
    </item>
    <item>
      <title>GesGPT: Speech Gesture Synthesis With Text Parsing from GPT</title>
      <link>https://arxiv.org/abs/2303.13013</link>
      <description>arXiv:2303.13013v2 Announce Type: replace-cross 
Abstract: Gesture synthesis has gained significant attention as a critical research field, aiming to produce contextually appropriate and natural gestures corresponding to speech or textual input. Although deep learning-based approaches have achieved remarkable progress, they often overlook the rich semantic information present in the text, leading to less expressive and meaningful gestures. In this letter, we propose GesGPT, a novel approach to gesture generation that leverages the semantic analysis capabilities of large language models , such as ChatGPT. By capitalizing on the strengths of LLMs for text analysis, we adopt a controlled approach to generate and integrate professional gestures and base gestures through a text parsing script, resulting in diverse and meaningful gestures. Firstly, our approach involves the development of prompt principles that transform gesture generation into an intention classification problem using ChatGPT. We also conduct further analysis on emphasis words and semantic words to aid in gesture generation. Subsequently, we construct a specialized gesture lexicon with multiple semantic annotations, decoupling the synthesis of gestures into professional gestures and base gestures. Finally, we merge the professional gestures with base gestures. Experimental results demonstrate that GesGPT effectively generates contextually appropriate and expressive gestures.</description>
      <guid isPermaLink="false">oai:arXiv.org:2303.13013v2</guid>
      <category>cs.CL</category>
      <category>cs.CV</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1109/LRA.2024.3359544</arxiv:DOI>
      <arxiv:journal_reference>IEEE Robotics and Automation Letters 9 (2024) 3</arxiv:journal_reference>
      <dc:creator>Nan Gao, Zeyu Zhao, Zhi Zeng, Shuwu Zhang, Dongdong Weng, Yihua Bao</dc:creator>
    </item>
    <item>
      <title>Learning Personalized Decision Support Policies</title>
      <link>https://arxiv.org/abs/2304.06701</link>
      <description>arXiv:2304.06701v2 Announce Type: replace-cross 
Abstract: Individual human decision-makers may benefit from different forms of support to improve decision outcomes, but when each form of support will yield better outcomes? In this work, we posit that personalizing access to decision support tools can be an effective mechanism for instantiating the appropriate use of AI assistance. Specifically, we propose the general problem of learning a decision support policy that, for a given input, chooses which form of support to provide to decision-makers for whom we initially have no prior information. We develop $\texttt{Modiste}$, an interactive tool to learn personalized decision support policies. $\texttt{Modiste}$ leverages stochastic contextual bandit techniques to personalize a decision support policy for each decision-maker and supports extensions to the multi-objective setting to account for auxiliary objectives like the cost of support. We find that personalized policies outperform offline policies, and, in the cost-aware setting, reduce the incurred cost with minimal degradation to performance. Our experiments include various realistic forms of support (e.g., expert consensus and predictions from a large language model) on vision and language tasks. Our human subject experiments validate our computational experiments, demonstrating that personalization can yield benefits in practice for real users, who interact with $\texttt{Modiste}$.</description>
      <guid isPermaLink="false">oai:arXiv.org:2304.06701v2</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CY</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Umang Bhatt, Valerie Chen, Katherine M. Collins, Parameswaran Kamalaruban, Emma Kallina, Adrian Weller, Ameet Talwalkar</dc:creator>
    </item>
    <item>
      <title>Sufficient dimension reduction for regression with metric space-valued responses</title>
      <link>https://arxiv.org/abs/2310.12402</link>
      <description>arXiv:2310.12402v2 Announce Type: replace-cross 
Abstract: Data visualization and dimension reduction for regression between a general metric space-valued response and Euclidean predictors is proposed. Current Fr\'ech\'et dimension reduction methods require that the response metric space be continuously embeddable into a Hilbert space, which imposes restriction on the type of metric and kernel choice. We relax this assumption by proposing a Euclidean embedding technique which avoids the use of kernels. Under this framework, classical dimension reduction methods such as ordinary least squares and sliced inverse regression are extended. An extensive simulation experiment demonstrates the superior performance of the proposed method on synthetic data compared to existing methods where applicable. The real data analysis of factors influencing the distribution of COVID-19 transmission in the U.S. and the association between BMI and structural brain connectivity of healthy individuals are also investigated.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.12402v2</guid>
      <category>stat.ME</category>
      <category>cs.HC</category>
      <category>stat.CO</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Abdul-Nasah Soale, Yuexiao Dong</dc:creator>
    </item>
    <item>
      <title>Decoding Social Sentiment in DAO: A Comparative Analysis of Blockchain Governance Communities</title>
      <link>https://arxiv.org/abs/2311.14676</link>
      <description>arXiv:2311.14676v3 Announce Type: replace-cross 
Abstract: Blockchain technology is leading a revolutionary transformation across diverse industries, with effective governance being critical for the success and sustainability of blockchain projects. Community forums, pivotal in engaging decentralized autonomous organizations (DAOs), significantly impact blockchain governance decisions. Concurrently, Natural Language Processing (NLP), particularly sentiment analysis, provides powerful insights from textual data. While prior research has explored the potential of NLP tools in social media sentiment analysis, there is a gap in understanding the sentiment landscape of blockchain governance communities. The evolving discourse and sentiment dynamics on the forums of top DAOs remain largely unknown. This paper delves deep into the evolving discourse and sentiment dynamics on the public forums of leading DeFi projects: Aave, Uniswap, Curve DAO, Yearn.finance, Merit Circle, and Balancer, focusing primarily on discussions related to governance issues. Our study shows that participants in decentralized communities generally express positive sentiments during Discord discussions. Furthermore, there is a potential interaction between discussion intensity and sentiment dynamics; higher discussion volume may contribute to a more stable sentiment from code analysis. The insights gained from this study are valuable for decision-makers in blockchain governance, underscoring the pivotal role of sentiment analysis in interpreting community emotions and its evolving impact on the landscape of blockchain governance. This research significantly contributes to the interdisciplinary exploration of the intersection of blockchain and society, specifically emphasizing the decentralized blockchain governance ecosystem. We provide our data and code for replicability as open access on GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2311.14676v3</guid>
      <category>cs.CY</category>
      <category>cs.CR</category>
      <category>cs.HC</category>
      <category>econ.GN</category>
      <category>q-fin.EC</category>
      <category>stat.AP</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.31219/osf.io/bq6tu</arxiv:DOI>
      <dc:creator>Yutong Quan, Xintong Wu, Wanlin Deng, Luyao Zhang</dc:creator>
    </item>
    <item>
      <title>AutoAct: Automatic Agent Learning from Scratch for QA via Self-Planning</title>
      <link>https://arxiv.org/abs/2401.05268</link>
      <description>arXiv:2401.05268v4 Announce Type: replace-cross 
Abstract: Language agents have achieved considerable performance on various complex question-answering tasks by planning with external tools. Despite the incessant exploration in this field, existing language agent systems still struggle with costly, non-reproducible data reliance and face the challenge of compelling a single model for multiple functions. To this end, we introduce AutoAct, an automatic agent learning framework for QA that does not rely on large-scale annotated data and synthetic planning trajectories from closed-source models (e.g., GPT-4). Given limited data with a tool library, AutoAct first automatically synthesizes planning trajectories without any assistance from humans or strong closed-source models. Then, AutoAct leverages a division-of-labor strategy to automatically differentiate based on the target task information and synthesized trajectories, producing a sub-agent group to complete the task. We conduct comprehensive experiments with different LLMs, which demonstrates that AutoAct yields better or parallel performance compared to various strong baselines. Further analysis demonstrates the effectiveness of the division-of-labor strategy, with the trajectory quality generated by AutoAct generally outperforming that of others. Code will be available at https://github.com/zjunlp/AutoAct.</description>
      <guid isPermaLink="false">oai:arXiv.org:2401.05268v4</guid>
      <category>cs.CL</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <category>cs.LG</category>
      <category>cs.MA</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuofei Qiao, Ningyu Zhang, Runnan Fang, Yujie Luo, Wangchunshu Zhou, Yuchen Eleanor Jiang, Chengfei Lv, Huajun Chen</dc:creator>
    </item>
    <item>
      <title>Beyond static AI evaluations: advancing human interaction evaluations for LLM harms and risks</title>
      <link>https://arxiv.org/abs/2405.10632</link>
      <description>arXiv:2405.10632v3 Announce Type: replace-cross 
Abstract: Model evaluations are central to understanding the safety, risks, and societal impacts of AI systems. While most real-world AI applications involve human-AI interaction, most current evaluations (e.g., common benchmarks) of AI models do not. Instead, they incorporate human factors in limited ways, assessing the safety of models in isolation, thereby falling short of capturing the complexity of human-model interactions. In this paper, we discuss and operationalize a definition of an emerging category of evaluations -- "human interaction evaluations" (HIEs) -- which focus on the assessment of human-model interactions or the process and the outcomes of humans using models. First, we argue that HIEs can be used to increase the validity of safety evaluations, assess direct human impact and interaction-specific harms, and guide future assessments of models' societal impact. Second, we propose a safety-focused HIE design framework -- containing a human-LLM interaction taxonomy -- with three stages: (1) identifying the risk or harm area, (2) characterizing the use context, and (3) choosing the evaluation parameters. Third, we apply our framework to two potential evaluations for overreliance and persuasion risks. Finally, we conclude with tangible recommendations for addressing concerns over costs, replicability, and unrepresentativeness of HIEs.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.10632v3</guid>
      <category>cs.CY</category>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Lujain Ibrahim, Saffron Huang, Lama Ahmad, Markus Anderljung</dc:creator>
    </item>
    <item>
      <title>Human-Agent Cooperation in Games under Incomplete Information through Natural Language Communication</title>
      <link>https://arxiv.org/abs/2405.14173</link>
      <description>arXiv:2405.14173v2 Announce Type: replace-cross 
Abstract: Developing autonomous agents that can strategize and cooperate with humans under information asymmetry is challenging without effective communication in natural language. We introduce a shared-control game, where two players collectively control a token in alternating turns to achieve a common objective under incomplete information. We formulate a policy synthesis problem for an autonomous agent in this game with a human as the other player. To solve this problem, we propose a communication-based approach comprising a language module and a planning module. The language module translates natural language messages into and from a finite set of flags, a compact representation defined to capture player intents. The planning module leverages these flags to compute a policy using an asymmetric information-set Monte Carlo tree search with flag exchange algorithm we present. We evaluate the effectiveness of this approach in a testbed based on Gnomes at Night, a search-and-find maze board game. Results of human subject experiments show that communication narrows the information gap between players and enhances human-agent cooperation efficiency with fewer turns.</description>
      <guid isPermaLink="false">oai:arXiv.org:2405.14173v2</guid>
      <category>cs.AI</category>
      <category>cs.HC</category>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Shenghui Chen, Daniel Fried, Ufuk Topcu</dc:creator>
    </item>
  </channel>
</rss>
