<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>physics.comp-ph updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/physics.comp-ph</link>
    <description>physics.comp-ph updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/physics.comp-ph" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Tue, 20 May 2025 04:00:38 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Saturday</day>
      <day>Sunday</day>
    </skipDays>
    <item>
      <title>On Robust $\beta$-Spectra Shape Parameter Extraction</title>
      <link>https://arxiv.org/abs/2505.11510</link>
      <description>arXiv:2505.11510v1 Announce Type: new 
Abstract: Experimental extraction of $\beta$-shape functions, C(W), is challenging. Comparing different experimental $\beta$-shapes to each other and to those predicted by theory in a consistent manner is difficult. This difficulty is compounded when different parameterizations of the $\beta$-shape function are used. Usually some form of a power polynomial of the total electron energy is chosen for this parametrization. This choice results in extracted coefficients that are highly correlated, with their physical meaning and numerical value dependent on the order of polynomial chosen. This is true for both theoretical and experimental coefficients, and leads to challenges when comparing coefficients from polynomials of different orders. Accurately representing the highly correlated uncertainties is difficult and subtle. These issues impact the underlying physical interpretation of shape function parameters. We suggest an alternative approach based on orthogonal polynomials. Orthogonal polynomials offer more stable coefficient extraction which is less dependent on the order of the polynomial, allow for easier comparison between theory and experimental coefficients from polynomials of different orders, and offer some observations on simple physical meaning and on the statistical limits of the extracted coefficients.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11510v1</guid>
      <category>physics.comp-ph</category>
      <category>nucl-ex</category>
      <category>nucl-th</category>
      <category>physics.chem-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>B. C. Rasco, T. Gray, T. Ruland</dc:creator>
    </item>
    <item>
      <title>Predicting and understanding diffusion lengths and lifetimes in solids via a many-body \textit{ab initio} method: The role of coupled dynamics</title>
      <link>https://arxiv.org/abs/2505.12230</link>
      <description>arXiv:2505.12230v1 Announce Type: new 
Abstract: We present an \textit{ab initio} method of diffusion, relaxation and dephasing processes of arbitrary observables, and corresponding diffusion lengths and lifetimes in solids. The method is based on linearized density-matrix master equation, with quantum treatment of electron scattering processes. It enables clear \textit{ab initio} descriptions of long lifetimes and diffusion lengths using approximate formulas at different levels, such as Dyakonov-Perel and drift-diffusion relations for spin decay and those beyond with coupled dynamics. Our results of graphene-hBN show that the coupling between dynamical processes can significantly affect spin diffusion and relaxation. Our method provides a transparent and powerful tool for predicting and understanding diffusion and relaxation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12230v1</guid>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Junqing Xu</dc:creator>
    </item>
    <item>
      <title>LaPON: A Lagrange's-mean-value-theorem-inspired operator network for solving PDEs and its application on NSE</title>
      <link>https://arxiv.org/abs/2505.12360</link>
      <description>arXiv:2505.12360v1 Announce Type: new 
Abstract: Accelerating the solution of nonlinear partial differential equations (PDEs) while maintaining accuracy at coarse spatiotemporal resolution remains a key challenge in scientific computing. Physics-informed machine learning (ML) methods such as Physics-Informed Neural Networks (PINNs) introduce prior knowledge through loss functions to ensure physical consistency, but their "soft constraints" are usually not strictly satisfied. Here, we propose LaPON, an operator network inspired by the Lagrange's mean value theorem, which embeds prior knowledge directly into the neural network architecture instead of the loss function, making the neural network naturally satisfy the given constraints. This is a hybrid framework that combines neural operators with traditional numerical methods, where neural operators are used to compensate for the effect of discretization errors on the analytical scale in under-resolution simulations. As evaluated on turbulence problem modeled by the Navier-Stokes equations (NSE), the multiple time step extrapolation accuracy and stability of LaPON exceed the direct numerical simulation baseline at 8x coarser grids and 8x larger time steps, while achieving a vorticity correlation of more than 0.98 with the ground truth. It is worth noting that the model can be well generalized to unseen flow states, such as turbulence with different forcing, without retraining. In addition, with the same training data, LaPON's comprehensive metrics on the out-of-distribution test set are at least approximately twice as good as two popular ML baseline methods. By combining numerical computing with machine learning, LaPON provides a scalable and reliable solution for high-fidelity fluid dynamics simulation, showing the potential for wide application in fields such as weather forecasting and engineering design.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12360v1</guid>
      <category>physics.comp-ph</category>
      <category>cs.LG</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Siwen Zhang, Xizeng Zhao, Zhengzhi Deng, Zhaoyuan Huang, Gang Tao, Nuo Xu, Zhouteng Ye</dc:creator>
    </item>
    <item>
      <title>Accelerating Bayesian Optimal Experimental Design via Local Radial Basis Functions: Application to Soft Material Characterization</title>
      <link>https://arxiv.org/abs/2505.13283</link>
      <description>arXiv:2505.13283v1 Announce Type: new 
Abstract: We develop a computational approach that significantly improves the efficiency of Bayesian optimal experimental design (BOED) using local radial basis functions (RBFs). The presented RBF--BOED method uses the intrinsic ability of RBFs to handle scattered parameter points, a property that aligns naturally with the probabilistic sampling inherent in Bayesian methods. By constructing accurate deterministic surrogates from local neighborhood information, the method enables high-order approximations with reduced computational overhead. As a result, computing the expected information gain (EIG) requires evaluating only a small uniformly sampled subset of prior parameter values, greatly reducing the number of expensive forward-model simulations needed. For demonstration, we apply RBF--BOED to optimize a laser-induced cavitation (LIC) experimental setup, where forward simulations follow from inertial microcavitation rheometry (IMR) and characterize the viscoelastic properties of hydrogels. Two experimental design scenarios, single- and multi-constitutive-model problems, are explored. Results show that EIG estimates can be obtained at just 8% of the full computational cost in a five-model problem within a two-dimensional design space. This advance offers a scalable path toward optimal experimental design in soft and biological materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13283v1</guid>
      <category>physics.comp-ph</category>
      <category>cond-mat.soft</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Tianyi Chu, Jonathan B. Estrada, Spencer H. Bryngelson</dc:creator>
    </item>
    <item>
      <title>Spatiotemporal Field Generation Based on Hybrid Mamba-Transformer with Physics-informed Fine-tuning</title>
      <link>https://arxiv.org/abs/2505.11578</link>
      <description>arXiv:2505.11578v1 Announce Type: cross 
Abstract: This research confronts the challenge of substantial physical equation discrepancies encountered in the generation of spatiotemporal physical fields through data-driven trained models. A spatiotemporal physical field generation model, named HMT-PF, is developed based on the hybrid Mamba-Transformer architecture, incorporating unstructured grid information as input. A fine-tuning block, enhanced with physical information, is introduced to effectively reduce the physical equation discrepancies. The physical equation residuals are computed through a point query mechanism for efficient gradient evaluation, then encoded into latent space for refinement. The fine-tuning process employs a self-supervised learning approach to achieve physical consistency while maintaining essential field characteristics. Results show that the hybrid Mamba-Transformer model achieves good performance in generating spatiotemporal fields, while the physics-informed fine-tuning mechanism further reduces significant physical errors effectively. A MSE-R evaluation method is developed to assess the accuracy and realism of physical field generation.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11578v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Peimian Du, Jiabin Liu, Xiaowei Jin, Mengwang Zuo, Hui Li</dc:creator>
    </item>
    <item>
      <title>Pull-off force prediction in viscoelastic adhesive Hertzian contact by physics augmented machine learning</title>
      <link>https://arxiv.org/abs/2505.11685</link>
      <description>arXiv:2505.11685v1 Announce Type: cross 
Abstract: Understanding and predicting the adhesive properties of viscoelastic Hertzian contacts is crucial for diverse engineering applications, including robotics, biomechanics, and advanced material design. The maximum adherence force of a Hertzian indenter unloaded from a viscoelastic substrate has been studied with analytical and numerical models. Analytical models are valid within their assumptions, numerical methods offer precision but can be computationally expensive, necessitating alternative solutions. This study introduces a novel physics-augmented machine learning (PA-ML) framework as a hybrid approach, bridging the gap between analytical models and data-driven solutions, which is capable of rapidly predicting the pull-off force in an Hertzian profile unloaded from a broad band viscoelastic material, with varying Tabor parameter, preload and retraction rate. Compared to previous models, the PA-ML approach provides fast yet accurate predictions in a wide range of conditions, properly predicting the effective surface energy and the work-to-pull-off. The integration of the analytical model provides critical guidance to the PA-ML framework, supporting physically consistent predictions. We demonstrate that physics augmentation enhances predictive accuracy, reducing mean squared error (MSE) while increasing model efficiency and interpretability. We provide data-driven and PA-ML models for real-time predictions of the adherence force in soft materials like silicons and elastomers opening to the possibility to integrate PA-ML into materials and interface design. The models are openly available on Zenodo and GitHub.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11685v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ali Maghami, Merten Stender, Antonio Papangelo</dc:creator>
    </item>
    <item>
      <title>Data Mining and Computational Screening of Rashba-Dresselhaus Splitting and Optoelectronic Properties in Two-Dimensional Perovskite Materials</title>
      <link>https://arxiv.org/abs/2505.12121</link>
      <description>arXiv:2505.12121v1 Announce Type: cross 
Abstract: Recent developments highlighting the promise of two-dimensional perovskites have vastly increased the compositional search space in the perovskite family. This presents a great opportunity for the realization of highly performant devices, and practical challenges associated with the identification of candidate materials. High-fidelity computational screening offers great value in this regard. In this study, we carry out a multiscale computational workflow, generating a dataset of two-dimensional perovskites in the Dion-Jacobson and Ruddlesden-Popper phases. Our dataset comprises ten B-site cations, four halogens, and over 20 organic cations across over 2,000 materials. We compute electronic properties, thermoelectric performance, and numerous geometric characteristics. Furthermore, we introduce a framework for the high-throughput computation of Rashba-Dresselhaus splitting. Finally, we use this dataset to train machine learning models for the accurate prediction of band gaps, candidate Rashba-Dresselhaus materials, and partial charges. The work presented herein can aid future investigations of two-dimensional perovskites with targeted applications in mind.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12121v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Robert Stanton, Wanyi Nie, Sergei Tretiak, Dhara J. Trivedi</dc:creator>
    </item>
    <item>
      <title>Efficient and Accurate Machine Learning Interatomic Potential for Graphene: Capturing Stress-Strain and Vibrational Properties</title>
      <link>https://arxiv.org/abs/2505.12140</link>
      <description>arXiv:2505.12140v1 Announce Type: cross 
Abstract: Machine learning interatomic potentials (MLIPs) offer an efficient and accurate framework for large-scale molecular dynamics (MD) simulations, effectively bridging the gap between classical force fields and \textit{ab initio} methods. In this work, we present a reactive MLIP for graphene, trained on an extensive dataset generated via \textit{ab initio} molecular dynamics (AIMD) simulations. The model accurately reproduces key mechanical and vibrational properties, including stress-strain behavior, elastic constants, phonon dispersion, and vibrational density of states. Notably, it captures temperature-dependent fracture mechanisms and the emergence of linear acetylenic carbon chains upon tearing. The phonon analysis also reveals the expected quadratic ZA mode and excellent agreement with experimental and DFT benchmarks. Our MLIP scales linearly with system size, enabling simulations of large graphene sheets with \textit{ab initio}-level precision. This work delivers a robust and transferable MLIP, alongside an accessible training workflow that can be extended to other materials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12140v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Felipe Hawthorne, Paulo R. E. Raulino, Ronaldo Rodrigues Pel\'a, Cristiano F. Woellner</dc:creator>
    </item>
    <item>
      <title>CLIP: A CUDA-Accelerated Lattice Boltzmann Framework for Interfacial Phenomena with Application to Liquid Jet Simulations</title>
      <link>https://arxiv.org/abs/2505.12205</link>
      <description>arXiv:2505.12205v1 Announce Type: cross 
Abstract: This work introduces CLIP, a CUDA-accelerated phase-field lattice Boltzmann framework for simulating immiscible two-phase flows with high density and viscosity ratios in both two- and three-dimensional domains. By leveraging GPU parallelism, the framework delivers substantial computational speedups, enabling large-scale simulations to be performed efficiently on standard desktop hardware without the need for high-performance computing clusters. It employs the Weighted Multi-Relaxation Time (WMRT) collision operator to enhance numerical stability and improve interface tracking under challenging multiphase conditions. The model is validated through a series of benchmark cases, including capillary wave dynamics, stationary drop tests, two-phase Poiseuille flow, shear-driven interface deformation, and Rayleigh-Taylor instability. It is further applied to simulate liquid jet breakup, capturing the transition from dripping to jetting regimes and identifying a critical Weber number of approximately 2.2. The results closely match experimental observations, offering detailed insights into breakup length, drop size distributions, and flow regime transitions. With its efficiency, accuracy, and scalability, the proposed framework serves as a powerful and accessible tool for investigating complex interfacial phenomena in multiphase flow physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12205v1</guid>
      <category>physics.flu-dyn</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Mehdi Shadkhah, Mohammad Taeibi Rahni, Azadeh Kebriaee, Mohammad Reza Salimi</dc:creator>
    </item>
    <item>
      <title>HORM: A Large Scale Molecular Hessian Database for Optimizing Reactive Machine Learning Interatomic Potentials</title>
      <link>https://arxiv.org/abs/2505.12447</link>
      <description>arXiv:2505.12447v1 Announce Type: cross 
Abstract: Transition state (TS) characterization is central to computational reaction modeling, yet conventional approaches depend on expensive density functional theory (DFT) calculations, limiting their scalability. Machine learning interatomic potentials (MLIPs) have emerged as a promising approach to accelerate TS searches by approximating quantum-level accuracy at a fraction of the cost. However, most MLIPs are primarily designed for energy and force prediction, thus their capacity to accurately estimate Hessians, which are crucial for TS optimization, remains constrained by limited training data and inadequate learning strategies. This work introduces the Hessian dataset for Optimizing Reactive MLIP (HORM), the largest quantum chemistry Hessian database dedicated to reactive systems, comprising 1.84 million Hessian matrices computed at the $\omega$B97x/6-31G(d) level of theory. To effectively leverage this dataset, we adopt a Hessian-informed training strategy that incorporates stochastic row sampling, which addresses the dramatically increased cost and complexity of incorporating second-order information into MLIPs. Various MLIP architectures and force prediction schemes trained on HORM demonstrate up to 63% reduction in the Hessian mean absolute error and up to 200 times increase in TS search compared to models trained without Hessian information. These results highlight how HORM addresses critical data and methodological gaps, enabling the development of more accurate and robust reactive MLIPs for large-scale reaction network exploration.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12447v1</guid>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Taoyong Cui, Yunhong Han, Haojun Jia, Chenru Duan, Qiyuan Zhao</dc:creator>
    </item>
    <item>
      <title>Efficient Implementation of Gaussian Process Regression Accelerated Saddle Point Searches with Application to Molecular Reactions</title>
      <link>https://arxiv.org/abs/2505.12519</link>
      <description>arXiv:2505.12519v1 Announce Type: cross 
Abstract: The task of locating first order saddle points on high-dimensional surfaces describing the variation of energy as a function of atomic coordinates is an essential step for identifying the mechanism and estimating the rate of thermally activated events within the harmonic approximation of transition state theory. When combined directly with electronic structure calculations, the number of energy and atomic force evaluations needed for convergence is a primary issue. Here, we describe an efficient implementation of Gaussian process regression (GPR) acceleration of the minimum mode following method where a dimer is used to estimate the lowest eigenmode of the Hessian. A surrogate energy surface is constructed and updated after each electronic structure calculation. The method is applied to a test set of 500 molecular reactions previously generated by Hermez and coworkers [J. Chem. Theory Comput. 18, 6974 (2022)]. An order of magnitude reduction in the number of electronic structure calculations needed to reach the saddle point configurations is obtained by using the GPR compared to the dimer method. Despite the wide range in stiffness of the molecular degrees of freedom, the calculations are carried out using Cartesian coordinates and are found to require similar number of electronic structure calculations as an elaborate internal coordinate method implemented in the Sella software package. The present implementation of the GPR surrogate model in C++ is efficient enough for the wall time of the saddle point searches to be reduced in 3 out of 4 cases even though the calculations are carried out at a low Hartree-Fock level.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12519v1</guid>
      <category>physics.chem-ph</category>
      <category>cs.LG</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Rohit Goswami (Science Institute and Faculty of Physical Sciences, University of Iceland, Reykjav\'ik, Iceland), Maxim Masterov (SURF, Amsterdam, The Netherlands), Satish Kamath (SURF, Amsterdam, The Netherlands), Alejandro Pe\~na-Torres (Science Institute and Faculty of Physical Sciences, University of Iceland, Reykjav\'ik, Iceland), Hannes J\'onsson (Science Institute and Faculty of Physical Sciences, University of Iceland, Reykjav\'ik, Iceland)</dc:creator>
    </item>
    <item>
      <title>CALM-PDE: Continuous and Adaptive Convolutions for Latent Space Modeling of Time-dependent PDEs</title>
      <link>https://arxiv.org/abs/2505.12944</link>
      <description>arXiv:2505.12944v1 Announce Type: cross 
Abstract: Solving time-dependent Partial Differential Equations (PDEs) using a densely discretized spatial domain is a fundamental problem in various scientific and engineering disciplines, including modeling climate phenomena and fluid dynamics. However, performing these computations directly in the physical space often incurs significant computational costs. To address this issue, several neural surrogate models have been developed that operate in a compressed latent space to solve the PDE. While these approaches reduce computational complexity, they often use Transformer-based attention mechanisms to handle irregularly sampled domains, resulting in increased memory consumption. In contrast, convolutional neural networks allow memory-efficient encoding and decoding but are limited to regular discretizations. Motivated by these considerations, we propose CALM-PDE, a model class that efficiently solves arbitrarily discretized PDEs in a compressed latent space. We introduce a novel continuous convolution-based encoder-decoder architecture that uses an epsilon-neighborhood-constrained kernel and learns to apply the convolution operator to adaptive and optimized query points. We demonstrate the effectiveness of CALM-PDE on a diverse set of PDEs with both regularly and irregularly sampled spatial domains. CALM-PDE is competitive with or outperforms existing baseline methods while offering significant improvements in memory and inference time efficiency compared to Transformer-based methods.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12944v1</guid>
      <category>cs.LG</category>
      <category>cs.AI</category>
      <category>cs.CV</category>
      <category>cs.NE</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Jan Hagnberger, Daniel Musekamp, Mathias Niepert</dc:creator>
    </item>
    <item>
      <title>Nanoindentation simulations for copper and tungsten with adaptive-precision potentials</title>
      <link>https://arxiv.org/abs/2505.12958</link>
      <description>arXiv:2505.12958v1 Announce Type: cross 
Abstract: We perform nanoindentation simulations for both the prototypical face-centered cubic metal copper and the body-centered cubic metal tungsten with a new adaptive-precision description of interaction potentials including different accuracy and computational costs: We combine both a computationally efficient embedded atom method (EAM) potential and a precise but computationally less efficient machine learning potential based on the atomic cluster expansion (ACE) into an adaptive-precision (AP) potential tailored for the nanoindentation. The numerically expensive ACE potential is employed selectively only in regions of the computational cell where large accuracy is required. The comparison with pure EAM and pure ACE simulations shows that for Cu, all potentials yield similar dislocation morphologies under the indenter with only small quantitative differences. In contrast, markedly different plasticity mechanisms are observed for W in simulations performed with the central-force EAM potential compared to results obtained using the ACE potential which is able to describe accurately the angular character of bonding in W due to its half-filled d-band. All ACE-specific mechanisms are reproduced in the AP nanoindentation simulations, however, with a significant speedup of 20-30 times compared to the pure ACE simulations. Hence, the AP potential overcomes the performance gap between the precise ACE and the fast EAM potential by combining the advantages of both potentials.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.12958v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>David Immel, Matous Mrovec, Ralf Drautz, Godehard Sutmann</dc:creator>
    </item>
    <item>
      <title>An introduction to Neural Networks for Physicists</title>
      <link>https://arxiv.org/abs/2505.13042</link>
      <description>arXiv:2505.13042v1 Announce Type: cross 
Abstract: Machine learning techniques have emerged as powerful tools to tackle various challenges. The integration of machine learning methods with Physics has led to innovative approaches in understanding, controlling, and simulating physical phenomena. This article aims to provide a practical introduction to neural network and their basic concepts. It presents some perspectives on recent advances at the intersection of machine learning models with physical systems. We introduce practical material to guide the reader in taking their first steps in applying neural network to Physics problems. As an illustrative example, we provide four applications of increasing complexity for the problem of a simple pendulum, namely: parameter fitting of the pendulum's ODE for the small-angle approximation; Application of Physics-Inspired Neural Networks (PINNs) to find solutions of the pendulum's ODE in the small-angle regime; Autoencoders applied to an image dataset of the pendulum's oscillations for estimating the dimensionality of the parameter space in this physical system; and the use of Sparse Identification of Non-Linear Dynamics (SINDy) architectures for model discovery and analytical expressions for the nonlinear pendulum problem (large angles).</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13042v1</guid>
      <category>physics.ed-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/publicdomain/zero/1.0/</dc:rights>
      <dc:creator>G. Caf\'e de Miranda, Gubio G. de Lima, Tiago de S. Farias</dc:creator>
    </item>
    <item>
      <title>Coupled integral equations method with open boundary conditions for calculation the characteristics of structured waveguides</title>
      <link>https://arxiv.org/abs/2505.13086</link>
      <description>arXiv:2505.13086v1 Announce Type: cross 
Abstract: The results of modification of the CASCIE code aimed at implementing open boundary conditions are presented. The accelerator section developed at CERN was chosen as a prototype for the structured waveguide under testing. Results of testing the CASCIE-M code confirms that the implementation of matrix open boundary conditions gives possibility to consider the structure in which waves enter and exit without additional reflections from couplers. It was shown that the dependence of the reflection coefficient on frequency differs from the similar dependence for a waveguide with couplers. It does not have a regular sequence of minimum and maximum values associated with reflections from the couplers and the formation of resonance conditions. This indicates that the reflections are of a different nature and are associated with inhomogeneity. The proposed modification of the coupled integral equation method allows us to investigate the accuracy of the field expansion on which coupled mode theory can be constructed that describes structured waveguides.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13086v1</guid>
      <category>physics.acc-ph</category>
      <category>physics.comp-ph</category>
      <category>physics.optics</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>M. I. Ayzatsky</dc:creator>
    </item>
    <item>
      <title>Lattice thermal conductivity of 16 elemental metals from molecular dynamics simulations with a unified neuroevolution potential</title>
      <link>https://arxiv.org/abs/2505.13179</link>
      <description>arXiv:2505.13179v1 Announce Type: cross 
Abstract: Metals play a crucial role in heat management in electronic devices, such as integrated circuits, making it vital to understand heat transport in elementary metals and alloys. In this work, we systematically study phonon thermal transport in 16 metals using the efficient homogeneous nonequilibrium molecular dynamics (HNEMD) method and the recently developed unified neuroevolution potential version 1 (UNEP-v1) for 16 metals and their alloys. We compare our results with existing ones based on the Boltzmann transport equation (BTE) approach and find that our HNEMD results align well with BTE results obtained by considering phonon-phonon scattering only. By contrast, HNEMD results based on the conventional embedded-atom method potential show less satisfactory agreement with BTE ones. Given the high accuracy of the UNEP-v1 model demonstrated in various metal alloys, we anticipate that the HNEMD method combined with the UNEP-v1 model will be a promising tool for exploring phonon thermal transport properties in complex systems such as high-entropy alloys.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13179v1</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Shuo Cao, Ao Wang, Zheyong Fan, Hua Bao, Ping Qian, Ye Su, Yu Yan</dc:creator>
    </item>
    <item>
      <title>Kinematic dynamos and resolution limits for Smoothed Particle Magnetohydrodynamics</title>
      <link>https://arxiv.org/abs/2505.13305</link>
      <description>arXiv:2505.13305v1 Announce Type: cross 
Abstract: Understanding the origin and evolution of magnetic fields on cosmological scales opens up a window into the physics of the early Universe. Numerical simulations of such fields require a careful treatment to faithfully solve the equations of magnetohydrodynamics (MHD) without introducing numerical artefacts. In this paper, we study the growth of the magnetic fields in controlled kinematic dynamo setups using both smoothed particle hydrodynamics implementations in the SWIFT code. We assess the quality of the reconstructed solution in the Roberts flow case against the reference implementation in the Pencil code and find generally a good agreement. Similarly, we reproduce the known features of the more complex ABC flow. Using a simple induction-diffusion balance model to analyse the results, we construct an "overwinding" trigger metric to locally detect regions where the magnetic diffusion cannot counteract the expected induction because of limitations in the method's ability to resolve magnetic field gradients. This metric is then used to identify the necessary resolution and resistivity levels to counteract the overwinding problem. We finally apply this metric to adiabatic cosmological simulations and discuss the resolution requirements needed to resolve the growth of the primordial fields without artefacts.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13305v1</guid>
      <category>astro-ph.CO</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Nikyta Shchutskyi, Matthieu Schaller, Orestis A. Karapiperis, Federico A. Stasyszyn, Axel Brandenburg</dc:creator>
    </item>
    <item>
      <title>Structure-preserving schemes conserving entropy and kinetic energy</title>
      <link>https://arxiv.org/abs/2505.13374</link>
      <description>arXiv:2505.13374v1 Announce Type: cross 
Abstract: This paper presents a novel structure-preserving scheme for Euler equations, focusing on the numerical conservation of entropy and kinetic energy. Explicit flux functions engineered to conserve entropy are introduced within the finite-volume framework. Further, discrete kinetic energy conservation too is introduced. A systematic inquiry is presented, commencing with an overview of numerical entropy conservation and formulation of entropy-conserving and kinetic energy-preserving fluxes, followed by the study of their properties and efficacy. A novelty introduced is to associate numerical entropy conservation to the discretization of the energy conservation equation. Furthermore, an entropy-stable shock-capturing diffusion method and a hybrid approach utilizing the entropy distance to manage smooth regions effectively are also introduced. The addition of artificial viscosity in appropriate regions ensures entropy generation sufficient to prevent numerical instabilities. Various test cases, showcasing the efficacy and stability of the proposed methodology, are presented.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.13374v1</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Kunal Bahuguna, Ramesh Kolluru, S. V. Raghurama Rao</dc:creator>
    </item>
    <item>
      <title>Goupil: A Monte Carlo engine for the backward transport of low-energy gamma-rays</title>
      <link>https://arxiv.org/abs/2412.02414</link>
      <description>arXiv:2412.02414v2 Announce Type: replace 
Abstract: Goupil is a software library designed for the Monte Carlo transport of low-energy gamma-rays, such as those emitted from radioactive isotopes. The library is distributed as a Python module. It implements a dedicated backward sampling algorithm that is highly effective for geometries where the source size largely exceeds the detector size. When used in conjunction with a conventional Monte Carlo engine (i.e., Geant), the response of a scintillation detector to gamma-active radio-isotopes scattered over the environment is accurately simulated (to the nearest percent) while achieving events rates of a few kHz (with a ~2.3 GHz CPU).</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.02414v2</guid>
      <category>physics.comp-ph</category>
      <category>nucl-ex</category>
      <category>physics.geo-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <arxiv:DOI>10.1016/j.cpc.2025.109653</arxiv:DOI>
      <arxiv:journal_reference>Comput. Phys. Commun. (2025) 109653</arxiv:journal_reference>
      <dc:creator>Valentin Niess, Kinson Vernet, Luca Terray</dc:creator>
    </item>
    <item>
      <title>OpenOrbitalOptimizer -- a reusable open source library for self-consistent field calculations</title>
      <link>https://arxiv.org/abs/2503.23034</link>
      <description>arXiv:2503.23034v2 Announce Type: replace 
Abstract: According to the modern paradigms of software engineering, standard tasks are best accomplished by reusable open source libraries. We describe OpenOrbitalOptimizer: a reusable open source C++ library for the iterative solution of coupled self-consistent field (SCF) equations $\boldsymbol{F}_{p}^{\sigma}(\{\boldsymbol{C}_{p}^{\sigma}\})\boldsymbol{C}_{p}^{\sigma}=\boldsymbol{C}_{p}^{\sigma}\boldsymbol{E}_{p}^{\sigma}$ for an arbitrary number of particle types $p$ and symmetries. Although OpenOrbitalOptimizer is a new project, it already implements standard algorithms for solving SCF equations: Pulay's direct inversion in the iterative subspace (DIIS), energy DIIS (EDIIS), augmented DIIS (ADIIS), and the optimal damping algorithm (ODA). The library was designed as an easy way to introduce the state-of-the-art convergence accelerators in a number of legacy programs. It is easy to interface with various programs, as it only requires a function to evaluate the total energy $E$ and Fock matrices $\{\boldsymbol{F}_{p}^{\sigma}\}$ for a given set of orbitals $\{\boldsymbol{C}_{p}^{\sigma}\}$. The only assumption behind the library is that one is able to easily store Fock and orbital matrices in memory, and to diagonalize the Fock matrices in full, which is the case in the overwhelming majority of quantum chemistry applications. We exemplify the library with nuclear-electronic orbital (NEO) calculations of protonated water clusters with Gaussian-type orbital basis sets. We find that a minimal-basis protonic guess works well, and that the stepwise SCF algorithm requires less computational time than the simultaneous SCF algorithm.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.23034v2</guid>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Susi Lehtola, Lori A. Burns</dc:creator>
    </item>
    <item>
      <title>A boundary integral equation formulation for transient electromagnetic transmission problems on Lipschitz domains</title>
      <link>https://arxiv.org/abs/2407.05823</link>
      <description>arXiv:2407.05823v3 Announce Type: replace-cross 
Abstract: We propose a boundary integral formulation for the dynamic problem of electromagnetic scattering and transmission by homogeneous dielectric obstacles. In the spirit of Costabel and Stephan, we use the transmission conditions to reduce the number of unknown densities and to formulate a system of coupled boundary integral equations describing the scattered and transmitted waves. The system is transformed into the Laplace domain where it is proven to be stable and uniquely solvable. The Laplace domain stability estimates are then used to establish the stability and unique solvability of the original time domain problem. Finally, we show how the bounds obtained in both Laplace and time domains can be used to derive error estimates for semi discrete Galerkin discretizations in space and for fully discrete numerical schemes that use Convolution Quadrature for time discretization and a conforming Galerkin method for discretization of the space variables.</description>
      <guid isPermaLink="false">oai:arXiv.org:2407.05823v3</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>math.AP</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1051/m2an/2025036</arxiv:DOI>
      <dc:creator>Tonatiuh S\'anchez-Vizuet</dc:creator>
    </item>
    <item>
      <title>Complexity of Tensor Product Functions in Representing Antisymmetry</title>
      <link>https://arxiv.org/abs/2501.05958</link>
      <description>arXiv:2501.05958v2 Announce Type: replace-cross 
Abstract: Tensor product function (TPF) approximations have been widely adopted in solving high-dimensional problems, such as partial differential equations and eigenvalue problems, achieving desirable accuracy with computational overhead that scales linearly with problem dimensions. However, recent studies have underscored the extraordinarily high computational cost of TPFs on quantum many-body problems, even for systems with as few as three particles. A key distinction in these problems is the antisymmetry requirement on the unknown functions. In the present work, we rigorously establish that the minimum number of involved terms for a class of TPFs to be exactly antisymmetric increases exponentially fast with the problem dimension. This class encompasses both traditionally discretized TPFs and the recent ones parameterized by neural networks. Our proof exploits the link between the antisymmetric TPFs in this class and the corresponding antisymmetric tensors and focuses on the Canonical Polyadic rank of the latter. As a result, our findings uncover a fundamental incompatibility between antisymmetry and low-rank TPFs in high-dimensional contexts and offer new insights for further developments.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.05958v2</guid>
      <category>math.NA</category>
      <category>cs.NA</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yuyang Wang, Yukuan Hu, Xin Liu</dc:creator>
    </item>
    <item>
      <title>Evaluating many-body stabilizer R\'enyi entropy by sampling reduced Pauli strings: singularities, volume law, and nonlocal magic</title>
      <link>https://arxiv.org/abs/2501.12146</link>
      <description>arXiv:2501.12146v3 Announce Type: replace-cross 
Abstract: We present a novel quantum Monte Carlo method for evaluating the $\alpha$-stabilizer R\'enyi entropy (SRE) for any integer $\alpha\ge 2$. By interpreting $\alpha$-SRE as partition function ratios, we eliminate the sign problem in the imaginary-time path integral by sampling \emph{reduced Pauli strings} within a \emph{reduced configuration space}, which enables efficient classical computations of $\alpha$-SRE and its derivatives to explore magic in previously inaccessible 2D/higher-dimensional systems. We first isolate the free energy part in $2$-SRE, which is a trivial term. Notably, at quantum critical points in 1D/2D transverse field Ising (TFI) models, we reveal nontrivial singularities associated with the \emph{characteristic function} contribution, directly tied to magic. Their interplay leads to complicated behaviors of $2$-SRE, avoiding extrema at critical points generally. In contrast, analyzing the volume-law correction to SRE reveals a discontinuity tied to criticalities, suggesting that it is more informative than the full-state magic. For conformal critical points, we claim it could reflect nonlocal magic residing in correlations. Finally, we verify that $2$-SRE fails to characterize magic in mixed states (e.g. Gibbs states), yielding nonphysical results. This work provides a powerful tool for exploring the roles of magic in large-scale many-body systems, and reveals intrinsic relation between magic and many-body physics.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.12146v3</guid>
      <category>quant-ph</category>
      <category>cond-mat.str-el</category>
      <category>physics.comp-ph</category>
      <category>physics.data-an</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yi-Ming Ding, Zhe Wang, Zheng Yan</dc:creator>
    </item>
    <item>
      <title>Accelerating Numerical Relativity with Code Generation: CUDA-enabled Hyperbolic Relaxation</title>
      <link>https://arxiv.org/abs/2501.14030</link>
      <description>arXiv:2501.14030v2 Announce Type: replace-cross 
Abstract: Next-generation gravitational wave detectors such as Cosmic Explorer, the Einstein Telescope, and LISA, demand highly accurate and extensive gravitational wave (GW) catalogs to faithfully extract physical parameters from observed signals. However, numerical relativity (NR) faces significant challenges in generating these catalogs at the required scale and accuracy on modern computers, as NR codes do not fully exploit modern GPU capabilities. In response, we extend NRPy, a Python-based NR code-generation framework, to develop NRPyEllipticGPU -- a CUDA-optimized elliptic solver tailored for the binary black hole (BBH) initial data problem. NRPyEllipticGPU is the first GPU-enabled elliptic solver in the NR community, supporting a variety of coordinate systems and demonstrating substantial performance improvements on both consumer-grade and HPC-grade GPUs. We show that, when compared to a high-end CPU, NRPyEllipticGPU achieves on a high-end GPU up to a sixteenfold speedup in single precision while increasing double-precision performance by a factor of 2--4. This performance boost leverages the GPU's superior parallelism and memory bandwidth to achieve a compute-bound application and enhancing the overall simulation efficiency. As NRPyEllipticGPU shares the core infrastructure common to NR codes, this work serves as a practical guide for developing full, CUDA-optimized NR codes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2501.14030v2</guid>
      <category>gr-qc</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Samuel D. Tootle, Leonardo R. Werneck, Thiago Assump\c{c}\~ao, Terrence Pierre Jacques, Zachariah B. Etienne</dc:creator>
    </item>
    <item>
      <title>ELECTRA: A Cartesian Network for 3D Charge Density Prediction with Floating Orbitals</title>
      <link>https://arxiv.org/abs/2503.08305</link>
      <description>arXiv:2503.08305v2 Announce Type: replace-cross 
Abstract: We present the Electronic Tensor Reconstruction Algorithm (ELECTRA) - an equivariant model for predicting electronic charge densities using floating orbitals. Floating orbitals are a long-standing concept in the quantum chemistry community that promises more compact and accurate representations by placing orbitals freely in space, as opposed to centering all orbitals at the position of atoms. Finding the ideal placement of these orbitals requires extensive domain knowledge, though, which thus far has prevented widespread adoption. We solve this in a data-driven manner by training a Cartesian tensor network to predict the orbital positions along with orbital coefficients. This is made possible through a symmetry-breaking mechanism that is used to learn position displacements with lower symmetry than the input molecule while preserving the rotation equivariance of the charge density itself. Inspired by recent successes of Gaussian Splatting in representing densities in space, we are using Gaussian orbitals and predicting their weights and covariance matrices. Our method achieves a state-of-the-art balance between computational efficiency and predictive accuracy on established benchmarks.</description>
      <guid isPermaLink="false">oai:arXiv.org:2503.08305v2</guid>
      <category>cs.LG</category>
      <category>physics.chem-ph</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Jonas Elsborg, Luca Thiede, Al\'an Aspuru-Guzik, Tejs Vegge, Arghya Bhowmik</dc:creator>
    </item>
    <item>
      <title>A silicon spin vacuum: isotopically enriched $^{28}$silicon-on-insulator and $^{28}$silicon from ultra-high fluence ion implantation</title>
      <link>https://arxiv.org/abs/2504.03332</link>
      <description>arXiv:2504.03332v2 Announce Type: replace-cross 
Abstract: Isotopically enriched silicon (Si) can greatly enhance qubit coherence times by minimizing naturally occurring $^{29}$Si which has a non-zero nuclear spin. Ultra-high fluence $^{28}$Si ion implantation of bulk natural Si substrates was recently demonstrated as an attractive technique to ultra-high $^{28}$Si isotopic purity. In this work, we apply this $^{28}$Si enrichment process to produce $^{28}$Si and $^{28}$Si-on-insulator (SOI) samples. Experimentally, we produced a $^{28}$Si sample on natural Si substrate with $^{29}$Si depleted to 7~ppm (limited by measurement noise floor), that is at least 100 nm thick. This is achieved with an ion energy that results in a sputter yield of less than one and an ultra-high ion fluence, as supported by our improved computational model that is based on fitting a large number of experiments. Further, our model predicts the $^{29}$Si and $^{30}$Si depletion in our sample to be less than 1~ppm. In the case of SOI, ion implantation conditions are found to be more stringent than those of bulk natural Si in terms of minimizing threading dislocations upon subsequent solid phase epitaxy annealing. Finally, we do not observe open volume defects in our $^{28}$SOI and $^{28}$Si samples after SPE annealing (620\deg C, 10 minutes).</description>
      <guid isPermaLink="false">oai:arXiv.org:2504.03332v2</guid>
      <category>cond-mat.mtrl-sci</category>
      <category>physics.comp-ph</category>
      <category>quant-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-nd/4.0/</dc:rights>
      <dc:creator>Shao Qi Lim, Brett C. Johnson, Sergey Rubanov, Nico Klingner, Bin Gong, Alexander M. Jakob, Danielle Holmes, David N. Jamieson, Jim S. Williams, Jeffrey C. McCallum</dc:creator>
    </item>
    <item>
      <title>Pedestrian mobility citizen science complements expert mapping for enhancing inclusive neighborhood placemaking</title>
      <link>https://arxiv.org/abs/2505.11098</link>
      <description>arXiv:2505.11098v2 Announce Type: replace-cross 
Abstract: Cities are complex systems that demand integrated approaches, with increasing attention focused on the neighborhood level. This study examines the interplay between expert-based mapping and citizen science in the Primer de Maig neighborhood of Granollers, Catalonia, Spain--an area marked by poor-quality public spaces and long-standing socio-economic challenges. Seventy-two residents were organized into 19 groups to record their pedestrian mobility while engaging in protocolized playful social actions. Their GPS identified opportunity units for meaningful public space activation. Although 56% of observed actions occurred within expert-defined units, the remaining 44% took place elsewhere. Clustering analysis of geo-located action stops revealed seven distinct clusters, highlighting overlooked areas with significant social potential. These findings underscore the complementarity of top-down and bottom-up approaches, demonstrating how citizen science and community science approaches enriches urban diagnostics by integrating subjective, community-based perspectives in public space placemaking and informing inclusive, adaptive sustainable urban transformation strategies.</description>
      <guid isPermaLink="false">oai:arXiv.org:2505.11098v2</guid>
      <category>physics.soc-ph</category>
      <category>cs.CY</category>
      <category>physics.comp-ph</category>
      <pubDate>Tue, 20 May 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-nc-sa/4.0/</dc:rights>
      <dc:creator>Ferran Larroya, Josep Perell\'o, Roger Paez, Manuela Valtchanova</dc:creator>
    </item>
  </channel>
</rss>
