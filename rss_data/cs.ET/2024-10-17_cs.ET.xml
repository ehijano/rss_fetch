<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.ET updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.ET</link>
    <description>cs.ET updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.ET" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Fri, 18 Oct 2024 02:19:14 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Malak: AI-based multilingual personal assistant to combat misinformation and generative AI safety issues</title>
      <link>https://arxiv.org/abs/2410.11856</link>
      <description>arXiv:2410.11856v1 Announce Type: cross 
Abstract: The widespread use of AI technologies to generate digital content has led to increased misinformation and online harm. Deep fake technologies, a type of AI, make it easier to create convincing but fake content on social media, leading to various cyber threats. Malicious actors exploit AI capabilities, posing digital, physical, and psychological harm to individuals. While social media platforms have safety measures such as content rating and feedback systems, these are often used by people with higher digital literacy. There is a lack of preventive measures and a need for user-friendly tools that can be used by people with lower digital literacy. Our goal is to create a user-friendly multilingual AI-based personal assistant, Malak, to reduce online harm and promote safe online interactions, benefiting users with lower literacy levels.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11856v1</guid>
      <category>cs.HC</category>
      <category>cs.ET</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Farnaz Farid, Farhad Ahamed</dc:creator>
    </item>
    <item>
      <title>Noise-robust chemical reaction networks training artificial neural networks</title>
      <link>https://arxiv.org/abs/2410.11919</link>
      <description>arXiv:2410.11919v1 Announce Type: cross 
Abstract: Artificial neural networks (NNs) can be implemented using chemical reaction networks (CRNs), where the concentrations of species act as inputs and outputs. In such biochemical computing, noise-robust computing is crucial due to the intrinsic and extrinsic noise present in chemical reactions. Previously suggested CRNs for feed-forward networks often utilized the rectified linear unit (ReLU) or discrete activation functions. However, one concern in this case is the discontinuities of the derivatives of those non-smooth functions, which can cause significant noise disruption during backpropagation. In this study, we propose a CRN that performs both feed-forward and training processes using smooth activation functions to avoid discontinuities in the backpropagation. All reactions occur in a single pot, and the reactions for training are bimolecular. Our case studies on XOR, Iris, MNIST datasets, and a non-linear regression model demonstrate that computation via the CRN (i) maintains accuracy despite noise in the reaction rates and the concentration of species and (ii) is insensitive to the choice of the running time and the magnitude of the noise in comparison to NNs with a non-smooth activation function. This work presents a noise-robust CRN for full NN computation, including backpropagation, paving the way for more stable and efficient biochemical computing systems.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11919v1</guid>
      <category>q-bio.MN</category>
      <category>cs.ET</category>
      <category>physics.chem-ph</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Sunghwa Kang, Jinsu Kim</dc:creator>
    </item>
    <item>
      <title>Enabling Data-Driven and Empathetic Interactions: A Context-Aware 3D Virtual Agent in Mixed Reality for Enhanced Financial Customer Experience</title>
      <link>https://arxiv.org/abs/2410.12051</link>
      <description>arXiv:2410.12051v1 Announce Type: cross 
Abstract: In this paper, we introduce a novel system designed to enhance customer service in the financial and retail sectors through a context-aware 3D virtual agent, utilizing Mixed Reality (MR) and Vision Language Models (VLMs). Our approach focuses on enabling data-driven and empathetic interactions that ensure customer satisfaction by introducing situational awareness of the physical location, personalized interactions based on customer profiles, and rigorous privacy and security standards. We discuss our design considerations critical for deployment in real-world customer service environments, addressing challenges in user data management and sensitive information handling. We also outline the system architecture and key features unique to banking and retail environments. Our work demonstrates the potential of integrating MR and VLMs in service industries, offering practical insights in customer service delivery while maintaining high standards of security and personalization.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12051v1</guid>
      <category>cs.HC</category>
      <category>cs.AI</category>
      <category>cs.ET</category>
      <category>cs.MM</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Cindy Xu, Mengyu Chen, Pranav Deshpande, Elvir Azanli, Runqing Yang, Joseph Ligman</dc:creator>
    </item>
    <item>
      <title>Sensing-assisted Near-field Energy Beam Focusing with ELAA Over Non-stationary Channels</title>
      <link>https://arxiv.org/abs/2410.12579</link>
      <description>arXiv:2410.12579v1 Announce Type: cross 
Abstract: This paper studies a novel training-free energy beam focusing approach for a near-field wireless power transfer (WPT) system with extremely large-scale antenna array (ELAA). In particular, we focus on the setup with one access point (AP) equipped with an extremely large-scale uniform planar array (UPA) serving multiple single-antenna energy receivers (ERs), in which the line-of-sight (LoS) dominated wireless channels are dependent on the relative positions of ERs and exhibit spatial non-stationarity. Different from conventional designs relying on training and feedback, we present a novel energy beam focusing design assisted by wireless radar sensing based on a two-stage transmission protocol. In the first stage, the AP performs wireless radar sensing to identify the ERs' visibility regions (VRs) and estimate their three-dimension (3D) positions for constructing the corresponding channel state information (CSI). In the second stage, the AP implements the transmit energy beam focusing based on the constructed CSI to efficiently charge these ERs. Under this setup, we first minimize the sensing duration in the first stage, while guaranteeing a specific accuracy threshold for position estimation. Next, we optimize the energy beamformers at the AP in the second stage to maximize the weighted harvested energy among all ERs subject to the maximum transmit power constraint. In this approach, the time resource allocation between the two stages is properly designed to optimize the ultimate energy transfer performance. Numerical results show that the proposed design performs close to the performance upper bound with perfect VR and CSI and significantly outperforms other benchmark schemes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12579v1</guid>
      <category>cs.IT</category>
      <category>cs.ET</category>
      <category>math.IT</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Li Zhang, Zixiang Ren, Yuan Fang, Ling Qiu, Jie Xu</dc:creator>
    </item>
    <item>
      <title>Simulation of Quantum Computers: Review and Acceleration Opportunities</title>
      <link>https://arxiv.org/abs/2410.12660</link>
      <description>arXiv:2410.12660v1 Announce Type: cross 
Abstract: Quantum computing has the potential to revolutionize multiple fields by solving complex problems that can not be solved in reasonable time with current classical computers. Nevertheless, the development of quantum computers is still in its early stages and the available systems have still very limited resources. As such, currently, the most practical way to develop and test quantum algorithms is to use classical simulators of quantum computers. In addition, the development of new quantum computers and their components also depends on simulations.
  Given the characteristics of a quantum computer, their simulation is a very demanding application in terms of both computation and memory. As such, simulations do not scale well in current classical systems. Thus different optimization and approximation techniques need to be applied at different levels.
  This review provides an overview of the components of a quantum computer, the levels at which these components and the whole quantum computer can be simulated, and an in-depth analysis of different state-of-the-art acceleration approaches. Besides the optimizations that can be performed at the algorithmic level, this review presents the most promising hardware-aware optimizations and future directions that can be explored for improving the performance and scalability of the simulations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.12660v1</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Alessio Cicero, Mohammad Ali Maleki, Muhammad Waqar Azhar, Anton Frisk Kockum, Pedro Trancoso</dc:creator>
    </item>
    <item>
      <title>Quantum Fourier Transform for Image Processing</title>
      <link>https://arxiv.org/abs/2305.05953</link>
      <description>arXiv:2305.05953v2 Announce Type: replace-cross 
Abstract: Quantum information processing and its subfield, quantum image processing, are rapidly growing fields as a result of advancements in the practicality of quantum mechanics. In this paper, we propose a quantum algorithm for processing information, such as one-dimensional time series and two-dimensional images, in the frequency domain. The information of interest is encoded into the magnitude of probability amplitude or the coefficient of each basis state. The oracle for filtering operates based on postselection results, and its explicit circuit design is presented. This oracle is versatile enough to perform all basic filtering, including high pass, low pass, band pass, band stop, and many other processing techniques. Finally, we present two novel schemes for transposing matrices in this paper. They use similar encoding rules but with deliberate choices in terms of selecting basis states. These schemes could potentially be useful for other quantum information processing tasks, such as edge detection. The proposed techniques are implemented on the IBM Qiskit quantum simulator. Some results are compared with traditional information processing results to verify their correctness and are presented in this paper.</description>
      <guid isPermaLink="false">oai:arXiv.org:2305.05953v2</guid>
      <category>quant-ph</category>
      <category>cs.DS</category>
      <category>cs.ET</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ze Yu Zhang, Weibo Gao</dc:creator>
    </item>
    <item>
      <title>Unleashing quantum algorithms with Qinterpreter: bridging the gap between theory and practice across leading quantum computing platforms</title>
      <link>https://arxiv.org/abs/2310.07173</link>
      <description>arXiv:2310.07173v3 Announce Type: replace-cross 
Abstract: Quantum computing is a rapidly emerging and promising field that has the potential to revolutionize numerous research domains, including drug design, network technologies and sustainable energy. Due to the inherent complexity and divergence from classical computing, several major quantum computing libraries have been developed to implement quantum algorithms, namely IBM Qiskit, Amazon Braket, Cirq, PyQuil, and PennyLane. These libraries allow for quantum simulations on classical computers and facilitate program execution on corresponding quantum hardware, e.g., Qiskit programs on IBM quantum computers. While all platforms have some differences, the main concepts are the same. QInterpreter is a tool embedded in the Quantum Science Gateway QubitHub using Jupyter Notebooks that translates seamlessly programs from one library to the other and visualizes the results. It combines the five well-known quantum libraries: into a unified framework. Designed as an educational tool for beginners, Qinterpreter enables the development and execution of quantum circuits across various platforms in a straightforward way. The work highlights the versatility and accessibility of Qinterpreter in quantum programming and underscores our ultimate goal of pervading Quantum Computing through younger, less specialized, and diverse cultural and national communities.</description>
      <guid isPermaLink="false">oai:arXiv.org:2310.07173v3</guid>
      <category>quant-ph</category>
      <category>cs.ET</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Wilmer Contreras Sep\'ulveda, \'Angel David Torres-Palencia, Jos\'e Javier S\'anchez Mondrag\'on, Braulio Misael Villegas-Mart\'inez, J. Jes\'us Escobedo-Alatorre, Sandra Gesing, N\'estor Lozano-Cris\'ostomo, Julio C\'esar Garc\'ia-Melgarejo, Juan Carlos S\'anchez P\'erez, Eddie Nelson Palacios- P\'erez, Omar PalilleroSandoval</dc:creator>
    </item>
    <item>
      <title>Exploring Smartphone-based Spectrophotometry for Nutrient Identification and Quantification</title>
      <link>https://arxiv.org/abs/2410.11027</link>
      <description>arXiv:2410.11027v2 Announce Type: replace-cross 
Abstract: Imbalanced nutrition is a global health issue with significant downstream effects. Current methods of assessing nutrient levels face several limitations, with accessibility being a major concern. In this paper, we take a step towards accessibly measuring nutrient status within the body. We explore the potential of smartphone-based spectrophotometry for identifying and quantifying nutrients in a solution by building and testing two prototype devices. We compared the prototypes and found that the limitations posed by the initial, simpler prototype were well addressed in the more portable and reliable second-generation device. With the second-generation prototype, we created and implemented a semi-automatic signal processing and analysis pipeline for analyzing absorption spectra. We thoroughly evaluated the prototypes by analyzing the effect of four different light sources and three reference spectra strategies. Results demonstrate that an LED bulb light source performed best, and all reference spectra strategies performed similarly. We then compared the second-generation prototype to a benchtop laboratory spectrophotometer to further validate the device. We applied the Beer-Lambert Law to demonstrate that our prototype is able to quantify the amount of vitamin B12 in a solution with an accuracy of up to 91.3%. Our in-depth analyses, discussions, and results demonstrate the potential use of smartphone-based spectrophotometry as an accessible method to identify and quantify nutrients and pave the way for future developments that can apply this approach to the human body.</description>
      <guid isPermaLink="false">oai:arXiv.org:2410.11027v2</guid>
      <category>physics.med-ph</category>
      <category>cs.ET</category>
      <pubDate>Thu, 17 Oct 2024 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Andrew Balch, Maria A. Cardei, Afsaneh Doryab</dc:creator>
    </item>
  </channel>
</rss>
