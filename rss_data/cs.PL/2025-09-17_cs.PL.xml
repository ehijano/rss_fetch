<?xml version='1.0' encoding='UTF-8'?>
<rss xmlns:arxiv="http://arxiv.org/schemas/atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/" version="2.0">
  <channel>
    <title>cs.PL updates on arXiv.org</title>
    <link>http://rss.arxiv.org/rss/cs.PL</link>
    <description>cs.PL updates on the arXiv.org e-print archive.</description>
    <atom:link href="http://rss.arxiv.org/rss/cs.PL" rel="self" type="application/rss+xml"/>
    <docs>http://www.rssboard.org/rss-specification</docs>
    <language>en-us</language>
    <lastBuildDate>Thu, 18 Sep 2025 01:34:09 +0000</lastBuildDate>
    <managingEditor>rss-help@arxiv.org</managingEditor>
    <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
    <skipDays>
      <day>Sunday</day>
      <day>Saturday</day>
    </skipDays>
    <item>
      <title>Converting IEC 61131-3 LD into SFC Using Large Language Model: Dataset and Testing</title>
      <link>https://arxiv.org/abs/2509.12593</link>
      <description>arXiv:2509.12593v1 Announce Type: new 
Abstract: In the domain of Programmable Logic Controller (PLC) programming, converting a Ladder Diagram (LD) into a Sequential Function Chart (SFC) is an inherently challenging problem, primarily due to the lack of domain-specific knowledge and the issue of state explosion in existing algorithms. However, the rapid development of Artificial Intelligence (AI) - especially Large Language Model (LLM) - offers a promising new approach.
  Despite this potential, data-driven approaches in this field have been hindered by a lack of suitable datasets. To address this gap, we constructed several datasets consisting of paired textual representations of SFC and LD programs that conform to the IEC 61131-3 standard.
  Based on these datasets, we explored the feasibility of automating the LD-SFC conversion using LLM. Our preliminary experiments show that a fine-tuned LLM model achieves up to 91% accuracy on certain dataset, with the lowest observed accuracy being 79%, suggesting that with proper training and representation, LLMs can effectively support LD-SFC conversion. These early results highlight the viability and future potential of this approach.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.12593v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <dc:creator>Yimin Zhang, Mario de Sousa</dc:creator>
    </item>
    <item>
      <title>Efficient Compilation of Algorithms into Compact Linear Programs</title>
      <link>https://arxiv.org/abs/2509.13006</link>
      <description>arXiv:2509.13006v1 Announce Type: new 
Abstract: Linear Programming (LP) is widely applied in industry and is a key component of various other mathematical problem-solving techniques. Recent work introduced an LP compiler translating polynomial-time, polynomial-space algorithms into polynomial-size LPs using intuitive high-level programming languages, offering a promising alternative to manually specifying each set of constraints through Algebraic Modeling Languages (AMLs). However, the resulting LPs, while polynomial in size, are often extremely large, posing challenges for existing LP solvers. In this paper, we propose a novel approach for generating substantially smaller LPs from algorithms. Our goal is to establish minimum-size compact LP formulations for problems in P having natural formulations with exponential extension complexities. Our broader vision is to enable the systematic generation of Compact Integer Programming (CIP) formulations for problems with exponential-size IPs having polynomial-time separation oracles. To this end, we introduce a hierarchical linear pipelining technique that decomposes nested program structures into synchronized regions with well-defined execution transitions -- functions of compile-time parameters. This decomposition allows us to localize LP constraints and variables within each region, significantly reducing LP size without the loss of generality, ensuring the resulting LP remains valid for all inputs of size $n$. We demonstrate the effectiveness of our method on two benchmark problems -- the makespan problem, which has exponential extension complexity, and the weighted minimum spanning tree problem -- both of which have exponential-size natural LPs. Our results show up to a $25$-fold reduction in LP size and substantial improvements in solver performance across both commercial and non-commercial LP solvers.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13006v1</guid>
      <category>cs.PL</category>
      <category>cs.MS</category>
      <category>math.OC</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Shermin Khosravi, David Bremner</dc:creator>
    </item>
    <item>
      <title>Pleasant Imperative Program Proofs with GallinaC</title>
      <link>https://arxiv.org/abs/2509.13019</link>
      <description>arXiv:2509.13019v1 Announce Type: new 
Abstract: Even with the increase of popularity of functional programming, imperative programming remains a key programming paradigm, especially for programs operating at lower levels of abstraction. When such software offers key components of a Trusted Computing Base (TCB), e.g. an operating system kernel, it becomes desirable to provide mathematical correctness proofs.
  However, current real-world imperative programming languages possess "expressive", i.e. overly permissive, semantics. Thus, producing correctness proofs of such programs becomes tedious and error-prone, requiring to take care of numerous "administrative" details. Ideally, a proof-oriented imperative language should feature well-behaved semantics while allowing imperative idioms.
  To obtain a high-degree of confidence in the correctness of such a language, its tools should be developed inside a proof-assistant such that program proofs are machine checked.
  We present GallinaC, a shallow embedding of a Turing-complete imperative language directly inside the functional programming language of the Rocq proof assistant, Gallina. In particular, it features a truly generic and unbounded while loop. Having a functional core means proofs about GallinaC programs may use the same tactics as proofs about pure functional ones.
  Work on GallinaC is still under progress, but we present first promising results. A prototype implementation has shown the viability of GallinaC with the correctness proof of a list reversal procedure for linked-lists of unknown size. We currently focus on the forward simulation between the GallinaC intermediate representation (IR) and Cminor, the entry language of the CompCert back-end.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13019v1</guid>
      <category>cs.PL</category>
      <category>cs.LO</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.427.2</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 427, 2025, pp. 24-32</arxiv:journal_reference>
      <dc:creator>Fr\'ed\'eric Fort, David Nowak, Vlad Rusu</dc:creator>
    </item>
    <item>
      <title>Navigating the Python Type Jungle</title>
      <link>https://arxiv.org/abs/2509.13022</link>
      <description>arXiv:2509.13022v1 Announce Type: new 
Abstract: Python's typing system has evolved pragmatically into a powerful but theoretically fragmented system, with scattered specifications. This paper proposes a formalization to address this fragmentation. The central contribution is a formal foundation that uses concepts from type theory to demonstrate that Python's type system can be elegantly described. This work aims to serve as a crucial first step toward the future development of type inference tools.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13022v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.427.6</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 427, 2025, pp. 79-97</arxiv:journal_reference>
      <dc:creator>Andrei Nacu (Faculty of Computer Science, Alexandru Ioan Cuza University, Ia\c{s}i), Dorel Lucanu (Faculty of Computer Science, Alexandru Ioan Cuza University, Ia\c{s}i)</dc:creator>
    </item>
    <item>
      <title>Try-Mopsa: Relational Static Analysis in Your Pocket</title>
      <link>https://arxiv.org/abs/2509.13128</link>
      <description>arXiv:2509.13128v1 Announce Type: new 
Abstract: Static analyzers are complex pieces of software with large dependencies. They can be difficult to install, which hinders adoption and creates barriers for students learning static analysis. This work introduces Try-Mopsa: a scaled-down version of the Mopsa static analysis platform, compiled into JavaScript to run purely as a client-side application in web browsers. Try-Mopsa provides a responsive interface that works on both desktop and mobile devices. Try-Mopsa features all the core components of Mopsa. In particular, it supports relational numerical domains. We present the interface, changes and adaptations required to have a pure JavaScript version of Mopsa. We envision Try-Mopsa as a convenient platform for onboarding or teaching purposes.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13128v1</guid>
      <category>cs.PL</category>
      <category>cs.SE</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Rapha\"el Monat</dc:creator>
    </item>
    <item>
      <title>Rebound: Efficient, Expressive, and Well-Scoped Binding</title>
      <link>https://arxiv.org/abs/2509.13261</link>
      <description>arXiv:2509.13261v1 Announce Type: new 
Abstract: We introduce the Rebound library that supports well-scoped term representations in Haskell and automates the definition of substitution, alpha-equivalence, and other operations that work with binding structures. The key idea of our design is the use of first-class environments that map variables to expressions in some new scope. By statically tracking scopes, users of this library gain confidence that they have correctly maintained the subtle invariants that stem from using de Bruijn indices. Behind the scenes, Rebound uses environments to optimize the application of substitutions, while providing explicit access to these data structures when desired. We demonstrate that this library is expressive by using it to implement a wide range of language features with sophisticated uses of binding and several different operations that use this abstract syntax. Our examples include pi-forall, a tutorial implementation of a type checker for a dependently-typed programming language. Finally, we benchmark Rebound to understand its performance characteristics and find that it produces faster code than competing libraries.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13261v1</guid>
      <category>cs.PL</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>new</arxiv:announce_type>
      <dc:rights>http://arxiv.org/licenses/nonexclusive-distrib/1.0/</dc:rights>
      <arxiv:DOI>10.1145/3759164.3759348</arxiv:DOI>
      <dc:creator>No\'e De Santo, Stephanie Weirich</dc:creator>
    </item>
    <item>
      <title>The Hidden Strength of Costrong Functors</title>
      <link>https://arxiv.org/abs/2509.13026</link>
      <description>arXiv:2509.13026v1 Announce Type: cross 
Abstract: Strong functors and monads are ubiquitous in Computer Science. More recently, comonads have demonstrated their use in structuring context-dependent notions of computation. However, the dualisation of ``being strong'' property passed somehow unobserved so far. We argue that ``being costrong'' gives a different understanding of how functors can interact with monoidal structures. This work in progress aims to explore costrong functors and their natural properties, with an eye towards the semantics of computations. </description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13026v1</guid>
      <category>cs.LO</category>
      <category>cs.PL</category>
      <category>math.CT</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <arxiv:DOI>10.4204/EPTCS.427.10</arxiv:DOI>
      <arxiv:journal_reference>EPTCS 427, 2025, pp. 141-154</arxiv:journal_reference>
      <dc:creator>Adriana Balan (Department of Mathematical Methods,Models,,Fundamental Sciences Applied in Engineering Research Center, National University of Science,Technology POLITEHNICA Bucharest), Silviu-George Pantelimon (Department of Computer Science, National University of Science,Technology POLITEHNICA Bucharest)</dc:creator>
    </item>
    <item>
      <title>On the Fixed Point Property in Reflexive Banach Spaces</title>
      <link>https://arxiv.org/abs/2509.13121</link>
      <description>arXiv:2509.13121v1 Announce Type: cross 
Abstract: Fixed point theory studies conditions under which nonexpansive maps on Banach spaces have fixed points. This paper examines the open question of whether every reflexive Banach space has the fixed point property. After surveying classical results, we propose a quantitative framework based on diametral l1 pressure and weighted selection functionals, which measure how much an orbit hull of a fixed point free nonexpansive map can collapse. We prove that if either invariant is uniformly positive, then the space must contain a copy of l1 and thus cannot be reflexive. We present finite dimensional certificates, positive and negative examples, and an x86-64 routine that computes mutual coherence and a lower bound for the pressure. The paper clarifies why existing approaches fail and outlines open problems and ethical considerations.</description>
      <guid isPermaLink="false">oai:arXiv.org:2509.13121v1</guid>
      <category>math.FA</category>
      <category>cs.PL</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by-sa/4.0/</dc:rights>
      <dc:creator>Faruk Alpay, Hamdi Alakkad</dc:creator>
    </item>
    <item>
      <title>Enhancing Automated Loop Invariant Generation for Complex Programs with Large Language Models</title>
      <link>https://arxiv.org/abs/2412.10483</link>
      <description>arXiv:2412.10483v3 Announce Type: replace-cross 
Abstract: Automated program verification has always been an important component of building trustworthy software. While the analysis of real-world programs remains a theoretical challenge, the automation of loop invariant analysis has effectively resolved the problem. However, real-world programs that often mix complex data structures and control flows pose challenges to traditional loop invariant generation tools. To enhance the applicability of invariant generation techniques, we proposed ACInv, an Automated Complex program loop Invariant generation tool, which combines static analysis with Large Language Models (LLMs) to generate the proper loop invariants. We utilize static analysis to extract the necessary information for each loop and embed it into prompts for the LLM to generate invariants for each loop. Subsequently, we employ an LLM-based evaluator to assess the generated invariants, refining them by either strengthening, weakening, or rejecting them based on their correctness, ultimately obtaining enhanced invariants. We conducted experiments on ACInv, which showed that ACInv outperformed previous tools on data sets with data structures, and maintained similar performance to the state-of-the-art tool AutoSpec on numerical programs without data structures. For the total data set, ACInv can solve 21% more examples than AutoSpec and can generate reference data structure templates.</description>
      <guid isPermaLink="false">oai:arXiv.org:2412.10483v3</guid>
      <category>cs.SE</category>
      <category>cs.AI</category>
      <category>cs.PL</category>
      <pubDate>Wed, 17 Sep 2025 00:00:00 -0400</pubDate>
      <arxiv:announce_type>replace-cross</arxiv:announce_type>
      <dc:rights>http://creativecommons.org/licenses/by/4.0/</dc:rights>
      <dc:creator>Ruibang Liu, Minyu Chen, Ling-I Wu, Jingyu Ke, Guoqiang Li</dc:creator>
    </item>
  </channel>
</rss>
